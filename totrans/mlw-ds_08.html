<html><head></head><body>
<h2 class="h2" id="ch08"><span epub:type="pagebreak" id="page_127"/><strong><span class="big">8</span></strong><br/><strong>BUILDING MACHINE LEARNING DETECTORS</strong></h2>
<div class="image1"><img alt="image" src="../images/common01.jpg"/></div>
<p class="noindent">Today, thanks to high-quality open source software that handles the heavy mathematical lifting of implementing machine learning systems, anyone who knows basic Python and understands the key concepts can use machine learning.</p>
<p class="indent">In this chapter, I show you how to build machine learning malware detection systems using <code>scikit-learn</code>, the most popular—and the best, in my opinion—open source machine learning package available. This chapter contains a lot of sample code. The major code blocks are accessible in the directory <em>malware_data_science/ch8/code</em>, and the corresponding sample data is accessible in the directory <em>malware_data_science/ch8/data</em> in the code and data (and on the virtual machine) accompanying this book.</p>
<p class="indent">By following along with the text, examining the sample code, and trying out the provided examples, you should be comfortable building and evaluating your own machine learning systems by the end of the chapter. You also learn to build a general malware detector and use the necessary tools to build malware detectors for specific malware families. The skills <span epub:type="pagebreak" id="page_128"/>you gain here will have a broad application, allowing you to apply machine learning to other security problems, such as detecting malicious emails or suspicious network streams.</p>
<p class="indent">First, you learn the terminology and concepts you need to know before using <code>scikit-learn</code>. Then, you use <code>scikit-learn</code> to implement a basic decision tree detector based on the decision tree concepts you learned in <a href="ch06.xhtml#ch06">Chapter 6</a>. Next, you learn how to integrate feature extraction code with <code>scikit-learn</code> to build a real-world malware detector that uses real-world feature extraction and a random forest approach to detect malware. Finally, you learn how to use <code>scikit-learn</code> to evaluate machine learning systems with the sample random forest detector.</p>
<h3 class="h3" id="lev122"><strong>Terminology and Concepts</strong></h3>
<p class="noindent">Let’s review some terminology first. The open source library <code>scikit-learn</code> (<code>sklearn</code> for short) has become popular in the machine learning community because it’s both powerful and easy to use. Many data scientists use the library within the computer security community and in other fields, and many rely on it as their main toolbox for performing machine learning tasks. Although <code>sklearn</code> is constantly being updated with new machine learning approaches, it provides a consistent programming interface that makes using these machine learning approaches simple.</p>
<p class="indent">Like many machine learning frameworks, <code>sklearn</code> requires training data in <em>vector</em> form. Vectors are arrays of numbers where each index in the array corresponds to a single feature of the training example software binary. For example, if the two features of software binaries our machine learning detector uses are <code>is compressed</code> and <code>contains encrypted data</code>, then our feature vector for a training example binary could be <code>[0,1]</code>. Here, the first index in the vector would represent whether or not the binary is compressed, with the zero indicating “no,” and the second index would represent whether or not the binary contains encrypted data, with the one indicating “yes.”</p>
<p class="indent">Vectors can be awkward to work with because you have to remember what feature each index maps to. Fortunately, <code>sklearn</code> provides helper code that translates other data representations to vector form. For example, you can use <code>sklearn</code>’s <code>DictVectorizer</code> class to transform dictionary representations of your training data (for instance, <code>{"is compressed":1,"contains encrypted</code> <code>data":0}</code>) into the vector representation that <code>sklearn</code> operates on, like <code>[0,1]</code>. Later, you can use the <code>DictVectorizer</code> to recover the mapping between the vector’s indices and the original feature names.</p>
<p class="indent">To train an <code>sklearn</code>-based detector, you need to pass in two separate objects to <code>sklearn</code>: feature vectors (as described previously) and a label vector. A <em>label vector</em> contains one number per training example, which corresponds, in our case, to whether or not the example is malware or benignware. For instance, if we pass three training examples to <code>sklearn</code>, and then pass the label vector <code>[0,1,0]</code>, we’re telling <code>sklearn</code> that the first sample is benignware, the second sample is malware, and the third is benignware. By convention, machine learning engineers use a capital <code>X</code> <span epub:type="pagebreak" id="page_129"/>variable to represent the training data and a lowercase <code>y</code> variable to represent the labels. The difference in case reflects the convention in mathematics of capitalizing variables that represent matrices (which we can think of as arrays of vectors) and lowercasing variables that represent individual vectors. You’ll see this convention used in machine learning sample code online, and I use this convention for the remainder of this book to get you comfortable with it.</p>
<p class="indent">The <code>sklearn</code> framework uses other terminology that you might find new as well. Instead of calling machine learning–based detectors “detectors,” <code>sklearn</code> calls them “classifiers.” In this context, the term <em>classifier</em> simply means a machine learning system that categorizes things into two or more categories. Therefore, a <em>detector</em> (the term I use throughout this book) is a special type of a classifier that places things into two categories, like malware and benignware. Also, instead of using the term <em>training</em>, <code>sklearn</code>’s documentation and API often use the term <em>fit</em>. For example, you’ll see a sentence like “fit a machine learning classifier using training examples,” which is the equivalent to saying “train a machine learning detector using training examples.”</p>
<p class="indent">Finally, instead of using the term <em>detect</em> in the context of classifiers, <code>sklearn</code> uses the term <em>predict</em>. This term is used in <code>sklearn</code>’s framework, and in the machine learning community more generally, whenever a machine learning system is used to perform a task, whether to predict the value of a stock a week from now or detect whether an unknown binary is malware.</p>
<h3 class="h3" id="lev123"><strong>Building a Toy Decision Tree–Based Detector</strong></h3>
<p class="noindent">Now that you’re familiar with <code>sklearn</code>’s technical terminology, let’s create a simple decision tree along the lines of what we discussed in <a href="ch06.xhtml#ch06">Chapter 6</a>, using the <code>sklearn</code> framework. Recall that decision trees play a “20 questions” type of game in which they ask a series of questions about input vectors to arrive at a decision concerning whether these vectors are malicious or benign. We walk through building a decision tree classifier, step by step, and then explore an example of a complete program. <a href="ch08.xhtml#ch08list1">Listing 8-1</a> shows how to import the requisite modules from <code>sklearn</code>.</p>
<pre>from sklearn import tree<br/>from sklearn.feature_extraction import DictVectorizer</pre>
<p class="listing" id="ch08list1"><em>Listing 8-1: Importing</em> <span class="codeitalic">sklearn</span> <em>modules</em></p>
<p class="indent">The first module we import, <code>tree</code>, is <code>sklearn</code>’s decision tree module. The second module, <code>feature_extraction</code>, is <code>sklearn</code>’s helper module from which we import the <code>DictVectorizer</code> class. The <code>DictVectorizer</code> class conveniently translates the training data provided in readable, dictionary form to the vector representation that <code>sklearn</code> requires to actually train machine learning detectors.</p>
<p class="indent">After we import the modules we need from <code>sklearn</code>, we instantiate the requisite <code>sklearn</code> classes, as shown in <a href="ch08.xhtml#ch08list2">Listing 8-2</a>.</p>
<pre><span epub:type="pagebreak" id="page_130"/>classifier = <span class="ent">➊</span>tree.DecisionTreeClassifier()<br/>vectorizer = <span class="ent">➋</span>DictVectorizer(sparse=<span class="ent">➌</span>False)</pre>
<p class="listing" id="ch08list2"><em>Listing 8-2: Initializing the decision tree classifier and vectorizer</em></p>
<p class="indent">The first class we instantiate, <code>DecisionTreeClassifier</code> <span class="ent">➊</span>, represents our detector. Although <code>sklearn</code> provides a number of parameters that control exactly how our decision tree will work, here we don’t select any parameters so that we’re using <code>sklearn</code>’s default decision tree settings.</p>
<p class="indent">The next class we instantiate is <code>DictVectorizer</code> <span class="ent">➋</span>. We set <code>sparse</code> to <code>False</code> <span class="ent">➌</span> in the constructor, telling <code>sklearn</code> that we do not want it to use sparse vectors, which save memory but are complicated to work with. Because <code>sklearn</code>’s decision tree module can’t use sparse vectors, we turn this feature off.</p>
<p class="indent">Now that we have instantiated our classes, we can initialize some sample training data, as shown in <a href="ch08.xhtml#ch08list3">Listing 8-3</a>.</p>
<pre>   # declare toy training data<br/><span class="ent">➊</span> training_examples = [<br/>   {'packed':1,'contains_encrypted':0},<br/>   {'packed':0,'contains_encrypted':0},<br/>   {'packed':1,'contains_encrypted':1},<br/>   {'packed':1,'contains_encrypted':0},<br/>   {'packed':0,'contains_encrypted':1},<br/>   {'packed':1,'contains_encrypted':0},<br/>   {'packed':0,'contains_encrypted':0},<br/>   {'packed':0,'contains_encrypted':0},<br/>   ]<br/><span class="ent">➋</span> ground_truth = [1,1,1,1,0,0,0,0]</pre>
<p class="listing" id="ch08list3"><em>Listing 8-3: Declaring training and label vectors</em></p>
<p class="indent">In this example, we initialize two structures—feature vectors and a label vector—that together comprise our training data. The feature vectors, assigned to the <code>training_examples</code> variable <span class="ent">➊</span>, are given in dictionary form. As you can see, we’re using two simple features. The first is <code>packed</code>, which represents whether a given file is packed, and the second is <code>contains_encrypted</code>, which represents whether the file contains encrypted data. The label vector, which is assigned to the <code>ground_truth</code> variable <span class="ent">➋</span>, represents whether each training example is malicious or benign. In this book, and in general among security data scientists, 0 always stands for benign and 1 always stands for malicious. In this case, the label vector declares that the first four feature vectors are malicious and the second four are benign.</p>
<h4 class="h4" id="lev124"><strong><em>Training Your Decision Tree Classifier</em></strong></h4>
<p class="noindent">Now that we’ve declared our training vectors and label vector, let’s train our decision tree model by calling the decision tree class instance’s <code>fit</code> method, as shown in <a href="ch08.xhtml#ch08list4">Listing 8-4</a>.</p>
<pre>   # initialize the vectorizer with the training data<br/><span class="ent">➊</span> vectorizer.fit(training_examples)<br/><span epub:type="pagebreak" id="page_131"/>   # transform the training examples to vector form<br/><span class="ent">➋</span> X = vectorizer.transform(training_examples)<br/>   y = ground_truth # call ground truth 'y', by convention</pre>
<p class="listing" id="ch08list4"><em>Listing 8-4: Initializing the</em> <span class="codeitalic">vectorizer</span> <em>class with training data</em></p>
<p class="indent">The code in <a href="ch08.xhtml#ch08list4">Listing 8-4</a> first initializes the <code>vectorizer</code> class that we initialized in <a href="ch08.xhtml#ch08list2">Listing 8-2</a> by calling the <code>fit</code> method <span class="ent">➊</span>. Here, the <code>fit</code> method tells <code>sklearn</code> to create a mapping between the <code>packed</code> feature and the <code>contains_encrypted</code> feature and vector array indices. Then we transform our dictionary-based feature vectors into numerical vector form by calling the <code>vectorizer</code> class’s <code>transform</code> method <span class="ent">➋</span>. Recall that we assign our feature vectors to a variable called <code>X</code> and our label vector to a variable called <code>y</code>, which is the naming convention in the machine learning community.</p>
<p class="indent">Now that we’re all set up with our training data, we can train our decision tree detector by calling the <code>fit</code> method on the decision tree classifier instances, like this:</p>
<pre># train the classifier (a.k.a. 'fit' the classifier)<br/>classifier.fit(X,y)</pre>
<p class="indent">As you can see, training the <code>sklearn</code> detector is as simple as that. But behind the scenes, <code>sklearn</code> is going through the algorithmic process of identifying a good decision tree for accurately detecting whether new software is malicious or benign, along the lines of the algorithm we discussed in the previous chapter.</p>
<p class="indent">Now that we’ve trained the detector, let’s use the code in <a href="ch08.xhtml#ch08list5">Listing 8-5</a> to detect whether a binary is malicious or benign.</p>
<pre>   test_example = <span class="ent">➊</span>{'packed':1,'contains_encrypted':0}<br/>   test_vector = <span class="ent">➋</span>vectorizer.transform(test_example)<br/><span class="ent">➌</span> print classifier.predict(test_vector) # prints [1]</pre>
<p class="listing" id="ch08list5"><em>Listing 8-5: Determining whether a binary is malicious</em></p>
<p class="indent">Here, we instantiate a dictionary-based feature vector for a hypothetical software binary <span class="ent">➊</span>, translate it to numerical vector form using <code>vectorizer</code> <span class="ent">➋</span>, which we declared earlier in our code, and then run the decision tree detector we built <span class="ent">➌</span> to determine whether or not the binary is malicious. You’ll see when we run the code that the classifier “thinks” that the new binary is malicious (because it gives a “1” as its output), and you’ll see why this is the case when we visualize our decision tree.</p>
<h4 class="h4" id="lev125"><strong><em>Visualizing the Decision Tree</em></strong></h4>
<p class="noindent">We can visualize the decision tree that <code>sklearn</code> has automatically created based on our training data, as shown in <a href="ch08.xhtml#ch08list6">Listing 8-6</a>.</p>
<pre># visualize the decision tree<br/>with open(<span class="ent">➊</span>"classifier.dot","w") as output_file:<br/><span epub:type="pagebreak" id="page_132"/>  <span class="ent">➋</span> tree.export_graphviz(<br/>        classifier,<br/>        feature_names=vectorizer.get_feature_names(),<br/>        out_file=output_file<br/>    )<br/><br/>import os<br/>os.system("dot classifier.dot -Tpng -o classifier.png")</pre>
<p class="listing" id="ch08list6"><em>Listing 8-6: Creating an image file of the decision tree using GraphViz</em></p>
<p class="indent">Here, we open a file called <em>classifier.dot</em> <span class="ent">➊</span> to which we write a network representation of our decision tree using the <code>export_graphviz()</code> function that <code>sklearn</code>’s <code>tree</code> module provides. Then we call <code>tree.export_graphviz</code> <span class="ent">➋</span> to write a GraphViz <em>.dot</em> file to <em>classifier.dot</em>, which writes a network representation of the decision tree to disk. Finally, we use the GraphViz <code>dot</code> command line program to create an image file that visualizes the decision tree, in a form that corresponds to what you learned about decision trees in <a href="ch06.xhtml#ch06">Chapter 6</a>. When you run this, you should get an output image file called <em>classifier.png</em> that looks like <a href="ch08.xhtml#ch08fig1">Figure 8-1</a>.</p>
<div class="image"><a id="ch08fig1"/><img alt="image" src="../images/f0132-01.jpg"/></div>
<p class="figcap"><em>Figure 8-1: Decision tree visualization</em></p>
<p class="indent">Although this decision tree visualization should be familiar from <a href="ch06.xhtml#ch06">Chapter 6</a>, it contains some new vocabulary. The first line in each box contains the name of the feature about which the node asks a question (in machine learning parlance, we say that the node “splits on” this feature). For example, the first node splits on the feature “packed”: if a binary is not packed, we move along the left arrow; otherwise, we move along the right arrow.</p>
<p class="indent">The second line of text in each box refers to that node’s <em>gini index</em>, which measures how much inequality there is between the malware and benignware training examples that match that node. The higher the gini index, the more skewed the samples that match that node are toward either benignware or malware. This means that a high gini index in each node is good, because the more the training examples skew toward either malware <span epub:type="pagebreak" id="page_133"/>or benignware, the more sure we are about whether new test examples are malware or benignware. The third line in each box just gives the number of training examples that matched that node.</p>
<p class="indent">You’ll notice that in the leaf nodes of the tree, the text in the box is different. These nodes don’t “ask a question;” instead, they provide an answer to the question “is this binary malicious or benign?” For example, in the leftmost leaf node, we have “value = [2. 1.],” which means that two benign training examples matched this node (not packed and not encrypted) and one malware training example matched the node. That is, if we reach this node, we’d assign a probability of 33 percent to the binary being malware (1 malware sample / 3 total samples = 33 percent). The gini value in these boxes shows how much information is gained about whether the binary is malware or benignware when we split on the question directly leading up to these nodes. As you can see, it can be useful to inspect visualizations of decision trees generated by <code>sklearn</code> to understand how our decision trees are making detections.</p>
<h4 class="h4" id="lev126"><strong><em>Complete Sample Code</em></strong></h4>
<p class="noindent"><a href="ch08.xhtml#ch08list7">Listing 8-7</a> shows the complete code for the decision tree workflow I have described thus far. This code should be easily legible to you now that we have worked through the code, piece by piece.</p>
<pre>#!/usr/bin/python<br/><br/># import sklearn modules<br/>from sklearn import tree<br/>from sklearn.feature_extraction import DictVectorizer<br/><br/># initialize the decision tree classifier and vectorizer<br/>classifier = tree.DecisionTreeClassifier()<br/>vectorizer = DictVectorizer(sparse=False)<br/><br/># declare toy training data<br/>training_examples = [<br/>{'packed':1,'contains_encrypted':0},<br/>{'packed':0,'contains_encrypted':0},<br/>{'packed':1,'contains_encrypted':1},<br/>{'packed':1,'contains_encrypted':0},<br/>{'packed':0,'contains_encrypted':1},<br/>{'packed':1,'contains_encrypted':0},<br/>{'packed':0,'contains_encrypted':0},<br/>{'packed':0,'contains_encrypted':0},<br/>]<br/>ground_truth = [1,1,1,1,0,0,0,0]<br/><br/># initialize the vectorizer with the training data<br/>vectorizer.fit(training_examples)<br/><br/># transform the training examples to vector form<br/>X = vectorizer.transform(training_examples)<br/>y = ground_truth # call ground truth 'y', by convention<br/><br/><span epub:type="pagebreak" id="page_134"/># train the classifier (a.k.a. 'fit' the classifier)<br/>classifier.fit(X,y)<br/><br/>test_example = {'packed':1,'contains_encrypted':0}<br/>test_vector = vectorizer.transform(test_example)<br/>print `classifier.predict(test_vector)` # prints [1]<br/><br/>#visualize the decision tree<br/>with open("classifier.dot","w") as output_file:<br/>    tree.export_graphviz(<br/>        classifier,<br/>        feature_names=vectorizer.get_feature_names(),<br/>        out_file=output_file<br/>    )<br/><br/>import os<br/>os.system("dot classifier.dot -Tpng -o classifier.png")</pre>
<p class="listing" id="ch08list7"><em>Listing 8-7: Complete decision tree workflow sample code</em></p>
<p class="indent">The sample machine learning malware detector we just explored demonstrates how to get started with <code>sklearn</code>’s functionality, but it’s missing some essential features required for a real-world malware detector. Let’s now explore what a real-world malware detector entails.</p>
<h3 class="h3" id="lev127"><strong>Building Real-World Machine Learning Detectors with sklearn</strong></h3>
<p class="noindent">To build a real-world detector, you need to use industrial-strength features of software binaries as well as write code to extract these features from software binaries. Industrial-strength features are those that reflect the content of binaries in all their complexity, which means we need to use hundreds or thousands of features. By “extracting” features I mean that you have to write code that identifies the presence of these features within binaries. You also need to use thousands of training examples and train a machine learning model at scale. Finally, you need to use <code>sklearn</code>’s more advanced detection approaches because the simple decision tree approaches we just explored don’t provide sufficient detection accuracy.</p>
<h4 class="h4" id="lev128"><strong><em>Real-World Feature Extraction</em></strong></h4>
<p class="noindent">The sample features I used previously, such as <code>is packed</code> and <code>contains encrypted data</code>, are simple toy examples, and these two features alone will never result in a working malware detector. As I mentioned previously, real-world malware detection systems use hundreds, thousands, or even millions of features. For example, a machine learning–based detector might use millions of character strings that occur in software binaries as features. Or it might use the values of software binary Portable Executable (PE) headers, the functions imported by a given binary, or some combination of all of these. Although we’ll work only with string features in this chapter, let’s take a moment to explore <span epub:type="pagebreak" id="page_135"/>common categories of features used in machine learning–based malware detection, starting with the string features.</p>
<h5 class="h5" id="lev129"><strong>String Features</strong></h5>
<p class="noindent">The string features of a software binary are all the contiguous strings of printable characters in the file that are at least some minimum length (in this book, this minimum is set to five characters). For example, suppose a binary file contains the following sequences of printable characters:</p>
<pre>["A", "The", "PE executable", "Malicious payload"]</pre>
<p class="indent">In this case, the strings we can use as features would be <code>"PE executable"</code> and <code>"Malicious payload"</code> because these two strings have more than five characters in them.</p>
<p class="indent">To transform string features into a format that <code>sklearn</code> can understand, we need to put them into a Python dictionary. We do this by using the actual strings as dictionary keys and then setting their values to 1 to indicate that the binary in question contains that string. For example, the previous sample binary would get a feature vector of <code>{"PE executable": 1, "Malicious payload": 1}</code>. Of course, most software binaries have hundreds of printable strings in them, not just two, and these strings can contain rich information about what a program does.</p>
<p class="indent">In fact, string features work well with machine learning–based detection because they capture so much information about software binaries. If the binary is a packed malware sample, then it’s likely to have few informative strings, which in itself can be a giveaway that the file is malicious. On the other hand, if parts of the file’s resources section are not packed or obfuscated, then those strings reveal much about the file’s behavior. For example, if the binary program in question makes HTTP requests, it’s common to see strings such as <code>"GET %s"</code> in that file’s set of strings.</p>
<p class="indent">String features have some limitations, however. For example, they don’t capture anything about the actual logic of a binary program, because they don’t include actual program code. So, although strings can be useful features even on packed binaries, they don’t reveal what packed binaries actually do. As a result, detectors based on string features are not ideal for detecting packed malware.</p>
<h5 class="h5" id="lev130"><strong>Portable Executable (PE) Header Features</strong></h5>
<p class="noindent">PE header features are extracted from the PE header metadata that resides in every Windows <em>.exe</em> and <em>.dll</em> file. For more information on the format of these headers, refer to <a href="ch01.xhtml#ch01">Chapter 1</a>. To extract PE features from static program binaries, you can use the code given in that chapter, and then encode file features in Python dictionary form, where the header field name is the dictionary key and the field value is the value corresponding to each key.</p>
<p class="indent">PE header features complement string features well. For example, whereas string features often do a good job of capturing the function calls and network transmissions made by a program, like the <code>"GET %s"</code> example, <span epub:type="pagebreak" id="page_136"/>PE header features capture information like a program binary’s compile timestamp, the layout of its PE sections, and which of those sections are marked executable and how large they are on disk. They also capture the amount of memory a program allocates upon startup, and many other runtime characteristics of a program binary that string features don’t capture.</p>
<p class="indent">Even when you’re dealing with packed binaries, PE header features can still do a decent job of distinguishing packed malware from packed benignware. This is because although we cannot see packed binaries’ code because of obfuscation, we can still see how much space the code takes up on disk and how the binary is laid out on disk or compressed over a series of file sections. These are telling details that can help a machine learning system distinguish malware from benignware. On the downside, PE header features don’t capture the actual instructions a program executes when it is run, or the functions that it calls.</p>
<h5 class="h5" id="lev131"><strong>Import Address Table (IAT) Features</strong></h5>
<p class="noindent">The Import Address Table (IAT), which you learned about in <a href="ch01.xhtml#ch01">Chapter 1</a>, is also an important source of machine learning features. The IAT contains a list of functions and libraries that a software binary imports from external DLL files. As such, the IAT contains important information about program behavior that you can use to complement the PE header features described in the previous section.</p>
<p class="indent">To use the IAT as a source of machine learning features, you need to represent each file as a dictionary of features, where the name of the imported library and function is the key, and the key maps to a 1, which indicates that the file in question contains that specific import (for example, the key <code>"KERNEL32.DLL:LoadLibraryA"</code>, where <code>KERNEL32.DLL</code> is the DLL and <code>LoadLibraryA</code> is the function call). The feature dictionary resulting from computing IAT features in this way for a sample would look like { <code>KERNEL32.DLL:LoadLibraryA: 1, ... }</code>, where we’d assign a 1 to any keys observed in a binary.</p>
<p class="indent">In my experience building malware detectors, I have found that IAT features rarely work well on their own—although these features capture useful high-level information about program behavior, the malware often obfuscates the IAT to make itself look like benignware. Even when malware contains no obfuscation, it often imports the same DLL calls that benignware also imports, making it hard to distinguish between malware and benignware simply based on IAT information. Finally, when malware is packed (compressed or encrypted, such that the real malware code is only visible after the malware executes and uncompresses or unencrypts itself), the IAT only contains imports that the packer uses, not the imports that the malware uses. That said, when you use IAT features in conjunction with other features like PE header features and string features, they can boost system accuracy.</p>
<h5 class="h5" id="lev132"><strong>N-grams</strong></h5>
<p class="noindent">So far you’ve learned about machine learning features that don’t involve any concept of ordering. For example, we discussed string features to <span epub:type="pagebreak" id="page_137"/>check whether or not a binary has a particular string, but not whether a particular string comes before or after another string in the layout of the binary on disk.</p>
<p class="indent">But sometimes order matters. For example, we might find that an important malware family imports only commonly used functions, but imports them in a very specific order, such that when we observe the functions in that order, we know we’re seeing that malware family and not benignware. To capture this kind of order information, you can use a machine learning concept called an N-gram.</p>
<p class="indent">N-grams sound more exotic than they are: they just involve laying out your features in the sequence in which they occur and then sliding a window of length <em>n</em> over the sequence, treating the sequence of features inside the window at each step as a single, aggregate feature. For example, if we had the sequence <code>["how", "now", "brown", "cow"]</code> and we wanted to extract N-gram features of length 2 (<em>n</em> = 2) from this sequence, we would have <code>[("how","now"), ("now","brown"), ("brown","cow")]</code> as our features.</p>
<p class="indent">In the context of malware detection, some kinds of data are most naturally represented as N-gram features. For example, when you disassemble a binary into its constituent instructions, like <code>["inc", "dec", "sub", "mov"]</code>, it makes sense to then use the N-gram approach to capture these sequences of instructions because representing a sequence of instructions can be useful in detecting particular malware implementations. Alternatively, when you’re executing binaries to examine their dynamic behavior, you can use the N-gram approach to represent binaries’ sequences of API calls or high-level behaviors.</p>
<p class="indent">I recommend experimenting with N-gram features in your machine learning–based malware detection systems whenever you’re working with data that occurs in some type of sequence. It often takes some trial and error to determine what number you should set <em>n</em> to, which determines the length of your N-grams. This trial and error involves varying the <em>n</em> value to see which value yields the best accuracy on your test data. Once you find the right number, N-grams can be powerful features for capturing the actual sequential behaviors of program binaries, thereby boosting system accuracy.</p>
<h4 class="h4" id="lev133"><strong><em>Why You Can’t Use All Possible Features</em></strong></h4>
<p class="noindent">Now that you know the strengths and weaknesses of different categories of features, you may be wondering why you can’t use all these features at once to build the best possible detector. There are a few reasons using all possible features is not a good idea.</p>
<p class="indent">First, extracting all the features we just explored takes a long time, which compromises how quickly your system can scan files. More importantly, if you use too many features on machine learning algorithms, you can run into memory issues and your system can take too long to train. This is why when building your systems, I recommend trying different features and honing in on those that work well on the kinds of malware you’re trying to detect (and the kinds of benignware you’re trying to avoid generating false positives on).</p>
<p class="indent"><span epub:type="pagebreak" id="page_138"/>Unfortunately, even if you do home in on one category of features, like string features, you’ll often have more features than most machine learning algorithms can handle. When using string features, you must have one feature for every unique string that occurs in your training data. For example, if training sample A contains the string <code>"hello world"</code>, and training sample B contains the string <code>"hello world!"</code>, then you’ll need to treat <code>"hello world"</code> and <code>"hello world!"</code> as two separate features. This means that when you’re dealing with thousands of training samples, you’ll quickly encounter thousands of unique strings, and your system will end up using that many features.</p>
<h4 class="h4" id="lev134"><strong><em>Using the Hashing Trick to Compress Features</em></strong></h4>
<p class="noindent">To get around the problem of having too many features, you can use a popular and straightforward solution called the <em>hashing trick</em>, also known as <em>feature hashing</em>. The idea is as follows: suppose you have a million unique string features in your training set, but the machine learning algorithm and hardware you’re using can only deal with 4,000 unique features across the whole training set. You need some way of compressing a million features down to a feature vector that’s 4,000 entries long.</p>
<p class="indent">The hashing trick makes these million features fit within a feature space of 4,000 by hashing each feature into one of 4,000 indices. Then you add the value of your original feature to the number at that index in your 4,000-dimensional feature vector. Of course, features often collide with this approach because their values are added together along the same dimension. This might affect system accuracy because the machine learning algorithm you’re using can’t “see” the value of individual features anymore. But in practice, this degradation in accuracy is often very small, and the benefit you get from the compressed representation of your features far outweighs this slight degradation that occurs because of the compression operation.</p>
<h5 class="h5" id="lev135"><strong>Implementing the Hashing Trick</strong></h5>
<p class="noindent">To make these ideas clearer, I walk you through sample code that implements the hashing trick. Here I show this code to illustrate how the algorithm works; later, we’ll use <code>sklearn</code>’s implementation of this function. Our sample code starts with a function declaration:</p>
<pre>def apply_hashing_trick(feature_dict, vector_size=2000):</pre>
<p class="indent">The <code>apply_hashing_trick()</code> function takes two parameters: the original feature dictionary and the size of the vector we store the smaller feature vector in after we apply the hashing trick.</p>
<p class="indent">Next, we create the new feature array using the following code:</p>
<pre>    new_features = [0 for x in range(vector_size)]</pre>
<p class="indent">The <code>new_features</code> array stores the feature information after applying the hashing trick. Then we perform the key operations of the hashing trick inside a <code>for</code> loop, like in <a href="ch08.xhtml#ch08list8">Listing 8-8</a>.</p>
<pre><span epub:type="pagebreak" id="page_139"/>    for key in <span class="ent">➊</span>feature_dict:<br/>        array_index = <span class="ent">➋</span>hash(key) % vector_size<br/>        new_features[array_index] += <span class="ent">➌</span>feature_dict[key]</pre>
<p class="listing" id="ch08list8"><em>Listing 8-8: Using a</em> <span class="codeitalic">for</span> <em>loop to perform a hash operation</em></p>
<p class="indent">Here, we use a <code>for</code> loop to iterate over every feature in the feature dictionary <span class="ent">➊</span>. To do this, first we hash the keys of the dictionary (in the case of string features, these would correspond to the software binaries’ individual strings) modulo <code>vector_size</code> such that the hash values are bounded between zero and <code>vector_size – 1</code> <span class="ent">➋</span>. We store the result of this operation in the <code>array_index</code> variable.</p>
<p class="indent">Still within the <code>for</code> loop, we increment the value of the <code>new_feature</code> array entry at index <code>array_index</code> by the value in our original feature array <span class="ent">➌</span>. In the case of string features, where our feature values are set to 1 to indicate that the software binary has that particular string, we would increment this entry by one. In the case of PE header features, where features have a range of values (for example, corresponding to the amount of memory a PE section will take up), we would add the value of the feature to the entry.</p>
<p class="indent">Finally, outside of the <code>for</code> loop, we simply return the <code>new_features</code> dictionary, like this:</p>
<pre>    return new_features</pre>
<p class="indent">At this point, <code>sklearn</code> can operate on <code>new_features</code> using just thousands instead of millions of unique features.</p>
<h5 class="h5" id="lev136"><strong>Complete Code for the Hashing Trick</strong></h5>
<p class="noindent"><a href="ch08.xhtml#ch08list9">Listing 8-9</a> shows the complete code for the hashing trick, which should now be familiar to you.</p>
<pre>def apply_hashing_trick(feature_dict,vector_size=2000):<br/>    # create an array of zeros of length 'vector_size'<br/>    new_features = [0 for x in range(vector_size)]<br/><br/>    # iterate over every feature in the feature dictionary<br/>    for key in feature_dict:<br/><br/>        # get the index into the new feature array<br/>        array_index = hash(key) % vector_size<br/><br/>        # add the value of the feature to the new feature array<br/>        # at the index we got using the hashing trick<br/>        new_features[array_index] += feature_dict[key]<br/><br/>    return new_features</pre>
<p class="listing" id="ch08list9"><em>Listing 8-9: Complete code for implementing the hashing trick</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_140"/>As you have seen, the feature hashing trick is easy to implement on your own, and doing so ensures that you understand how it works. However, you can also just use <code>sklearn</code>’s implementation, which is easy to use and more optimized.</p>
<h5 class="h5" id="lev137"><strong>Using sklearn’s FeatureHasher</strong></h5>
<p class="noindent">To use <code>sklearn</code>’s built-in implementation instead of implementing your own hashing solution, you need to first import <code>sklearn</code>’s <code>FeatureHasher</code> class, like this:</p>
<pre>from sklearn.feature_extraction import FeatureHasher</pre>
<p class="indent">Next, instantiate the <code>FeatureHasher</code> class:</p>
<pre>hasher = FeatureHasher(n_features=2000)</pre>
<p class="indent">To do this, you declare <code>n_features</code> to be the size of the new array that results from applying the hashing trick.</p>
<p class="indent">Then, to apply the hashing trick to some feature vectors, you simply run them through the <code>FeatureHasher</code> class’s <code>transform</code> method:</p>
<pre>features = [{'how': 1, 'now': 2, 'brown': 4},{'cow': 2, '.': 5}]<br/>hashed_features = hasher.transform(features)</pre>
<p class="indent">The result is effectively the same as our custom implementation of the feature hashing trick shown in <a href="ch08.xhtml#ch08list9">Listing 8-9</a>. The difference is that here we’re simply using <code>sklearn</code>’s implementation, since it’s easier to use a well-maintained machine learning library than our own code. The complete sample code is shown in <a href="ch08.xhtml#ch08list10">Listing 8-10</a>.</p>
<pre>from sklearn.feature_extraction import FeatureHasher<br/>hasher = FeatureHasher(n_features=10)<br/>features = [{'how': 1, 'now': 2, 'brown': 4},{'cow': 2, '.': 5}]<br/>hashed_features = hasher.transform(features)</pre>
<p class="listing" id="ch08list10"><em>Listing 8-10: Implementing</em> <span class="codeitalic">FeatureHasher</span></p>
<p class="indent">There are a few things to note about feature hashing before we move on. First, as you may have guessed, feature hashing obfuscates the feature information you pass into a machine learning algorithm because it adds feature values together simply based on the fact that they hash to the same bin. This means that, in general, the fewer bins you use (or the more features you hash into some fixed numbers of bins), the worse your algorithm will perform. Surprisingly, machine learning algorithms can still work well even when using the hashing trick, and because we simply can’t deal with millions or billions of features on modern hardware, we usually have to use the feature hashing trick in security data science.</p>
<p class="indent">Another limitation of the feature hashing trick is that it makes it difficult or impossible to recover the original features you hashed when <span epub:type="pagebreak" id="page_141"/>analyzing the internals of your model. Take the example of decision trees: because we’re hashing arbitrary features into each entry of our feature vectors, we don’t know which of the features we added to a given entry is causing a decision tree algorithm to split on this entry, since any number of features could have caused the decision tree to think splitting on this entry was a good idea. Although this is a significant limitation, security data scientists live with it because of the huge benefits of the feature hashing trick in compressing millions of features down to a manageable number.</p>
<p class="indent">Now that we’ve gone over the building blocks required for building a real-world malware detector, let’s explore how to build an end-to-end machine learning malware detector.</p>
<h3 class="h3" id="lev138"><strong>Building an Industrial-Strength Detector</strong></h3>
<p class="noindent">From a software requirements perspective, our real-world detector will need to do three things: extract features from software binaries for use in training and detection, train itself to detect malware using training data, and actually perform detection on new software binaries. Let’s walk through the code that does each of these things, which will show you how it all fits together.</p>
<p class="indent">You can access the code I use in this section at <em>malware_data_science/ch8/code/complete_detector.py</em> in the code accompanying this book, or at the same location in the virtual machine provided with this book. A one-line shell script, <em>malware_data_science/ch8/code/run_complete_detector.sh</em>, shows how to run the detector from the shell.</p>
<h4 class="h4" id="lev139"><strong><em>Extracting Features</em></strong></h4>
<p class="noindent">To create our detector, the first thing we implement is code to extract features from training binaries (I skip over boilerplate code here and focus on the core functions of the program). Extracting features involves extracting the relevant data from training binaries, storing these features within a Python dictionary, and then, if we think our number of unique features will become prohibitively large, transforming them using <code>sklearn</code>’s implementation of the hashing trick.</p>
<p class="indent">For simplicity’s sake, we use only string features and choose to use the hashing trick. <a href="ch08.xhtml#ch08list11">Listing 8-11</a> shows how to do both.</p>
<pre>def get_string_features(<span class="ent">➊</span>path,<span class="ent">➋</span>hasher):<br/>    # extract strings from binary file using regular expressions<br/>    chars = r" -~"<br/>    min_length = 5<br/>    string_regexp = '[%s]{%d,}' % (chars, min_length)<br/>    file_object = open(path)<br/>    data = file_object.read()<br/>    pattern = re.compile(string_regexp)<br/>    strings = pattern.findall(data)<br/><br/>    # store string features in dictionary form<br/>  <span class="ent">➌</span> string_features = {}<br/><span epub:type="pagebreak" id="page_142"/>    for string in strings:<br/>        string_features[string] = 1<br/><br/>    # hash the features using the hashing trick<br/>  <span class="ent">➍</span> hashed_features = hasher.transform([string_features])<br/><br/>    # do some data munging to get the feature array<br/>    hashed_features = hashed_features.todense()<br/>    hashed_features = numpy.asarray(hashed_features)<br/>    hashed_features = hashed_features[0]<br/><br/>    # return hashed string features<br/>  <span class="ent">➎</span> print "Extracted {0} strings from {1}".format(len(string_features),path)<br/>    return hashed_features</pre>
<p class="listing" id="ch08list11"><em>Listing 8-11: Defining the</em> <span class="codeitalic">get_string_features</span> <em>function</em></p>
<p class="indent">Here, we declare a single function called <code>get_string_features</code> that takes the path to the target binary <span class="ent">➊</span> and an instance of <code>sklearn</code>’s feature hashing class <span class="ent">➋</span> as its arguments. Then we extract the target file’s strings using a regular expression, which parses out all printable strings of minimum length 5. Then, we store the features in a Python dictionary <span class="ent">➌</span> for further processing by setting each string’s value to 1 in the dictionary, simply indicating that that feature is present in the binary.</p>
<p class="indent">Next, we hash the features using <code>sklearn</code>’s hashing trick implementation by calling <code>hasher</code>. Notice that we wrap the <code>string_features</code> dictionary in a Python list as we pass it into the <code>hasher</code> instance <span class="ent">➍</span> because <code>sklearn</code> requires that we pass in a list of dictionaries to be transformed, rather than a single dictionary.</p>
<p class="indent">Because we passed in our feature dictionary as a list of dictionaries, features are returned as a list of arrays. Additionally, they are returned in <em>sparse</em> format, a compressed representation that can be useful for processing large matrices, which we won’t discuss in this book. We need to get our data back into a normal <code>numpy</code> vector.</p>
<p class="indent">To get the data back into normal format, we call <code>.todense()</code> and <code>.</code><code>asarray</code><code>()</code>, and then select the first array in the list of <code>hasher</code> results to recover our final feature vector. The last step in the function is simply to return the feature vector <code>hashed_features</code> <span class="ent">➎</span> to the caller.</p>
<h4 class="h4" id="lev140"><strong><em>Training the Detector</em></strong></h4>
<p class="noindent">Because <code>sklearn</code> does most of the hard work of training machine learning systems, training a detector requires only a small amount of code once we’ve extracted machine learning features from our target binaries.</p>
<p class="indent">To train a detector, we first need to extract features from our training examples, and then instantiate the feature hasher and the <code>sklearn</code> machine learning detector we wish to use (in this case, we use a random forest classifier). Then we need to call <code>sklearn</code>’s <code>fit</code> method on the detector to train it on the examples’ binaries. Finally, we save the detector and feature hasher to disk so we can use them when we want to scan files in the future.</p>
<p class="indent"><span epub:type="pagebreak" id="page_143"/><a href="ch08.xhtml#ch08list12">Listing 8-12</a> shows the code for training the detector.</p>
<pre>def <span class="ent">➊</span>get_training_data(benign_path,malicious_path,hasher):<br/>    def <span class="ent">➋</span>get_training_paths(directory):<br/>        targets = []<br/>        for path in os.listdir(directory):<br/>            targets.append(os.path.join(directory,path))<br/>        return targets<br/>  <span class="ent">➌</span> malicious_paths = get_training_paths(malicious_path)<br/>  <span class="ent">➍</span> benign_paths = get_training_paths(benign_path)<br/>  <span class="ent">➎</span> X = [get_string_features(path,hasher) <br/>    for path in malicious_paths + benign_paths]<br/>    y = [1 for i in range(len(malicious_paths))] <br/>    + [0 for i in range(len(benign_paths))]<br/>    return X, y<br/>def <span class="ent">➏</span>train_detector(X,y,hasher):<br/>    classifier = tree.RandomForestClassifier()<br/>  <span class="ent">➐</span> classifier.fit(X,y)<br/>  <span class="ent">➑</span> pickle.dump((classifier,hasher),open("saved_detector.pkl","w+"))</pre>
<p class="listing" id="ch08list12"><em>Listing 8-12: Programming</em> <span class="codeitalic">sklearn</span> <em>to train the detector</em></p>
<p class="indent">Let’s start by declaring the <code>get_training_data()</code> function <span class="ent">➊</span>, which extracts features from training examples we provide. The function has three arguments: a path to a directory containing examples of benign binary programs (<code>benign_path</code>), a path to a directory containing examples of malicious binary programs (<code>malicious_path</code>), and an instance of the <code>sklearn</code> <code>FeatureHasher</code> class used to do feature hashing (<code>hasher</code>).</p>
<p class="indent">Next, we declare <code>get_training_paths()</code> <span class="ent">➋</span>, a local helper function that gets us the list of absolute file paths for files occurring in a given directory. In the next two lines, we use <code>get_training_paths</code> to get us the lists of paths that occur in the malicious <span class="ent">➌</span> and benign <span class="ent">➍</span> training example directories.</p>
<p class="indent">Finally, we extract our features and create our label vector. We do this by calling the <code>get_string_features</code> function described in <a href="ch08.xhtml#ch08list11">Listing 8-11</a> on every training example file path <span class="ent">➎</span>. Notice that the label vector has a 1 for every malicious path and a 0 for every benign path, such that the numbers at the indices in the label vector correspond to the label of the feature vectors at those same indices in the <code>X</code> array. This is the form in which <code>sklearn</code> expects feature and label data, and it allows us to tell the library the label for each feature vector.</p>
<p class="indent">Now that we’ve finished extracting features and created our feature vector <code>X</code> and our label vector <code>y</code>, we’re ready to tell <code>sklearn</code> to train our detector using the feature vectors and the label vector.</p>
<p class="indent">We do this using the <code>train_detector()</code> function <span class="ent">➏</span>, which takes three arguments: the training example feature vectors (<code>X</code>), the label vector (<code>y</code>), and the instance of <code>sklearn</code>’s feature hasher (<code>hasher</code>). In the function body we instantiate <code>tree.RandomForestClassifier</code>, the <code>sklearn</code> detector. Then we pass <code>X</code> and <code>y</code> into the detector’s <code>fit</code> method to train it <span class="ent">➐</span>, and then use the Python <code>pickle</code> module <span class="ent">➑</span> to save the detector and hasher for future use.</p>
<h4 class="h4" id="lev141"><span epub:type="pagebreak" id="page_144"/><strong><em>Running the Detector on New Binaries</em></strong></h4>
<p class="noindent">Now let’s go over how to use the saved detector we just trained to detect malware in new program binaries. <a href="ch08.xhtml#ch08list13">Listing 8-13</a> shows how to write the <code>scan_file()</code> function to do this.</p>
<pre>def scan_file(path):<br/>    if not os.path.exists("saved_detector.pkl"):<br/>        print "Train a detector before scanning files."<br/>        sys.exit(1)<br/>  <span class="ent">➊</span> with open("saved_detector.pkl") as saved_detector:<br/>        classifier, hasher = pickle.load(saved_detector)<br/>    features = <span class="ent">➋</span>get_string_features(path,hasher)<br/>    result_proba = <span class="ent">➌</span>classifier.predict_proba(features)[1]<br/>    # if the user specifies malware_paths and <br/>    # benignware_paths, train a detector<br/>  <span class="ent">➍</span> if result_proba &gt; 0.5:<br/>        print "It appears this file is malicious!",`result_proba`<br/>    else:<br/>        print "It appears this file is benign.",`result_proba`</pre>
<p class="listing" id="ch08list13"><em>Listing 8-13: Running the detector on new binaries</em></p>
<p class="indent">Here, we declare the <code>scan_file()</code> function to scan a file to determine whether it’s malicious or benign. Its only argument is the path to the binary that we are going to scan. The function’s first job is to load the saved detector and hasher from the <code>pickle</code> file to which they were saved <span class="ent">➊</span>.</p>
<p class="indent">Next, we extract features from the target file using the function <code>get_string_features</code> <span class="ent">➋</span> we defined in <a href="ch08.xhtml#ch08list11">Listing 8-11</a>.</p>
<p class="indent">Finally, we call the detector’s <code>predict</code> method to decide whether or not the file in question is malicious, given the features extracted. We do this using the <code>predict_proba</code> method <span class="ent">➌</span> of the <code>classifier</code> instance and selecting the second element of the array that it returns, which corresponds to the probability that the file is malicious. If this probability is above 0.5, or 50 percent <span class="ent">➍</span>, we say the file is malicious; otherwise, we tell the user that it’s benign. We can change this decision threshold to something much higher to minimize false positives.</p>
<h4 class="h4" id="lev142"><strong><em>What We’ve Implemented So Far</em></strong></h4>
<p class="noindent"><a href="ch08.xhtml#ch08list14">Listing 8-14</a> shows the code for this small-scale but realistic malware detector in its entirety. I hope that the code reads fluidly to you now that you’ve seen how each individual piece works.</p>
<pre>#!/usr/bin/python<br/><br/>import os<br/>import sys<br/>import pickle<br/>import argparse<br/>import re<br/>import numpy<br/><span epub:type="pagebreak" id="page_145"/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.feature_extraction import FeatureHasher<br/><br/>def get_string_features(path,hasher):<br/>    # extract strings from binary file using regular expressions<br/>    chars = r" -~"<br/>    min_length = 5<br/>    string_regexp = '[%s]{%d,}' % (chars, min_length)<br/>    file_object = open(path)<br/>    data = file_object.read()<br/>    pattern = re.compile(string_regexp)<br/>    strings = pattern.findall(data)<br/><br/>    # store string features in dictionary form<br/>    string_features = {}<br/>    for string in strings:<br/>        string_features[string] = 1<br/><br/>    # hash the features using the hashing trick<br/>    hashed_features = hasher.transform([string_features])<br/><br/>    # do some data munging to get the feature array<br/>    hashed_features = hashed_features.todense()<br/>    hashed_features = numpy.asarray(hashed_features)<br/>    hashed_features = hashed_features[0]<br/><br/>    # return hashed string features<br/>    print "Extracted {0} strings from {1}".format(len(string_features),path)<br/>    return hashed_features<br/><br/>def scan_file(path):<br/>    # scan a file to determine if it is malicious or benign<br/>    if not os.path.exists("saved_detector.pkl"):<br/>        print "Train a detector before scanning files."<br/>        sys.exit(1)<br/>    with open("saved_detector.pkl") as saved_detector:<br/>        classifier, hasher = pickle.load(saved_detector)<br/>    features = get_string_features(path,hasher)<br/>    result_proba = classifier.predict_proba([features])[:,1]<br/>    # if the user specifies malware_paths and <br/>    # benignware_paths, train a detector<br/>    if result_proba &gt; 0.5:<br/>        print "It appears this file is malicious!",`result_proba`<br/>    else:<br/>        print "It appears this file is benign.",`result_proba`<br/><br/>def train_detector(benign_path,malicious_path,hasher):<br/>    # train the detector on the specified training data<br/>    def get_training_paths(directory):<br/>        targets = []<br/>        for path in os.listdir(directory):<br/>            targets.append(os.path.join(directory,path))<br/>        return targets<br/>    malicious_paths = get_training_paths(malicious_path)<br/>    benign_paths = get_training_paths(benign_path)<br/><span epub:type="pagebreak" id="page_146"/>    X = [get_string_features(path,hasher) for path in malicious_paths + benign_paths]<br/>    y = [1 for i in range(len(malicious_paths))] + [0 for i in range(len(benign_paths))]<br/>    classifier = tree.RandomForestClassifier(64)<br/>    classifier.fit(X,y)<br/>    pickle.dump((classifier,hasher),open("saved_detector.pkl","w+"))<br/><br/>def get_training_data(benign_path,malicious_path,hasher):<br/>    def get_training_paths(directory):<br/>        targets = []<br/>        for path in os.listdir(directory):<br/>            targets.append(os.path.join(directory,path))<br/>        return targets<br/>    malicious_paths = get_training_paths(malicious_path)<br/>    benign_paths = get_training_paths(benign_path)<br/>    X = [get_string_features(path,hasher) for path in malicious_paths + benign_paths]<br/>    y = [1 for i in range(len(malicious_paths))] + [0 for i in range(len(benign_paths))]<br/>    return X, y<br/><br/>parser = argparse.ArgumentParser("get windows object vectors for files")<br/>parser.add_argument("--malware_paths",default=None,help="Path to malware training files")<br/>parser.add_argument("--benignware_paths",default=None,help="Path to benignware training files")<br/>parser.add_argument("--scan_file_path",default=None,help="File to scan")<br/>args = parser.parse_args()<br/><br/>hasher = FeatureHasher(20000)<br/>if args.malware_paths and args.benignware_paths:<br/>    train_detector(args.benignware_paths,args.malware_paths,hasher)<br/>elif args.scan_file_path:<br/>    scan_file(args.scan_file_path)<br/>else:<br/>    print "[*] You did not specify a path to scan," \<br/>        " nor did you specify paths to malicious and benign training files" \<br/>        " please specify one of these to use the detector.\n"<br/>    parser.print_help()</pre>
<p class="listing" id="ch08list14"><em>Listing 8-14: Basic machine learning malware detector code</em></p>
<p class="indent">Writing a machine learning–based malware detector is great, but evaluating and improving its performance is necessary if you’re going to deploy the detector with any confidence in its efficacy. Next, you learn different ways to evaluate the performance of your detector.</p>
<h3 class="h3" id="lev143"><strong>Evaluating Your Detector’s Performance</strong></h3>
<p class="noindent">Conveniently, <code>sklearn</code> contains code that makes it easy to evaluate detection systems using measurements like ROC curves, which you learned about in <a href="ch07.xhtml#ch07">Chapter 7</a>. The <code>sklearn</code> library also provides additional evaluation functionality specific to evaluating machine learning systems. For example, you can use <code>sklearn</code>’s functions for performing cross-validation, which is a powerful method for predicting how well your detector will work when you deploy it.</p>
<p class="indent"><span epub:type="pagebreak" id="page_147"/>In this section, you learn how to use <code>sklearn</code> to plot ROC curves that show your detector’s accuracy. You also learn about cross-validation and how to implement it with <code>sklearn</code>.</p>
<h4 class="h4" id="lev144"><strong><em>Using ROC Curves to Evaluate Detector Efficacy</em></strong></h4>
<p class="noindent">Recall that Receiver Operating Characteristic (ROC) curves measure the changes in a detector’s true positive rate (the percentage of malware that it successfully detects) and false positive rate (the percentage of benignware that it falsely flags as malware) as you adjust its sensitivity.</p>
<p class="indent">The higher the sensitivity, the more false positives you will get but the greater your detection rate. The lower the sensitivity, the fewer false positives but also the fewer detections you’ll get. To compute a ROC curve you need a detector that can output a <em>threat score</em> such that the higher its value the more likely it is that a binary is malicious. Conveniently, <code>sklearn</code>’s implementations of decision trees, logistic regression, k-nearest neighbors, random forests, and other machine learning approaches covered in this book all provide the option of outputting a threat score that reflects whether a file is malware or benignware. Let’s explore how we can use ROC curves to determine a detector’s accuracy.</p>
<h4 class="h4" id="lev145"><strong><em>Computing ROC Curves</em></strong></h4>
<p class="noindent">To compute a ROC curve for the machine learning detector we built in <a href="ch08.xhtml#ch08list14">Listing 8-14</a>, we need to do two things: first, define an experimental setup, and second, implement the experiment using <code>sklearn</code>’s <code>metrics</code> module. For our basic experimental setup, we’ll split our training examples in half such that we use the first half for training and the second half for computing the ROC curve. This split simulates the problem of detecting zero-day malware. Basically, by splitting the data, we’re telling the program, “show me one set of benignware and malware that I’ll use to learn how to identify malware and benignware, and then show me the other set to test me on how well I learned the concept of malware and benignware.” Because the detector has never seen the malware (or benignware) in the test set, this evaluation setup is a simple way to predict how well the detector will do against truly new malware.</p>
<p class="indent">Implementing this split with <code>sklearn</code> is straightforward. First, we add an option to the argument parser class of our detector program to signal that we want to evaluate the detector’s accuracy, like this:</p>
<pre>parser.add_argument("--evaluate",default=False,<br/>action="store_true",help="Perform cross-validation")</pre>
<p class="indent">Then, in the part of the program where we process command line arguments, shown in <a href="ch08.xhtml#ch08list15">Listing 8-15</a>, we add another <code>elif</code> clause that handles the case that the user has added <code>-evaluate</code> to the command line arguments.</p>
<pre><span epub:type="pagebreak" id="page_148"/>elif args.malware_paths and args.benignware_paths and args.evaluate:<br/>  <span class="ent">➊</span> hasher = FeatureHasher()<br/>    X, y = <span class="ent">➋</span>get_training_data(<br/>    args.benignware_paths,args.malware_paths,hasher)<br/>    evaluate(X,y,hasher)<br/>def <span class="ent">➌</span>evaluate(X,y,hasher):<br/>    import random<br/>    from sklearn import metrics<br/>    from matplotlib import pyplot</pre>
<p class="listing" id="ch08list15"><em>Listing 8-15: Running the detector on new binaries</em></p>
<p class="indent">Let’s walk through this code in detail. First, we instantiate an <code>sklearn</code> feature hasher <span class="ent">➊</span>, get the training data we require for our evaluation experiment <span class="ent">➋</span>, and then call a function named <code>evaluate</code> <span class="ent">➌</span>, which takes the training data (<code>X, y</code>) and the feature hasher instance (<code>hasher</code>) as its parameters and then imports three modules we need to perform the evaluation. We use the <code>random</code> module to randomly select which training examples to use for training the detector and which to use for testing it. We use the <code>metrics</code> module from <code>sklearn</code> to compute the ROC curve, and we use the <code>pyplot</code> module from <code>matplotlib</code> (the de facto standard Python library for data visualization) to visualize the ROC curve.</p>
<h4 class="h4" id="lev146"><strong><em>Splitting Data into Training and Test Sets</em></strong></h4>
<p class="noindent">Now that we’ve randomly sorted the <code>X</code> and <code>y</code> arrays corresponding to our training data, we can split these arrays into equally sized training and test sets, as shown in <a href="ch08.xhtml#ch08list16">Listing 8-16</a>, which continues defining the <code>evaluate()</code> function begun in <a href="ch08.xhtml#ch08list15">Listing 8-15</a>.</p>
<pre>    <span class="ent">➊</span> X, y = numpy.array(X), numpy.array(y)<br/>    <span class="ent">➋</span> indices = range(len(y))<br/>    <span class="ent">➌</span> random.shuffle(indices)<br/>    <span class="ent">➍</span> X, y = X[indices], y[indices]<br/>       splitpoint = len(X) * 0.5<br/>    <span class="ent">➎</span> splitpoint = int(splitpoint)<br/>    <span class="ent">➏</span> training_X, test_X = X[:splitpoint], X[splitpoint:]<br/>       training_y, test_y = y[:splitpoint], y[splitpoint:]</pre>
<p class="listing" id="ch08list16"><em>Listing 8-16: Splitting the data into training and test sets</em></p>
<p class="indent">First, we convert <code>X</code> and <code>y</code> into <code>numpy</code> arrays <span class="ent">➊</span>, and then we create a list of indices corresponding to the number of elements in <code>X</code> and <code>y</code> <span class="ent">➋</span>. Next, we randomly shuffle these indices <span class="ent">➌</span> and reorder <code>X</code> and <code>y</code> based on this new order <span class="ent">➍</span>. This sets us up to randomly assign samples to either our training set or our test set, ensuring that we don’t split the samples simply by the order in which they occur in our experimental data directory. To complete the random split, we divide the arrays in half by finding the array index that evenly splits the dataset in half, rounding this point to the nearest integer using the <code>int()</code> function <span class="ent">➎</span>, and then actually splitting the <code>X</code> and <code>y</code> arrays into training and test sets <span class="ent">➏</span>.</p>
<p class="indent"><span epub:type="pagebreak" id="page_149"/>Now that we have our training and test sets, we can instantiate and train our decision tree detector using the training data using the following:</p>
<pre>    classifier = RandomForestClassifier()<br/>    classifier.fit(training_X,training_y)</pre>
<p class="indent">Then we use the trained classifier to get scores for our test examples corresponding to the likelihood that these test examples are malicious:</p>
<pre>    scores = classifier.predict_proba(test_X)[:,-1]</pre>
<p class="indent">Here, we call the <code>predict_proba()</code> method on our classifier, which predicts the probability that our test examples are benignware or malware. Then, using <code>numpy</code> indexing magic, we pull out only the probabilities that the samples are malicious, as opposed to benign. Keep in mind that these probabilities are redundant (for example, if the probability an example is malicious is 0.99, then the probability it’s benign is 0.01, since probabilities add up to 1.00), so all we need is the malware probability here.</p>
<h4 class="h4" id="lev147"><strong><em>Computing the ROC Curve</em></strong></h4>
<p class="noindent">Now that we’ve computed malware probabilities (which we can also refer to as “scores”) using our detector, it’s time to compute our ROC curve. We do this by first calling the <code>roc_curve</code> function within <code>sklearn</code>’s <code>metrics</code> module, like this:</p>
<pre>    fpr, tpr, thresholds = metrics.roc_curve(test_y, scores)</pre>
<p class="indent">The <code>roc_curve</code> function tests a variety of <em>decision thresholds,</em> or score thresholds above which we would deem a software binary to be malicious, and measures what the false positive rate and true positive rate of the detector would be if we were to use that detector.</p>
<p class="indent">You can see that the <code>roc_curve</code> function takes two arguments: the label vector for our test examples (<code>test_y</code>) and the <code>scores</code> array, which contains our detector’s judgment about how malicious it thinks each training example is. The function returns three related arrays: <code>fpr</code>, <code>tpr</code>, and <code>thresholds</code>. These arrays are all of equal length, such that the false positive rate, true positive rate, and decision threshold at each index correspond to one another.</p>
<p class="indent">Now we can use <code>matplotlib</code> to visualize the ROC curve we just calculated. We do this by calling the <code>plot</code> method on <code>matplotlib</code>’s <code>pyplot</code> module, as shown here:</p>
<pre>    pyplot.plot(fpr,tpr,'r-')<br/>    pyplot.xlabel("Detector false positive rate")<br/>    pyplot.ylabel("Detector true positive rate")<br/>    pyplot.title("Detector ROC Curve")<br/>    pyplot.show()</pre>
<p class="indent"><span epub:type="pagebreak" id="page_150"/>We call the <code>xlabel</code>, <code>ylabel</code>, and <code>title</code> methods to label the chart’s axes and title, and then the <code>show</code> method to make the chart window pop up.</p>
<p class="indent">The resulting ROC curve is shown in <a href="ch08.xhtml#ch08fig2">Figure 8-2</a>.</p>
<div class="image"><a id="ch08fig2"/><img alt="image" src="../images/f0150-01.jpg"/></div>
<p class="figcap"><em>Figure 8-2: Visualizing the detector’s ROC curve</em></p>
<p class="indent">You can see from the plot in <a href="ch08.xhtml#ch08fig2">Figure 8-2</a> that our detector performs well for such a basic example. At around a 1 percent false positive rate (10<sup>–2</sup>), it can detect about 94 percent of the malware samples in the test set. We’re only training it on a few hundred training examples here; to get better accuracy we’d need to train it on tens of thousands, hundreds of thousands, or even millions of examples (alas, scaling machine learning to this degree is beyond the scope of this book).</p>
<h4 class="h4" id="lev148"><strong><em>Cross-Validation</em></strong></h4>
<p class="noindent">Although visualizing the ROC curve is useful, we can actually do better at predicting our detector’s real-world accuracy by performing many experiments on our training data, not just one. Recall that to perform our test, we split our training examples in half, training the detector on the first half and testing it on the second half. This is really an insufficient test of our detector. In the real world, we won’t be measured on our accuracy on this particular set of test examples but rather on our accuracy on new, previously unseen malware. To get a better sense of how we’ll perform once we <span epub:type="pagebreak" id="page_151"/>deploy, we need to run more than just one experiment on one set of test data; we need to perform many experiments on many test sets and get a sense of the overall trend in accuracy.</p>
<p class="indent">We can use <em>cross-validation</em> to do this. The basic idea behind cross-validation is to split our training examples into a number of folds (here I use three folds, but you can use more). For example, if you had 300 examples and decided to split them into three folds, the first 100 samples would go in the first fold, the second 100 would go in the second fold, and the third 100 would go in the third fold.</p>
<p class="indent">Then we run three tests. In the first test, we train the system on folds 2 and 3 and test the system on fold 1. On the second test, we repeat this process but train the system on folds 1 and 3 and test the system on fold 2. On the third test, as you can probably predict by now, we train the system on folds 1 and 2 and test the system on fold 3. <a href="ch08.xhtml#ch08fig3">Figure 8-3</a> illustrates this cross-validation process.</p>
<div class="image"><a id="ch08fig3"/><img alt="image" src="../images/f0151-01.jpg"/></div>
<p class="figcap"><em>Figure 8-3: A visualization of a sample cross-validation process</em></p>
<p class="indent">The <code>sklearn</code> library makes implementing cross-validation easy. To do this, let’s rewrite our <code>evaluate</code> function from <a href="ch08.xhtml#ch08list15">Listing 8-15</a> as <code>cv_evaluate</code>.</p>
<pre>def cv_evaluate(X,y,hasher):<br/>    import random<br/>    from sklearn import metrics<br/>    from matplotlib import pyplot<br/>    from sklearn.cross_validation import KFold</pre>
<p class="indent">We start the <code>cv_evaluate()</code> function the same way we started our initial evaluation function, except that here we also import the <code>KFold</code> class from <code>sklearn</code>’s <code>cross_validation</code> module. <em>K-fold cross-validation</em>, or <code>KFold</code> for short, is synonymous with the type of cross-validation I just discussed and is the most common way to do cross-validation.</p>
<p class="indent">Next, we convert our training data to <code>numpy</code> arrays so that we can use <code>numpy</code>’s enhanced array indexing on it:</p>
<pre>    X, y = numpy.array(X), numpy.array(y)</pre>
<p class="indent">The following code actually starts the cross-validation process:</p>
<pre>    fold_counter = 0<br/>       for train, test in KFold(len(X),3,<span class="ent">➊</span>shuffle=True):<br/><span epub:type="pagebreak" id="page_152"/>        <span class="ent">➋</span> training_X, training_y = X[train], y[train]<br/>           test_X, test_y = X[test], y[test]</pre>
<p class="indent">We first instantiate the <code>KFold</code> class, passing in the number of training examples we have as the first parameter and the number of folds we’d like to use as the second argument. The third argument, <code>shuffle=True</code> <span class="ent">➊</span>, tells <code>sklearn</code> to randomly sort our training data before dividing it into three folds. The <code>KFold</code> instance is actually an iterator that gives a different training or test example split on each iteration. Within the <code>for</code> loop, we assign the training instances and test instances to the <code>training_X</code> and <code>training_y</code> arrays <span class="ent">➋</span> that contain the corresponding elements.</p>
<p class="indent">After preparing the training and test data, we’re ready to instantiate and train the <code>RandomForestClassifier</code>, as you’ve learned to do previously in this chapter:</p>
<pre>        classifier = RandomForestClassifier()<br/>        classifier.fit(training_X,training_y)</pre>
<p class="indent">Finally, we compute a ROC curve for this particular fold and then plot a line that represents this ROC curve:</p>
<pre>        scores = classifier.predict_proba(test_X)[:,-1]<br/>        fpr, tpr, thresholds = metrics.roc_curve(test_y, scores)<br/>        pyplot.semilogx(fpr,tpr,label="Fold number {0}".format(fold_counter))<br/>        fold_counter += 1</pre>
<p class="indent">Note that we don’t call the <code>matplotlib</code> <code>show</code> method to display the chart just yet. We do this after all the folds have been evaluated and we’re ready to show all three lines at once. As we did in the previous section, we label our axes and give the plot a title, like this:</p>
<pre>    pyplot.xlabel("Detector false positive rate")<br/>    pyplot.ylabel("Detector true positive rate")<br/>    pyplot.title("Detector Cross-Validation ROC Curves")<br/>    pyplot.legend()<br/>    pyplot.grid()<br/>    pyplot.show()</pre>
<p class="indent">The resulting ROC curve is shown in <a href="ch08.xhtml#ch08fig4">Figure 8-4</a>.</p>
<p class="indent">As you can see, our results were similar on every fold, but there is definitely some variation. Our detection rate (true positive rate) over the three runs averages about 90 percent at a 1 percent false positive rate. This estimate, which takes into account all three cross-validation experiments, is a more accurate estimate of our detector’s performance than we’d get if we just ran one experiment on our data; in that case, which samples we happened to use for training and testing would lead to a somewhat random outcome. By running more experiments, we can get a more robust sense of our solution’s efficacy.</p>
<div class="image"><span epub:type="pagebreak" id="page_153"/><a id="ch08fig4"/><img alt="image" src="../images/f0153-01.jpg"/></div>
<p class="figcap"><em>Figure 8-4: Plotting the detector’s ROC curve using cross-validation</em></p>
<p class="indent">Note that these results are not great because we’re training on a very small amount of data: a few hundred malware and benignware samples. At my day job, where we train large-scale machine learning malware detection systems, we usually train on hundreds of millions of samples. You don’t need hundreds of millions of samples to train your own malware detector, but you’ll want to assemble datasets of at least tens of thousands of samples to start getting really good performance (for example, a 90 percent detection rate at a 0.1 percent false positive rate).</p>
<h3 class="h3" id="lev149"><strong>Next Steps</strong></h3>
<p class="noindent">So far, I covered how to use Python and <code>sklearn</code> to extract features from a training dataset of software binaries, and then train and evaluate a decision tree–based machine learning approach. To improve the system, you can use features other than or in addition to printable string features (for example, the PE header, instruction N-gram, or Import Address Table features discussed previously), or you could use a different machine learning algorithm.</p>
<p class="indent">To make the detector more accurate, I recommend going beyond <code>sklearn</code>’s <code>RandomForestClassifier</code> (<code>sklearn.ensemble.RandomForestClassifier</code>) to try other classifiers. Recall from the previous chapter that <em>random forest detectors</em> are also based on decision trees, but instead of just one decision tree, they build many decision trees, randomizing the way they are built. To <span epub:type="pagebreak" id="page_154"/>determine whether a new file is malware or benignware, each of these decision trees makes individual decisions, which we combine by summing them up and dividing them by the total number of trees to get the average result.</p>
<p class="indent">You can also use other algorithms that <code>sklearn</code> provides, such as logistic regression. Using any of these algorithms can be as simple as doing a search and replace in the sample code discussed in this chapter. For example, in this chapter we instantiate and train our decision tree as follows:</p>
<pre>        classifier = RandomForestClassifier()<br/>        classifier.fit(training_X,training_y)</pre>
<p class="indent">But you can simply replace that code with this:</p>
<pre>        from sklearn.linear_model import LogisticRegression<br/>        classifier = LogisticRegression()<br/>        classifier.fit(training_X,training_y)</pre>
<p class="indent">This replacement yields a logistic regression detector instead of a decision tree–based detector. By computing a new cross validation–based evaluation of this Logistic Regression detector and comparing it to the results from <a href="ch08.xhtml#ch08fig4">Figure 8-4</a>, you could determine which works better.</p>
<h3 class="h3" id="lev150"><strong>Summary</strong></h3>
<p class="noindent">In this chapter, you learned the ins and outs of building machine learning–based malware detectors. Specifically, you learned how to extract features from software binaries for machine learning, how to compress these features using the hashing trick, and how to train machine learning–based malware detectors using these extracted features. You also learned how to plot ROC curves to examine the relationship between a detector’s detection threshold and its true and false positive rates. Finally, you learned about cross-validation, a more advanced evaluation concept, and other possible extensions to enhance the detector used in this chapter.</p>
<p class="indent">This concludes this book’s discussion of machine learning–based malware detection using <code>sklearn</code>. We’ll cover another set of machine learning methods, known as deep learning methods or artificial neural networks in <a href="ch10.xhtml#ch10">Chapters 10</a> and <a href="ch11.xhtml#ch11">11</a>. You now have the basic knowledge necessary to effectively use machine learning in the context of malware identification. I encourage you to read more about machine learning. Because computer security is in many ways a data analysis problem, machine learning is here to stay in the security industry and will continue to be useful not only in detecting malicious binaries but also in detecting malicious behavior in network traffic, system logs, and other contexts.</p>
<p class="indent">In the next chapter, we’ll take a deep dive into visualizing malware relationships, which can help us quickly understand the similarities and differences between large numbers of malware samples.</p>
</body></html>