- en: '**12'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**12**'
- en: SAMPLING**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**抽样**'
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: We’ve powered the majority of our experiments by extracting samples from the
    uniform distribution. While we’ve also worked with the normal distribution ([Chapter
    1](ch01.xhtml)), beta distribution ([Chapter 3](ch03.xhtml)), and binomial distribution
    ([Chapter 9](ch09.xhtml)), the tried-and-true uniform distribution is our oldest
    and dearest friend.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的大多数实验都通过从均匀分布中提取样本来进行。虽然我们也使用过正态分布（[第1章](ch01.xhtml)）、贝塔分布（[第3章](ch03.xhtml)）和二项分布（[第9章](ch09.xhtml)），但经得起时间考验的均匀分布仍是我们最古老且最亲密的朋友。
- en: In this chapter, we’ll sample from arbitrary probability distributions, be they
    discrete or continuous. This ability is critical to simulation and fundamental
    to Bayesian inference.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将从任意概率分布中抽样，无论是离散的还是连续的。这一能力对模拟至关重要，也是贝叶斯推断的基础。
- en: First, we’ll discuss terminology and unpack the term *Bayesian inference*. Following
    that, we’ll dive into sampling from arbitrary discrete probability distributions,
    first in one dimension, then in two.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将讨论术语并解析术语*贝叶斯推断*。接下来，我们将深入探讨从任意离散概率分布中抽样，首先是一维的，然后是二维的。
- en: Discrete distributions dealt with, we’ll move on to sampling from continuous
    distributions via inverse transform sampling, rejection sampling, and Markov Chain
    Monte Carlo sampling using the Metropolis-Hastings algorithm.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理完离散分布后，我们将继续通过逆变换抽样、拒绝抽样以及使用Metropolis-Hastings算法的马尔可夫链蒙特卡罗抽样来从连续分布中抽样。
- en: This is perhaps our most mathematical chapter, but don’t let that throw you.
    If you want to continue exploring the algorithms or apply them to different situations,
    the code is what matters.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是我们最数学化的一章，但不要因此感到困惑。如果你想继续探索这些算法或将它们应用于不同的情况，代码才是最重要的。
- en: '**Introduction to Sampling**'
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**抽样简介**'
- en: Before diving into sampling, let’s agree on terminology and the concepts that
    terminology entails. We’ll also introduce notions related to Bayesian statistics
    and inference, with the latter being a prime motivator for, and beneficiary of,
    the development of sampling algorithms.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入讨论抽样之前，让我们先达成一致，了解一些术语及其所包含的概念。我们还将介绍与贝叶斯统计和推断相关的概念，后者是抽样算法发展的主要推动力和受益者。
- en: '***Terminology***'
  id: totrans-10
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***术语***'
- en: If we roll a standard die, we’ll get one of six possible outputs, each occurring
    with equal probability. We express this distribution as a bar graph with bars
    labeled 1 through 6, each of equal height corresponding to the fraction 1/6\.
    The sum of the fractions represented by each bar is 1 because the graph is a discrete
    probability distribution.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们掷一个标准的骰子，结果可能是六个输出中的一个，每个结果出现的概率相等。我们将这种分布表示为一个条形图，图中的条形标记为1至6，每个条形的高度相等，对应于1/6的分数。每个条形所代表的分数的总和为1，因为该图是离散概率分布。
- en: 'The *probability mass function (PMF)* tells us the probability of any discrete
    outcome. For a standard die, the PMF is 1/6 for each outcome. For a binomial distribution,
    the PMF depends on the number of trials (*n*) and the probability of an event
    happening (*p*) per trial according to the formula ![Image](../images/f0324-01.jpg).
    Here *k*, *k* = 0, . . . , *n*, is the number of events occurring during the *n*
    trials. Think of the continuous case as moving the discrete case to more and more
    possible outcomes; for example, a bar graph where the bars become increasingly
    narrow until they have an infinitesimal width. Talk of infinitesimals often implies
    calculus, as is the case here. The discrete distribution morphs into a continuous
    one so that:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*概率质量函数 (PMF)* 告诉我们任何离散结果的概率。对于标准骰子，PMF是每个结果的1/6。对于二项分布，PMF取决于试验次数（*n*）和每次试验中事件发生的概率（*p*），公式如下：![Image](../images/f0324-01.jpg)。这里的
    *k*，*k* = 0, . . . , *n*，是* n *次试验中事件发生的次数。可以将连续情况看作是将离散情况扩展到更多的可能结果；例如，一个条形图，其中条形逐渐变窄，直到它们的宽度变得无穷小。谈论无穷小通常意味着微积分，正如这里所示。离散分布转变为连续分布，从而：'
- en: '![Image](../images/f0324-02.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0324-02.jpg)'
- en: Here, *f*(*x*) is a *probability density function (PDF)*, the continuous analog
    of a probability mass function. The notation *P*(*X* = *i*) stands for the probability
    of a random variable, *X*, taking on the value *i*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*f*(*x*)是*概率密度函数 (PDF)*，它是概率质量函数的连续类比。符号 *P*(*X* = *i*) 表示随机变量 *X* 取值 *i*
    的概率。
- en: The *∫* symbol is simply an old-fashioned script “S” for “sum.” The thing summed
    is an infinite number of areas formed by rectangles of width *dx* (a single entity,
    not the product of *d* and *x*) and height *f*(*x*), that is, the PDF function
    value at *x*. If limits are given, ![Image](../images/f0324-01a.jpg), the sum
    is for *x* = *a* through *x* = *b*. No limits given implies “sum over all *x*
    that matter, even if from –*∞* to +*∞*.”
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*∫*符号只是一个老式的“S”字母，代表“求和”。求和的对象是由宽度为*dx*（一个实体，而不是*d*与*x*的乘积）和高度为*f*(*x*)的矩形所形成的无限多个面积，即在*x*处的PDF函数值。如果给定了限制条件，![Image](../images/f0324-01a.jpg)，求和就是对从*x*
    = *a*到*x* = *b*的*x*进行求和。如果没有给定限制条件，意味着“对所有有意义的*x*求和，即使是从–*∞*到+*∞*。”'
- en: 'Sample a discrete distribution, and the probability of returning *x* is *P*(*X*
    = *x*), or the probability associated with the bar labeled *x*. The probability
    of sampling a continuous distribution and getting a specific *x* is, counterintuitively,
    *P*(*x*) = 0 for any real number *x*. We can’t talk of the probability of returning
    *x* as a sample, but instead, the probability of the sample lying in some range,
    [*a*, *b*]. That probability is:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对离散分布进行抽样，返回*x*的概率是*P*(*X* = *x*)，即与标记为*x*的条形图相关的概率。抽样连续分布并得到特定*x*的概率，反直觉地是*P*(*x*)
    = 0，对于任何实数*x*都成立。我们不能讨论返回*x*作为样本的概率，而是讨论样本落在某个范围[*a*, *b*]中的概率。这个概率是：
- en: '![Image](../images/f0324-04.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0324-04.jpg)'
- en: This is nothing more than the area under the PDF from *a* to *b*. The variables
    in the integral are dummy variables. I switched from *x* to *t* to avoid confusion
    with the *x* we’re asking about on the left-hand side of the equation.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这不过是从*a*到*b*之间PDF下的面积。积分中的变量是虚拟变量。我从*x*换成了*t*，以避免与我们在方程左边讨论的*x*混淆。
- en: We must talk about the probability over a range in the continuous case because
    not all infinities are created equal, a fact first realized by Georg Cantor in
    the 19th century. Because there are so many more real numbers than integers, the
    probability of selecting any one from a continuous distribution becomes identically
    zero. While the algorithms of this chapter return samples that appear to come
    from the desired continuous distribution, don’t be fooled. As with all computation,
    we never use real numbers, but rational numbers in one form or another. Ultimately,
    our samples approximate the desired continuous probability distribution. However,
    as they say, if it walks like a duck and quacks like a duck, it’s a duck—or a
    reasonably useful facsimile of one.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在连续情况下，我们必须讨论某个范围的概率，因为并不是所有的无穷大都是相同的，这一点是19世纪乔治·康托尔首次意识到的。由于实数比整数多得多，从连续分布中选择任何一个实数的概率实际上是零。虽然本章的算法返回的样本看起来像是来自所需的连续分布，但不要被迷惑。像所有计算一样，我们永远不会使用实数，而是以某种形式使用有理数。最终，我们的样本近似于所需的连续概率分布。然而，正如他们所说的，如果它走起来像只鸭子，叫起来像只鸭子，那它就是只鸭子——或者至少是一个合理有用的类似物。
- en: The PMF and PDF relate to the probability of sampling a particular value from
    a distribution. A related concept is the *cumulative distribution function (CDF)*,
    which we use for both discrete and continuous distributions. The CDF at *x* is
    the sum of the area under the PMF or PDF from its lowest value to *x*. If we sum
    over all the bars of the discrete distribution or integrate over all of the PDF,
    we get an area of 1, so the CDF is a function running from 0 on the left to 1
    on the right as *x* increases.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: PMF和PDF与从分布中抽取特定值的概率有关。一个相关的概念是*累积分布函数（CDF）*，我们用于离散分布和连续分布。在*x*处的CDF是从PMF或PDF的最小值到*x*之间的面积总和。如果我们对离散分布的所有条形图进行求和，或者对所有PDF进行积分，我们得到的面积为1，因此CDF是一个从左侧的0到右侧的1的函数，随着*x*的增大而变化。
- en: For example, [Figure 12-1](ch012.xhtml#ch012fig01) shows the PMF (top left)
    and CDF (top right) for a binomial distribution with *n* = 10 trials, each with
    probability *p* = 0.7\. On the bottom are the PDF and CDF for a standard normal
    distribution. In both cases, the CDF approaches 1 from the left.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[图12-1](ch012.xhtml#ch012fig01)显示了一个二项分布的PMF（左上）和CDF（右上），其中*n* = 10次试验，每次的概率*p*
    = 0.7。底部则是标准正态分布的PDF和CDF。在这两种情况下，CDF都从左侧接近1。
- en: '![Image](../images/12fig01.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/12fig01.jpg)'
- en: '*Figure 12-1: The PMF and CDF for a binomial distribution (top) and a standard
    normal distribution (bottom)*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*图12-1：二项分布的PMF和CDF（上）与标准正态分布的PDF和CDF（下）*'
- en: The code to generate [Figure 12-1](ch012.xhtml#ch012fig01) is in *cdf.py*, which
    demonstrates how to realize pure math as code, at least with regard to probability
    functions. I’ll skip the plotting portion of the code; see [Listing 12-1](ch012.xhtml#ch012list01)
    for the remaining relevant bits.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 生成[图12-1](ch012.xhtml#ch012fig01)的代码在*cdf.py*中，它展示了如何将纯数学转化为代码，至少在概率函数方面是这样。我会跳过代码的绘图部分；有关其余相关代码，请参见[列表12-1](ch012.xhtml#ch012list01)。
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Listing 12-1: Generating CDFs from PMFs and PDFs*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表12-1：从PMF和PDF生成CDF*'
- en: The first code paragraph generates samples from the binomial distribution. To
    save effort, I’m using NumPy’s function to draw 10,000 random samples, meaning
    `z` is a vector of 10,000 values, each a randomly selected sample from the binomial
    distribution. To get the distribution itself, we need a histogram. The samples,
    in `z`, are integers, so the most efficient way to get the counts is with the
    `bincount` method. There were *n* = 10 trials, but there are 11 possible outcomes
    from 0 events up to 10, hence `minlength=11` in the call to `bincount`.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 第一段代码从二项分布中生成样本。为了节省时间，我使用了NumPy的函数来抽取10,000个随机样本，这意味着`z`是一个包含10,000个值的向量，每个值是从二项分布中随机选取的样本。为了得到分布本身，我们需要一个直方图。样本在`z`中是整数，因此获取计数的最有效方法是使用`bincount`方法。实验次数为*n*
    = 10，但可能的结果有11种，从0次事件到10次事件，因此在调用`bincount`时，`minlength=11`。
- en: Let’s turn to the `h = h / h.sum()` line. The `bincount` method returns the
    per-outcome counts. We want a discrete probability distribution, which must sum
    to 1, so we divide each count by the total to transform them into fractions adding
    to 1\. Therefore, `h` is now an *estimate* of the discrete binomial probability
    distribution for *n* = 10 and *p* = 0.7\. For a better estimate of the true binomial
    distribution, increase the number of samples to 20,000 or more.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下`h = h / h.sum()`这一行。`bincount`方法返回每个结果的计数。我们想要一个离散的概率分布，它的总和必须为1，因此我们将每个计数除以总和，将它们转换为相加为1的分数。因此，`h`现在是*n*
    = 10 和 *p* = 0.7 的离散二项分布的*估计值*。为了更好地估计真实的二项分布，可以将样本数量增加到20,000个或更多。
- en: A discrete distribution’s CDF is the running sum of the per-outcome probabilities.
    In other words
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 离散分布的CDF是每个结果概率的累加和。换句话说，
- en: '![Image](../images/f0326-01.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0326-01.jpg)'
- en: NumPy’s `cumsum` calculates this cumulative sum for us to generate the entire
    CDF in a single function call.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy的`cumsum`为我们计算这个累积和，以便在一次函数调用中生成整个CDF。
- en: 'The continuous case is similar, though we don’t need to draw samples from it
    because the PDF of the normal distribution has a closed-form representation. For
    the standard normal (*µ* = 0, *σ* = 1), the PDF is:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 连续情况类似，尽管我们不需要从中抽样，因为正态分布的PDF有封闭形式的表示。对于标准正态分布（*µ* = 0, *σ* = 1），PDF为：
- en: '![Image](../images/f0326-02.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0326-02.jpg)'
- en: In code, we estimate this function (`y`) using 10,000 values of *x* equally
    spaced from –7 to 7 (`linspace`).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，我们使用从–7到7之间均匀分布的10,000个*x*值（`linspace`）来估计这个函数（`y`）。
- en: To estimate the CDF, however, we can’t simply sum the values in `y` as in the
    discrete case. The area under the PDF must sum to 1, but because it’s an area,
    we multiply each *y* value by the width of the rectangle it makes with the *x*-axis.
    The rectangle’s width is the difference between successive `x` values, so we multiply
    `y` by `x[1] - x[0]` before summing. There’s no need to scale `y`, as the values
    in `y` are the actual PDF values, not counts.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，要估计CDF，我们不能像离散情况那样简单地将`y`中的值相加。PDF下的面积必须为1，但因为它是一个面积，我们将每个*y*值乘以它与*x*轴之间矩形的宽度。矩形的宽度是相邻`x`值之间的差异，因此在求和之前，我们将`y`乘以`x[1]
    - x[0]`。不需要缩放`y`，因为`y`中的值是实际的PDF值，而不是计数。
- en: This chapter’s goal is to sample from arbitrary distributions, where “sampling”
    means that we ask a distribution to give us a number according to the probabilities
    assigned to possible outputs. The higher the *y*-axis value of a distribution
    in a PMF or PDF plot, the higher the oracle’s probability of selecting that number
    (discrete) or a number in a very narrow range about that position (continuous).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是从任意分布中抽样，其中“抽样”意味着我们要求一个分布根据可能输出的概率给我们一个数字。分布在PMF或PDF图中的*y*轴值越高，oracle选择该数字（离散的）或该位置附近非常窄范围内的数字（连续的）概率就越高。
- en: For example, the code in *nselect.py* generates the plot in [Figure 12-2](ch012.xhtml#ch012fig02),
    in which the black dots on the *x*-axis signify 30 samples from the normal distribution.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，*nselect.py* 中的代码生成了 [图12-2](ch012.xhtml#ch012fig02) 中的图形，其中 *x* 轴上的黑点表示来自正态分布的
    30 个样本。
- en: '![Image](../images/12fig02.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/12fig02.jpg)'
- en: '*Figure 12-2: Thirty samples from a standard normal distribution*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*图12-2：来自标准正态分布的 30 个样本*'
- en: The samples are concentrated near the center of the PDF—the most likely region
    to be sampled. As we draw more samples, their density along the *x*-axis increases
    in proportion to the probability of being selected. Transforming the density into
    counts via a histogram approximates the PDF itself.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 样本集中在 PDF 的中心附近——最有可能被采样的区域。当我们绘制更多样本时，它们在 *x* 轴上的密度与被选择的概率成正比。通过直方图将密度转换为计数，近似
    PDF 本身。
- en: Now, let’s discuss Bayesian inference, as its use depends on efficient sampling
    from complicated probability distributions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论贝叶斯推断，因为它的应用依赖于从复杂的概率分布中高效地采样。
- en: '***Bayesian Inference***'
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***贝叶斯推断***'
- en: English minister Thomas Bayes (1701–1761) originated a seemingly simple equation
    that has recently turned the world of statistics on its head. Deriving the equation
    is an exercise in basic probability theory.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 英国部长托马斯·贝叶斯（1701–1761）提出了一个看似简单的方程，最近它颠覆了统计学的世界。推导这个方程是一个基本概率理论的练习。
- en: We write the probability of event *B* happening, given that event *A* has already
    happened, as *P*(*B*|*A*). This is the *conditional probability* of *B* given
    *A*. The probability of *A* happening is *P*(*A*), and the probability of both
    *B* and *A* happening is their *joint probability*, *P*(*A*, *B*).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将事件 *B* 发生的概率表示为，已知事件 *A* 已经发生，即 *P*(*B*|*A*)。这是给定 *A* 的条件概率 *B*。事件 *A* 发生的概率是
    *P*(*A*)，而 *B* 和 *A* 同时发生的概率是它们的 *联合概率*，即 *P*(*A*, *B*)。
- en: 'Probability theory states that *P*(*B*, *A*) = *P*(*B*|*A*)*P*(*A*), which,
    switching the order of events, gives us *P*(*A*, *B*) = *P*(*A*|*B*)*P*(*B*).
    Joint probabilities represent the probability of all combinations of the events,
    meaning *P*(*B*, *A*) = *P*(*A*, *B*). Putting these observations together tells
    us that:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 概率论指出，*P*(*B*, *A*) = *P*(*B*|*A*)*P*(*A*)，反过来交换事件的顺序，我们得到 *P*(*A*, *B*) = *P*(*A*|*B*)*P*(*B*)。联合概率表示所有事件组合的概率，这意味着
    *P*(*B*, *A*) = *P*(*A*, *B*)。将这些观察结果结合起来告诉我们：
- en: '![Image](../images/f0328-01.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0328-01.jpg)'
- en: 'The final equation is *Bayes’ theorem*, which relates the *posterior probability*,
    *P*(*B*|*A*), to the product of the *likelihood*, *P*(*A*|*B*), and the *prior
    probability*, *P*(*B*). The denominator on the right, *P*(*A*), is the *evidence*.
    It’s a normalizing value to ensure that the posterior probability is a probability—that
    the sum over the PDF of the posterior is 1\. In practice, *P*(*A*) becomes an
    integral that typically can’t be expressed in closed form. In Bayesian modeling,
    the likelihood and prior probabilities are selected and known functional forms,
    but the evidence becomes intractable. This is where the sampling methods we’ll
    discuss soon come into play. Drawing samples from the posterior is *Bayesian inference*.
    Without advanced sampling methods, Bayesian inference is all but impossible; with
    them, Bayesian inference becomes a paradigm shift, as Sharon Bertsch McGrayne
    notes in her book *The Theory That Would Not Die* (Yale University Press, 2011):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的方程是 *贝叶斯定理*，它将 *后验概率* *P*(*B*|*A*) 与 *似然* *P*(*A*|*B*) 和 *先验概率* *P*(*B*)
    的乘积相关联。右侧分母 *P*(*A*) 是 *证据*，它是一个归一化值，用来确保后验概率是一个概率——即后验的 PDF 总和为 1。在实践中，*P*(*A*)
    成为一个通常无法以闭式表达的积分。在贝叶斯建模中，似然和先验概率是选择并已知的函数形式，但证据变得难以处理。这就是我们将要讨论的采样方法派上用场的地方。从后验分布中抽取样本就是
    *贝叶斯推断*。没有先进的采样方法，贝叶斯推断几乎是不可能的；有了这些方法，贝叶斯推断就变成了一种范式转变，正如 Sharon Bertsch McGrayne
    在她的著作《那不死的理论》（耶鲁大学出版社，2011）中所指出的：
- en: The combination of Bayes and Markov Chain Monte Carlo has been called “arguably
    the most powerful mechanism ever created for processing data and knowledge.”
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯与马尔可夫链蒙特卡洛（MCMC）的结合被称为“可能是有史以来为处理数据和知识创造的最强大的机制”。
- en: Markov Chain Monte Carlo is one of the sampling algorithms we’ll explore in
    this chapter. While we recognize Monte Carlo from [Chapter 11](ch011.xhtml), we’ll
    discuss the Markov chain aspect in time.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫链蒙特卡洛（MCMC）是我们将在本章探讨的采样算法之一。虽然我们在 [第11章](ch011.xhtml) 中已经认识到蒙特卡洛方法，但我们将在适当的时候讨论马尔可夫链的部分。
- en: Let’s start sampling from arbitrary distributions.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从任意分布开始采样。
- en: '**Discrete Distributions**'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**离散分布**'
- en: 'An arbitrary, one-dimensional discrete probability mass function might look
    like:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一个任意的一维离散概率质量函数可能是这样的：
- en: '*p[X]*(*x*) = [1, 1, 3, 4, 5, 1, 7, 4, 3]'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*p[X]*(*x*) = [1, 1, 3, 4, 5, 1, 7, 4, 3]'
- en: While perhaps unexpected, as far as we’re concerned this is a perfectly valid
    PMF represented as a Python list. It illustrates a distribution returning samples
    in the range 0 through 8 (the list has nine elements), and each sample returns
    an index into the PMF. As it stands, the PMF isn’t *normalized*, so the sum of
    the “probabilities” isn’t 1; it’s 1 + 1 + 3 + 4 + 5 + 1 + 7 + 4 + 3 = 29\. To
    get probabilities, we divide each number by this sum.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这可能出乎意料，但对我们而言，这是一个完全有效的PMF，表示为Python列表。它说明了一个返回0到8范围内样本的分布（该列表有九个元素），每个样本返回PMF中的一个索引。就目前而言，PMF并未*归一化*，因此“概率”的总和不是1；它是1
    + 1 + 3 + 4 + 5 + 1 + 7 + 4 + 3 = 29。为了得到概率，我们需要将每个数字除以这个总和。
- en: 'The PMF tells us the proportion with which each value—0 through 8—appears,
    on average, after a large number of samples. For example, 6 appears seven times
    as often as 0 because the ratio between 6 and 0 is 7 : 1\. Likewise, the ratio
    between 6 and 7 is 7 : 4, and so on.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 'PMF告诉我们，每个值——从0到8——出现的比例，经过大量采样后，它们的出现频率。例如，6出现的次数是0的7倍，因为6与0的比例是7 : 1。同样，6与7的比例是7
    : 4，依此类推。'
- en: 'Let’s calculate the ratio between the probability of sampling a 6 (7/29) and
    the probability of getting a 0 (1/29):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算采样6的概率（7/29）与采样0的概率（1/29）之间的比率：
- en: '![Image](../images/f0329-01.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0329-01.jpg)'
- en: The result is as expected.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 结果符合预期。
- en: This section explores three approaches to sampling from arbitrary discrete distributions.
    Two approaches expect the PMF to be normalized (sums to 1), while the third uses
    a PMF expressed as integer ratios between the elements. This may seem to be a
    drawback, but we often sample from distributions approximated by histograms, and
    the bins of a histogram are integer counts.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了三种从任意离散分布中采样的方法。两种方法期望PMF已归一化（总和为1），而第三种方法使用作为整数比率表示的PMF。这看起来可能是一个缺点，但我们经常从通过直方图近似的分布中采样，而直方图的桶是整数计数。
- en: '***Sequential Search***'
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***顺序搜索***'
- en: In [Chapter 7](ch07.xhtml), we generated fractals using IFS by applying maps
    selected according to a given probability. In other words, we sampled from a distribution
    over maps. The code we used is in [Listing 12-2](ch012.xhtml#ch012list02).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](ch07.xhtml)中，我们使用IFS生成了分形，通过应用根据给定概率选择的映射。换句话说，我们从映射的分布中采样。我们使用的代码在[列表12-2](ch012.xhtml#ch012list02)中。
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Listing 12-2: Choosing a map*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表12-2：选择一个映射*'
- en: '[Listing 12-2](ch012.xhtml#ch012list02) implements a version of *inversion
    sampling by sequential search*; at least, that’s what Luc Devroye calls it in
    his book *Non-Uniform Random Variate Generation* (Springer, 1986). You’ll find
    Devroye’s book on his website, *[http://luc.devroye.org/books-luc.html](http://luc.devroye.org/books-luc.html)*.
    He’s giving it away. I recommend grabbing a copy.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表12-2](ch012.xhtml#ch012list02)实现了*通过顺序搜索的反转采样*；至少，按照Luc Devroye在他的书《非均匀随机变量生成》（Springer，1986）中的说法，叫做反转采样。你可以在Devroye的[网站](http://luc.devroye.org/books-luc.html)上找到他的书。他正在免费提供。我推荐你抓紧时间下载一份。'
- en: The implementation in [Listing 12-2](ch012.xhtml#ch012list02) isn’t exactly
    terse. We can do better, as in [Listing 12-3](ch012.xhtml#ch012list03).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表12-2](ch012.xhtml#ch012list02)中的实现并不简洁。我们可以做得更好，参考[列表12-3](ch012.xhtml#ch012list03)。'
- en: '[PRE2]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Listing 12-3: A more parsimonious implementation of inversion by sequential
    search*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表12-3：通过顺序搜索的更简洁的反转实现*'
- en: First, we hand the function the PMF as `probs`, which we expect to be normalized.
    The second argument is our old friend, an instance of `RE` configured to return
    floats in [0, 1).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将PMF作为`probs`传递给函数，预计它已归一化。第二个参数是我们老朋友，一个配置为返回[0, 1)区间浮动数值的`RE`实例。
- en: The code picks a uniformly distributed value, `u`, and subtracts the probabilities
    in `probs`, in order, until the result is zero or negative. We then return the
    number of times we subtract, `k`, as the sampled index into `probs` after adjusting
    for indexing from zero.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 代码选择一个均匀分布的值`u`，并按顺序从`probs`中减去概率，直到结果为零或负值。然后我们返回减去的次数`k`，作为调整索引后的`probs`中的采样索引。
- en: We can visualize the sampling process as in [Figure 12-3](ch012.xhtml#ch012fig03)
    using the unnormalized PMF we discussed earlier.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像[图12-3](ch012.xhtml#ch012fig03)所示，使用我们之前讨论的未归一化PMF来可视化采样过程。
- en: '*p[X]*(*x*) = [1, 1, 3, 4, 5, 1, 7, 4, 3]'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*p[X]*(*x*) = [1, 1, 3, 4, 5, 1, 7, 4, 3]'
- en: '![Image](../images/12fig03.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/12fig03.jpg)'
- en: '*Figure 12-3: Sequential sampling of a discrete distribution*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-3：离散分布的顺序采样*'
- en: The Probability row reflects this PMF where the length of each box is in proportion
    to the other boxes so that the 7 box is seven times longer than the 1 box. To
    get the probability passed in `probs`, divide each box label by the sum, 29.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 概率行反映了这个 PMF，其中每个框的长度与其他框成比例，因此 7 号框比 1 号框长七倍。要获取传入 `probs` 的概率，请将每个框标签除以总和
    29。
- en: '[Figure 12-3](ch012.xhtml#ch012fig03) shows a selected *u* as a double arrow.
    This *u* is about 0.4 because it’s a bit less than half the distance across the
    entire PMF, which must sum to 1\. The vertical line after the box labeled 5 marks
    the full set of probabilities subtracted from *u* until *u* < 0\. We subtract
    five boxes in this order: 1, 1, 3, 4, and 5\. Adjust for indexing from 0, and
    the returned sample is 4—the label on the matched box below *u* in the Value row.
    Ignore the Reorder row for the time being.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-3](ch012.xhtml#ch012fig03) 显示了选定的 *u* 作为一个双向箭头。这个 *u* 约为 0.4，因为它略小于整个
    PMF 一半的距离，而 PMF 的总和必须为 1。标记为 5 的框后面的垂直线标记了从 *u* 中减去的完整概率集合，直到 *u* < 0。我们按以下顺序减去五个框：1，1，3，4
    和 5。根据从 0 开始的索引调整，返回的样本是 4——即与 *u* 匹配的框下方在值行中的标签。暂时忽略重新排序行。'
- en: This process maps [0, 1) to [0, 8] using the width of the boxes to transform
    the uniform input to a nonuniform output that will match the desired PMF if we
    draw enough samples. Try selecting other samples by closing your eyes and placing
    your finger somewhere on [Figure 12-3](ch012.xhtml#ch012fig03)’s Probability row.
    Then, slide your finger down to the Value row and read off the output, which is
    the number of boxes covered from the left. After repeating this a few times, you
    should see that 6 will be chosen most often, followed by 4\. Inversion sampling
    by sequential search is our first discrete sampling algorithm.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程使用框的宽度将 [0, 1) 映射到 [0, 8]，通过转换均匀输入为非均匀输出，如果我们抽取足够的样本，输出将匹配所需的 PMF。试着通过闭上眼睛并将手指放在
    [图 12-3](ch012.xhtml#ch012fig03) 的概率行的某个地方来选择其他样本。然后，将手指滑动到值行，并读取输出，即从左侧覆盖的框数。重复几次后，你应该会发现
    6 被选择的频率最高，其次是 4。通过顺序搜索的反转采样是我们的第一种离散采样算法。
- en: Let’s make one minor improvement. The top row of [Figure 12-3](ch012.xhtml#ch012fig03)
    presents the PMF in order, meaning the probability assigned to 0 is 1/29, while
    the probability assigned to 6 is 7/29\. This makes sense if we use [Listing 12-3](ch012.xhtml#ch012list03)
    to sample from the distribution. However, to get 6 (the most frequent value) as
    a sample, we need to search from the beginning of the probability vector each
    time. If we list the probabilities in descending order, we’ll select the most
    likely outcome after one pass through the `while` loop of [Listing 12-3](ch012.xhtml#ch012list03).
    The next most likely outcome requires only two passes, and so on. This notion
    leads to the Reorder row of [Figure 12-3](ch012.xhtml#ch012fig03).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一个小小的改进。[图 12-3](ch012.xhtml#ch012fig03) 的顶部行按顺序展示了 PMF，这意味着分配给 0 的概率是 1/29，而分配给
    6 的概率是 7/29。如果我们使用 [清单 12-3](ch012.xhtml#ch012list03) 从分布中采样，这样是有意义的。然而，要获得 6（最频繁的值）作为一个样本，我们每次都需要从概率向量的开始处进行搜索。如果我们按降序列出概率，那么在通过
    [清单 12-3](ch012.xhtml#ch012list03) 的 `while` 循环后，最可能的结果将被选中。下一个最可能的结果只需要两次循环，依此类推。这一概念导致了
    [图 12-3](ch012.xhtml#ch012fig03) 中的重新排序行。
- en: The bars of the Reorder row run from left to right in decreasing size order,
    with the label on each bar listing the value to return should that bar be selected.
    Notice, the algorithm in [Listing 12-3](ch012.xhtml#ch012list03) doesn’t change;
    it’s still subtracting probabilities from *u*, but they’re now ordered from greatest
    to least. Therefore, we must map the index returned by [Listing 12-3](ch012.xhtml#ch012list03)
    to identify the true value selected. For example, if [Listing 12-3](ch012.xhtml#ch012list03)
    returns index 1, the mapping knows that 1 → 4 to return 4 as the selected value.
    This adjustment should speed things up, depending on the arrangement of probabilities
    in `probs`. The reordering tweak is our second discrete sampling algorithm.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 重新排序行的条形图从左到右按大小降序排列，每个条形图上的标签列出如果该条形图被选中时返回的值。请注意，[清单 12-3](ch012.xhtml#ch012list03)
    中的算法没有改变；它仍然是从 *u* 中减去概率，但它们现在按从大到小的顺序排列。因此，我们必须将 [清单 12-3](ch012.xhtml#ch012list03)
    返回的索引映射到识别出实际选中的值。例如，如果 [清单 12-3](ch012.xhtml#ch012list03) 返回索引 1，则映射知道 1 → 4，从而返回
    4 作为选中的值。根据 `probs` 中概率的排列，这一调整应该能加快速度。重新排序的调整是我们的第二种离散采样算法。
- en: '***Fast-Loaded Dice Roller***'
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***快速加载骰子滚动器***'
- en: 'Our final discrete sampling algorithm is relatively new: the *Fast Loaded Dice
    Roller (FLDR)*, presented by Saad et al. in their 2020 paper, “The Fast Loaded
    Dice Roller: A Near-Optimal Exact Sampler for Discrete Probability Distributions.”
    You’ll find the code and paper on their GitHub site at *[https://github.com/probcomp/fast-loaded-dice-roller](https://github.com/probcomp/fast-loaded-dice-roller)*.
    We need only the *fldr.py* file from the *src/python* directory. Either copy that
    file from the GitHub repo via your browser or install the full package with `pip`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最终离散抽样算法相对较新：*快速加载骰子滚动器（FLDR）*，由 Saad 等人在其2020年的论文《快速加载骰子滚动器：离散概率分布的近似最优精确采样器》中提出。你可以在他们的
    GitHub 网站上找到代码和论文，链接为 *[https://github.com/probcomp/fast-loaded-dice-roller](https://github.com/probcomp/fast-loaded-dice-roller)*。我们只需要
    *src/python* 目录中的 *fldr.py* 文件。你可以通过浏览器从 GitHub 仓库复制该文件，或者使用 `pip` 安装完整的包：
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you copy *fldr.py* from GitHub, place it in the folder for this chapter.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从 GitHub 复制 *fldr.py*，将其放入本章的文件夹中。
- en: The FLDR paper describes the algorithm and its genesis. It also refers to the
    Devroye book mentioned earlier, which motivated the algorithm’s design. We won’t
    discuss the details, as they’re rather involved and mathematical. However, it’s
    interesting to learn that there are more sophisticated ways of thinking about
    sampling from a discrete distribution.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: FLDR 论文描述了该算法及其起源。它还提到了前面提到的 Devroye 书籍，这本书激发了该算法的设计。我们不会讨论细节，因为它们相当复杂且富有数学性。然而，了解有更多复杂的思维方式来考虑从离散分布中抽样是很有趣的。
- en: The version of FLDR we’ll use wants PMFs as vectors of integers, precisely as
    I’ve presented them so far. Using the FLDR requires two steps; the first conditions
    the algorithm based on the PMF, and the second draws individual samples on demand.
    We need the `fldr_preprocess_int` function to configure the sampler and the function
    `fldr_sample` to draw a sample. The FLDR code is not NumPy aware, but we can live
    with that.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的 FLDR 版本需要将 PMF 表示为整数向量，正如我迄今为止所展示的那样。使用 FLDR 需要两个步骤；第一个步骤根据 PMF 对算法进行条件化，第二个步骤根据需求抽取单个样本。我们需要
    `fldr_preprocess_int` 函数来配置采样器，和 `fldr_sample` 函数来抽取样本。FLDR 代码并不支持 NumPy，但我们可以接受这一点。
- en: Now that we have our algorithms, we’ll pit them against each other.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了算法，接下来将它们互相对比。
- en: '***Runtime Performance***'
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***运行时性能***'
- en: Let’s find out whether our algorithms work, and how they compare to each other
    in terms of runtime performance.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看我们的算法是否有效，并且它们在运行时性能上如何相互比较。
- en: 'First, run *discrete_test.py* without arguments:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，运行 *discrete_test.py*，不带参数：
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The command line’s form is familiar. The only required argument is the number
    of samples to draw from the nine-element distribution presented at start of “Discrete
    Distributions” on [page 328](ch012.xhtml#ch00lev1_79): [1, 1, 3, 4, 5, 1, 7, 4,
    3].'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 命令行的形式很熟悉。唯一必需的参数是要从“离散分布”章节开头提到的九元素分布中抽取的样本数量，具体见[第328页](ch012.xhtml#ch00lev1_79)：[1,
    1, 3, 4, 5, 1, 7, 4, 3]。
- en: 'Let’s select some samples:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们选择一些样本：
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The command line requests 5,000 samples and displays the number of times each
    possible output was selected by algorithm type. For example, 1 was selected 187
    times by the sequential algorithm. As we expect, 6 is the most frequent output.
    The final line contains the expected number of samples, found by multiplying the
    probability by the number of samples, rounded to the nearest integer.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 命令行请求5000个样本，并显示每种可能输出被不同算法类型选择的次数。例如，顺序算法选择了187次1。正如我们预期的那样，6是最常见的输出。最后一行包含了预期的样本数量，它是通过将概率乘以样本数并四舍五入到最近的整数得到的。
- en: The three algorithms appear to work as expected, with the results close to the
    expected output. Looking at the runtime on the right, the sequential algorithm
    is the slowest, the reordered algorithm is slightly faster, and FLDR is nearly
    an order of magnitude faster still.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这三种算法似乎按照预期工作，结果接近预期输出。从右侧的运行时间来看，顺序算法最慢，重新排序的算法稍微更快，而FLDR则快了将近一个数量级。
- en: If we ask for 50 samples instead of 5,000
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要求50个样本而不是5000个
- en: '[PRE6]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: the output is noisy, as the expected frequency and the sampled frequencies are
    farther apart; for example, the sequential algorithm picked 2 in 10 instances
    while the expected frequency is only 5.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是噪声的，因为预期频率和采样频率相差较远；例如，顺序算法在10次中选择了2，而预期频率仅为5。
- en: '[Figure 12-4](ch012.xhtml#ch012fig04) demonstrates this effect visually using
    FLDR to select 50 versus 5,000 samples.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12-4](ch012.xhtml#ch012fig04)通过 FLDR 展示了这种效果，使用 FLDR 选择了50个样本与5000个样本进行对比。'
- en: '![Image](../images/12fig04.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/12fig04.jpg)'
- en: '*Figure 12-4: Sampling from a discrete distribution using 50 samples (left)
    and 5,000 (right)*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-4：使用50个样本（左）和5000个样本（右）从离散分布中采样*'
- en: The bars are the true distribution and the dots are the samples, both expressed
    as probabilities.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 条形图表示真实分布，点表示样本，二者均以概率表示。
- en: '[Figure 12-5](ch012.xhtml#ch012fig05) displays the runtime performance of our
    samplers for ⌊*N^α*⌋ samples with *α* running from 1 to 6 in 25 steps. Note that
    the *x*-axis is in units of 1 million.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-5](ch012.xhtml#ch012fig05)展示了我们的采样器在对⌊*N^α*⌋个样本进行采样时的运行时性能，其中 *α* 从1变化到6，步长为25。请注意，*x*
    轴单位是百万。'
- en: '![Image](../images/12fig05.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/12fig05.jpg)'
- en: '*Figure 12-5: Sample time as a function of the number of samples*'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-5：样本时间与样本数量的关系*'
- en: We can safely say that all three sampling algorithms run in ![Image](../images/c0301-01.jpg)(*n*)
    time. However, [Figure 12-5](ch012.xhtml#ch012fig05) is a good practical example
    for us. Big O notation ignores multiplicative factors, so while all three algorithms
    run in linear time, in practice we’ll want to use FLDR.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以放心地说，所有三种采样算法的运行时间都是 ![图片](../images/c0301-01.jpg)(*n*) 时间复杂度。然而，[图 12-5](ch012.xhtml#ch012fig05)
    对我们来说是一个很好的实际例子。大O符号忽略了乘法因子，因此虽然所有三种算法的运行时间是线性的，但在实际应用中我们希望使用 FLDR。
- en: Let’s walk through *discrete_test.py*, starting with the setup ([Listing 12-4](ch012.xhtml#ch012list04)).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步了解 *discrete_test.py*，从设置部分开始（[清单 12-4](ch012.xhtml#ch012list04)）。
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*Listing 12-4: Setting up* discrete_test.py'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 12-4：设置* discrete_test.py'
- en: We’ll focus on the beginning, where we introduce functions from `fldr`, and
    on the end, where we define `probabilities`.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重点关注开始部分，在这里我们引入了来自 `fldr` 的函数，以及结束部分，在这里我们定义了 `probabilities`。
- en: FLDR wants integer counts, so we use `probabilities` in that case. When working
    with sequential sampling algorithms, which need true probabilities, we use `prob`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: FLDR 需要整数计数，因此在这种情况下我们使用 `probabilities`。当使用需要真实概率的顺序采样算法时，我们使用 `prob`。
- en: '[Listing 12-5](ch012.xhtml#ch012list05) uses each algorithm to draw the requested
    number of samples. Each case creates a vector of the samples, `z`, timing how
    long it takes. A list comprehension draws the samples.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 12-5](ch012.xhtml#ch012list05) 使用每种算法绘制所请求的样本数量。每种情况都会创建一个样本向量 `z`，并计时绘制这些样本所花费的时间。使用列表推导式来绘制样本。'
- en: '[PRE8]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '*Listing 12-5: Sampling with each algorithm*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 12-5：使用每种算法进行采样*'
- en: The first code paragraph calls `Sequential`, which we saw in [Listing 12-3](ch012.xhtml#ch012list03),
    and then creates the histogram with `bincount` before displaying the counts and
    generation time.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个代码段调用了我们在 [清单 12-3](ch012.xhtml#ch012list03) 中看到的 `Sequential`，然后使用 `bincount`
    创建直方图，最后显示计数和生成时间。
- en: The second paragraph ultimately calls `Sequential`, but first rearranges `prob`
    to be in decreasing sort order. NumPy’s `argsort` returns the indices that sort
    `prob` in ascending order. The `[::-1]` idiom reverses the list to put `idx` in
    decreasing order.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 第二段代码最终调用了 `Sequential`，但首先将 `prob` 按降序排列。NumPy 的 `argsort` 返回能够将 `prob` 按升序排序的索引。`[::-1]`
    语法则将列表反转，使得 `idx` 按降序排列。
- en: We then call `Sequential` with `p` instead of `prob`. This means that the values
    in `z` are not the proper indices, but indices into `idx`, which holds the proper
    indices. In other words, `idx` is the mapping to get the proper sample values.
    A call to `bincount` using `idx` indexed by `z` generates the correct sample frequencies.
    Consider taking a moment to convince yourself that `idx[z]` makes sense.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们用 `p` 而不是 `prob` 调用 `Sequential`。这意味着 `z` 中的值不是正确的索引，而是指向 `idx` 的索引，`idx`
    保存了正确的索引。换句话说，`idx` 是获取正确样本值的映射。通过使用 `z` 索引的 `idx` 调用 `bincount` 可以生成正确的样本频率。考虑花点时间确认一下
    `idx[z]` 是有意义的。
- en: Symmetry tells us that the final code paragraph in [Listing 12-5](ch012.xhtml#ch012list05)
    draws samples using FLDR by repeated calls to `fldr_sample`. But first, we have
    to pass the probabilities to `fldr_preprocess_int` to create the structure `fldr_sample`
    uses.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对称性告诉我们，[清单 12-5](ch012.xhtml#ch012list05) 中的最后一段代码通过重复调用 `fldr_sample` 使用 FLDR
    绘制样本。但首先，我们必须将概率传递给 `fldr_preprocess_int`，以创建 `fldr_sample` 使用的结构。
- en: The final line of [Listing 12-5](ch012.xhtml#ch012list05) displays the expected
    per-value counts by rounding the product of the probability and the number of
    samples, `N`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 12-5](ch012.xhtml#ch012list05) 的最后一行通过将概率与样本数 `N` 相乘并取整，显示了每个值的预期计数。'
- en: What if the distribution we want to sample from is two dimensional? What does
    that even mean? Let’s find out.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要采样的分布是二维的呢？那是什么意思呢？让我们找出答案。
- en: '***Two Dimensions***'
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***二维***'
- en: We can store a one-dimensional discrete distribution in a vector. By extension,
    we might imagine storing a two-dimensional distribution in a matrix. But how do
    we interpret the distribution?
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将一维离散分布存储在一个向量中。通过扩展，我们可以想象将二维分布存储在一个矩阵中。但是我们如何解释这个分布呢？
- en: Since a one-dimensional distribution tells us how often we should expect to
    sample each value, then a two-dimensional distribution refers to a *pair* of values,
    namely the indices of each dimension.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 由于一维分布告诉我们每个值应该出现的频率，二维分布则是指一对值，即每个维度的索引。
- en: 'Consider this two-dimensional distribution, for example:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这个二维分布，例如：
- en: '![Image](../images/f0335-01.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0335-01.jpg)'
- en: The sum of all elements is 1, so *p[X]*(***x***) is a PMF. Note that I have
    replaced *x* with ***x***, a vector. We can also write *p[X]*(*x*, *y*) to emphasize
    that we have two dimensions.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 所有元素的总和为1，因此*p[X]*(***x***)是一个PMF。注意，我已经将*x*替换为***x***，一个向量。我们还可以写*p[X]*(*x*,
    *y*)以强调我们有两个维度。
- en: The distribution says that *P*(*X* = 0, *Y* = 0) = 0.1 while *P*(*X* = 2, *Y*
    = 3) = 0.2, that is, the value of the variables are the indices of the rows and
    columns of the matrix representing the distribution. Two-dimensional probability
    distributions show up when considering joint distributions—how often a pair of
    random variables appear together with some combination of values.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 分布表示*p*(*X* = 0, *Y* = 0) = 0.1，而*p*(*X* = 2, *Y* = 3) = 0.2，也就是说，变量的值是表示分布的矩阵中行和列的索引。二维概率分布出现在考虑联合分布时——即一对随机变量如何一起出现并拥有某种值的组合。
- en: 'We’ll use our existing sampling techniques to draw samples from a two-dimensional
    distribution by unraveling the distribution, sampling, and converting the samples
    back to two-dimensional pairs. For example, unraveling the previous distribution
    gives us:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用现有的采样技术，通过解开分布、采样，然后将样本转换回二维对来从二维分布中抽取样本。例如，解开之前的分布给我们带来了：
- en: '*p[X]*(*x*) = [0.1, 0.0, 0.1, 0.2, 0.0, 0.0, 0.1, 0.1, 0.2, 0.0, 0.0, 0.2]'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*p[X]*(*x*) = [0.1, 0.0, 0.1, 0.2, 0.0, 0.0, 0.1, 0.1, 0.2, 0.0, 0.0, 0.2]'
- en: If we sample from this distribution using one of the aforementioned algorithms,
    we’ll get samples in the range [0, 11]. To convert the samples back to pairs,
    we must undo the raveling, meaning we need to know the number of rows and columns
    in the original two-dimensional distribution.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用上述算法之一从这个分布中抽样，我们将得到范围在[0, 11]之间的样本。为了将样本转换回对，我们必须撤销解开操作，这意味着我们需要知道原始二维分布中的行数和列数。
- en: 'Let’s walk through an example. Run *discrete_ravel.py* with this command line:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来演示。使用以下命令行运行*discrete_ravel.py*：
- en: '[PRE9]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The output consists of four sections. The code itself samples from the previous
    *p[X]*(***x***) by unraveling it, sampling, then mapping the samples back to (*x*,
    *y*) pairs that represent the frequency with which combinations of *x* and *y*
    appear. If all goes well, one- and two-dimensional histograms of these frequencies
    should approximate *p[X]*(***x***).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 输出由四个部分组成。代码本身通过解开*p[X]*(***x***)进行采样，然后将样本映射回表示*x*和*y*组合出现频率的(*x*, *y*)对。如果一切顺利，这些频率的一维和二维直方图应该接近*p[X]*(***x***)。
- en: 'The first output line gives us:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个输出行给出了：
- en: '[PRE10]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This is a PMF generated from the samples drawn using the unraveled histogram.
    The values are all around 0.1 and 0.2, which is encouraging.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个由解开直方图采样得到的PMF。其值都在0.1和0.2之间，这让人感到鼓舞。
- en: 'The second output block is the same estimated PMF remapped to two dimensions:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个输出块是相同的估计PMF，重新映射到二维：
- en: '[PRE11]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This looks very much like *p[X]*(***x***).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来很像*p[X]*(***x***)。
- en: 'The estimated PMF looks right. As for the sampled values, here are the first
    eight drawn from the unraveled PMF:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 估计的PMF看起来是正确的。至于采样值，这里是从解开的PMF中抽取的前八个样本：
- en: '[PRE12]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Mapped back to pairs, these samples become:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 映射回成对，这些样本变成：
- en: '[PRE13]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The conversion from one-dimensional sample to two-dimensional pair is
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 从一维样本到二维对的转换是
- en: (*x*, *y*) = (*z* ÷ 4, *z* mod 4)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: (*x*, *y*) = (*z* ÷ 4, *z* mod 4)
- en: where *z* is the 1D sample value and ÷ means integer division. The 4 comes from
    the number of columns in the two-dimensional PMF.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*z*是1D样本值，÷表示整数除法。4来自于二维PMF中的列数。
- en: '[Listing 12-6](ch012.xhtml#ch012list06) shows the unravel, sample, remap process.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[Listing 12-6](ch012.xhtml#ch012list06)展示了解开、采样、重新映射的过程。'
- en: '[PRE14]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '*Listing 12-6: Sampling a two-dimensional PMF by unraveling*'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 12-6: 通过解开采样二维PMF*'
- en: The two-dimensional PMF is in `prob2`, which unravels to become the one-dimensional
    PMF `prob`. The second paragraph samples from `prob` as we did earlier. Notice
    `rng`, an instance of our `RE` class. I’m ignoring some of the code head of *discrete_ravel.py*,
    so make sure to review the file itself. As before, the sample counts come from
    `bincout`, which we then turn back into a one-dimensional PMF by dividing `h`
    by the sum of the counts.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 二维PMF存储在`prob2`中，展开后变成一维PMF `prob`。第二段代码从`prob`中进行采样，就像我们之前做的那样。注意`rng`，它是我们`RE`类的一个实例。我忽略了*discrete_ravel.py*文件中的一些代码头，因此请确保检查文件本身。像之前一样，样本计数来自`bincout`，我们然后通过将`h`除以计数的总和来将其转换回一维PMF。
- en: Three of the four outputs come next as `h`, `h` reshaped as a 3×4 matrix, and
    the first eight samples from `z`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是四个输出中的三个，分别为`h`、`h`重塑为3×4矩阵，以及从`z`中提取的前八个样本。
- en: When mapping samples to pairs, we save time by calling `unravel_index`, which
    needs the one-dimensional indices along with the shape of the source array—here
    3×4 from `prob2`. NumPy returns the *x*- and *y*-coordinates, so a pair is (*x*[0],
    *y*[0]) and so on, as given by the list comprehension using `zip`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在将样本映射到对时，我们通过调用`unravel_index`来节省时间，它需要一维索引和源数组的形状——这里是来自`prob2`的3×4。NumPy返回*x*和*y*坐标，因此一对值为(*x*[0]，*y*[0])，依此类推，通过`zip`实现的列表推导式给出。
- en: We can also use this unraveling approach for distributions of more than two
    dimensions. If we have three random variables—*X*, *Y*, and *Z*—then samples from
    a three-dimensional PMF, *p[XYZ]*(*x*, *y*, *z*), are triplets, (*x*, *y*, *z*),
    according to the probability with which a particular combination of values appears.
    We unravel, sample in one dimension, and use `unravel_index` to map back to triplets.
    Bear in mind that as the dimensionality increases, the number of samples necessary
    to reasonably approximate the distribution goes up dramatically.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用这种展开方法处理超过二维的分布。如果我们有三个随机变量——*X*、*Y*和*Z*——那么来自三维PMF的样本，*p[XYZ]*(*x*,
    *y*, *z*)，就是三元组(*x*, *y*, *z*)，根据某个特定值组合出现的概率。我们展开、在一个维度上进行采样，然后使用`unravel_index`将其映射回三元组。请记住，随着维度的增加，合理逼近分布所需的样本数量会急剧增加。
- en: Suppose every random variable in our system takes on one of 10 possible values.
    If we have only one variable, we must sample from a probability distribution representable
    as a vector of 10 elements. With two random variables, we need a matrix to represent
    the joint distribution, a 10 × 10 = 100-element vector when unraveled. If we have
    three random variables, we unravel to a vector of 10 × 10 × 10 = 1,000 elements;
    for four random variables, we need 10,000 elements.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们系统中的每个随机变量都有10个可能的取值。如果我们只有一个变量，我们必须从一个可以表示为10个元素的向量的概率分布中进行采样。如果有两个随机变量，我们需要一个矩阵来表示联合分布，展开后是一个10
    × 10 = 100个元素的向量。如果有三个随机变量，我们展开为10 × 10 × 10 = 1,000个元素；如果有四个随机变量，我们需要10,000个元素。
- en: Fixing the number of values at 10, an *n*-dimensional PMF unravels into a vector
    of 10*^n* elements—the distribution size scales exponentially with dimensionality.
    Therefore, this trick works best for only two or three dimensions.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 固定值的数量为10时，*n*维的PMF展开成一个包含10*^n*个元素的向量——分布大小随着维度的增加而呈指数级增长。因此，这个技巧最适用于二维或三维。
- en: '***Images***'
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***图像***'
- en: Now for a bit of fun. The code in *discrete_2d.py* knows how to use grayscale
    versions of images as discrete two-dimensional probability distributions, so we
    can sample from them. A grayscale image is a matrix of integer values from 0 to
    255, making an unraveled grayscale image immediately useful to FLDR as a distribution.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来点有趣的东西。*discrete_2d.py*中的代码知道如何使用图像的灰度版本作为离散的二维概率分布，因此我们可以从中进行采样。灰度图像是一个包含从0到255的整数值的矩阵，使得展开后的灰度图像立刻可以作为分布被FLDR使用。
- en: Samples become pixel locations. The higher the image intensity at a pixel, the
    more likely it is to be sampled. Therefore, if we draw enough samples, scale them
    to [0, 1], and multiply by 255, we can transform the estimated distribution back
    into an image and compare it with the original. That’s a lot of words; let’s look
    at some code.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 样本变成了像素位置。图像某个像素的强度越高，它被采样的可能性就越大。因此，如果我们绘制足够的样本，将其缩放到[0, 1]范围内并乘以255，我们可以将估计的分布转回图像并与原图进行比较。说了这么多，让我们来看一些代码。
- en: The four paragraphs in [Listing 12-7](ch012.xhtml#ch012list07) present the essential
    code, minus imports and command line processing.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[Listing 12-7](ch012.xhtml#ch012list07)中的四段代码展示了核心代码，省略了导入和命令行处理部分。'
- en: '[PRE15]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '*Listing 12-7: Treating images as two-dimensional distributions and sampling
    from them*'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: To turn the input image into a one-dimensional distribution, we first load the
    image, resize it to half its original dimensionality, and then unravel it into
    a list of pixel intensities, [0, 255]. Using a list comprehension with `int` is
    necessary because FLDR doesn’t work with NumPy arrays.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: The next paragraph configures FLDR (`x`) and then uses it to draw `N` samples
    (`z`), with `N` given on the command line.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Samples in hand, `unravel_index` turns the one-dimensional samples into (*x*,
    *y*) pairs, or pixel locations. We then use the pixel locations to populate `im`,
    a two-dimensional histogram counting the number of times FLDR selected each pixel.
    To convert `im` into an image, we must scale it so that the most often sampled
    pixel has a value of 1, which we get by dividing by the maximum.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: The final few lines of code create an output directory and dump the original
    and sampled images into it. We must multiply `im`, now [0, 1], by 255 and make
    it an unsigned int before writing it to disk as an image.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Run *discrete_2d.py* without arguments to learn the command line options. Try
    experimenting with the images in *test_images* and those in *images*. The latter
    contains high-contrast images that might make it easier to see where samples are
    coming from, especially the inverted images (those with “_inv” in their filename).
    The ramp images present a linear, quadratic, and cubic ramp, from left to right.
    We’ll sample brighter regions first as they’re more probable.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 12-6](ch012.xhtml#ch012fig06) shows one of the high-contrast images
    where white areas are most likely to be sampled. This version of the image prints
    well. The inverse version requires far fewer samples in general.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig06.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-6: Original hawk image (top left) and sampled images with an increasing
    number of samples*'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 12-6](ch012.xhtml#ch012fig06), the original image is in the upper
    left, followed by sampled images using 60,000, 120,000, 240,000, 480,000, and
    960,000 samples, left to right and top to bottom. I used this command line
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: varying the number of samples as needed.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: This experiment concludes our investigation of sampling from discrete distributions.
    Let’s move on to the more mathematically relevant case of sampling from continuous
    distributions and learn some new techniques, culminating in our introduction to
    the world of Markov Chain Monte Carlo.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '**Continuous Distributions**'
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s change focus to consider continuous distributions, represented by PDFs
    that admit any real number input over their range. The techniques of the previous
    section no longer work in this case—at least not without alteration—but other
    methods exist, three of which we’ll explore: inverse transform sampling, rejection
    sampling, and Markov Chain Monte Carlo.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '***Inverse Transform***'
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We represent continuous distributions by PDFs. Note the word *function*, which
    tells us there’s a mathematical relationship describing the shape of the PDF.
    The CDF for a given PDF is an integral:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0340-01.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
- en: The integral is the continuous version of summing discrete probabilities. It
    represents the area under the PDF from –*∞* to some *x*. Replace –*∞* with any
    value below which the PDF is always zero.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: The CDF runs from 0 up to 1, meaning that a plot of the CDF produces *y*-axis
    values that begin with 0 and end with 1; review [Figure 12-1](ch012.xhtml#ch012fig01)’s
    CDFs. If we pick a random value on the *y*-axis of the CDF plot, slide horizontally
    from there to the curve, and move down to the *x*-axis, we’ll have a sample from
    the PDF. Pick another *y*-axis starting point and repeat the process to get a
    new *x* and yet another sample from the PDF. Uniformly sampling *y*-axis values
    in [0, 1] produces *x* values that, when histogrammed, follow the form of the
    PDF.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: To express this process mathematically, flip the graph of a function, *F*(*x*),
    along the line *y* = *x* (which runs 45 degrees up from the *x*-axis in the first
    quadrant), and you have a graph of the inverse of the function, *F*^(–1)(*x*),
    if it exists. The inverse flips *x* and *y* values, meaning inputs to the inverse
    function act like *y* values for the function, and the output of the inverse function
    is the *x* producing that input for the function itself.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, if we know the functional form of the inverse of a function representing
    a CDF, we can sample from the PDF by selecting random values in [0, 1] as inputs
    and keeping the outputs of the inverse CDF as the desired samples. This process
    is *inverse transform sampling*.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Let’s work through an example. Suppose we want to draw samples from an *exponential
    distribution*, whose PDF is
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '*f*(*x*) = λ*e*^(–λ*x*)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: with λ (lambda) being a constant that decides how quickly the PDF decays from
    a maximum of λ at *x* = 0\. The most probable samples from this PDF are close
    to zero, with samples farther from zero less likely.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'The CDF for this PDF is an integral:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0340-03.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, *F*(*x*) = 1 – *e*^(–λ*x*). If we find the inverse of this function,
    we can generate exponentially distributed samples from uniformly distributed inputs.
    To find the inverse, set the CDF equal to *u* (for *uniform sample*) and solve
    for *x*:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0341-01.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
- en: We now have *F*^(–1)(*u*), a mapping from uniform inputs *u* in [0, 1], the
    range of the CDF, to *x*, a value selected based on the shape of the exponential
    distribution PDF. Before putting the inverse function to work, let’s make one
    more observation.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: We don’t care, specifically, about the exact pairing of this *u* to that *x*
    in terms of a sequence of *u*’s. We plan on picking *u* values at random. Because
    *u* is in [0, 1], 1 – *u* is also in [0, 1], but “flipped” along the *u*-axis
    because it’s the complement of *u*, giving us two values that sum to 1\. So, we
    can replace 1 – *u* in *F*^(–1)(*u*) with *u*, and our samples will still be from
    the exponential distribution. This step isn’t necessary, but it makes the plot
    of the inverse function look less strange to us, as we’re used to curves that
    decay from a high point as *x* increases to the right.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 12-7](ch012.xhtml#ch012fig07) shows a plot of *F*^(–1)(*u*) = (–log
    *u*)/λ, where specific *u* values have been mapped to their respective *x* outputs.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig07.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-7: Inverse transform sampling from* e^(–λ*x*) *using – log(*u*)/λ*'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: The distribution of the *x* values—or a properly scaled histogram of many *x*
    values from many *u* inputs—will become a better approximation of λ*e*^(–λ*x*)
    as the number of samples increases.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: The file *inverse.py* samples from functions supplied as the inverse of their
    CDF. In other words, we give the code *F*^(–1)(*u*) and the corresponding PDF,
    *f*(*x*), along with the desired number of samples, and it gives us the samples,
    along with a plot of the PDF and the histogram of the samples.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use the code to draw samples from *f*(*x*) = 2*e*^(–2*x*). The inverse
    CDF for this PDF is *F*^(–1)(*u*) = (–log *u*)/2\. To draw 1,000 samples, use
    a command line like so:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The first argument is the desired number of samples. The second, enclosed in
    double quotation marks, is a NumPy-aware version of the code implementing *F*^(–1)(*u*)
    that uses NumPy functions and `u` as the independent variable. The next argument,
    also enclosed in double quotes, is *f*(*x*), the PDF. Note that it’s a function
    of `x`, not `u`. The remaining arguments are the output directory and the usual
    randomness source with an optional seed.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Figure 12 shows the output of *inverse.py* for 1,000 (left) and 10,000 (right)
    samples.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig08.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-8: 1,000 (left) and 10,000 (right) samples from 2*e^(*–2*x)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: The code scales the output so the curve and histogram match. The samples follow
    the desired distribution, with more samples better representing the PDF. The 10,000
    samples are beginning to select *x* values farther from zero.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s walk through another example. The Kumaraswamy distribution is like the
    beta distribution, but the functional forms of the PDF and CDF are conducive to
    inverse sampling. Specifically:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0342-01.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: Here, *a* and *b* are constants that define the shape of the distribution, much
    like the *a* and *b* of the beta distribution. I leave it as an exercise for you
    to show that *F*^(–1)(*u*) comes from *F*(*x*).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s draw samples from this distribution for *a* = 2 and *b* = 5\. The command
    line we need is:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The resulting plot is in [Figure 12-9](ch012.xhtml#ch012fig09). As expected,
    the samples follow the shape of the distribution.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的图形见[图 12-9](ch012.xhtml#ch012fig09)。如预期的那样，样本遵循分布的形状。
- en: '![Image](../images/12fig09.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../images/12fig09.jpg)'
- en: '*Figure 12-9: Sampling Kumaraswamy (2,5)*'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-9：Kumaraswamy (2,5) 的抽样*'
- en: 'The primary code in *inverse.py* is straightforward because we supply the PDF
    and inverse CDF on the command line in a form that lets us use Python’s `eval`
    function:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '*inverse.py* 中的主要代码很简单，因为我们在命令行中提供了 PDF 和逆 CDF，它们的形式允许我们使用 Python 的 `eval`
    函数：'
- en: '[PRE19]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: That’s all there is. We create `samples` to hold the `N` requested samples,
    and then loop to generate `samples[i]` from `u` by evaluating the inverse CDF
    function passed from the command line as the `ifunc` string. The remainder of
    *inverse.py* creates the output plot.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。我们创建 `samples` 来保存请求的 `N` 个样本，然后通过评估从命令行传入的逆 CDF 函数（作为 `ifunc` 字符串）来循环生成
    `samples[i]`。*inverse.py* 的其余部分用于创建输出图形。
- en: Inverse transform sampling is direct and works from closed-form functions, but
    it’s of limited applicability because of the two conditions that must be met to
    allow its use. The PDF must produce a closed-form CDF, and that CDF must be invertible
    to get *F*^(–1)(*u*). This doesn’t happen too often, especially for arbitrary
    continuous PDFs. In “Exercises” on [page 358](ch012.xhtml#ch00lev1_81), I suggest
    another PDF/CDF combination that works with *inverse.py*, but only if you restrict
    *u* to something other than [0, 1).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 逆变换抽样是直接的，并且适用于封闭形式的函数，但由于必须满足的两个条件，它的适用性有限。PDF 必须生成封闭形式的 CDF，并且该 CDF 必须是可逆的，以便得到
    *F*^(–1)(*u*)。这种情况并不常见，特别是对于任意连续的 PDF。在[第 358 页](ch012.xhtml#ch00lev1_81)的“习题”中，我建议了另一种
    PDF/CDF 组合，可以与 *inverse.py* 配合使用，但前提是你将 *u* 限制在 [0, 1] 以外的范围。
- en: Let’s explore the next continuous PDF sampling algorithm, rejection sampling.
    Unlike inverse transform sampling, rejection sampling works with arbitrary PDFs.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨下一个连续 PDF 抽样算法——拒绝抽样。与逆变换抽样不同，拒绝抽样适用于任意的 PDF。
- en: '***Rejection***'
  id: totrans-216
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***拒绝***'
- en: We want to draw samples from a function *q*(*x*) so that a histogram of many
    samples from the function converges on the shape of the function itself. While
    we don’t know how to sample directly from *q*(*x*), we can sample from a *proposal
    function* that we’ll call *p*(*x*). If we find a constant, *c*, such that
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望从函数 *q*(*x*) 中抽样，使得从该函数中得到的多个样本的直方图趋近于该函数本身的形状。虽然我们不知道如何直接从 *q*(*x*) 中抽样，但我们可以从一个我们称之为
    *p*(*x*) 的提议函数中抽样。如果我们找到了一个常数 *c*，使得
- en: '*q*(*x*) *≤ cp*(*x*), ∀*x*'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '*q*(*x*) *≤ cp*(*x*)，∀*x*'
- en: then we can use samples from *p*(*x*) to draw samples from *q*(*x*). Recall
    that ∀ means “for all.”
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用 *p*(*x*) 的样本从 *q*(*x*) 中抽样。回想一下，∀ 表示“对于所有”。
- en: First, we draw a sample from the proposal function, *x ∼ p*(*x*), where *∼*
    means “draw a sample from.” This gives us a candidate *x* position.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从提议函数中抽取一个样本，*x ∼ p*(*x*)，其中 *∼* 表示“从…抽样”。这给了我们一个候选的 *x* 位置。
- en: Next, we pick a *y* value that’s some fraction of the way up from *x* but still
    less than *cp*(*x*). In other words, we pick a uniform value in the range [0,
    *cp*(*x*)], or *y* = *ucp*(*x*) for some *u* in [0, 1].
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们选择一个 *y* 值，它是从 *x* 向上某个比例的值，但仍然小于 *cp*(*x*)。换句话说，我们在区间 [0, *cp*(*x*)]
    中选择一个均匀值，或 *y* = *ucp*(*x*)，其中 *u* 在 [0, 1] 之间。
- en: If *y ≤ q*(*x*), we keep *x* as a sample from *q*(*x*); otherwise, we reject
    *x* and repeat with another sample from *p*(*x*). We stop when the desired number
    of samples from *q*(*x*) have been kept.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *y ≤ q*(*x*)，我们保留 *x* 作为 *q*(*x*) 的样本；否则，我们拒绝 *x* 并重新从 *p*(*x*) 中抽取另一个样本。我们在保留了所需数量的
    *q*(*x*) 样本后停止。
- en: '[Figure 12-10](ch012.xhtml#ch012fig10) shows the situation for two candidate
    *x* positions.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-10](ch012.xhtml#ch012fig10) 展示了两个候选 *x* 位置的情况。'
- en: '![Image](../images/12fig10.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../images/12fig10.jpg)'
- en: '*Figure 12-10: Rejection sampling with two candidate* x *positions*'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-10：使用两个候选 *x* 位置的拒绝抽样*'
- en: The solid curve is *q*(*x*), the function we want to sample from. The dashed
    curve, here a uniform value over the range of *q*(*x*), is *cp*(*x*).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 实线曲线是 *q*(*x*)，我们希望从中抽样的函数。虚线曲线，这里是 *q*(*x*) 范围内的均匀值，是 *cp*(*x*)。
- en: Let’s look at *x* = *x*[0] first. The algorithm says to sample from *p*(*x*),
    which gives us *x*[0]. Next, we pick a *y* some fraction of the way up from *x*[0]
    to *cp*(*x*[0]). We can write this as *y*[0] = *u*[0]*cp*(*x*[0]). While we know
    that *y*[0] will always be less than or equal to *cp*(*x*[0]), we’re wondering
    whether *y*[0] is less than *q*(*x*[0]). For *x*[0], this is the case, so we accept
    *x*[0] as a valid sample from *q*(*x*).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: In *x*[1], *y*[1] = *u*[1]*cp*(*x*[1]) is greater than *q*(*x*[1]), so we reject
    *x*[1] as a valid sample from *q*(*x*) and the process repeats.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: 'Algorithmically, the process boils down to the following:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '*x ∼ p*(*x*).'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*u ∼ U*[0, 1).'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If *ucp*(*x*) *≤ q*(*x*), accept *x* as a sample; otherwise, reject *x*.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat from step 1 until we’ve accepted *N* samples.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You might see the condition of step 3 written as
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0345-01.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
- en: which we get by dividing by *cp*(*x*). In that form, we’re asking whether *u*
    is less than the fraction of the way to *cp*(*x*) covered by *q*(*x*) for the
    selected *x*. If not, reject *x* and try again.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Think of rejection sampling as randomly throwing darts at the *xy*-plane. If
    the *y*-coordinate of the dart is less than both *cp*(*x*) and *q*(*x*), we accept
    the dart’s *x*-coordinate as a sample from *q*(*x*). In effect, we’re keeping
    all the *x*-coordinate values for darts that land under the *q*(*x*) curve. We
    did the same in [Chapter 3](ch03.xhtml) to estimate *π*.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s put this process into practice with *rejection.py*:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Rejection sampling works for any proposal function, *p*(*x*), so long as we
    can draw samples from it, but *rejection.py* restricts us to two options: a uniform
    distribution, represented by the dashed line in [Figure 12-10](ch012.xhtml#ch012fig10),
    and a normal distribution with a given mean (*µ*) and standard deviation (*σ*).
    The Box-Muller transform lets us sample from a normal distribution (see [Chapter
    1](ch01.xhtml)).'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Let’s reproduce the example in [Figure 12-10](ch012.xhtml#ch012fig10). The proposal
    function is a uniform distribution multiplied by 4.1, as this puts the proposal
    function just above the highest part of the sampling function, *q*(*x*)
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0345-02.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
- en: which is the sum of two normal curves centered at ±5, with one being four times
    higher than the other.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we sample:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The output tells us we need over 830,000 candidate samples to get the requested
    100,000\. That’s a conversion rate of 12 percent, meaning we rejected 88 percent
    of the candidates. The efficiency of rejection sampling depends critically on
    the closeness between the proposal function, *cp*(*x*), and the sampling function,
    *q*(*x*). The closer the proposal function is to the sampling function, the better.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 12-11](ch012.xhtml#ch012fig11) shows a histogram of the samples from
    *q*(*x*). The proposal function is in [Figure 12-10](ch012.xhtml#ch012fig10).
    Note that rejection sampling doesn’t care whether *p*(*x*) and *q*(*x*) are normalized
    (in which the area under the curves is 1). So long as *cp*(*x*) is above *q*(*x*),
    all will be well (if perhaps slow).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig11.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-11: Sampling with a uniform proposal function*'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use a normal curve for the proposal function:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The proposal function is now a normal curve with a mean of 0 and a standard
    deviation of 1\. The multiplier is 4.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: The output is in *reject1*. We’re told that we need 1.5 million candidates to
    get 100,000 samples for a conversion rate of 6.6 percent. [Figure 12-12](ch012.xhtml#ch012fig12)
    shows the histogram (left) and a plot of the proposal and sampling functions (right).
    The plots might seem strange to you, for good reason.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig12.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-12: Using N(0,1) as the proposal function*'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: The proposal function is the dashed curve on the right in [Figure 12-12](ch012.xhtml#ch012fig12).
    It’s centered between the normal curves making up *q*(*x*), and is larger than
    *q*(*x*) over only a small region around zero. The algorithm can’t select samples
    in areas where *p*(*x*) < *q*(*x*); therefore, it selects only in the region covering
    the overlap between the right part of the leftmost normal curve and the left part
    of the rightmost normal curve.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: In the histogram on the left, the code scales *q*(*x*) and the histogram of
    the samples, so both have 1 as their maximum *y* value. The histogram peaks at
    two locations, the left and right maxima of the overlap region. While not what
    we’re after, the output from this run is correct, given the constraints.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try a few more examples. The file *run_rejection_examples* contains [Listing
    12-8](ch012.xhtml#ch012list08).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '*Listing 12-8: Additional examples*'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 12-13](ch012.xhtml#ch012fig13) shows the generated plots for *reject2*
    through *reject5* from top to bottom.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: The topmost plot covers the entire *q*(*x*) range, with samples drawn from each
    peak. The next row shows samples from only the left peak, as the proposal function
    covers it and a tiny part of the right peak. The third row limits selection to
    *x ∈* [–11, 4], restricting the range of samples while still mirroring the shape
    of *q*(*x*). The final row of [Listing 12-8](ch012.xhtml#ch012list08) switches
    to a new function, *q*(*x*) = 2*x*² + 3, and a uniform proposal function.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig13.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-13: Histograms and proposal functions for the command lines in [Listing
    12-8](ch012.xhtml#ch012list08)*'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Experiment with *rejection.py* with *q*(*x*) functions and proposal functions
    that either completely or partially cover *q*(*x*). Remember to pick a *c* such
    that *q*(*x*) < *cp*(*x*) for the regions from which you want to sample.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: 'Rejection sampling isn’t restricted to one dimension. For example, if we have
    *q*(*x*, *y*), we can draw samples as long as we can sample from *p*(*x*, *y*).
    The uniform function, which is 1 for all (*x*, *y*) points, is an easy *p*(*x*,
    *y*) to use. A multivariate normal distribution will also work, though it’s harder
    to code and visualize. The algorithm remains the same, but instead of drawing
    *x* from *p*(*x*), we draw (*x*, *y*) from *p*(*x*, *y*)—a random point in 2D
    space. The test is still *ucp*(*x*, *y*) *≤ q*(*x*, *y*), or:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0349-01.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
- en: If the condition holds, the point (*x*, *y*) is a sample from *q*(*x*, *y*).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: The extension to arbitrary dimensions, ***x*** = (*x*[0], *x*[1], *x*[2], .
    . . ), follows as long as we can sample from *p*(***x***). However, as the dimensionality
    increases, the number of samples rejected tends to increase exponentially (for
    each new dimension) unless *p*(***x***) follows *q*(***x***) very closely, which
    is quite difficult to do while maintaining easy sampling from *p*(***x***). This
    effect, where the utility of rejection sampling decreases with the problem’s dimensionality,
    is a form of the *curse of dimensionality* that frequently plagues machine learning
    models as well.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'The inefficiency of rejection sampling as the dimensionality of the problem
    increases leads to our final sampling algorithm, which handles high-dimensional
    problems: Markov Chain Monte Carlo.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '***Markov Chain Monte Carlo***'
  id: totrans-271
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Our final sampling algorithm is the most powerful: *Markov Chain Monte Carlo
    (MCMC)*. We learned about Monte Carlo algorithms in [Chapter 10](ch010.xhtml).
    The phrase *Markov chain*, named after Russian mathematician Andrey Markov (1856–1922),
    refers to a process where the *transition probability* of moving from a current
    state to a new state depends only on the current state and nothing that came before.
    Markov chains are helpful in simulations because what happens next depends solely
    on what the system is currently doing, regardless of its history.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: MCMC uses Markov chains to approximate sampling from a complex probability distribution.
    A *stationary distribution* in Markov chains, typically denoted as ***π***, is
    a vector in the discrete case or a PDF in the continuous case. Regardless of the
    initial distribution, walking the Markov chain eventually reaches the stationary
    distribution governed solely by the transition probabilities if specific criteria
    are met.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: We’ll first delve into stationary distributions; then, we’ll explore the Metropolis-Hastings
    algorithm and use it to walk a continuous Markov chain—only to realize that its
    stationary distribution is the very PDF we want to sample from.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '**Walking a Markov Chain**'
  id: totrans-275
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s work through an example. Fezzes are all the rage this year. Everyone’s
    wearing them, and there are three colors: red, green, or blue. The probability
    of a person changing their fez color next year depends on the color they wear
    this year. The probabilities are fixed from year to year. What happens to an initial
    distribution of fez colors as time passes? Will the distribution of colors change
    continuously or eventually settle down to a specific, perhaps stationary, distribution?'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: We encode transition probabilities in a matrix where the row shows a current
    state (a fez color) and the columns of that row represent the probability of a
    transition from the current state to a new state—a new fez color, which may be
    the same as the current.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this transition matrix:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0350-01.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
- en: The rows are red, green, and blue fezzes, as are the columns. Therefore, if
    someone is wearing a red fez this year, they have a 53 percent chance of wearing
    a red fez again next year, a 5 percent chance of changing to a green fez, and
    a 42 percent chance of donning a blue fez. The row sums to 1, as it must. Similarly,
    a green fez aficionado has an 83 percent likelihood of continuing to wear a green
    fez next year, though 13 percent will switch to a red fez, and a rogue 4 percent
    will go all in on a blue fez.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the transition matrix, we need an initial distribution of fezzes:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0350-02.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
- en: The vector tells us 70 percent of the population owns a red fez, 24 percent
    a green one, and only 6 percent a blue one.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: 'To find out what the distribution looks like next year, we need to see what
    happens to the proportion of the population wearing each fez color when acted
    on by the transition matrix. Those wearing a red fez transition to new colors
    according to the transition matrix’s first row, [0.53, 0.05, 0.42]. We multiply
    the red-fez wearers by the transition probabilities to get the fraction of next
    year’s fez colors from those currently wearing a red fez:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0350-03.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
- en: For the greens, we multiply the second row of the transition matrix by 0.24,
    and for the blues we multiply the last row by 0.06\. Finally, we sum across to
    get the new distribution of fez colors.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: 'In the end, these steps involve nothing more than multiplying the current distribution
    as a row vector by the transition matrix:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0350-04.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
- en: Next year, 41 percent of the population will wear red fezzes, 25 percent will
    wear green, and nearly 34 percent blue. The Markov property tells us that the
    following distribution is this distribution multiplied again on the right by the
    transition matrix, and so on.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: The file *markov_chain.py* accepts an initial distribution of fez colors (***π***)
    and a transition matrix (***P***) and generates the Markov chain until the distribution
    becomes stationary. To make things more interesting, the distribution of red,
    green, and blue fezzes is treated as an RGB color so that the output file, *markov_chain.png*,
    shows the transition from initial to stationary distribution as a color bar running
    from left to right.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the code with the previous values:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The first three values are the initial distribution: red, green, and blue fezzes.
    The final argument, which must not contain spaces, is a Python list representing
    the transition matrix. The values are not precisely the same as before, but the
    inputs are scaled by their respective sums so that'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0351-01.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
- en: and likewise for the individual rows of the transition matrix.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: We print the Markov chain
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: which tells us that the stationary distribution is 22 percent red, 51.5 percent
    green, and 26.4 percent blue fezzes.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Try experimenting with the code, changing the input distribution to `1 0 0`
    (100 percent red) or `0 0 1` (100 percent blue). You’ll always end up at the stationary
    distribution, though the number of links in the chain might differ. Then, alter
    the transition matrix and see what happens.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 'The only portion of the code worth discussing builds the chain:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `while` loop runs until the difference between the new distribution and
    the `last` distribution is less than or equal to `eps`. The `chain` list holds
    the sequence of distributions. We use `@` to perform the matrix multiplication,
    ***π** ← **πP***.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: The power behind MCMC comes from the fact that the Metropolis-Hastings algorithm,
    to which we now turn, runs the Markov chain without directly generating it, but
    as a proxy returns samples from ***π*** once the chain is long enough to reach
    the stationary distribution.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '**Exploring Metropolis-Hastings**'
  id: totrans-304
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A paper titled “Equation of State Calculations by Fast Computing Machines” appeared
    in the June 1953 edition of *The Journal of Chemical Physics*. The authors were
    Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H.
    Teller, and Edward Teller. The paper introduced the *Metropolis algorithm*, named
    as such because Metropolis’s name is first on the paper. However, as so often
    happens in the thoroughly human enterprise of science, the process that led to
    the algorithm is disputed. It appears more likely now that the actual inventors
    were Marshall and Arianna Rosenbluth, not Metropolis. All five authors have since
    passed away, so it’s doubtful we’ll ever know the whole story. We’ll refer to
    the algorithm by its modern name, the Metropolis algorithm, knowing full well
    that credit may belong elsewhere.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: In 1970, Wilfred Hastings extended the algorithm to the case where the proposal
    distribution is not symmetric; hence the algorithm is now known as *Metropolis-Hastings
    (MH)*. We’ll restrict ourselves to a symmetric normal distribution as the proposal
    distribution, so, technically, we’re using only the Metropolis part.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: MH generates samples using a proposal distribution in much the same way as rejection
    sampling; however, in this case, the proposal distribution walks around randomly
    (we’ll learn what that means soon) and, as a consequence, alters a Markov chain
    distribution. Run the random walk with proper rejection and acceptance of moves
    for long enough, and eventually, we’ll reach the Markov chain’s stationary distribution.
    At that point, the samples MH returns are from the stationary distribution, which
    is the distribution we want to draw samples from in the first place. How convenient!
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '*A full mathematical treatment of MH and what it’s doing under the hood is
    beyond what we tackle here. Those interested will find a good summary on Gregory
    Gundersen’s blog:* [https://gregorygundersen.com/blog/2019/11/02/metropolis-hastings](https://gregorygundersen.com/blog/2019/11/02/metropolis-hastings)*.*'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: For our purposes, we’ll accept MH’s claims and instead look at the random walk
    version of the algorithm. MH requires a function to sample from, the functional
    form we want our samples to follow when we make a histogram of their distribution.
    This is the stationary distribution for a Markov chain, so we’ll call this function
    *π*(*x*) (not to be confused with the number, *π*). MH works well in the multidimensional
    case, but we’ll limit ourselves to one dimension, so it’s *π*(*x*) and not ***π***(*x*).
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: MH also requires a proposal distribution, *Q*(*x*). We’ll use a normal distribution
    because it’s symmetric, and we know how to sample from it efficiently, *x′ ∼ N*(*x*,
    *σ*) for a user-supplied *σ* and mean *x*.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: 'With *π*(*x*) and *Q*(*x*) on hand, random walk MH is straightforward:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Pick an initial sample, *x*; for example, *x* = 1.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Propose a new sample based on the current: *x′ ∼ N*(*x*, *σ*).'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define ![Image](../images/f0353-01.jpg)
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define *ρ* = min(1, *A*).
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define *u ∼* uniform(0, 1).
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If *u* < *ρ*, accept *x′*, *x ← x′*.
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Otherwise, keep *x*.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Output *x* as a sample.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat steps 2–8 until all desired samples are collected.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The acceptance value, *A*, evaluates the function we want to sample from using
    the current sample position, *x*, and the proposed sample position, *x′*. If this
    value, passed through *ρ* (rho) to limit it to a maximum of 1, is less than a
    random uniform sample, accept the proposal (*x′*) as a new sample; otherwise,
    stick with the current sample, *x*. Before looping, output whatever *x* is as
    a sample from the distribution, *π*(*x*).
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: This algorithm is the simplest way to implement MH. In practice, we can make
    it even simpler because there’s no need to define *ρ*; we can use *A* as it is
    because *u* is always in [0, 1).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: In step 2, the new proposal position, *x′*, comes from the proposal function,
    a normal distribution centered on *x*, the current sample. This is the random
    walk part. In step 6, if *x′* is ultimately accepted, it becomes the new *x* we
    use to pick the next proposal position. In other words, the normal curve jumps
    to a new position on the *x*-axis when a proposal is accepted. We’ll soon generate
    animations showing this behavior.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: We base acceptance or rejection on the value of *π*(*x′*) and *π*(*x*), that
    is, the ratio of *π*’s *y* value at the proposed new sample position and the current.
    If *π* has a high value at the current position, the fraction, *A*, will be small,
    meaning the comparison in step 6 is less likely to succeed. If the proposal is
    rejected, *x* is output again as a sample from *π*. We want this because *π* has
    a high *y* value at that *x*. If *π*(*x*) is tiny, *π*(*x′*) is more likely greater,
    meaning *A* is greater than 1\. If *A* > 1, *ρ* = 1 and the proposal position
    will always be selected because *u* < 1\. Therefore, the parts of *π* less likely
    to be selected when viewing *π* as a PDF will be less often sampled.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Given this behavior, we can imagine that, in time, the random walk based on
    samples from the normal distribution will wander over *π* in proportion to *π*’s
    value at each position, thereby generating samples in the desired proportions.
    I haven’t commented on *σ*, the user-supplied parameter to MH, yet. We’ll experiment
    with it shortly and understand its effect then.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: As for the definition of *A*, I’ve written it as the ratio of *π*(*x*) evaluated
    at the current and proposed *x* positions. This is the Metropolis version of the
    algorithm, which works with symmetric proposal distributions. If the proposal
    distribution isn’t symmetric, the numerator and denominator each have an additional
    multiplicative factor. In the symmetric case, this factor is the same for the
    numerator and denominator, so it cancels.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '*A* is a ratio, and Bayes’ theorem writes the posterior as the product of the
    likelihood and the prior, all divided by a normalizing factor that, in practice,
    is usually an intractable integral. Since it works with the ratio, MH cancels
    this integral, so we don’t need to compute it in the first place. MH makes it
    possible to sample from posterior distributions using only the likelihoods and
    priors. This makes Bayesians very happy and leads to the dramatic quote earlier
    in the chapter about Bayes and MCMC.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the algorithm to see that your samples *don’t* follow *π*(*x*). We’ve neglected
    a key statement about the MH algorithm: it doesn’t claim to immediately generate
    samples from *π*(*x*), but only in the limit, after some period of time. How long
    a time, and how many samples do we generate before we trust that the samples are
    coming from *π*(*x*)? There is no foolproof answer to that question. Our experiment
    with fezzes generally converged to the stationary distribution after a dozen or
    fewer iterations. That might be the case with MH, but it’s generally accepted
    that complex *π*(*x*) functions require many thousands of samples or more before
    they come from *π*(*x*). Therefore, when we implement MH in code, we’ll specify
    a number of *burn-in* samples, which we’ll throw away, and keep only those that
    come after. We did something similar in [Chapter 7](ch07.xhtml) when playing the
    chaos game to generate points on the attractor of an iterated function system.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: This is a random walk algorithm and a Markov algorithm because we randomly draw
    the next candidate sample, *x′*, from a distribution with a mean value based on
    the current sample, *x*. In a random walk, the next position is relative to the
    current position. It’s a Markov algorithm because history doesn’t matter; only
    the current sample position, *x*, influences any possible new position. Finally,
    it’s a Monte Carlo algorithm because it depends on randomness and isn’t guaranteed
    to generate accurate samples from *π*(*x*), at least initially.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive into some code and contemplate the *mcmc.py* file. You’ll find code
    to parse the command line, sample from a normal distribution, and generate a series
    of plots using the samples—all of which we’ve seen several times before.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: The heart of *mcmc.py* is the `MH` function ([Listing 12-9](ch012.xhtml#ch012list09)).
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '*Listing 12-9: A random walk Metropolis-Hastings sampler*'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: As with rejection sampling, `func` is a string defining *π*(*x*). The rules
    for its composition are the same as with *rejection.py*. We ultimately want `nsamples`’
    worth of samples, excluding the first `burn`’s worth, which we discard. This explains
    the `while` loop condition knowing that the list `samples` holds all the generated
    samples.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: The body of the `while` loop is a direct implementation of the MH algorithm,
    ignoring the explicit definition of *A* and *ρ*. First, we sample a proposal position,
    `p`, from a normal curve centered on the current sample position, `q`. Then, if
    we’ve given `MH limits`, they restrict the portion of *π*(*x*) we sample from
    in the end. We did the same with rejection sampling.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: We define `func` with `x` as the independent variable, so we need to call `eval`
    and assign to `x` to get the numerator (`num`) and denominator (`den`). Finally,
    if *u* is less than `num`/`den`, accept `p` as the new `q` before appending `q`
    to `samples`.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Once we’ve acquired all samples—including those marked as burn-in, for plotting
    purposes—return `samples` as a NumPy vector after excluding the burn-in samples.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: 'Run *mcmc.py* without arguments to see the command line arguments it expects:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: There are a lot of arguments here, but we know what most of them do. We want
    `N` samples after ignoring the first `burn` samples. We know that `func` is a
    string defining *π*(*x*). If `limits` isn’t `none`, it restricts the *x*-axis
    range sampled.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: We use `q` to supply an initial sample position. Finally, the shape of the proposal
    function, the normal distribution from which *x′* is drawn, depends on `sigma`.
    If `sigma` is too small, the normal distribution is narrow, and it’s harder to
    jump to other parts of *π*(*x*). On the other hand, if `sigma` is larger, it’s
    easier to sample from all of *π*(*x*), to a point.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: We understand `outdir`, `kind`, and `seed`. The final argument is the required
    string, either `yes` or `no`. If `yes`, the output plot showing *π*(*x*) and the
    histogram of samples will also show the normal distribution centered on the initial
    `q` with standard deviation `sigma`. Read through *mcmc.py* to understand how
    the output plots are made. Let’s run the code to understand what it produces.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin with this command line:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We’re asking for 100,000 samples after 10,000 were thrown away as burn-in. We
    use the same sum-of-two-normal-curves function for *π*(*x*) as with rejection
    sampling. The `none` option opens all of the *x*-axis to sampling, though we’ll
    end up sampling only where *π*(*x*) is nonzero. The initial sample position is
    0 and `sigma` is 3\. Finally, we want to see the initial distribution function
    in the output plot; we’re fixing the pseudorandom generator and seed and dumping
    all output in `tmp`.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 12-14](ch012.xhtml#ch012fig14) shows the plots *mcmc.py* creates.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig14.jpg)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-14: Using Metropolis-Hastings to sample from π(*x*) (top) along
    with the trace (bottom left) and burn-in plots (bottom right)*'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: The top plot is *π*(*x*) along with the histogram of the samples MH produced.
    Also included, because we said `yes` on the command line, is the initial proposal
    distribution, a normal curve centered at *x* = 0 with *σ* = 3\. Note that the
    curves are scaled to have 1.0 as their maximum value. As with rejection sampling,
    we’re looking for the shape of *π*(*x*) and the histogram to match.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: The graphs on the bottom of [Figure 12-14](ch012.xhtml#ch012fig14) are *trace
    plots* that show the sampled *x* as a function of the sample number. Think of
    “sample number” as time, so the graphs show how *x* changes over time. The plot
    on the left follows samples generated after the burn-in period, while the plot
    on the right shows the burn-in samples.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: The plots were created by the same command line as the top plot, but the total
    number of samples was set to 10,000, with 1,000 for burn-in. On the left, most
    samples are near *x* = –5, the peak of the larger normal curve from which *π*(*x*)
    is made. The remaining samples center on *x* = 5, the smaller peak. The burn-in
    plot on the right, however, jumps around near the respective peaks.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many things to explore with *mcmc.py*. I’ll offer two suggestions
    as starting points. I recommend running these command lines, then contemplating
    the output to see if you fully understand it. Remember to look at the trace plots
    as well, especially for *π*(*x*) = 2*x*² + 3:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Earlier, I promised that we’d create a movie showing the random walk inherent
    in our implementation of MH; I’ll make good on that promise now. Run this command:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The file *mcmc_movie.py* is very similar to *mcmc.py*. The output directory,
    *tmp*, contains a new directory, *frames*. This directory contains files running
    from *frame_0000.png* to *frame_0899.png* showing each proposed sample (thin vertical
    line) along with each accepted sample (thick vertical line) as MH moves through
    its random walk. Use an image viewer that can page through a directory of files
    in alphabetical order to view the walk as a movie, or download *mcmc_movie.mp4*
    from the book’s GitHub page.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  id: totrans-358
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here are some things you may wish to try:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: Update `ChooseMap` in *ifs.py* to use `Sequential` ([Listing 12-3](ch012.xhtml#ch012list03)).
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use *inverse.py* with ![Image](../images/f0358-01.jpg) instead of just *u*.
    Does anything change about the samples? What does this *F*^(–1)(*u*) look like?
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Cauchy distribution is characterized by *µ* and *γ*. The PDF is![Image](../images/f0358-02.jpg)
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'with corresponding CDF:'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Image](../images/f0358-03.jpg)'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Try to sample from this function with *inverse.py*. Set *µ* = –2 and *γ* =
    1\. For example:'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: What do you see? Now, replace *inverse.py* with *inverse_cauchy.py*. What’s
    the difference between the two programs? There are times when algorithms need
    to be tweaked to succeed.
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Execute the shell script *run_rejection_c* and explain the output in terms
    of the rejection test for cases when *cp*(*x*) ≫ *q*(*x*) versus just barely exceeding
    *q*(*x*). Hint: consider the likelihood of picking a *y* value for a given *x*
    when *q*(*x*) *≈ cp*(*x*).'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Experiment with *mcmc.py* using functions that are always positive over some
    given range. What happens as you make the burn-in larger or smaller? Try changing
    *σ*. Do large or small *σ* values work better? Here’s a function to try:'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*p[X]*(*x*) = sin³(*x*) + 1'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'I suggest a command line like this one:'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Can you explain the plot and histogram? The limits are, roughly, –3*π* to 3*π*.
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Summary**'
  id: totrans-374
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, we sampled from arbitrary distributions. First, we introduced
    terminology and concepts from Bayesian inference, a primary user of sampling techniques.
    After that, we sampled from discrete distributions, which often appear when working
    with histograms. We learned about sequential sampling and the FLDR, both of which
    run in ![Image](../images/c0301-01.jpg)(*n*) time—though, practically, the dice
    roller is some five to seven times faster.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: We then experimented with sampling from a two-dimensional discrete distribution
    by unraveling the two-dimensional distribution to manipulate it as a one-dimensional
    distribution. As grayscale images are, in effect, two-dimensional discrete distributions,
    we sampled from them and observed that more intense pixels were sampled most often.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuous distributions, characterized by PDFs, came next. In certain cases,
    sampling becomes a simple process if the cumulative distribution function is invertible.
    When such is not the case, we explored two approaches: rejection sampling and
    MCMC with the MH algorithm.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: Rejection sampling works well in one dimension, but suffers as the dimensionality
    of the samples increases. We explored how the algorithm behaves for two proposal
    distributions, the uniform and the normal, to realize that the closer the proposal
    function is to the actual PDF, the fewer samples are rejected and the more efficient
    the algorithm becomes.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: When the distribution we want to sample becomes complex or is of high dimensionality,
    rejection sampling is best replaced by MCMC. We learned about MH in one dimension
    using a symmetric normal distribution as the proposal distribution. Animated plots
    showed the progress of the sampling algorithm over time.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
