- en: '**7'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: FINDING A GOOD SET OF HYPERPARAMETERS**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As discussed in earlier chapters, especially [Section 3.2.1](ch03.xhtml#ch03lev2sec1),
    most analysts’ approach to the problem of determining good values of hyperparameters
    is to use cross-validation. In this chapter, we’ll learn to use a `qeML` function,
    `qeFT()`, that greatly facilitates the process.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Combinations of Hyperparameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Note that typically we are talking about *sets* of hyperparameters. Suppose,
    for instance, that we wish to use PCA in a k-NN setting. Then we have two hyperparameters:
    the number of neighbors *k* and the number of principal components *m*. Thus we
    are interested in finding a good *combination* of a *k* value and an *m* value.'
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, the combinations are larger than just pairs. With `qeDT()`, for
    instance, there are hyperparameters `alpha`, `minsplit`, `minbucket`, `maxdepth`,
    and `mtry`. We thus wish to find a good set of five hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Many ML methods have even more hyperparameters. The more hyperparameters an
    ML method has, the more challenging it is to find a good combination of values.
    The `qeML` function `qeFT()` is aimed at facilitating this search.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Before continuing, note that though ML discussions—as well as some software
    documentation—will often refer to finding the **best** hyperparameter combination,
    this is typically an illusion. Due to p-hacking (see [Section 1.13](ch01.xhtml#ch01lev13)),
    the best combination for a given training set may not be the best for predicting
    new data, which is what counts. Nevertheless, by the end of this chapter, you’ll
    have the tools to dependably determine **good** combinations.*'
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Grid Searching with qeFT()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many ML packages include functions to do a *grid search*, which means evaluating
    all possible hyperparameter combinations. However, the number of combinations
    is typically so large that a full grid search would take a prohibitive amount
    of time to run.
  prefs: []
  type: TYPE_NORMAL
- en: Some grid search software libraries attempt to solve this problem by evaluating
    only combinations that seem promising, via an iterative search moving through
    narrow parts of the grid. At each iteration, the algorithm updates its guess as
    to what to try next. This saves time but can move in the wrong direction and,
    again, is vulnerable to p-hacking problems.
  prefs: []
  type: TYPE_NORMAL
- en: The `qeML` function `qeFT()` takes a more cautious approach. It generates a
    large number of random hyperparameter combinations, with the number being specified
    by the user, and evaluates them according to the relevant loss criterion (MAPE
    for numeric- *Y* settings or OME for classification settings). It tabulates and
    displays the results and includes a graphical display option. And, most importantly
    and uniquely, it guards against p-hacking, as will be explained shortly.
  prefs: []
  type: TYPE_NORMAL
- en: The `qeFT()` function is a `qe`-series wrapper for a `regtools` function, `fineTuning()`.
    Recall that another term for hyperparameters is *tuning parameters*. The function
    name is a pun on the old radio days, when tuning to the precise frequency of your
    favorite station was known as “fine-tuning.”
  prefs: []
  type: TYPE_NORMAL
- en: '***7.2.1 How to Call qeFT()***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Here is the basic `qeFT()` call form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at the roles of the arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: data   As in all of the `qe*`-series, our input data.
  prefs: []
  type: TYPE_NORMAL
- en: yName   As in all of the `qe*`-series, the name of our *Y* column.
  prefs: []
  type: TYPE_NORMAL
- en: qeftn   ML function name, such as `qeKNN`.
  prefs: []
  type: TYPE_NORMAL
- en: pars   R list specifying which `qeftn` hyperparameter values we wish to consider,
    such as *k* in k-NN.
  prefs: []
  type: TYPE_NORMAL
- en: nCombs   Number of random combinations of the hyperparameters to evaluate. If
    `NULL`, then all possible combinations will be run.
  prefs: []
  type: TYPE_NORMAL
- en: nTst   Size of the holdout sets.
  prefs: []
  type: TYPE_NORMAL
- en: nXval   Number of holdout sets to run for each hyperparameter combination.
  prefs: []
  type: TYPE_NORMAL
- en: showProgress   For the impatient; print results as they become available.
  prefs: []
  type: TYPE_NORMAL
- en: In short, we run the specified ML function `qeftn` on `nCombs` combinations
    of hyperparameters using ranges shown in `pars`. For each combination, we generate
    `nXval` training/test partitions of the data, with the test portion being of size
    `nTst`. We then tabulate the resulting MAPE or OME values across all combinations
    of hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Note the difference between `qeFT()` and the `replicMeans()` function introduced
    in [Section 3.2.2](ch03.xhtml#ch03lev2sec2). The latter deals with the problem
    that the analyst may feel that a single holdout set is not enough to accurately
    assess performance. The `qeFT()` function does this too, via the argument `nXval`,
    but it does much more, automating the search process.
  prefs: []
  type: TYPE_NORMAL
- en: '7.3 Example: Programmer and Engineer Data'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Returning to the US census data on programmers’ and engineers’ salaries in the
    year 2000 (see [Section 3.2.3](ch03.xhtml#ch03lev2sec3)), let’s find good hyperparameters
    to predict wage income.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The only hyperparameter argument here is `k`. We’ve specified its range as `5:25`—that
    is, we try *k* = 5, *k* = 6, and so on, up through *k* = 25\. Since we’ve left
    out the `nCombs` argument, we investigated all 21 of these by default.
  prefs: []
  type: TYPE_NORMAL
- en: The `meanAcc` is the primary result, giving us the mean `testAcc` over all cross-validation
    runs. We will explain the `CI` and `bonfCI` columns in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.3.1 Confidence Intervals***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At first it would seem that *k* = 5 neighbors is best. Indeed, that is our guess
    as to the optimal *k* for our setting here (meaning this *n*, this feature set,
    this sampled population, and so on). But we should be careful. Here is why.
  prefs: []
  type: TYPE_NORMAL
- en: Any `testAcc` value output from a `qe*`-series function is random, due to the
    randomness of the holdout sets. With `qeFT()`, we look at many holdout sets and
    average the result to obtain `meanAcc`. Since all the holdout sets are random,
    then so is `meanAcc`. Of course, the larger the `nXval`, the better the accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Thus the `meanAcc` column is only approximate. The idea of the `CI` column is
    to get an idea as to the accuracy of that approximation. Specifically, the values
    in the `CI` column are the right endpoints of approximate 95 percent confidence
    intervals (CIs) for the true mean accuracy of any given combination. (For those
    who know statistics, these are *one-sided* CIs, of the form (− ∞, *a*).)
  prefs: []
  type: TYPE_NORMAL
- en: In our case here, the `meanAcc` value for 7 neighbors is well within that CI
    for 5 neighbors. It’s really a toss-up between using 5 or 7 neighbors, and their
    `meanAcc` numbers are not too far apart anyway. Thus we should not take the apparent
    superiority of *k* = 5 literally.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, the `CI` column “keeps us honest,” serving to remind us that
    `meanAcc` is only approximate and giving us some idea whether the apparent top
    few performers are distinguishable from each other.
  prefs: []
  type: TYPE_NORMAL
- en: But there’s more. When we construct a large number of CIs, their overall validity
    declines due to p-hacking (see [Section 1.13](ch01.xhtml#ch01lev13)). CIs that
    are set individually at a nominal 95 percent level have a much lower overall confidence
    level. To see this, imagine tossing 10 coins. The individual probability of heads
    is 0.5 for each coin, but the probability that *all* of them come up heads is
    much lower. Similarly, if we have ten 95 percent CIs, the probability that they
    are *all* correct is much less than 95 percent.
  prefs: []
  type: TYPE_NORMAL
- en: The `bonfCI` column adjusts for that, using something called *Bonferroni−Dunn*
    CIs. In other words, that column gives us CIs that take into account that we are
    looking at many random CIs. We thus really should look more at that column than
    the `CI` one.
  prefs: []
  type: TYPE_NORMAL
- en: In our case here, the adjusted CI bounds are only a little larger than the original
    ones. This means we are not in much danger of p-hacking in this simple example.
    But as discussed in [Section 1.13](ch01.xhtml#ch01lev13), it could be an issue
    with an ML algorithm having many hyperparameters. In such a setting, it is quite
    possible that we will pounce on a seemingly “best” combination that actually is
    quite unrepresentative and thus much inferior to some other alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: We have no way of knowing that is the case, of course, but a good rule of thumb
    is to consider taking the more moderate combination among several with similar
    `meanAcc` values rather than extremely large or small values of the hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, consider neural networks (we will look at these further in [Chapter
    11](ch11.xhtml)), which typically have a number of hyperparameters, including:'
  prefs: []
  type: TYPE_NORMAL
- en: number of layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: number of neurons per layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: dropout rate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: learning rate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: momentum
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: initial weights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to investigate a broad variety of hyperparameter combinations, we would
    need to set the `nCombs` argument in `qeFT()` to a very large number, putting
    us at significant risk of finding a combination that is not actually very effective
    but that accidentally looks great. The `bonfCI` column warns us of this; the higher
    the discrepancy between it and the `CI` column, the greater the risk.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, we are merely seeking a *good* combination of hyperparameters,
    not the absolute best. For any particular combination, the `bonfCI` figure is
    giving us a reasonable indication as to whether this combination will work well
    in predicting future cases. As with many things in ML, there is no magic formula
    for how to deal with the CIs, but they can act as informal aids to our thinking.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Here’s a bit of history on Bonferroni−Dunn intervals: Traditionally, only
    the name Bonferroni is used, in honor of the Italian mathematician who developed
    the probability inequality central to the CIs. However, as a former student of
    Professor Olive Jean Dunn, I have been pleased to find that her name is now often
    included, as she was the one who proposed using the inequality for constructing
    CIs.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***7.3.2 The Takeaway on Grid Searching***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The takeaway here is that we cannot take the ordering of results in a grid search
    literally. The first few “best” results may actually be similar. Moreover, the
    apparent “best” may actually be unrepresentative. Settle on a “good” combination
    that is hopefully not too extreme rather than trying to optimize.
  prefs: []
  type: TYPE_NORMAL
- en: '7.4 Example: Programmer and Engineer Data'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s try predicting occupation instead of wage income.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The CIs, especially the Bonferroni−Dunn ones—which, as noted, are more reliable—suggest
    that any of the first `k` values have about the same predictive ability. The `bonfCI`
    value for 4 neighbors extends to include the `meanAcc` value for 5 neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: Note the role of `nXval` here. We simply used too few cross-validations. We
    should try more, but if not, the values of `k`, 1, 2, 3, 4, and 7, look about
    the same. Conservatively, we might choose to use 3 or 4 neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: '7.5 Example: Phoneme Data'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This dataset, which is included in the `regtools` package, seeks to predict
    one of two phoneme types from five sound measurements. Let’s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The *Y* column here is `lbl`. As noted, it has two levels, so this is a two-class
    classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try `qeDT()` on this data. As noted, the various hyperparameters interact
    with each other, so at first, we might not try using all of them. We might just
    use, say, `alpha`, `minbucket`, and `maxdepth`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to specify ranges that we want to investigate for each of these parameters.
    Once again, there is no formula for deciding this, and one must gain insight from
    experience. But as an example, let’s try 0.01, 0.05, 0.10, 0.25, 0.50, and 1 for
    `alpha`, and 1, 5, and 10 for `minbucket`, and so on, as seen in the call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Recall the role of `nCombs`. If we set it to `NULL`, that means we want `qeFT()`
    to try all possible combinations of our specified hyperparameter ranges. It turns
    out that there are 216 combinations (not shown). But we had set `nCombs` to 50,
    so `qeFT()` ran 50 randomly chosen combinations among the 216, and thus we see
    only 50 rows in the output here.
  prefs: []
  type: TYPE_NORMAL
- en: The more hyperparameters an ML algorithm has, and the more values we try for
    each one, the more possible combinations we have. In some cases, there are just
    too many to try them all, hence the non- `NULL` use of `nCombs`.
  prefs: []
  type: TYPE_NORMAL
- en: Note, too, that the more hyperparameter combinations we run, the greater the
    risk of p-hacking. It is here that the `bonfCI` column is most useful. The fact
    that, in the output above, the `bonfCI` column is very close to the `CI` column
    in most cases tells us that p-hacking is probably not an issue for this data.
  prefs: []
  type: TYPE_NORMAL
- en: Now, what might we glean from this output?
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning matters. The lowest OME values were about half of the
    largest ones.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since the first three `CI` values are very close and within each other’s CIs,
    any of the first three hyperparameter combinations should be good.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first 20 hyperparameter combinations all had a value of 8 for `maxdepth`.
    This suggests that we might do even better with a value larger than 8.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Larger values of `alpha` seemed to do better. This suggests that we try some
    additional large values. For instance, we didn’t try any values between 0.50 and
    1, so 0.75 might be worth a try.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The top three combinations all had `mtry = 0`, while the bottom ones had a value
    of 3 for that hyperparameter. We probably should do more detailed investigation
    here.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The hyperparameters do interact. Look at line 6, for instance. The value of
    `alpha` was smaller than in most top lines, putting a damper on the node-splitting
    process, but this was compensated for in part by small values of `minsplit` and
    `minbucket`, which encourage lots of node splitting. Such negative “correlations”
    are clear in the graphical display capability of `qeFT()` (not shown).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 7.6 Conclusions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: No doubt about it, finding a good set of hyperparameters is one of the major
    challenges in ML. But in this chapter we’ve seen tools that can be used for this
    purpose, and we can be reasonably confident that we’ve made a good choice.
  prefs: []
  type: TYPE_NORMAL
