- en: '**9'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**9'
- en: CPU ARCHITECTURE**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 架构**
- en: '![Image](../images/comm1.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/comm1.jpg)'
- en: Without question, the design of the central processing unit (CPU) has the greatest
    impact on the performance of your software. To execute a particular instruction
    (or command), a CPU requires a certain amount of electronic circuitry specific
    to that instruction. As you increase the number of instructions the CPU can support,
    you also increase the CPU’s complexity and the amount of circuitry, or *logic
    gates*, needed to execute them. Therefore, to keep the number of logic gates and
    the associated costs reasonably small, CPU designers must restrict the number
    and complexity of the instructions the CPU can execute. This is known as the CPU’s
    *instruction set*.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，中央处理单元（CPU）的设计对软件性能有着最大的影响。为了执行特定的指令（或命令），CPU需要特定的电子电路来处理该指令。随着CPU支持的指令数量增加，CPU的复杂度和执行这些指令所需的电路量或*逻辑门*也会增加。因此，为了保持逻辑门的数量和相关成本合理地较小，CPU设计师必须限制CPU能够执行的指令数量和复杂性。这就是所谓的CPU的*指令集*。
- en: This chapter, and the next, discusses the design of CPUs and their instruction
    sets—information that is absolutely crucial for writing high-performance software.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章以及下一章将讨论CPU及其指令集的设计——这些信息对于编写高性能软件至关重要。
- en: '**9.1 Basic CPU Design**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**9.1 基本的CPU设计**'
- en: Programs in early computer systems were often hardwired into the circuitry.
    That is, the computer’s wiring determined exactly what algorithm the computer
    would execute. The computer had to be rewired in order to solve a different problem.
    This was a difficult task, something that only electrical engineers were able
    to do.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 早期计算机系统中的程序通常是硬接线到电路中的。也就是说，计算机的接线决定了计算机将执行的算法。计算机必须重新接线才能解决不同的问题。这是一个困难的任务，只有电气工程师能够完成。
- en: Thus, the next advance in computer design was the programmable computer system,
    in which a computer operator could easily “rewire” the computer using a panel
    of sockets and plug wires known as a *patch board*. A computer program consisted
    of rows of sockets, with each row representing one operation (instruction) during
    the program’s execution. To execute an instruction, the programmer inserted a
    wire into its corresponding socket (see [Figure 9-1](ch09.xhtml#ch09fig01)).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，计算机设计的下一个进展是可编程计算机系统，在这种系统中，计算机操作员可以使用一组插槽和连接电线的面板，轻松地“重新接线”计算机，这就是*跳线板*。计算机程序由一排排插槽组成，每一排表示程序执行期间的一个操作（指令）。为了执行一条指令，程序员将电线插入相应的插槽中（参见[图
    9-1](ch09.xhtml#ch09fig01)）。
- en: '![image](../images/09fig01.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/09fig01.jpg)'
- en: '*Figure 9-1: Patch board programming*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-1：跳线板编程*'
- en: The number of possible instructions was limited by how many sockets could fit
    on each row. CPU designers quickly realized that with a small amount of additional
    logic circuitry, they could reduce the number of sockets required for specifying
    *n* different instructions from *n* sockets to log[2](*n*) sockets. They did this
    by assigning a unique binary number to each instruction (for example, [Figure
    9-2](ch09.xhtml#ch09fig02) shows how to represent eight instructions using only
    3 bits).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 可用指令的数量受到每排插槽能够容纳多少个插槽的限制。CPU设计师很快意识到，通过少量的额外逻辑电路，他们可以将指定*n*个不同指令所需的插槽数量从*n*个插槽减少到log[2](*n*)个插槽。他们通过为每个指令分配一个唯一的二进制数字来实现这一点（例如，[图
    9-2](ch09.xhtml#ch09fig02)展示了如何使用仅3个位表示8条指令）。
- en: '![image](../images/09fig02.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/09fig02.jpg)'
- en: '*Figure 9-2: Encoding instructions*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-2：编码指令*'
- en: The example in [Figure 9-2](ch09.xhtml#ch09fig02) requires eight logic functions
    to decode the *A*, *B*, and *C* bits on the patch board, but the extra circuitry
    (a single three- to eight-line decoder) is worth the cost, because it reduces
    the total number of sockets from eight to three for each instruction.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9-2](ch09.xhtml#ch09fig02)中的示例需要八个逻辑功能来解码跳线板上的*A*、*B*和*C*位，但额外的电路（一个三到八线解码器）是值得的，因为它将每个指令的插槽总数从八个减少到三个。'
- en: Many CPU instructions require operands. For example, the `mov` instruction moves
    data from one location in the computer to another, such as from one register to
    another, and therefore requires a source operand and a destination operand. The
    operands were encoded as part of the machine instruction, with sockets corresponding
    to the source and destination. [Figure 9-3](ch09.xhtml#ch09fig03) shows one possible
    combination of sockets to handle a `mov` instruction.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 许多CPU指令需要操作数。例如，`mov` 指令将数据从计算机的一个位置移动到另一个位置，比如从一个寄存器到另一个寄存器，因此需要源操作数和目标操作数。操作数被编码为机器指令的一部分，插槽对应源和目标。[图9-3](ch09.xhtml#ch09fig03)展示了处理
    `mov` 指令的插槽组合之一。
- en: '![image](../images/09fig03.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/09fig03.jpg)'
- en: '*Figure 9-3: Encoding instructions with source and destination fields*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9-3：编码带有源和目标字段的指令*'
- en: The `mov` instruction would move data from the source register to the destination
    register, the `add` instruction would add the value of the source register to
    the destination register, and so on. This scheme allowed the encoding of 128 different
    instructions with just seven sockets per instruction.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`mov` 指令将数据从源寄存器移动到目标寄存器，`add` 指令将源寄存器的值加到目标寄存器，以此类推。这个方案允许在每条指令仅使用七个插槽的情况下，编码出128条不同的指令。'
- en: As noted earlier, a big problem with patch-board programming was that a program’s
    functionality was limited by the number of sockets available on the machine. Early
    computer designers recognized a relationship between the sockets on the patch
    board and bits in memory. They realized they could store the binary equivalent
    of a machine instruction in main memory, fetch that binary number when the CPU
    wanted to execute the instruction, and then load it into a special register to
    decode the instruction. Known as the *stored program computer*, this invention
    was another major advance in computer design.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，早期板式编程的一个大问题是，程序的功能受限于机器上可用的插槽数量。早期计算机设计师意识到，板式插槽与内存中的比特之间存在关系。他们意识到，可以将机器指令的二进制等价物存储在主内存中，当CPU需要执行指令时，从内存中获取该二进制数，并将其加载到一个特殊寄存器中进行解码。这个发明被称为*存储程序计算机*，它是计算机设计的另一个重要进展。
- en: The trick was to add more circuitry, called the *control unit (CU)*, to the
    CPU. The control unit uses a special register, the *instruction pointer*, to hold
    the address of an instruction’s binary numeric code (also known as an *operation
    code* or *[opcode](gloss01.xhtml#gloss01_182)*). The control unit fetches the
    instruction’s opcode from memory and places it in the instruction decoding register
    for execution. After executing the instruction, the control unit increments the
    instruction pointer and fetches the next instruction from memory for execution.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方法是向CPU中添加更多电路，称为*控制单元（CU）*。控制单元使用一个特殊的寄存器，即*指令指针*，来保存指令的二进制数字代码地址（也称为*操作码*或*[opcode](gloss01.xhtml#gloss01_182)*）。控制单元从内存中提取指令的操作码，并将其放入指令解码寄存器中执行。执行完指令后，控制单元递增指令指针，并从内存中获取下一条指令进行执行。
- en: '**9.2 Decoding and Executing Instructions: Random Logic vs. Microcode**'
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**9.2 解码与执行指令：随机逻辑与微代码**'
- en: 'Once the control unit fetches an instruction from memory, traditional CPUs
    use two common approaches to execute the instruction: random logic (hardwired)
    and microcode (emulation). The 80x86 family, for example, uses both of these techniques.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦控制单元从内存中获取指令，传统CPU通常使用两种常见方法来执行指令：随机逻辑（硬连线）和微代码（仿真）。例如，80x86系列就同时使用了这两种技术。
- en: The *random logic*^([1](footnotes.xhtml#fn9_1a)) or hardwired approach uses
    decoders, latches, counters, and other hardware logic devices to operate on the
    opcode data. Random logic is fast but poses a circuitry design challenge; for
    CPUs with large and complex instruction sets, it’s difficult to properly lay out
    the logic so that related circuits are close to one another in the two-dimensional
    space of the chip.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*随机逻辑*^([1](footnotes.xhtml#fn9_1a))或硬连线方法使用解码器、锁存器、计数器和其他硬件逻辑设备来操作操作码数据。随机逻辑速度快，但在电路设计上带来挑战；对于具有大规模复杂指令集的CPU来说，很难合理布局电路，以便在芯片的二维空间中将相关电路放置得尽可能接近。'
- en: CPUs based on microcode contain a small, very fast *execution unit* (circuitry
    responsible for executing a particular function), known as a *[microengine](gloss01.xhtml#gloss01_156)*,
    that uses the binary opcode to select a set of instructions from the microcode
    bank. This microcode executes one microinstruction per clock cycle, and the sequence
    of microinstructions executes all the steps to perform whatever calculations are
    necessary for that instruction.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 基于微码的CPU包含一个小而快速的*执行单元*（负责执行特定功能的电路），称为* [微引擎](gloss01.xhtml#gloss01_156)*，它使用二进制操作码从微码库中选择一组指令。这个微码每个时钟周期执行一条微指令，微指令的序列执行所有步骤，以完成该指令所需的所有计算。
- en: Although this *microengine* itself is fast, it must fetch its instructions from
    the microcode ROM (read-only memory). Therefore, if memory technology is slower
    than the execution logic, the micro-engine must run at the same speed as the microcode
    ROM, which in turn limits the speed at which the CPU can run.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个*微引擎*本身非常快，但它必须从微码ROM（只读内存）中获取指令。因此，如果内存技术比执行逻辑更慢，微引擎必须以与微码ROM相同的速度运行，这反过来限制了CPU的运行速度。
- en: The random logic approach decreases the time to execute an opcode’s instruction,
    provided that typical CPU speeds are faster than memory speeds, but that doesn’t
    mean it’s necessarily faster than the microcode approach. Random logic often includes
    a sequencer that steps through several states (one state per clock cycle). Whether
    you use up clock cycles executing microinstructions or stepping through a random
    logic state machine, you’re still burning up time.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 随机逻辑方法可以减少执行操作码指令的时间，前提是典型的CPU速度比内存速度更快，但这并不意味着它一定比微码方法更快。随机逻辑通常包含一个顺序器，按顺序遍历多个状态（每个时钟周期一个状态）。无论你是通过执行微指令消耗时钟周期，还是在随机逻辑状态机中逐步执行，你仍然在消耗时间。
- en: Which approach is better for CPU design depends entirely on the current state
    of memory technology. If memory technology is faster than CPU technology, the
    microcode approach probably makes more sense. If memory technology is slower than
    CPU technology, random logic tends to execute machine instructions more quickly.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 哪种方法更适合CPU设计完全取决于当前的内存技术状态。如果内存技术比CPU技术更快，微码方法可能更有意义。如果内存技术比CPU技术更慢，随机逻辑通常能更快地执行机器指令。
- en: '**9.3 Executing Instructions, Step by Step**'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**9.3 按步骤执行指令**'
- en: Regardless of which approach the CPU uses, you need to understand how a CPU
    executes individual machine instructions. To that end, we’ll consider four representative
    80x86 instructions—`mov`, `add`, `loop`, and `jnz` (*jump if not zero*)—to give
    you a sense of how a CPU executes all the instructions in its instruction set.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 无论CPU使用哪种方法，你都需要理解CPU如何执行单个机器指令。为此，我们将考虑四个具有代表性的80x86指令——`mov`、`add`、`loop`和`jnz`（*如果不为零则跳转*）——来让你了解CPU如何执行其指令集中的所有指令。
- en: As you saw earlier, the `mov` instruction copies data from a source operand
    to a destination operand. The `add` instruction adds the value of its source operand
    to its destination operand. `loop` and `jnz` are *conditional jump* instructions—they
    test some condition and, if it’s `true`, they jump to some other instruction in
    memory; if it’s `false`, they continue with the next instruction. The `jnz` instruction
    tests a Boolean variable within the CPU known as the *zero flag* and either transfers
    control to the target instruction (the instruction to jump to) if the zero flag
    contains `0`, or continues with the next instruction if the zero flag contains
    `1`. The program indicates the address of the target instruction by specifying
    the distance, in bytes, between it and the `jnz` instruction in memory.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你之前看到的，`mov`指令将数据从源操作数复制到目标操作数。`add`指令将源操作数的值加到目标操作数中。`loop`和`jnz`是*条件跳转*指令——它们测试某个条件，如果为`true`，它们跳转到内存中的某个其他指令；如果为`false`，则继续执行下一条指令。`jnz`指令测试CPU内的一个布尔变量，称为*零标志*，如果零标志的值为`0`，则将控制转移到目标指令（跳转到的指令）；如果零标志的值为`1`，则继续执行下一条指令。程序通过指定目标指令与`jnz`指令在内存中的字节距离来指示目标指令的地址。
- en: 'The `loop` instruction decrements the value of the ECX register and, if the
    resulting value does not contain `0`, transfers control to a target instruction.
    This is a good example of a *complex instruction set computer (CISC)* instruction
    because it does more than one operation:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`loop`指令递减ECX寄存器的值，并且如果结果值不为`0`，则将控制转移到目标指令。这是*复杂指令集计算机（CISC）*指令的一个好例子，因为它执行了多个操作：'
- en: It subtracts 1 from ECX.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它从ECX中减去1。
- en: It does a conditional jump if ECX does not contain `0`.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果ECX不为`0`，它会进行条件跳转。
- en: 'That is, `loop` is roughly equivalent to the following instruction sequence:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，`loop`大致相当于以下指令序列：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To execute the `mov`, `add`, `jnz`, and `loop` instructions, the CPU has to
    execute a number of different operations. Each operation requires a finite amount
    of time to execute, and the time required to execute the entire instruction generally
    amounts to one clock cycle per operation or *stage* (step) that the CPU executes.
    Obviously, the more stages needed for an instruction, the slower it will run.
    Because they have many execution stages, complex instructions generally run slower
    than simple instructions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行`mov`、`add`、`jnz`和`loop`指令，CPU需要执行一系列不同的操作。每个操作执行都需要一定的时间，整个指令执行所需的时间通常等于CPU执行每个操作或*阶段*（步骤）所需的一个时钟周期。显然，指令所需的阶段越多，它的运行速度就越慢。由于复杂指令具有多个执行阶段，因此它们的运行速度通常比简单指令慢。
- en: 'Although 80x86 CPUs differ and don’t necessarily execute the exact same steps,
    their sequence of operations is similar. This section presents some possible sequences,
    all starting with the same three execution stages:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管80x86 CPU有所不同，并不一定执行完全相同的步骤，但它们的操作序列是相似的。本节展示了一些可能的序列，所有序列都从相同的三个执行阶段开始：
- en: Fetch the instruction’s opcode from memory.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取指令的操作码。
- en: Update the EIP (extended instruction pointer) register with the address of the
    byte following the opcode.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用紧跟操作码后的字节地址更新EIP（扩展指令指针）寄存器。
- en: Decode the instruction’s opcode to see what instruction it specifies.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码指令的操作码，以查看它指定了什么指令。
- en: '***9.3.1 The mov Instruction***'
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.3.1 mov 指令***'
- en: 'A decoded 32-bit 80x86 `mov(`srcReg`,` destReg`);` instruction might use the
    following (additional) execution stages:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 解码后的32位80x86 `mov(`srcReg`,` destReg`);`指令可能使用以下（额外的）执行阶段：
- en: Fetch the data from the source register (srcReg).
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从源寄存器（srcReg）获取数据。
- en: Store the fetched value into the destination register (destReg).
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将获取的值存储到目标寄存器（destReg）中。
- en: 'The `mov(`srcReg`,` destMem`);` instruction could use the following execution
    stages:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`mov(`srcReg`,` destMem`);`指令可能使用以下执行阶段：'
- en: Fetch the displacement associated with the memory operand from the memory location
    immediately following the opcode.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从紧跟操作码后的内存位置获取与内存操作数相关的位移值。
- en: Update EIP to point at the first byte beyond the operand that follows the opcode.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，使其指向操作码后面操作数的第一个字节。
- en: Compute the effective address of the destination memory location, if the `mov`
    instruction uses a complex addressing mode (for example, the indexed addressing
    mode).
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果`mov`指令使用复杂的寻址模式（例如，索引寻址模式），则计算目标内存位置的有效地址。
- en: Fetch the data from srcReg.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从srcReg获取数据。
- en: Store the fetched value into the destination memory location.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将获取的值存储到目标内存位置。
- en: A `mov(`srcMem`,` destReg`);` instruction is very similar, simply swapping the
    register access for the memory access in these steps.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`mov(`srcMem`,` destReg`);`指令非常类似，只是将寄存器访问与内存访问交换了这些步骤。'
- en: 'The `mov(`constant`,` destReg`);` instruction could use the following execution
    stages:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`mov(`constant`,` destReg`);`指令可能使用以下执行阶段：'
- en: Fetch the constant associated with the source operand from the memory location
    immediately following the opcode.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从紧跟操作码后的内存位置获取与源操作数相关的常量。
- en: Update EIP to point at the first byte beyond the constant that follows the opcode.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，使其指向操作码后面的第一个字节。
- en: Store the constant value into the destination register.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将常量值存储到目标寄存器中。
- en: Assuming each stage requires one clock cycle for execution, this sequence (including
    the three common stages) will require six clock cycles to execute.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 假设每个阶段需要一个时钟周期执行，那么这个序列（包括三个共同的阶段）将需要六个时钟周期来执行。
- en: 'The `mov(`constant`,` destMem`);` instruction could use the following execution
    stages:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`mov(`constant`,` destMem`);`指令可能使用以下执行阶段：'
- en: Fetch the displacement associated with the memory operand from the memory location
    immediately following the opcode.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从紧跟在操作码后的内存位置获取与内存操作数相关的位移值。
- en: Update EIP to point at the first byte beyond the operand that follows the opcode.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，使其指向紧跟在操作数后的第一个字节。
- en: Fetch the constant operand’s value from the memory location immediately following
    the displacement associated with the memory operand.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从紧跟在内存操作数位移后的内存位置获取常量操作数的值。
- en: Update EIP to point at the first byte beyond the constant.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，使其指向常量的第一个字节。
- en: Compute the effective address of the destination memory location, if the `mov`
    instruction uses a complex addressing mode (for example, the indexed addressing
    mode).
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算目标内存位置的有效地址，如果`mov`指令使用复杂寻址模式（例如，索引寻址模式）。
- en: Store the constant value into the destination memory location.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将常量值存入目标内存位置。
- en: '***9.3.2 The add Instruction***'
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.3.2 add指令***'
- en: 'The `add` instruction is a little more complex. Here’s a typical set of operations
    (beyond the common set) that the decoded `add(`srcReg`,` destReg`);` instruction
    must complete:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`add`指令稍微复杂一些。以下是解码后的`add(`srcReg`,` destReg`);`指令必须完成的典型操作（超出了常见操作集）：'
- en: Fetch the value of the source register and send it to the *arithmetic logical
    unit (ALU)*, which handles arithmetic on the CPU.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取源寄存器的值并将其发送到*算术逻辑单元（ALU）*，该单元负责处理CPU中的算术运算。
- en: Fetch the value of the destination register operand and send it to the ALU.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取目标寄存器操作数的值并将其发送到ALU。
- en: Instruct the ALU to add the values.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指示ALU将值相加。
- en: Store the result back into the destination register operand.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果存回目标寄存器操作数。
- en: Update the flags register with the result of the addition operation.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用加法操作的结果更新标志寄存器。
- en: '**NOTE**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*The* flags register, *also known as the* condition-codes register *or* program-status
    word*, is an array of Boolean variables in the CPU that tracks whether the previous
    instruction produced an overflow, a zero result, a negative result, or other such
    condition.*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*标志寄存器，*也称为*条件码寄存器*或*程序状态字*，是CPU中的一个布尔变量数组，用于跟踪前一条指令是否产生溢出、零结果、负结果或其他类似的条件。*'
- en: 'If the source operand is a memory location instead of a register, and the `add`
    instruction takes the form `add(`srcMem`,` destReg`);`, then the instruction sequence
    is slightly more complicated:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果源操作数是内存位置而非寄存器，且`add`指令的形式为`add(`srcMem`,` destReg`);`，则指令序列稍微复杂一些：
- en: Fetch the displacement associated with the memory operand from the memory location
    immediately following the opcode.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从紧跟在操作码后的内存位置获取与内存操作数相关的位移值。
- en: Update EIP to point at the first byte beyond the operand that follows the opcode.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，使其指向紧跟在操作数后的第一个字节。
- en: Compute the effective address of the source memory location, if the `add` instruction
    uses a complex addressing mode (for example, the indexed addressing mode).
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算源内存位置的有效地址，如果`add`指令使用复杂寻址模式（例如，索引寻址模式）。
- en: Fetch the source operand’s data from memory and send it to the ALU.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取源操作数的数据并将其发送到ALU。
- en: Fetch the value of the destination register operand and send it to the ALU.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取目标寄存器操作数的值并将其发送到ALU。
- en: Instruct the ALU to add the values.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指示ALU将值相加。
- en: Store the result back into the destination register operand.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果存回目标寄存器操作数。
- en: Update the flags register with the result of the addition operation.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用加法操作的结果更新标志寄存器。
- en: 'If the source operand is a constant and the destination operand is a register,
    the `add` instruction takes the form `add(`constant`,` destReg`);` and the CPU
    might deal with it as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果源操作数是常量且目标操作数是寄存器，则`add`指令的形式为`add(`constant`,` destReg`);`，CPU可能会按如下方式处理它：
- en: Fetch the constant operand that immediately follows the opcode in memory and
    send it to the ALU.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取紧跟在操作码后的常量操作数，并将其发送到ALU。
- en: Update EIP to point at the first byte beyond the constant that follows the opcode.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，使其指向紧跟在操作码后的常量的第一个字节。
- en: Fetch the value of the destination register operand and send it to the ALU.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取目标寄存器操作数的值并将其发送到ALU。
- en: Instruct the ALU to add the values.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指示ALU将值相加。
- en: Store the result back into the destination register operand.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果存回目标寄存器操作数。
- en: Update the flags register with the result of the addition operation.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用加法操作的结果更新标志寄存器。
- en: This instruction sequence requires nine cycles to complete.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令序列需要九个周期来完成。
- en: 'If the source operand is a constant, and the destination operand is a memory
    location, then the `add` instruction takes the form `add(`constant`,` destMem`);`
    and the sequence is slightly more complicated:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果源操作数是常数，并且目标操作数是内存位置，那么`add`指令的形式为`add(`constant`,` destMem`);`，此时序列稍显复杂：
- en: Fetch the displacement associated with the memory operand from memory immediately
    following the opcode.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从紧跟操作码之后的内存中获取与内存操作数相关的位移值。
- en: Update EIP to point at the first byte beyond the operand that follows the opcode.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，使其指向操作码后紧跟操作数的第一个字节。
- en: Compute the effective address of the destination memory location, if the `add`
    instruction uses a complex addressing mode (for example, the indexed addressing
    mode).
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果`add`指令使用复杂的寻址模式（例如，索引寻址模式），则计算目标内存位置的有效地址。
- en: Fetch the constant operand that immediately follows the memory operand’s displacement
    value and send it to the ALU.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取紧跟在内存操作数位移值后的常数操作数，并将其发送到ALU。
- en: Fetch the destination operand’s data from memory and send it to the ALU.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取目标操作数的数据并将其发送到ALU。
- en: Update EIP to point at the first byte beyond the constant that follows the memory
    operand.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，使其指向紧跟内存操作数后常数的第一个字节。
- en: Instruct the ALU to add the values.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指示ALU进行加法运算。
- en: Store the result back into the destination memory operand.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果存储回目标内存操作数中。
- en: Update the flags register with the result of the addition operation.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用加法运算结果更新标志寄存器。
- en: This instruction sequence requires 11 or 12 cycles to complete, depending on
    whether the effective address computation is necessary.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令序列需要11或12个周期来完成，具体取决于是否需要计算有效地址。
- en: '***9.3.3 The jnz Instruction***'
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.3.3 jnz指令***'
- en: 'Because the 80x86 `jnz` instruction does not allow different types of operands,
    it needs only one sequence of steps. The `jnz` `label;` instruction might use
    the following additional execution stages once decoded:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 由于80x86的`jnz`指令不允许不同类型的操作数，它只需要一个步骤序列。解码后的`jnz` `label;`指令可能使用以下附加的执行阶段：
- en: Fetch the displacement value (the jump distance) and send it to the ALU.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取位移值（跳转距离），并将其发送到ALU。
- en: Update the EIP register to hold the address of the instruction following the
    displacement operand.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP寄存器，以保存紧跟位移操作数后的指令地址。
- en: Test the zero flag to see if it is clear (that is, if it contains `0`).
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试零标志，看它是否被清除（即是否包含`0`）。
- en: If the zero flag was clear, copy the value in EIP to the ALU.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果零标志被清除，将EIP中的值复制到ALU。
- en: If the zero flag was clear, instruct the ALU to add the displacement and EIP
    values.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果零标志被清除，指示ALU将位移值与EIP值相加。
- en: If the zero flag was clear, copy the result of the addition back to the EIP.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果零标志被清除，将加法结果复制回EIP。
- en: Notice how the `jnz` instruction requires fewer steps, and thus runs in fewer
    clock cycles, if the jump is not taken. This is very typical for conditional jump
    instructions.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果跳转未被执行，`jnz`指令需要的步骤更少，因此运行时所需的时钟周期也更少。这对于条件跳转指令来说是非常典型的。
- en: '***9.3.4 The loop Instruction***'
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.3.4 循环指令***'
- en: Because the 80x86 `loop` instruction does not allow different types of operands,
    it needs only one sequence of steps. The decoded 80x86 `loop` instruction might
    use an execution sequence like the following:^([2](footnotes.xhtml#fn9_2a))
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于80x86的`loop`指令不允许不同类型的操作数，它只需要一个步骤序列。解码后的80x86 `loop`指令可能使用如下的执行序列：^([2](footnotes.xhtml#fn9_2a))
- en: Fetch the value of the ECX register and send it to the ALU.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取ECX寄存器的值并将其发送到ALU。
- en: Instruct the ALU to decrement this value.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指示ALU将此值递减。
- en: Send the result back to the ECX register. Set a special internal flag if this
    result is nonzero.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果发送回ECX寄存器。如果该结果非零，则设置一个特殊的内部标志。
- en: Fetch the displacement value (the jump distance) following the opcode in memory
    and send it to the ALU.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取紧跟在操作码后的位移值（跳转距离），并将其发送到ALU。
- en: Update the EIP register with the address of the instruction following the displacement
    operand.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用紧跟在位移操作数后的指令地址更新EIP寄存器。
- en: Test the special internal flag to see if ECX was nonzero.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试特殊的内部标志，查看ECX是否非零。
- en: If the flag was set (that is, it contains `1`), copy the value in EIP to the
    ALU.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果标志被设置（即它包含`1`），将EIP中的值复制到ALU。
- en: If the flag was set, instruct the ALU to add the displacement and EIP values.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果标志被设置，指示ALU将位移值与EIP值相加。
- en: If the flag was set, copy the result of the addition back to the EIP register.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果标志位被设置， 将加法的结果复制回EIP寄存器。
- en: As with the `jnz` instruction, note that the `loop` instruction executes more
    rapidly if the branch is not taken, and the CPU continues execution with the instruction
    that immediately follows the `loop` instruction.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 与`jnz`指令类似，请注意，`loop`指令在未跳转时执行得更快，CPU将继续执行紧接在`loop`指令之后的指令。
- en: '**9.4 RISC vs. CISC: Improving Performance by Executing More, Faster, Instructions**'
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**9.4 RISC与CISC：通过执行更多、更快的指令提高性能**'
- en: Early microprocessors (including the 80x86 and its predecessors) are examples
    of *complex instruction set computers (CISCs)*. At the time these CPUs were created,
    the thinking was that having each instruction do more work made programs run faster
    because they executed fewer instructions (as CPUs with less complex instructions
    had to execute more instructions to do the same amount of work). The Digital Equipment
    Corporation (DEC) PDP-11 and its successor, the VAX, epitomized this design philosophy.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的微处理器（包括80x86及其前身）是*复杂指令集计算机（CISC）*的典型例子。当时设计这些CPU时的思路是，让每条指令完成更多的工作可以让程序运行得更快，因为它们执行的指令较少（而具有较少复杂指令的CPU则需要执行更多指令才能完成相同的工作量）。数字设备公司（DEC）的PDP-11及其继任者VAX就是这种设计理念的代表。
- en: 'In the early 1980s, computer architecture researchers discovered that this
    complexity came at a huge cost. All the hardware necessary to support these complex
    instructions wound up constraining the overall clock speed of the CPU. Experiments
    with the VAX 11-780 minicomputer demonstrated that programs executing multiple,
    simple, instructions were faster than those executing fewer, more complex, instructions.
    Those researchers hypothesized that if they stripped the instruction set down
    to the bare essentials, using only simple instructions, they could boost the hardware’s
    performance (by increasing the clock speed). They called this new architecture
    *reduced instruction set computer (RISC)*.^([3](footnotes.xhtml#fn9_3a)) So began
    the great “RISC versus CISC” debate: which architecture was really better?'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在1980年代初期，计算机架构研究人员发现，这种复杂性带来了巨大的代价。所有支持这些复杂指令所需的硬件最终限制了CPU的整体时钟速度。对VAX 11-780小型计算机的实验表明，执行多个简单指令的程序比执行较少、更加复杂的指令的程序运行得更快。这些研究人员假设，如果将指令集精简到最基本的部分，只使用简单的指令，就能提升硬件性能（通过提高时钟速度）。他们将这种新架构称为*精简指令集计算机（RISC）*。^([3](footnotes.xhtml#fn9_3a))由此开始了伟大的“RISC与CISC”辩论：哪种架构更好？
- en: 'On paper, at least, RISC CPUs looked better. In practice, they ran at slower
    clock speeds, because existing CISC designs had a huge head start (as their designers
    had had many more years to optimize them). By the time RISC CPU designs had matured
    enough to run at higher clock speeds, the CISC designs had evolved, taking advantage
    of the RISC research. Today, the 80x86 CISC CPU is still the high-performance
    king. RISC CPUs found a different niche: they tend to be more power efficient
    than CISC processors, so they typically wind up in portable and low-power designs
    (such as cell phones and tablets).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 至少在纸面上，RISC CPU看起来更好。实际上，它们的时钟速度较慢，因为现有的CISC设计有一个巨大的先发优势（因为它们的设计者有更多的时间来优化它们）。当RISC
    CPU设计成熟到足以实现更高时钟速度时，CISC设计已经进化，利用了RISC研究的成果。今天，80x86 CISC CPU仍然是高性能的王者。RISC CPU则找到了不同的市场：它们通常比CISC处理器更节能，因此通常出现在便携和低功耗设计中（例如手机和平板电脑）。
- en: Though the 80x86 (a CISC CPU) remains the performance leader, it’s still possible
    to write programs with a larger number of simple 80x86 instructions that run faster
    than those with fewer, more complex 80x86 instructions. 80x86 designers have kept
    these legacy instructions around to allow you to execute older software that still
    contains them. Newer compilers, however, avoid these legacy instructions to produce
    faster-running code.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管80x86（CISC CPU）仍然是性能的领导者，但仍然可以编写包含更多简单的80x86指令的程序，这些程序比那些包含较少、更复杂80x86指令的程序运行得更快。80x86设计者保留了这些遗留指令，以便你能够执行仍包含这些指令的旧软件。然而，新的编译器避免使用这些遗留指令，从而生成运行速度更快的代码。
- en: Nevertheless, one important takeaway from RISC research is that the execution
    time of each instruction is largely dependent upon the amount of work it does.
    The more internal operations an instruction requires, the longer it will take
    to execute. In addition to improving execution time by reducing the number of
    internal operations, RISC also prioritized internal operations that could execute
    concurrently—that is, *in parallel*.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，从RISC研究中得出一个重要的结论是，每条指令的执行时间在很大程度上取决于它所做的工作量。一条指令所需的内部操作越多，执行时间就越长。除了通过减少内部操作的数量来提高执行时间，RISC还优先考虑能够并行执行的内部操作——即*并行*。
- en: '**9.5 Parallelism: The Key to Faster Processing**'
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**9.5 并行性：加速处理的关键**'
- en: If we can reduce the amount of time it takes for a CPU to execute the individual
    instructions in its instruction set, an application containing a sequence of those
    instructions will also run faster than it otherwise would.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能够减少CPU执行其指令集中的每条指令所需的时间，那么包含这些指令序列的应用程序也将比平时运行得更快。
- en: An early goal of the RISC processors was to execute one instruction per clock
    cycle, on average. However, even if a RISC instruction is simplified, its actual
    execution still requires multiple steps. So how could the processors achieve this
    goal? The answer is parallelism.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: RISC处理器的早期目标是平均每个时钟周期执行一条指令。然而，即使RISC指令被简化，它的实际执行仍然需要多个步骤。那么，处理器如何实现这一目标呢？答案是并行性。
- en: 'Consider the following steps for a `mov(`srcReg`,` destReg`);` instruction:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下`mov(srcReg, destReg)`指令的步骤：
- en: Fetch the instruction’s opcode from memory.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取指令的操作码。
- en: Update the EIP register with the address of the byte following the opcode.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用操作码后一个字节的地址更新EIP寄存器。
- en: Decode the instruction’s opcode to see what instruction it specifies.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码指令的操作码，以查看它指定了什么指令。
- en: Fetch the data from srcReg.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`srcReg`中获取数据。
- en: Store the fetched value into the destination register (destReg).
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将获取的值存入目标寄存器（destReg）。
- en: The CPU must fetch the instruction’s opcode from memory before it updates the
    EIP register instruction with the address of the byte beyond the opcode, decode
    the opcode before it knows to fetch the value of the source register, and fetch
    the value of the source register before it can store the fetched value in the
    destination register.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: CPU必须在更新EIP寄存器并获取操作码后一个字节的地址之前从内存中获取指令的操作码，必须在知道要获取源寄存器的值之前解码操作码，必须在能够将获取的值存入目标寄存器之前获取源寄存器的值。
- en: 'All but one of the stages in the execution of this `mov` instruction are *serial*.
    That is, the CPU must execute one stage before proceeding to the next. The exception
    is step 2, updating the EIP register. Although this stage must follow the first
    stage, none of the following stages depend upon it. We could execute this step
    concurrently with any of the others, and it wouldn’t affect the operation of the
    `mov` instruction. By doing two of the stages in parallel, then, we can reduce
    this instruction’s execution time by one clock cycle. The following sequence illustrates
    one possible concurrent execution:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 执行这个`mov`指令的所有阶段都*是串行的*。也就是说，CPU必须在执行下一阶段之前完成当前阶段。唯一的例外是第2步，更新EIP寄存器。虽然这一阶段必须在第一阶段之后执行，但之后的所有阶段都不依赖于它。我们可以与其他任何阶段并行执行这一步，它也不会影响`mov`指令的操作。通过并行执行两个阶段，我们可以将该指令的执行时间减少一个时钟周期。以下序列展示了一个可能的并行执行方式：
- en: Fetch the instruction’s opcode from memory.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取指令的操作码。
- en: Decode the instruction’s opcode to see what instruction it specifies.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码指令的操作码，以查看它指定了什么指令。
- en: Fetch the data from srcReg *and* update the EIP register with the address of
    the byte following the opcode.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`srcReg`中获取数据，并用操作码后一个字节的地址更新EIP寄存器。
- en: Store the fetched value into the destination register (destReg).
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将获取的值存入目标寄存器（destReg）。
- en: 'Although the remaining stages in the `mov(`srcReg`,` destReg`);` instruction
    must be serialized, other forms of the `mov` instruction offer similar opportunities
    to save cycles by executing stages concurrently. For example, consider the 80x86
    `mov([ebx+disp],` `eax);` instruction:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管`mov(srcReg, destReg)`指令中的其余阶段必须串行执行，但`mov`指令的其他形式也提供了通过并行执行阶段来节省周期的类似机会。例如，考虑80x86的`mov([ebx+disp],
    eax)`指令：
- en: Fetch the instruction’s opcode from memory.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取指令的操作码。
- en: Update the EIP register with the address of the byte following the opcode.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用操作码后一个字节的地址更新EIP寄存器。
- en: Decode the instruction’s opcode to see what instruction it specifies.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码指令的操作码，以确定其指定的指令。
- en: Fetch the displacement value for use in calculating the effective address of
    the source operand.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取位移值，用于计算源操作数的有效地址。
- en: Update EIP to point at the first byte after the displacement value in memory.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，指向内存中位移值后的第一个字节。
- en: Compute the effective address of the source operand.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算源操作数的有效地址。
- en: Fetch the value of the source operand’s data from memory.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取源操作数的数据值。
- en: Store the result into the destination register operand.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果存储到目标寄存器操作数中。
- en: 'Once again, we can overlap the execution of several stages in this instruction.
    In the following example, we reduce the number of steps from eight to six by overlapping
    both updates of EIP with two other operations:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们可以重叠执行此指令的多个阶段。在以下示例中，我们通过将EIP的两次更新与其他两项操作重叠，将步骤数从八个减少到六个：
- en: Fetch the instruction’s opcode from memory.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取指令的操作码。
- en: Decode the instruction’s opcode to see what instruction it specifies, *and*
    update the EIP register with the address of the byte following the opcode.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码指令的操作码，以确定其指定的指令，*并*更新EIP寄存器，指向操作码后面的字节地址。
- en: Fetch the displacement value for use in calculating the effective address of
    the source operand.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取位移值，用于计算源操作数的有效地址。
- en: Compute the effective address of the source operand, *and* update EIP to point
    at the first byte after the displacement value in memory.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算源操作数的有效地址，*并*更新EIP，指向内存中位移值后的第一个字节。
- en: Fetch the value of the source operand’s data from memory.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取源操作数的数据值。
- en: Store the result into the destination register operand.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果存储到目标寄存器操作数中。
- en: 'As a last example, consider the `add(`constant`,` `[ebx+`disp`]);` instruction.
    Its serial execution looks like this:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一个示例，考虑 `add(`constant`,` `[ebx+`disp`]);` 指令。其串行执行如下：
- en: Fetch the instruction’s opcode from memory.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取指令的操作码。
- en: Update the EIP register with the address of the byte following the opcode.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用操作码后面的字节地址更新EIP寄存器。
- en: Decode the instruction’s opcode to see what instruction it specifies.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码指令的操作码，以确定其指定的指令。
- en: Fetch the displacement value from the memory location immediately following
    the opcode.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从紧跟在操作码后面的内存位置获取位移值。
- en: Update EIP to point at the first byte beyond the displacement operand that follows
    the opcode.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，指向操作码后面的第一个字节，超越位移操作数。
- en: Compute the effective address of the second operand.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算第二个操作数的有效地址。
- en: Fetch the constant operand that immediately follows the displacement value in
    memory and send it to the ALU.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取紧跟在位移值后面的常量操作数，并将其发送到ALU。
- en: Fetch the destination operand’s data from memory and send it to the ALU.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取目标操作数的数据，并将其发送到算术逻辑单元（ALU）。
- en: Update EIP to point at the first byte beyond the constant that follows the displacement
    operand.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，指向位移操作数后面常量的第一个字节。
- en: Instruct the ALU to add the values.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指示ALU执行加法操作。
- en: Store the result back into the destination (second) operand.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果存储回目标（第二）操作数中。
- en: Update the flags register with the result of the addition operation.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用加法操作的结果更新标志寄存器。
- en: 'We can overlap several stages in this instruction because they don’t depend
    on the result of their immediate predecessor:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重叠执行此指令的多个阶段，因为它们不依赖于其直接前驱的结果：
- en: Fetch the instruction’s opcode from memory.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取指令的操作码。
- en: Decode the instruction’s opcode to see what instruction it specifies *and* update
    the EIP register with the address of the byte following the opcode.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码指令的操作码，以确定其指定的指令，*并*更新EIP寄存器，指向操作码后面的字节地址。
- en: Fetch the displacement value from the memory location immediately following
    the opcode.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从紧跟在操作码后面的内存位置获取位移值。
- en: Update EIP to point at the first byte beyond the displacement operand that follows
    the opcode *and* compute the effective address of the memory operand (`ebx+`disp).
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新EIP，指向操作码后面超越位移操作数的第一个字节，*并*计算内存操作数（`ebx+`disp）的有效地址。
- en: Fetch the constant operand that immediately follows the displacement value and
    send it to the ALU.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取紧跟在位移值后面的常量操作数，并将其发送到ALU。
- en: Fetch the destination operand’s data from memory and send it to the ALU.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取目标操作数的数据，并将其发送到ALU。
- en: Instruct the ALU to add the values *and* update EIP to point at the first byte
    beyond the constant value.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指示 ALU 执行加法操作，并更新 EIP 以指向常量值之后的第一个字节。
- en: Store the result back into the second operand *and* update the flags register
    with the result of the addition operation.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果存储回第二个操作数 *并* 使用加法操作的结果更新标志寄存器。
- en: Although it might seem like the CPU could fetch the constant and the memory
    operand in the same stage because their values do not depend upon each other,
    it can’t do this (yet!) because it has only a single data bus, and both values
    are coming from memory. In the next section you’ll see how we can overcome this
    problem.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管看起来 CPU 可以在同一阶段获取常量和内存操作数，因为它们的值互不依赖，但它不能这样做（至少目前不能！），因为它只有一个数据总线，而这两个值都来自内存。在接下来的章节中，你将看到我们如何克服这个问题。
- en: By overlapping various execution stages, we’ve substantially reduced the number
    of steps, and consequently the number of clock cycles, that these instructions
    need to complete execution. This is a major key to improving CPU performance without
    cranking up the chip’s clock speed. However, there’s only so much to be gained
    from this approach alone, because instruction execution is still serialized. Starting
    with the next section, we’ll see how to overlap the execution of adjacent instructions
    in order to save additional cycles.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 通过重叠执行的各个阶段，我们大大减少了这些指令完成执行所需的步骤数，从而减少了时钟周期数。这是提升 CPU 性能的关键之一，而无需提高芯片的时钟频率。然而，单凭这一方法的收获是有限的，因为指令执行仍然是串行的。从下一个章节开始，我们将看到如何重叠相邻指令的执行，以节省额外的周期。
- en: '***9.5.1 Functional Units***'
  id: totrans-182
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.1 功能单元***'
- en: As you’ve seen in the `add` instruction, the steps for adding two values and
    then storing their sum can’t be done concurrently, because you can’t store the
    sum until after you’ve computed it. Furthermore, there are some resources that
    the CPU can’t share between steps in an instruction. There is only one data bus,
    and the CPU can’t fetch an instruction’s opcode while it is trying to store data
    to memory. In addition, many of the steps that make up the execution of an instruction
    share functional units in the CPU.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在 `add` 指令中所见，两个值相加并存储其和的步骤不能并行进行，因为你必须先计算出和，才能进行存储操作。此外，CPU 无法在指令执行过程中共享某些资源。只有一个数据总线，CPU
    在试图将数据存储到内存时不能获取指令的操作码。此外，许多构成指令执行的步骤共享 CPU 中的功能单元。
- en: '*Functional units* are groups of logic that perform a common operation, such
    as the arithmetic logical unit and the control unit. A functional unit can do
    only one operation at a time; you can’t do two operations concurrently that use
    the same functional unit. To design a CPU that executes several stages in parallel,
    we must arrange those stages to reduce potential conflicts, or add extra logic
    so that two (or more) operations can occur simultaneously by executing in different
    functional units.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '*功能单元* 是执行公共操作的逻辑单元，例如算术逻辑单元和控制单元。一个功能单元一次只能执行一个操作；你不能同时执行两个使用相同功能单元的操作。为了设计一个可以并行执行多个阶段的
    CPU，我们必须合理安排这些阶段，以减少潜在的冲突，或者增加额外的逻辑，以便通过在不同功能单元中执行，能够同时进行两个（或更多）操作。'
- en: 'Consider again the steps that a `mov(`srcMem`,` destReg`);` instruction might
    require:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 再次考虑 `mov(srcMem, destReg);` 指令可能需要的步骤：
- en: Fetch the instruction’s opcode from memory.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取指令的操作码。
- en: Update the EIP register to hold the address of the displacement value following
    the opcode.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新 EIP 寄存器以保存紧跟操作码之后的位移值地址。
- en: Decode the instruction’s opcode to see what instruction it specifies.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码指令的操作码，查看它指定了什么指令。
- en: Fetch the displacement value from memory to compute the source operand’s effective
    address.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取位移值，以计算源操作数的有效地址。
- en: Update the EIP register to hold the address of the byte beyond the displacement
    value.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新 EIP 寄存器以保存超出位移值的字节地址。
- en: Compute the effective address of the source operand.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算源操作数的有效地址。
- en: Fetch the value of the source operand.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取源操作数的值。
- en: Store the fetched value into the destination register.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将获取的值存储到目标寄存器中。
- en: The first operation uses the value of the EIP register, so we can’t overlap
    it with the subsequent step, which adjusts the value in EIP. In addition, the
    first operation uses the bus to fetch the instruction opcode from memory, and
    because every step that follows this one depends upon this opcode, it’s unlikely
    that we’ll be able to overlap it with any other.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个操作使用EIP寄存器的值，因此我们不能将其与后续步骤重叠，后续步骤会调整EIP中的值。此外，第一个操作使用总线从内存中获取指令操作码，并且由于后续的每个步骤都依赖于该操作码，因此不太可能将其与其他步骤重叠。
- en: The second and third operations don’t share any functional units, and the third
    operation doesn’t depend upon the value of the EIP register, which is modified
    in the second step. Therefore, we can modify the control unit so that it combines
    these steps, adjusting the EIP register at the same time that it decodes the instruction.
    This will shave one cycle off the execution of the `mov` instruction.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步和第三步没有共享任何功能单元，并且第三步不依赖于EIP寄存器的值，而该寄存器在第二步中被修改。因此，我们可以修改控制单元，使其在解码指令的同时调整EIP寄存器。这样可以减少`mov`指令执行所需的一个周期。
- en: The third and fourth steps, which decode the instruction’s opcode and fetch
    the displacement value, don’t look like they can be done in parallel, because
    you must decode the instruction’s opcode to determine whether the CPU needs to
    fetch a displacement operand from memory. However, we can design the CPU to fetch
    the displacement anyway so that it’s available if we need it.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 第三步和第四步，即解码指令操作码和获取位移值，看起来无法并行执行，因为必须解码操作码以确定CPU是否需要从内存中获取位移操作数。然而，我们可以设计CPU使其仍然预取位移值，以便在需要时可以使用。
- en: Of course, there’s no way to overlap the execution of steps 7 and 8 because
    the CPU must fetch the value before storing it away.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，步骤7和步骤8的执行无法重叠，因为CPU必须在存储之前先获取该值。
- en: 'By combining all the steps that are possible, we might obtain the following
    sequence for a `mov` instruction:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将所有可能的步骤组合在一起，我们可能得到以下`mov`指令的执行顺序：
- en: Fetch the instruction’s opcode from memory.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取指令的操作码。
- en: Decode the instruction’s opcode to see what instruction it specifies, *and*
    update the EIP register to hold the address of the displacement value following
    the opcode.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码指令的操作码以查看它指定的指令，*并*更新EIP寄存器以保存操作码后跟的位移值的地址。
- en: Fetch the displacement value from memory to compute the source operand’s effective
    address, *and* update the EIP register to hold the address of the byte beyond
    the displacement value.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取位移值，以计算源操作数的有效地址，*并*更新EIP寄存器以保存位移值后的字节地址。
- en: Compute the effective address of the source operand.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算源操作数的有效地址。
- en: Fetch the value of the source operand from memory.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取源操作数的值。
- en: Store the fetched value into the destination register.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将获取的值存入目标寄存器。
- en: By adding a small amount of logic to the CPU, we’ve shaved one or two cycles
    off the execution of the `mov` instruction. This simple optimization works with
    most of the other instructions as well.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向CPU添加少量逻辑，我们已经减少了`mov`指令执行所需的一两个周期。这种简单的优化同样适用于大多数其他指令。
- en: Now consider the `loop` instruction, which has several steps that use the ALU.
    If the CPU has only a single ALU, it must execute these steps sequentially. However,
    if the CPU has multiple ALUs (that is, multiple functional units), it can execute
    some of these steps in parallel. For example, the CPU could decrement the value
    in the ECX register (using the ALU) at the same time it updates the EIP value.
    Note that the `loop` instruction also uses the ALU to compare the decremented
    ECX value against `0` (to determine if it should branch). However, there’s a data
    dependency between incrementing ECX and comparing it with `0`; therefore, the
    CPU can’t perform both of these operations at the same time.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑`loop`指令，它有几个使用ALU的步骤。如果CPU只有一个ALU，它必须按顺序执行这些步骤。然而，如果CPU有多个ALU（即多个功能单元），它可以并行执行其中的一些步骤。例如，CPU可以在更新EIP值的同时减少ECX寄存器中的值（使用ALU）。请注意，`loop`指令还使用ALU将减少后的ECX值与`0`进行比较（以决定是否跳转）。然而，递减ECX和将其与`0`比较之间存在数据依赖关系，因此CPU无法同时执行这两项操作。
- en: '***9.5.2 The Prefetch Queue***'
  id: totrans-207
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.2 预取队列***'
- en: Now that we’ve looked at some simple optimization techniques, consider what
    happens when the `mov` instruction executes on a CPU with a 32-bit data bus. If
    the `mov` instruction fetches an 8-bit displacement value from memory, the CPU
    may wind up fetching an additional 3 bytes along with the displacement value (the
    32-bit data bus lets us fetch 4 bytes in a single bus cycle). The second byte
    on the data bus is actually the opcode of the next instruction. If we could save
    this opcode until the execution of the next instruction, we could shave a cycle
    off its execution time because it wouldn’t have to fetch the same opcode byte
    again.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看过一些简单的优化技术，考虑当`mov`指令在具有32位数据总线的CPU上执行时会发生什么。如果`mov`指令从内存中获取一个8位位移值，CPU可能会连同位移值一起获取额外的3个字节（32位数据总线使我们可以在一个总线周期中获取4个字节）。数据总线上的第二个字节实际上是下一条指令的操作码。如果我们能够将这个操作码保留到下一条指令执行时再使用，那么我们就能节省一个周期的执行时间，因为它就不需要再次获取相同的操作码字节了。
- en: '**9.5.2.1 Using Unused Bus Cycles**'
  id: totrans-209
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**9.5.2.1 使用未使用的总线周期**'
- en: There are still more improvements we can make. While the `mov` instruction is
    executing, the CPU isn’t accessing memory on every clock cycle. For example, while
    data is being stored into the destination register, the bus is idle. When the
    bus is idle, we can prefetch and save the instruction opcode and operands of the
    next instruction.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然可以做更多的改进。当`mov`指令执行时，CPU并不是在每个时钟周期都访问内存。例如，当数据被存储到目标寄存器时，数据总线是空闲的。数据总线空闲时，我们可以预取并保存下一条指令的操作码和操作数。
- en: The hardware that does this is the *[prefetch queue](gloss01.xhtml#gloss01_203)*.
    [Figure 9-4](ch09.xhtml#ch09fig04) shows the internal organization of a CPU with
    a prefetch queue.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此操作的硬件是*【预取队列】(gloss01.xhtml#gloss01_203)*。[图9-4](ch09.xhtml#ch09fig04)展示了带有预取队列的CPU内部结构。
- en: '![image](../images/09fig04.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/09fig04.jpg)'
- en: '*Figure 9-4: CPU design with a prefetch queue*'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9-4：带有预取队列的CPU设计*'
- en: The *bus interface unit (BIU)*, as its name implies, controls access to the
    address and data buses. The BIU acts as a “traffic cop” and handles simultaneous
    requests for bus access by different modules, such as the execution unit and the
    prefetch queue. Whenever some component inside the CPU wishes to access main memory,
    it sends this request to the BIU.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '*总线接口单元（BIU）*，顾名思义，控制着地址总线和数据总线的访问。BIU充当“交通警察”，处理不同模块（如执行单元和预取队列）对总线访问的同时请求。每当CPU内部的某个组件希望访问主存时，它会向BIU发送这个请求。'
- en: Whenever the execution unit is not using the BIU, the BIU can fetch additional
    bytes from the memory that holds the machine instructions and store them in the
    prefetch queue. Then, whenever the CPU needs an instruction opcode or operand
    value, it grabs *the next available byte* from the prefetch queue. Because the
    BIU grabs multiple bytes at a time from memory, and because, per clock cycle,
    the CPU generally consumes fewer bytes from the prefetch queue than are available,
    instructions will normally be sitting in the prefetch queue for the CPU’s use.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 每当执行单元不使用总线接口单元（BIU）时，BIU可以从存储机器指令的内存中获取更多字节，并将它们存储在预取队列中。然后，每当CPU需要指令操作码或操作数值时，它从预取队列中获取*下一个可用字节*。因为BIU一次从内存中获取多个字节，并且每个时钟周期内，CPU通常从预取队列中消耗的字节数少于可用字节数，所以指令通常会在预取队列中待命，供CPU使用。
- en: However, there’s no guarantee that all instructions and operands will be sitting
    in the prefetch queue when we need them. For example, consider the 80x86 `jnz
    Label;` instruction. If the 2-byte form of the instruction appears at locations
    400 and 401 in memory, the prefetch queue may contain the bytes at addresses 402,
    403, 404, 405, 406, 407, and so on. If `jnz` transfers control to `Label` at target
    address 480, the bytes at addresses 402, 403, 404, and so on, won’t be of any
    use to the CPU. The system will have to pause for a moment to fetch the data at
    address 480 before it can go on. Most of the time, the CPU fetches sequential
    values from memory, though, so having the data in the prefetch queue saves time.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并不能保证所有指令和操作数在需要时都能位于预取队列中。例如，考虑80x86的`jnz Label;`指令。如果该指令的2字节形式出现在内存的地址400和401处，预取队列可能包含地址402、403、404、405、406、407等位置的字节。如果`jnz`将控制转移到目标地址480处的`Label`，那么地址402、403、404等处的字节对CPU就没有用了。系统将不得不暂停片刻，以便从地址480处获取数据，才能继续执行。尽管如此，大多数时候，CPU从内存中获取的是顺序值，因此将数据保存在预取队列中可以节省时间。
- en: '**9.5.2.2 Overlapping Instructions**'
  id: totrans-217
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**9.5.2.2 指令重叠**'
- en: Another improvement we can make is to overlap the processes of decoding the
    next instruction’s opcode and executing the last step of the previous instruction.
    After the CPU processes the operand, the next available byte in the prefetch queue
    is an opcode, which the CPU can decode because the instruction decoder is idle
    while the CPU executes the steps of the current instruction. Of course, if the
    current instruction modifies the EIP register, the time the CPU spends on the
    decoding operation goes to waste; however, because it occurs in parallel with
    other operations of the current instruction, this decoding doesn’t slow down the
    system (though it does require extra circuitry).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个改进是将解码下一个指令的操作码与执行前一个指令的最后一步操作重叠。在CPU处理操作数后，预取队列中下一个可用的字节是操作码，CPU可以解码它，因为指令解码器在CPU执行当前指令的步骤时处于空闲状态。当然，如果当前指令修改了EIP寄存器，那么CPU在解码操作上花费的时间就会浪费；然而，由于这与当前指令的其他操作并行进行，因此这种解码不会拖慢系统速度（尽管需要额外的电路）。
- en: '**9.5.2.3 Summarizing Background Prefetch Events**'
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**9.5.2.3 总结背景预取事件**'
- en: 'Our instruction execution sequence now assumes that the following CPU prefetch
    events are occurring (concurrently) in the background:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的指令执行顺序假设以下CPU预取事件正在后台（并行）发生：
- en: If the prefetch queue is not full (generally it can hold between 8 and 32 bytes,
    depending on the processor) and the BIU is idle on the current clock cycle, fetch
    the next double word located at the address found in the EIP register at the beginning
    of the clock cycle.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果预取队列未满（通常它可以容纳8到32字节，具体取决于处理器），并且BIU在当前时钟周期内处于空闲状态，则从EIP寄存器中找到的地址开始，获取下一个双字。
- en: If the instruction decoder is idle and the current instruction does not require
    an instruction operand, the CPU should begin decoding the opcode at the front
    of the prefetch queue. If the current instruction requires an instruction operand,
    then the CPU begins decoding the byte just beyond that operand in the prefetch
    queue.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果指令解码器处于空闲状态，并且当前指令不需要操作数，CPU应开始解码预取队列前端的操作码。如果当前指令需要操作数，那么CPU会开始解码预取队列中位于该操作数之后的字节。
- en: 'Now let’s reconsider our `mov(`srcreg`,` destreg`);` instruction. Because we’ve
    added the prefetch queue and the BIU, we can overlap the fetch and decode stages
    of this instruction with specific stages of the previous instruction to get the
    following steps:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们重新考虑我们的`mov(`srcreg`,` destreg`);`指令。因为我们已经添加了预取队列和BIU，我们可以将此指令的获取和解码阶段与前一个指令的特定阶段重叠，以得到以下步骤：
- en: Fetch and decode the instruction; this is overlapped with the previous instruction.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取并解码指令；这与前一个指令重叠。
- en: Fetch the source register and update the EIP register with the address of the
    next instruction.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取源寄存器，并使用下一个指令的地址更新EIP寄存器。
- en: Store the fetched value into the destination register.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将获取的值存储到目标寄存器中。
- en: The instruction execution timings in this example assume that the opcode is
    present in the prefetch queue and that the CPU has already decoded it. If either
    is not true, additional cycles will be necessary to fetch the opcode from memory
    and decode the instruction.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 本示例中的指令执行时序假设操作码已存在于预取队列中，并且CPU已对其进行解码。如果两者之一不成立，则需要额外的周期来从内存中获取操作码并解码指令。
- en: '***9.5.3 Conditions That Hinder the Performance of the Prefetch Queue***'
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.3 阻碍预取队列性能的条件***'
- en: When they transfer control to the target location, jump and conditional jump
    instructions are slower than other instructions, because the CPU can’t overlap
    the processes of fetching and decoding the opcode for the next instruction with
    the process of executing a jump instruction that transfers control. It may take
    several cycles after the execution of a jump instruction for the prefetch queue
    to reload.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 跳转和条件跳转指令在转移控制到目标位置时比其他指令慢，因为CPU不能将获取和解码下一个指令的操作与执行跳转指令的过程重叠，这会导致控制转移。在执行跳转指令之后，预取队列可能需要几个周期才能重新加载。
- en: '**NOTE**'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*If you want to write fast code, avoid jumping around in your program as much
    as possible.*'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你想写出快速的代码，尽量避免在程序中跳来跳去。*'
- en: Conditional jump instructions invalidate the prefetch queue only if they actually
    transfer control to the target location. If the jump condition is `false`, execution
    continues with the next instruction and the values in the prefetch queue remain
    valid. Therefore, while writing the program, if you can determine which jump condition
    occurs most frequently, you should arrange your program so that the most common
    condition causes the program to continue with the next instruction rather than
    jump to a separate location.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 条件跳转指令只有在实际跳转到目标位置时才会使预取队列失效。如果跳转条件为`false`，执行将继续进行下一条指令，且预取队列中的值保持有效。因此，在编写程序时，如果你能确定哪个跳转条件最常发生，应安排程序使最常见的条件导致程序继续执行下一条指令，而不是跳转到其他位置。
- en: In addition, instruction size (in bytes) can affect the performance of the prefetch
    queue. The larger the instruction, the faster the CPU will empty the prefetch
    queue. Instructions involving constants and memory operands tend to be the largest.
    If you execute a sequence of these instructions in a row, the CPU may end up having
    to wait because it is removing instructions from the prefetch queue faster than
    the BIU is copying data to the prefetch queue. So, whenever possible, try to use
    shorter instructions.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，指令大小（以字节为单位）会影响预取队列的性能。指令越大，CPU清空预取队列的速度就越快。涉及常数和内存操作数的指令通常是最大的。如果你连续执行一系列这样的指令，CPU可能会因为它从预取队列中移除指令的速度快于BIU将数据复制到预取队列的速度而不得不等待。因此，尽可能使用较短的指令。
- en: Finally, prefetch queues work best when you have a wide data bus. The 16-bit
    8086 processor runs much faster than the 8-bit 8088 because it can keep the prefetch
    queue full with fewer bus accesses. Don’t forget, the CPU needs to use the bus
    for other purposes. Instructions that access memory compete with the prefetch
    queue for access to the bus. If you have a sequence of instructions that all access
    memory, the prefetch queue may quickly empty, and once that happens, the CPU must
    wait for the BIU to fetch new opcodes from memory before it can continue executing
    instructions.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，预取队列在数据总线较宽时表现最佳。16位的8086处理器比8位的8088运行得更快，因为它可以用更少的总线访问来保持预取队列的满状态。别忘了，CPU需要使用总线进行其他操作。访问内存的指令与预取队列争夺对总线的访问。如果你有一系列访问内存的指令，预取队列可能会很快被清空，一旦发生这种情况，CPU必须等待BIU从内存中获取新的操作码，才能继续执行指令。
- en: '***9.5.4 Pipelining: Overlapping the Execution of Multiple Instructions***'
  id: totrans-235
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.4 流水线：重叠执行多条指令***'
- en: Executing instructions in parallel using a BIU and an execution unit is a special
    case of pipelining. Most modern processors incorporate pipelining to improve performance.
    With just a few exceptions, pipelining allows us to execute one instruction per
    clock cycle.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 使用BIU和执行单元并行执行指令是流水线的一个特例。大多数现代处理器都采用流水线技术来提高性能。除少数例外，流水线使我们能够每个时钟周期执行一条指令。
- en: The advantage of the prefetch queue is that it lets the CPU overlap the processes
    of fetching and decoding the instruction opcode with the execution of other instructions.
    Assuming you’re willing to add hardware, you can execute almost all operations
    in parallel. That is the idea behind pipelining.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 预取队列的优势在于它允许CPU将获取和解码指令操作码的过程与其他指令的执行过程重叠。假设你愿意添加硬件，你几乎可以并行执行所有操作。这就是流水线的基本思想。
- en: Pipelined operation improves an application’s average performance by executing
    several instructions concurrently. However, as you saw with the prefetch queue,
    certain instructions (and combinations thereof) fare better than others in a pipelined
    system. By understanding how pipelined operation works, you can organize your
    applications to run faster.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线操作通过并行执行多条指令来提高应用程序的平均性能。然而，正如你在预取队列中看到的那样，某些指令（及其组合）在流水线系统中表现得比其他指令更好。通过理解流水线操作的工作原理，你可以组织你的应用程序，使其运行得更快。
- en: '**9.5.4.1 A Typical Pipeline**'
  id: totrans-239
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**9.5.4.1 一个典型的流水线**'
- en: 'Consider the steps necessary to do a generic operation, with each step taking
    one clock cycle:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑执行一个通用操作所需的步骤，每个步骤都需要一个时钟周期：
- en: Fetch the instruction’s opcode from memory.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从内存中获取指令的操作码。
- en: Decode the opcode *and*, if required, prefetch a displacement operand, a constant
    operand, or both.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码操作码*并*（如果需要）预取位移操作数、常数操作数或两者。
- en: If required, compute the effective address for a memory operand (for example,
    `[ebx+`disp`]`).
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果需要，计算内存操作数的有效地址（例如，`[ebx+disp]`）。
- en: If required, fetch the value of any memory operand and/or register.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如有需要，获取任何内存操作数和/或寄存器的值。
- en: Compute the result.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算结果。
- en: Store the result into the destination register.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果存储到目标寄存器中。
- en: Assuming you’re willing to pay for some extra silicon, you can build a little
    *miniprocessor* to handle each step. The organization would look something like
    [Figure 9-5](ch09.xhtml#ch09fig05).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你愿意为一些额外的硅片付费，你可以为每个步骤构建一个小型*微处理器*来处理。其组织结构类似于[图 9-5](ch09.xhtml#ch09fig05)所示。
- en: '![image](../images/09fig05.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/09fig05.jpg)'
- en: '*Figure 9-5: A pipelined implementation of instruction execution*'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-5：指令执行的流水线实现*'
- en: In stage 4, the CPU fetches both the source and destination operands. You can
    set this up by putting multiple data paths inside the CPU (such as from the registers
    to the ALU) and ensuring that no two operands ever compete for simultaneous use
    of the data bus (that is, there are no memory-to-memory operations).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在第4阶段，CPU获取源操作数和目的操作数。你可以通过在CPU内部放置多个数据路径（例如从寄存器到算术逻辑单元ALU）并确保没有两个操作数会同时竞争数据总线的使用来设置这一点（也就是说，没有内存到内存的操作）。
- en: If you design a separate piece of hardware for each stage in the pipeline in
    [Figure 9-5](ch09.xhtml#ch09fig05), almost all of them can take place in parallel.
    Of course, you can’t fetch and decode the opcode for more than one instruction
    at the same time, but you can fetch the opcode of the next instruction while decoding
    the current instruction’s opcode. If you have an *n*-stage pipeline, you will
    usually have *n* instructions executing concurrently. [Figure 9-6](ch09.xhtml#ch09fig06)
    shows pipelining in operation. T1, T2, T3, and so on, represent consecutive “ticks”
    (time = 1, time = 2, and so on) of the system clock.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你为流水线中的每个阶段设计一个单独的硬件组件，如[图 9-5](ch09.xhtml#ch09fig05)所示，它们几乎都可以并行执行。当然，你不能同时获取和解码多个指令的操作码，但你可以在解码当前指令的操作码时，提前获取下一条指令的操作码。如果你有一个*n*阶段的流水线，通常会有*n*条指令并发执行。[图
    9-6](ch09.xhtml#ch09fig06)展示了流水线操作的情况。T1、T2、T3等代表系统时钟的连续“滴答”（时间 = 1，时间 = 2，依此类推）。
- en: '![image](../images/09fig06.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/09fig06.jpg)'
- en: '*Figure 9-6: Instruction execution in a pipeline*'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-6：流水线中的指令执行*'
- en: At time T = T1, the CPU fetches the opcode byte for the first instruction. At
    T = T2, the CPU begins decoding the opcode for the first instruction, and, in
    parallel, it fetches a block of bytes from the prefetch queue in the event that
    the first instruction has an operand. Also in parallel with the decoding of the
    first instruction, the CPU instructs the BIU to fetch the opcode of the second
    instruction because the first instruction no longer needs that circuitry.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间T = T1时，CPU获取第一条指令的操作码字节。在T = T2时，CPU开始解码第一条指令的操作码，并且并行地从预取队列中获取一块字节，假设第一条指令有一个操作数。同时，CPU还指示BIU获取第二条指令的操作码，因为第一条指令不再需要那个电路。
- en: Note that there is a minor conflict here. The CPU is attempting to fetch the
    next byte from the prefetch queue for use as an operand; at the same time, it
    is fetching operand data from the prefetch queue for use as an opcode. How can
    it do both at once? You’ll see the solution shortly.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这里存在一个小冲突。CPU正试图从预取队列中获取下一个字节作为操作数；同时，它也在从预取队列中获取操作数数据作为操作码。它如何能同时做这两件事呢？稍后你将看到解决方案。
- en: At time T = T3, the CPU computes the address of any memory operand if the first
    instruction accesses memory. If the first instruction doesn’t access memory, the
    CPU does nothing. During T3, the CPU also decodes the opcode of the second instruction
    and fetches any operands in the second instruction. Finally, the CPU also fetches
    the opcode for the third instruction. With each advancing tick of the clock, another
    execution stage of each instruction in the pipeline completes, and the CPU fetches
    the opcode of yet another instruction from memory.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间T = T3时，CPU计算任何内存操作数的地址，如果第一条指令访问了内存。如果第一条指令不访问内存，CPU什么也不做。在T3期间，CPU还解码第二条指令的操作码，并获取第二条指令中的操作数。最后，CPU还获取第三条指令的操作码。随着时钟每一次的前进，流水线中每条指令的另一个执行阶段完成，CPU又从内存中获取下一条指令的操作码。
- en: This process continues until, at T = T6, the CPU completes the execution of
    the first instruction, computes the result for the second, and fetches the opcode
    for the sixth instruction in the pipeline. The important thing to note is that
    after T = T5, the CPU completes an instruction on every clock cycle. Once the
    CPU fills the pipeline, it completes one instruction on each cycle. This is true
    even if there are complex addressing modes to be computed, memory operands to
    fetch, or other operations that consume cycles on a nonpipelined processor. All
    you need to do is add more stages to the pipeline, and you can still effectively
    process each instruction in one clock cycle.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程持续进行，直到T = T6时，CPU完成了第一条指令的执行，计算了第二条指令的结果，并获取了流水线中第六条指令的操作码。需要注意的重要事项是，在T
    = T5之后，CPU在每个时钟周期内都会完成一条指令。一旦CPU填充了流水线，它就在每个周期完成一条指令。即使有复杂的寻址模式需要计算、内存操作数需要获取，或其他在非流水线处理器上消耗周期的操作，这一点也是成立的。你所需要做的只是增加更多的阶段到流水线中，你仍然可以在一个时钟周期内有效地处理每一条指令。
- en: Now back to the small conflict in the pipeline organization I mentioned earlier.
    At T = T2, for example, the CPU attempts to prefetch a block of bytes containing
    any operands of the first instruction, and at the same time it fetches the opcode
    of the second instruction. Until the CPU decodes the first instruction, it doesn’t
    know how many operands the instruction requires or their length. Moreover, until
    it determines that information, the CPU doesn’t know what byte to fetch as the
    opcode of the second instruction. So how can the pipeline fetch the opcode of
    the next instruction in parallel with any address operands of the current instruction?
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在回到我之前提到的流水线组织中的小冲突。例如，在T = T2时，CPU尝试预取包含第一条指令任何操作数的一块字节，同时它还获取第二条指令的操作码。在CPU解码第一条指令之前，它不知道该指令需要多少个操作数，也不知道它们的长度。而且，直到它确定了这些信息，CPU才知道该获取哪一个字节作为第二条指令的操作码。那么，流水线如何能与当前指令的任何地址操作数并行获取下一条指令的操作码呢？
- en: One solution is to disallow this simultaneous operation in order to avoid the
    potential data hazard. If an instruction has an address or constant operand, we
    can simply delay the start of the next instruction. Unfortunately, many instructions
    have these additional operands, so this approach will substantially hinder the
    CPU’s execution speed.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解决方案是禁止同时操作，以避免潜在的数据危害。如果一条指令有地址或常量操作数，我们可以简单地延迟下一条指令的开始。不幸的是，许多指令都有这些额外的操作数，因此这种方法会显著阻碍CPU的执行速度。
- en: The second solution is to throw a lot more hardware at the problem. Operand
    and constant sizes usually come in 1-, 2-, and 4-byte lengths. Therefore, if we
    actually fetch the bytes in memory that are located at offsets 1, 3, and 5 bytes
    beyond the current opcode we are decoding, one of them will probably contain the
    opcode of the next instruction. Once we are through decoding the current instruction,
    we know how many bytes it consumes, and, therefore, we know the offset of the
    next opcode. We can use a simple data selector circuit to choose which of the
    three candidate opcode bytes we want to use.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种解决方案是投入更多硬件来解决问题。操作数和常量的大小通常为1字节、2字节或4字节。因此，如果我们实际从内存中获取位于当前操作码解码位置之后1字节、3字节和5字节的字节，那么其中之一可能包含下一条指令的操作码。一旦我们解码完当前指令，就知道它消耗了多少字节，因此我们也知道下一条操作码的偏移位置。我们可以使用一个简单的数据选择电路来选择三个候选操作码字节中我们要使用的字节。
- en: In practice, we actually have to select the next opcode byte from more than
    three candidates because 80x86 instructions come in many different lengths. For
    example, a `mov` instruction that copies a 32-bit constant to a memory location
    can be 10 or more bytes long. Moreover, instructions vary in length from 1 to
    15 bytes. And some opcodes on the 80x86 are longer than 1 byte, so the CPU may
    have to fetch multiple bytes in order to properly decode the current instruction.
    However, by throwing more hardware at the problem, we can decode the current opcode
    at the same time we’re fetching the next.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，我们实际上需要从三个以上的候选项中选择下一个操作码字节，因为80x86指令有多种不同的长度。例如，一个将32位常量复制到内存位置的`mov`指令可能长达10个字节或更多。此外，指令的长度从1字节到15字节不等。并且80x86上的一些操作码超过1字节，因此CPU可能需要获取多个字节才能正确解码当前指令。然而，通过投入更多硬件，我们可以在获取下一条指令的同时解码当前的操作码。
- en: '**9.5.4.2 Stalls in a Pipeline**'
  id: totrans-262
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**9.5.4.2 流水线中的停顿**'
- en: 'Unfortunately, the scenario presented in the previous section is a little too
    simplistic. There are two problems that our simple pipeline ignores: competition
    between instructions for access to the bus (known as *bus contention*), and nonsequential
    instruction execution. Both problems may increase the average execution time of
    the instructions in the pipeline. By understanding how the pipeline works, you
    can write your software to avoid these pitfalls and improve the performance of
    your applications.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，上一节中呈现的场景过于简单。我们的简单流水线忽略了两个问题：指令之间对总线的访问竞争（即*总线竞争*）和非顺序指令执行。这两个问题可能会增加流水线中指令的平均执行时间。通过了解流水线的工作原理，你可以编写软件以避免这些陷阱，从而提高应用程序的性能。
- en: Bus contention can occur whenever an instruction needs to access an item in
    memory. For example, if a `mov(`reg`,` mem`);` instruction needs to store data
    in memory and a `mov(`mem`,` reg`);` instruction needs to fetch data from memory,
    contention for the address and data bus may develop because the CPU will be trying
    to do both operations simultaneously.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 总线竞争可能发生在任何一条指令需要访问内存中的某个项时。例如，如果`mov(`reg`,` mem`);`指令需要将数据存储到内存中，而`mov(`mem`,`
    reg`);`指令需要从内存中取数据，那么由于CPU试图同时执行这两个操作，可能会发生地址和数据总线的竞争。
- en: One simplistic way to handle bus contention is through a *[pipeline stall](gloss01.xhtml#gloss01_193)*.
    The CPU, when faced with contention for the bus, gives priority to the instruction
    farthest along in the pipeline. This stalls the later instruction in the pipeline,
    and it takes two cycles to execute that instruction (see [Figure 9-7](ch09.xhtml#ch09fig07)).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 处理总线竞争的一个简单方法是通过*[流水线停顿](gloss01.xhtml#gloss01_193)*。当CPU面临总线竞争时，会优先处理流水线中已执行得最远的指令。这会导致流水线中较后的指令停顿，并且该指令的执行需要两个时钟周期（参见[图
    9-7](ch09.xhtml#ch09fig07)）。
- en: '![image](../images/09fig07.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/09fig07.jpg)'
- en: '*Figure 9-7: A pipeline stall*'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-7：流水线停顿*'
- en: There are many other cases of bus contention. For example, fetching operands
    for an instruction requires access to the prefetch queue at the same time that
    the CPU needs to access it to fetch the opcode of the next instruction. Given
    the simple pipelining scheme that we’ve outlined so far, it’s unlikely that most
    instructions would execute at one clock (cycle) per instruction (CPI).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他总线竞争的情况。例如，获取操作数的指令需要访问预取队列，同时CPU还需要访问该队列以获取下一条指令的操作码。鉴于我们迄今为止概述的简单流水线方案，大多数指令不太可能以每条指令一个时钟周期（CPI）来执行。
- en: As another example of a pipeline stall, consider what happens when an instruction
    *modifies* the value in the EIP register. For example, the `jnz` instruction might
    change the value in the EIP register if it transfers control to its target label,
    which implies that the next set of instructions to be executed does not immediately
    follow the `jnz` instruction. By the time the instruction `jnz label;` completes
    execution (assuming the zero flag is clear so that the branch is taken), we’ve
    already started five other instructions and we’re only one clock cycle away from
    completing the first of these. The CPU must not execute those instructions, or
    it will compute improper results.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 作为流水线停顿的另一个例子，考虑当一条指令*修改*EIP寄存器中的值时会发生什么。例如，如果`jnz`指令将控制转移到目标标签，它可能会改变EIP寄存器中的值，这意味着下一组要执行的指令并不紧接在`jnz`指令之后。当指令`jnz
    label;`执行完毕时（假设零标志位清除，因此分支被采取），我们已经启动了另外五条指令，而且距离完成第一条指令只剩一个时钟周期。CPU必须避免执行这些指令，否则它将计算出不正确的结果。
- en: The only reasonable solution is to *flush* the entire pipeline and begin fetching
    opcodes anew. However, doing so causes a severe execution time penalty. It will
    take the length of the pipeline (six cycles in our example) before the next instruction
    completes execution. The longer the pipeline is, the more you can accomplish per
    cycle in the system, but the slower a program will run if it jumps around quite
    a bit. Unfortunately, you can’t control the number of stages in the pipeline,^([4](footnotes.xhtml#fn9_4a))
    but you *can* control the number of transfer instructions in your programs, so
    it’s best to keep these to a minimum in a pipelined system.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一合理的解决方案是*刷新*整个流水线，并重新开始获取操作码。然而，这样做会导致严重的执行时间惩罚。在我们的示例中，下一条指令完成执行需要流水线的长度（六个周期）。流水线越长，系统每个周期可以完成的任务就越多，但如果程序跳跃很频繁，执行速度就越慢。不幸的是，你无法控制流水线的阶段数^([4](footnotes.xhtml#fn9_4a))，但你*可以*控制程序中的传输指令数量，因此在流水线系统中最好将这些指令保持在最小限度。
- en: '***9.5.5 Instruction Caches: Providing Multiple Paths to Memory***'
  id: totrans-271
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.5 指令缓存：提供多条内存路径***'
- en: System designers can resolve many problems with bus contention through the intelligent
    use of the prefetch queue and the cache memory subsystem. As you’ve seen, they
    can design the prefetch queue to buffer data from the instruction stream. However,
    they can also use a separate *[instruction cache](gloss01.xhtml#gloss01_124)*
    (apart from the data cache) to hold machine instructions. As a programmer, you
    have no control over how your CPU’s instruction cache is organized, but knowing
    how it operates might prompt you to use certain instruction sequences that would
    otherwise create stalls.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 系统设计师可以通过智能使用预取队列和缓存内存子系统来解决许多总线竞争问题。正如你所看到的，他们可以设计预取队列来缓冲来自指令流的数据。然而，他们也可以使用一个独立的*[指令缓存](gloss01.xhtml#gloss01_124)*（与数据缓存分开）来存储机器指令。作为程序员，你无法控制CPU的指令缓存是如何组织的，但了解它的工作方式可能会促使你使用某些指令序列，这些序列在其他情况下可能会导致停顿。
- en: Suppose the CPU has two separate memory spaces, one for instructions and one
    for data, each with its own bus. This is called the *[Harvard architecture](gloss01.xhtml#gloss01_107)*
    because the first such machine was built at Harvard University. On a Harvard machine,
    there’s no contention for the bus; the BIU can continue to fetch opcodes on the
    instruction bus while accessing memory on the data/memory bus (see [Figure 9-8](ch09.xhtml#ch09fig08)).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 假设CPU有两个独立的内存空间，一个用于指令，另一个用于数据，每个内存空间都有自己的总线。这被称为*[哈佛架构](gloss01.xhtml#gloss01_107)*，因为第一台这样的机器是在哈佛大学建造的。在哈佛机器上，不会发生总线竞争；BIU可以继续在指令总线上获取操作码，同时访问数据/内存总线上的内存（参见[图
    9-8](ch09.xhtml#ch09fig08)）。
- en: '![image](../images/09fig08.jpg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/09fig08.jpg)'
- en: '*Figure 9-8: A typical Harvard machine*'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-8：典型的哈佛架构机器*'
- en: In the real world, there are very few true Harvard machines. The extra pins
    needed on the processor to support two physically separate buses increase the
    cost of the processor and introduce many other engineering problems. However,
    microprocessor designers have discovered that they can obtain many of the benefits
    of the Harvard architecture with few of its disadvantages by using separate on-chip
    caches for data and instructions. Advanced CPUs use an internal Harvard architecture
    and an external von Neumann architecture. [Figure 9-9](ch09.xhtml#ch09fig09) shows
    the structure of the 80x86 with separate data and instruction caches.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，真正的哈佛架构机器非常少。为了支持两个物理上独立的总线，处理器上需要额外的引脚，这增加了处理器的成本并引入了许多其他工程问题。然而，微处理器设计师发现，通过使用独立的片上缓存来存储数据和指令，他们可以在很少有其缺点的情况下获得哈佛架构的许多优点。先进的CPU使用内部哈佛架构和外部冯·诺依曼架构。[图
    9-9](ch09.xhtml#ch09fig09)展示了带有独立数据和指令缓存的80x86结构。
- en: '![image](../images/09fig09.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/09fig09.jpg)'
- en: '*Figure 9-9: Using separate code and data caches*'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-9：使用独立的代码和数据缓存*'
- en: Each path between the sections inside the CPU represents an independent bus,
    and data can flow on all paths concurrently. This means that the prefetch queue
    can pull instruction opcodes from the instruction cache while the execution unit
    is writing data to the data cache. However, it’s not always possible, even with
    a cache, to avoid bus contention. In the arrangement with two separate caches,
    the BIU still has to use the data/address bus to fetch opcodes from memory whenever
    they are not located in the instruction cache. Likewise, the data cache still
    has to buffer data from memory on occasion.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: CPU内部各部分之间的每条路径代表一个独立的总线，数据可以在所有路径上并行流动。这意味着预取队列可以从指令缓存中拉取指令操作码，而执行单元则将数据写入数据缓存。然而，即使有缓存，也不总是能避免总线竞争。在有两个独立缓存的安排中，BIU仍然需要使用数据/地址总线从内存中提取操作码，只要它们不在指令缓存中。同样，数据缓存仍然需要偶尔从内存中缓存数据。
- en: Although you can’t control the presence, size, or type of cache on a CPU, you
    must be aware of how the cache operates in order to write the best programs. On-chip,
    level-one (L1) instruction caches are generally quite small (between 4KB and 64KB
    on typical CPUs) compared to the size of main memory. Therefore, the shorter your
    instructions, the more of them will fit in the cache (tired of “shorter instructions”
    yet?). The more instructions you have in the cache, the less often bus contention
    will occur. Likewise, using registers to hold temporary results places less strain
    on the data cache, so it doesn’t need to flush data to memory or retrieve data
    from memory quite so often.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你无法控制CPU上缓存的存在、大小或类型，但你必须了解缓存的工作原理，以便编写最佳程序。在芯片上，一级（L1）指令缓存通常非常小（在典型的CPU上，介于4KB和64KB之间），与主内存的大小相比，因此，指令越短，就能装入缓存的指令越多（你还厌烦“短指令”了吗？）。缓存中存储的指令越多，总线竞争发生的频率就越低。同样，使用寄存器保存临时结果会减少对数据缓存的压力，这样就不需要频繁地将数据刷新到内存或从内存中检索数据了。
- en: '***9.5.6 Pipeline Hazards***'
  id: totrans-281
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.6 流水线危害***'
- en: 'There is another problem with using a pipeline: hazards. There are two types
    of hazards: control hazards and data hazards. We’ve actually discussed control
    hazards already, although we didn’t refer to them by name. A control hazard occurs
    whenever the CPU branches to some new location in memory and consequently has
    to flush from the pipeline the instructions that are in various stages of execution.
    A data hazard occurs when two instructions attempt to access the same memory location
    out of sequence.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 使用流水线还有另一个问题：危害。危害有两种类型：控制危害和数据危害。我们实际上已经讨论过控制危害，尽管没有按名称提及。当CPU跳转到内存中的某个新位置时，控制危害就会发生，随之而来的是必须从流水线中清除各个执行阶段的指令。数据危害发生在两条指令试图按顺序访问同一个内存位置时。
- en: 'Let’s take a look at data hazards using the execution profile for the following
    instruction sequence:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下指令序列的执行概况来看一下数据危害：
- en: '[PRE1]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: When these two instructions execute, the pipeline will look something like [Figure
    9-10](ch09.xhtml#ch09fig10).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 当这两条指令执行时，流水线的状态会像[图9-10](ch09.xhtml#ch09fig10)一样。
- en: '![image](../images/09fig10.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/09fig10.jpg)'
- en: '*Figure 9-10: A data hazard*'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9-10：数据危害*'
- en: These two instructions attempt to fetch the 32-bit value whose address is held
    in the SomeVar pointer variable. *However, this sequence of instructions won’t
    work properly!* The second instruction accesses the value in EBX before the first
    instruction copies the address of memory location SomeVar into EBX (T5 and T6
    in [Figure 9-10](ch09.xhtml#ch09fig10)).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这两条指令试图获取地址存储在SomeVar指针变量中的32位值。*然而，这个指令序列无法正常工作！* 第二条指令在第一条指令将内存位置SomeVar的地址复制到EBX之前就访问了EBX中的值（[图9-10](ch09.xhtml#ch09fig10)中的T5和T6）。
- en: CISC processors, like the 80x86, handle hazards automatically. (Some RISC chips
    do not, and if you tried this sequence on certain RISC chips, you would store
    an incorrect value in EAX.) In order to handle the data hazard in this example,
    CISC processors stall the pipeline to synchronize the two instructions. The actual
    execution would look something like [Figure 9-11](ch09.xhtml#ch09fig11).
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 像80x86这样的CISC处理器会自动处理危害。（有些RISC芯片不会，如果你在某些RISC芯片上尝试这个序列，你将把一个错误的值存储在EAX中。）为了处理这个示例中的数据危害，CISC处理器会暂停流水线以同步这两条指令。实际执行可能看起来像[图9-11](ch09.xhtml#ch09fig11)。
- en: '![image](../images/09fig11.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/09fig11.jpg)'
- en: '*Figure 9-11: How a CISC CPU handles a data hazard*'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9-11：CISC CPU如何处理数据危害*'
- en: By delaying the second instruction by two clock cycles, the CPU guarantees that
    the load instruction will load EAX with the value at the proper address. Unfortunately,
    the `mov([ebx], eax);` instruction now executes in three clock cycles rather than
    one. However, requiring two extra clock cycles is better than producing incorrect
    results.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将第二条指令延迟两个时钟周期，CPU确保加载指令会在正确的地址加载EAX的值。不幸的是，`mov([ebx], eax);`指令现在需要三个时钟周期才能执行，而不是一个时钟周期。然而，增加两个时钟周期总比产生错误的结果要好。
- en: 'Fortunately, you (or your compiler) can reduce the impact that hazards have
    on program execution speed within your software. A data hazard occurs when the
    source operand of one instruction was a destination operand of a previous instruction.
    There’s nothing wrong with loading EBX from SomeVar and then loading EAX from
    [EBX] (that is, the double-word memory location pointed at by EBX), *as long as
    they don’t occur one right after the other*. Suppose the code sequence had been:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，你（或你的编译器）可以减少程序执行速度中，由于冲突带来的影响。数据冲突发生在当一条指令的源操作数是前一条指令的目的操作数时。将EBX从SomeVar加载然后再从[EBX]加载EAX（即，EBX指向的双字内存位置）是没有问题的，*只要它们不是紧接着执行的*。假设代码序列是：
- en: '[PRE2]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We could reduce the effect of the hazard in this code sequence by simply rearranging
    the instructions, as follows:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过简单地重新排列指令来减少该代码序列中冲突的影响，具体如下：
- en: '[PRE3]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now the `mov([ebx], eax);` instruction requires only one additional clock cycle.
    By inserting yet another instruction between the `mov(`SomeVar`, ebx);` and the
    `mov([ebx], eax);` instructions, you can eliminate the effects of the hazard altogether
    (of course, the inserted instruction must not modify the values in the EAX and
    EBX registers).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`mov([ebx], eax);`指令只需要一个额外的时钟周期。通过在`mov(`SomeVar`, ebx);`和`mov([ebx], eax);`指令之间插入另一条指令，你可以完全消除冲突的影响（当然，插入的指令不能修改EAX和EBX寄存器中的值）。
- en: On a pipelined processor, the order of instructions in a program may dramatically
    affect the program’s performance. If you’re writing assembly code, always look
    for possible hazards and eliminate them wherever possible by rearranging your
    instruction sequences. If you’re using a compiler, choose one that properly handles
    instruction ordering.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个流水线处理器中，程序中指令的顺序可能会极大地影响程序的性能。如果你在编写汇编代码，始终要注意可能的冲突，并通过重新排列指令序列尽可能消除它们。如果你使用的是编译器，选择一个能够正确处理指令顺序的编译器。
- en: '***9.5.7 Superscalar Operation: Executing Instructions in Parallel***'
  id: totrans-299
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.7 超标量操作：并行执行指令***'
- en: With the pipelined architecture shown so far, we could achieve, at best, execution
    times of one CPI. Is it possible to execute instructions faster than this? At
    first you might think, “Of course not—we can do at most one operation per clock
    cycle, so there’s no way we can execute more than one instruction per clock cycle.”
    Keep in mind, however, that a single instruction is *not* a single operation.
    In the examples presented earlier, each instruction took between six and eight
    operations to complete. By adding seven or eight separate units to the CPU, we
    could effectively execute these eight operations in one clock cycle, yielding
    one CPI. If we add more hardware and execute, say, 16 operations at once, can
    we achieve 0.5 CPI? The answer is a qualified yes. A CPU that includes this additional
    hardware is a *superscalar* CPU, and it can execute more than one instruction
    during a single clock cycle. The 80x86 family began supporting superscalar execution
    with the introduction of the Pentium processor.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在目前的流水线架构下，最好的执行时间是每条指令一个CPI。是否可以比这个更快地执行指令呢？一开始你可能会想，“当然不行——我们每个时钟周期最多只能执行一条操作，所以我们不可能每个时钟周期执行多条指令。”然而，请记住，一个指令*并非*一个操作。在之前的例子中，每条指令完成的操作数量在六到八个之间。通过在CPU中添加七到八个独立的单元，我们可以有效地在一个时钟周期内执行这八个操作，从而得到一个CPI。如果我们添加更多硬件，并一次性执行例如16个操作，我们能达到0.5
    CPI吗？答案是有条件的“可以”。一个包含这些额外硬件的CPU被称为*超标量*CPU，它可以在一个时钟周期内执行多条指令。80x86家族从Pentium处理器开始支持超标量执行。
- en: A superscalar CPU has several execution units (see [Figure 9-12](ch09.xhtml#ch09fig12)).
    If it encounters in the prefetch queue two or more instructions that it can execute
    independently, it will do so.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 超标量CPU拥有多个执行单元（见[图9-12](ch09.xhtml#ch09fig12)）。如果它在预取队列中遇到两条或更多条可以独立执行的指令，它将同时执行它们。
- en: '![image](../images/09fig12.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/09fig12.jpg)'
- en: '*Figure 9-12: A CPU that supports superscalar operation*'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-12：支持超标量操作的CPU*'
- en: 'There are a couple of advantages to going superscalar. Suppose you have the
    following instructions in the instruction stream:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 使用超标量有几个优点。假设指令流中有以下指令：
- en: '[PRE4]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If there are no other problems or hazards in the surrounding code, and all 6
    bytes for these two instructions are currently in the prefetch queue, there’s
    no reason why the CPU can’t fetch and execute both instructions in parallel. All
    it takes is extra silicon on the CPU chip to implement two execution units.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 如果周围代码没有其他问题或冒险，而且这两条指令的6个字节目前都在预取队列中，那么没有理由不能并行获取并执行这两条指令。实现这一点只需要在CPU芯片上增加额外的硅片来实现两个执行单元。
- en: Besides speeding up independent instructions, a superscalar CPU can also speed
    up program sequences that have hazards. One limitation of normal CPUs is that
    once a hazard occurs, the offending instruction will completely stall the pipeline.
    Every instruction that follows the stalled instruction will also have to wait
    for the CPU to synchronize the execution of the offending instructions. With a
    superscalar CPU, however, instructions following the hazard may continue execution
    through the pipeline as long as they don’t have hazards of their own. This alleviates
    (though it does not eliminate) some of the need for careful instruction scheduling.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 除了加速独立指令外，超标量CPU还可以加速具有数据冒险的程序序列。普通CPU的一项限制是，一旦发生冒险，受影响的指令会完全停滞管线。随后的每条指令也必须等待CPU同步执行被阻塞的指令。然而，超标量CPU可以在不具有自身冒险的情况下，继续执行那些跟随冒险指令的指令。这减轻了（虽然并未消除）对精确指令调度的某些需求。
- en: 'The way you write software for a superscalar CPU can dramatically affect its
    performance. First and foremost is that rule you’re probably sick of by now: *use
    short instructions*. The shorter your instructions, the more instructions the
    CPU can fetch in a single operation and, therefore, the more likely the CPU will
    execute faster than one CPI. Most superscalar CPUs do not completely duplicate
    the execution unit. There might be multiple ALUs, floating-point units, and so
    on, which means that certain instruction sequences can execute very quickly, while
    others won’t. You have to study the exact composition of your CPU to decide which
    instruction sequences produce the best performance.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 你编写针对超标量CPU的软件方式会显著影响其性能。最重要的是你现在可能已经厌烦的规则：*使用短指令*。指令越短，CPU每次操作中可以获取的指令就越多，因此，CPU执行速度比每周期指令数（CPI）大于1的情况更有可能更快。大多数超标量CPU并没有完全复制执行单元。可能有多个算术逻辑单元（ALU）、浮点单元等，这意味着某些指令序列可以非常快速地执行，而其他指令则不能。你需要研究CPU的精确组成，以决定哪些指令序列能产生最佳的性能。
- en: '***9.5.8 Out-of-Order Execution***'
  id: totrans-309
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.8 非顺序执行***'
- en: 'In a standard superscalar CPU, it is the programmer’s (or compiler’s) responsibility
    to arrange the instructions to avoid hazards and pipeline stalls. Fancier CPUs
    can actually remove some of this burden and improve performance by automatically
    rescheduling instructions while the program executes. To understand how this is
    possible, consider the following instruction sequence:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准超标量CPU中，安排指令以避免冒险和管线停滞是程序员（或编译器）的责任。更先进的CPU实际上可以通过在程序执行过程中自动重新调度指令，减轻这一负担并提高性能。为了理解如何实现这一点，考虑以下的指令序列：
- en: '[PRE5]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: There’s a data hazard between the first and second instructions. The second
    instruction must delay until the first instruction completes execution. This introduces
    a pipeline stall and increases the running time of the program. Typically, the
    stall affects every instruction that follows. However, the third instruction’s
    execution does not depend on the result from either of the first two instructions.
    Therefore, there’s no reason to stall the execution of the `mov(2000, ecx);` instruction.
    It can continue executing while the second instruction waits for the first to
    complete. This technique is called *[out-of-order execution](gloss01.xhtml#gloss01_187)*
    because the CPU can execute instructions prior to the completion of instructions
    appearing previously in the code stream.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条和第二条指令之间存在数据冒险。第二条指令必须等待直到第一条指令执行完毕。这会导致流水线停顿，并增加程序的运行时间。通常，停顿会影响随后的每一条指令。然而，第三条指令的执行不依赖于前两条指令的任何结果。因此，**`mov(2000,
    ecx);`** 指令的执行不需要停顿。它可以在第二条指令等待第一条指令完成时继续执行。这种技术被称为 *[乱序执行](gloss01.xhtml#gloss01_187)*，因为
    CPU 可以在代码流中出现的指令完成之前就执行这些指令。
- en: Keep in mind that the CPU can execute instructions out of sequence only if doing
    so produces exactly the same results as sequential execution. While there are
    many little technical issues that make this feature more difficult than it seems,
    with enough engineering effort you can implement it.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，CPU 只能在确保执行顺序与顺序执行结果完全相同的情况下乱序执行指令。虽然有许多技术问题使得这一特性比看起来更为复杂，但只要付出足够的工程努力，还是可以实现的。
- en: '***9.5.9 Register Renaming***'
  id: totrans-314
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.9 寄存器重命名***'
- en: 'One problem that hampers the effectiveness of superscalar operation on the
    80x86 CPU is its limited number of general-purpose registers. Suppose, for example,
    that the CPU had four different pipelines and, therefore, was capable of executing
    four instructions simultaneously. Presuming no conflicts existed among these instructions
    and they could all execute simultaneously, it would still be very difficult to
    actually achieve four instructions per clock cycle because most instructions operate
    on two register operands. For four instructions to execute concurrently, you’d
    need eight different registers: four destination registers and four source registers
    (none of the destination registers could double as source registers of other instructions).
    CPUs that have lots of registers can handle this task quite easily, but the limited
    register set of the 80x86 makes this difficult. Fortunately, there’s a trick to
    alleviate part of the problem: *[register renaming](gloss01.xhtml#gloss01_215)*.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 一个限制 80x86 CPU 超标量操作效能的问题是其有限数量的通用寄存器。例如，假设 CPU 拥有四个不同的流水线，因此能够同时执行四条指令。假设这些指令之间没有冲突，且可以同时执行，那么实际上很难在每个时钟周期内实现四条指令同时执行，因为大多数指令需要操作两个寄存器操作数。为了实现四条指令同时执行，你需要八个不同的寄存器：四个目标寄存器和四个源寄存器（任何目标寄存器都不能作为其他指令的源寄存器）。拥有大量寄存器的
    CPU 可以轻松处理这个任务，但 80x86 的寄存器有限，使得这一任务变得困难。幸运的是，有一个技巧可以缓解部分问题：*[寄存器重命名](gloss01.xhtml#gloss01_215)*。
- en: 'Register renaming is a sneaky way to give a CPU more registers than it actually
    has. Programmers won’t have direct access to these extra registers, but the CPU
    can use them to prevent hazards in certain cases. For example, consider the following
    short instruction sequence:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 寄存器重命名是一种巧妙的方式，能够让 CPU 拥有比实际更多的寄存器。程序员无法直接访问这些额外的寄存器，但 CPU 可以利用它们在某些情况下防止发生数据冒险。例如，考虑以下的简短指令序列：
- en: '[PRE6]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There’s a data hazard between the first and second instructions as well as between
    the third and fourth instructions. Out-of-order execution in a superscalar CPU
    would normally allow the first and third instructions to execute concurrently,
    and then the second and fourth instructions could execute concurrently. However,
    there’s also a data hazard between the first and third instructions because they
    use the same register. The programmer could have easily solved this problem by
    using a different register (say, EBX) for the third and fourth instructions. However,
    let’s assume that the programmer was unable to do this because all the other registers
    were holding important values. Is this sequence doomed to executing in four cycles
    on a superscalar CPU that should require only two?
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条和第二条指令之间、第三条和第四条指令之间都有数据冲突。在超标量CPU中，乱序执行通常会允许第一条和第三条指令同时执行，然后第二条和第四条指令也可以同时执行。然而，第一条和第三条指令之间也存在数据冲突，因为它们使用了相同的寄存器。程序员本可以通过使用不同的寄存器（比如EBX）来解决第三条和第四条指令之间的冲突。然而，假设程序员无法这么做，因为所有其他寄存器都保存着重要的值。这个指令序列是否注定会在应该只需两个周期的超标量CPU上执行四个周期？
- en: 'One advanced trick a CPU can employ is to create a bank of registers for each
    of the general-purpose registers on the CPU. That is, rather than having a single
    EAX register, the CPU could support an array of EAX registers; let’s call these
    registers EAX[0], EAX[1], EAX[2], and so on. Similarly, you could have an array
    of each of the other registers: EBX[0] through EBX[*n*], ECX[0] through ECX[*n*],
    and so on. The instruction set doesn’t permit the programmer to select one of
    these specific register array elements for a given instruction, but the CPU can
    automatically choose among them if doing so wouldn’t change the overall computation
    and could speed up program execution. This is known as *register renaming*. For
    example, consider the following sequence (with register array elements automatically
    chosen by the CPU):'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: CPU可以采用的一个高级技巧是为每个通用寄存器创建一个寄存器池。也就是说，CPU可以支持一个EAX寄存器数组，而不是只有一个EAX寄存器；我们可以将这些寄存器称为EAX[0]、EAX[1]、EAX[2]，以此类推。同样，你也可以为其他寄存器创建一个数组：EBX[0]到EBX[*n*]、ECX[0]到ECX[*n*]，以此类推。指令集不允许程序员为某条指令选择这些特定寄存器数组元素中的一个，但如果这样做不会改变整体计算并且能够加速程序执行，CPU可以自动选择其中的一个。这就是*寄存器重命名*。例如，考虑以下序列（由CPU自动选择寄存器数组元素）：
- en: '[PRE7]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Because EAX[0] and EAX[1] are different registers, the CPU can execute the first
    and third instructions concurrently. Likewise, the CPU can execute the second
    and fourth instructions concurrently.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 因为EAX[0]和EAX[1]是不同的寄存器，CPU可以同时执行第一条和第三条指令。同样，CPU也可以同时执行第二条和第四条指令。
- en: Although this is a simple example, and different CPUs implement register renaming
    in many different ways, you can see how the CPU can use this technique to improve
    performance.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个简单的示例，而且不同的CPU在实现寄存器重命名时有不同的方式，但你可以看到CPU如何利用这一技术来提升性能。
- en: '***9.5.10 VLIW Architecture***'
  id: totrans-323
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.10 VLIW架构***'
- en: Superscalar operation attempts to schedule, in hardware, the execution of multiple
    instructions simultaneously. Another technique, which Intel is using in its IA-64
    architecture, involves *very long instruction words (VLIW)*. In a VLIW computer
    system, the CPU fetches a large block of bytes (41 bits in the case of the IA-64
    Itanium CPU) and decodes and executes it all at once. This block of bytes usually
    contains two or more instructions (three in the case of the IA-64). VLIW computing
    requires the programmer or compiler to properly schedule the instructions in each
    block so that there are no hazards or other conflicts, but if all goes well, the
    CPU can execute three or more instructions per clock cycle.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 超标量操作尝试在硬件中调度多个指令同时执行。另一种技术是Intel在其IA-64架构中使用的*超长指令字（VLIW）*。在VLIW计算机系统中，CPU会提取一个大的字节块（对于IA-64
    Itanium CPU是41位），并一次性解码并执行。这块字节块通常包含两条或更多指令（在IA-64中是三条）。VLIW计算要求程序员或编译器正确调度每个块中的指令，以避免任何数据冲突或其他问题，但如果一切顺利，CPU每个时钟周期可以执行三条或更多指令。
- en: '***9.5.11 Parallel Processing***'
  id: totrans-325
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.11 并行处理***'
- en: Most techniques for improving CPU performance via architectural advances involve
    the parallel execution of instructions. If programmers are aware of the underlying
    architecture, they can write code that runs faster, but these architectural advances
    often improve performance significantly even if programmers do not write special
    code to take advantage of them.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '大多数通过架构进步提高CPU性能的技术都涉及指令的并行执行。如果程序员了解底层架构，他们可以编写更快的代码，但即使程序员没有编写特殊代码来利用这些架构进步，这些进步也常常能显著提升性能。  '
- en: The only problem with ignoring the underlying architecture is that there’s only
    so much the hardware can do to parallelize a program that requires sequential
    execution for proper operation. To truly produce a parallel program, the programmer
    must specifically write parallel code, though, of course, this requires architectural
    support from the CPU. This section and the next touch on the types of support
    a CPU can provide.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 忽视底层架构的唯一问题是，硬件在将需要顺序执行才能正常运行的程序并行化方面所能做的有限。要真正生成并行程序，程序员必须专门编写并行代码，当然，这也需要CPU的架构支持。本节及下一节将涉及CPU可以提供的支持类型。
- en: Common CPUs use what’s known as the *single instruction, single data (SISD)*
    model. This means that the CPU executes one instruction at a time, and that instruction
    operates on a single piece of data.^([5](footnotes.xhtml#fn9_5a)) Two common parallel
    models are the *single instruction, multiple data (SIMD)* and *multiple instruction,
    multiple data (MIMD)* models. Many modern CPUs, including the 80x86, include limited
    support for these parallel-execution models, providing a hybrid SISD/SIMD/MIMD
    architecture.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '常见的CPU使用被称为*单指令单数据（SISD）*模型。这意味着CPU一次只执行一条指令，并且该指令只操作一片数据。^([5](footnotes.xhtml#fn9_5a))
    两种常见的并行模型是*单指令多数据（SIMD）*和*多指令多数据（MIMD）*模型。许多现代CPU，包括80x86，都在一定程度上支持这些并行执行模型，提供了一种混合的SISD/SIMD/MIMD架构。  '
- en: 'In the SIMD model, the CPU executes a single instruction stream, just like
    the pure SISD model, but operates on multiple pieces of data concurrently. For
    example, consider the 80x86 `add` instruction. This is a SISD instruction that
    operates on (that is, produces) a single piece of data. True, the instruction
    fetches values from two source operands, but the end result is that the `add`
    instruction stores a sum into only a single destination operand. An SIMD version
    of `add`, on the other hand, would compute several sums simultaneously. The 80x86
    MMX and SIMD instruction extensions, the ARM’s Neon instructions, and the PowerPC’s
    AltiVec instructions, operate in exactly this fashion. With the `paddb` MMX instruction,
    for example, you can add up to eight separate pairs of values with the execution
    of a single instruction. Here’s an example of this instruction:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '在SIMD模型中，CPU执行单一的指令流，就像纯SISD模型一样，但它并行地操作多个数据片段。例如，考虑80x86的`add`指令。这是一个SISD指令，操作（即生成）单个数据。的确，该指令从两个源操作数中获取值，但最终结果是`add`指令只将和存储到一个目标操作数中。另一方面，SIMD版本的`add`会同时计算多个和。例如，通过`paddb`
    MMX指令，你可以在执行单一指令的情况下，加法最多达到八对独立的值。以下是此指令的示例：  '
- en: '[PRE8]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Although this instruction appears to have only two operands (like a typical
    SISD `add` instruction on the 80x86), the MMX registers (MM0 and MM1) actually
    hold eight independent byte values (the MMX registers are 64 bits wide but are
    treated as eight 8-bit values).
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管该指令看起来只有两个操作数（像典型的80x86的SISD `add`指令），但MMX寄存器（MM0和MM1）实际上存储着八个独立的字节值（MMX寄存器是64位宽，但被视为八个8位值）。  '
- en: Unless you have an algorithm that can take advantage of SIMD instructions, they’re
    not that useful. Fortunately, high-speed 3D graphics and multimedia applications
    benefit greatly from these SIMD (and MMX) instructions, so their inclusion in
    the 80x86 CPU offers a huge performance boost for these important applications.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '除非你有一个能够利用SIMD指令的算法，否则它们并不那么有用。幸运的是，高速3D图形和多媒体应用程序从这些SIMD（和MMX）指令中受益匪浅，因此它们在80x86
    CPU中的加入为这些重要应用程序提供了巨大的性能提升。  '
- en: The MIMD model uses multiple instructions, operating on multiple pieces of data
    (usually with one instruction per data object, though one of these instructions
    could also operate on multiple data items). These multiple instructions execute
    independently of one another, so it’s very rare that a single program (or, more
    specifically, a single thread of execution) would use the MIMD model. However,
    if you have a multiprogramming environment with multiple programs attempting to
    execute concurrently, the MIMD model does allow each of those programs to execute
    its own code stream simultaneously. This type of parallel system is called a *multiprocessor
    system*.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: MIMD 模型使用多个指令，操作多个数据块（通常每个数据对象使用一条指令，尽管这些指令中的某一条也可能操作多个数据项）。这些指令彼此独立执行，因此很少有单个程序（或者更具体地说，单个执行线程）会使用
    MIMD 模型。然而，如果你有一个多任务环境，其中多个程序试图同时执行，MIMD 模型确实允许每个程序同时执行自己的代码流。这种类型的并行系统被称为*多处理器系统*。
- en: '***9.5.12 Multiprocessing***'
  id: totrans-334
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***9.5.12 多处理***'
- en: Pipelining, superscalar operation, out-of-order execution, and VLIW designs
    are all techniques that CPU designers use in order to execute several operations
    in parallel. These techniques support *fine-grained parallelism* and are useful
    for speeding up adjacent instructions in a computer system. If adding more functional
    units increases parallelism, what would happen if you added another CPU to the
    system? This approach, known as *[multiprocessing](gloss01.xhtml#gloss01_169)*,
    can improve system performance, though not as uniformly as other techniques.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线技术、超标量操作、乱序执行和 VLIW 设计都是 CPU 设计师用来并行执行多个操作的技术。这些技术支持*精细粒度并行性*，并有助于加速计算机系统中相邻指令的执行。如果增加更多的功能单元可以提高并行性，那么如果你向系统中添加另一个
    CPU 会发生什么呢？这种方法称为*[多处理](gloss01.xhtml#gloss01_169)*，它可以提高系统性能，尽管没有其他技术那样均匀。
- en: Multiprocessing doesn’t help a program’s performance unless that program is
    specifically written for use on a multiprocessor system. If you build a system
    with two CPUs, those CPUs cannot trade off executing alternate instructions within
    a single program. It is very expensive, time-wise, to switch the execution of
    a program’s instructions from one processor to another. Therefore, multiprocessor
    systems are effective only with an operating system that executes multiple processes
    or threads concurrently. To differentiate this type of parallelism from that afforded
    by pipelining and superscalar operation, we’ll call this *coarse-grained parallelism*.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 多处理并不会提高程序的性能，除非该程序是专门为在多处理器系统上运行而编写的。如果你构建一个有两个 CPU 的系统，这些 CPU 无法在单个程序中交替执行指令。将程序的指令从一个处理器切换到另一个处理器在时间上是非常昂贵的。因此，多处理器系统仅在能够并发执行多个进程或线程的操作系统中有效。为了将这种类型的并行性与流水线和超标量操作提供的并行性区分开来，我们称其为*粗粒度并行性*。
- en: Adding multiple processors to a system is not as simple as wiring two or more
    processors to the motherboard. To understand why this is so, consider two separate
    programs running on separate processors in a multiprocessor system. These two
    processors communicate with each other by writing to a block of shared physical
    memory. When CPU 1 writes to this block of memory it caches the data locally and
    might not actually write the data to physical memory for some time. If CPU 2 attempts
    to simultaneously read this block of shared memory, it winds up reading the old
    data out of main memory (or its local cache) rather than reading the updated data
    that CPU 1 wrote to its local cache. This is known as the *cache-coherency* problem.
    In order for these two functions to operate properly, the two CPUs must notify
    each other whenever they make changes to shared objects, so the other CPU can
    update its own locally cached copy.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 向系统中添加多个处理器并不像将两个或多个处理器接入主板那样简单。为了理解为什么会这样，考虑在一个多处理器系统中运行的两个独立程序，这两个程序分别运行在不同的处理器上。这两个处理器通过写入共享物理内存块来相互通信。当
    CPU 1 向该内存块写入数据时，它会在本地缓存数据，并且可能不会立即将数据写入物理内存。如果 CPU 2 尝试同时读取这个共享内存块，它最终从主内存（或其本地缓存）中读取旧数据，而不是读取
    CPU 1 写入其本地缓存的更新数据。这就是*缓存一致性*问题。为了让这两个功能正常运行，这两个 CPU 必须在修改共享对象时互相通知对方，以便另一个 CPU
    可以更新其本地缓存的副本。
- en: Multiprocessing is an area where the RISC CPUs have a big advantage over Intel’s
    CPUs. While Intel 80x86 systems reach a point of diminishing returns at around
    32 processors, Sun SPARC and other RISC processors easily support 64-CPU systems
    (with more arriving, it seems, every day). This is why large databases and large
    web server systems tend to use expensive Unix-based RISC systems rather than 80x86
    systems.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 多处理是RISC CPU相对于英特尔CPU的一个重要优势领域。虽然英特尔80x86系统在大约32个处理器时会遇到收益递减的情况，Sun SPARC和其他RISC处理器则轻松支持64个CPU系统（而且似乎每天都有更多的处理器问世）。这就是为什么大型数据库和大型网页服务器系统倾向于使用昂贵的基于Unix的RISC系统，而非80x86系统。
- en: Newer versions of the Intel i-series and Xeon processors support a hybrid form
    of multiprocessing known as *[hyperthreading](gloss01.xhtml#gloss01_113)*. The
    idea behind hyperthreading is deceptively simple—in a typical superscalar processor
    it’s rare for an instruction sequence to utilize all the CPU’s functional units
    on each clock cycle. Rather than allow those functional units to go unused, the
    CPU can run two separate threads of execution concurrently and keep all the functional
    units occupied. This allows a single CPU to effectively do the work of 1.5 CPUs
    in a typical multiprocessor system.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 更新版的英特尔i系列和Xeon处理器支持一种称为*[超线程技术](gloss01.xhtml#gloss01_113)*的混合多处理方式。超线程技术背后的理念看似简单——在典型的超标量处理器中，很少有指令序列能够在每个时钟周期内充分利用CPU的所有功能单元。与其让这些功能单元空闲，CPU可以同时运行两个独立的执行线程，从而保持所有功能单元都在工作。这使得单个CPU在典型的多处理器系统中，能够有效地完成相当于1.5个CPU的工作量。
- en: '**9.6 For More Information**'
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**9.6 更多信息**'
- en: 'Hennessy, John L., and David A. Patterson. *Computer Architecture: A Quantitative
    Approach*. 5th ed. Waltham, MA: Elsevier, 2012.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 'Hennessy, John L., 和 David A. Patterson. *计算机架构：定量方法*. 第5版. Waltham, MA: Elsevier,
    2012.'
- en: '**NOTE**'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*One subject missing from this chapter is the design of the CPU’s actual instruction
    set. That is the subject of the next chapter.*'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章中缺少的一个主题是CPU实际指令集的设计。这是下一章的内容。*'
