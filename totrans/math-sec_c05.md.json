["```\n{\n  ❶ \"id\": 4912964953915055,\n    \"created_at\": \"2019-5-22 23:03:22\",\n  ❷ \"content\": \"Process within summer especially song when letter nearly.\",\n    \"source\": \"Data Faker\",\n  ❸ \"in_reply_to_screen_name\": \"Some User\",\n    \"in_reply_to_id\": 1234334523168,\n    \"in_reply_to_account_id\": 346835683,\n  ❹ \"account\": {\n        \"id\": \"6336091949992\",\n        \"screen_name\": \"juliekennedy\",\n        \"location\": \"846 Adam Spring #616\\nE Chicago, IL 21342\",\n        \"description\": \"Faked profile Data\",\n        \"url\": \"http://www.smith.com/\"\n    },\n  ❺ \"reblog_count\": 0,\n    \"liked_count\": 0\n}\n```", "```\n❶ import pandas as pd\nimport json\n\n❷ def user_to_series(dict_obj):\n    \"\"\"Convert a nested JSON user into a flat series\"\"\"\n    renamed = {}\n    for k in dict_obj.keys():\n        nk = \"user_%s\" % k\n        v = dict_obj[k]\n        renamed[nk] = v\n    ret = pd.Series(renamed)\n    return ret\n\nseries_data = [] # 1 JSON object per post object\n❸ with open(\"fake_posts.json\") as data:\n    text = data.read().strip()\n    rows = text.split(\"\\n\") # JSON objects stored as list of strings\nfor row in rows:\n  ❹ obj = json.loads(row)   # Converted row string to JSON object\n    series_data.append(obj) # Add to JSON list\n\n❺ t_df = pd.DataFrame(series_data) # 1 row per JSON object\n❻ post_df = pd.concat([t_df, t_df[\"account\"].apply(user_to_series)], axis=1)\n# Data is flat now. Remove the original JSON object feature.\n❼ post_df.drop(\"account\", axis=1, inplace=True)\n```", "```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28034 entries, 0 to 28033\nData columns (total 14 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   id                       28034 non-null  int64  \n 1   created_at               28034 non-null  object \n 2   source                   28034 non-null  object \n 3   content                  28034 non-null  object \n 4   in_reply_to_account_id   10302 non-null  object \n 5   in_reply_to_id           10302 non-null  float64\n 6   reblogs_count            28034 non-null  int64  \n 7   favourites_count         28034 non-null  int64  \n 8   user_id                  28034 non-null  object \n 9   user_screen_name         28034 non-null  object \n 10  user_location            28034 non-null  object \n 11  user_description         28034 non-null  object \n 12  user_url                 28034 non-null  object \n 13  in_reply_to_screen_name  10302 non-null  object \ndtypes: float64(1), int64(3), object(10)\nmemory usage: 3.0+ MB\n```", "```\n❶ G = nx.DiGraph()\n❷ for idx in post_df.index:\n  ❸ row = post_df.loc[idx]\n  ❹ G.add_edge(\n      row[\"in_reply_to_screen_name\"], row[\"user_screen_name\"],\n    ❺ capacity=len(row[\"content\"])\n    )\nprint(len(G.nodes))\n```", "```\n❶ o_posts = post_df[post_df[\"in_reply_to_screen_name\"].isna() == True]\nr_posts = post_df[post_df[\"in_reply_to_id\"].isna() == False]\nif len(r_posts.index.to_list()) != 0:\n  ❷ replied_to = r_posts[\"in_reply_to_id\"].values\n  ❸ o_no_r = o_posts.loc[o_posts[\"id\"].isin(replied_to) == False]\n    p_len = float(len(o_no_r.index.to_list()))\n    o_len = float(len(o_posts.index.to_list()) - p_len)\n  ❹ info_exchange = float(p_len / o_len)\nelse:\n    info_exchange = -1\nprint(\"The RI score is: %.4f \" % info_exchange)\n```", "```\nr_posts = post_df[post_df[\"in_reply_to_id\"].isna() == False]\n```", "```\nuG = nx.to_undirected(G)\ncliques = list(nx.algorithms.clique.find_cliques(uG))\n```", "```\n❶ deg_ct = G.out_degree()\nsorted_deg = sorted(deg_ct, key=lambda kv: kv[1])\ntop_source = sorted_deg[-1]\n❷ source_cliques = [c for c in cliques if top_source[0] in c]\n❸ sG = G.subgraph(source_cliques[0])\n```", "```\nconda install -y networkx=2.6.3\n```", "```\n❶ post_df[\"content\"] = post_df[\"content\"].str.lower()\n❷ env = post_df[post_df[\"content\"].str.contains(\"environment\")]\n❸ repl = post_df[post_df[\"in_reply_to_id\"].isin(env[\"id\"].values)]\nhG = nx.DiGraph()\nfor idx in repl.index:\n    row = repl.loc[idx]\n  ❹ hG.add_edge(row[\"in_reply_to_screen_name\"], row[\"user_screen_name\"])\n❺ hub_scores, auth_scores = nx.hits(hG, max_iter=1000, tol=0.01)\n```", "```\n❶ ancestors = list(nx.all_pairs_lowest_common_ancestor(G))\npred_count = {}\nfor p, lca in ancestors:\n  ❷ if p not in G.edges():\n        if lca in pred_count.keys():\n          ❸ pred_count[lca] += 1\n        else:\n          ❹ pred_count[lca] = 1\nsorted_pred = sorted(pred_count.items(), key=lambda kv: kv[1], reverse=True)\n\nfor k in sorted_pred[0:5]:\n    print(\"%s can bridge %d new connection\" % (k[0], k[1]))\n```", "```\ngeorgejohnson can bridge 444 new connection\ndannyhoover can bridge 444 new connection\nvkhan can bridge 372 new connection\njudith20 can bridge 336 new connection\ndavid49 can bridge 216 new connection\n```", "```\n❶ from mastodon import Mastodon\nimport pandas as pd\n\n❷ ACCESS_TOKEN = `\"YOUR-TOKEN-HERE\"`\nBASE_URL = \"https://defcon.social\"\n❸ m = Mastodon(access_token=ACCESS_TOKEN, api_base_url=BASE_URL)\n\n❹ timeline_data = m.timeline(timeline=\"public\")\n\ndf = pd.DataFrame(timeline_data)\ndf[\"id\"] = df[\"id\"].astype(dtype=str)\ndf[\"in_reply_to_id\"] = df[\"in_reply_to_id\"].astype(dtype=str)\ndf[\"in_reply_to_account_id\"] = df[\"in_reply_to_account_id\"].astype(dtype=str)\n\nprint(df.info())\n❺ df.to_csv(\"mastodon_timeline.csv\")\n```"]