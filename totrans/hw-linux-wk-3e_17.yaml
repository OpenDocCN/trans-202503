- en: '17'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Virtualization
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: The word *virtual* can be vague in computing systems. It’s used primarily to
    indicate an intermediary that translates a complex or fragmented underlying layer
    to a simplified interface that can be used by multiple consumers. Consider an
    example that we’ve already seen, virtual memory, which allows multiple processes
    to access a large bank of memory as if each had its own insulated bank of memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'That definition is still a bit daunting, so it might be better to explain the
    typical purpose of virtualization: creating isolated environments so that you
    can get multiple systems to run without clashing.'
  prefs: []
  type: TYPE_NORMAL
- en: Because virtual machines are relatively easy to understand at a higher level,
    that’s where we’ll start our tour of virtualization. However, the discussion will
    remain on that higher level, aiming to explain some of the many terms you may
    encounter when working with virtual machines, without getting into the vast sea
    of implementation specifics.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll go into a bit more technical detail on containers. They’re built with
    the technology you’ve already seen in this book, so you can see how these components
    can be combined. In addition, it’s relatively easy to interactively explore containers.
  prefs: []
  type: TYPE_NORMAL
- en: 17.1 Virtual Machines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Virtual machines are based on the same concept as virtual memory, except with
    *all* of the machine’s hardware instead of just memory. In this model, you create
    an entirely new machine (processor, memory, I/O interfaces, and so on) with the
    help of software, and run a whole operating system in it—including a kernel. This
    type of virtual machine is more specifically called a *system virtual machine*,
    and it’s been around for decades. For example, IBM mainframes traditionally use
    system virtual machines to create a multiuser environment; in turn, users get
    their own virtual machine running CMS, a simple single-user operating system.
  prefs: []
  type: TYPE_NORMAL
- en: You can construct a virtual machine entirely in software (usually called an
    *emulator*) or by utilizing the underlying hardware as much as possible, as is
    done in virtual memory. For our purposes in Linux, we’ll look at the latter kind
    due to its superior performance, but note that a number of popular emulators support
    old computer and gaming systems, such as the Commodore 64 and Atari 2600.
  prefs: []
  type: TYPE_NORMAL
- en: The world of virtual machines is diverse, with a tremendous amount of terminology
    to wade through. Our exploration of virtual machines will focus primarily on how
    that terminology relates to what you might experience as a typical Linux user.
    We’ll also discuss some of the differences you might encounter in virtual hardware.
  prefs: []
  type: TYPE_NORMAL
- en: 17.1.1  Hypervisors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Overseeing one or more virtual machines on a computer is a piece of software
    called a *hypervisor* or *virtual machine monitor (VMM)*, which works similarly
    to how an operating system manages processes. There are two types of hypervisors,
    and the way you use a virtual machine depends on the type. To most users, the
    *type 2 hypervisor* is the most familiar, because it runs on a normal operating
    system such as Linux. For example, VirtualBox is a type 2 hypervisor, and you
    can run it on your system without extensive modifications. You might have already
    used it while reading this book to test and explore different kinds of Linux systems.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, a *type 1 hypervisor* is more like its own operating system
    (especially the kernel), built specifically to run virtual machines quickly and
    efficiently. This kind of hypervisor might occasionally employ a conventional
    companion system such as Linux to help with management tasks. Even though you
    might never run one on your own hardware, you interact with type 1 hypervisors
    all the time. All cloud computing services run as virtual machines under type
    1 hypervisors such as Xen. When you access a website, you’re almost certainly
    hitting software running on such a virtual machine. Creating an instance of an
    operating system on a cloud service such as AWS is creating a virtual machine
    on a type 1 hypervisor.
  prefs: []
  type: TYPE_NORMAL
- en: In general, a virtual machine with its operating system is called a *guest*.
    The *host* is whatever runs the hypervisor. For type 2 hypervisors, the host is
    just your native system. For type 1 hypervisors, the host is the hypervisor itself,
    possibly combined with a specialized companion system.
  prefs: []
  type: TYPE_NORMAL
- en: 17.1.2  Hardware in a Virtual Machine
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In theory, it should be straightforward for the hypervisor to provide hardware
    interfaces for a guest system. For example, to provide a virtual disk device,
    you could create a big file somewhere on the host and provide access as a disk
    with standard device I/O emulation. This approach is a strict hardware virtual
    machine; however, it is inefficient. Making virtual machines practical for a variety
    of needs requires some changes.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the differences you might encounter between real and virtual hardware
    are a result of a bridging that allows guests to access host resources more directly.
    Bypassing virtual hardware between the host and guest is known as *paravirtualization*.
    Network interfaces and block devices are among the most likely to receive this
    treatment; for example, a */dev/xvd* device on a cloud computing instance is a
    Xen virtual disk, using a Linux kernel driver to talk directly to the hypervisor.
    Sometimes paravirtualization is used for the sake of convenience; for example,
    on a desktop-capable system such as VirtualBox, drivers are available to coordinate
    the mouse movement between the virtual machine window and the host environment.
  prefs: []
  type: TYPE_NORMAL
- en: Whatever the mechanism, the goal of virtualization is always to reduce the problem
    just enough so that the guest operating system can treat the virtual hardware
    as it would any other device. This ensures that all of the layers on top of the
    device function properly. For example, on a Linux guest system, you want a kernel
    to be able to access virtual disks as block devices so that you can partition
    and create filesystems on them with the usual tools.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual Machine CPU Modes
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most of the details about how virtual machines work are beyond the scope of
    this book, but the CPU deserves a mention because we’ve already talked about the
    difference between kernel mode and user mode. The specific names of these modes
    vary depending on the processor (for example, the x86 processors use a system
    called *privilege rings*), but the idea is always the same. In kernel mode, the
    processor can do almost anything; in user mode, some instructions are not allowed,
    and memory access is limited.
  prefs: []
  type: TYPE_NORMAL
- en: The first virtual machines for the x86 architecture ran in user mode. This presented
    a problem, because the kernel running inside the virtual machine wants to be in
    kernel mode. To counter this, the hypervisor can detect and react to (“trap”)
    any restricted instructions coming from a virtual machine. With a little work,
    the hypervisor emulates the restricted instructions, enabling virtual machines
    to run in kernel mode on an architecture not designed for it. Because most of
    the instructions a kernel executes aren’t restricted, those run normally, and
    the performance impact is fairly minimal.
  prefs: []
  type: TYPE_NORMAL
- en: Soon after the introduction of this kind of hypervisor, processor manufacturers
    realized that there was a market for processors that could assist the hypervisor
    by eliminating the need for the instruction trap and emulation. Intel and AMD
    released these feature sets as VT-x and AMD-V, respectively, and most hypervisors
    now support them. In some cases, they are required.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to learn more about virtual machines, start with Jim Smith and
    Ravi Nair’s *Virtual Machines: Versatile Platforms for Systems and Processes*
    (Elsevier, 2005). This also includes coverage of *process virtual machines*, such
    as the Java virtual machine (JVM), which we won’t discuss here.'
  prefs: []
  type: TYPE_NORMAL
- en: 17.1.3  Common Uses of Virtual Machines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the Linux world, virtual machine use often falls into one of a few categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Testing and trials There are many use cases for virtual machines when you need
    to try something outside of a normal or production operating environment. For
    example, when you’re developing production software, it’s essential to test software
    in a machine separate from the developer’s. Another use is to experiment with
    new software, such as a new distribution, in a safe and “disposable” environment.
    Virtual machines allow you to do this without having to purchase new hardware.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Application compatibility When you need to run something under an operating
    system that differs from your normal one, virtual machines are essential.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Servers and cloud services As mentioned earlier, all cloud services are built
    on virtual machine technology. If you need to run an internet server, such as
    a web server, the quickest way to do so is to pay a cloud provider for a virtual
    machine instance. Cloud providers also offer specialized servers, such as databases,
    which are just preconfigured software sets running on virtual machines.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 17.1.4  Drawbacks of Virtual Machines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For many years, virtual machines have been the go-to method of isolating and
    scaling services. Because you can create virtual machines through a few clicks
    or an API, it’s very convenient to create servers without having to install and
    maintain hardware. That said, some aspects remain troublesome in day-to-day operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*It can be cumbersome and time-consuming to install and/or configure the system
    and application*. Tools such as Ansible can automate this process, but it still
    takes a significant amount of time to bring up a system from scratch. If you’re
    using virtual machines to test software, you can expect this time to accumulate
    quickly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Even when configured properly, virtual machines start and reboot relatively
    slowly*. There are a few ways around this, but you’re still booting a full Linux
    system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*You have to maintain a full Linux system, keeping current with updates and
    security on each virtual machine*. These systems have systemd and sshd, as well
    as any tools on which your application depends.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Your application might have some conflicts with the standard software set
    on a virtual machine*. Some applications have strange dependencies, and they don’t
    always get along well with the software found on a production machine. In addition,
    dependencies like libraries can change with an upgrade in the machine, breaking
    things that once worked.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Isolating your services on separate virtual machines can be wasteful and costly*.
    The standard industry practice is to run no more than one application service
    on a system, which is robust and easier to maintain. In addition, some services
    can be further segmented; if you run multiple websites, it’s preferable to keep
    them on different servers. However, this is at odds with keeping costs down, especially
    when you’re using cloud services, which charge per virtual machine instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These problems are really no different from the ones you’d encounter running
    services on real hardware, and they aren’t necessarily impediments in small operations.
    However, once you start running more services, they’ll become more noticeable,
    costing time and money. This is when you might consider containers for your services.
  prefs: []
  type: TYPE_NORMAL
- en: 17.2 Containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Virtual machines are great for insulating an entire operating system and its
    set of running applications, but sometimes you need a lighter-weight alternative.
    Container technology is now a popular way to fulfill this need. Before we go into
    the details, let’s take a step back to see its evolution.
  prefs: []
  type: TYPE_NORMAL
- en: The traditional way of operating computer networks was to run multiple services
    on the same physical machine; for example, a name server could also act as an
    email server and perform other tasks. However, you shouldn’t really trust any
    software, including servers, to be secure or stable. To enhance the security of
    the system and to keep services from interfering with one another, there are some
    basic ways to put up barriers around server daemons, especially when you don’t
    trust one of them very much.
  prefs: []
  type: TYPE_NORMAL
- en: One method of service isolation is using the `chroot()` system call to change
    the root directory to something other than the actual system root. A program can
    change its root to something like */var/spool/my_service* and no longer be able
    to access anything outside that directory. In fact, there is a `chroot` program
    that allows you to run a program with a new root directory. This type of isolation
    is sometimes called a *chroot jail* because processes can’t (normally) escape
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Another type of restriction is the resource limit (rlimit) feature of the kernel,
    which restricts how much CPU time a process can consume or how big its files can
    be.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the ideas that containers are built on: you’re altering the environment
    and restricting the resources with which processes run. Although there’s no single
    defining feature, a *container* can be loosely defined as a restricted runtime
    environment for a set of processes, the implication being that those processes
    can’t touch anything on the system outside that environment. In general, this
    is called *operating system–level virtualization*.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to keep in mind that a machine running one or more containers
    still has only one underlying Linux kernel. However, the processes inside a container
    can use the user-space environment from a Linux distribution different than the
    underlying system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The restrictions in containers are built with a number of kernel features.
    Some of the important aspects of processes running in a container are:'
  prefs: []
  type: TYPE_NORMAL
- en: They have their own cgroups.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They have their own devices and filesystem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They cannot see or interact with any other processes on the system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They have their own network interfaces.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pulling all of those things together is a complicated task. It’s possible to
    alter everything manually, but it can be challenging; just getting a handle on
    the cgroups for a process is tricky. To help you along, many tools can perform
    the necessary subtasks of creating and managing effective containers. Two of the
    most popular are Docker and LXC. This chapter focuses on Docker, but we’ll also
    touch on LXC to see how it differs.
  prefs: []
  type: TYPE_NORMAL
- en: 17.2.1  Docker, Podman, and Privileges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To run the examples in this book, you need a container tool. The examples here
    are built with Docker, which you can normally install with a distribution package
    without any trouble.
  prefs: []
  type: TYPE_NORMAL
- en: There is an alternative to Docker called Podman. The primary difference between
    the two tools is that Docker requires a server to be running when using containers,
    while Podman does not. This affects the way the two systems set up containers.
    Most Docker configurations require superuser privileges to access the kernel features
    used by its containers, and the dockerd daemon does the relevant work. In contrast,
    you can run Podman as a normal user, called *rootless* operation. When run this
    way, it uses different techniques to achieve isolation.
  prefs: []
  type: TYPE_NORMAL
- en: You can also run Podman as the superuser, causing it to switch over to some
    of the isolation techniques that Docker uses. Conversely, newer versions of dockerd
    support a rootless mode.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, Podman is command line–compatible with Docker. This means you can
    substitute `podman` for `docker` in the examples here, and they’ll still work.
    However, there are differences in the implementations, especially when you’re
    running Podman in rootless mode, so those will be noted where applicable.
  prefs: []
  type: TYPE_NORMAL
- en: 17.2.2  A Docker Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The easiest way to familiarize yourself with containers is to get hands-on.
    The Docker example here illustrates the principal features that make containers
    work, but providing an in-depth user manual is beyond the scope of this book.
    You should have no trouble understanding the online documentation after reading
    this, and if you’re looking for an extensive guide, try Nigel Poulton’s *Docker
    Deep Dive* (author, 2016).
  prefs: []
  type: TYPE_NORMAL
- en: First you need to create an *image*, which comprises the filesystem and a few
    other defining features for a container to run with. Your images will nearly always
    be based on prebuilt ones downloaded from a repository on the internet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Install Docker on your system (your distribution’s add-on package is probably
    fine), make a new directory somewhere, change to that directory, and create a
    file called *Dockerfile* containing these lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This configuration uses the lightweight Alpine distribution. The only change
    we’re making is adding the bash shell, which we’re doing not just for an added
    measure of interactive usability but also to create a unique image and see how
    that procedure works. It’s possible (and common) to use public images and make
    no changes to them whatsoever. In that case, you don’t need a Dockerfile.
  prefs: []
  type: TYPE_NORMAL
- en: 'Build the image with the following command, which reads the Dockerfile in the
    current directory and applies the identifier `hlw_test` to the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Be prepared for a lot of output. Don’t ignore it; reading through it this first
    time will help you understand how Docker works. Let’s break it up into the steps
    that correspond to the lines of the Dockerfile. The first task is to retrieve
    the latest version of the Alpine distribution container from the Docker registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Notice the heavy use of SHA256 digests and shorter identifiers. Get used to
    them; Docker needs to track many little pieces. In this step, Docker has created
    a new image with the identifier `f70734b6a266` for the basic Alpine distribution
    image. You can refer to that specific image later, but you probably won’t need
    to, because it’s not the final image. Docker will build more on top of it later.
    An image that isn’t intended to be a final product is called an *intermediate
    image*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next part of our configuration is the bash shell package installation in
    Alpine. As you read the following, you’ll probably recognize output that results
    from the `apk add bash` command (shown in bold):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: What’s not so obvious is *how* that’s happening. When you think about it, you
    probably aren’t running Alpine on your own machine here. So how can you run the
    `apk` command that belongs to Alpine already?
  prefs: []
  type: TYPE_NORMAL
- en: The key is the line that says `Running in 4f0fb4632b31`. You haven’t asked for
    a container yet, but Docker has set up a new container with the intermediate Alpine
    image from the previous step. Containers have identifiers as well; unfortunately,
    they look no different from image identifiers. To add to the confusion, Docker
    calls the temporary container an *intermediate container*, which differs from
    an intermediate image. Intermediate images stay around after a build; intermediate
    containers do not.
  prefs: []
  type: TYPE_NORMAL
- en: After setting up the (temporary) container with ID `4f0fb4632b31`, Docker ran
    the `apk` command inside that container to install bash, and then saved the resulting
    changes to the filesystem into a new intermediate image with the ID `12ef4043c80a`.
    Notice that Docker also removes the container after completion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, Docker makes the final changes required to run a bash shell when starting
    a container from the new image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, you now have a final image with the ID `1b64f94e5a54`, but
    because you tagged it (in two separate steps), you can also refer to it as `hlw_test`
    or `hlw_test:latest`. Run `docker images` to verify that your image and the Alpine
    image are present:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Running Docker Containers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You’re now ready to start a container. There are two basic ways to run something
    in a container with Docker: you can either create the container and then run something
    inside it (in two separate steps), or you can simply create and run in one step.
    Let’s jump right into it and start one with the image that you just built:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You should get a bash shell prompt where you can run commands in the container.
    That shell will run as the root user.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’re the curious type, you’ll probably want to take a look around the
    container. Run some commands, such as `mount` and `ps`, and explore the filesystem
    in general. You’ll quickly notice that although most things look like a typical
    Linux system, others do not. For example, if you run a complete process listing,
    you’ll get just two entries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Somehow, in the container, the shell is process ID 1 (remember, on a normal
    system, this is init), and nothing else is running except for the process listing
    that you’re executing.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, it’s important to remember that these processes are simply ones
    that you can see on your normal (host) system. If you open another shell window
    on your host system, you can find a container process in a listing, though it
    will require a little searching. It should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This is our first encounter with one of the kernel features used for containers:
    Linux kernel *namespaces* specifically for process IDs. A process can create a
    whole new set of process IDs for itself and its children, starting at PID 1, and
    then they are able to see only those.'
  prefs: []
  type: TYPE_NORMAL
- en: Overlay Filesystems
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Next, explore the filesystem in your container. You’ll find it’s somewhat minimal;
    this is because it’s based on the Alpine distribution. We’re using Alpine not
    just because it’s small, but also because it’s likely to be different from what
    you’re used to. However, when you take a look at the way the root filesystem is
    mounted, you’ll see it’s very different from a normal device-based mount:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This is an *overlay filesystem*, a kernel feature that allows you to create
    a filesystem by combining existing directories as layers, with changes stored
    in a single spot. If you look on your host system, you’ll see it (and have access
    to the component directories), and you’ll also find where Docker attached the
    original mount.
  prefs: []
  type: TYPE_NORMAL
- en: In the mount output, you’ll see the `lowerdir`, `upperdir`, and `workdir` directory
    parameters. The lower directory is actually a colon-separated series of directories,
    and if you look them up on your host system, you’ll find that the last one 1 is
    the base Alpine distribution that was set up in the first step of the image build
    (just look inside; you’ll see the distribution root directory). If you follow
    the two preceding directories, you’ll see they correspond to the other two build
    steps. Therefore, these directories “stack” on top of each other in order from
    right to left.
  prefs: []
  type: TYPE_NORMAL
- en: The upper directory goes on top of those, and it’s also where any changes to
    the mounted filesystem appear. It doesn’t have to be empty when you mount it,
    but for containers, it doesn’t make much sense to put anything there to start.
    The work directory is a place for the filesystem driver to do its work before
    writing changes to the upper directory, and it must be empty upon mount.
  prefs: []
  type: TYPE_NORMAL
- en: As you can imagine, container images with many build steps have quite a few
    layers. This is sometimes a problem, and there are various strategies to minimize
    the number of layers, such as combining `RUN` commands and multistage builds.
    We won’t go into details about those here.
  prefs: []
  type: TYPE_NORMAL
- en: Networking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although you can choose to have a container run in the same network as the host
    machine, you normally want some kind of isolation in the network stack for safety.
    There are several ways to achieve this in Docker, but the default (and most common)
    is called a bridge network, using another kind of namespace—the network namespace
    (netns). Before running anything, Docker creates a new network interface (usually
    *docker0*) on the host system, typically assigned to a private network such as
    172.17.0.0/16, so the interface in this case would be assigned to 172.17.0.1\.
    This network is for communication between the host machine and its containers.
  prefs: []
  type: TYPE_NORMAL
- en: Then, when creating a container, Docker creates a new network namespace, which
    is almost completely empty. At first, the new namespace (which will be the one
    in the container) contains only a new, private loopback (*lo*) interface. To prepare
    the namespace for actual use, Docker creates a *virtual interface* on the host,
    which simulates a link between two actual network interfaces (each with its own
    device) and places one of those devices in the new namespace. With a network configuration
    using an address on the Docker network (172.17.0.0/16 in our case) on the device
    in the new namespace, processes can send packets on that network and be received
    on the host. This can be confusing, because different interfaces in different
    namespaces can have the same name (for example, the container’s can be *eth0*,
    as well as the host machine).
  prefs: []
  type: TYPE_NORMAL
- en: Because this uses a private network (and a network administrator probably wouldn’t
    want to route anything to and from these containers blindly), if left this way,
    the container processes using that namespace couldn’t reach the outside world.
    To make it possible to reach outside hosts, the Docker network on the host configures
    NAT.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 17-1](#figure17-1) shows a typical setup. It includes the physical
    layer with the interfaces, as well as the internet layer of the Docker subnet
    and the NAT linking this subnet to the rest of the host machine and its outside
    connections.'
  prefs: []
  type: TYPE_NORMAL
- en: '![f17001](image_fi/500402c17/f17001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-1: Bridge network in Docker. The thick link represents the virtual
    interface pair bond.'
  prefs: []
  type: TYPE_NORMAL
- en: Rootless operation networking in Podman is different because setting up virtual
    interfaces requires superuser access. Podman still uses a new network namespace,
    but it needs an interface that can be set up to operate in user space. This is
    a TAP interface (usually at *tap0*), and in conjunction with a forwarding daemon
    called slirp4netns, container processes can reach the outside world. This is less
    capable; for example, containers cannot connect to one another.
  prefs: []
  type: TYPE_NORMAL
- en: There’s a lot more to networking, including how to expose ports in the container’s
    network stack for external services to use, but the network topology is the most
    important thing to understand.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Operation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At this point, we could continue with a discussion of the various other kinds
    of isolation and restrictions that Docker enables, but it would take a long time
    and you probably get the point by now. Containers don’t come from one particular
    feature, but rather a collection of them. A consequence is that Docker must keep
    track of all of the things we do when creating a container and must also be able
    to clean them up.
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker defines a container as “running” as long as it has a process running.
    You can show the currently running containers with `docker ps`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As soon as all of its processes terminate, Docker puts them in an exit state,
    but it still keeps the containers (unless you start with the `--rm` option). This
    includes the changes made to the filesystem. You can easily access the filesystem
    with `docker export`.
  prefs: []
  type: TYPE_NORMAL
- en: You need to be aware of this, because `docker ps` doesn’t show exited containers
    by default; you have to use the `-a` option to see everything. It’s really easy
    to accumulate a large pile of exited containers, and if the application running
    in the container creates a lot of data, you can run out of disk space and not
    know why. Use `docker rm` to remove a terminated container.
  prefs: []
  type: TYPE_NORMAL
- en: 'This also applies to old images. Developing an image tends to be a repetitive
    process, and when you tag an image with the same tag as an existing image, Docker
    doesn’t remove the original image. The old image simply loses that tag. If you
    run `docker images` to show all the images on your system, you can see all of
    the images. Here’s an example showing a previous version of an image without a
    tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Use `docker rmi` to remove an image. This also removes any unnecessary intermediate
    images that the image builds on. If you don’t remove images, they can add up over
    time. Depending on what’s in the images and how they are built, this can consume
    a significant amount of storage space on your system.
  prefs: []
  type: TYPE_NORMAL
- en: In general, Docker does a lot of meticulous versioning and checkpointing. This
    layer of management reflects a particular philosophy compared to tools like LXC,
    which you’ll see soon.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Service Process Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One potentially confusing aspect of Docker containers is the lifecycle of the
    processes inside them. Before a process can completely terminate, its parent is
    supposed to collect (“reap”) its exit code with the `wait()` system call. However,
    in a container, there are some situations in which dead processes can remain because
    their parents don’t know how to react. Along with the way that many images are
    configured, this might lead you to conclude that you’re not supposed to run multiple
    processes or services inside a Docker container. This is not correct.
  prefs: []
  type: TYPE_NORMAL
- en: You can have many processes in a container. The shell we ran in our example
    starts a new child process when you run a command. The only thing that really
    matters is that when you have child processes, the parent cleans up upon their
    exit. Most parents do this, but in certain circumstances, you might run into a
    situation where one does not, especially if it doesn’t know that it has children.
    This can happen when there are multiple levels of process spawning, and the PID
    1 inside the container ends up being the parent of a child that it doesn’t know
    about.
  prefs: []
  type: TYPE_NORMAL
- en: To remedy this, if you have a simple single-minded service that just spawns
    some processes and seems to leave lingering processes even when a container is
    supposed to terminate, you can add the `--init` option to `docker run`. This creates
    a very simple init process to run as PID 1 in the container and act as a parent
    that knows what to do when a child process terminates.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you’re running multiple services or tasks inside a container (such
    as multiple workers for some job server), instead of starting them with a script,
    you might consider using a process management daemon such as Supervisor (supervisord)
    to start and monitor them. This not only provides the necessary system functionality,
    but also gives you more control over service processes.
  prefs: []
  type: TYPE_NORMAL
- en: On that note, if you’re thinking about this kind of model for a container, there’s
    a different option that you might consider, and it doesn’t involve Docker.
  prefs: []
  type: TYPE_NORMAL
- en: 17.2.3  LXC
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our discussion has revolved around Docker not only because it’s the most popular
    system for building container images, but also because it makes it very easy to
    get started and jump into the layers of isolation that containers normally provide.
    However, there are other packages for creating containers, and they take different
    approaches. Of these, LXC is one of the oldest. In fact, the first versions of
    Docker were built on LXC. If you understood the discussion of how Docker does
    its work, you won’t have trouble with LXC technical concepts, so we won’t go over
    any examples. Instead, we’ll just explore some of the practical differences.
  prefs: []
  type: TYPE_NORMAL
- en: The term *LXC* is sometimes used to refer to the set of kernel features that
    make containers possible, but most people use it to refer specifically to a library
    and package containing a number of utilities for creating and manipulating Linux
    containers. Unlike Docker, LXC involves a fair amount of manual setup. For example,
    you have to create your own container network interface, and you need to provide
    user ID mappings.
  prefs: []
  type: TYPE_NORMAL
- en: Originally, LXC was intended to be as much of an entire Linux system as possible
    inside the container—init and all. After installing a special version of a distribution,
    you could install everything you needed for whatever you were running inside the
    container. That part isn’t too different from what you’ve seen with Docker, but
    there is more setup to do; with Docker, you just download a bunch of files and
    you’re ready to go.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, you might find LXC more flexible in adapting to different needs.
    For example, by default, LXC doesn’t use the overlay filesystem that you saw with
    Docker, although you can add one. Because LXC is built on a C API, you can use
    this granularity in your own software application if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: An accompanying management package called LXD can help you work through some
    of LXC’s finer, manual points (such as network creation and image management)
    and offers a REST API that you can use to access LXC instead of the C API.
  prefs: []
  type: TYPE_NORMAL
- en: 17.2.4  Kubernetes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Speaking of management, containers have become popular for many kinds of web
    servers, because you can start a bunch of containers from a single image across
    multiple machines, providing excellent redundancy. Unfortunately, this can be
    difficult to manage. You need to perform tasks such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Track which machines are able to run containers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start, monitor, and restart containers on those machines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure container startup.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure the container networking as required.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load new versions of container images and update all running containers gracefully.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That isn’t a complete list, nor does it properly convey the complexity of each
    task. Software was begging to be developed for it, and among the solutions that
    appeared, Google’s Kubernetes has become dominant. Perhaps one of the largest
    contributing factors for this is its ability to run Docker container images.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes has two basic sides, much like any client-server application. The
    server involves the machine(s) available to run containers, and the client is
    primarily a set of command-line utilities that launch and manipulate sets of containers.
    The configuration files for containers (and the groups they form) can be extensive,
    and you’ll quickly find that most of the work involved on the client side is creating
    the appropriate configuration.
  prefs: []
  type: TYPE_NORMAL
- en: You can explore the configuration on your own. If you don’t want to deal with
    setting up the servers yourself, use the Minikube tool to install a virtual machine
    running a Kubernetes cluster on your own machine.
  prefs: []
  type: TYPE_NORMAL
- en: 17.2.5  Pitfalls of Containers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you think about how a service like Kubernetes works, you’ll also realize
    that a system utilizing containers is not without its costs. At minimum, you still
    need one or more machines on which to run your containers, and this has to be
    a full-fledged Linux machine, whether it’s on real hardware or a virtual machine.
    There’s still a maintenance cost here, although it might be simpler to maintain
    this core infrastructure than a configuration that requires many custom software
    installations.
  prefs: []
  type: TYPE_NORMAL
- en: That cost can take several forms. If you choose to administer your own infrastructure,
    that’s a significant investment of time, and still has hardware, hosting, and
    maintenance costs. If you instead opt to use a container service like a Kubernetes
    cluster, you’ll be paying the monetary cost of having someone else do the work
    for you.
  prefs: []
  type: TYPE_NORMAL
- en: 'When thinking of the containers themselves, keep in mind the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Containers can be wasteful in terms of storage*. In order for any application
    to function inside a container, the container must include all the necessary support
    of a Linux operating system, such as shared libraries. This can become quite large,
    especially if you don’t pay particular attention to the base distribution that
    you choose for your containers. Then, consider your application itself: how big
    is it? This situation is mitigated somewhat when you’re using an overlay filesystem
    with several copies of the same container, because they share the same base files.
    However, if your application creates a lot of runtime data, the upper layers of
    all of those overlays can grow large.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*You still have to think about other system resources, such as CPU time*. You
    can configure limits on how much containers can consume, but you’re still constrained
    by how much the underlying system can handle. There’s still a kernel and block
    devices. If you overload stuff, then your containers, the system underneath, or
    both will suffer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*You might need to think differently about where you store your data*. In container
    systems such as Docker that use overlay filesystems, the changes made to the filesystem
    during runtime are thrown away after the processes terminate. In many applications,
    all of the user data goes into a database, and then that problem is reduced to
    database administration. But what about your logs? Those are necessary for a well-functioning
    server application, and you still need a way to store them. A separate log service
    is a must for any substantial scale of production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Most container tools and operation models are geared toward web servers*.
    If you’re running a typical web server, you’ll find a great deal of support and
    information about running web servers in containers. Kubernetes, in particular,
    has a lot of safety features for preventing runaway server code. This can be an
    advantage, because it compensates for how (frankly) poorly written most web applications
    are. However, when you’re trying to run another kind of service, it can sometimes
    feel like you’re trying to drive a square peg into a round hole.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Careless container builds can lead to bloat, configuration problems, and malfunction*.
    The fact that you’re creating an isolated environment doesn’t shield you from
    making mistakes in that environment. You might not have to worry so much about
    the intricacies of systemd, but plenty of other things still can go wrong. When
    problems arise in any kind of system, inexperienced users tend to add things in
    an attempt to make the problem go away, often haphazardly. This can continue (often
    blindly) until at last there’s a somewhat functional system—with many additional
    issues. You need to understand the changes you make.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Versioning can be problematic*. We used the `latest` tag for the examples
    in this book. This is supposed to be the latest (stable) release of a container,
    but it also means that when you build a container based on the latest release
    of a distribution or package, something underneath can change and break your application.
    One standard practice is to use a specific version tag of a base container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Trust can be an issue*. This applies particularly to images built with Docker.
    When you base your containers on those in the Docker image repository, you’re
    placing trust in an additional layer of management that they haven’t been altered
    to introduce even more security problems than usual, and that they’ll be there
    when you need them. This contrasts with LXC, where you’re encouraged to build
    your own to a certain degree.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When considering these issues, you might think that containers have a lot of
    disadvantages compared to other ways of managing system environments. However,
    that’s not the case. No matter what approach you choose, these problems are present
    in some degree and form—and some of them are easier to manage in containers. Just
    remember that containers won’t solve every problem. For example, if your application
    takes a long time to start on a normal system (after booting), it will also start
    slowly in a container.
  prefs: []
  type: TYPE_NORMAL
- en: 17.3 Runtime-Based Virtualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A final kind of virtualization to mention is based on the type of environment
    used to develop an application. This differs from the system virtual machines
    and containers that we’ve seen so far, because it doesn’t use the idea of placing
    applications onto different machines. Instead, it’s a separation that applies
    only to a particular application.
  prefs: []
  type: TYPE_NORMAL
- en: The reason for these kinds of environments is that multiple applications on
    the same system can use the same programming language, causing potential conflicts.
    For example, Python is used in several places on a typical distribution and can
    include many add-on packages. If you want to use the system’s version of Python
    in your own package, you can run into trouble if you want a different version
    of one of the add-ons.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at how Python’s virtual environment feature creates a version of
    Python with only the packages that you want. The way to start is by creating a
    new directory for the environment like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, look inside the new *test-venv* directory. You’ll see a number of system-like
    directories such as *bin*, *include*, and *lib*. To activate the virtual environment,
    you need to source (not execute) the `test-venv/bin/activate` script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The reason for sourcing the execution is that activation is essentially setting
    an environment variable, which you can’t do by running an executable. At this
    point, when you run Python, you get the version in *test-venv/bin* directory (which
    is itself only a symbolic link), and the `VIRTUAL_ENV` environment variable is
    set to the environment base directory. You can run `deactivate` to exit to the
    virtual environment.
  prefs: []
  type: TYPE_NORMAL
- en: It isn’t any more complicated than that. With this environment variable set,
    you get a new, empty packages library in *test-venv/lib*, and anything new you
    install when in the environment goes there instead of in the main system’s library.
  prefs: []
  type: TYPE_NORMAL
- en: Not all programming languages allow virtual environments in the way Python does,
    but it’s worth knowing about it, if for no other reason than to clear up some
    confusion about the word *virtual*.
  prefs: []
  type: TYPE_NORMAL
- en: Bibliography
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Abrahams, Paul W., and Bruce Larson, *UNIX for the Impatient*, 2nd ed. Boston:
    Addison-Wesley Professional, 1995.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Aho, Alfred V., Brian W. Kernighan, and Peter J. Weinberger, *The AWK Programming
    Language*. Boston: Addison-Wesley, 1988.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Aho, Alfred V., Monica S. Lam, Ravi Sethi, and Jeffery D. Ullman, *Compilers:
    Principles, Techniques, and Tools*, 2nd ed. Boston: Addison-Wesley, 2006.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Aumasson, Jean-Philippe, *Serious Cryptography: A Practical Introduction to
    Modern Encryption*. San Francisco: No Starch Press, 2017.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Barrett, Daniel J., Richard E. Silverman, and Robert G. Byrnes, *SSH, The Secure
    Shell: The Definitive Guide*, 2nd ed. Sebastopol, CA: O’Reilly, 2005.'
  prefs: []
  type: TYPE_NORMAL
- en: Beazley, David M., *Python Distilled*. Addison-Wesley, 2021.
  prefs: []
  type: TYPE_NORMAL
- en: 'Beazley, David M., Brian D. Ward, and Ian R. Cooke, “The Inside Story on Shared
    Libraries and Dynamic Loading.” *Computing in Science & Engineering* 3, no. 5
    (September/October 2001): 90–97.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calcote, John, *Autotools: A Practitioner’s Guide to GNU Autoconf, Automake,
    and Libtool*, 2nd ed. San Francisco: No Starch Press, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Carter, Gerald, Jay Ts, and Robert Eckstein, *Using Samba: A File and Print
    Server for Linux, Unix, and Mac OS X*, 3rd ed. Sebastopol, CA: O’Reilly, 2007.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Christiansen, Tom, brian d foy, Larry Wall, and Jon Orwant, *Programming Perl:
    Unmatched Power for Processing and Scripting*, 4th ed. Sebastopol, CA: O’Reilly,
    2012.'
  prefs: []
  type: TYPE_NORMAL
- en: 'chromatic, *Modern Perl*, 4th ed. Hillsboro, OR: Onyx Neon Press, 2016.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Davies, Joshua. *Implementing SSL/TLS Using Cryptography and PKI*. Hoboken,
    NJ: Wiley, 2011.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Friedl, Jeffrey E. F., *Mastering Regular Expressions*, 3rd ed. Sebastopol,
    CA: O’Reilly, 2006.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Gregg, Brendan, *Systems Performance: Enterprise and the Cloud*, 2nd ed. Boston:
    Addison-Wesley, 2020.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Grune, Dick, Kees van Reeuwijk, Henri E. Bal, Ceriel J. H. Jacobs, and Koen
    Langendoen, *Modern Compiler Design*, 2nd ed. New York: Springer, 2012.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hopcroft, John E., Rajeev Motwani, and Jeffrey D. Ullman, *Introduction to
    Automata Theory, Languages, and Computation*, 3rd ed. Upper Saddle River, NJ:
    Prentice Hall, 2006.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kernighan, Brian W., and Rob Pike, *The UNIX Programming Environment*. Upper
    Saddle River, NJ: Prentice Hall, 1984.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kernighan, Brian W., and Dennis M. Ritchie, *The C Programming Language*, 2nd
    ed. Upper Saddle River, NJ: Prentice Hall, 1988.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kochan, Stephen G., and Patrick Wood, *Unix Shell Programming*, 3rd ed. Indianapolis:
    SAMS Publishing, 2003.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Levine, John R., *Linkers and Loaders*. San Francisco: Morgan Kaufmann, 1999.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Lucas, Michael W., *SSH Mastery: OpenSSH, PuTTY, Tunnels, and Keys*, 2nd ed.
    Detroit: Tilted Windmill Press, 2018.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Matloff, Norman, *The Art of R Programming: A Tour of Statistical Software
    Design*. San Francisco: No Starch Press, 2011.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mecklenburg, Robert, *Managing Projects with GNU Make*, 3rd ed. Sebastopol,
    CA: O’Reilly, 2005.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Peek, Jerry, Grace Todino-Gonguet, and John Strang, *Learning the UNIX Operating
    System: A Concise Guide for the New User*, 5th ed. Sebastopol, CA: O’Reilly, 2001.'
  prefs: []
  type: TYPE_NORMAL
- en: Pike, Rob, Dave Presotto, Sean Dorward, Bob Flandrena, Ken Thompson, Howard
    Trickey, and Phil Winterbottom, “Plan 9 from Bell Labs.” Accessed February 1,
    2020, [https://9p.io/sys/doc/.](https://9p.io/sys/doc/)
  prefs: []
  type: TYPE_NORMAL
- en: Poulton, Nigel, *Docker Deep Dive*. Author, 2016.
  prefs: []
  type: TYPE_NORMAL
- en: Quinlan, Daniel, Rusty Russell, and Christopher Yeoh, eds., “Filesystem Hierarchy
    Standard, Version 3.0.” Linux Foundation, 2015, [https://refspecs.linuxfoundation.org/fhs.shtml](https://refspecs.linuxfoundation.org/fhs.shtml).
  prefs: []
  type: TYPE_NORMAL
- en: 'Raymond, Eric S., ed., *The New Hacker’s Dictionary*. 3rd ed. Cambridge, MA:
    MIT Press, 1996.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Robbins, Arnold, *sed & awk Pocket Reference*, 2nd ed. Sebastopol, CA: O’Reilly,
    2002.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Robbins, Arnold, Elbert Hannah, and Linda Lamb, *Learning the vi and Vim Editors:
    Unix Text Processing*, 7th ed. Sebastopol, CA: O’Reilly, 2008.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Salus, Peter H., *The Daemon, the Gnu, and the Penguin*. Tacoma, WA: Reed Media
    Services, 2008.'
  prefs: []
  type: TYPE_NORMAL
- en: Samar, Vipin, and Roland J. Schemers III. “Unified Login with Pluggable Authentication
    Modules (PAM),” October 1995, Open Software Foundation (RFC 86.0), [http://www.opengroup.org/rfc/rfc86.0.html](http://www.opengroup.org/rfc/rfc86.0.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Schwartz, Randal L., brian d foy, and Tom Phoenix, *Learning Perl: Making Easy
    Things Easy and Hard Things Possible*, 7th ed. Sebastopol, CA: O’Reilly, 2016.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Shotts, William, *The Linux Command Line*, 2nd ed. San Francisco: No Starch
    Press, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Silberschatz, Abraham, Peter B. Galvin, and Greg Gagne, *Operating System Concepts*,
    10th ed. Hoboken, NJ: Wiley, 2018.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Smith, Jim, and Ravi Nair, *Virtual Machines: Versatile Platforms for Systems
    and Processes*. Cambridge, MA: Elsevier, 2005.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Stallman, Richard M., *GNU Emacs Manual*, 18th ed. Boston: Free Software Foundation,
    2018.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Stevens, W. Richard, Bill Fenner, and Andrew M. Rudoff, *Unix Network Programming,
    Volume 1: The Sockets Networking API*, 3rd ed. Boston: Addison-Wesley Professional,
    2003.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tanenbaum, Andrew S., and Herbert Bos, *Modern Operating Systems*, 4th ed.
    Upper Saddle River, NJ: Prentice Hall, 2014.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tanenbaum, Andrew S., and David J. Wetherall, *Computer Networks*, 5th ed.
    Upper Saddle River, NJ: Prentice Hall, 2010.'
  prefs: []
  type: TYPE_NORMAL
