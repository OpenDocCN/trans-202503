- en: '**12'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: INPUT AND OUTPUT**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/comm1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'A typical program has three basic tasks: input, computation, and output. So
    far we’ve concentrated on the computational aspects of the computer system, but
    now we’ll turn to input and output.'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will focus on the primitive input/output (I/O) activities of the
    CPU, rather than on the abstract file or character I/O that high-level applications
    usually employ. It will discuss how the CPU transfers data to and from the outside
    world, paying special attention to the performance issues behind I/O operations.
    As all high-level I/O activities are eventually routed through the low-level I/O
    systems, it’s crucial to understand how these processes work if you want to write
    programs that communicate efficiently with the outside world.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.1 Connecting a CPU to the Outside World**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first thing to know is that I/O in a typical computer system is radically
    different from I/O in a typical high-level programming language. At the primitive
    I/O levels of a computer system, you’ll rarely find machine instructions that
    behave like Pascal’s `writeln`, C++’s `cout`, C’s `printf`, Swift’s `print`, or
    even the HLA `stdin` and `stdout` statements. In fact, most I/O machine instructions
    behave exactly like the 80x86’s `mov` instruction. To send data to an output device,
    the CPU simply moves that data to a special memory location; and to read data
    from an input device, the CPU retrieves the data from the device’s address. I/O
    operations behave much like memory read and write operations, except that I/O
    usually involves more wait states.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the CPU’s ability to read and write data at a given port address,
    I/O ports can be grouped into five categories: read-only, write-only, read/write,
    dual I/O, and bidirectional.'
  prefs: []
  type: TYPE_NORMAL
- en: A *read-only port* is an input port. If the CPU can only read the data from
    the port, then the data must come from some source external to the computer system.
    It’s never a good idea to try to write to a read-only port because, although the
    hardware typically ignores such attempts, it can cause some devices to fail. A
    good example of a read-only port is the status port on the original IBM PC’s parallel
    printer interface. Data from this port specifies the current status of the printer,
    while the hardware ignores any data written to this port.
  prefs: []
  type: TYPE_NORMAL
- en: A *write-only port* is always an output port. Data written to such a port is
    available for use by an external device. Attempting to read data from a write-only
    port generally returns whatever garbage value happens to be on the data bus, so
    your programs shouldn’t depend on the meaning of such values. An output port typically
    uses a latch device to hold data to be sent to the outside world. When a CPU writes
    to a port address associated with an output latch, the latch stores the data and
    makes it available on an external set of signal lines (see [Figure 12-1](ch12.xhtml#ch12fig01)).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/12fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-1: A typical write-only port*'
  prefs: []
  type: TYPE_NORMAL
- en: A perfect example of an output port is a parallel printer port. The CPU typically
    writes an ASCII character to a byte-wide output port that connects to the DB-25F
    connector on the back of the computer’s case. A cable transmits this data to the
    printer, where it arrives on the printer’s input port (from the printer’s perspective,
    it is reading the data from the computer system). A processor inside the printer
    typically converts this ASCII character to a sequence of dots that it prints on
    paper.
  prefs: []
  type: TYPE_NORMAL
- en: Output ports can be write-only or read/write. The port in [Figure 12-1](ch12.xhtml#ch12fig01),
    for example, is a write-only port. Because the outputs on the latch do not loop
    back to the CPU’s data bus, the CPU can’t read the data the latch contains. Both
    the address decode line (En) and the write control line (W) must be active for
    the latch to operate. If the CPU tries to read the data located at the latch’s
    address, the address decode line is active but the write control line is not,
    so the latch does not respond to the read request.
  prefs: []
  type: TYPE_NORMAL
- en: A *read/write port* is an output (write-only) port as far as the outside world
    is concerned. However, as the name implies, the CPU can also read data from such
    a port—specifically, it reads the data that was last written to the port. Doing
    so does not affect the data presented to the external peripheral device.^([1](footnotes.xhtml#fn12_1a))
    [Figure 12-2](ch12.xhtml#ch12fig02) illustrates a read/write port.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/12fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-2: A read/write port*'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the data written to the output port loops back to a second latch.
    Placing the address of these two latches on the address bus asserts the *address
    decode lines* on both latches. Therefore, to select between the two latches, the
    CPU must also assert either the read line or the write line. Asserting the read
    line (which happens during a read operation) will enable the lower latch. This
    places the data previously written to the output port on the CPU’s data bus, allowing
    the CPU to read that data.
  prefs: []
  type: TYPE_NORMAL
- en: The port in [Figure 12-2](ch12.xhtml#ch12fig02) is not an input port—true input
    ports read data from external pins. Although the CPU can read data from this latch,
    the organization of this circuit simply allows the CPU to read the data it previously
    wrote to the port, thus saving the program from having to maintain this value
    in a separate variable. The data on the external connector is output only, and
    you can’t connect real-world input devices to these signal pins.
  prefs: []
  type: TYPE_NORMAL
- en: A *dual I/O port* is also a read/write port, but when you read a dual I/O port,
    you read data from an external input device rather than the last data written
    to the output side of the port’s address. Writing data to a dual I/O port transmits
    data to some external output device, just as writing to a write-only port does.
    [Figure 12-3](ch12.xhtml#ch12fig03) shows how you could interface a dual I/O port
    with the system.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/12fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-3: A dual I/O port*'
  prefs: []
  type: TYPE_NORMAL
- en: A dual I/O port is actually created with two ports—a read-only port and a write-only
    port—that share the same port address. Reading from the address accesses the read-only
    port, and writing to the address accesses the write-only port. Essentially, this
    port arrangement uses the read (R) and write (W) control lines to provide an extra
    address bit that specifies which of the two ports to use.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, a *bidirectional port* allows the CPU to both read data from and write
    data to an external device. To function properly, a bidirectional port must pass
    various control lines, such as read and write enable, to the peripheral device
    so that the device can change the direction of data transfer based on the CPU’s
    read/write request. In effect, a bidirectional port is an extension of the CPU’s
    bus through a bidirectional latch or buffer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, a given peripheral device utilizes multiple I/O ports. The original
    IBM PC parallel printer interface, for example, uses three port addresses: a read/write
    I/O port, a read-only input port, and a write-only output port. The read/write
    data port allows the CPU to read the last ASCII character written through it.
    The input port returns control signals from the printer, which indicate whether
    the printer is ready to accept another character, offline, out of paper, and other
    statuses. The output port transmits control information to the printer. Later-model
    PCs substituted a bidirectional port for the data port, allowing data transfer
    from and to a device through the parallel port. The bidirectional data port improved
    performance for various devices such as disk and tape drives connected to the
    PC’s parallel port. (Of course, modern PCs talk to printers over the USB port—that’s
    quite a different animal from the hardware perspective, though.)'
  prefs: []
  type: TYPE_NORMAL
- en: '**12.2 Other Ways to Connect Ports to the System**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The examples thus far may have given you the impression that the CPU always
    reads and writes peripheral data using the data bus. However, while the CPU generally
    transfers the data it has *read* from input ports across the data bus, it doesn’t
    always use the data bus to *write* data to output ports. In fact, a very common
    output method is to simply access a port’s address directly without writing any
    data to it. [Figure 12-4](ch12.xhtml#ch12fig04) illustrates a simple example of
    this technique using a set/reset (S/R) flip-flop.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/12fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-4: Outputting data to a port by directly accessing that port*'
  prefs: []
  type: TYPE_NORMAL
- en: In this circuit, an address decoder decodes two separate addresses. Any read
    or write access to the first address sets the output line to a `1`; any read or
    write access to the second address sets the output line to a `0`. This circuit
    ignores the data on the CPU’s data lines, as well as the status of the read and
    write lines. The only thing that matters is that the CPU accesses one of these
    two addresses.
  prefs: []
  type: TYPE_NORMAL
- en: Another possible way to connect an output port to a system is to connect the
    read/write status lines to the data input of a D flip-flop. [Figure 12-5](ch12.xhtml#ch12fig05)
    shows how you could design such a device.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/12fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-5: Outputting data using the read/write control as the data to output*'
  prefs: []
  type: TYPE_NORMAL
- en: In this diagram, any read of the port sets the output bit to `0`, while any
    write to this port sets the output bit to `1` (the read control line will be `HIGH`
    when writing to the specified address).
  prefs: []
  type: TYPE_NORMAL
- en: These are only two examples of an amazing variety of designs that engineers
    have devised to avoid using the data bus (largely to reduce hardware costs or
    improve performance). However, unless otherwise noted, the remaining examples
    in this chapter presume that the CPU reads and writes data to and from an external
    device using the data bus.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.3 I/O Mechanisms**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are three basic I/O mechanisms that computer systems use to communicate
    with peripheral devices: memory-mapped input/output, I/O-mapped input/output,
    and direct memory access (DMA). *Memory-mapped I/O* uses ordinary locations within
    the CPU’s memory address space to communicate with peripheral devices. *[I/O-mapped
    input/output](gloss01.xhtml#gloss01_115)* uses an address space separate from
    memory, as well as special machine instructions to transfer data between that
    I/O address space and the outside world. *Direct memory access (DMA)* is a special
    form of memory-mapped I/O where the peripheral device reads and writes data located
    in memory without CPU intervention. Each I/O mechanism has its own set of advantages
    and disadvantages, as we will discuss in this section.'
  prefs: []
  type: TYPE_NORMAL
- en: Usually, the hardware system designer determines how a device connects to a
    computer system; programmers have little control over this decision. Nevertheless,
    by paying attention to the costs and benefits of the I/O mechanism used for communication
    between the CPU and the peripheral device, you can choose code sequences that
    will maximize I/O performance within your applications.
  prefs: []
  type: TYPE_NORMAL
- en: '***12.3.1 Memory-Mapped I/O***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A memory-mapped peripheral device is connected to the CPU’s address and data
    lines exactly like regular memory, so whenever the CPU writes to or reads from
    the address associated with the peripheral device, the CPU transfers data to or
    from the device. This mechanism has several benefits and only a few disadvantages.
  prefs: []
  type: TYPE_NORMAL
- en: The principle advantage of a memory-mapped I/O subsystem is that the CPU can
    use any instruction that accesses memory, such as `mov`, to transfer data between
    the CPU and a peripheral. For example, if you’re trying to access a read/write
    or bidirectional port, you can use an 80x86 *read/modify/write* instruction, like
    `add`, to read the port, manipulate the value, and then write data back to the
    port, all with a single instruction. Of course, if the port is read-only or write-only,
    such an instruction will be of little use.
  prefs: []
  type: TYPE_NORMAL
- en: The big disadvantage of memory-mapped I/O devices is that they consume addresses
    in the CPU’s memory map. Every byte of address space that a peripheral device
    consumes is one less byte available for installing actual memory. Generally, the
    minimum amount of space you can allocate to a peripheral (or block of related
    peripherals) is a page of memory (4,096 bytes on an 80x86). Fortunately, a typical
    PC has only a couple dozen such devices, so this usually isn’t much of a problem.
    However, it can become a problem with some peripheral devices, like video cards,
    that consume a large chunk of the address space. Some video cards have between
    1GB and 32GB of on-board memory that they map into the memory address space, which
    means that the 1GB to 32GB address range consumed by such a card is not available
    to the system for use as regular RAM (though this is hardly a concern on a 64-bit
    processor).
  prefs: []
  type: TYPE_NORMAL
- en: I/O and the Cache
  prefs: []
  type: TYPE_NORMAL
- en: The CPU cannot cache values intended for memory-mapped I/O ports. Caching data
    from an input port would mean that subsequent reads of the port would access the
    value in the cache rather than the port data, which could be different. Similarly,
    with a write-back cache mechanism, some writes might never reach an output port
    because the CPU might save up several writes in the cache before sending the last
    one to the actual I/O port. In order to avoid these potential problems, we need
    some mechanism to tell the CPU not to cache accesses to certain memory locations.
  prefs: []
  type: TYPE_NORMAL
- en: The solution is found in the CPU’s memory management subsystem. The 80x86’s
    page table entries, for example, contain a flag that the CPU can use to determine
    whether it is okay to map data from a page in memory to the cache. If this flag
    is set one way, the cache operates normally; if the flag is set the other way,
    the CPU does not cache accesses to that page.
  prefs: []
  type: TYPE_NORMAL
- en: '***12.3.2 I/O-Mapped Input/Output***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As noted previously, I/O-mapped input/output uses a special I/O address space
    separate from the normal memory space, coupled with special machine instructions
    to access device addresses. For example, the 80x86 CPUs provide the `in` and `out`
    instructions specifically for this purpose. These instructions behave like `mov`
    except that they transmit data to and from the special I/O address space rather
    than the normal memory address space. Typically, processors that provide I/O-mapped
    input/output capabilities use the same physical address bus to transfer both memory
    addresses and I/O device addresses. Additional control lines differentiate between
    addresses that belong to the normal memory space and those that belong to the
    special I/O address space. This means that such CPUs could use both I/O-mapped
    input/output or memory-mapped I/O. Therefore, if the number of I/O-mapped locations
    in the CPU’s address space is insufficient, a hardware designer can always use
    memory-mapped I/O instead (as a video card does on a typical PC).
  prefs: []
  type: TYPE_NORMAL
- en: In modern 80x86 PC systems that utilize the PCI bus (or later variants), special
    peripheral chips on the system’s motherboard remap the I/O address space into
    the main memory space, allowing programs to access I/O-mapped devices using either
    memory-mapped or I/O-mapped input/output.
  prefs: []
  type: TYPE_NORMAL
- en: '***12.3.3 Direct Memory Access***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Memory-mapped I/O subsystems and I/O-mapped subsystems are both forms of *programmed
    I/O*, as they require the CPU to move data between the peripheral device and memory.
    To store into memory a sequence of 10 bytes taken from a programmed I/O input
    port, the CPU must read each value from the input port and store it into memory.
  prefs: []
  type: TYPE_NORMAL
- en: However, processing data 1 byte (or word or double word) at a time via the CPU
    may be too slow for very high-speed I/O devices. Such devices generally have an
    interface to the CPU’s bus so they can read and write memory directly—that is,
    without the CPU as an intermediary. Direct memory access (DMA) allows I/O operations
    to proceed in parallel with other CPU operations, which increases the overall
    speed of the system—unless the CPU and the DMA device both try to use the address
    and data buses at the same time. Concurrent processing occurs only if the bus
    is free for use by the I/O device, which happens when the CPU has a cache and
    is accessing cached code and data. Nevertheless, even if the CPU must halt and
    wait for a DMA operation to complete before beginning a different operation, the
    DMA approach is still much faster, because many of the bus operations are instruction
    fetches or I/O port accesses that don’t occur during DMA operations.
  prefs: []
  type: TYPE_NORMAL
- en: A typical DMA controller consists of a pair of counters and other circuitry
    that interfaces with memory and the peripheral device. One of the counters serves
    as an address register, supplying an address on the address bus for each transfer.
    The second counter specifies the number of data transfers. The application initializes
    the DMA controller’s address counter with the address of the block where it should
    begin transferring data. Each time the peripheral device wants to transfer data
    to or from memory, it sends a signal to the DMA controller, which places the value
    of the address counter on the address bus. In coordination with the DMA controller,
    the peripheral device places data on the data bus to write to memory during an
    input operation, or it reads data from the data bus, taken from memory, during
    an output operation.^([2](footnotes.xhtml#fn12_2a)) After a successful data transfer,
    the DMA controller increments its address register and decrements the transfer
    counter. This process repeats until the transfer counter decrements to zero.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.4 I/O Speed Hierarchy**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Different peripheral devices have different data transfer rates. Some devices,
    like keyboards, are extremely slow compared to CPU speeds. Other devices, like
    solid-state disk drives, can actually transfer data faster than the CPU can process
    it. The appropriate programming technique for data transfer depends strongly on
    the transfer speed of the peripheral device involved in the I/O operation. Therefore,
    before discussing how to write the most appropriate code, we should establish
    some terminology to describe the different transfer rates of peripheral devices.
  prefs: []
  type: TYPE_NORMAL
- en: '**Low-speed devices** Devices that produce or consume data at a rate much slower
    than the CPU is capable of processing. For the purposes of discussion, we’ll assume
    that low-speed devices operate at speeds that are three or more orders of magnitude
    slower than the CPU.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Medium-speed devices** Devices that transfer data at approximately the same
    rate as, or up to three orders of magnitude slower than, the CPU (accessing the
    device using programmed I/O).'
  prefs: []
  type: TYPE_NORMAL
- en: '**High-speed devices** Devices that transfer data faster than the CPU is capable
    of handling using programmed I/O.'
  prefs: []
  type: TYPE_NORMAL
- en: The speed of the peripheral device determines the type of I/O mechanism used
    for the I/O operation. Clearly, high-speed devices must use DMA because programmed
    I/O is too slow. Medium- and low-speed devices can use any of the three I/O mechanisms
    for data transfer (though low-speed devices rarely use DMA because of the cost
    of the extra hardware involved).
  prefs: []
  type: TYPE_NORMAL
- en: With typical bus architectures, CPUs are capable of one transfer per microsecond
    or better. Therefore, high-speed devices are those that transfer data more rapidly
    than once per microsecond. Medium-speed transfers are those that involve a data
    transfer every 1 to 100 microseconds. Low-speed devices usually transfer data
    less often than once every 100 microseconds. Of course, these definitions for
    low-, medium-, and high-speed devices are system dependent. Faster CPUs with faster
    buses allow faster medium-speed operations.
  prefs: []
  type: TYPE_NORMAL
- en: Note that one transfer per microsecond is not the same as a 1MB-per-second transfer
    rate. A peripheral device can actually transfer more than 1 byte per data transfer
    operation. For example, when using the 80x86 `in(dx,` `eax);` instruction, the
    peripheral device can transfer 4 bytes in one transfer. Therefore, if the device
    is capable of one transfer per microsecond, it can transfer 4MB per second using
    this instruction.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.5 System Buses and Data Transfer Rates**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In [Chapter 6](ch06.xhtml#ch06), you saw that the CPU communicates with memory
    and I/O devices using the system bus. If you’ve ever looked inside a computer
    or read the specifications for a system, you’ve probably seen terms like *[PCI](gloss01.xhtml#gloss01_192)*,
    *[ISA](gloss01.xhtml#gloss01_127)*, *EISA*, or even *NuBus* used to refer to the
    computer’s system bus. In this section, we’ll discuss how these different computer
    system buses relate to the CPU bus, and how they affect the performance of a system.
  prefs: []
  type: TYPE_NORMAL
- en: A single computer system often employs multiple buses. Therefore, a software
    engineer can choose which peripheral devices to use based upon their bus connections.
    Maximizing performance for a particular bus may require different programming
    techniques than for other buses. Although it’s not possible to choose the buses
    a particular computer system employs, a software engineer can select among the
    available buses to improve an application.
  prefs: []
  type: TYPE_NORMAL
- en: Computer system buses like PCI (Peripheral Component Interconnect) and ISA (Industry
    Standard Architecture) define physical connectors inside a computer system. Specifically,
    they describe the set of electronic signals (*connector pins* on the bus), physical
    dimensions (that is, connector layouts and distances from one another), and a
    data transfer protocol for connecting different electronic devices. These buses
    are often extensions of the CPU’s *local bus* (the address, data, and control
    lines), because many of the signals on the system buses are identical to the CPU’s
    signals.
  prefs: []
  type: TYPE_NORMAL
- en: However, peripheral buses themselves are not necessarily identical to the CPU’s
    bus—they may have additional or fewer signals compared to those on the CPU. For
    example, the ISA bus supports only 24 address lines compared with the Intel and
    AMD’s x86-64 40 to 52 address lines.
  prefs: []
  type: TYPE_NORMAL
- en: Different peripheral devices are designed to use different peripheral buses.
    [Figure 12-6](ch12.xhtml#ch12fig06) shows the organization of the PCI and ISA
    buses in a typical computer system.^([3](footnotes.xhtml#fn12_3a))
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/12fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-6: Connection of the PCI and ISA buses in a typical PC*'
  prefs: []
  type: TYPE_NORMAL
- en: Notice how the CPU’s address and data buses connect to a PCI bus controller
    peripheral device, but not to the PCI bus itself. The PCI bus controller contains
    two sets of pins, providing a *bridge* between the CPU’s local bus and the PCI
    bus. The signal lines on the local bus are not connected directly to the corresponding
    lines on the PCI bus; instead, the PCI bus controller acts as an intermediary,
    rerouting all data transfer requests between the CPU and the PCI bus.
  prefs: []
  type: TYPE_NORMAL
- en: Also note that the ISA bus controller is usually connected to the PCI bus controller,
    not directly to the CPU. This is typically for cost or performance reasons (there
    may be a limit to the number of devices that can connect directly to the CPU bus
    without additional buffering, for example).
  prefs: []
  type: TYPE_NORMAL
- en: The CPU’s local bus usually runs at some fraction of the CPU’s frequency. Typical
    local bus frequencies are currently 66 MHz, 100 MHz, 133 MHz, 400 MHz, 533 MHz,
    and 800 MHz, but they may become even faster. Usually, only memory and a few selected
    peripherals like the PCI bus controller sit on the CPU’s bus and operate at this
    high frequency.
  prefs: []
  type: TYPE_NORMAL
- en: Because a typical CPU’s bus is 64 bits wide and it’s theoretically possible
    to achieve one data transfer per clock cycle, the CPU’s bus has a maximum data
    transfer rate of 8 bytes times the clock frequency, or 800MB per second for a
    100 MHz bus. In practice, CPUs rarely achieve the maximum data transfer rate,
    but they do achieve some percentage of it, so the faster the bus, the more data
    can move in and out of the CPU (and caches) in a given amount of time.
  prefs: []
  type: TYPE_NORMAL
- en: '***12.5.1 Performance of the PCI Bus***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The PCI bus comes in several configurations. The base configuration has a 32-bit-wide
    data bus operating at 33 MHz. Like the CPU’s local bus, the PCI bus is theoretically
    capable of transferring data on each clock cycle. This means that the bus has
    a theoretical maximum data transfer rate of 4 bytes times 33 MHz, or 132MB per
    second. In practice, though, the PCI bus doesn’t come anywhere near this level
    of performance except in short bursts. Newer versions of the PCI-e offer up to
    16 “lanes,” allowing for much faster data transfer (largely for high-performance
    video cards).
  prefs: []
  type: TYPE_NORMAL
- en: Whenever the CPU wants to access a peripheral on the PCI bus, it must negotiate
    with other peripheral devices for the right to use the bus. This negotiation can
    take several clock cycles before the PCI controller grants the CPU access to the
    bus. If a CPU writes a double word per bus transfer, the negotiation time actually
    slows the transfer rate dramatically. The only way to achieve anywhere near the
    maximum theoretical bandwidth on the bus is to use a DMA controller and move blocks
    of data in *burst mode*. In burst mode, the DMA controller negotiates just once
    for the bus and then makes many transfers without giving up the bus between each
    one.
  prefs: []
  type: TYPE_NORMAL
- en: There are a couple of enhancements to the PCI bus that improve performance.
    Some PCI buses support a 64-bit-wide data path. This, obviously, doubles the maximum
    theoretical data transfer rate from 4 bytes per transfer to 8 bytes per transfer.
    Another enhancement is running the bus at 66 MHz, which also doubles the throughput.
    With a 64-bit-wide, 66 MHz bus, you would quadruple the data transfer rate of
    the baseline configuration. These optional enhancements to the PCI bus allow it
    to grow with the CPU as CPUs increase their performance. A high-performance version
    of the PCI bus, PCI-X, was available for a while, but it has largely been replaced
    by the PCI-e bus. PCI-e is a serial bus, transmitting data serially over a few
    data lines. However, it uses lanes to pass additional data in parallel. For example,
    a 16-lane PCI-e bus is 16 times faster than a single-lane variant.
  prefs: []
  type: TYPE_NORMAL
- en: '***12.5.2 Performance of the ISA Bus***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The ISA bus is a carryover from the original PC/AT computer system. This bus
    is 16 bits wide and operates at 8 MHz. It requires four clock cycles for each
    bus cycle (a *bus cycle* is the time it takes to transfer one 16-bit word of data
    across the ISA bus). For this and other reasons, the ISA bus is capable of about
    only one data transmission per microsecond. With a 16-bit-wide bus, data transfer
    is limited to about 2MB per second. This is much slower than both the CPU’s local
    bus and the PCI bus. Generally, the ISA bus is really only capable of supporting
    low-speed and medium-speed devices—like an RS-232 communications device, a modem,
    or a parallel printer interface—to the ISA bus. Most other devices, like disks,
    scanners, and network cards, are too fast for the ISA bus.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the ISA bus on most systems involves first negotiating for the PCI
    bus, but the PCI bus is so much faster than the ISA bus that this negotiation
    time has very little impact on the performance of peripherals on the ISA bus.
    Therefore, connecting the ISA controller directly to the CPU’s local bus wouldn’t
    noticeably improve performance.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, the ISA bus is thoroughly obsolete these days, and you won’t find
    it on modern PCs. A few industrial PCs and SBCs (single-board computers) support
    ISA bus connections for legacy applications, but other than that the ISA bus is
    dead.
  prefs: []
  type: TYPE_NORMAL
- en: '***12.5.3 The AGP Bus***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Video display (aka graphics) cards are very special peripherals that need maximum
    bus performance to ensure quick screen updates and fast graphic operations. Unfortunately,
    if the CPU has to constantly negotiate with other peripherals for the use of the
    PCI bus, graphics performance can suffer. To overcome this problem, video card
    designers created the *Accelerated Graphics Port (AGP)*, an interface between
    the CPU’s local bus and the video display card that provides various control lines
    and bus protocols specifically designed for video display cards.
  prefs: []
  type: TYPE_NORMAL
- en: The AGP connection lets the CPU quickly move data to and from the video display
    RAM (see [Figure 12-7](ch12.xhtml#ch12fig07)).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/12fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-7: The AGP bus interface*'
  prefs: []
  type: TYPE_NORMAL
- en: Because there’s only one AGP port per system, only one card can use the AGP
    slot at a time. The upside of this is that the system never has to negotiate for
    access to the AGP bus. However, by 2008 the performance of video cards surpassed
    that of the AGP bus. Most modern video cards use multilane PCI-e bus interfaces
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.6 Buffering**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If a particular I/O device produces or consumes data faster than the system
    is capable of transferring data to or from that device, the system designer has
    two choices: provide a faster connection between the CPU and the device, or slow
    down the rate of transfer between the two.'
  prefs: []
  type: TYPE_NORMAL
- en: If the peripheral device is connected to a slow bus like ISA, a system designer
    can create a faster connection by switching to a wider bus like the 64-bit PCI,
    a faster bus (one with a higher frequency), or a higher-performance bus like PCI-e.
    System designers can also sometimes create a faster interface to the bus, as they
    did with the AGP connection.
  prefs: []
  type: TYPE_NORMAL
- en: The alternative—slowing down the transfer rate between the peripheral and the
    computer system—isn’t always as bad an option as it might initially seem. Most
    high-speed devices don’t transfer data to the system at a constant rate. Instead,
    they typically transfer a block of data rapidly and then sit idle for some time.
    Although the burst rate is higher than the CPU or memory can handle, the average
    data transfer rate is usually lower. If you can average out the high-bandwidth
    peaks and transfer some of the data when the peripheral is inactive, you can easily
    move data between the peripheral and the computer system without resorting to
    an expensive, high-bandwidth bus or connection.
  prefs: []
  type: TYPE_NORMAL
- en: The trick is to use memory on the peripheral side to buffer the data. The peripheral
    can rapidly fill this buffer with data during an input operation, and rapidly
    extract data from the buffer during an output operation. Once the peripheral device
    is inactive, the system either empties or refills the buffer at a sustainable
    rate. As long as the average data transfer rate of the peripheral device is below
    the maximum bandwidth the system supports, and the buffer is large enough to hold
    bursts of data going to and from the peripheral, this scheme lets the peripheral
    communicate with the system at a lower average data transfer rate.
  prefs: []
  type: TYPE_NORMAL
- en: Often, to save costs, the buffering takes place in memory on the CPU rather
    than on the peripheral device. In this case, it is often the software engineer’s
    responsibility to initialize the buffer for a peripheral device. In some cases,
    neither the peripheral device nor the OS provides a buffer for the peripheral’s
    data, so the application must do so in order to maintain maximum performance and
    avoid data loss. In other cases, the device or OS may provide a small buffer,
    but the application itself might not process the data often enough to avoid data
    overruns in the small buffer; in these situations, an application can create a
    larger buffer that is local to the application.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.7 Handshaking**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many I/O devices cannot accept data at just any rate. For example, an i9-based
    PC is capable of sending several hundred million characters per second to a printer,
    but printers can’t print that many characters each second. Likewise, an input
    device such as a keyboard will never transmit several million keystrokes per second
    to the system (because the keyboard operates at human speeds, not computer speeds).
    Because of these differences in capabilities, the CPU needs some way to coordinate
    data transfer between the computer system and its peripheral devices.
  prefs: []
  type: TYPE_NORMAL
- en: One common approach is to send and receive status bits on a port separate from
    the data port. For example, a printer could send a single bit to tell the system
    whether it is ready to accept more data. Likewise, a single status bit in a different
    port could specify whether a keystroke is available at the keyboard data port.
    The CPU can test these bits prior to writing a character to the printer or reading
    a key from the keyboard.
  prefs: []
  type: TYPE_NORMAL
- en: Using status bits to indicate that a device is ready to accept or transmit data
    is known as *handshaking*, so named because the protocol is similar to two people
    signifying agreement with a handshake.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following 80x86 assembly language program segment demonstrates how handshaking
    works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This code fragment will continuously loop while the HO bit of the printer status
    register (at input port `$379`) contains `0` and will exit once the HO bit is
    set (indicating that the printer is ready to accept data).
  prefs: []
  type: TYPE_NORMAL
- en: '**12.8 Timeouts on an I/O Port**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One problem with the `repeat..until` loop in the previous section is that it
    could spin indefinitely as it waits for the printer to become ready to accept
    additional input. If someone turns the printer off or the printer cable becomes
    disconnected, the program could freeze up, forever waiting for the printer to
    become available. Usually, it’s a better idea to inform the user when something
    goes wrong rather than allowing the system to hang. To do this, include a *timeout*
    period in the loop; once exceeded, the timeout causes the program to alert the
    user that something is wrong with the peripheral device.
  prefs: []
  type: TYPE_NORMAL
- en: You can expect some sort of response from most peripheral devices within a reasonable
    amount of time. For example, even in the worst case, most printers will be ready
    to accept additional character data within a few seconds of the last transmission.
    Therefore, something is probably wrong if 30 seconds or more has passed without
    the printer accepting a new character. A program written to detect this kind of
    problem typically pauses, asking the user to check the printer, and then resumes
    printing once the user indicates the problem is resolved.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a good timeout period is not an easy task. You must carefully balance
    the irritation of possible false alarms from the program with the pain of having
    it lock up for long periods when something actually is wrong. Both situations
    are equally annoying.
  prefs: []
  type: TYPE_NORMAL
- en: 'An easy way to create a timeout period is to count the number of times the
    program loops while waiting for a handshake signal from a peripheral. Consider
    the following modification to the `repeat..until` loop from the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This code will exit once the printer is ready to accept data or when approximately
    30 seconds have expired. You might question the 30-second figure, since a software-based
    loop (counting down ECX to 0) should run at different speeds on different processors.
    However, the `in()` instruction reads a port on the bus, and that means this instruction
    will take approximately 1 microsecond to execute (I/O ports often inject lots
    of wait states). Hence, one million times through the loop will take about a second
    (plus or minus 50 percent, but close enough for our purposes). This is true almost
    regardless of the CPU frequency.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.9 Interrupts and Polled I/O**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*[Polling](gloss01.xhtml#gloss01_195)* is the process of constantly testing
    a port to see if data is available. The handshaking loops of the previous sections
    provide good examples of polling—the CPU waits in a short loop, testing the printer
    port’s status value until the printer is ready to accept more data, and then the
    CPU can transfer more data to the printer. Polled I/O is inherently inefficient.
    If the printer in this example takes 10 seconds to accept another byte of data,
    the CPU spins, doing nothing productive for those 10 seconds.'
  prefs: []
  type: TYPE_NORMAL
- en: In early personal computer systems, this is exactly how a program would behave.
    When a program wanted to read a key from the keyboard, it would poll the keyboard
    status port until a key was available. These early computers could not do other
    processing while waiting for the keyboard.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution to this problem is to use an *interrupt mechanism*. An interrupt
    is triggered by an external hardware event, such as the printer becoming ready
    to accept another character, that causes the CPU to interrupt its current instruction
    sequence and call a special *interrupt service routine (ISR)*. Typically, an ISR
    runs through the following sequence of events:'
  prefs: []
  type: TYPE_NORMAL
- en: It preserves the current values of all machine registers and flags so that the
    interrupted computation can be continued later.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It does whatever operation is necessary to *service* the interrupt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It restores the registers and flags to the values they had before the interrupt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It resumes execution of the code that was interrupted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In most computer systems, typical I/O devices generate an interrupt whenever
    they make data available to the CPU, or when they become able to accept data from
    the CPU. The ISR quickly processes the interrupt request in the background, allowing
    some other computation to proceed normally in the foreground.
  prefs: []
  type: TYPE_NORMAL
- en: Though ISRs are usually written by OS designers or peripheral device manufacturers,
    most OSes enable you to pass an interrupt to an application via *signals* or some
    similar mechanism. This allows you to include ISRs directly within an application.
    You could use this facility, for example, to have a peripheral device notify your
    application when its internal buffer is full and the application needs to copy
    data from the peripheral’s buffer to an application buffer to prevent data loss.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.10 Protected-Mode Operation and Device Drivers**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you’re working on an ancient Windows 95 or 98 system, you can write assembly
    code to access I/O ports directly. The handshaking code shown earlier is a good
    example of this. However, modern versions of Windows and all versions of Linux
    and macOS employ a *protected mode* of operation. In this mode, direct access
    to devices is restricted to the OS and certain privileged programs. Standard applications,
    even those written in assembly language, are not so privileged. If you write a
    simple program that attempts to send data to an I/O port, the system will generate
    an illegal access exception and halt your program.
  prefs: []
  type: TYPE_NORMAL
- en: Linux won’t allow just any program to access I/O ports; only programs with “superuser”
    (root) privileges can do so. For limited I/O access, it’s possible to use the
    Linux `ioperm` system call to make certain I/O ports accessible from user applications.
    (For more details, read the man page on `ioperm`.)
  prefs: []
  type: TYPE_NORMAL
- en: If Linux, macOS, and Windows don’t allow direct access to peripheral devices,
    how does a program communicate with these devices? Clearly, this *can* be done,
    because applications interact with real-world devices all the time. The answer
    is that these OSes permit specially written modules, known as *device drivers*,
    to access I/O ports. A complete discussion of writing device drivers is well beyond
    the scope of this book, but understanding how they work may help you understand
    the possibilities and limitations of I/O under a protected-mode OS.
  prefs: []
  type: TYPE_NORMAL
- en: '***12.10.1 The Device Driver Model***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A device driver is a special type of program that links with the OS. It must
    follow some specific protocols, and it must make some special calls to the OS
    that are not available to standard applications. Furthermore, in order to install
    a device driver in your system, you must have administrator privileges, because
    device drivers pose all kinds of security and resource allocation risks, and you
    can’t leave your system vulnerable. Therefore, installation is not a trivial process,
    and application programs cannot load and unload drivers at will.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, there are only a limited number of devices found on a typical PC,
    so you only need a limited number of device drivers. You would typically install
    a device driver in the OS at the same time you install the device, or, if the
    device is built into the PC, at the same time you install the OS. About the only
    time you’d really need to write your own device driver is when building your own
    device, or in unique cases where you need to take advantage of some device’s capabilities
    that standard device drivers don’t handle.
  prefs: []
  type: TYPE_NORMAL
- en: The device driver model works well with low-speed devices, where the OS and
    device driver can respond to the device much more quickly than it requires. The
    model is also great for use with medium- and high-speed devices where the system
    transmits large blocks of data to and from the device. However, the device driver
    model does have a few drawbacks, one being that it does not support medium- and
    high-speed data transfers that require substantial interaction between the device
    and the application.
  prefs: []
  type: TYPE_NORMAL
- en: The problem is that calling the OS is an expensive process. Whenever an application
    makes a call to the OS to transmit data to the device, it can potentially take
    hundreds of microseconds, if not milliseconds, before the device driver actually
    sees the application’s data. If the interaction between the device and the application
    requires a constant flurry of bytes moving back and forth, there will be a big
    delay if each transfer has to go through the OS. For applications of this sort,
    you’ll need to write a special device driver that can handle the transactions
    itself rather than continually returning to the application.
  prefs: []
  type: TYPE_NORMAL
- en: Because applications can’t access devices directly (in modern OSes), all communication
    between them must take place through a device driver intermediary. The question,
    then, is how do applications communicate with device drivers?
  prefs: []
  type: TYPE_NORMAL
- en: '***12.10.2 Communication with Device Drivers***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the most part, communicating with a peripheral device under a modern OS
    is exactly like writing data to a file or reading data from a file. In most OSes,
    you open a “file” using a special filename like *COM1* (the serial port) or *LPT1*
    (the parallel port) and the OS automatically creates a connection to the specified
    device. When you are finished using the device, you “close” the associated file,
    which tells the OS that the application is done with the device so other applications
    can use it.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, most devices don’t support the same semantics as disk files. Some
    devices, like printers or modems, can accept a long stream of unformatted data,
    but others may require that you preformat the data into blocks and write the blocks
    to the device with a single write operation. The exact semantics depend upon the
    particular device. Nevertheless, the typical way to send data to a peripheral
    is to use an OS “write” function to which you pass a buffer containing some data,
    and the way to read data from a device is to call an OS “read” function to which
    you pass the address of some buffer into which the OS will place the data it reads.
  prefs: []
  type: TYPE_NORMAL
- en: But not all devices conform to these *stream-I/O* data semantics of file I/O,
    either. Therefore, most OSes provide a *device-control API* that lets you pass
    information directly to the peripheral’s device driver to handle the cases where
    a stream-I/O model fails.
  prefs: []
  type: TYPE_NORMAL
- en: Because it varies by OS, the exact details concerning the OS API interface are
    a bit beyond the scope of this book. Though most OSes use a similar scheme, they
    differ enough to make it impossible to describe them in a general way. So, for
    further details, consult the programmer’s reference for your particular OS.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.11 For More Information**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Silberschatz, Abraham, Peter Baer Galvin, and Greg Gagne. “[Chapter 13](ch13.xhtml#ch13):
    I/O Systems.” In *Operating System Concepts*. 8th ed. Hoboken, NJ: John Wiley
    & Sons, 2009.'
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Early editions of Patterson and Hennessy’s* Computer Architecture: A Quantitative
    Approach *provided a good chapter on I/O devices and buses; sadly, as it covered
    very old peripheral devices, the authors dropped the chapter rather than updating
    it in subsequent revisions. Internet searches seem to be the last place you can
    find consistent information on this subject (outside of this book, of course).*'
  prefs: []
  type: TYPE_NORMAL
