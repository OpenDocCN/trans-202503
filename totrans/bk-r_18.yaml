- en: '**15**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**PROBABILITY**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/common-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The concept of *probability* is central to statistical reasoning. Even the most
    complicated statistical techniques and models usually have the ultimate goal of
    making a probabilistic statement about a phenomenon. In this chapter, I’ll use
    simple, everyday examples to illustrate this key idea in preparation for the remaining
    chapters. If you’re already familiar with the basics of probability and random
    variables and the associated terminology, you may want to skip ahead to [Chapter
    16](ch16.xhtml#ch16), where R functionality begins to feature more prominently.
  prefs: []
  type: TYPE_NORMAL
- en: '**15.1 What Is a Probability?**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *probability* is a number that describes the “magnitude of chance” associated
    with making a particular observation or statement. It’s always a number between
    0 and 1 (inclusive) and is often expressed as a fraction. Exactly how you calculate
    a probability depends on the definition of an *event*.
  prefs: []
  type: TYPE_NORMAL
- en: '***15.1.1 Events and Probability***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In statistics, an *event* typically refers to a specific outcome that can occur.
    To describe the chance of event *A* actually occurring, you use a probability,
    denoted by Pr(*A*). At the extremes, Pr(*A*) = 0 suggests *A* cannot occur, and
    Pr(*A*) = 1 suggests that *A* occurs with complete certainty.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say you roll a six-sided, fair die. Let *A* be the event “you roll a
    5 or a 6.” You can assume that each outcome on a standard die has a probability
    of occurring 1/6 in any given roll. Under these conditions, you have this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0310-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is what’s known as a *frequentist*, or *classical*, probability, and it
    is assumed to be the relative frequency with which an event occurs over many identical,
    objective trials.
  prefs: []
  type: TYPE_NORMAL
- en: As another example, say you’re married and arrive home much later than usual.
    Let *B* be the event “your significant other is angry” because of your tardiness.
    It’s a relatively straightforward process to observe *A* in a mathematical sense,
    but *B* isn’t so objectively observed, and the quantity can’t be easily computed.
    Instead, you might assign a number to Pr(*B*) given your own past experience.
    For example, you might say “I think Pr(*B*) = 0.5” if you think there’s a 50-50
    chance your partner will be mad, but this would be based on your personal impressions
    of the situation and knowledge of your spouse’s temperament or mood, not on an
    impartial experiment that could be easily reproduced for any two individuals.
    This is known as a *Bayesian* probability, which uses prior knowledge or subjective
    belief to inform the calculations.
  prefs: []
  type: TYPE_NORMAL
- en: Owing to its naturally implied objectivity, the frequentist interpretation is
    the generally assumed definition of probability; you’ll focus on this kind of
    probability in this book. If you are interested in getting to grips with Bayesian
    analyses using R, Kruschke ([2010](ref.xhtml#ref36)) represents a well-received
    text on the subject.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Though it is tempting to define the concept of probability in terms of* likelihood
    *(and colloquially, many do), likelihood is taken to mean something slightly different
    in statistical theory, so I’ll avoid this term for now.*'
  prefs: []
  type: TYPE_NORMAL
- en: The way in which you compute probabilities when considering multiple events
    is determined by several important rules. These are similar in nature to the concepts
    of AND and OR that are key to comparing the logical values `TRUE` and `FALSE`
    in R via `&&` and `||` (refer to [Section 4.1.3](ch04.xhtml#ch04lev2sec39)). Just
    like these logical comparisons, calculation of probabilities based on several
    defined events can usually be broken down into a specific calculation concerning
    two distinct events. To serve as a simple running example over the next few sections,
    assume you roll a standard die and define event *A* to be “you roll a 4 or more”
    and event *B* to be “you roll an even number.” You can therefore conclude that
    both ![image](../images/f0310-02.jpg) and ![image](../images/f0310-03.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: '***15.1.2 Conditional Probability***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A *conditional* probability is the probability of one event occurring after
    taking into account the occurrence of another event. The quantity Pr(*A*|*B*)
    represents “the probability that *A* occurs, *given* that *B* has already occurred,”
    and vice versa if you write Pr(*B*| *A*).
  prefs: []
  type: TYPE_NORMAL
- en: If Pr(*A*|*B*) = Pr(*A*), then the two events are *independent*; if Pr(*A*|*B*)
    ≠ Pr(*A*), then the two events are *dependent*. Generally, you can’t assume that
    Pr(*A*|*B*) is equal to Pr(*B*| *A*).
  prefs: []
  type: TYPE_NORMAL
- en: Turn to *A* and *B* as defined previously for a roll of a die. You already know
    that ![image](../images/f0310-02.jpg). Now think of Pr(*A*|*B*). What is the probability
    your outcome is a 4 or more, *given* an even number has occurred? Since there
    are three even numbers, 2, 4, and 6, the probability that you roll a 4 or more,
    assuming an even number had occurred, is ![image](../images/2by3.jpg). Thus, Pr(*A*|*B*)
    ≠ Pr(*A*) in this context, and the two events are therefore not independent.
  prefs: []
  type: TYPE_NORMAL
- en: '***15.1.3 Intersection***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The *intersection* of two events is written as Pr(*A* ∩ *B*) and is read as
    “the probability that both *A* and *B* occur simultaneously.” It is common to
    represent this as a Venn diagram, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0311-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the disc labeled *A* represents the outcome (or outcomes) that satisfies
    *A*, and disc *B* represents the outcomes for *B*. The shaded area represents
    the specific outcome (or outcomes) that satisfies both *A* and *B*, and the area
    outside both discs represents the outcome (or outcomes) that satisfies neither
    *A* nor *B*. Theoretically, you have this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e15-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If Pr(*A* ∩ *B*) = 0, then you say the two events are *mutually exclusive*.
    In other words, they cannot occur simultaneously. Also note that if the two events
    are independent, then [Equation (15.1)](ch15.xhtml#ch15eq1) simplifies to Pr(*A*
    ∩ *B*) = Pr(*A*) × Pr(*B*).
  prefs: []
  type: TYPE_NORMAL
- en: Returning to the die example, what is the probability that on a single toss
    you roll an even number *and* it’s a 4 or more? Using the fact that ![image](../images/f0312-02.jpg)
    and that ![image](../images/f0310-03.jpg), it is easy to compute ![image](../images/f0312-03.jpg)
    and confirm this in R if you really want to.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the two events are not mutually exclusive because Pr(*A* ∩
    *B*) ≠ 0\. This makes sense—it’s perfectly possible in a die roll to observe a
    number that’s both even and at least 4.
  prefs: []
  type: TYPE_NORMAL
- en: '***15.1.4 Union***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The *union* of two events is written as Pr(*A* ∪ *B*) and is read as “the probability
    that *A* or *B* occurs.” Here is the representation of a union as a Venn diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0312-04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Theoretically, you have this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e15-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The reason you need to subtract the intersection in this diagram is that in
    summing Pr(*A*) and Pr(*B*) alone, you’d be incorrectly counting Pr(*A* ∩ *B*)
    twice. Note, though, that if the two events are mutually exclusive, then [Equation
    (15.2)](ch15.xhtml#ch15eq2) does simplify to Pr(*A* ∪ *B*) = Pr(*A*) + Pr(*B*).
  prefs: []
  type: TYPE_NORMAL
- en: 'So, in rolling the die, what’s the probability that you observe an even number
    *or* one that’s at least 4? Using (15.2), it’s easy to find that ![image](../images/f0312-06.jpg).
    The following confirms this in R:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '***15.1.5 Complement***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Lastly, the probability of the *complement* of an event is written as Pr(*Ā*)
    and is read as “the probability that *A* does *not* occur.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Here it is as a Venn diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0313-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'From this diagram, you can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Pr(*Ā*) = 1 − Pr(*A*)
  prefs: []
  type: TYPE_NORMAL
- en: 'Wrapping up the running example, it’s straightforward to find the probability
    that you do not roll a 4 or greater: ![image](../images/f0313-02.jpg). Naturally,
    if a 4, 5, or 6 is not obtained, then you must’ve rolled a 1, 2, or 3, so there
    are three possible outcomes left out of the six.'
  prefs: []
  type: TYPE_NORMAL
- en: Sure, the die-rolling example may not represent the most pressing need facing
    statistical researchers today, but it has provided some clear illustrations of
    the behavior and terminology associated with the very real rules of probability.
    These rules apply across the board and play an important role in the interpretation
    of arguably more pressing endeavors in statistical modeling.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 15.1**'
  prefs: []
  type: TYPE_NORMAL
- en: You have a standard deck of 52 playing cards. There are two colors (black and
    red) and four suits (spades are black, clubs are black, hearts are red, and diamonds
    are red). Each suit has 13 cards, in which there is an ace, numbered cards from
    2 to 10, and three face cards (jack, queen, and king).
  prefs: []
  type: TYPE_NORMAL
- en: You randomly draw and then replace a card. What’s the probability it’s an ace?
    What’s the probability it’s the 4 of spades?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You randomly draw a card, and after replacing it, you draw another. Let *A*
    be the event that the card is a club; let *B* be the event that the card is red.
    What is Pr(*A*|*B*)? That is, what is the probability the second card is a club,
    *given* the first one was a red card? Are the two events independent?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat (b), this time assuming that when the first (club) card is drawn, it
    is not replaced. Would this change your answer to (b) in terms of independence?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let *C* be the event a card is a face card, and let *D* be the event a card
    is black. You draw a single card. Evaluate Pr(*C* ∩ *D*). Are the two events mutually
    exclusive?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**15.2 Random Variables and Probability Distributions**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *random variable* is a variable whose specific outcomes are assumed to arise
    by chance or according to some random or *stochastic* mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: You’ve already encountered *variables*—characteristics that describe an individual
    entity based on data you’ve observed ([Section 13.1](ch13.xhtml#ch13lev1sec42)).
    When you’re considering random variables, however, assume you have not yet made
    an observation. The chances of observing a specific value, or one within a specific
    interval, for that random variable has associated with it a probability.
  prefs: []
  type: TYPE_NORMAL
- en: It therefore makes sense to think of random variables as being tied to a function
    that defines these probabilities, which is referred to as a *probability distribution*.
    In this section, you’ll look at some elementary ways in which random variables
    are summarized and how their corresponding probability distributions are dealt
    with statistically.
  prefs: []
  type: TYPE_NORMAL
- en: '***15.2.1 Realizations***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: So, the concept of a random variable revolves around the consideration of the
    possible outcomes of a variable in a probabilistic fashion. When you’ve actually
    made observations of a random variable, these are referred to as *realizations*.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following—suppose you roll your beloved die. Define the random
    variable *Y* to be the result. The possible realizations are *Y* = 1, *Y* = 2,
    *Y* = 3, *Y* = 4, *Y* = 5, and *Y* = 6.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s say you’re planning to go on a picnic and monitor the maximum daily
    temperature at your preferred spot. Let the random variable *W* be the temperature
    in degrees Fahrenheit you observe there. Technically, you might say that the possible
    realizations of *W* lie in the interval −∞ < *W* < ∞.
  prefs: []
  type: TYPE_NORMAL
- en: These examples serve to illustrate two types of random variables. *Y* is a *discrete
    random variable*; *W* is a *continuous random variable*. Whether any given random
    variable is discrete or continuous has consequences for the way in which you think
    about, and may utilize, the probabilities associated with making realizations.
  prefs: []
  type: TYPE_NORMAL
- en: '***15.2.2 Discrete Random Variables***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A discrete random variable follows the same definitions as the variables covered
    in [Chapter 13](ch13.xhtml#ch13). Its realizations can take on only certain precise
    values, for which no other degree of measurement accuracy is possible or interpretable.
    Rolling a standard die can result in only those six distinct possibilities described
    previously by *Y*, and it would make no sense to observe, for example, “5.91.”
  prefs: []
  type: TYPE_NORMAL
- en: From [Section 15.1.1](ch15.xhtml#ch15lev2sec128), you know a probability is
    directly tied to defined outcomes known as *events*. When discussing a discrete
    random variable, events are therefore defined with respect to the distinct possible
    values the variable can take, and the corresponding probability distribution is
    formed when you consider the range of all the probabilities associated with all
    possible realizations.
  prefs: []
  type: TYPE_NORMAL
- en: Probability distributions tied to discrete random variables are called *probability
    mass functions*. Since these define the probabilities of all possible outcomes,
    the sum of the probabilities in any complete probability mass function must always
    equal exactly 1.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose you go into a casino and play a simple gambling game. At
    each turn, you can either lose $4 with probability 0.32, break even (win or lose
    nothing) with probability 0.48, win $1 with probability 0.15, or win $8 with probability
    0.05\. Because these are the only four possible outcomes, the probabilities sum
    to 1\. Let the discrete random variable *X* be defined as the “amount earned”
    at each turn you have. The distribution of these probabilities is expressed in
    [Table 15-1](ch15.xhtml#ch15tab1); note that the loss of $4 is represented as
    a negative earning as per the definition of *X*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 15-1:** Probabilities and Cumulative Probabilities for the Amount Won,
    *X*, in a Hypothetical Gambling Game'
  prefs: []
  type: TYPE_NORMAL
- en: '| ***x*** | **–4** | **0** | **1** | **8** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Pr(*X* = *x*) | 0.32 | 0.48 | 0.15 | 0.05 |'
  prefs: []
  type: TYPE_TB
- en: '| Pr(*X* ≤ *x*) | 0.32 | 0.80 | 0.95 | 1.00 |'
  prefs: []
  type: TYPE_TB
- en: '**Cumulative Probability Distributions of Discrete Random Variables**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The *cumulative probability* is also an important part of the general idea of
    a probability distribution. A cumulative probability for a random variable *X*
    is “the probability of observing less than or equal to *x*” and written as Pr(*X*
    ≤ *x*). In the discrete case, you obtain the distribution of cumulative probabilities
    by summing the individual probabilities of the mass function up to and including
    any given value of *x*. This is shown in the bottom row of [Table 15-1](ch15.xhtml#ch15tab1).
    For example, though Pr(*X* = 0) is 0.48, Pr(*X* ≤ 0) = 0.32 + 0.48 = 0.80.
  prefs: []
  type: TYPE_NORMAL
- en: 'Visualizing probability distributions is always useful, and because of the
    discrete nature of *X*, it’s easy to use the `barplot` function for this. Using
    skills from [Section 14.1](ch14.xhtml#ch14lev1sec44), the following code first
    stores vectors of the possible outcomes and corresponding probabilities (`X.outcomes`
    and `X.prob` respectively) and then produces the left image in [Figure 15-1](ch15.xhtml#ch15fig1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The optional argument `space=0` eliminates the gaps between the bars.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, you can use the built-in `cumsum` function to progressively sum the entries
    in `X.prob`, as shown next, giving you the cumulative probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, using `X.cumul`, the cumulative probability distribution can be plotted
    in the same way as earlier; the following line generates the right panel of [Figure
    15-1](ch15.xhtml#ch15fig1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![image](../images/f15-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 15-1: Visualizing the probability distribution associated with event-specific
    probabilities of a hypothetical gambling game (left) and the corresponding cumulative
    probability distribution (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, it’s important to remember the following for any probability mass
    function based on a discrete random variable *X*:'
  prefs: []
  type: TYPE_NORMAL
- en: • There are *k* distinct outcomes *x*[1],. . . , *x*[k].
  prefs: []
  type: TYPE_NORMAL
- en: • For each *x*[i], where *i* = {1,. . . , *k*}, 0 ≤ Pr(*X* = *x[i]*) ≤ 1.
  prefs: []
  type: TYPE_NORMAL
- en: • ![image](../images/f0317-01.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: '**Mean and Variance of a Discrete Random Variable**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: It’s useful to be able describe or summarize properties of a random variable
    of interest as you would for raw data. The most useful two properties are the
    mean and variance, both of which depend upon the relevant distribution of probabilities
    associated with that random variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'For some discrete random variable *X*, the *mean* *μ[X]* (also referred to
    as the *expectation* or the *expected value* ![image](../images/common-01a.jpg)[*X*])
    is the “average outcome” that you can expect over many realizations. Say *X* has
    *k* possible outcomes, labeled *x*[1], *x*[2], ..., *x[k]*. Then, you have the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e15-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: To find the mean, simply multiply the numeric value of each outcome by its corresponding
    probability and sum the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a discrete random variable *X*, the *variance* ![image](../images/f0317-03.jpg),
    also written as Var[*X*], quantifies the variability in the possible realizations
    of *X*. Theoretically, in terms of expectations, it can be shown that ![image](../images/f0317-04.jpg).
    As you can see, calculation of the discrete random variable variance depends upon
    its mean *μ[X]* and is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e15-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Again, the procedure is straightforward—the variance is computed by squaring
    the differences between each realization and mean and then multiplying by the
    corresponding probability of the occurrence before summing these products.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the probabilities associated with each outcome are often unknown
    and are estimated from observed data. Following that step, you apply the formulas
    in (15.3) and (15.4) to obtain *estimates* of the respective properties. Also,
    note that the general descriptions of mean and variance are the same as in [Section
    13.2](ch13.xhtml#ch13lev1sec43)—only you’re now quantifying centrality and spread
    with respect to a random phenomenon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider the gambling game with the possible realizations of the amount
    earned, *X*, and the associated probabilities as specified in [Table 15-1](ch15.xhtml#ch15tab1).
    With vector-oriented behavior (refer to [Section 2.3.4](ch02.xhtml#ch02lev2sec23)),
    using R to calculate the mean and variance of *X* is easy. With the objects `X.outcomes`
    and `X.prob` from earlier, you can get the mean of *X* from the element-wise multiplication
    in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'So, *μ[X]* = −0.73\. By the same token, the following provides the variance
    of *X*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You can also compute the standard deviation by taking the square root of the
    variance (recall the definitions in [Section 13.2.4](ch13.xhtml#ch13lev2sec119)).
    This is done with the built-in `sqrt` command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Based on these results, you can make several comments on the gambling game and
    its outcomes. The expected outcome of −0.73 suggests that, on average, you’ll
    lose $0.73 per turn, with a standard deviation of about $2.82\. These quantities
    are not, and need not be, one of the specifically defined outcomes. They describe
    the behavior of the random mechanism over the long run.
  prefs: []
  type: TYPE_NORMAL
- en: '***15.2.3 Continuous Random Variables***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Again following from the definitions of variables from [Chapter 13](ch13.xhtml#ch13),
    a continuous random variable has no limit to the number of possible realizations.
    For a discrete random variable, it is natural to think of a specific outcome as
    an event and assign it a corresponding probability. Things are a little different
    when you’re dealing with a continuous random variable, however. If you take the
    picnic example in [Section 15.2.1](ch15.xhtml#ch15lev2sec133), you can see that
    even if you restrict the range of possible values of temperature measurement that
    you assume *W* could take, say, to between 40 and 90 degrees Fahrenheit (or, expressed
    more formally, 40 ≤ *W* ≤ 90), there are still an infinite number of distinct
    values on that continuum. Measuring 59.1 degrees makes as much sense as observing
    something like 59.16742 degrees. As such, it isn’t possible to assign probabilities
    to specific, single temperatures; instead, you assign a probability to *intervals*
    of values. For example, based on *W*, asking Pr(*W* = 55.2)—“What is the probability
    the temperature is *exactly* 55.2 degrees Fahrenheit?”—is not a valid question.
    However, asking Pr(*W* ≤ 55.2)—“What is the probability it’s *less than or equal
    to* 55.2 degrees?”—is answerable because it defines an interval.
  prefs: []
  type: TYPE_NORMAL
- en: This is easier to understand if you again think about precisely how the probabilities
    will be distributed. With a discrete random variable, you can straightforwardly
    envisage its mass function as discrete, namely, something like [Table 15-1](ch15.xhtml#ch15tab1),
    which can be plotted like [Figure 15-1](ch15.xhtml#ch15fig1). However, with continuous
    random variables, the function that describes the distribution of probabilities
    must now therefore be *continuous* on the range of possible values. Probabilities
    are computed as “areas underneath” that continuous function, and, as with discrete
    random variables, the “total area” underneath a continuous probability distribution
    must evaluate to exactly 1\. A probability distribution tied to a continuous random
    variable is called a *probability density function*.
  prefs: []
  type: TYPE_NORMAL
- en: 'These facts will become clearer when considering the following example. Suppose
    you’re told the probabilities associated with the picnic temperature random variable
    40 ≤ *W* ≤ 90 follow the density function *f*(*w*), where the following is true:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e15-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The division by 625 is needed in this particular function to ensure a total
    probability of 1\. This will make more sense in a visualization. To plot this
    density function, first consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The first assignment sets up an even sequence of values to represent certain
    realizations of *w* simply called `w`; the second assignment uses relational operators
    and the element-wise logical operator `&` to create a logical flag vector identifying
    those elements of `w` that form the “lower half” of values for *f* (*w*) as defined
    by [Equation (15.5)](ch15.xhtml#ch15eq5); the third assignment does the same for
    the “upper half” of values.
  prefs: []
  type: TYPE_NORMAL
- en: The next lines make use of `lower.w` and `upper.w` to evaluate the correct result
    of *f* (*w*) for the entries in `w`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This doesn’t mean you’ve just written an R-coded function to return *f* (*w*)
    for any *w*. You’ve merely created the vector `w` and obtained the corresponding
    values of the *mathematical* function as the vector `fw`. However, these two vectors
    are sufficient for plotting. Using skills from [Chapter 7](ch07.xhtml#ch07), you
    can plot a line representing the continuous density function *f*(*w*) for 35 ≤
    *w* ≤ 95.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The plot is given in [Figure 15-2](ch15.xhtml#ch15fig2); note the addition of
    a dashed horizontal line at *f*(*w*) = 0 using `abline`.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f15-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 15-2: Visualizing the probability density function as defined by [Equation
    (15.5)](ch15.xhtml#ch15eq5) for the picnic temperature random variable* W *(left)
    and illustrating the computation of a specific probability from the text (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: You can see that the continuous function defined by [Equation (15.5)](ch15.xhtml#ch15eq5)
    yields a triangular shape, with an apex at *w* = 65\. The increasing line from
    *w* = 40 to *w* = 65 represents the first of the three components of (15.5), the
    decreasing line represents the second component, and for all *w* < 40 and *w*
    > 90, the line sits at zero, which is the third and final component of (15.5).
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, any function *f* (*w*) that defines a probability density for a
    random variable *W* must possess the following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: • *f* (*w*) ≥ 0 for all −∞ < *w* < ∞; and
  prefs: []
  type: TYPE_NORMAL
- en: • ![image](../images/f0321-01.jpg) (the total area underneath the function must
    be 1).
  prefs: []
  type: TYPE_NORMAL
- en: In terms of the temperature example, you can see from (15.5) that *f* (*w*)
    ≥ 0 for any value of *w*. To calculate the total area underneath the function,
    you need be concerned only with the function evaluated at 40 ≤ *w* ≤ 90 since
    it’s zero everywhere else.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can do this geometrically by working out the area of the triangle formed
    by the function and the horizontal line at zero. For this triangle, you can use
    the standard “half base times height” rule. The base of the triangle is 90 − 40
    = 50, and the apex is at a value of 0.04\. So, in R, half the base width times
    the height can be given with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This confirms it is indeed equal to 1; you can now see the reason behind my
    specific definition in (15.5).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s return to the question of obtaining the probability that the temperature
    is less than or equal to 55.2 degrees Fahrenheit. For this you must find the area
    underneath *f*(*w*), the probability density function, bounded by the horizontal
    line at zero and an imaginary vertical line at 55.2\. This particular area forms
    another triangle, for which it is again appropriate to use the “half base times
    height rule.” In Cartesian coordinates, this is the triangle formed by the vertices
    at (40,0), (55.2,0), and (55.2, *f* (55.2)), as shown in the right panel of [Figure
    15-2](ch15.xhtml#ch15fig2)—you’ll see how this is plotted in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, you should first work out the value *f* (55.2). From [Equation (15.5)](ch15.xhtml#ch15eq5),
    this is provided by creating the following object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Note that this isn’t a probability; it cannot be assigned to specific realizations.
    It’s just the height value of the triangle on the continuous density function
    that you’re going to need in order to calculate the interval-based probability
    Pr(*W* ≤ 55.2).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can easily determine that the base of the triangle of interest in this
    particular setting is 55.2 − 40 = 15.2\. Then, along with `fw.specific`, note
    that “half base times height” gives the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The answer is reached. You’ve shown geometrically, using *f*(*w*), that Pr(*W*
    ≤ 55.2) = 0.185 (when rounded to three decimal places). In other words, you can
    say that there is roughly an 18.5 percent chance that the maximum temperature
    at the picnic spot will be less than or equal to 55.2 degrees Fahrenheit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, all this is easier to digest visually. The following R code replots
    the density function *f* (*w*) and marks off and shades the area of interest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The result is the right panel of [Figure 15-2](ch15.xhtml#ch15fig2). The plotting
    commands should be familiar from [Chapter 7](ch07.xhtml#ch07), barring `polygon`.
    The built-in `polygon` function allows you to supply custom vertices in order
    to draw or shade a polygon upon an existing plot. Here, a matrix with two columns
    is defined using `rbind`, providing the *x* and *y* locations (first and second
    columns, respectively) of the three corners of the triangle to shade. Note that
    creation of `fw.specific.vertices` has made use of `fw.specific`, the value of
    *f* (*w*) at *w* = 55.2; this is the topmost vertex of the shaded triangle. Further
    arguments to `polygon` control the shading (`col="gray"`) and whether to draw
    a border around the defined polygon (`border=NA` requests no border).
  prefs: []
  type: TYPE_NORMAL
- en: 'Not all density functions can be appraised in this simple geometric fashion.
    Formally, *integration* is the mathematical operation used to find areas under
    a continuous function, denoted with the ∫ symbol. That is, the mathematically
    inclined familiar with this technique should find it straightforward to show that
    “the area under *f* (*w*) from *w* = 40 to *w* = 55.2, providing Pr(*W* ≤ 55.2)”
    is yielded by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0322-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In R, the third line of this calculation looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: R finds the correct result. I’ll leave the mathematical details aside, but it’s
    nice to confirm that the more general integral does match the intuitive geometric
    solution based on the area of the triangle, computed earlier as `fw.specific.area`.
  prefs: []
  type: TYPE_NORMAL
- en: It’s now becoming clearer why it doesn’t make sense to assign probabilities
    to single, specific realizations associated with continuous random variables.
    For example, evaluating the “area under the function *f* (*w*)” at a single value
    is the same as finding the area of a polygon with a base width of *zero*, and
    hence, the probability itself is technically zero for *any* Pr(*W* = *w*). Furthermore,
    in the continuous setting, it makes no difference to your calculations if you
    use < or ≤, or > or ≥. So although you found Pr(*W* ≤ 55.2) earlier, if you had
    been tasked to find Pr(*W* < 55.2), you would have gotten the same answer of 0.185\.
    It may all seem a little unnatural at first, but it all comes down to the idea
    of an infinite number of possible realizations so that there’s no meaningful interpretation
    of “equality” to a specific value.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cumulative Probability Distributions of Continuous Random Variables**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The cumulative probability distribution for a continuous variable is interpreted
    in the same way as for a discrete variable. Given a certain value *w*, the cumulative
    distribution function provides the probability of observing *w* or less. This
    may seem familiar; the probability you worked out earlier, Pr(*W* ≤ 55.2), based
    on the shaded triangle on the right of [Figure 15-2](ch15.xhtml#ch15fig2) or using
    analytical methods, is itself a cumulative probability. More generally, you find
    a cumulative probability for a continuous random variable by calculating the area
    under the density function of interest from −∞ to *w*. This general treatment
    therefore requires mathematical integration of the relevant probability density
    function. Looking at [Figure 15-2](ch15.xhtml#ch15fig2), you should imagine a
    vertical line moving from left to right of the density plot and, at every location,
    evaluating the area under the density function to the left of that line.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the picnic temperature example, it can be shown that the cumulative distribution
    function *F* is given with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e15-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Making use of the sequence `w` and the logical flag vectors `lower.w` and `upper.w`
    from earlier, you can use the same vector subset-and-overwrite approach to plot
    *F*(*w*); the following code creates the required vector `Fw` and produces [Figure
    15-3](ch15.xhtml#ch15fig3):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![image](../images/f15-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 15-3: Plotting the cumulative distribution function of the picnic temperature
    example, which is given as [Equation (15.6)](ch15.xhtml#ch15eq6). The cumulative
    probability of observing a temperature less than (or equal to) 55.2 is marked
    off.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Including these extra two lines following creation of this plot clearly identifies
    the fact that at *w* = 55.2, the cumulative probability is located precisely on
    the curve of *F*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '**Mean and Variance of a Continuous Random Variable**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Naturally, it’s also possible, and useful, to determine the mean and variance
    of a continuous random variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a continuous random variable *W* with density *f*, the mean *μ[W]* (or
    *expectation* or *expected value* ![image](../images/common-01a.jpg)) is again
    interpreted as the “average outcome” that you can expect over many realizations.
    This is expressed mathematically as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e15-7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This equation represents the continuous analogue of [Equation (15.3)](ch15.xhtml#ch15eq3)
    and can be read as “the total area underneath the function given by multiplication
    of the density *f*(*w*) with the value of *w* itself.”
  prefs: []
  type: TYPE_NORMAL
- en: 'For *W*, the variance ![image](../images/f0317-03.jpg), also written as Var[*W*],
    quantifies the variability inherent in realizations of *W*. Calculation of the
    continuous random variable variance depends upon its mean *μ[W]* and is given
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e15-8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Again, the procedure is to find the area under the density function multiplied
    by a certain quantity—in this case, the squared difference of the value of *w*
    with the overall expected value *μ[W]*.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation of the mean and variance of the picnic temperature random variable
    must follow (15.7) and (15.8), respectively. These calculations become rather
    complex, so I won’t reproduce them here. However, [Figure 15-2](ch15.xhtml#ch15fig2)
    shows that the mean of *W* must be *μ[W]* = 65; it is the perfect center of the
    symmetric density function *f* (*w*).
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of the required integrals, you can therefore use the previously stored
    `w` and `fw` objects to view the two functions, *w f* (*w*) and (*w* − *μ[W]*)²
    *f* (*w*), by executing the following, which produces the two images in [Figure
    15-4](ch15.xhtml#ch15fig4):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![image](../images/f15-04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 15-4: Integrands for the expected value (left) and variance (right)
    of the probability density function for the temperature example*'
  prefs: []
  type: TYPE_NORMAL
- en: Rest assured that the following can be shown mathematically using [Equations
    (15.7)](ch15.xhtml#ch15eq7) and [(15.8)](ch15.xhtml#ch15eq8).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0326-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'By visually approximating the area underneath each of the images in [Figure
    15-4](ch15.xhtml#ch15fig4), you find these results are consistent. As earlier,
    the standard deviation of the distribution of *W* is given with the square root
    of the variance, and the following readily provides this value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '***15.2.4 Shape, Skew, and Modality***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At this point, you’re familiar with both continuous and discrete random variables
    and their natural pairings with a distribution of probabilities, and you’ve had
    a look at visualizations of distributions of probability mass and density functions.
    In this section, I’ll define some terminology used to describe the appearance
    of these distributions—being able to describe your visual impressions is just
    as important as being able to readily compute them.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll often hear or read about the following descriptors:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Symmetry** A distribution is *symmetric* if you can draw a vertical line
    down the center, and it is equally reflected with 0.5 probability falling on either
    side of this center line (see [Figure 15-2](ch15.xhtml#ch15fig2)). A symmetric
    probability distribution implies that the mean and the median of the distribution
    are identical.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Skew** If a distribution is *asymmetric*, you can qualify your description
    further by discussing *skew*. When the “tail” of a distribution (in other words,
    moving away from its measures of centrality) tapers off longer in one direction
    than the other, it is in this direction that the distribution is said to be skewed.
    *Positive* or *right* skew indicates a tail extending longer to the right of center;
    *negative* or *left* skew refers to a tail extending longer to the left of center.
    You could also qualify the strength or prominence of the skew.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Modality** A probability distribution doesn’t always necessarily have a single
    peak. *Modality* describes the number of easily identifiable peaks in the distribution
    of interest. *Unimodal*, *bimodal*, and *trimodal*, for example, are the terms
    used to describe distributions with one, two, and three peaks, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 15-5](ch15.xhtml#ch15fig5) provides some visual interpretations of
    symmetry, asymmetry, skew, and modality. (Note that although they are drawn with
    a continuous line, you can assume they represent the general shape of either a
    discrete probability mass function *or* a continuous density function.)'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f15-05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 15-5: General examples of the terms used to describe probability distributions.
    The top three images are unimodal and highlight the notion of symmetry versus
    asymmetric skew; the bottom two images emphasize the reference to modality.*'
  prefs: []
  type: TYPE_NORMAL
- en: You can use these descriptors when discussing the probability distributions
    for the gambling game and picnic temperature examples. The mass function for *X*,
    on the left in [Figure 15-1](ch15.xhtml#ch15fig1), is unimodal and asymmetric—it
    appears to have a mild but noticeable right skew. The density function for *W*,
    given in [Figure 15-2](ch15.xhtml#ch15fig2), is also unimodal, though as noted
    earlier is perfectly symmetric.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 15.2**'
  prefs: []
  type: TYPE_NORMAL
- en: For each of the following definitions, identify whether it’s best described
    as a random variable or as a *realization* of a random variable. Furthermore,
    identify whether each statement describes a continuous or a discrete quantity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The number of coffees *x* made by your local shop on June 3, 2016
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The number of coffees *X* made by your local shop on any given day
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Y*, whether or not it rains tomorrow'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Z*, the amount of rain that falls tomorrow'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How many crumbs *k* on your desk right now
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Total collective weight *W* of the crumbs on your desk at any specified time
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Suppose you construct the following table providing probabilities associated
    with the random variable *S*, the total stars given to any movie in a particular
    genre by a certain critic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| ***s*** | **1** | **2** | **3** | **4** | **5** |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Pr(*S* = *s*)** | 0.10 | 0.13 | 0.21 | ??? | 0.15 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: Assuming this table describes the complete set of outcomes, evaluate the missing
    probability Pr(*S* = 4).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Obtain the cumulative probabilities.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the mean of *S*, the expected number of stars this critic will award
    any given movie in this genre?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the standard deviation of *S*?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the probability that any given movie in this genre will be given at
    least three stars?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Visualize, and briefly comment on the appearance of, the probability mass function.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Return to the picnic temperature example based on the random variable *W* defined
    in [Section 15.2.3](ch15.xhtml#ch15lev2sec135).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write an R function to return *f*(*w*) as per [Equation (15.5)](ch15.xhtml#ch15eq5)
    for any numeric vector of values supplied as *w*. Try to avoid using a loop in
    favor of vector-oriented operations.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Write an R function to return *F*(*w*) as per [Equation (15.6)](ch15.xhtml#ch15eq6)
    for any numeric vector of values supplied as *w*. Again, try to avoid using a
    loop, either explicit or implicit.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use your functions from (i) and (ii) to confirm the results from the text, in
    other words, that *f* (55.2) = 0.02432 and that *F*(55.2) = 0.184832.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Make use of your function for *F*(*w*) to compute Pr(*W* > 60). Hint: Note
    that because the total area underneath *f* (*w*) is one, Pr(*W* > 60) = 1 − Pr(*W*
    ≤ 60).'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Find Pr(60.3 < *W* < 76.89).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Assume each of the following plots labeled (i)–(iv) shows the general appearance
    of a probability distribution. Use terminology from [Section 15.2.4](ch15.xhtml#ch15lev2sec136)
    to describe the shape of each.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![image](../images/f0329-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Important Code in This Chapter**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| **Function/operator** | **Brief description** | **First occurrence** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `polygon` | Add shaded polygon to plot | [Section 15.2.3](ch15.xhtml#ch15lev2sec135),
    [p. 322](ch15.xhtml#page_322) |'
  prefs: []
  type: TYPE_TB
