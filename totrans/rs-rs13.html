<html><head></head><body><div id="sbo-rt-content"><section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="223" id="Page_223"/>13</span><br/>
<span class="ChapterTitle">The Rust Ecosystem</span></h1>
</header>
<figure class="opener">
<img src="Images/chapterart.png" alt="" width="206" height="206"/>
</figure>
<p class="ChapterIntro">Programming rarely happens in a vacuum these days—nearly every Rust crate you build is likely to take dependencies on <em>some</em> code that wasn’t written by you. Whether this trend is good, bad, or a little of both is a subject of heavy debate, but either way, it’s a reality of today’s developer experience. </p>
<p>In this brave new interdependent world, it’s more important than ever to have a solid grasp of what libraries and tools are available and to stay up to date on the latest and greatest of what the Rust community has to offer. This chapter is dedicated to how you can leverage, track, understand, and contribute back to the Rust ecosystem. Since this is the final chapter, in the closing section I’ll also provide some suggestions of additional resources you can explore to continue developing your Rust skills.</p>
<h2 id="h1--0001"><span epub:type="pagebreak" title="224" id="Page_224"/>What’s Out There?</h2>
<p class="BodyFirst">Despite its relative youth, Rust already has an ecosystem large enough that it’s hard to keep track of everything that’s available. If you know what you want, you may be able to search your way to a set of appropriate crates and then use download statistics and superficial vibe-checks on each crate’s repository to determine which may make for reasonable dependencies. However, there’s also a plethora of tools, crates, and general language features that you might not necessarily know to look for that could potentially save you countless hours and difficult design decisions.</p>
<p>In this section, I’ll go through some of the tools, libraries, and Rust features I have found helpful over the years in the hopes that they may come in useful for you at some point too!</p>
<h3 id="h2--0001">Tools</h3>
<p class="BodyFirst">First off, here are some Rust tools I find myself using regularly that you should add to your toolbelt:</p>
<p class="ListHead"><b><code class="bold">cargo-deny</code></b></p>
<ol class="none">
<li>Provides a way to lint your dependency graph. At the time of writing, you can use <code>cargo-deny</code> to allow only certain licenses, deny-list crates or specific crate versions, detect dependencies with known vulnerabilities or that use Git sources, and detect crates that appear multiple times with different versions in the dependency graph. By the time you’re reading this, there may be even more handy lints in place.</li>
</ol>
<p class="ListHead"><b><code class="bold">cargo-expand</code></b></p>
<ol class="none">
<li>Expands macros in a given crate and lets you inspect the output, which makes it much easier to spot mistakes deep down in macro transcribers or procedural macros. <code>cargo-expand</code> is an invaluable tool when you’re writing your own macros.</li>
</ol>
<p class="ListHead"><b><code class="bold">cargo-hack</code></b></p>
<ol class="none">
<li>Helps you check that your crate works with any combination of features enabled. The tool presents an interface similar to that of Cargo itself (like <code>cargo check</code>, <code>build</code>, and <code>test</code>) but gives you the ability to run a given command with all possible combinations (the <em>powerset</em>) of the crate’s features.</li>
</ol>
<p class="ListHead"><b><code class="bold">cargo-llvm-lines</code></b></p>
<ol class="none">
<li>Analyzes the mapping from Rust code to the intermediate representation (IR) that’s passed to the part of the Rust compiler that actually generates machine code (LLVM), and tells you which bits of Rust code produce the largest IR. This is useful because a larger IR means longer compile times, so identifying what Rust code generates a bigger IR (due <span epub:type="pagebreak" title="225" id="Page_225"/>to, for example, monomorphization) can highlight opportunities for reducing compile times.</li>
</ol>
<p class="ListHead"><b><code class="bold">cargo-outdated</code></b></p>
<ol class="none">
<li>Checks whether any of your dependencies, either direct or transitive, have newer versions available. Crucially, unlike <code>cargo update</code>, it even tells you about new major versions, so it’s an essential tool for checking if you’re missing out on newer versions due to an outdated major version specifier. Just keep in mind that bumping the major version of a dependency may be a breaking change for your crate if you expose that dependency’s types in your interface!</li>
</ol>
<p class="ListHead"><b><code class="bold">cargo-udeps</code></b></p>
<ol class="none">
<li>Identifies any dependencies listed in your <em>Cargo.toml</em> that are never actually used. Maybe you used them in the past but they’ve since become redundant, or maybe they should be moved to <code>dev-dependencies</code>; whatever the case, this tool helps you trim down bloat in your dependency closure.</li>
</ol>
<p>While they’re not specifically tools for developing Rust, I highly recommend <code>fd</code> and <code>ripgrep</code> too—they’re excellent improvements over their predecessors <code>find</code> and <code>grep</code> and also happen to be written in Rust themselves. I use both every day.</p>
<h3 id="h2--0002">Libraries</h3>
<p class="BodyFirst">Next up are some useful but lesser-known crates that I reach for regularly, and that I suspect I will continue to depend on for a long time:</p>
<p class="ListHead"><b><code class="bold">bytes</code></b></p>
<ol class="none">
<li>Provides an efficient mechanism for passing around subslices of a single piece of contiguous memory without having to copy or deal with lifetimes. This is great in low-level networking code where you may need multiple views into a single chunk of bytes, and copying is a no-no.</li>
</ol>
<p class="ListHead"><b><code class="bold">criterion</code></b></p>
<ol class="none">
<li>A statistics-driven benchmarking library that uses math to eliminate noise from benchmark measurements and reliably detect changes in performance over time. You should almost certainly be using it if you’re including micro-benchmarks in your crate.</li>
</ol>
<p class="ListHead"><b><code class="bold">cxx</code></b></p>
<ol class="none">
<li>Provides a safe and ergonomic mechanism for calling C++ code from Rust and Rust code from C++. If you’re willing to invest some time into declaring your interfaces more thoroughly in advance in exchange for much nicer cross-language compatibility, this library is well worth your attention.</li>
</ol>
<p class="ListHead"><b><span epub:type="pagebreak" title="226" id="Page_226"/><code class="bold">flume</code></b></p>
<ol class="none">
<li>Implements a multi-producer, multi-consumer channel that is faster, more flexible, and simpler than the one included with the Rust standard library. It also supports both asynchronous and synchronous operation and so is a great bridge between those two worlds.</li>
</ol>
<p class="ListHead"><b><code class="bold">hdrhistogram</code></b></p>
<ol class="none">
<li>A Rust port of the High Dynamic Range (HDR) histogram data structure, which provides a compact representation of histograms across a wide range of values. Anywhere you currently track averages or min/max values, you should most likely be using an HDR histogram instead; it can give you much better insight into the distribution of your metrics.</li>
</ol>
<p class="ListHead"><b><code class="bold">heapless</code></b></p>
<ol class="none">
<li>Supplies data structures that do not use the heap. Instead, <code>heapless</code>’s data structures are all backed by static memory, which makes them perfect for embedded contexts or other situations in which allocation is undesirable.</li>
</ol>
<p class="ListHead"><b><code class="bold">itertools</code></b></p>
<ol class="none">
<li>Extends the <code>Iterator</code> trait from the standard library with lots of new convenient methods for deduplication, grouping, and computing powersets. These extension methods can significantly reduce boilerplate in code, such as where you manually implement some common algorithm over a sequence of values, like finding the min and max at the same time (<code>Itertools::minmax</code>), or where you use a common pattern like checking that an iterator has exactly one item (<code>Itertools::exactly_one</code>).</li>
</ol>
<p class="ListHead"><b><code class="bold">nix</code></b></p>
<ol class="none">
<li>Provides idiomatic bindings to system calls on Unix-like systems, which allows for a much better experience than trying to cobble together the C-compatible FFI types yourself when working with something like <code>libc</code> directly.</li>
</ol>
<p class="ListHead"><b><code class="bold">pin-project</code></b></p>
<ol class="none">
<li>Provides macros that enforce the pinning safety invariants for annotated types, which in turn provide a safe pinning interface to those types. This allows you to avoid most of the hassle of getting <code>Pin</code> and <code>Unpin</code> right for your own types. There’s also <code>pin-project-lite</code>, which avoids the (currently) somewhat heavy dependency on the procedural macro machinery at the cost of slightly worse ergonomics.</li>
</ol>
<p class="ListHead"><b><code class="bold">ring</code></b></p>
<ol class="none">
<li>Takes the good parts from the cryptography library BoringSSL, written in C, and brings them to Rust through a fast, simple, and <span epub:type="pagebreak" title="227" id="Page_227"/>hard-to-misuse interface. It’s a great starting point if you need to use cryptography in your crate. You’ve already most likely come across this in the <code>rustls</code> library, which uses <code>ring</code> to provide a modern, secure-by-default TLS stack.</li>
</ol>
<p class="ListHead"><b><code class="bold">slab</code></b></p>
<ol class="none">
<li>Implements an efficient data structure to use in place of <code>HashMap&lt;Token, T&gt;</code>, where <code>Token</code> is an opaque type used only to differentiate between entries in the map. This kind of pattern comes up a lot when managing resources, where the set of current resources must be managed centrally but individual resources must also be accessible somehow.</li>
</ol>
<p class="ListHead"><b><code class="bold">static_assertions</code></b></p>
<ol class="none">
<li>Provides static assertions—that is, assertions that are evaluated at, and thus may fail at, compile time. You can use it to assert things like that a type implements a given trait (like <code>Send</code>) or is of a given size. I highly recommend adding these kinds of assertions for code where those guarantees are likely to be important.</li>
</ol>
<p class="ListHead"><b><code class="bold">structopt</code></b></p>
<ol class="none">
<li>Wraps the well-known argument parsing library <code>clap</code> and provides a way to describe your application’s command line interface entirely using the Rust type system (plus macro annotations). When you parse your application’s arguments, you get a value of the type you defined, and you thus get all the type checking benefits, like exhaustive matching and IDE auto-complete.</li>
</ol>
<p class="ListHead"><b><code class="bold">thiserror</code></b></p>
<ol class="none">
<li>Makes writing custom enumerated error types, like the ones we discussed in <span class="xref" itemid="xref_target_Chapter 4">Chapter 4</span>, a joy. It takes care of implementing the recommended traits and following the established conventions and leaves you to define just the critical bits that are unique to your application.</li>
</ol>
<p class="ListHead"><b><code class="bold">tower</code></b></p>
<ol class="none">
<li>Effectively takes the function signature <code>async fn(Request) -&gt; Response</code> and implements an entire ecosystem on top of it. At its core is the <code>Service</code> trait, which represents a type that can turn a request into a response (something I suspect may make its way into the standard library one day). This is a great abstraction to build anything that looks like a service on top of.</li>
</ol>
<p class="ListHead"><b><code class="bold">tracing</code></b></p>
<ol class="none">
<li>Provides all the plumbing needed to efficiently trace the execution of your applications. Crucially, it is agnostic to the types of events you’re tracing and what you want to do with those events. This library can be <span epub:type="pagebreak" title="228" id="Page_228"/>used for logging, metrics collection, debugging, profiling, and obviously tracing, all with the same machinery and interfaces.</li>
</ol>
<h3 id="h2--0003">Rust Tooling</h3>
<p class="BodyFirst">The Rust toolchain has a few features up its sleeve that you may not know to look for. These are usually for very specific use cases, but if they match yours, they can be lifesavers!</p>
<h4 id="h3--0001">Rustup</h4>
<p class="BodyFirst">Rustup, the Rust toolchain installer, does its job so efficiently that it tends to fade into the background and get forgotten about. You’ll occasionally use it to update your toolchain, set a directory override, or install a component, but that’s about it. However, Rustup supports one very handy trick that it’s worthwhile to know about: the toolchain override shorthand. You can pass <code>+toolchain</code> as the first argument to any Rustup-managed binary, and the binary will work as if you’d set an override for the given toolchain, run the command, and then reset the override back to what it was previously. So, <code>cargo +nightly miri</code> will run Miri using the nightly toolchain, and <code>cargo +1.53.0 check</code> will check if the code compiles with Rust 1.53.0. The latter comes in particularly handy for checking that you haven’t broken your minimum supported Rust version contract.</p>
<p>Rustup also has a neat subcommand, <code>doc</code>, that opens a local copy of the Rust standard library documentation for the current version of the Rust compiler in your browser. This is invaluable if you’re developing on the go without an internet connection!</p>
<h4 id="h3--0002">Cargo</h4>
<p class="BodyFirst">Cargo also has some handy features that aren’t always easy to discover. The first of these is <code>cargo tree</code>, a Cargo subcommand built right into Cargo itself for inspecting a crate’s dependency graph. This command’s primary purpose is to print the dependency graph as a tree. This can be useful on its own, but where <code>cargo tree</code> really shines is through the <code>--invert</code> option: it takes a crate identifier and produces an inverted tree showing all the dependency paths from the current crate that bring in that dependency. So, for example, <code>cargo tree -i rand</code> will print all of the ways in which the current crate depends on any version of <code>rand</code>, including through transitive dependencies. This is invaluable if you want to eliminate a dependency, or a particular version of a dependency, and wonder why it still keeps being pulled in. You can also pass the <code>-e features</code> option to include information about why each Cargo feature of the crate in question is enabled.</p>
<p>Speaking of Cargo subcommands, it’s really easy to write your own, whether for sharing with other people or just for your own local development. When Cargo is invoked with a subcommand it doesn’t recognize, it checks whether a program by the name <code>cargo-$subcommand</code> exists. If it does, Cargo invokes that program and passes it any arguments that were passed <span epub:type="pagebreak" title="229" id="Page_229"/>on the command line—so, <code>cargo foo bar</code> will invoke <code>cargo-foo</code> with the argument <code>bar</code>. Cargo will even integrate this command with <code>cargo help</code> by translating <code>cargo help foo</code> into a call to <code>cargo-foo --help</code>.</p>
<p>As you work on more Rust projects, you may notice that Cargo (and Rust more generally) isn’t exactly forgiving when it comes to disk space. Each project gets its own target directory for its compilation artifacts, and over time you end up accumulating several identical copies of compiled artifacts for common dependencies. Keeping artifacts for each project separate is a sensible choice, as they aren’t necessarily compatible across projects (say, if one project uses different compiler flags than another). But in most developer environments, sharing build artifacts is entirely reasonable and can save a fair amount of compilation time when switching between projects. Luckily, configuring Cargo to share build artifacts is simple: just set <code>[build] target</code> in your <em>~/.cargo/config.toml</em> file to the directory you want those shared artifacts to go in, and Cargo will take care of the rest. No more target directories in sight! Just make sure you clean out that directory every now and again too, and be aware that <code>cargo clean</code> will now clean <em>all</em> of your projects’ build artifacts.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Using a shared build directory can cause problems for projects that assume that compiler artifacts will always be under the <em>target/</em> subdirectory, so watch out for that. Also note that if a project <em>does</em> use different compiler flags, you’ll end up recompiling affected dependencies every time you move into or out of that project. In such cases, you’re best off overriding the target directory in that project’s Cargo configuration to a distinct location.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Finally, if you ever feel like Cargo is taking a suspiciously long time to build your crate, you can reach for the currently unstable Cargo <code>-Ztimings</code> flag. Running Cargo with that flag outputs information about how long it took to process each crate, how long build scripts took to run, what crates had to wait for what other crates to finish compiling, and tons of other useful metrics. This might highlight a particularly slow dependency chain that you can then work to eliminate, or reveal a build script that compiles a native dependency from scratch that you can make use system libraries instead. If you want to dive even deeper, there’s also <code>rustc -Ztime-passes</code>, which emits information about where time is spent inside of the compiler for each crate—though that information is likely only useful if you’re looking to contribute to the compiler itself.</p>
<h4 id="h3--0003">rustc</h4>
<p class="BodyFirst">The Rust compiler also has some lesser-known features that can prove useful to enterprising developers. The first is the currently unstable <code>-Zprint-type-sizes</code> argument, which prints the sizes of all the types in the current crate. This produces a lot of information for all but the tiniest crates but is immensely valuable when trying to determine the source of unexpected time spent in calls to <code>memcpy</code> or to find ways to reduce memory use when allocating lots of objects of a particular type. The <code>-Zprint-type-sizes</code> argument <span epub:type="pagebreak" title="230" id="Page_230"/>also displays the computed alignment and layout for each type, which may point you to places where turning, say, a <code>usize</code> into a <code>u32</code> could have a significant impact on a type’s in-memory representation. After you debug a particular type’s size, alignment, and layout, I recommend adding static assertions to make sure that they don’t regress over time. You may also be interested in the <code>variant_size_differences</code> lint, which issues a warning if a crate contains <code>enum</code> types whose variants significantly differ in size.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	To call <code>rustc</code> with particular flags, you have a few options: you can either set them in the <code>RUSTFLAGS</code> environment variable or <code>[build] rustflags</code> in your <em>.cargo/config.toml</em> to have them apply to every invocation of <code>rustc</code> from Cargo, or you can use <code>cargo rustc</code>, which will pass any arguments you provide only to the <code>rustc</code> invocation for the current crate.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>If your profiling samples look weird, with stack frames reordered or entirely missing, you could also try <code>-Cforce-frame-pointers = yes</code>. Frame pointers provide a more reliable way to unwind the stack—which is done a lot during profiling—at the cost of an extra register being used for function calls. Even though stack unwinding <em>should</em> work fine with just regular debug symbols enabled (remember to set <code>debug = true</code> when using the release profile), that’s not always the case, and frame pointers may take care of any issues you do encounter.</p>
<h3 id="h2--0004">The Standard Library</h3>
<p class="BodyFirst">The Rust standard library is generally considered to be small compared to those of other programming languages, but what it lacks in breadth, it makes up for in depth; you won’t find a web server implementation or an X.509 certificate parser in Rust’s standard library, but you will find more than 40 different methods on the <code>Option</code> type alongside over 20 trait implementations. For the types it does include, Rust does its best to make available any relevant functionality that meaningfully improves ergonomics, so you avoid all that verbose boilerplate that can so easily arise otherwise. In this section, I’ll present some types, macros, functions, and methods from the standard library that you may not have come across before, but that can often simplify or improve (or both) your code.</p>
<h4 id="h3--0004">Macros and Functions</h4>
<p class="BodyFirst">Let’s start off with a few free-standing utilities. First up is the <code class="bold">write!</code> macro, which lets you use format strings to write into a file, a network socket, or anything else that implements <code>Write</code>. You may already be familiar with it—but one little-known feature of <code>write!</code> is that it works with both <code>std::io::Write</code> and <code>std::fmt::Write</code>, which means you can use it to write formatted text directly into a <code>String</code>. That is, you can write <code>use std::fmt::Write; write!(&amp;mut s, "{}+1={}", x, x + 1);</code> to append the formatted text to the <code>String s</code>!</p>
<p>The <code class="bold">iter::once</code> function takes any value and produces an iterator that yields that value once. This comes in handy when calling functions that take <span epub:type="pagebreak" title="231" id="Page_231"/>iterators if you don’t want to allocate, or when combined with <code>Iterator::chain</code> to append a single item to an existing iterator.</p>
<p>We briefly talked about <code class="bold">mem::replace</code> in <span class="xref" itemid="xref_target_Chapter 1">Chapter 1</span>, but it’s worth bringing up again in case you missed it. This function takes an exclusive reference to a <code>T</code> and an owned <code>T</code>, swaps the two so that the referent is now the owned <code>T</code>, and returns ownership of the previous referent. This is useful when you need to take ownership of a value in a situation where you have only an exclusive reference, such as in implementations of <code>Drop</code>. See also <code>mem::take</code> for when <code>T: Default</code>.</p>
<h4 id="h3--0005">Types</h4>
<p class="BodyFirst">Next, let’s look at some handy standard library types. The <code class="bold">BufReader</code> and <code class="bold">BufWriter</code> types are a must for I/O operations that issue many small read or write calls to the underlying I/O resource. These types wrap the respective underlying <code>Read</code> or <code>Write</code> and implement <code>Read</code> and <code>Write</code> themselves, but they additionally buffer the operations to the I/O resource such that many small reads do only one large read, and many small writes do only one large write. This can significantly improve performance as you don’t have to cross the system call barrier into the operating system as often.</p>
<p>The <code class="bold">Cow</code> type, mentioned in <span class="xref" itemid="xref_target_Chapter 3">Chapter 3</span>, is useful when you want flexibility in what types you hold or need flexibility in what you return. You’ll rarely use <code>Cow</code> as a function argument (recall that you should let the caller allocate if necessary), but it’s invaluable as a return type as it allows you to accurately represent the return types of functions that may or may not allocate. It’s also a perfect fit for types that can be used as inputs <em>or</em> outputs, such as core types in RPC-like APIs. Say we have a type <code>EntityIdentifier</code> like in <a href="#listing13-1" id="listinganchor13-1">Listing 13-1</a> that is used in an RPC service interface.</p>
<pre><code>struct EntityIdentifier {
    namespace: String,
    name: String,
}</code></pre>
<p class="CodeListingCaption"><a id="listing13-1">Listing 13-1</a>: A representation of a combined input/output type that requires allocation</p>
<p>Now imagine two methods: <code>get_entity</code> takes an <code>EntityIdentifier</code> as an argument, and <code>find_by</code> returns an <code>EntityIdentifier</code> based on some search parameters. The <code>get_entity</code> method requires only a reference since the identifier will (presumably) be serialized before being sent to the server. But for <code>find_by</code>, the entity will be deserialized from the server response and must therefore be represented as an owned value. If we make <code>get_entity</code> take <code>&amp;EntityIdentifier</code>, it will mean callers must still allocate owned <code>String</code>s to call <code>get_entity</code> even though that’s not required by the interface, since it’s required to construct an <code>EntityIdentifier</code> in the first place! We could instead introduce a separate type for <code>get_entity</code>, <code>EntityIdenifierRef</code>, that holds only <code>&amp;str</code> types, but then we’d have two types to represent one thing. <code>Cow</code> to the rescue! <a href="#listing13-2" id="listinganchor13-2">Listing 13-2</a> shows an <code>EntityIdentifier</code> that instead holds <code>Cow</code>s internally.</p>
<pre><code><span epub:type="pagebreak" title="232" id="Page_232"/>struct EntityIdentifier&lt;'a&gt; {
    namespace: Cow&lt;'a, str&gt;,
    name: Cow&lt;'a str&gt;,
}</code></pre>
<p class="CodeListingCaption"><a id="listing13-2">Listing 13-2</a>: A representation of a combined input/output type that does not require allocation</p>
<p>With this construction, <code>get_entity</code> can take any <code>EntityIdentifier&lt;'_&gt;</code>, which allows the caller to use just references to call the method. And <code>find_by</code> can return <code>EntityIdentifier&lt;'static&gt;</code>, where all the fields are <code>Cow::Owned</code>. One type shared across both interfaces, with no unnecessary allocation requirements!</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	If you implement a type this way, I recommend you also provide an <code>into_own</code><code>ed</code> method that turns an <code>&lt;'a&gt;</code> instance into a <code>&lt;'static&gt;</code> instance by calling <code>Cow::into_owned</code> on all the fields. Otherwise, users will have no way to make longer-lasting clones of your type when all they have is an <code>&lt;'a&gt;</code>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>The <code class="bold">std::sync::Once</code> type is a synchronization primitive that lets you run a given piece of code exactly once, at initialization time. This is great for initialization that’s part of an FFI where the library on the other side of the FFI boundary requires that the initialization is performed only once.</p>
<p>The <code class="bold">VecDeque</code> type is an oft-neglected member of <code>std::collections</code> that I find myself reaching for surprisingly often—basically, whenever I need a stack or a queue. Its interface is similar to that of a <code>Vec</code>, and like <code>Vec</code> its in-memory representation is a single chunk of memory. The difference is that <code>VecDeque</code> keeps track of both the start and end of the actual data in that single allocation. This allows constant-time push and pop from <em>either</em> side of the <code>VecDeque</code>, meaning it can be used as a stack, as a queue, or even both at the same time. The cost you pay is that the values are no longer necessarily contiguous in memory (they may have wrapped around), which means that <code>VecDeque&lt;T&gt;</code> does not implement <code>AsRef&lt;[T]&gt;</code>.</p>
<h4 id="h3--0006">Methods</h4>
<p class="BodyFirst">Let’s round off with a rapid-fire look at some neat methods. First up is <code class="bold">Arc::make_mut</code>, which takes a <code>&amp;mut Arc&lt;T&gt;</code> and gives you a <code>&amp;mut T</code>. If the <code>Arc</code> is the last one in existence, it gives you the <code>T</code> that was behind the <code>Arc</code>; otherwise, it allocates a new <code>Arc&lt;T&gt;</code> that holds a clone of the <code>T</code>, swaps that in for the currently referenced <code>Arc</code>, and then gives <code>&amp;mut</code> to the <code>T</code> in the new singleton <code>Arc</code>. </p>
<p>The <code class="bold">Clone::clone_from</code> method is an alternative form of <code>.clone()</code> that lets you reuse an instance of the type you clone rather than allocate a new one. In other words, if you already have an <code>x: T</code>, you can do <code>x.clone_from(y)</code> rather than <code>x = y.clone()</code>, and you might save yourself some allocations.</p>
<p><code class="bold">std::fmt::Formatter::debug_*</code> is by far the easiest way to implement <code>Debug</code> yourself if <code>#[derive(Debug)]</code> won’t work for your use case, such as if you want to include only some fields or expose information that isn’t exposed by the <code/><span epub:type="pagebreak" title="233" id="Page_233"/>Debug implementations of your type’s fields. When implementing the <code>fmt</code> method of <code>Debug</code>, simply call the appropriate <code>debug_</code> method on the <code>Formatter</code> that’s passed in (<code>debug_struct</code> or <code>debug_map</code>, for example), call the included methods on the resulting type to fill in details about the type (like <code>field</code> to add a field or <code>entries</code> to add a key/value entry), and then call <code>finish</code>.</p>
<p><code class="bold">Instant::elapsed</code> returns the <code>Duration</code> since an <code>Instant</code> was created. This is much more concise than the common approach of creating a new <code>Instant</code> and subtracting the earlier instance.</p>
<p><code class="bold">Option::as_deref</code> takes an <code>Option&lt;P&gt;</code> where <code>P: Deref</code> and returns <code>Option&lt;&amp;P::Target&gt;</code> (there’s also an <code>as_deref_mut</code> method). This simple operation can make functional transformation chains that operate on <code>Option</code> much cleaner by avoiding the inscrutable <code>.as_ref().map(|r| &amp;**r)</code>.</p>
<p><code class="bold">Ord::clamp</code> lets you take any type that implements <code>Ord</code> and clamp it between two other values of a given range. That is, given a lower limit <code>min</code> and an upper limit <code>max</code>, <code>x.clamp(min, max)</code> returns <code>min</code> if <code>x</code> is less than <code>min</code>, <code>max</code> if <code>x</code> is greater than <code>max</code>, and <code>x</code> otherwise.</p>
<p><code class="bold">Result::transpose</code> and its counterpart <code class="bold">Option::transpose</code> invert types that nest <code>Result</code> and <code>Option</code>. That is, transposing a <code>Result&lt;Option&lt;T&gt;, E&gt;</code> gives an <code>Option&lt;Result&lt;T, E&gt;&gt;</code>, and vice versa. When combined with <code>?</code>, this operation can make for cleaner code when working with <code>Iterator::next</code> and similar methods in fallible contexts.</p>
<p><code class="bold">Vec::swap_remove</code> is <code>Vec::remove</code>’s faster twin. <code>Vec::remove</code> preserves the order of the vector, which means that to remove an element in the middle, it must shift all the later elements in the vector down by one. This can be very slow for large vectors. <code>Vec::swap_remove</code>, on the other hand, swaps the to-be-removed element with the last element and then truncates the vector’s length by one, which is a constant-time operation. Be aware, though, that it will shuffle your vector around and thus invalidate old indexes!</p>
<h2 id="h1--0002">Patterns in the Wild</h2>
<p class="BodyFirst">As you start exploring codebases that aren’t your own, you’ll likely come across a couple of common Rust patterns that we haven’t discussed in the book so far. Knowing about them will make it easier to recognize them, and thus understand their purpose, when you do encounter them. You may even find use for them in your own codebase one day!</p>
<h3 id="h2--0005">Index Pointers</h3>
<p class="BodyFirst">Index pointers allow you to store multiple references to data within a data structure without running afoul of the borrow checker. For example, if you want to store a collection of data so that it can be efficiently accessed in more than one way, such as by keeping one <code>HashMap</code> keyed by one field and one keyed by a different field, you don’t want to store the underlying data multiple times too. You could use <code>Arc</code> or <code>Rc</code>, but they use dynamic reference counting that introduces unnecessary overhead, and the extra bookkeeping requires you to store additional bytes per entry. You could use references, but the lifetimes become difficult if not impossible to manage because the <span epub:type="pagebreak" title="234" id="Page_234"/>data and the references live in the same data structure (it’s a self-referential data structure, as we discussed in <span class="xref" itemid="xref_target_Chapter 8">Chapter 8</span>). You could use raw pointers combined with <code>Pin</code> to ensure the pointers remain valid, but that introduces a lot of complexity as well as unsafety you then need to carefully consider.</p>
<p>Most crates use index pointers—or, as I like to call them, <em>indeferences</em>—instead. The idea is simple: store each data entry in some indexable data structure like a <code>Vec</code>, and then store just the index in a derived data structure. To then perform an operation, first use the derived data structure to efficiently find the data index, and then use the index to retrieve the referenced data. No lifetimes needed—and you can even have cycles in the derived data representation if you wish!</p>
<p>The <code>indexmap</code> crate, which provides a <code>HashMap</code> implementation where the iteration order matches the map insertion order, provides a good example of this pattern. The implementation has to store the keys in two places, both in the map of keys to values and in the list of all the keys, but it obviously doesn’t want to keep two copies in case the key type itself is large. So, it uses index pointers. Specifically, it keeps all the key/value pairs in a single <code>Vec</code> and then keeps a mapping from key hashes to <code>Vec</code> indexes. To iterate over all the elements of the map, it just walks the <code>Vec</code>. To look up a given key, it hashes that key, looks that hash up in the mapping, which yields the key’s index in the <code>Vec</code> (the index pointer), and then uses that to get the key’s value from the <code>Vec</code>.</p>
<p>The <code>petgraph</code> crate, which implements graph data structures and algorithms, also uses this pattern. The crate stores one <code>Vec</code> of all node values and another of all edge values and then only ever uses the indexes into those <code>Vec</code>s to refer to a node or edge. So, for example, the two nodes associated with an edge are stored in that edge simply as two <code>u32</code>s, rather than as references or reference-counted values.</p>
<p>The trick lies in how you support deletions. To delete a data entry, you first need to search for its index in all of the derived data structures and remove the corresponding entries, and then you need to remove the data from the root data store. If the root data store is a <code>Vec</code>, removing the entry will also change the index of one other data entry (when using <code>swap_remove</code>), so you then need to go update all the derived data structures to reflect the new index for the entry that moved.</p>
<h3 id="h2--0006">Drop Guards</h3>
<p class="BodyFirst">Drop guards provide a simple but reliable way to ensure that a bit of code runs even in the presence of panics, which is often essential in unsafe code. An example is a function that takes a closure <code>f: FnOnce</code> and executes it under mutual exclusion using atomics. Say the function uses <code>compare_exchange</code> (discussed in <span class="xref" itemid="xref_target_Chapter 10">Chapter 10</span>) to set a Boolean from <code>false</code> to <code>true</code>, calls <code>f</code>, and then sets the Boolean back to <code>false</code> to end the mutual exclusion. But consider what happens if <code>f</code> panics—the function will never get to run its cleanup, and no other call will be able to enter the mutual exclusion section ever again.</p>
<p>It’s possible to work around this using <code>catch_unwind</code>, but drop guards provide an alternative that is often more ergonomic. <a href="#listing13-3" id="listinganchor13-3">Listing 13-3</a> shows <span epub:type="pagebreak" title="235" id="Page_235"/>how, in our current example, we can use a drop guard to ensure the Boolean always gets reset.</p>
<pre><code>fn mutex(lock: &amp;AtomicBool, f: impl FnOnce()) {
    <span class="LiteralGray">// .. while lock.compare_exchange(false, true).is_err() ..</span>
    struct DropGuard&lt;'a&gt;(&amp;'a AtomicBool);
    impl Drop for DropGuard&lt;'_&gt; {
        fn drop(&amp;mut self) {
            self.0.store(true, Ordering::Release);
        }
    }
    let _guard = DropGuard(lock);
    f();
}</code></pre>
<p class="CodeListingCaption"><a id="listing13-3">Listing 13-3</a>: Using a drop guard to ensure code gets run after an unwinding panic</p>
<p>We introduce the local type <code>DropGuard</code> that implements <code>Drop</code> and place the cleanup code in its implementation of <code>Drop::drop</code>. Any necessary state can be passed in through the fields of <code>DropGuard</code>. Then, we construct an instance of the guard type just before we call the function that might panic, which is <code>f</code> here. When <code>f</code> returns, whether due to a panic or because it returns normally, the guard is dropped, its destructor runs, the lock is released, and all is well.</p>
<p>It’s important that the guard is assigned to a variable that is dropped at the end of the scope, after the user-provided code has been executed. This means that even though we never refer to the guard’s variable again, it needs to be given a name, as <code>let _ = DropGuard(lock)</code> would drop the guard immediately—before the user-provided code even runs!</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Like <code>catch_unwind</code>, drop guards work only when panics unwind. If the code is compiled with <code>panic=abort</code>, no code gets to run after the panic.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>This pattern is frequently used in conjunction with thread locals, when library code may wish to set the thread local state so that it’s valid only for the duration of the execution of the closure, and thus needs to be cleared afterwards. For example, at the time of writing, Tokio uses this pattern to provide information about the executor calling <code>Future::poll</code> to leaf resources like <code>TcpStream</code> without having to propagate that information through function signatures that are visible to users. It’d be no good if the thread local state continued to indicate that a particular executor thread was active even after <code>Future::poll</code> returned due to a panic, so Tokio uses a drop guard to ensure that the thread local state is reset.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	You’ll often see <code>Cell</code> or <code>Rc&lt;RefCell&gt;</code> used in thread locals. This is because thread locals are accessible only through shared references, since a thread might access a thread local again that it is already referencing somewhere higher up in the call stack. Both types provide interior mutability without incurring much overhead because they’re intended only for single-threaded use, and so are ideal for this use case.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2--0007"><span epub:type="pagebreak" title="236" id="Page_236"/>Extension Traits</h3>
<p class="BodyFirst">Extension traits allow crates to provide additional functionality to types that implement a trait from a different crate. For example, the <code>itertools</code> crate provides an extension trait for <code>Iterator</code>, which adds a number of convenient shortcuts for common (and not so common) iterator operations. As another example, <code>tower</code> provides <code>ServiceExt</code>, which adds several more ergonomic operations to wrap the low-level interface in the <code>Service</code> trait from <code>tower-service</code>.</p>
<p>Extension traits tend to be useful either when you do not control the base trait, as with <code>Iterator</code>, or when the base trait lives in a crate of its own so that it rarely sees breaking releases and thus doesn’t cause unnecessary ecosystem splits, as with <code>Service</code>.</p>
<p>An extension trait extends the base trait it is an extension of (<code>trait ServiceExt: Service</code>) and consists solely of provided methods. It also comes with a blanket implementation for any <code>T</code> that implements the base trait (<code>impl&lt;T&gt; ServiceExt for T where T: Service {}</code>). Together, these conditions ensure that the extension trait’s methods are available on anything that implements the base trait.</p>
<h3 id="h2--0008">Crate Preludes</h3>
<p class="BodyFirst">In <span class="xref" itemid="xref_target_Chapter 12">Chapter 12</span>, we talked about the standard library prelude that makes a number of types and traits automatically available without you having to write any <code>use</code> statements. Along similar lines, crates that export multiple types, traits, or functions that you’ll often use together sometimes define their own prelude in the form of a module called <code>prelude</code>, which re-exports some particularly common subset of those types, traits, and functions. There’s nothing magical about that module name, and it doesn’t get used automatically, but it serves as a signal to users that they likely want to add <code>use </code><var>somecrate</var><code>::prelude::*</code> to files that want to use the crate in question. The <code>*</code> is a <em>glob import</em> and tells Rust to use all publicly available items from the indicated module. This can save quite a bit of typing when the crate has a lot of items you’ll usually need to name.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Items used through <code>*</code> have lower precedence than items that are used explicitly by name. This is what allows you to define items in your own crate that overlap with what’s in the standard library prelude without having to specify which one to use.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Preludes are also great for crates that expose a lot of extension traits, since trait methods can be called only if the trait that defines them is in scope. For example, the <code>diesel</code> crate, which provides ergonomic access to relational databases, makes extensive use of extension traits so you can write code like:</p>
<pre><code>posts.filter(published.eq(true)).limit(5).load::&lt;Post&gt;(&amp;connection)</code></pre>
<p class="BodyContinued">This line will work only if all the right traits are in scope, which the prelude takes care of.</p>
<p><span epub:type="pagebreak" title="237" id="Page_237"/>In general, you should be careful when adding glob imports to your code, as they can potentially turn additions to the indicated module into backward-incompatible changes. For example, if someone adds a new trait to a module you glob-import from, and that new trait makes a method <code>foo</code> available on a type that already had some other <code>foo</code> method, code that calls <code>foo</code> on that type will no longer compile as the call to <code>foo</code> is now ambiguous. Interestingly enough, while the existence of glob imports makes any module addition a technically breaking change, the Rust RFC on API evolution (RFC 1105; see <a href="https://rust-lang.github.io/rfcs/1105-api-evolution.html" class="LinkURL">https://rust-lang.github.io/rfcs/1105-api-evolution.html</a>) does <em>not</em> require a library to issue a new major version for such a change. The RFC goes into great detail about why, and I recommend you read it, but the gist is that minor releases are allowed to require minimally invasive changes to dependents, like having to add type annotations in edge cases, because otherwise a large fraction of changes would require new major versions despite being very unlikely to actually break any consumers.</p>
<p>Specifically in the case of preludes, using glob imports is usually fine when recommended by the vending crate, since its maintainers know that their users will use glob imports for the prelude module and thus will take that into account when deciding whether a change requires a major version bump.</p>
<h2 id="h1--0003">Staying Up to Date</h2>
<p class="BodyFirst">Rust, being such a young language, is evolving rapidly. The language itself, the standard library, the tooling, and the broader ecosystem are all still in their infancy, and new developments happen every day. While staying on top of all the changes would be infeasible, it’s worth your time to keep up with significant developments so that you can take advantage of the latest and greatest features in your projects.</p>
<p>For monitoring improvements to Rust itself, including new language features, standard library additions, and core tooling upgrades, the official Rust blog at <a href="https://blog.rust-lang.org/" class="LinkURL">https://blog.rust-lang.org/</a><em> </em>is a good, low-volume place to start. It mainly features announcements for each new Rust release. I recommend you make a habit of reading these, as they tend to include interesting tidbits that will slowly but surely deepen your knowledge of the language. To dig a little deeper, I highly recommend reading the detailed changelogs for Rust and Cargo as well (links can usually be found near the bottom of each release announcement). The changelogs surface changes that weren’t large enough to warrant a paragraph in the release notes but that may be just what you need two weeks from now. For a less frequently updated news source, check in on <em>The Edition Guide</em> at <a href="https://doc.rust-lang.org/edition-guide/" class="LinkURL">https://doc.rust-lang.org/edition-guide/</a>, which outlines what’s new in each Rust edition. Rust editions tend to be released every three years.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Clippy is often able to tell you when you can take advantage of a new language or standard library feature—always enable Clippy!</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p><span epub:type="pagebreak" title="238" id="Page_238"/>If you’re curious about how Rust itself is developed, you may also want to subscribe to the <em>Inside Rust</em> blog at<em> </em><a href="https://blog.rust-lang.org/inside-rust/" class="LinkURL">https://blog.rust-lang.org/inside-rust/</a>. It includes updates from the various Rust teams, as well as incident reports, larger change proposals, edition planning information, and the like. To get involved in Rust development yourself—which I highly encourage, as it’s a lot of fun and a great learning experience—you can check out the various Rust working groups at <a href="https://www.rust-lang.org/governance/" class="LinkURL">https://www.rust-lang.org/governance/</a>, which each focus on improving a specific aspect of Rust. Find one that appeals to you, check in with the group wherever it meets and ask how you may be able to help. You can also join the community discussion about Rust internals over at <a href="https://internals.rust-lang.org/" class="LinkURL">https://internals.rust-lang.org/</a>; this is another great way to get insight into the thought that goes into every part of Rust’s design and development.</p>
<p>As is the case for most programming languages, much of Rust’s value is derived from its community. Not only do the members of the Rust community constantly develop new work-saving crates and discover new Rust-specific techniques and design patterns, but they also collectively and continuously help one another understand, document, and explain how to take best advantage of the Rust language. Everything I have covered in this book, and much more, has already been discussed by the community in thousands of comment threads, blog posts, and Twitter and Discord conversations. Dipping into these discussions even just once in a while is almost guaranteed to show you new things about a language feature, a technique, or a crate that you didn’t already know.</p>
<p>The Rust community lives in a lot of places, but some good places to start are the Users forum (<a href="https://users.rust-lang.org/" class="LinkURL">https://users.rust-lang.org/</a>), the Rust subreddit (<a href="https://www.reddit.com/r/rust/" class="LinkURL">https://www.reddit.com/r/rust/</a>), the Rust Community Discord (<a href="https://discord.gg/rust-lang-community" class="LinkURL">https://discord.gg/rust-lang-community</a>), and the Rust Twitter account (<a href="https://twitter.com/rustlang" class="LinkURL">https://twitter.com/rustlang</a>). You don’t have to engage with all of these, or all of the time—pick one you like the vibe of, and check in occasionally!</p>
<p>A great single location for staying up to date with ongoing developments is the <em>This Week in Rust</em> blog (<a href="https://this-week-in-rust.org/" class="LinkURL">https://this-week-in-rust.org/</a>), a “weekly summary of [Rust’s] progress and community.” It links to official announcements and changelogs as well as popular community discussions and resources, interesting new crates, opportunities for contributions, upcoming Rust events, and Rust job opportunities. It even lists interesting language RFCs and compiler PRs, so this site truly has it all! Discerning what information is valuable to you and what isn’t may be a little daunting, but even just scrolling through and clicking occasional links that appear interesting is a good way to keep a steady stream of new Rust knowledge trickling into your brain.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Want to look up when a particular feature landed on stable? Can I Use… (<a href="https://caniuse.rs/" class="LinkURL">https://caniuse.rs/</a>) has you covered.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h2 id="h1--0004">What Next?</h2>
<p class="BodyFirst">So, you’ve read this book front to back, absorbed all the knowledge it imparts, and are still hungry for more? Great! There are a number of other <span epub:type="pagebreak" title="239" id="Page_239"/>excellent resources out there for broadening and deepening your knowledge and understanding of Rust, and in this very final section I’ll give you a survey of some of my favorites so that you can keep learning. I’ve divided them into subsections based on how different people prefer to learn so that you can find resources that’ll work for you.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	A challenge with learning on your own, especially in the beginning, is that progress is hard to perceive. Implementing even the simplest of things can take an outsized amount of time when you have to constantly refer to documentation and other resources, ask for help, or debug to learn how some aspect of Rust works. All of that non-coding work can make it seem like you’re treading water and not really improving. But you’re <em>learning</em>, which is progress in and of itself—it’s just harder to notice and appreciate.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2--0009">Learn by Watching</h3>
<p class="BodyFirst">Watching experienced developers code is essentially a life hack to remedy the slow starting phase of solo learning. It allows you to observe the process of designing and building while utilizing someone else’s experience. Listening to experienced developers articulate their thinking and explain tricky concepts or techniques as they come up can be an excellent alternative to struggling through problems on your own. You’ll also pick up a variety of auxiliary knowledge like debugging techniques, design patterns, and best practices. Eventually you will have to sit down and do things yourself—it’s the only way to check that you actually understand what you’ve observed—but piggybacking on the experience of others will almost certainly make the early stages more pleasant. And if the experience is interactive, that’s even better!</p>
<p>So, with that said, here are some Rust video channels that I recommend:</p>
<ol class="none">
<li>Perhaps unsurprisingly, my own channel:<em> </em><a href="https://www.youtube.com/c/JonGjengset/" class="LinkURL">https://www.youtube.com/c/JonGjengset/</a>. I have a mix of long-form coding videos and short(er) code-based theory/concept explanation videos, as well as occasional videos that dive into interesting Rust coding stories.</li>
<li>The <em>Awesome Rust Streaming</em> listing: <a href="https://github.com/jamesmunns/awesome-rust-streaming/" class="LinkURL">https://github.com/jamesmunns/awesome-rust-streaming/</a>. This resource lists a wide variety of developers who stream Rust coding or other Rust content.</li>
<li>The channel of Tim McNamara, the author of <em>Rust in Action</em>: <a href="https://www.youtube.com/c/timClicks/" class="LinkURL">https://www.youtube.com/c/timClicks/</a>. Tim’s channel, like mine, splits its time between implementation and theory, though Tim has a particular knack for creative visual projects, which makes for fun viewing.</li>
<li>Jonathan Turner’s <em>Systems with JT</em> channel: <a href="https://www.youtube.com/c/SystemswithJT/" class="LinkURL">https://www.youtube.com/c/SystemswithJT/</a>. Jonathan’s videos document their work on Nushell, their take on a “new type of shell,” providing a great sense of what it’s like to work on a nontrivial existing codebase.</li>
<li>Ryan Levick’s channel: <a href="https://www.youtube.com/c/RyanLevicksVideos/" class="LinkURL">https://www.youtube.com/c/RyanLevicksVideos/</a>. Ryan mainly posts videos that tackle particular Rust concepts and walks <span epub:type="pagebreak" title="240" id="Page_240"/>through them using concrete code examples, but he also occasionally does implementation videos (like FFI for Microsoft Flight Simulator!) and deep dives into how well-known crates work under the hood.</li>
</ol>
<p>Given that I make Rust videos, it should come as no surprise that I am a fan of this approach to teaching. But this kind of receptive or interactive learning doesn’t have to come in the form of videos. Another great avenue for learning from experienced developers is pair programming. If you have a colleague or friend with expertise in a particular aspect of Rust you’d like to learn, ask if you can do a pair-programming session with them to solve a problem together!</p>
<h3 id="h2--0010">Learn by Doing</h3>
<p class="BodyFirst">Since your ultimate goal is to get better at writing Rust, there’s no substitute for programming experience. No matter what or how many resources you learn from, you need to put that learning into practice. However, finding a good place to start can be tricky, so here I’ll give some suggestions.</p>
<p>Before I dive into the list, I want to provide some general guidance on how to pick projects. First, choose a project that <em>you </em>care about, without worrying too much whether others care about it. While there are plenty of popular and established Rust projects out there that would love to have you as a contributor, and it’s fun to be able to say “I contributed to the well-known library X,” your first priority must be your own interest. Without concrete motivation, you’ll quickly lose steam and find contributing to be a chore. The very best targets are projects that you use yourself and have experienced problems with—go fix them! Nothing is more satisfying than getting rid of a long-standing personal nuisance while also contributing back to the community.</p>
<p>Okay, so back to project suggestions. First and foremost, consider contributing to the Rust compiler and its associated tools. It’s a high-quality codebase with good documentation and an endless supply of issues (you probably know of some yourself), and there are several great mentors who can provide outlines for how to approach solving issues. If you look through the issue tracker for issues marked E-easy or E-mentor, you’ll likely find a good candidate quickly. As you gain more experience, you can keep leveling up to contribute to trickier parts.</p>
<p>If that’s not your cup of tea, I recommend finding something you use frequently that’s written in another language and porting it to Rust—not necessarily with the intention of replacing the original library or tool, but just because the experience will allow you to focus on writing Rust without having to spend too much time coming up with all the functionality yourself. If it turns out well, the fact that it already exists suggests that someone else also needed it, so there may be a wider audience for your port too! Data structures and command-line tools often make for great porting subjects, but find a niche that appeals to you.</p>
<p>Should you be more of a “build it from scratch” kind of person, I recommend looking back at your own development experience so far and thinking about similar code you’ve ended up writing in multiple projects (whether <span epub:type="pagebreak" title="241" id="Page_241"/>in Rust or in other languages). Such repetition tends to be a good signal that something is reusable and could be turned into a library. If nothing comes to mind, David Tolnay maintains a list of smaller utility crates that other Rust developers have requested at <a href="https://github.com/dtolnay/request-for-implementation/" class="LinkURL">https://github.com/dtolnay/request-for-implementation/</a> that may provide a source of inspiration. If you’re looking for something more substantial and ambitious, there’s also the Not Yet Awesome list at <a href="https://github.com/not-yet-awesome-rust/not-yet-awesome-rust/" class="LinkURL">https://github.com/not-yet-awesome-rust/not-yet-awesome-rust/</a> that lists things that should exist in Rust but don’t (yet).</p>
<h3 id="h2--0011">Learn by Reading</h3>
<p class="BodyFirst">Although the state of affairs is constantly improving, finding good Rust reading material beyond the beginner level can still be tricky. Here’s a collection of pointers to some of my favorite resources that continue to teach me new things or serve as good references when I have particularly niche or nuanced questions.</p>
<p>First, I recommend looking through the official virtual Rust books linked from <a href="https://www.rust-lang.org/learn/" class="LinkURL">https://www.rust-lang.org/learn/</a>. Some, like the Cargo book, are more reference-like while others, like the Embedded book, are more guide-like, but they’re all deep sources of solid technical information about their respective topics. <em>The Rustonomicon</em> (<a href="https://doc.rust-lang.org/nomicon/" class="LinkURL">https://doc.rust-lang.org/nomicon/</a>), in particular, is a lifesaver when you’re writing unsafe code.</p>
<p>Two more books that are worth checking out are the <em>Guide to rustc Development</em> (<a href="https://rustc-dev-guide.rust-lang.org/" class="LinkURL">https://rustc-dev-guide.rust-lang.org/</a>) and the <em>Standard Library Developers Guide</em> (<a href="https://std-dev-guide.rust-lang.org/" class="LinkURL">https://std-dev-guide.rust-lang.org/</a>). These are fantastic resources if you’re curious about how the Rust compiler does what it does or how the standard library is designed, or if you want some pointers before you try your hand at contributing to Rust itself. The official Rust guidelines are also a treasure trove of information; I’ve already mentioned the <em>Rust API Guidelines</em> (<a href="https://rust-lang.github.io/api-guidelines/" class="LinkURL">https://rust-lang.github.io/api-guidelines/</a>) in the book, but a <em>Rust Unsafe Code Guidelines Reference</em> is also available (<a href="https://rust-lang.github.io/unsafe-code-guidelines/" class="LinkURL">https://rust-lang.github.io/unsafe-code-guidelines/</a>), and by the time you read this book there may be more.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	One of the resources listed at <a href="https://www.rust-lang.org/learn/" class="LinkURL">https://www.rust-lang.org/learn/</a> is the Rust Reference, which is essentially a full specification for the Rust language. While parts of it are quite dry, like the exact grammar used for parsing or basics about the in-memory representations of the primitive types, some of it is fascinating reading, like the section on type layout and the enumeration of behavior considered undefined.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>There are also a number of unofficial virtual Rust books that are enormously valuable collections of experience and knowledge. <em>The Little Book of Rust Macros</em> (<a href="https://veykril.github.io/tlborm/" class="LinkURL">https://veykril.github.io/tlborm/</a>), for example, is indispensable if you want to write nontrivial declarative macros, and <em>The Rust Performance Book</em> (<a href="https://nnethercote.github.io/perf-book/" class="LinkURL">https://nnethercote.github.io/perf-book/</a>) is filled with tips and tricks for improving the performance of Rust code both at the micro and the macro level. Other great resources include the <em>Rust Fuzz Book</em> (<a href="https://rust-fuzz.github.io/book/" class="LinkURL">https://rust-fuzz.github.io/book/</a>), which explores fuzz testing in more detail, and <span epub:type="pagebreak" title="242" id="Page_242"/>the <em>Rust Cookbook</em> (<a href="https://rust-lang-nursery.github.io/rust-cookbook/" class="LinkURL">https://rust-lang-nursery.github.io/rust-cookbook/</a>), which suggests idiomatic solutions to common programming tasks. There’s even a resource for finding more books, <em>The Little Book of Rust Books</em> (<a href="https://lborb.github.io/book/unofficial.html" class="LinkURL">https://lborb.github.io/book/unofficial.html</a>)!</p>
<p>If you prefer more hands-on reading, the Tokio project has published <em>mini-redis</em> (<a href="https://github.com/tokio-rs/mini-redis/" class="LinkURL">https://github.com/tokio-rs/mini-redis/</a>), an incomplete but idiomatic implementation of a Redis client and server that’s extremely well documented and specifically written to serve as a guide to writing asynchronous code. If you’re more of a data structures person, <em>Learn Rust with Entirely Too Many Linked Lists</em> (<a href="https://rust-unofficial.github.io/too-many-lists/" class="LinkURL">https://rust-unofficial.github.io/too-many-lists/</a>) is an enlightening and fun read that gets into lots of gnarly details about ownership and references. If you’re looking for something closer to the hardware, Philipp Oppermann’s <em>Writing an OS in Rust</em> (<a href="https://os.phil-opp.com/" class="LinkURL">https://os.phil-opp.com/</a>) goes through the whole operating system stack in great detail while teaching you good Rust patterns in the process. I also highly recommend Amos’s collection of articles (<a href="https://fasterthanli.me/tags/rust/" class="LinkURL">https://fasterthanli.me/tags/rust/</a>) if you want a wide sampling of interesting deep dives written in a conversational style.</p>
<p>When you feel more confident in your Rust abilities and need more of a quick reference than a long tutorial, I’ve found the <em>Rust Language Cheat Sheet</em> (<a href="https://cheats.rs/" class="LinkURL">https://cheats.rs/</a>) great for looking things up quickly. It also provides very nice visual explanations for most topics, so even if you’re looking up something you’re not intimately familiar with already, the explanations are pretty approachable.</p>
<p>And finally, if you want to put all of your Rust understanding to the test, go give David Tolnay’s <em>Rust Quiz</em> (<a href="https://dtolnay.github.io/rust-quiz/" class="LinkURL">https://dtolnay.github.io/rust-quiz/</a>) a try. There are some real mind-benders in there, but each question comes with a thorough explanation of what’s going on, so even if you get one wrong, you’ll have learned from the experience!</p>
<h3 id="h2--0012">Learn by Teaching</h3>
<p class="BodyFirst">My experience has been that the best way to learn something well and thoroughly, by far, is to try to teach it to others. I have learned an enormous amount from writing this book, and I learn new things every time I make a new Rust video or podcast episode. So, I wholeheartedly recommend that you try your hand at teaching others about some of the things you’ve learned from reading this book or that you learn from here on out. It can take whatever form you prefer: in person, writing a blog post, tweeting, making a video or podcast, or giving a talk. The important thing is that you try to convey your newfound knowledge in your own words to someone who doesn’t already understand the topic—in doing so, you also give back to the community so that the next you that comes along has a slightly easier time getting up to speed. Teaching is a humbling and deeply educational experience, and I cannot recommend it highly enough.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Whether you’re looking to teach or be taught, make sure to visit Awesome Rust Mentors (<a href="https://rustbeginners.github.io/awesome-rust-mentors/" class="LinkURL">https://rustbeginners.github.io/awesome-rust-mentors/</a>).</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h2 id="h1--0005"><span epub:type="pagebreak" title="243" id="Page_243"/>Summary</h2>
<p class="BodyFirst">In this chapter, we’ve covered Rust beyond what exists in your local workspace. We surveyed useful tools, libraries, and Rust features; looked at how to stay up to date as the ecosystem continues to evolve; and then discussed how you can get your hands dirty and contribute back to the ecosystem yourself. Finally, we discussed where you can go next to continue your Rust journey now that this book has reached its end. And with that, there’s little more to do than to declare:</p>
<pre><code>}</code></pre>
</section>
</div></body></html>