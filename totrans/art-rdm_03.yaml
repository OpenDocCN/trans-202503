- en: '**3'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SIMULATE THE REAL WORLD**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Computer simulations* are programs that use randomness to simulate real-world
    events and processes. More specifically, computer simulations manipulate *models*,
    programmatic stand-ins for the real world.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll begin this chapter by defining what a model is. Then we’ll get our feet
    wet with two straightforward simulation examples: estimating *π* by throwing darts
    and gathering people together in a room to estimate the probability that at least
    two of them share a birthday. Once we’ve done that, we’ll wade in further to explore
    Darwinian evolution via simulation, capturing essential characteristics of natural
    selection and genetic drift.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Introduction to Models**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can define a model in many ways, but I like this definition from Daniel
    L. Hartl in *A Primer of Population Genetics and Genomics* (Oxford University
    Press, 2020):'
  prefs: []
  type: TYPE_NORMAL
- en: A model is an intentional simplification of a complex situation designed to
    eliminate extraneous detail in order to focus on the essentials.
  prefs: []
  type: TYPE_NORMAL
- en: Think of a model as an approximation of something that we’re interested in exploring
    or characterizing. There are no requirements for what that something is or for
    how we model it.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, a model is a piece of code that attempts to capture the essential
    character of a real-world process, like what happens to the probability of shared
    birthdays as more and more people gather in a room, or how natural selection and
    genetic drift affect the genomes of a population. Simulation lets us control the
    experimental world while allowing random behavior, to understand what has happened
    or might happen, especially as critical parameters (environmental factors) are
    varied.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following statement, which is attributed to British statistician
    George Box:'
  prefs: []
  type: TYPE_NORMAL
- en: All models are wrong, but some are useful.
  prefs: []
  type: TYPE_NORMAL
- en: Unless particularly trivial, all models are wrong in some way, especially those
    of the real world. If the model is well conceived and well implemented, it might
    lead to valuable conclusions about the modeled process. The word *process* implies
    a sequence of events, that is, time. Many models simulate processes unfolding
    in time; for example, we’ll explore fundamental evolutionary processes acting
    at a population level over time.
  prefs: []
  type: TYPE_NORMAL
- en: A good model captures enough of the thing being modeled to generate conclusions
    worthy of confidence tempered with reality. Blind faith in a model’s output isn’t
    recommended. At best, a model falls into the “trust, but verify” category—a good
    rule of thumb for all scientific claims.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s slide into simulation by throwing darts to estimate *π*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Estimate Pi**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ll generate an estimate of *π*, the ratio between the circumference of a
    circle and its diameter, by throwing darts at a board. Doing this in real life
    would be time consuming, so we’ll simulate the process instead; that is, we’ll
    make a model.
  prefs: []
  type: TYPE_NORMAL
- en: '***Using a Dartboard***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: First, let’s learn how throwing darts at a board tells us about the value of
    *π*. For that, we need a diagram ([Figure 3-1](ch03.xhtml#ch03fig01)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-1: Simulating dart throws*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3-1](ch03.xhtml#ch03fig01) shows a square with a circle inside it.
    The circle’s diameter isn’t marked explicitly, but we’ll say it’s 2, meaning the
    radius is 1\. The diameter also matches the length of the sides of the square;
    therefore, the areas of the square and circle are'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0075-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'implying:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0075-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We calculate *π* by dividing the area of the circle by the area of the square
    and multiplying that by 4.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we throw many darts, or pick many random points, they’ll eventually cover
    the circle and the square. We can use the number of darts that land inside each
    shape as a proxy for the areas. We now have an algorithm: throw darts and count
    the number that land inside the circle (*N*) and inside the square (*M*), then
    divide *N* by *M* and multiply by 4 to get an estimate of *π*.'
  prefs: []
  type: TYPE_NORMAL
- en: The previous figure’s example points are all in the first quadrant, which works
    well for our estimate because the ratio of the area of the square to the circle
    is the same as the ratio of the portion of each shape in the first quadrant. Specifically,
    the first quadrant is 1/4 the size of the full shapes, so the areas are divided
    by 4\. But both the circle and square areas are divided by 4, meaning their ratio
    remains the same, *π*/4\. This means we need only to throw darts that land in
    the first quadrant.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand how to estimate the respective areas and *π* by throwing
    darts, how should we actually “throw” them? The answer lies in the previous comment
    about the first quadrant.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Randomly pick two numbers in [0, 1) and call them *x* and *y*. These become
    the point where the dart lands, (*x*, *y*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increment *M*, the counter for the number of points in the square.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If *x*² + *y*² ≤ 1, increment *N*, the number of points inside the circle.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat steps 1 through 3 for as many darts as desired.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Return (4*N*)/*M* as the estimate of *π*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We pick points in [0, 1) so that the points are all in the first quadrant and
    land inside the square. Therefore, if we throw *n* darts, *M* = *n*, and we need
    only ask if the same points are also inside the circle.
  prefs: []
  type: TYPE_NORMAL
- en: 'In step 2 we ask a question about the circle, with *x*² + *y*² ≤ 1 coming from
    the Pythagorean theorem: *a*² + *b*² = *c*², where *c* is the side opposite the
    right angle. Here the triangle sides are *x* and *y*, meaning the radius (*r*
    = 1) is the hypotenuse, *x*² + *y*². Any point forming a hypotenuse less than
    *r* = 1 is inside the circle.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we proceed, we should ask whether this is a fair model of the process
    of throwing darts, and whether we’ve made any unfair assumptions. After all, a
    model attempts to mimic *what’s most important* about a process. We’re using two
    uniformly selected random numbers in [0, 1) to represent the location where a
    dart might land, and we’ve made only one assumption: that *all* darts land in
    the first quadrant. Limiting the random values to [0, 1) eliminates out-of-range
    darts, so we count every dart throw as landing in at least the square.'
  prefs: []
  type: TYPE_NORMAL
- en: With these questions answered, we’re ready to test.
  prefs: []
  type: TYPE_NORMAL
- en: '***Simulating Random Darts***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The code we want is in *sim_pi.py*. To run it, supply the number of simulated
    darts and the desired randomness source. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This throws 10,000 darts using PCG64\. The result is *π ≈* 3.1612\. The correct
    value rounded to four digits is 3.1416, so we’re in the ballpark. The estimate
    uses only four decimal places because we’re approximating *π* with a fraction
    that has a denominator of 10,000\. Ten more runs gives:'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1496, 3.1188, 3.1468, 3.1700, 3.1292, 3.1372, 3.0916, 3.1608, 3.1236, 3.1140
  prefs: []
  type: TYPE_NORMAL
- en: Combining all 11 runs gives *π ≈* 3.1366, which is about 0.16 percent off from
    the four-digit value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s increase the number of darts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: That’s more like it. The correct value to six places is 3.141593.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go for broke—this should nail it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Odd. We threw 100 times as many darts as the previous run, but the result wasn’t
    as good. Nothing’s wrong with our approach; that’s how the random cookie crumbles.
    A second run using PCG64 and 100 million darts returned 3.14160636, which is better.
    Still, it raises the question: Why such variation? That’s the nature of a random
    generator, and it serves as a reminder to repeat simulations multiple times to
    convince ourselves that they’re producing reasonable output and to get numerous
    estimates.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Individual runs using the other randomness sources supported by the `RE` class
    gave:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The last run uses *RandomDotOrg.bin*, a 510MB file of random data from *[random.org](http://random.org)*.
    All randomness sources produce reasonable estimates of *π* but are still not satisfying.
    Why aren’t they closer to the actual value of 3.14159265 . . . ?
  prefs: []
  type: TYPE_NORMAL
- en: '***Understanding the RE Class Output***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s reconsider what we want the random throwing of darts to simulate. We’re
    looking to compare *areas*, so we want the darts to cover the areas as evenly
    as possible.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3-2](ch03.xhtml#ch03fig02), which is a duplicate of [Figure 1-5](ch01.xhtml#ch01fig05),
    shows us what is happening. The middle plot in the figure shows the placement
    of points when using a random generator. There are gaps and places where the points
    are concentrated. It’s a reasonable coverage of the area, but not a uniformly
    dense one.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-2: Bad quasirandom (left), pseudorandom (middle), and good quasirandom
    sequences (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The right plot in [Figure 3-2](ch03.xhtml#ch03fig02), from a pair of quasirandom
    sequences, is much more uniform over the area. Let’s try using that instead. The
    code we want for this case is in *sim_pi_quasi.py*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The first argument is the number of darts; the other two are the bases for the
    quasirandom sequence. To cover a 2D plane, we need two different bases, here 2
    and 3\. As the number of darts increases, so does the quality of the estimate.
    With 1 million darts, it has already matched the first run of *sim_pi.py* with
    PCG64\. There’s no randomness here; every run with the same number of darts and
    the same bases results in the same output. Also, because we’re generating the
    quasirandom sequence in pure Python, the runtime increases dramatically with the
    number of darts. For example, this run
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: is correct to five decimals but took 12 minutes to run on my reference Intel
    i7 system. Asking for 100 million samples produces *π ≈* 3.14159184 after a two-and-a-half-hour
    run.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s focus momentarily on the performance of each pseudorandom generator supported
    by the `RE` class. The file *sim_pi_test.py* estimates *π* 50 times each for PCG64,
    MT19937, MINSTD, `urandom`, and `RDRAND` using 2 million simulated dart throws.
    The result is the box plot in [Figure 3-3](ch03.xhtml#ch03fig03).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-3: A box plot showing the distribution of π estimates by randomness
    source*'
  prefs: []
  type: TYPE_NORMAL
- en: A *box plot* is a diagram summarizing a set of data; in this case, the 50 estimates
    of *π*, that is, the 50 separate runs of *sim_pi.py* for each pseudorandom generator.
    Each generator’s output produces a box with a horizontal bar across it. The bar
    represents the median value, or the 50th percentile. Half the estimates were below
    this value and half above. The box’s lower and upper limits are the 25th and 75th
    percentiles, respectively. So, 75 percent of the estimates were below the upper
    part of the box and the remaining 25 percent were above it.
  prefs: []
  type: TYPE_NORMAL
- en: The *whiskers*, called fliers by Matplotlib, extend beyond the box. The height
    of the box, the difference between the 75th percentile and the 25th, is known
    as the *interquartile range (IQR)*. The whiskers are the box quartiles plus or
    minus 1.5 times the IQR. Any data values outside the whiskers are candidates for
    *outliers*, values that are atypical when compared to the rest of the data. Outliers
    might be errors or the exciting thing we’re looking for; context is everything.
  prefs: []
  type: TYPE_NORMAL
- en: The five boxes in [Figure 3-3](ch03.xhtml#ch03fig03) are statistically identical.
    There are two potential outliers for MINSTD, but another run of *sim_pi_test.py*
    generates a new plot with a different set of boxes and potential outliers, even
    from `RDRAND`, which is as close to a true source of randomness as we can get
    for repeated sampling. Random processes sometimes produce strange output; there’s
    no meaning attached to it. This phenomenon is partly why detecting true cancer
    clusters can be tricky.
  prefs: []
  type: TYPE_NORMAL
- en: '***Implementing the Darts Model***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Our dart-throwing simulation works. Now, let’s review the code to understand
    how:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The code at the bottom parses the command line to get the number of darts to
    throw (`N`) and the type of randomness source to use (`kind`). A generator is
    created (`rng`) and passed, along with the number of darts, to `Simulate`, which
    returns an estimate of *π* that is then printed.
  prefs: []
  type: TYPE_NORMAL
- en: All the action is in `Simulate`. We need `N` points, the locations where our
    darts landed. We can either use `rng` twice—first to get *x*-coordinates and then
    again to get *y*-coordinates—or generate twice as many points as we need and partition
    them in pairs. I chose the latter. Therefore, `v` contains 2*N* values. The first
    and then every other point become `x`, while the second and every other after
    that become `y`.
  prefs: []
  type: TYPE_NORMAL
- en: By design, all the points are inside the square. We need only to decide which
    are also inside the circle. For that, we need to know if *x*² + *y*² *≤ r*² for
    radius *r* = 1\. To this end, we set `d` to *x*² + *y*² and use NumPy’s `where`
    to find the indices that are less than or equal to 1\. The count of those indices
    tells us how many points are `inside` the circle. Finally, the function returns
    the estimate of *π* as four times the number inside divided by the number of darts
    thrown.
  prefs: []
  type: TYPE_NORMAL
- en: Our dart simulation is complete. Now, let’s simulate a party to see how many
    people we need in a room to have a better-than-50 percent chance that at least
    two of them share a birthday.
  prefs: []
  type: TYPE_NORMAL
- en: '**Birthday Paradox**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'How many people need to be in a room for the probability of at least two of
    them sharing a birthday to be above 50 percent? There’s a mathematical way to
    determine this probability, but if we don’t know the math, we can find it by extensive
    experimentation: we can throw many parties, with differing numbers of people invited,
    and at each one figure out if at least two of them share a birthday. While this
    approach will work, it’ll be terribly slow and expensive.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Simulating 100,000 Parties***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Assuming we aren’t willing to write a grant proposal for a million dollars
    to conduct this experiment with actual people, to say nothing of gaining review
    board approval and informed consent from thousands of people, is there any other
    way to approach the problem? You guessed it: simulation.'
  prefs: []
  type: TYPE_NORMAL
- en: Every person has a birthday, so we’ll simulate the number of people in the room
    and assign each a randomly selected birthday. Then we’ll look at each possible
    pair and ask if they have the same birthday. There are 365 days in a year, ignoring
    leap years, so we’ll represent birthdays by picking a day of the year as a proxy
    for an actual birthday. In other words, each simulated person is assigned an integer
    in [0, 364]. If any two have the same number, they share a birthday.
  prefs: []
  type: TYPE_NORMAL
- en: We want the probability of a match for a given number of people, meaning one
    simulation isn’t sufficient. We need many, many simulations for a fixed number
    of people in the room. The number of times there’s a match divided by the number
    of simulations converges to the probability we seek.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s our algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Fix the number of people in the room (*K*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign each of the *K* people a birthday ([0, 364]).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check each possible pair. If they share a birthday, increment *M*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat from step 2 *N* times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The estimated probability for *K* people in a room is *M*/*N*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We’ll vary *K* from 2 to 50\. *N* should be a large number, like *N* = 100,000
    to simulate 100,000 parties with *K* people. We can always make *N* larger and
    try again, as varying simulation parameters and observing what happens is part
    of what makes simulations worthwhile. If things blow up when we make a subtle
    change, we might have a bug in our code or, worse yet, a logic flaw in our design.
  prefs: []
  type: TYPE_NORMAL
- en: '***Testing the Birthday Model***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The code we need is in *birthday.py*. Let’s run it to understand its output
    before walking through it. For example, here’s the output for a run asking for
    the probability of at least one match in a room with 11 people:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We’re told that the probability of at least one birthday match for a room of
    11 people is about 14 percent. The second argument is the randomness source to
    use, here MINSTD. Feel free to experiment with other sources.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we add a third argument, we can store the output and bring it into Python
    to understand what it means:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The first line runs the code a second time. Notice that the probability changes
    slightly; random selection of birthdays will produce varying results that eventually
    converge to a mean after many repetitions of the simulation. We’ll experiment
    with this fact in a bit.
  prefs: []
  type: TYPE_NORMAL
- en: Next, I ran Python (and ignored the startup message) before importing NumPy
    and the output file, *11.npy*. The `d` array contains a histogram of the number
    of times that many birthday matches were found for 100,000 simulations where the
    index into `d` is the number. [Table 3-1](ch03.xhtml#ch03tab01) shows the number
    of matches and how often they appeared.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 3-1:** Number of Matches and Frequency of Appearance'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Matches** | **Count** | **Percent** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 85,739 | 85.739 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 13,462 | 13.462 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 663 | 0.663 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 125 | 0.125 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 10 | 0.010 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 0 | 0.000 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 0 | 0.000 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 1 | 0.001 |'
  prefs: []
  type: TYPE_TB
- en: 'In 85.7 percent of the cases, when 11 people were in the room no two shared
    a birthday. Likewise, 13.5 percent of the cases resulted in a single pair sharing
    a birthday. Finally, in one run out of 100,000, seven pairs of people shared a
    birthday. This is the nature of randomness: sometimes remarkable things happen.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, I ran *birthday.py* five times, once for each of the randomness sources
    built into `RE`, and always with 23 people in the room. The average probability
    returned was 0.507478 or 50.7 percent. This is the first number of people to return
    a probability greater than 50 percent; therefore, to answer the question at the
    beginning of this section, we need 23 people in a room, on average, to have a
    greater than 50 percent chance that at least two of them share a birthday.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try to visualize what’s happening here ([Figure 3-4](ch03.xhtml#ch03fig04)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-4: The probability of at least one match as a function of number
    of people (left) and the histogram of matches by people in the room (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: The left-hand side of [Figure 3-4](ch03.xhtml#ch03fig04) shows the probability
    of one or more matches as a function of the number of people in the room. The
    vertical line is 23 people, and the dashed horizontal line is 50 percent. As claimed,
    23 people is the minimum number needed to exceed 50 percent.
  prefs: []
  type: TYPE_NORMAL
- en: The right side of [Figure 3-4](ch03.xhtml#ch03fig04) presents three histograms
    showing the fraction of runs returning the indicated number of matches. The bars
    are offset to prevent overlapping, but the leftmost bar is on the actual number
    of matches. When there are only 10 people in the room, the probability of no match
    is high and more than one match is essentially zero. For 23 people, one match
    is relatively common, two less so, and three pairs happen about 3 percent of the
    time. With 40 people, we’re past the 23-person transition, so it’s more likely
    than not to have multiple matches.
  prefs: []
  type: TYPE_NORMAL
- en: '***Implementing the Birthday Model***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s take a walk through *birthday.py*, shown in [Listing 3-1](ch03.xhtml#ch03list01).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 3-1: Simulate checking birthdays for multiple people in a room*'
  prefs: []
  type: TYPE_NORMAL
- en: As with *sim_pi.py*, all the action is in `Simulate`. The code at the bottom
    of [Listing 3-1](ch03.xhtml#ch03list01) parses the command line to get the number
    of people in the room along with the randomness source, one of those supported
    by `RE` or a filename, and, if specified, the name of an output file (a NumPy
    array). Note that `rng` is configured to return integers in [0, 365).
  prefs: []
  type: TYPE_NORMAL
- en: The randomness source (`rng`) and the number of people in the room are passed
    to `Simulate`. The return value is a histogram of the number of times that many
    matches occurred in the fixed 100,000 simulations (`matches`). The first element
    of `matches` is the number of times there were no matches, so the sum of all remaining
    elements divided by the sum of all elements is the probability of one or more
    matches (`prob`). The code then displays the probability and writes the histogram
    to disk if requested.
  prefs: []
  type: TYPE_NORMAL
- en: In `Simulate`, `M` is the number of people in the room, fixed for all 100,000
    simulations. `Matches` will hold the outcome of each simulation, or the number
    of matches found.
  prefs: []
  type: TYPE_NORMAL
- en: The first `for` loop covers the simulations. For each simulation, a random set
    of birthdays is selected (`bdays`), one for each of the `M` persons in the room.
    Then, the double loop over `i` and `j` compares the `i`th person’s birthday with
    all others, counting each `match`. The loop limits for `i` and `j` avoid double-counting;
    if the `i`th person’s birthday matches the `j`th person’s, then the `j`th person’s
    will match the `i`th person’s, which has already been counted. When all pairs
    of people have been compared, the count in `match` is appended to `matches`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, after all 100,000 simulations, the list `matches` is turned into a
    NumPy array and passed to `np.bincount` to count the occurrences of each number
    of matches.
  prefs: []
  type: TYPE_NORMAL
- en: Is *birthday.py* a fair simulation? Does it do what we expect? As Hartl says,
    does it “eliminate extraneous detail in order to focus on the essentials”? The
    essential task here is to pick birthdays fairly once the number of people in the
    room is fixed. We assumed that birthdays are uniformly distributed throughout
    the year—a reasonable assumption.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simulations we’ve discussed so far are warm-ups. Let’s kick things up a
    notch and explore what is, surely, the most important process in the world, at
    least to the myriad of lifeforms on this planet: evolution.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Simulating Evolution**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The evolution of organisms is a complex process affected by genetic and environmental
    factors. In this section, we’ll explore two factors: natural selection and genetic
    drift.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Natural selection*, described by Darwin in the 19th century, is often characterized
    as “survival of the fittest.” It posits that in an environment, organisms whose
    *genotype* (genetic code) leads to an increased likelihood of survival and reproduction
    are those more likely to pass their genes on to succeeding generations. In this
    way, over time, the characteristics of the organism are modified, often eventually
    leading to organisms that can no longer breed with each other—that is, new species.'
  prefs: []
  type: TYPE_NORMAL
- en: While natural selection relates to improved likelihood of survival and reproduction,
    *genetic drift* is an effect caused by environmental changes that isolate a small
    population of organisms from the larger population. In genetic drift, the subpopulation
    of organisms present during the time of isolation will have a different mix of
    genes that can cause rapid changes in the overall gene pool, often leading to
    new species.
  prefs: []
  type: TYPE_NORMAL
- en: We want to simulate the essential components of natural selection and genetic
    drift. Let’s begin with the former; once we simulate natural selection, simulating
    genetic drift becomes that much clearer.
  prefs: []
  type: TYPE_NORMAL
- en: '***Natural Selection***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Here are the requirements for simulating natural selection:'
  prefs: []
  type: TYPE_NORMAL
- en: We need a population of organisms, each consisting of a collection of genes.
    An organism’s genes determine its fitness to the environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We need an environment and some way to characterize it in terms of how well
    organisms are adapted to it. Additionally, we need a measure of fitness for this
    environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We need to simulate natural selection’s two most important tools: breeding
    between organisms (*crossover*) and random *mutation*. This simulation must be
    affected by an organism’s level of fitness to the environment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We need to step from generation to generation so we can monitor the population
    over time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we need to easily visualize the characteristics of the population as
    it evolves across generations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s work through each statement.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Organisms**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Our organisms have six genes in their genomes, each with 16 possible variants
    or *alleles*. Therefore, an organism is a vector of six elements, each [0, 15].
    These numbers will become clear as we proceed.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Environment**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We’ll define our environment by a set of genes that correspond to the “ideal”
    organism, the one best suited to the environment. In nature, most organisms are
    well suited to their environment; if they weren’t, they’d quickly go extinct.
    However, in the spirit of simulation, we’ll pick a set of genes to be the “best”
    and use them as a proxy for the environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use the distance between the environment’s gene vector and an organism’s
    gene vector as a measure of the organism’s fitness. The smaller this distance,
    the fitter the organism. While there are many possible definitions of “distance”
    when discussing vectors (points), we’ll use the *Euclidean distance*: the straight
    line distance between two points. We’ll imagine each gene vector to be the coordinates
    of a point in a six-dimensional space.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the environment’s gene vector is **e** = (*e*[0], *e*[1], *e*[2], *e*[3],
    *e*[4], *e*[5]) and the organism’s is **x** = (*x*[0], *x*[1], *x*[2], *x*[3],
    *x*[4], *x*[5]), then the Euclidean distance between them is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0086-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In other words, it’s the square root of the sum of the squares of the differences,
    coordinate by coordinate. Here, each coordinate is an integer in [0, 15] to represent
    the selected allele for that gene. In addition, we’ll define a minimum distance
    to interpret as “good enough.”
  prefs: []
  type: TYPE_NORMAL
- en: '**Crossover and Mutation**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Sexual reproduction is a brilliant method for mixing genes and creating diversity
    in the gene pool. Our organisms will breed by crossover, which picks a position
    along the genome and copies all the genes of the first parent up to that point,
    followed by all the remaining genes from the second parent. The new combination
    becomes the genetic code of the offspring. Finally, we’ll apply random mutation
    by picking a gene and randomly changing its value. [Figure 3-5](ch03.xhtml#ch03fig05)
    illustrates the crossover and mutation process.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-5: Crossover and mutation producing a new offspring organism (frog
    image in the public domain, courtesy of Wikimedia Commons)*'
  prefs: []
  type: TYPE_NORMAL
- en: Our organisms aren’t frogs, but you get the idea. Two organisms create an offspring
    using the first two genes of one and the final four of the other. Then, mutation
    changes one of the genes from 10 to 2.
  prefs: []
  type: TYPE_NORMAL
- en: To simulate fitness influencing reproduction, we’ll bias the selection of organisms
    such that those with smaller fitness values are more likely to breed. We’ll do
    this with a *beta distribution*, which is included with NumPy. A beta distribution
    uses two parameters to affect the shape reflecting the overall histogram of samples.
    If both parameters, *a* and *b*, are equal to 1, the beta distribution mimics
    a uniform distribution. If the *b* parameter is increased slightly, the distribution
    is modified, making it more likely that values closer to zero will be selected.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, when breeding the next generation, we’ll select population members
    with indices closer to zero. We’ll sort the population by fitness, with fitter
    organisms nearer to the top of the 2D array of organisms, in which each row is
    an organism and each column a gene.
  prefs: []
  type: TYPE_NORMAL
- en: The net result is that fitter organisms are more likely to breed. Therefore,
    generation by generation, we expect the entire population to inch closer to the
    ideal fitness for the environment.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Population from Generation to Generation**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: I previously alluded to keeping the population in a 2D array. We’ll fix the
    population size at 384 organisms; why will become apparent in time. Therefore,
    a population of organisms becomes a 2D array of 384 rows and 6 columns. Each generation
    will breed another 384 organisms. Put another way, our organisms are seasonal;
    they live a season (time step) and die after spawning the next generation. Population
    geneticists often use such a discrete model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, a simulation implements each of these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Select the initial population at random.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select an environment at random.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For *N* generations, calculate the per-organism fitness, sort the population
    by fitness, and breed each member of the population using crossover and mutation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create output based on the sequence of populations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Visualization**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Every generation produces a population of 384 organisms, each with 6 genes represented
    by one of 16 alleles. Now we’ll learn why the population is always 384 organisms
    with 6 genes. We want to produce as output an image where each row of the image
    shows the population, one organism per pixel, along with the environment. Therefore,
    the output image will have 384 columns plus additional columns to show the environment.
    Each pixel gets its color from the genetic code of the corresponding organism
    with genes mapping to 4 bits of a 24-bit RGB color value, as in [Figure 3-6](ch03.xhtml#ch03fig06).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-6: Mapping genes to RGB colors*'
  prefs: []
  type: TYPE_NORMAL
- en: In the figure, the gene vector becomes a forest green pixel. As the generations
    evolve, we expect the population to move closer to the color of the environment.
    Of course, random mutation will have some say in the matter, as well as fitness;
    we’ll experiment with both.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin with a static environment.
  prefs: []
  type: TYPE_NORMAL
- en: '***Static World***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We’ll dive into code after our experiments. To run an experiment with a static
    environment, use *darwin_static.py*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'There are several parameters, common to most of our experiments:'
  prefs: []
  type: TYPE_NORMAL
- en: 500   Number of generations (rows)
  prefs: []
  type: TYPE_NORMAL
- en: 60   Fitness bias, [0, 1000]
  prefs: []
  type: TYPE_NORMAL
- en: 0.01   Mutation probability
  prefs: []
  type: TYPE_NORMAL
- en: 4   “Good enough” threshold
  prefs: []
  type: TYPE_NORMAL
- en: minstd   Generator name, or filename
  prefs: []
  type: TYPE_NORMAL
- en: darwin_static.png   Output image name
  prefs: []
  type: TYPE_NORMAL
- en: 73939133   Seed value (optional)
  prefs: []
  type: TYPE_NORMAL
- en: While the simulation runs, you’ll see the average fitness per generation. As
    the generations evolve, the fitness decreases until it hovers around the “good
    enough” value. When the simulation ends, then take a look at *darwin_static.png*.
    Color is required, but the image begins something like [Figure 3-7](ch03.xhtml#ch03fig07).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-7: Visualizing a static world*'
  prefs: []
  type: TYPE_NORMAL
- en: Even with the seed specified, there will be variation between runs because we’re
    using the NumPy beta distribution function, and it doesn’t pay attention to our
    seed value.
  prefs: []
  type: TYPE_NORMAL
- en: Read the image from top to bottom. The top row is the initial, randomly generated
    population of 384 organisms. Each subsequent row is another generation bred from
    the one above, each time sorted by fitness so that fitter organisms are closer
    to the left edge. The stripe on the far left is the environment, represented by
    the ideal genome’s color.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you follow down the rows of the image, the population becomes more like
    the ideal environment. However, it never collapses to match the environment exactly.
    Three command line arguments affect how quickly and consistently the population
    matches the environment: the fitness bias, the mutation probability, and the “good
    enough” threshold. Let’s understand each.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Fitness Bias**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The fitness bias is an integer in the range 0 to 1,000\. As we’ll learn in the
    code, this value is divided by 1,000 and added to the second beta distribution
    parameter. The purpose is to increase the fitness of organisms with genomes that
    are better suited to the environment. If the fitness bias is 0, there’s no reproductive
    benefit to being better suited to the environment. As the bias increases, the
    reproductive benefit increases to cause the population to approach the environment’s
    ideal more rapidly.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, run *darwin_static.py* a second time and change only the fitness
    bias from 60 to 600\. The population should approach the environment’s ideal in
    only a few generations. Change the fitness bias to 0 and run again. What do you
    notice now? The population isn’t able to improve because a fitness bias of 0 means
    no reproductive benefit based on an organism’s genome. If you make the fitness
    bias 15, you might need about 1,500 generations, but you should see the population
    eventually adapt to the environment. Even a small reproductive advantage matters
    over the long haul.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Mutation Probability**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now, set the fitness bias to 60 and adjust the mutation rate, expressed as a
    probability. For example, a mutation rate of 0.01 gives each newly bred organism
    a 1 percent chance of undergoing random mutation. A 1 percent mutation rate is
    exceptionally high compared to living animals, but we need to see the effects
    we’re after without millions of generations.
  prefs: []
  type: TYPE_NORMAL
- en: Change the mutation rate of *darwin_static.py* to 0; this means each new generation
    will be created by crossover only. Run a few times and look at the output. What
    do you notice? The population fitness should hit 4 (a distance of 4 from the ideal
    genome) and remain there indefinitely. It can’t do anything else because the genomes
    are already “ideal,” so there’s nothing left to change; pick any two for crossover,
    and, regardless of the crossover point, the offspring’s genome will still be identical
    to the parents’.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how sensitive the population is to mutation. Alter the mutation rate
    from 0.01 to 0.1 (10 percent) and run a few more times. Notice that the population
    adapts to the environment, but never completely. Indeed, as you look down the
    rows of the output image, you’ll likely see regions where many members of the
    population were adapted, but a new mutation appeared and quickly altered the balance
    so that the population had to adapt again in the following generations.
  prefs: []
  type: TYPE_NORMAL
- en: My runs that used a mutation rate of 0.1 generally ended with the population
    mean fitness in the 7.5 to 8.5 range, much higher than the 4 found by no mutation.
    If you change the mutation rate to 0.2 or even 0.8, the population should have
    a harder time adapting to the environment because mutations continually push the
    population away from the ideal. Changing the mutation to a lower rate, say 0.005,
    leads the population to adapt well, but over time (that is, moving down the rows
    of the output image), you’ll see that small groups of mutants appear, then adapt,
    then appear again with another mutation. In the output image, these groups appear
    as splashes of color on the right side of the image—the least fit organisms with
    the lowest probability of breeding.
  prefs: []
  type: TYPE_NORMAL
- en: '**The “Good Enough” Threshold**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The final command line argument is the mysterious “good enough” value, the minimum
    distance between the environment’s ideal genome and an organism’s. When calculating
    the population’s fitness, any distance less than this value is set to this value.
    Experiment by changing the “good enough” value while holding the fitness bias
    and mutation rate fixed (for example, at 60 and 0.01, respectively). The higher
    the “good enough” value, the coarser the population’s adaptation to the environment.
    Set it to 0 and the population will collapse to the ideal, quickly if the fitness
    bias is larger; if the mutation rate is 0, the population will stay there.
  prefs: []
  type: TYPE_NORMAL
- en: I recommend experimenting with *darwin_static.py* until you develop an intuitive
    feel for how changes to the fitness bias, mutation rate, and “good enough” value
    affect the outcome. Try to predict what you expect to see in the output image
    ahead of time. When using simulations, it’s vital to vary parameters, especially
    by pushing them to their limits. Not only does this help with understanding the
    processes the simulation is attempting to capture, it serves as a sanity check
    on the simulation itself, as a way to perhaps uncover weaknesses or errors making
    the results less valid.
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, environments are not static, at least not for timeframes
    over which evolution typically acts (though rapid evolution is possible). Let’s
    add a new feature to the simulation, allowing the environment to change slowly
    with time to understand how such change affects the population.
  prefs: []
  type: TYPE_NORMAL
- en: '***Gradually Changing World***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The code in *darwin_slow.py* is almost identical to the code of the previous
    section, but it introduces a new feature: the environment will change, slightly,
    at an interval specified on the command line. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The new parameter is the 0.01 before the pseudorandom generator (`mt19937`).
    It says to slightly modify the environment on each generation with a probability
    of 1 percent. The *darwin_slow.py* example leads to an output image where the
    environment changes four times. The output image is similar to the static case,
    but each environment transition is marked with a black line on the left. For example,
    the first two transitions appear as in [Figure 3-8](ch03.xhtml#ch03fig08).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-8: The environment in transition*'
  prefs: []
  type: TYPE_NORMAL
- en: Detail will be visible only in the full-color image; see *darwin_slow.png* on
    the book’s GitHub repository. The initial, random population is adapting to the
    environment when the first transition occurs. The population then quickly adapts
    to the new environment when the environment changes again.
  prefs: []
  type: TYPE_NORMAL
- en: If you look at the full *darwin_slow.png* image—hopefully using an image view
    allowing full resolution horizontally—you’ll notice that after the second change
    to the environment, the population adapts quite well, but it takes several generations.
    The visual effect is to smear the colors to the right, where the less fit organisms
    are listed. I recommend running the simulation several times without the fixed
    seed of 66 to observe the overall effect with different colors. Then, explore
    how modifications to the fitness bias and mutation rate play out as the smooth
    changes to the environment happen. To get you started, observe what happens on
    multiple runs with the parameters listed in [Table 3-2](ch03.xhtml#ch03tab02).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 3-2:** Parameters to Try'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Fitness bias** | **Mutation rate** | **Environment probability** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 600 | 0.01 | 0.300 |'
  prefs: []
  type: TYPE_TB
- en: '| 60 | 0.01 | 0.300 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0.01 | 0.005 |'
  prefs: []
  type: TYPE_TB
- en: The first two parameter sets illustrate the effect of a rapidly changing environment
    with both strong and not so strong advantages to fitter organisms. The final set
    of parameters uses the weakest of reproductive advantages, but couples it with
    an almost static environment.
  prefs: []
  type: TYPE_NORMAL
- en: Slowly varying environments give organisms time to adapt. However, throughout
    the Earth’s long history, not all environmental changes were slow; some were quite
    sudden, even happening overnight. Let’s simulate a catastrophe.
  prefs: []
  type: TYPE_NORMAL
- en: '***Catastrophic World***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One fine day, some 66 million years ago, the lifeforms of Earth were minding
    their own business when a giant asteroid rudely interrupted and, as a consequence,
    ended the 100-million-year-plus reign of the nonavian dinosaurs. Bad news for
    them; good news for us. A catastrophe happened, and life responded and appeared
    quite different after the impact. The same thing happened about 252 million years
    ago during The Great Dying when life nearly perished. The world after the extinction
    looked very different from the world before.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve simulated gradual environmental change; now, let’s give the simulation
    a hard knock and see what happens. We need *darwin_catastrophic.py*. Give it a
    go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The parameters are identical to those of *darwin_slow.py*, the difference being
    that whenever the environment should change, it does so by picking an entirely
    new ideal environment genome. The transitions are stark. The image generated is
    similar to that of *darwin_slow.py*, but without the horizontal black line to
    mark the transitions. In this case, the transitions are, generally, quite obvious.
    To see what I mean, run the code, or look at *darwin_catastrophic.png* on the
    book’s GitHub page.
  prefs: []
  type: TYPE_NORMAL
- en: Experiment with the simulation parameters to explore the consequences. For example,
    change the number of generations to 2,000 and look at the output image in its
    entirety by zooming out. The population’s delayed response to each environmental
    catastrophe is plain to see.
  prefs: []
  type: TYPE_NORMAL
- en: Our final simulation introduces genetic drift. How do suddenly split populations
    fare in adapting to new environments?
  prefs: []
  type: TYPE_NORMAL
- en: '***Genetic Drift***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A *population bottleneck* happens when a population experiences a sudden reduction
    in size. One kind of population bottleneck is the *founder effect*, which occurs
    when a small population splits from a larger population. The random mix of alleles
    in the new, smaller population might dramatically affect the long-term survival
    and evolution of the organisms. The code in *darwin_drift.py* simulates genetic
    drift due to the founding of a new, smaller population.
  prefs: []
  type: TYPE_NORMAL
- en: The code is similar to the previous examples, but with a twist. First, a larger
    population (all 384 organisms) evolves for generations trying to adapt to its
    environment. Then, a specified fraction of the whole population “splits off” to
    become a new population. The two populations now evolve separately. Imagine a
    colony of organisms stranded on an island and no longer able to breed with their
    mainland cousins. To make things interesting, after the split, a catastrophe happens,
    so we can observe how well (or poorly) the two populations cope with the sudden
    change in environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The 0.2 before `pcg64` now refers to the fraction of the population that will
    split off to form the new population; that is, 20 percent of the population, randomly
    selected, breaks off to create the new population, leaving the other 80 percent
    as the larger population.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike our other simulations, *darwin_drift.py* expects a base filename (`darwin_drift`)
    instead of a complete filename. The code outputs an image, *darwin_drift.png*,
    along with a plot of the mean population fitness by generation, *darwin_drift_plot.png*.
    As before, there are 500 generations using a fitness bias of 60 and a mutation
    probability of 1 percent.
  prefs: []
  type: TYPE_NORMAL
- en: So what does our image look like? Yet again, I suggest you review the color
    image from the book’s GitHub repository, but part of the output is in [Figure
    3-9](ch03.xhtml#ch03fig09).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-9: Visualizing genetic drift*'
  prefs: []
  type: TYPE_NORMAL
- en: This snippet of the larger image shows part of the simulation after the split.
    The smaller population is on the left, with the larger on the right. Also, if
    you examine the environment, there is a sudden catastrophe about one-sixth of
    the way down. The two populations respond differently to the disaster. This is
    particularly visible in the color version of the image.
  prefs: []
  type: TYPE_NORMAL
- en: Before the catastrophe, both populations were reasonably well adapted to their
    environment. However, the smaller population cannot recover after the catastrophe
    or successfully adjust to the new environment. The larger population does eventually
    adapt. The color version of the image clearly shows that the smaller population
    sometimes produces generations where organisms are adapting to the new environment,
    but they never last long. This effect mirrors reality; small populations are often
    very fragile and easily harmed by rapid environmental change because they lack
    the genetic diversity to adapt in time.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3-10](ch03.xhtml#ch03fig10) tracks mean population fitness as a function
    of generation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-10: Mean population fitness by generation before and after the catastrophe*'
  prefs: []
  type: TYPE_NORMAL
- en: The founder effect event happens around generation 145, where two lines appear.
    The thicker line follows the smaller population. At first, both populations are
    relatively fit to the environment, which hasn’t yet changed, though it could be
    argued that there is more variation in fitness in the smaller population.
  prefs: []
  type: TYPE_NORMAL
- en: The catastrophe occurs around generation 318\. Immediately afterward, both populations’
    fitness scores increase dramatically. Remember, a lower fitness score is better.
    Subsequent generations begin to adapt to the new environment, but not at the same
    rate. The larger population, still 80 percent of the original size, adapts to
    the new environment over time; however, the smaller population fails to do so,
    at least for the 500 generations simulated. For most runs of *darwin_drift.py*,
    the smaller population fails to adapt to the new environment as well as the larger
    population. Sometimes the reverse happens. We’ll talk about this effect in the
    discussion.
  prefs: []
  type: TYPE_NORMAL
- en: What happens if the population splits in half (0.5)? Or, what if the new population
    is a tiny fraction, say 5 or 10 percent? It’s probably easiest to experiment in
    these cases by fixing the fitness bias and mutation rate. Then, fix the population
    fraction and vary those parameters.
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 3-9](ch03.xhtml#ch03fig09), when the population splits, the members
    of the new, smaller population are selected at random. Therefore, they typically
    have an uneven representation of the genotypes in the larger population due to
    chance. That difference might mean that uncommon genotypes now have an opportunity
    to become more common.
  prefs: []
  type: TYPE_NORMAL
- en: 'This effect is illustrated by the code in *drift.py*. First, a “population”
    of 10,000 digits, [0, 9], are selected. Then 20 subpopulations are constructed
    by choosing 50 members of the larger population at random. Finally, the mean of
    the larger population is displayed along with the mean of 20 subpopulations. If
    the mix of digits is the same in each, then the means will be quite close to each
    other. They are not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The subpopulation means range from a low of 3.60 to a high of 5.40\. Uniformly
    selected digits should give a population mean of 4.5, which is close to the larger
    population mean. The subpopulations, due to random chance, represent very different
    collections of digits (genomes). Now we understand why population bottlenecks
    lead to genetic drift.
  prefs: []
  type: TYPE_NORMAL
- en: '***Testing the Simulations***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We used four different sets of code for the previous simulations. Rather than
    detail each, thereby committing the literary equivalent of “death by PowerPoint,”
    let’s walk through one of them here and present snippets from the others as needed.
  prefs: []
  type: TYPE_NORMAL
- en: Look at [Listing 3-2](ch03.xhtml#ch03list02), which contains the critical parts
    of *darwin_static.py*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 3-2: Simulating a static environment*'
  prefs: []
  type: TYPE_NORMAL
- en: I’ve excluded comments and code related to generating the output image. Please
    review the file itself if you’re curious about how those parts work. I recommend
    reading through at least `MakeRGB` to understand the mapping from genes to RGB
    color values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code falls naturally into three parts: parsing the command line ➊, setting
    up the simulation ➋, and running the simulation ➍. In the first part, the randomness
    engine (`rng`) is configured, with or without a seed, to return floats in [0,
    1). The engine is used for different things, so it’s better to use only the basic
    range and adjust the bounds and data type as needed.'
  prefs: []
  type: TYPE_NORMAL
- en: Then the initial population (`pop`) of 384 organisms (`npop`) is created ➋.
    Each organism is given a randomly generated genome ➌. The `environment` is similarly
    defined. The final two variables, `hpop` and `henv`, track the evolution of the
    population and, for other variants of the code, the environment. Note the use
    of a 3D array imagined here as a vector of 2D arrays, each holding the population
    for that generation. The output image is produced using both `hpop` and `henv`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simulation is now ready; the initial population and environment have been
    defined. The main loop ➍ evaluates each generation. The loop body has four paragraphs:
    calculate the per-organism fitness ➎, sort the population by fitness ➏, keep a
    copy of the population for image generation ➐, and, finally, breed the next generation
    ➑.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go through each of those steps. To calculate fitness, we subtract each
    organism’s genome from that of the environment and square and sum the result across
    all genes before applying the square root. This is the NumPy version of [Equation
    3.1](ch03.xhtml#ch03equ1). Fitness in hand, `idx` sorts both the population and
    the fitness vector so that fitter organisms are closer to the beginning of the
    population ➏. Then `hpop` stores the sorted population and environment for the
    output image ➐. The mean population fitness is also printed. As the population
    evolves, this mean value should decrease, depending on the mutation rate and the
    fitness bias.
  prefs: []
  type: TYPE_NORMAL
- en: The last thing to do for this generation is replace it ➑. Repeated calls to
    `Mate` breed a new population of `npop` organisms from the existing population
    as shown in [Listing 3-3](ch03.xhtml#ch03list03).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 3-3: Producing the next generation*'
  prefs: []
  type: TYPE_NORMAL
- en: Here, `Mate` is given the current population and associated fitness (both sorted),
    along with the fitness bias (`advantage`). As mentioned, the fitness bias is divided
    by 1,000.
  prefs: []
  type: TYPE_NORMAL
- en: The function needs to select two distinct organisms, indices `i` and `j`, and
    then produce a new organism by crossover. A call to NumPy’s `beta` function returns
    a value in [0, 1), which, when scaled by the size of the population, will return
    an integer in [0, 383]. The `while` loop runs until a distinct second organism
    is selected (`j`).
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3-11](ch03.xhtml#ch03fig11) shows beta distributions for different
    fitness bias values.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-11: Beta distribution as altered by fitness bias value. Fit organisms
    are more likely to breed if the left portion of the distribution is higher than
    the right.*'
  prefs: []
  type: TYPE_NORMAL
- en: If the bias is 0, the beta distribution acts as a uniform distribution. There
    are 100 bins in the plot, so each will appear about 1 percent of the time (solid
    line). A relatively weak fitness bias of 60 favors small values, or fitter organisms,
    while strongly rejecting the least fit. Similarly, a bias of 900 selects most
    fit to least fit linearly.
  prefs: []
  type: TYPE_NORMAL
- en: Crossover selects a gene position, [0, 5], and constructs the offspring (`org`)
    by keeping the first `c` genes of one parent and adding in the remaining genes
    from the second. Then, if a random value is less than the global `mutation` threshold,
    a randomly selected gene is given a new value, [0, 15]. Finally, the function
    returns the new organism’s genome.
  prefs: []
  type: TYPE_NORMAL
- en: 'To recap: configure, then loop over generations evaluating the population’s
    current fitness before using that information to breed the next generation. Once
    the dust settles, generate the output image.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The file *darwin_slow.py*, which changes the environment as the population
    evolves, is nearly identical to *darwin_static.py*. The loop has one additional
    code paragraph after breeding the next generation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `eprob` is the probability of the environment changing, read from the
    command line. If the environment is to change, we add an `offset` vector to alter
    the ideal genome by ±1 for each gene. Compare this with the catastrophic environmental
    change from *darwin_catastrophic.py*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The final program, *darwin_drift.py*, is structurally similar to *darwin_catastrophic.py*,
    but after a set number of generations, the population splits into two. After this
    split, the environment is altered catastrophically. Although bookkeeping is involved,
    conceptually nothing new is happening.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Use the following exercises as a springboard to expand your appreciation for
    the power of simulation. When working through them, entertain any “what if” questions
    that pop into your head:'
  prefs: []
  type: TYPE_NORMAL
- en: Alter *sim_pi.py* to make two calls to `rng`, first to get the *x*-coordinates,
    then to get the *y*-coordinates. Do you notice any difference? Did you expect
    to?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modify *birthday.py* to use *N* = 1,000,000 or *N* = 10,000\. Is there a noticeable
    difference?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We assumed that birthdays are uniformly distributed throughout the year. This
    isn’t strictly true, at least for Western countries. For those countries, September
    birthdays are more common. What happens to the true probability of two randomly
    selected people sharing a birthday in that case? Does it increase or decrease?
    You may wish to explore the file *birthday_true.py*, which uses data from the
    United Kingdom.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many people need to be at the party to have a 99 percent probability of
    at least one birthday match?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our evolution simulations assumed that all members of a generation bred and
    then died to produce a new generation that was the same size as the last. What
    happens if the least fit 10 percent die and do not reproduce while the fittest
    2 percent breed twice?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bonus points:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In his 1889 book, *Calcul des probabilités*, Joseph Bertrand outlined three
    approaches for calculating the probability that a randomly selected chord of a
    circle is longer than the side of an equilateral triangle inscribed in the circle.
    The files *bertrand0.py*, *bertrand1.py*, and *bertrand2.py* implement simulations
    corresponding to the three approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: '***bertrand0.py***   Use the chord defined by two randomly selected points
    on the circumference of the circle.'
  prefs: []
  type: TYPE_NORMAL
- en: '***bertrand1.py***   Use the chord perpendicular to a randomly selected point
    along a randomly selected radius of the circle.'
  prefs: []
  type: TYPE_NORMAL
- en: '***bertrand2.py***   Use a randomly selected point inside the circle as the
    midpoint of the chord.'
  prefs: []
  type: TYPE_NORMAL
- en: Run all three approaches to select random chords of the circle. For example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: produces the estimated probability along with a plot showing the selected chords,
    as shown in [Figure 3-12](ch03.xhtml#ch03fig12).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/03fig12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3-12: Selected chords when choosing points on the circumference of
    the circle*'
  prefs: []
  type: TYPE_NORMAL
- en: What is the estimated probability for each approach? Which one is correct? This
    is known as *Bertrand’s paradox*, and it serves as a cautionary tale to be careful
    when defining what we want to simulate and how we go about it. Review the code
    to see how the chords are selected.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, we began an introductory exploration of models and simulations;
    we’ll continue to encounter various models throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'We started slowly, with simulations estimating the value of *π* by throwing
    darts and the number of people in a room, on average, necessary to have a better
    than 50 percent chance of at least two sharing a birthday. We then constructed
    a model to simulate two essential aspects of biological evolution: natural selection
    and genetic drift. We learned that even an incomplete model can be a useful tool
    that offers helpful insights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our simulations captured some essence of important evolutionary mechanisms,
    like natural selection and genetic drift, but a huge part of reality was missing:
    death and extinction. For example, many small populations kept evolving when they
    ought to have gone extinct. Extinction is natural; virtually every species that
    has ever lived is extinct (though there’s no reason for us to hurry the process
    along). Adding death and extinction would create a level of complexity to the
    simulation that doesn’t fit with what we can accomplish in this book. Regardless,
    the simulations of this section are practical and illustrative as far as they
    go. All analogies fail at some point—that doesn’t make them useless.'
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter continues our investigation of useful randomness by diving
    into the world of optimization. Can randomness be put to work in service of locating
    the best of something?
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*There is no formal resolution to Bertrand’s paradox. Many people, including
    me, feel that p = 1/2 is the most reasonable answer.*'
  prefs: []
  type: TYPE_NORMAL
