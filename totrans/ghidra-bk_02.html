<html><head></head><body><div id="sbo-rt-content"><span epub:type="pagebreak" id="page_3"/>
<h2 class="h2" id="ch01"><strong><span class="big">1</span><br/>INTRODUCTION TO DISASSEMBLY</strong></h2>
<div class="image1"><img src="Images/com.jpg" alt="Image" width="204" height="204"/></div>
<p class="noindent">You may be wondering what to expect in a book dedicated to Ghidra. While obviously Ghidra-centric, this book is not intended to come across as <em>The Ghidra User’s Manual</em>. Instead, we intend to use Ghidra as the enabling tool for discussing reverse engineering techniques that you will find useful in analyzing a wide variety of software, ranging from vulnerable applications to malware. When appropriate, we will provide detailed steps in Ghidra for performing specific actions related to the task at hand. As a result, we will take a rather roundabout walk through Ghidra’s capabilities, beginning with the basic tasks you will want to perform upon initial examination of a file and leading up to advanced uses and customization of Ghidra for more challenging reverse engineering problems. We make no attempt to cover all of Ghidra’s features. We do, however, cover the features you will find most useful in meeting your reverse engineering challenges. This book will help make Ghidra the most potent weapon in your arsenal of tools.</p>
<span epub:type="pagebreak" id="page_4"/>
<p class="indent">Prior to diving into any Ghidra specifics, we will cover some of the basics of the disassembly process and review other tools available for reverse engineering compiled code. While these tools may not match the complete range of Ghidra’s capabilities, each does address specific subsets of Ghidra functionality and offers valuable insight into specific Ghidra features. The remainder of this chapter is dedicated to understanding the disassembly process from a high level.</p>
<h3 class="h3" id="ch01lev11"><strong>Disassembly Theory</strong></h3>
<p class="noindent">Anyone who has spent any time at all studying programming languages has probably learned about the various generations of languages, but they are summarized here for those who may have been sleeping:</p>
<p class="uln-indent"><strong>First-generation languages</strong> These are the lowest form of language, generally consisting of ones and zeros or a shorthand form, such as hexadecimal, and readable only by binary ninjas. Distinguishing data from instructions is difficult at this level because all the content looks the same. First-generation languages may also be referred to as <em>machine languages</em>, and in some cases <em>byte code</em>, while machine language programs are often referred to as <em>binaries</em>.</p>
<p class="uln-indent"><strong>Second-generation languages</strong> Also called <em>assembly languages</em>, second-generation languages are a mere table lookup away from machine language and generally map specific bit patterns, or operation codes (opcodes), to short but memorable character sequences called <em>mnemonics</em>. These mnemonics help programmers remember the instructions with which they are associated. An <em>assembler</em> is a tool used by programmers to translate their assembly language programs into machine language suitable for execution. In addition to instruction mnemonics, a complete assembly language generally includes <em>directives</em> to the assembler that help dictate the memory layout of code and data in the final binary.</p>
<p class="uln-indent"><strong>Third-generation languages</strong> These languages take another step toward the expressive capability of natural languages by introducing keywords and constructs that programmers use as the building blocks for their programs. Third-generation languages are generally platform independent, though programs written using them may be platform dependent as a result of using features unique to a specific operating system. Often-cited examples of third-generation languages include FORTRAN, C, and Java. Programmers generally use compilers to translate their programs into assembly language or all the way to machine language (or some rough equivalent such as byte code).</p>
<p class="uln-indent"><strong>Fourth-generation languages</strong> These exist but aren’t relevant to this book and are not discussed.</p>
<span epub:type="pagebreak" id="page_5"/>
<h3 class="h3" id="ch01lev12"><strong>The What of Disassembly</strong></h3>
<p class="noindent">In a traditional software development model, compilers, assemblers, and linkers are used by themselves or in combination to create executable programs. To work our way backward (or reverse engineer programs), we use tools to undo the assembly and compilation processes. Not surprisingly, such tools are called <em>disassemblers</em> and <em>decompilers</em>, and they do pretty much what their names indicate. A disassembler undoes the assembly process, so we should expect assembly language as the output (and therefore machine language as input). Decompilers aim to produce output in a high-level language when given assembly or even machine language as input.</p>
<p class="indent">The promise of “source code recovery” will always be attractive in a competitive software market, and thus the development of usable decompilers remains an active research area in computer science. The following are just a few of the reasons that decompilation is difficult:</p>
<p class="uln-indent"><strong>The compilation process is lossy.</strong> At the machine language level, there are no variable or function names, and variable type information can be determined only by how the data is used rather than explicit type declarations. When you observe 32 bits of data being transferred, you’ll need to do some investigative work to determine whether those 32 bits represent an integer, a 32-bit floating point value, or a 32-bit pointer.</p>
<p class="uln-indent"><strong>Compilation is a many-to-many operation.</strong> This means that a source program can be translated to assembly language in many different ways, and machine language can be translated back to source in many different ways. As a result, compiling a file and immediately decompiling it commonly yields a source file that is vastly different from the original.</p>
<p class="uln-indent"><strong>Decompilers are language and library dependent.</strong> Processing a binary produced by a Delphi compiler with a decompiler designed to generate C code can yield very strange results. Similarly, feeding a compiled Windows binary through a decompiler that has no knowledge of the Windows programming API may not yield anything useful.</p>
<p class="uln-indent"><strong>A nearly perfect disassembly capability is needed in order to accurately decompile a binary.</strong> Any errors or omissions in the disassembly phase will almost certainly propagate through to the decompiled code. Disassembled code can be verified for correctness against appropriate processor reference manuals; however, no canonical reference manuals are available to use in verifying the correctness of a decompiler’s output.</p>
<p class="indent">Ghidra has a built-in decompiler, which is the subject of <a href="ch19.xhtml#ch19">Chapter 19</a>.</p>
<span epub:type="pagebreak" id="page_6"/>
<h3 class="h3" id="ch01lev13"><strong>The Why of Disassembly</strong></h3>
<p class="noindent">The purpose of disassembly tools is often to facilitate understanding of programs when source code is unavailable. Common situations in which disassembly is used include the following:</p>
<ul>
<li class="noindent">Analysis of malware</li>
<li class="noindent">Analysis of closed source software for vulnerabilities</li>
<li class="noindent">Analysis of closed source software for interoperability</li>
<li class="noindent">Analysis of compiler-generated code to validate compiler performance or correctness</li>
<li class="noindent">Display of program instructions while debugging</li>
</ul>
<p class="noindent">The subsequent sections explain each situation in more detail.</p>
<h4 class="h4" id="ch01lev14"><strong><em>Malware Analysis</em></strong></h4>
<p class="noindent">Unless you are dealing with script-based malware, malware authors seldom do you the favor of providing the source code to their creations. Lacking source code, you are faced with a very limited set of options for discovering exactly how the malware behaves. The two main techniques for malware analysis are dynamic analysis and static analysis. <em>Dynamic analysis</em> involves allowing the malware to execute in a carefully controlled environment (sandbox) while recording every observable aspect of its behavior by using any number of system instrumentation utilities. In contrast, <em>static analysis</em> attempts to understand the behavior of a program simply by reading through the program code, which, in the case of malware, generally consists solely of a disassembly listing and possibly a decompiler listing.</p>
<h4 class="h4" id="ch01lev15"><strong><em>Vulnerability Analysis</em></strong></h4>
<p class="noindent">For the sake of simplification, let’s break the entire security-auditing process into three steps: vulnerability discovery, vulnerability analysis, and exploit development. The same steps apply whether you have source code or not; however, the level of effort increases substantially when all you have is a binary. The first step in the process is to discover a potentially exploitable condition in a program. This is often accomplished using dynamic techniques such as fuzzing,<sup><a id="ch01fn1a" href="footnotes.xhtml#ch01fn1">1</a></sup> but it can also be performed (usually with much more effort) via static analysis. Once a problem has been discovered, further analysis is often required to determine whether the problem is exploitable at all and, if so, under what conditions.</p>
<p class="indent">Identifying variables that can be manipulated to the attacker’s advantage is an important early step in vulnerability discovery. Disassembly listings provide the level of detail required to understand exactly how the compiler has chosen to allocate program variables. For example, it might <span epub:type="pagebreak" id="page_7"/>be useful to know that a 70-byte character array declared by a programmer was rounded up to 80 bytes when allocated by the compiler. Disassembly listings also provide the only means to determine exactly how a compiler has chosen to order all of the variables declared globally or within functions. Understanding the spatial relationships among variables is often essential when attempting to develop exploits. Ultimately, by using a disassembler and a debugger together, an exploit may be developed.</p>
<h4 class="h4" id="ch01lev16"><strong><em>Software Interoperability</em></strong></h4>
<p class="noindent">When software is released in binary form only, it is very difficult for competitors to create software that can interoperate with it or to provide plugin replacements for that software. A common example is driver code released for hardware that is supported on only one platform. When a vendor is slow to support or, worse yet, refuses to support the use of its hardware with alternative platforms, substantial reverse engineering effort may be required in order to develop software drivers to support the hardware. In these cases, static code analysis is almost the only remedy and often must go beyond the software driver to understand embedded firmware.</p>
<h4 class="h4" id="ch01lev17"><strong><em>Compiler Validation</em></strong></h4>
<p class="noindent">Since the purpose of a compiler (or assembler) is to generate machine language, good disassembly tools are often required to verify that the compiler is doing its job in accordance with any design specifications. Analysts may also be interested in locating additional opportunities for optimizing compiler output and, from a security standpoint, ascertaining whether the compiler itself has been compromised to the extent that it may be inserting backdoors into generated code.</p>
<h4 class="h4" id="ch01lev18"><strong><em>Debugging Displays</em></strong></h4>
<p class="noindent">Perhaps the single most common use of disassemblers is to generate listings within debuggers. Unfortunately, disassemblers embedded within debuggers tend to lack sophistication. They are generally incapable of batch disassembly and sometimes balk at disassembling when they cannot determine the boundaries of a function. This is one of the reasons it is best to use a debugger in conjunction with a high-quality disassembler to provide better situational awareness and context during debugging.</p>
<h3 class="h3" id="ch01lev19"><strong>The How of Disassembly</strong></h3>
<p class="noindent">Now that you’re well versed in the purposes of disassembly, it’s time to move on to how the process actually works. Consider a typical daunting task faced by a disassembler: <em>Take these 100KB, distinguish code from data, convert the code to assembly language for display to a user, and please don’t miss anything along the way.</em> We could tack on any number of special requests, such as asking the disassembler to locate functions, recognize jump tables, and identify local variables, making the disassembler’s job that much more difficult.</p>
<span epub:type="pagebreak" id="page_8"/>
<p class="indent">To accommodate all of our demands, any disassembler will need to pick and choose from a variety of algorithms as it navigates through the files we feed it. The quality of the generated disassembly listing will be directly related to the quality of the algorithms utilized and how well they have been implemented.</p>
<p class="indent">In this section, we discuss two of the fundamental algorithms in use today for disassembling machine code. As we present these algorithms, we also point out their shortcomings in order to prepare you for situations in which your disassembler appears to fail. By understanding a disassembler’s limitations, you will be able to manually intervene to improve the overall quality of the disassembly output.</p>
<h4 class="h4" id="ch01lev20"><strong><em>A Basic Disassembly Algorithm</em></strong></h4>
<p class="noindent">For starters, let’s develop a simple algorithm for accepting machine language as input and producing assembly language as output. In doing so, you will gain an understanding of the challenges, assumptions, and compromises that underlie an automated disassembly process:</p>
<ol>
<li class="noindent">The first step in the disassembly process is to identify a region of code to disassemble. This is not necessarily as straightforward as it may seem. Instructions are generally mixed with data, and it is important to distinguish between the two. In the most common case, disassembly of an executable file, the file will conform to a common format for executable files such as the <em>Portable Executable (PE)</em> format used on Windows and the <em>Executable and Linkable Format (ELF)</em> common on many Unix-based systems. These formats typically contain mechanisms (often in the form of hierarchical file headers) for locating the sections of the file that contain code and entry points into that code.<sup><a id="ch01fn2a" href="footnotes.xhtml#ch01fn2">2</a></sup></li>
<li class="noindent">Given the address of an instruction, the next step is to read the value or values contained at that address (or file offset) and perform a table lookup to match the binary opcode value to its assembly language mnemonic. Depending on the complexity of the instruction set being disassembled, this may be a trivial process, or it may involve several additional operations such as understanding any prefixes that may modify the instruction’s behavior and determining any operands required by the instruction. For instruction sets with variable-length instructions, such as the Intel x86 instruction set, additional instruction bytes may need to be retrieved in order to completely disassemble a single instruction.</li>
<li class="noindent">Once an instruction has been fetched and any required operands decoded, its assembly language equivalent is formatted and output as part of the disassembly listing. It may be possible to choose from more <span epub:type="pagebreak" id="page_9"/>than one assembly language output syntax. For example, the two predominant formats for x86 assembly language are the Intel format and the AT&amp;T format.</li>
<li class="noindent">Following the output of an instruction, we need to advance to the next instruction and repeat the previous process until we have disassembled every instruction in the file.</li>
</ol>
<div class="box5">
<p class="boxtitle-c"><strong>X86 ASSEMBLY SYNTAX: AT&amp;T VS. INTEL</strong></p>
<p class="noindent">Two main syntaxes are used for assembly source code: AT&amp;T and Intel. Even though they are second-generation languages, the two vary greatly in syntax—from variable, constant, and register access, to segment and instruction size overrides, to indirection and offsets. The AT&amp;T assembly syntax is distinguished by its use of the <span class="literal">%</span> symbol to prefix all register names, the use of <span class="literal">$</span> as a prefix for literal constants (also called <em>immediate operands</em>), and its operand ordering in which the source operand appears on the left and the destination operand appears on the right. Using AT&amp;T syntax, the instruction to add 4 to the <span class="literal">EAX</span> register would be <span class="literal">add $0x4,%eax</span>. The GNU Assembler <span class="literal">(as)</span> and many other GNU tools, including <span class="literal">gcc</span> and <span class="literal">gdb</span>, utilize AT&amp;T syntax by default.</p>
<p class="indent">Intel syntax differs from AT&amp;T in that it requires no register or literal prefixes, and the operand ordering is reversed such that the source operand appears on the right and the destination appears on the left. The same <span class="literal">add</span> instruction using the Intel syntax would be <span class="literal">add eax,0x4</span>. Assemblers utilizing Intel syntax include the Microsoft Assembler (MASM) and the Netwide Assembler (NASM).</p>
</div>
<p class="indent">Various algorithms exist for determining where to begin a disassembly, how to choose the next instruction to be disassembled, how to distinguish code from data, and how to determine when the last instruction has been disassembled. The two predominant disassembly algorithms are linear sweep and recursive descent.</p>
<h4 class="h4" id="ch01lev21"><strong><em>Linear Sweep Disassembly</em></strong></h4>
<p class="noindent">The <em>linear sweep</em> disassembly algorithm takes a very straightforward approach to locating instructions to disassemble: where one instruction ends, another begins. As a result, the most difficult decisions faced are where to begin and when to stop. The usual solution is to assume that everything contained in sections of a program marked as code (typically specified by the program file’s headers) represents machine language instructions. Disassembly begins with the first byte in a code section and moves, in a linear fashion, through the section, disassembling one instruction after another until the end of the section is reached. No effort is made to understand the program’s control flow through recognition of nonlinear instructions such as branches.</p>
<span epub:type="pagebreak" id="page_10"/>
<p class="indent">During the disassembly process, a pointer can be maintained to mark the beginning of the instruction currently being disassembled. As part of the disassembly process, the length of each instruction is computed and used to determine the location of the next instruction to be disassembled. Instruction sets with fixed-length instructions (MIPS, for example) are somewhat easier to disassemble, as locating subsequent instructions is straightforward.</p>
<p class="indent">The main advantage of the linear sweep algorithm is that it provides complete coverage of a program’s code sections. One of the primary disadvantages of the linear sweep method is that it fails to account for data that may be comingled with code. This is evident in <a href="ch01.xhtml#exa1_1">Listing 1-1</a>, which shows the output of a function disassembled with a linear sweep disassembler.</p>
<p class="programs">    40123f:   55                       push ebp<br/>
    401240:   8b ec                    mov ebp,esp<br/>
    401242:   33 c0                    xor eax,eax<br/>
    401244:   8b 55 08                 mov edx,DWORD PTR [ebp+8]<br/>
    401247:   83 fa 0c                 cmp edx,0xc<br/>
    40124a:   0f 87 90 00 00 00        ja 0x4012e0<br/>
    401250:   ff 24 95 57 12 40 00     jmp DWORD PTR [edx*4+0x401257]<span class="ent">➊</span><br/>
<span class="ent">➋</span>  401257:   e0 12                    loopne 0x40126b<br/>
    401259:   40                       inc eax<br/>
    40125a:   00 8b 12 40 00 90        add BYTE PTR [ebx-0x6fffbfee],cl<br/>
    401260:   12 40 00                 adc al,BYTE PTR [eax]<br/>
    401263:   95                       xchg ebp,eax<br/>
    401264:   12 40 00                 adc al,BYTE PTR [eax]<br/>
    401267:   9a 12 40 00 a2 12 40     call 0x4012:0xa2004012<br/>
    40126e:   00 aa 12 40 00 b2        add BYTE PTR [edx-0x4dffbfee],ch<br/>
    401274:   12 40 00                 adc al,BYTE PTR [eax]<br/>
    401277:   ba 12 40 00 c2           mov edx,0xc2004012<br/>
    40127c:   12 40 00                 adc al,BYTE PTR [eax]<br/>
    40127f:   ca 12 40                 lret 0x4012<br/>
    401282:   00 d2                    add dl,dl<br/>
    401284:   12 40 00                 adc al,BYTE PTR [eax]<br/>
    401287:   da 12                    ficom DWORD PTR [edx]<br/>
    401289:   40                       inc eax<br/>
    40128a:   00 8b 45 0c eb 50        add BYTE PTR [ebx+0x50eb0c45],cl<br/>
    401290:   8b 45 10                 mov eax,DWORD PTR [ebp+16]<br/>
    401293:   eb 4b                    jmp 0x4012e0</p>
<p class="ex-caption" id="exa1_1"><em>Listing 1-1: Linear sweep disassembly</em></p>
<p class="indent">This function contains a switch statement, and the compiler used in this case has elected to implement the switch by using a jump table to resolve case label targets. Furthermore, the compiler has elected to embed the jump table within the function itself. The <span class="literal">jmp</span> statement <span class="ent">➊</span> references an address table <span class="ent">➋</span>. Unfortunately, the disassembler treats the address table as if it were a series of instructions and incorrectly generates the following assembly language representation.</p>
<span epub:type="pagebreak" id="page_11"/>
<p class="indent">If we treat successive 4-byte groups in the jump table <span class="ent">➋</span> as little-endian values,<sup><a id="ch01fn3a" href="footnotes.xhtml#ch01fn3">3</a></sup> we see that each represents a pointer to a nearby address that is in fact the destination for one of the various jumps (<span class="literal">004012e0</span>, <span class="literal">0040128b</span>, <span class="literal">00401290</span>, . . .). Thus, the <span class="literal">loopne</span> instruction <span class="ent">➋</span> is not an instruction at all. Instead, it indicates a failure of the linear sweep algorithm to properly distinguish embedded data from code.</p>
<p class="indent">Linear sweep is used by the disassembly engines contained in the GNU debugger (gdb), Microsoft’s WinDbg debugger, and the <span class="literal">objdump</span> utility.</p>
<h4 class="h4" id="ch01lev22"><strong><em>Recursive Descent Disassembly</em></strong></h4>
<p class="noindent">The <em>recursive descent</em> disassembly algorithm takes a different approach to locating instructions: it focuses on the concept of control flow, which determines whether an instruction should be disassembled based on whether it is referenced by another instruction. To understand recursive descent, it is helpful to classify instructions according to how they affect the instruction pointer.</p>
<h5 class="h5" id="ch01lev23"><strong>Sequential Flow Instructions</strong></h5>
<p class="noindent"><em>Sequential flow instructions</em> pass execution to the instruction that immediately follows. Examples of sequential flow instructions include simple arithmetic instructions, such as <span class="literal">add</span>; register-to-memory transfer instructions, such as <span class="literal">mov</span>; and stack-manipulation operations, such as <span class="literal">push</span> and <span class="literal">pop</span>. For such instructions, disassembly proceeds as with linear sweep.</p>
<h5 class="h5" id="ch01lev24"><strong>Conditional Branching Instructions</strong></h5>
<p class="noindent"><em>Conditional branching instructions</em>, such as the x86 <span class="literal">jnz</span>, offer two possible execution paths. If the condition evaluates to true, the branch is taken, and the instruction pointer must be changed to reflect the target of the branch. However, if the condition is false, execution continues in a linear fashion, and a linear sweep methodology can be used to disassemble the next instruction. As it is generally not possible in a static context to determine the outcome of a conditional test, the recursive descent algorithm disassembles both paths, deferring disassembly of the branch target instruction by adding the address of the target instruction to a list of addresses to be disassembled at a later point.</p>
<h5 class="h5" id="ch01lev25"><strong>Unconditional Branching Instructions</strong></h5>
<p class="noindent"><em>Unconditional branches</em> do not follow the linear flow model and therefore are handled differently by the recursive descent algorithm. As with the sequential flow instructions, execution can flow to only one instruction; however, that <span epub:type="pagebreak" id="page_12"/>instruction need not immediately follow the branch instruction. In fact, as seen in <a href="ch01.xhtml#exa1_1">Listing 1-1</a>, there is no requirement at all for an instruction to immediately follow an unconditional branch. Therefore, there is no reason to immediately disassemble the bytes that follow an unconditional branch.</p>
<p class="indent">A recursive descent disassembler attempts to determine the target of the unconditional jump and continues disassembly at the target address. Unfortunately, some unconditional branches can cause problems for recursive descent disassemblers. When the target of a jump instruction depends on a runtime value, it may not be possible to determine the destination of the jump by using static analysis. The x86 instruction <span class="literal">jmp</span> <span class="literal">rax</span> demonstrates this problem. The <span class="literal">rax</span> register contains a value only when the program is actually running. Since the register contains no value during static analysis, we have no way to determine the target of the jump instruction, and, consequently, we have no way to determine where to continue the disassembly process.</p>
<h5 class="h5" id="ch01lev26"><strong>Function Call Instructions</strong></h5>
<p class="noindent"><em>Function call instructions</em> operate similarly to unconditional jump instructions (including the inability of the disassembler to determine the target of instructions such as <span class="literal">call rax</span>), with the additional expectation that execution usually returns to the instruction immediately following the call instruction after the function completes. In this regard, they are similar to conditional branch instructions in that they generate two execution paths. The target address of the call instruction is added to a list for deferred disassembly, while the instruction immediately following the call is disassembled in a manner similar to linear sweep.</p>
<p class="indent">Recursive descent can fail if programs do not behave as expected when returning from called functions. For example, code in a function can deliberately manipulate the return address of that function so that upon completion, control returns to a location different from the one expected by the disassembler. A simple example is shown in the following incorrect listing, where function <span class="literal">badfunc</span> simply adds 1 to the return address before returning to the caller:</p>
<p class="programs">badfunc proc near<br/>
48 FF 04 24  inc qword ptr [rsp] ; increments saved return addr<br/>
C3           retn<br/>
badfunc endp<br/>
<span epub:type="pagebreak" id="page_13"/>
; -------------------------------------<br/>
label:<br/>
E8 F6 FF FF FF   call badfunc<br/>
05 48 89 45 F8   add eax, F8458948h<span class="ent">➊</span></p>
<p class="indent">As a result, control does not actually pass to the <span class="literal">add</span> instruction <span class="ent">➊</span> following the call to <span class="literal">badfunc</span>. A proper disassembly appears next:</p>
<p class="programs">badfunc proc near<br/>
48 FF 04 24  inc qword ptr [rsp]<br/>
C3           retn<br/>
badfunc endp<br/>
; -------------------------------------<br/>
label:<br/>
E8 F6 FF FF FF  call badfunc<br/>
05              db 5        ;formerly the first byte of the add instruction<br/>
48 89 45 F8     mov [rbp-8], rax<span class="ent">➊</span></p>
<p class="indent">This listing more clearly shows the flow of the program in which function <span class="literal">badfunc</span> actually returns to the <span class="literal">mov</span> instruction <span class="ent">➊</span>. It is important to understand that a linear sweep disassembler will also fail to properly disassemble this code, though for slightly different reasons.</p>
<h5 class="h5" id="ch01lev27"><strong>Return Instructions</strong></h5>
<p class="noindent">In some cases, the recursive descent algorithm runs out of paths to follow. A function <em>return instruction</em> (x86 <span class="literal">ret</span>, for example) offers no information about which instruction will be executed next. If the program were actually running, an address would be taken from the top of the runtime stack, and execution would resume at that address. Disassemblers do not have the benefit of access to a stack. Instead, disassembly abruptly comes to a halt. It is at this point that the recursive descent disassembler turns to the list of addresses it has been setting aside for deferred disassembly. An address is removed from this list, and the disassembly process is continued from this address. This is the recursive process that lends the disassembly algorithm its name.</p>
<p class="indent">One of the principle advantages of the recursive descent algorithm is its superior ability to distinguish code from data. As a control flow-based algorithm, it is much less likely to incorrectly disassemble data values as code. The main disadvantage of recursive descent is the inability to follow indirect code paths, such as jumps or calls, which utilize tables of pointers to look up a target address. However, with the addition of some heuristics to identify pointers to code, recursive descent disassemblers can provide very complete code coverage and excellent recognition of code versus data. <a href="ch01.xhtml#exa1_2">Listing 1-2</a> shows the output of Ghidra’s recursive descent disassembler used on the same switch statement shown earlier in <a href="ch01.xhtml#exa1_1">Listing 1-1</a>.</p>
<p class="programs">0040123f  PUSH   EBP<br/>
00401240  MOV    EBP,ESP<br/>
00401242  XOR    EAX,EAX<br/>
00401244  MOV    EDX,dword ptr [EBP + param_1]<br/>
00401247  CMP    EDX,0xc<br/>
0040124a  JA     switchD_00401250::caseD_0<br/>
        switchD_00401250::switchD<br/>
00401250  JMP    dword ptr [EDX*0x4 + -&gt;switchD_00401250::caseD_0] = 004012e0<br/>
        switchD_00401250::switchdataD_00401257<br/>
00401257  addr   switchD_00401250::caseD_0<br/>
0040125b  addr   switchD_00401250::caseD_1<br/>
0040125f  addr   switchD_00401250::caseD_2<br/>
00401263  addr   switchD_00401250::caseD_3<br/>
00401267  addr   switchD_00401250::caseD_4<br/>
0040126b  addr   switchD_00401250::caseD_5<br/>
0040126f  addr   switchD_00401250::caseD_6<br/>
<span epub:type="pagebreak" id="page_14"/>
00401273  addr   switchD_00401250::caseD_7<br/>
00401277  addr   switchD_00401250::caseD_8<br/>
0040127b  addr   switchD_00401250::caseD_9<br/>
0040127f  addr   switchD_00401250::caseD_a<br/>
00401283  addr   switchD_00401250::caseD_b<br/>
00401287  addr   switchD_00401250::caseD_c<br/>
        switchD_00401250::caseD_1<br/>
0040128b  MOV    EAX,dword ptr [EBP + param_2]<br/>
0040128e  JMP    switchD_00401250::caseD_00040128E</p>
<p class="ex-caption" id="exa1_2"><em>Listing 1-2: Recursive descent disassembly</em></p>
<p class="indent">Note that this section of the binary has been recognized as a switch statement and formatted accordingly. An understanding of the recursive descent process will help us recognize situations in which Ghidra may produce less-than-optimal disassemblies and allow us to develop strategies to improve Ghidra’s output.</p>
<h3 class="h3" id="ch01lev28"><strong>Summary</strong></h3>
<p class="noindent">Is deep understanding of disassembly algorithms essential when using a disassembler? No. Is it useful? Yes! Battling your tools is the last thing you want to spend time doing while reverse engineering. One of the many advantages of Ghidra is that, as an interactive disassembler, it offers you plenty of opportunity to guide and override its decisions. The net result is quite often a disassembly that is both thorough and accurate.</p>
<p class="indent">In the next chapter, we review a variety of existing tools that prove useful in many reverse engineering situations. While not directly related to Ghidra, many of these tools have influenced Ghidra, and they help to explain the wide variety of informational displays available in the Ghidra user interface.</p>
</div>



  </body></html>