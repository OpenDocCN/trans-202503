["```\nCREATE TABLE meat_poultry_egg_establishments (\n  1 establishment_number text CONSTRAINT est_number_key PRIMARY KEY,\n    company text,\n    street text,\n    city text,\n    st text,\n    zip text,\n    phone text,\n    grant_date date,\n  2 activities text,\n    dbas text\n);\n\n3 COPY meat_poultry_egg_establishments\nFROM '`C:\\YourDirectory\\`MPI_Directory_by_Establishment_Name.csv'\nWITH (FORMAT CSV, HEADER);\n\n4 CREATE INDEX company_idx ON meat_poultry_egg_establishments (company);\n```", "```\nSELECT count(*) FROM meat_poultry_egg_establishments;\n```", "```\nSELECT company,\n       street,\n       city,\n       st,\n       count(*) AS address_count\nFROM meat_poultry_egg_establishments\nGROUP BY company, street, city, st\nHAVING count(*) > 1\nORDER BY company, street, city, st;\n```", "```\ncompany                    street                     city          st    address_count\n-----------------------    -----------------------    ----------    --    -------------\nAcre Station Meat Farm     17076 Hwy 32 N             Pinetown      NC                2\nBeltex Corporation         3801 North Grove Street    Fort Worth    TX                2\nCloverleaf Cold Storage    111 Imperial Drive         Sanford       NC                2\n`--snip--`\n```", "```\nSELECT st,\n       count(*) AS st_count\nFROM meat_poultry_egg_establishments\nGROUP BY st\nORDER BY st;\n```", "```\nst    st_count\n--    --------\nAK          17\nAL          93\nAR          87\nAS           1\n`--snip--`\nWA         139\nWI         184\nWV          23\nWY           1\n             3\n```", "```\nSELECT establishment_number,\n       company,\n       city,\n       st,\n       zip\nFROM meat_poultry_egg_establishments\nWHERE st IS NULL;\n```", "```\nest_number           company                            city      st    zip\n-----------------    -------------------------------    ------    --    -----\nV18677A              Atlas Inspection, Inc.             Blaine          55449\nM45319+P45319        Hall-Namie Packing Company, Inc                    36671\nM263A+P263A+V263A    Jones Dairy Farm                                   53538\n```", "```\nSELECT company,\n       count(*) AS company_count\nFROM meat_poultry_egg_establishments\nGROUP BY company\nORDER BY company ASC;\n```", "```\ncompany                        company_count\n---------------------------    -------------\n`--snip--`\nArmour - Eckrich Meats, LLC                1\nArmour-Eckrich Meats LLC                   3\nArmour-Eckrich Meats, Inc.                 1\nArmour-Eckrich Meats, LLC                  2\n`--snip--`\n```", "````Solely for the purpose of this example, I replicated a common error I’ve committed before. When I converted the original Excel file to a CSV file, I stored the ZIP code in the default “General” number format instead of as a text value, and any ZIP code that begins with a zero lost its leading zero because an integer can’t start with a zero. As a result, 07502 appears in the table as `7502`. You can make this error in a variety of ways, including by copying and pasting data into Excel columns set to “General.” After being burned a few times, I learned to take extra caution with numbers that should be formatted as text.    My deliberate error appears when we run the code in [Listing 10-6](#listing10-6). The example introduces `length()`, a *string function* that counts the number of characters in a string. We combine `length()` with `count()` and `GROUP BY` to determine how many rows have five characters in the `zip` field and how many have a value other than five. To make it easy to scan the results, we use `length()` in the `ORDER BY` clause.    ``` SELECT length(zip),         count(*) AS length_count  FROM meat_poultry_egg_establishments  GROUP BY length(zip)  ORDER BY length(zip) ASC; ```    Listing 10-6: Using `length()` and `count()` to test the `zip` column    The results confirm the formatting error. As you can see, `496` of the ZIP codes are four characters long, and `86` are three characters long, which likely means these numbers originally had two leading zeros that my conversion erroneously eliminated:    ``` length    length_count  ------    ------------       3              86       4             496       5            5705 ```    Using the `WHERE` clause, we can see which states these shortened ZIP codes correspond to, as shown in [Listing 10-7](#listing10-7).    ``` SELECT st,         count(*) AS st_count  FROM meat_poultry_egg_establishments  1 WHERE length(zip) < 5  GROUP BY st  ORDER BY st ASC; ```    Listing 10-7: Filtering with `length()` to find short `zip` values    We use the `length()` function inside the `WHERE` clause 1 to return a count of rows where the ZIP code is less than five characters for each state code. The result is what we would expect. The states are largely in the Northeast region of the United States where ZIP codes often start with a zero:    ``` st    st_count  --    --------  CT          55  MA         101  ME          24  NH          18  NJ         244  PR          84  RI          27  VI           2  VT          27 ```    Obviously, we don’t want this error to persist, so we’ll add it to our list of items to correct. So far, we need to correct the following issues in our dataset:    *   Missing values for three rows in the `st` column *   Inconsistent spelling of at least one company’s name *   Inaccurate ZIP codes due to file conversion    Next, we’ll look at how to use SQL to fix these issues by modifying your data.    ## Modifying Tables, Columns, and Data    Almost nothing in a database, from tables to columns and the data types and values they contain, is set in concrete after it’s created. As your needs change, you can use SQL to add columns to a table, change data types on existing columns, and edit values. Given the issues we discovered in the `meat_poultry_egg_establishments` table, being able to modify our database will come in handy.    We’ll use two SQL commands. The first, `ALTER TABLE`, is part of the ANSI SQL standard and provides options to `ADD COLUMN`, `ALTER COLUMN`, and `DROP COLUMN`, among others.    The second command, `UPDATE`, also included in the SQL standard, allows you to change values in a table’s columns. You can supply criteria using `WHERE` to choose which rows to update.    Let’s explore the basic syntax and options for both commands and then use them to fix the issues in our dataset.    ### Modifying Tables with ALTER TABLE    We can use the `ALTER TABLE` statement to modify the structure of tables. The following examples show standard ANSI SQL syntax for common operations, starting with the code for adding a column to a table:    ``` ALTER TABLE `table` ADD COLUMN `column` `data_type`; ```    We can remove a column with the following syntax:    ``` ALTER TABLE `table` DROP COLUMN `column`; ```    To change the data type of a column, we would use this code:    ``` ALTER TABLE `table` ALTER COLUMN `column` SET DATA TYPE `data_type`; ```    We add a `NOT NULL` constraint to a column like so:    ``` ALTER TABLE `table` ALTER COLUMN `column` SET NOT NULL; ```    Note that in PostgreSQL and some other systems, adding a constraint to the table causes all rows to be checked to see whether they comply with the constraint. If the table has millions of rows, this could take a while.    Removing the `NOT NULL` constraint looks like this:    ``` ALTER TABLE `table` ALTER COLUMN `column` DROP NOT NULL; ```    When you execute `ALTER TABLE` with the placeholders filled in, you should see a message that reads `ALTER TABLE` in the pgAdmin output screen. If an operation violates a constraint or if you attempt to change a column’s data type and the existing values in the column won’t conform to the new data type, PostgreSQL returns an error. But PostgreSQL won’t give you any warning about deleting data when you drop a column, so use extra caution before dropping a column.    ### Modifying Values with UPDATE    The `UPDATE` statement, part of the ANSI SQL standard, modifies the data in a column that meets a condition. It can be applied to all rows or a subset of rows. Its basic syntax for updating the data in every row in a column follows this form:    ``` UPDATE `table`  SET `column` = `value`; ```    We first pass `UPDATE` the name of the table. Then to `SET` we pass the column we want to update. The new `value` to place in the column can be a string, number, the name of another column, or even a query or expression that generates a value. The new value must be compatible with the column data type.    We can update values in multiple columns by adding additional columns and source values and separating each with a comma:    ``` UPDATE `table`  SET `column_a` = `value`,   `column_b` = `value`; ```    To restrict the update to particular rows, we add a `WHERE` clause with some criteria that must be met before the update can happen, such as rows where values equal a date or match a string:    ``` UPDATE `table`  SET `column` = `value`  WHERE `criteria`; ```    We can also update one table with values from another table. Standard ANSI SQL requires that we use a *subquery*, a query inside a query, to specify which values and rows to update:    ``` UPDATE `table`  SET `column` = (SELECT `column`                FROM `table_b`                WHERE `table.column` = `table_b.column`)  WHERE EXISTS (SELECT `column`                FROM `table_b`                WHERE `table.column` = `table_b.column`); ```    The value portion of `SET`, inside the parentheses, is a subquery. A `SELECT` statement inside parentheses generates the values for the update by joining columns in both tables on matching row values. Similarly, the `WHERE EXISTS` clause uses a `SELECT` statement to ensure that we only update rows where both tables have matching values. If we didn’t use `WHERE EXISTS`, we might inadvertently set some values to `NULL` without planning to. (If this syntax looks somewhat complicated, that’s okay. I’ll cover subqueries in detail in Chapter 13.)    Some database managers offer additional syntax for updating across tables. PostgreSQL supports the ANSI standard but also a simpler syntax using a `FROM` clause:    ``` UPDATE `table`  SET `column` = `table_b.column`  FROM `table_b`  WHERE `table.column = table_b.column`; ```    When you execute an `UPDATE` statement, you’ll get a message stating `UPDATE` along with the number of rows affected.    ### Viewing Modified Data with RETURNING    If you add an optional `RETURNING` clause to `UPDATE`, you can view the values that were modified without having to run a second, separate query. The syntax of the clause uses the `RETURNING` keyword followed by a list of columns or a wildcard in the same manner that we name columns following `SELECT`. Here’s an example:    ``` UPDATE `table`  SET `column_a` = `value`  RETURNING `column_a`, `column_b`, `column_c`; ```    Instead of just noting the number of rows modified, `RETURNING` directs the database to show the columns you specify for the rows modified. This is a PostgreSQL-specific implementation that you also can use with `INSERT` and `DELETE FROM`. We’ll try it with some of our examples.    ### Creating Backup Tables    Before modifying a table, it’s a good idea to make a copy for reference and backup in case you accidentally destroy some data. [Listing 10-8](#listing10-8) shows how to use a variation of the familiar `CREATE TABLE` statement to make a new table from the table we want to duplicate.    ``` CREATE TABLE meat_poultry_egg_establishments_backup AS  SELECT * FROM meat_poultry_egg_establishments; ```    Listing 10-8: Backing up a table    The result should be a pristine copy of your table with the new specified name. You can confirm this by counting the number of records in both tables at once:    ``` SELECT      (SELECT count(*) FROM meat_poultry_egg_establishments) AS original,      (SELECT count(*) FROM meat_poultry_egg_establishments_backup) AS backup; ```    The results should return the same count from both tables, like this:    ``` original    backup  --------    ------      6287      6287 ```    If the counts match, you can be sure your backup table is an exact copy of the structure and contents of the original table. As an added measure and for easy reference, we’ll use `ALTER TABLE` to make copies of column data within the table we’re updating.    ### Restoring Missing Column Values    The query in [Listing 10-4](#listing10-4) earlier revealed that three rows in the `meat_poultry_egg_establishments` table don’t have a value in the `st` column:    ``` est_number           company                            city      st    zip  -----------------    -------------------------------    ------    --    -----  V18677A              Atlas Inspection, Inc.             Blaine          55449  M45319+P45319        Hall-Namie Packing Company, Inc                    36671  M263A+P263A+V263A    Jones Dairy Farm                                   53538 ```    To get a complete count of establishments in each state, we need to fill those missing values using an `UPDATE` statement.    #### Creating a Column Copy    Even though we’ve backed up this table, let’s take extra caution and make a copy of the `st` column within the table so we still have the original data if we make some dire error somewhere. Let’s create the copy and fill it with the existing `st` column values as in [Listing 10-9](#listing10-9).    ``` 1 ALTER TABLE meat_poultry_egg_establishments ADD COLUMN st_copy text;    UPDATE meat_poultry_egg_establishments  2 SET st_copy = st; ```    Listing 10-9: Creating and filling the `st_copy` column with `ALTER TABLE` and `UPDATE`    The `ALTER TABLE` statement 1 adds a column called `st_copy` using the same `text` data type as the original `st` column. Next, the `SET` clause 2 in `UPDATE` fills our new `st_copy` column with the values in column `st`. Because we don’t specify any criteria using `WHERE`, values in every row are updated, and PostgreSQL returns the message `UPDATE 6287`. Again, it’s worth noting that on a very large table, this operation could take some time and also substantially increase the table’s size. Making a column copy in addition to a table backup isn’t entirely necessary, but if you’re the patient, cautious type, it can be worthwhile.    We can confirm the values were copied properly with a simple `SELECT` query on both columns, as in [Listing 10-10](#listing10-10).    ``` SELECT st,         st_copy  FROM meat_poultry_egg_establishments  WHERE st IS DISTINCT FROM st_copy  ORDER BY st; ```    Listing 10-10: Checking values in the `st` and `st_copy` columns    To check for differences between values in the columns, we use `IS DISTINCT FROM` in the `WHERE` clause. You’ve used `DISTINCT` before to find unique values in a column (Chapter 3); in this context, `IS DISTINCT FROM` tests whether values in `st` and `st_copy` are different. This keeps us from having to scan every row ourselves. Running this query will return zero rows, meaning the values match throughout the table.    Now, with our original data safely stored, we can update the three rows with missing state codes. This is now our in-table backup, so if something goes drastically wrong while we’re updating the original column, we can easily copy the original data back in. I’ll show you how after we apply the first updates.    #### Updating Rows Where Values Are Missing    To update those rows’ missing values, we first find the values we need with a quick online search: Atlas Inspection is located in Minnesota; Hall-Namie Packing is in Alabama; and Jones Dairy is in Wisconsin. We add those states to the appropriate rows in [Listing 10-11](#listing10-11).    ``` UPDATE meat_poultry_egg_establishments  SET st = 'MN'  1 WHERE establishment_number = 'V18677A';    UPDATE meat_poultry_egg_establishments  SET st = 'AL'  WHERE establishment_number = 'M45319+P45319';    UPDATE meat_poultry_egg_establishments  SET st = 'WI'  WHERE establishment_number = 'M263A+P263A+V263A'  2 RETURNING establishment_number, company, city, st, zip; ```    Listing 10-11: Updating the `st` column for three establishments    Because we want each `UPDATE` statement to affect a single row, we include a `WHERE` clause 1 for each that identifies the company’s unique `establishment_number`, which is the table’s primary key. When we run the first two queries, PostgreSQL responds with the message `UPDATE 1`, showing that only one row was updated for each query. When we run the third, the `RETURNING` clause 2 directs the database to show several columns from the row that was updated:    ``` establishment_number   company           city      st    zip  --------------------   ----------------  --------  --    -----  M263A+P263A+V263A      Jones Dairy Farm            WI    53538 ```    If we rerun the code in [Listing 10-4](#listing10-4) to find rows where `st` is `NULL`, the query should return nothing. Success! Our count of establishments by state is now complete.    #### Restoring Original Values    What happens if we botch an update by providing the wrong values or updating the wrong rows? We’ll just copy the data back from either the full table backup or the column backup. [Listing 10-12](#listing10-12) shows the two options.    ``` 1 UPDATE meat_poultry_egg_establishments  SET st = st_copy;    2 UPDATE meat_poultry_egg_establishments original  SET st = backup.st  FROM meat_poultry_egg_establishments_backup backup  WHERE original.establishment_number = backup.establishment_number; ```    Listing 10-12: Restoring original `st` column values    To restore the values from the backup column in `meat_poultry_egg_establishments`, run an `UPDATE` query 1 that sets `st` to the values in `st_copy`. Both columns should again have the identical original values. Alternatively, you can create an `UPDATE` 2 that sets `st` to values in the `st` column from the `meat_poultry_egg_establishments_backup` table you made in [Listing 10-8](#listing10-8). This will obviate the fixes you made to add missing state values, so if you want to try this query, you’ll need to redo the fixes using [Listing 10-11](#listing10-11).    ### Updating Values for Consistency    In [Listing 10-5](#listing10-5), we discovered several cases where a single company’s name was entered inconsistently. These inconsistencies will hinder us if we want to aggregate data by company name, so we’ll fix them.    Here are the spelling variations of Armour-Eckrich Meats in [Listing 10-5](#listing10-5):    ``` `--snip--`  Armour - Eckrich Meats, LLC  Armour-Eckrich Meats LLC  Armour-Eckrich Meats, Inc.  Armour-Eckrich Meats, LLC  `--snip--` ```    We can standardize the spelling using an `UPDATE` statement. To protect our data, we’ll create a new column for the standardized spellings, copy the names in `company` into the new column, and work in the new column. [Listing 10-13](#listing10-13) has the code for both actions.    ``` ALTER TABLE meat_poultry_egg_establishments ADD COLUMN company_standard text;    UPDATE meat_poultry_egg_establishments  SET company_standard = company; ```    Listing 10-13: Creating and filling the `company_standard` column    Now, let’s say we want any name in `company` that starts with the string `Armour` to appear in `company_standard` as `Armour-Eckrich Meats`. (This assumes we’ve checked all Armour entries and want to standardize them.) With [Listing 10-14](#listing10-14), we can update all the rows matching the string `Armour` using `WHERE`.    ``` UPDATE meat_poultry_egg_establishments  SET company_standard = 'Armour-Eckrich Meats'  1 WHERE company LIKE 'Armour%'  2 RETURNING company, company_standard; ```    Listing 10-14: Using an `UPDATE` statement to modify column values that match a string    The important piece of this query is the `WHERE` clause that uses the `LIKE` keyword 1 for case-sensitive pattern matching introduced in Chapter 3. Including the wildcard syntax `%` at the end of the string `Armour` updates all rows that start with those characters regardless of what comes after them. The clause lets us target all the varied spellings used for the company’s name. The `RETURNING` clause 2 causes the statement to provide the results of the updated `company_standard` column next to the original `company` column:    ``` company                        company_standard  ---------------------------    --------------------  Armour-Eckrich Meats LLC       Armour-Eckrich Meats  Armour - Eckrich Meats, LLC    Armour-Eckrich Meats  Armour-Eckrich Meats LLC       Armour-Eckrich Meats  Armour-Eckrich Meats LLC       Armour-Eckrich Meats  Armour-Eckrich Meats, Inc.     Armour-Eckrich Meats  Armour-Eckrich Meats, LLC      Armour-Eckrich Meats  Armour-Eckrich Meats, LLC      Armour-Eckrich Meats ```    The values for Armour-Eckrich in `company_standard` are now standardized with consistent spelling. To standardize other company names in the table, we would create an `UPDATE` statement for each case. We would also keep the original `company` column for reference.    ### Repairing ZIP Codes Using Concatenation    Our final fix repairs values in the `zip` column that lost leading zeros. Zip codes in Puerto Rico and the US Virgin Islands begin with two zeros, so we need to restore two leading zeros to the values in `zip`. For the other states, located mostly in New England, we’ll restore a single leading zero.    We’ll use `UPDATE` in conjunction with the double-pipe *string concatenation operator* (`||`). Concatenation combines two string values into one (it will also combine a string and a number into a string). For example, inserting `||` between the strings `abc` and `xyz` results in `abcxyz`. The double-pipe operator is a SQL standard for concatenation supported by PostgreSQL. You can use it in many contexts, such as `UPDATE` queries and `SELECT`, to provide custom output from existing as well as new data.    First, [Listing 10-15](#listing10-15) makes a backup copy of the `zip` column as we did earlier.    ``` ALTER TABLE meat_poultry_egg_establishments ADD COLUMN zip_copy text;    UPDATE meat_poultry_egg_establishments  SET zip_copy = zip; ```    Listing 10-15: Creating and filling the `zip_copy` column    Next, we use the code in [Listing 10-16](#listing10-16) to perform the first update.    ``` UPDATE meat_poultry_egg_establishments  1 SET zip = '00' || zip  2 WHERE st IN('PR','VI') AND length(zip) = 3; ```    Listing 10-16: Modifying codes in the `zip` column missing two leading zeros    We use `SET` to set the value in the `zip` column 1 to the result of the concatenation of `00` and the existing value. We limit the `UPDATE` to only those rows where the `st` column has the state codes `PR` and `VI` 2 using the `IN` comparison operator from Chapter 3 and add a test for rows where the length of `zip` is `3`. This entire statement will then only update the `zip` values for Puerto Rico and the Virgin Islands. Run the query; PostgreSQL should return the message `UPDATE 86`, which is the number of rows we expect to change based on our earlier count in [Listing 10-6](#listing10-6).    Let’s repair the remaining ZIP codes using a similar query in [Listing 10-17](#listing10-17).    ``` UPDATE meat_poultry_egg_establishments  SET zip = '0' || zip  WHERE st IN('CT','MA','ME','NH','NJ','RI','VT') AND length(zip) = 4; ```    Listing 10-17: Modifying codes in the `zip` column missing one leading zero    PostgreSQL should return the message `UPDATE 496`. Now, let’s check our progress. Earlier in [Listing 10-6](#listing10-6), when we aggregated rows in the `zip` column by length, we found `86` rows with three characters and `496` with four.    Using the same query now returns a more desirable result: all the rows have a five-digit ZIP code.    ``` length    count  ------    -----       5     6287 ```    I’ll discuss additional string functions in Chapter 14 when we consider advanced techniques for working with text.    ### Updating Values Across Tables    In “Modifying Values with UPDATE” earlier in the chapter, I showed the standard ANSI SQL and PostgreSQL-specific syntax for updating values in one table based on values in another. This syntax is particularly valuable in a relational database where primary keys and foreign keys establish table relationships. In those cases, we may need information in one table to update values in another table.    Let’s say we’re setting an inspection deadline for each of the companies in our table. We want to do this by US regions, such as Northeast, Pacific, and so on, but those regional designations don’t exist in our table. However, they *do* exist in the file *state_regions.csv*, included with the book’s resources, that contains matching `st` state codes. Once we load that file into a table, we can use that data in an `UPDATE` statement. Let’s begin with the New England region to see how this works.    Enter the code in [Listing 10-18](#listing10-18), which contains the SQL statements to create a `state_regions` table and fill the table with data:    ``` CREATE TABLE state_regions (      st text CONSTRAINT st_key PRIMARY KEY,      region text NOT NULL  );    COPY state_regions  FROM '`C:\\YourDirectory\\`state_regions.csv'  WITH (FORMAT CSV, HEADER); ```    Listing 10-18: Creating and filling a `state_regions` table    We’ll create two columns in a `state_regions` table: one containing the two-character state code `st` and the other containing the `region` name. We set the primary key constraint to the `st` column, which holds a unique `st_key` value to identify each state. In the data you’re importing, each state is present and assigned to a census region, and territories outside the United States are labeled as outlying areas. We’ll update the table one region at a time.    Next, let’s return to the `meat_poultry_egg_establishments` table, add a column for inspection dates, and then fill in that column with the New England states. [Listing 10-19](#listing10-19) shows the code.    ``` ALTER TABLE meat_poultry_egg_establishments      ADD COLUMN inspection_deadline timestamp with time zone;    1 UPDATE meat_poultry_egg_establishments establishments  2 SET inspection_deadline = '2022-12-01 00:00 EST'  3 WHERE EXISTS (SELECT state_regions.region                FROM state_regions                WHERE establishments.st = state_regions.st                      AND state_regions.region = 'New England'); ```    Listing 10-19: Adding and updating an `inspection_deadline` column    The `ALTER TABLE` statement creates the `inspection_deadline` column in the `meat_poultry_egg_establishments` table. In the `UPDATE` statement, we give the table an alias of `establishments` to make the code easier to read 1 (and do so omitting the optional `AS` keyword). Next, `SET` assigns a timestamp value of `2022-12-01 00:00 EST` to the new `inspection_deadline` column 2. Finally, `WHERE EXISTS` includes a subquery that connects the `meat_poultry_egg_establishments` table to the `state_regions` table we created in [Listing 10-18](#listing10-18) and specifies which rows to update 3. The subquery (in parentheses, beginning with `SELECT`) looks for rows in the `state_regions` table where the `region` column matches the string `New England`. At the same time, it joins the `meat_poultry_egg_establishments` table with the `state_regions` table using the `st` column from both tables. In effect, the query is telling the database to find all the `st` codes that correspond to the New England region and use those codes to filter the update.    When you run the code, you should receive a message of `UPDATE 252`, which is the number of companies in New England states. You can use the code in [Listing 10-20](#listing10-20) to see the effect of the change.    ``` SELECT st, inspection_deadline  FROM meat_poultry_egg_establishments  GROUP BY st, inspection_deadline  ORDER BY st; ```    Listing 10-20: Viewing updated `inspection_date` values    The results should show the updated inspection deadlines for all New England companies. The top of the output shows Connecticut has received a deadline timestamp, for example, but states outside New England remain `NULL` because we haven’t updated them yet:    ``` st    inspection_deadline  --    ---------------------  `--snip--`  CA  CO  CT    2022-12-01 00:00:00-05  DC  `--snip--` ```    To fill in deadlines for additional regions, substitute a different region for `New England` in [Listing 10-19](#listing10-19) and rerun the query.    ## Deleting Unneeded Data    The most irrevocable way to modify data is to remove it entirely. SQL includes options to remove rows and columns along with options to delete an entire table or database. We want to perform these operations with caution, removing only data or tables we don’t need. Without a backup, your data is gone for good.    In this section, we’ll use a variety of SQL statements to delete data. If you didn’t back up the `meat_poultry_egg_establishments` table using [Listing 10-8](#listing10-8), now is a good time to do so.    Writing and executing these statements is fairly simple, but doing so comes with a caveat. If deleting rows, a column, or a table would cause a violation of a constraint, such as the foreign key constraint covered in Chapter 8, you need to deal with that constraint first. That might involve removing the constraint, deleting data in another table, or deleting another table. Each case is unique and will require a different way to work around the constraint.    ### Deleting Rows from a Table    To remove rows from a table, we can use either `DELETE FROM` or `TRUNCATE`, which are both part of the ANSI SQL standard. Each offers options that are useful depending on your goals.    Using `DELETE FROM`, we can remove all rows from a table, or we can add a `WHERE` clause to delete only the portion that matches an expression we supply. To delete all rows from a table, use the following syntax:    ``` DELETE FROM `table_name`; ```    To remove only selected rows, add a `WHERE` clause along with the matching value or pattern to specify which ones you want to delete:    ``` DELETE FROM `table_name` WHERE `expression`; ```    For example, to exclude US territories from our processors table, we can remove the companies in those locations using the code in [Listing 10-21](#listing10-21).    ``` DELETE FROM meat_poultry_egg_establishments  WHERE st IN('AS','GU','MP','PR','VI'); ```    Listing 10-21: Deleting rows matching an expression    Run the code; PostgreSQL should return the message `DELETE 105`. This means the 105 rows where the `st` column held any of the codes designating a territory that you supplied via the `IN` keyword have been removed from the table.    With large tables, using `DELETE FROM` to remove all rows can be inefficient because it scans the entire table as part of the process. In that case, you can use `TRUNCATE`, which skips the scan. To empty the table using `TRUNCATE`, use the following syntax:    ``` TRUNCATE `table_name`; ```    A handy feature of `TRUNCATE` is the ability to reset an `IDENTITY` sequence, such as one you may have created to serve as a surrogate primary key, as part of the operation. To do that, add the `RESTART IDENTITY` keywords to the statement:    ``` TRUNCATE `table_name` RESTART IDENTITY; ```    We’ll skip truncating any tables for now as we need the data for the rest of the chapter.    ### Deleting a Column from a Table    Earlier we created a backup `zip` column called `zip_copy`. Now that we’ve finished working on fixing the issues in `zip`, we no longer need `zip_copy`. We can remove the backup column, including all the data within the column, from the table using the `DROP` keyword in the `ALTER TABLE` statement.    The syntax for removing a column is similar to other `ALTER TABLE` statements:    ``` ALTER TABLE `table_name` DROP COLUMN `column_name`; ```    The code in [Listing 10-22](#listing10-22) removes the `zip_copy` column:    ``` ALTER TABLE meat_poultry_egg_establishments DROP COLUMN zip_copy; ```    Listing 10-22: Removing a column from a table using `DROP`    PostgreSQL returns the message `ALTER TABLE`, and the `zip_copy` column should be deleted. The database doesn’t actually rewrite the table to remove the column; it just marks the column as deleted in its internal catalog and no longer shows it or adds data to it when new rows are added.    ### Deleting a Table from a Database    The `DROP TABLE` statement is a standard ANSI SQL feature that deletes a table from the database. This statement might come in handy if, for example, you have a collection of backups, or *working tables*, that have outlived their usefulness. It’s also useful when you need to change the structure of a table significantly; in that case, rather than using too many `ALTER TABLE` statements, you can just remove the table and create a fresh one by running a new `CREATE TABLE` statement and re-importing the data.    The syntax for the `DROP TABLE` command is simple:    ``` DROP TABLE `table_name`; ```    For example, [Listing 10-23](#listing10-23) deletes the backup version of the `meat_poultry_egg_establishments` table.    ``` DROP TABLE meat_poultry_egg_establishments_backup; ```    Listing 10-23: Removing a table from a database using `DROP`    Run the query; PostgreSQL should respond with the message `DROP TABLE` to indicate the table has been removed.    ## Using Transactions to Save or Revert Changes    So far, our alterations in this chapter have been final. That is, after you run a `DELETE` or `UPDATE` query (or any other query that alters your data or database structure), the only way to undo the change is to restore from a backup. However, there is a way to check your changes before finalizing them and cancel the change if it’s not what you intended. You do this by enclosing the SQL statement within a *transaction*, which includes keywords that allow you to commit your changes if they are successful or roll them back if not. You define a transaction using the following keywords at the beginning and end of the query:    1.  `START TRANSACTION` Signals the start of the transaction block. In PostgreSQL, you can also use the non-ANSI SQL `BEGIN` keyword. 2.  `COMMIT` Signals the end of the block and saves all changes. 3.  `ROLLBACK` Signals the end of the block and reverts all changes.    You can include multiple statements between `BEGIN` and `COMMIT` to define a sequence of operations that perform one unit of work in a database. An example is when you buy concert tickets, which might involve two steps: charging your credit card and reserving your seats so someone else can’t buy them. A database programmer would want either both steps in the transaction to happen (say, when your card charge goes through) or neither to happen (if you cancel at checkout). Defining both steps as one transaction—also called a *transaction block*—keeps them as a unit; if one step is canceled or throws an error, the other gets canceled too. You can learn more details about transactions and PostgreSQL at [https://www.postgresql.org/docs/current/tutorial-transactions.html](https://www.postgresql.org/docs/current/tutorial-transactions.html).    We can use a transaction block to review changes a query makes and then decide whether to keep or discard them. In our table, let’s say we’re cleaning dirty data related to the company AGRO Merchants Oakland LLC. The table has three rows listing the company, but one row has an extra comma in the name:    ``` Company  ---------------------------  AGRO Merchants Oakland LLC  AGRO Merchants Oakland LLC  AGRO Merchants Oakland, LLC ```    We want the name to be consistent, so we’ll remove the comma from the third row using an `UPDATE` query, as we did earlier. But this time we’ll check the result of our update before we make it final (and we’ll purposely make a mistake we want to discard). [Listing 10-24](#listing10-24) shows how to do this using a transaction block.    ``` 1 START TRANSACTION;    UPDATE meat_poultry_egg_establishments  2 SET company = 'AGRO Merchantss Oakland LLC'  WHERE company = 'AGRO Merchants Oakland, LLC';    3 SELECT company  FROM meat_poultry_egg_establishments  WHERE company LIKE 'AGRO%'  ORDER BY company;    4 ROLLBACK; ```    Listing 10-24: Demonstrating a transaction block    Beginning with `START TRANSACTION;` 1, we’ll run each statement separately. The database responds with the message `START TRANSACTION`, letting you know that any succeeding changes you make to data will not be made permanent unless you issue a `COMMIT` command. Next, we run the `UPDATE` statement, which changes the company name in the row where it has an extra comma. I intentionally added an extra `s` in the name used in the `SET` clause 2 to introduce a mistake.    When we view the names of companies starting with the letters `AGRO` using the `SELECT` statement 3, we see that, oops, one company name is misspelled now.    ``` Company  ---------------------------  AGRO Merchants Oakland LLC  AGRO Merchants Oakland LLC  AGRO Merchantss Oakland LLC ```    Instead of rerunning the `UPDATE` statement to fix the typo, we can simply discard the change by running the `ROLLBACK;` 4 command. When we rerun the `SELECT` statement to view the company names, we’re back to where we started:    ``` Company  ---------------------------  AGRO Merchants Oakland LLC  AGRO Merchants Oakland LLC  AGRO Merchants Oakland, LLC ```    From here, you correct your `UPDATE` statement by removing the extra `s` and rerun it, beginning with the `START TRANSACTION` statement again. If you’re happy with the changes, run `COMMIT;` to make them permanent.    Transaction blocks are often used for more complex situations rather than checking simple changes. Here you’ve used them to test whether a query behaves as desired, saving you time and headaches. Next, let’s look at another way to save time when updating lots of data.    ## Improving Performance When Updating Large Tables    With PostgreSQL, adding a column to a table and filling it with values can quickly inflate the table’s size because the database creates a new version of the existing row each time a value is updated, but it doesn’t delete the old row version. That essentially doubles the table’s size. (You’ll learn how to clean up these old rows when I discuss database maintenance in “Recovering Unused Space with VACUUM” in Chapter 19.) For small datasets, the increase is negligible, but for tables with hundreds of thousands or millions of rows, the time required to update rows and the resulting extra disk usage can be substantial.    Instead of adding a column and filling it with values, we can save disk space by copying the entire table and adding a populated column during the operation. Then, we rename the tables so the copy replaces the original, and the original becomes a backup. Thus, we have a fresh table without the added old rows.    [Listing 10-25](#listing10-25) shows how to copy `meat_poultry_egg_establishments` into a new table while adding a populated column. To do this, if you didn’t already drop the `meat_poultry_egg_establishments_backup` table as shown in [Listing 10-23](#listing10-23), go ahead and drop it. Then run the `CREATE TABLE` statement.    ``` CREATE TABLE meat_poultry_egg_establishments_backup AS  1 SELECT *,        2 '2023-02-14 00:00 EST'::timestamp with time zone AS reviewed_date  FROM meat_poultry_egg_establishments; ```    Listing 10-25: Backing up a table while adding and filling a new column    The query is a modified version of the backup script in [Listing 10-8](#listing10-8). Here, in addition to selecting all the columns using the asterisk wildcard 1, we also add a column called `reviewed_date` by providing a value cast as a `timestamp` data type 2 and the `AS` keyword. That syntax adds and fills `reviewed_date`, which we might use to track the last time we checked the status of each plant.    Then we use [Listing 10-26](#listing10-26) to swap the table names.    ``` 1 ALTER TABLE meat_poultry_egg_establishments      RENAME TO meat_poultry_egg_establishments_temp;  2 ALTER TABLE meat_poultry_egg_establishments_backup      RENAME TO meat_poultry_egg_establishments;  3 ALTER TABLE meat_poultry_egg_establishments_temp      RENAME TO meat_poultry_egg_establishments_backup; ```    Listing 10-26: Swapping table names using `ALTER TABLE`    Here we use `ALTER TABLE` with a `RENAME TO` clause to change a table name. The first statement changes the original table name to one that ends with `_temp` 1. The second statement renames the copy we made with [Listing 10-24](#listing10-24) to the original name of the table 2. Finally, we rename the table that ends with `_temp` to the ending `_backup` 3. The original table is now called `meat_poultry_egg_establishments_backup`, and the copy with the added column is called `meat_poultry_egg_establishments`. This process avoids updating rows and thus inflating the table.    ## Wrapping Up    Gleaning useful information from data sometimes requires modifying the data to remove inconsistencies, fix errors, and make it more suitable for supporting an accurate analysis. In this chapter you learned some useful tools to help you assess dirty data and clean it up. In a perfect world, all datasets would arrive with everything clean and complete. But such a perfect world doesn’t exist, so the ability to alter, update, and delete data is indispensable.    Let me restate the important tasks of working safely. Be sure to back up your tables before you start making changes. Make copies of your columns, too, for an extra level of protection. When I discuss database maintenance for PostgreSQL later in the book, you’ll learn how to back up entire databases. These few steps of precaution will save you a world of pain.    In the next chapter, we’ll return to math to explore some of SQL’s advanced statistical functions and techniques for analysis.````"]