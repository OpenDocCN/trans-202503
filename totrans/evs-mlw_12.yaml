- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_B_11">9</samp> <samp class="SANS_Dogma_OT_Bold_B_11">ANTI-DISASSEMBLY</samp>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/opener.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Because disassemblers break down binary files into assembly code based on their
    own (often very complex) algorithms, there’s some room for error. Malware authors
    are aware of this vulnerability and can actively exploit it. They may also attempt
    to obfuscate the malware’s control flow or string and API function call references,
    making the code especially difficult to navigate statically. These are examples
    of *anti-disassembly* techniques, or ways in which malware complicates the process
    of reverse engineering code with a disassembler. In this chapter, we’ll look at
    these tactics in depth and what malware analysts can do to address them.
  prefs: []
  type: TYPE_NORMAL
- en: '### <samp class="SANS_Futura_Std_Bold_B_11">Breaking Disassemblers</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: Disassemblers interpret a file based on their own hardcoded logic and assumptions,
    which means that they can interpret bytes in different and sometimes problematic
    ways. Code could be incorrectly disassembled into data, or vice versa, and bytes
    might be added to the wrong instructions, producing completely new and erroneous
    instructions.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, the bytes <samp class="SANS_TheSansMonoCd_W5Regular_11">e8 8c
    45 0a 90</samp> can be dissembled into a call instruction. Removing the first
    byte (<samp class="SANS_TheSansMonoCd_W5Regular_11">e8</samp>) would result in
    a completely different disassembled instruction. In this common anti-disassembly
    approach, known as the *rogue byte* technique, rogue bytes are inserted into the
    malware to confuse the disassembly process. Consider, for example, the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here you can see several disassembled instructions in the right column, the
    bytes that make up those instructions in the middle column, and the address offset
    in the left column. These disassembled instructions don’t make much sense. For
    example, there’s a jump-if-zero (<samp class="SANS_TheSansMonoCd_W5Regular_11">jz</samp>)
    instruction with a target of <samp class="SANS_TheSansMonoCd_W5Regular_11">loc_402109</samp>
    <samp class="SANS_TheSansMonoCd_W5Regular_11">+ 1</samp>. This jump will always
    occur because the <samp class="SANS_TheSansMonoCd_W5Regular_11">mov</samp> instruction
    prior to the <samp class="SANS_TheSansMonoCd_W5Regular_11">jz</samp> instruction
    sets <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp> to <samp class="SANS_TheSansMonoCd_W5Regular_11">0</samp>,
    but the code jumps to the *second* byte of the next instruction (byte <samp class="SANS_TheSansMonoCd_W5Regular_11">8b</samp>).
    The code also includes a call instruction to an address that doesn’t even exist
    in this executable, since our executable is in the <samp class="SANS_TheSansMonoCd_W5Regular_11">0x00402xxx</samp>
    address range, not the <samp class="SANS_TheSansMonoCd_W5Regular_11">0x900xxxxx</samp>
    range. Let’s take a closer look.
  prefs: []
  type: TYPE_NORMAL
- en: 'As [Chapter 3](chapter3.xhtml) explained, a disassembler doesn’t always know
    how to differentiate code from data. This means that when it converts bytes to
    code, that code may in reality be data, or vice versa. The bytes that make up
    the <samp class="SANS_TheSansMonoCd_W5Regular_11">call 0x900a4590</samp> instruction
    are <samp class="SANS_TheSansMonoCd_W5Regular_11">e8 8b 45 0a 90</samp>. The first
    byte, <samp class="SANS_TheSansMonoCd_W5Regular_11">e8</samp>, represents the
    call instruction in the x86 assembly instruction set. If we take out this byte,
    we’re left with <samp class="SANS_TheSansMonoCd_W5Regular_11">8b 45 0a 90</samp>.
    This series of bytes in x86 assembly is equivalent to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here we have a <samp class="SANS_TheSansMonoCd_W5Regular_11">mov</samp> instruction
    (to move the value stored on the stack at <samp class="SANS_TheSansMonoCd_W5Regular_11">ebp+10</samp>
    to <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp>), followed by a <samp
    class="SANS_TheSansMonoCd_W5Regular_11">nop</samp> instruction. This code makes
    a lot more sense than our original call instruction (<samp class="SANS_TheSansMonoCd_W5Regular_11">call
    0x900a4590</samp>). Thus, it seems that the first byte (<samp class="SANS_TheSansMonoCd_W5Regular_11">e8</samp>)
    is a rogue byte, added to the code simply to confuse disassemblers.
  prefs: []
  type: TYPE_NORMAL
- en: You can deal with this by overriding incorrect code or data. In IDA, you can
    hit the C and D keys (C for converting data to code and D for converting code
    to data). In Ghidra, it’s the opposite, confusingly enough; press C for converting
    code to data (C stands for “clear code bytes,” in this case) and D for converting
    data to code (D stands for “disassemble”).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you select the bogus call instruction in IDA and press D, the instruction
    is broken into data, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that what once was code is now data bytes, starting at ❶. Now, if you
    select the byte values starting at offset <samp class="SANS_TheSansMonoCd_W5Regular_11">0040210A</samp>
    (taking care not to select the <samp class="SANS_TheSansMonoCd_W5Regular_11">e8</samp>
    byte) and continuing until <samp class="SANS_TheSansMonoCd_W5Regular_11">0040210D</samp>,
    then press C to convert this to code, you get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The malware moves <samp class="SANS_TheSansMonoCd_W5Regular_11">0x00</samp>
    into <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp> (in order to zero-out
    <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp>) and then uses a condition
    jump (<samp class="SANS_TheSansMonoCd_W5Regular_11">jz</samp>); as noted earlier,
    the code will always take this jump. However, now the code jumps right over the
    rogue byte (<samp class="SANS_TheSansMonoCd_W5Regular_11">e8</samp>) and executes
    the <samp class="SANS_TheSansMonoCd_W5Regular_11">mov</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">nop</samp>
    instructions instead. This malware sample cleverly inserted the rogue byte in
    order to trick the disassembler into thinking that it was part of the original
    call instruction!
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a fairly simple example of an anti-disassembly method, but it’s a common
    one. This presents a challenge for both disassemblers and reverse engineers. When
    you encounter situations like this, in which code is simply incorrect or doesn’t
    make sense, try manually converting the code to data bytes or some of the bytes
    into code. It may help you fix up the code so that you can better understand it.  ###
    <samp class="SANS_Futura_Std_Bold_B_11">Control Flow Obfuscation</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The next anti-disassembly method we’ll look at is *control flow obfuscation*,
    or adding unnecessary complexity to the malware code, making it much more difficult
    to analyze statically. This type of obfuscation can also flummox disassemblers,
    which may fail to properly disassemble the code.
  prefs: []
  type: TYPE_NORMAL
- en: To add this type of obfuscation, malware authors use specialized code obfuscators
    designed specifically for this purpose or malware packers, which we’ll discuss
    in detail in [Chapter 17](chapter17.xhtml). Let’s dig into some of the common
    methods used to obfuscate control flow. At the end of this section, we’ll discuss
    a few general strategies to deal with these tactics.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Unnecessary Jumps</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Malware authors may add unnecessary jump statements to break up the malware’s
    code into smaller blocks (see [Figure 9-1](chapter9.xhtml#fig9-1)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig9-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-1: Unnecessary jump
    instructions</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The code in [Figure 9-1](chapter9.xhtml#fig9-1) was once a single block, but
    an obfuscator has broken it into chunks, with each block connecting to the next
    with a jump statement. Functionally, the code is the same, but now reverse engineers
    will have more difficulty understanding and following it. This example is quite
    basic, but obfuscators can add a nearly infinite amount of complexity to code,
    as you’ll see in the next few sections.
  prefs: []
  type: TYPE_NORMAL
- en: 'Obfuscators can also make code jump forward and backward frequently in order
    to make it harder to follow sequentially, as in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This code jumps around to different areas simply for the sake of confusion.
    It first jumps to <samp class="SANS_TheSansMonoCd_W5Regular_11">loc_402B20</samp>,
    then back up to <samp class="SANS_TheSansMonoCd_W5Regular_11">loc_402A30</samp>,
    and then back down to <samp class="SANS_TheSansMonoCd_W5Regular_11">loc_402B65</samp>,
    creating a hard-to-follow code flow logic.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Unnecessary Code</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Malware authors can add other types of unnecessary code to their malware. For
    example, they might create copies of code blocks or functions that are effectively
    the same, or at least very similar, so that the code can then be executed interchangeably,
    leading to the same final block of code, as shown in [Figure 9-2](chapter9.xhtml#fig9-2).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig9-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-2: Interchangeable
    code blocks</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: This doesn’t affect the malware’s behavior but creates complexity for reverse
    engineers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, malware authors and obfuscators can add dummy code that will
    never be executed and exists only to confuse analysts, waste CPU cycles, and slow
    down the analysis process. This code could be anything, so it’s difficult to provide
    concrete examples of what it might look like, but this snippet demonstrates the
    technique:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This code is simply incrementing the <samp class="SANS_TheSansMonoCd_W5Regular_11">ecx</samp>
    register by 1, pushing this value to the stack, decrementing it by 1, and then
    pushing that value to the stack. It quite obviously serves no valid purpose.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Control Flow Flattening</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Control flow flattening* is a method of obfuscating control flow by compressing
    a sequence of conditional code blocks into a single block. This is usually accomplished
    via switch statements that direct control flow. [Figure 9-3](chapter9.xhtml#fig9-3)
    shows a program before control flattening has occurred.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig9-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-3: A program before
    control flow flattening is applied</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: This program represents normal, unobfuscated code. In the code block labeled
    ❶, there’s a conditional statement that will jump to one of two locations (code
    block ❷ or ❸). If this program were run through a control flow–flattening algorithm,
    it might end up looking more like [Figure 9-4](chapter9.xhtml#fig9-4).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig9-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-4: A program after
    control flow flattening is applied</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 9-3](chapter9.xhtml#fig9-3), code block ❶ was responsible for the
    conditional statement that led to the jump to either code block ❷ or ❸. In the
    flattened code, a *central dispatch* code block ❶ is responsible for the conditional
    statement but also keeps track of where the code should “flow” next. After the
    dispatcher directs the control flow to a block of code, control is returned to
    the dispatcher, which directs the control flow further. The dispatcher adds complexity
    to the disassembled code, making it more difficult for an analyst to understand
    its purpose and where execution will flow next.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Opaque Predicates</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An *opaque predicate* (see [Figure 9-5](chapter9.xhtml#fig9-5)) is a value that
    is known to the program’s author but not to the program or disassembler at runtime.
    The program’s creator (in our case, the malware author) knows that a certain expression
    will result in a specific value, for example, but neither we as reverse engineers
    nor our disassembler tools know this.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig9-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-5: An opaque predicate
    in action</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: This code can take one of two paths, determined by the expression <samp class="SANS_TheSansMonoCd_W5Regular_11">1</samp>
    <samp class="SANS_TheSansMonoCd_W5Regular_11">==</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11">2</samp>
    (the opaque predicate). The malware author already knows that the program will
    take the branch to the right, but the analyst and the disassembler must manually
    analyze the logic to learn this. Obviously, this is a simplified example that
    almost anyone could decipher. However, malware authors can make an opaque predicate
    infinitely complex, for example, by calculating complicated mathematical functions
    at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: This technique can also be combined with those previously mentioned, such as
    adding unnecessary code. The malware author could include a large amount of garbage
    code in the left branch that will never be executed. The reverse engineer must
    understand the opaque predicate before analyzing the rest of the program to avoid
    wasting time on the garbage code. Opaque predicates are difficult to deal with
    and, as mentioned, can be as basic or complex as the malware author wishes. Often
    the best way to deal with them is to step through the malware in a debugger that
    will help reveal the true control flow.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Return Pointer Abuse</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Another way to obfuscate control flow is with return (<samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp>)
    instructions. For example, if a program executes Function B, once it reaches the
    end of that function, Function B will issue a <samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp>
    instruction to return to its parent function (Function A). Before Function B can
    return, though, the program needs to know where to return to. Therefore, the return
    address is pushed to the stack before Function B executes and is popped off the
    stack once the <samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp> instruction
    is executed. The following assembly code demonstrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This code issues a <samp class="SANS_TheSansMonoCd_W5Regular_11">push</samp>
    instruction to push <samp class="SANS_TheSansMonoCd_W5Regular_11">returnAddress</samp>
    and then executes the <samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp>
    instruction, which will pop <samp class="SANS_TheSansMonoCd_W5Regular_11">returnAddress</samp>
    off the stack to return the program’s control flow to the parent function.
  prefs: []
  type: TYPE_NORMAL
- en: Malware can abuse the way return pointers work to replicate a <samp class="SANS_TheSansMonoCd_W5Regular_11">call</samp>
    or <samp class="SANS_TheSansMonoCd_W5Regular_11">jmp</samp> instruction. By pushing
    an address to the stack and then executing a <samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp>
    instruction, the malware will force the control flow to execute the code at the
    new return address. This can confuse some disassemblers and generally makes following
    the code more difficult for the analyst as well.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">SEH Handler Abuse</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Malware can also take advantage of the *structured exception handler (SEH)*,
    which stores a series of addresses for the pieces of code responsible for handling
    exceptions in Windows applications. When the application raises an exception,
    its control flow transfers to one of the addresses stored in the SEH.
  prefs: []
  type: TYPE_NORMAL
- en: 'Malware can abuse the SEH by creating a new exception handler that points to
    malicious code. When the malware purposefully causes an exception in its code,
    the control flow will be transferred to code referenced in the exception handler.
    As a result, the analyst will need to know where the malware established the exception
    handler, as well as where the exception handler is pointing, in order to properly
    reverse engineer the code. Consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The focus of this code block is <samp class="SANS_TheSansMonoCd_W5Regular_11">fs:[0]</samp>,
    which essentially points to the current exception handler. The malware replaces
    the default exception handler code with a pointer to malicious code (<samp class="SANS_TheSansMonoCd_W5Regular_11">evil.429D8C</samp>).
    Once the malware triggers an exception, the code’s control flow will be transferred
    to the address <samp class="SANS_TheSansMonoCd_W5Regular_11">evil.429D8C</samp>.
    As there are no <samp class="SANS_TheSansMonoCd_W5Regular_11">jmp</samp>, <samp
    class="SANS_TheSansMonoCd_W5Regular_11">ret</samp>, or <samp class="SANS_TheSansMonoCd_W5Regular_11">call</samp>
    instructions in use here, this control flow transfer can be difficult for the
    untrained eye to follow, so be on the lookout for code referencing <samp class="SANS_TheSansMonoCd_W5Regular_11">fs:[0]</samp>.
    It’s also common to see this followed by a <samp class="SANS_TheSansMonoCd_W5Regular_11">div</samp>
    instruction, which might indicate that the malware is attempting to cause a division-by-zero
    exception. We’ll discuss SEH and this specific code block further in [Chapter
    11](chapter11.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Function Pointer Abuse</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As you’ve seen, a typical control flow transfer to a new function will involve
    a jump or call instruction. However, crafty malware can obscure these instructions
    by introducing function pointers like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This malware sample moves the offset address of the function <samp class="SANS_TheSansMonoCd_W5Regular_11">sub_4511D5</samp>
    into a variable on the stack, <samp class="SANS_TheSansMonoCd_W5Regular_11">var_26</samp>.
    Then, it uses a call instruction and references the <samp class="SANS_TheSansMonoCd_W5Regular_11">var_26</samp>
    variable, which contains the address of the target function it wishes to call
    (<samp class="SANS_TheSansMonoCd_W5Regular_11">sub_4511D5</samp>).
  prefs: []
  type: TYPE_NORMAL
- en: This is a simple technique, but you can likely see how it might cause confusion
    during static analysis. To overcome this technique, you’d have to pinpoint the
    suspect call instruction and look backward through the code until you could identify
    what is stored in the referenced function pointer. Malware authors can make this
    obfuscation technique much more complex, however. For example, it can pass function
    offsets between different variables, which would make it very difficult for the
    analyst to identify the call’s target function. Analyzing code such as this in
    a debugger can better help you understand what is going on.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Control Flow Obfuscation
    Countermeasures</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This chapter has outlined only a few of the most common control flow obfuscation
    techniques, but you can overcome most of them with a few methods. First, you can
    use the same approach described in “Breaking Disassemblers” on [page 152](chapter9.xhtml#pg_152).
    If you spot code that is impossible or simply doesn’t make sense, try converting
    it into data. This may help you spot anomalies such as rogue bytes. The inverse
    is also true: if you spot data abnormalities or large sections of data in between
    code, try converting the data into code and reassessing it. This small tip may
    help you get around many simple anti-disassembly techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: Second, stepping through the code in a debugger can make a world of difference;
    it usually makes understanding the code and control flow much easier. The debugger
    can be used alongside the disassembler, and you can set a debugger breakpoint
    on the addresses of code that you don’t entirely understand. If you spot a rogue
    byte in the code, for example, the debugger can help you understand what may be
    occurring. Some malware analysts like to use a disassembler with a built-in debugger
    (such as IDA Pro) for this very reason, but a separate disassembler and debugger
    will do just fine. I typically pair x64dbg with Ghidra or IDA.
  prefs: []
  type: TYPE_NORMAL
- en: Third, you can try to identify the obfuscator that was used on the malware.
    For example, tools such as Detect It Easy (DIE) and Exeinfo PE will attempt to
    identify possible obfuscators and packers (covered in [Chapter 17](chapter17.xhtml)).
    Once you’ve identified the obfuscator or packer, doing a bit of research on how
    it works may give you some insight into how you can reverse it, or there may even
    be a public deobfuscator available! Some tools attempt to generically deobfuscate
    code and remove some of the complexity, but in my experience they tend to not
    work very well and can leave holes in the code or misinterpret it. Finally, different
    disassemblers tend to disassemble code a bit differently. If you primarily use
    IDA, for example, give Ghidra or another disassembler a try and see if you get
    a result that’s easier to understand.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, dealing with anti-disassembly requires knowledge and experience
    of the assembly language, and there’s no substitute for that. Learning assembly
    (x86, x64, or for whatever type of malware you’re reversing) and continuing to
    build that skill set will help you more quickly identify the anti-disassembly
    and code obfuscation techniques being employed by malware.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">API Call and String Obfuscation</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, you’ll learn how malware can obfuscate its Windows API function
    calls and strings to hide its intentions from analysts.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Dogma_OT_Bold_B_15">NOTE</samp>
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This section outlines obfuscation techniques that are specifically applicable
    to anti-disassembly and protection against static analysis, but [Chapter 16](chapter16.xhtml)
    covers more generic obfuscation techniques. API call and string obfuscation can
    also be used for endpoint defense evasion, such as sidestepping anti-malware software,
    but [Part IV](part4.xhtml) will discuss this topic in more depth.*'
  prefs: []
  type: TYPE_NORMAL
- en: '#### <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Dynamic API
    Function Resolution</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: '*Dynamic API function resolution* is when a program dynamically obtains the
    address of a function it wishes to call, rather than including the function in
    its import address table (IAT). The Windows API function <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp>
    can assist with this. <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp>
    retrieves the procedural address of a function inside a given module, and it takes
    two parameters: a handle to the module where the target function resides, and
    the name of the target function itself. Sometimes <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp>
    is preceded by a call to <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibrary</samp>,
    which will load the module that contains the target function. Let’s take a look
    at this in practice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This malware sample first pushes the name of the module that contains the target
    function (in this case, *kernel32.dll*) to the stack and invokes <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibraryA</samp>,
    which loads this library into the address space of the process. <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibraryA</samp>
    returns a handle to the *kernel32.dll* module, which is stored in <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp>
    and is then pushed to the stack (<samp class="SANS_TheSansMonoCd_W5Regular_11">push
    eax</samp>). Next, the code pushes the name of the target function <samp class="SANS_TheSansMonoCd_W5Regular_11">IsDebuggerPresent</samp>
    to the stack and calls <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp>.
    The call to <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp>
    returns the address of the target function and stores it in <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp>.
    Finally, the malware executes a call instruction with the target of <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp>,
    which will subsequently invoke <samp class="SANS_TheSansMonoCd_W5Regular_11">IsDebuggerPresent</samp>.
    As you can see, this technique adds a layer of obfuscation to the function call.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Jump Tables and Indirect
    API Calls</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: API calls can be obfuscated with *jump tables*, data structures that map addresses
    of external libraries. Jump tables can serve as a method both to obfuscate control
    flow and to hamper static code analysis. [Figure 9-6](chapter9.xhtml#fig9-6) shows
    what a jump table might look like in action.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig9-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-6: A jump table in
    action</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: In this simplified example, the malware’s main code makes <samp class="SANS_TheSansMonoCd_W5Regular_11">call</samp>
    instructions to different addresses representing the Windows API function the
    malware wishes to call. The malware’s code then transfers control flow to the
    jump table, which in this case is essentially a list of further <samp class="SANS_TheSansMonoCd_W5Regular_11">call</samp>
    instructions that use <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp>
    to get the procedure address of the target Windows API function, and subsequently
    invokes that function. When the malware wishes to call <samp class="SANS_TheSansMonoCd_W5Regular_11">WriteFile</samp>,
    for example, it makes a call to <samp class="SANS_TheSansMonoCd_W5Regular_11">sub_2082A2B0</samp>,
    which jumps to the jump table, which in turn gets the address of <samp class="SANS_TheSansMonoCd_W5Regular_11">WriteFile</samp>
    in the *kernel32.dll* library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Jump tables can be as simple as a list of <samp class="SANS_TheSansMonoCd_W5Regular_11">call</samp>
    instructions, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: API functions in the jump table can be dynamically resolved upon the malware’s
    initial execution (thus building the table dynamically) or can be invoked by the
    malware as needed, meaning the function addresses are resolved on demand. This
    adds further complexity to the jump table, making the code more difficult for
    the reverser to follow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Malware may also use indirect API calls. Similar to jump tables, API function
    addresses are dynamically resolved and stored in memory or in CPU registers for
    later use. Then, the malware invokes the function by issuing a call instruction
    for the address of the function rather than by function name. You can see this
    in the following 64-bit simplified code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This code is using indirect calls to obfuscate its function calls. First, it
    moves the name of the target function it wishes to call (<samp class="SANS_TheSansMonoCd_W5Regular_11">CryptEncrypt</samp>)
    into <samp class="SANS_TheSansMonoCd_W5Regular_11">rdx</samp>, as well as the
    associated module name (<samp class="SANS_TheSansMonoCd_W5Regular_11">hModule</samp>),
    which, in the case of these functions, resides in *kernel32.dll*. Next, the code
    calls <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp> to get
    the address of the <samp class="SANS_TheSansMonoCd_W5Regular_11">CryptEncrypt</samp>
    function. Then, the code moves this address onto the stack (<samp class="SANS_TheSansMonoCd_W5Regular_11">mov
    [rbp-39], rax</samp>), which will be used later. The code runs this procedure
    twice more, for the functions <samp class="SANS_TheSansMonoCd_W5Regular_11">CryptDecrypt</samp>
    and <samp class="SANS_TheSansMonoCd_W5Regular_11">WriteFile</samp>. After storing
    the addresses of its target functions on the stack, the code can later invoke
    these functions by their addresses like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This call instruction will invoke the function stored on the stack at <samp
    class="SANS_TheSansMonoCd_W5Regular_11">rbp-39</samp>, which happens to be <samp
    class="SANS_TheSansMonoCd_W5Regular_11">CryptEncrypt</samp>, a function used for
    encrypting data. Calling functions this way provides a layer of obfuscation for
    researchers who are manually reverse engineering the code.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Stack Strings</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Stack strings* refer to strings that are built on the stack dynamically in
    memory by the malware. They add a layer of obfuscation to a malware executable,
    making static analysis a bit more time-consuming, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This code snippet contains several <samp class="SANS_TheSansMonoCd_W5Regular_11">mov</samp>
    instructions, representing the code moving data onto the stack. What’s interesting
    about them is that they’re moving hex values, byte by byte, into a buffer (<samp
    class="SANS_TheSansMonoCd_W5Regular_11">ebp+file</samp>). If you convert these
    hex values into ASCII (using the R key in IDA or selecting **Right-click****Convert****Char**
    in Ghidra), you can deobfuscate this stack string like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now you can make a more educated guess about what the malware is doing with
    this data. It’s creating a string (<samp class="SANS_TheSansMonoCd_W5Regular_11">evil.dll</samp>)
    on the stack and calling <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibraryA</samp>,
    which will load this malicious DLL file into the malware’s process. This is a
    form of *process injection*, a technique [Part IV](part4.xhtml) will cover in
    depth.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some great tools malware analysts can use for automating stack string
    deobfuscation. Running a malware sample through FLOSS (discussed in [Chapter 2](chapter2.xhtml)),
    for example, can deobfuscate some basic string obfuscation and build an IDA script
    file so that you can easily load this data back into your IDA database. Here’s
    an example of FLOSS output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '*Pestr* ([*https://<wbr>pev<wbr>.sourceforge<wbr>.io*](https://pev.sourceforge.io)),
    another tool for stack string deobfuscation, can be run nearly the same way. Both
    tools are easy enough to quickly run before starting your reverse engineering
    process and may save you some time when analyzing malware code that has implemented
    basic string obfuscation.'
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Data Hashing</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Malware authors can obfuscate malware functionalities by using data *hashing*,
    which is a kind of one-way data encoding; that is, it takes some data and encodes
    it into something else that can’t be reversed. The ransomware family Maze uses
    the well-known *ROR-13* hashing algorithm to obfuscate Windows API function calls,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The <samp class="SANS_TheSansMonoCd_W5Regular_11">mov</samp> instruction in
    the second line moves the ROR-13 hash <samp class="SANS_TheSansMonoCd_W5Regular_11">7C0DFCAAh</samp>,
    the value of <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp>,
    onto the stack. Similarly, the hash <samp class="SANS_TheSansMonoCd_W5Regular_11">0EC0E4E8Eh</samp>
    represents the <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibraryA</samp>
    function, which moved to the stack in line 8\. This malware is obfuscating its
    calls to the <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp>
    and <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibraryA</samp> functions
    using hashes in place of the function name. There must be a function that is responsible
    for interpreting these hashes and loading the address of the target functions
    (in this case, function <samp class="SANS_TheSansMonoCd_W5Regular_11">sub_4011A0</samp>),
    but this is not shown in the preceding code and the specifics of this are outside
    the scope of this chapter. However, this is well documented, such as in the blog
    post “Windows API Hashing in Malware” at [*https://<wbr>www<wbr>.ired<wbr>.team<wbr>/offensive<wbr>-security<wbr>/defense<wbr>-evasion<wbr>/windows<wbr>-api<wbr>-hashing<wbr>-in<wbr>-malware*](https://www.ired.team/offensive-security/defense-evasion/windows-api-hashing-in-malware).
  prefs: []
  type: TYPE_NORMAL
- en: It’s difficult to understand what’s happening here simply by reviewing the code,
    since the function names are hashed and therefore unreadable. Luckily, many disassemblers
    have special features or plug-ins that can automatically identify potential hashed
    function names. In my case, the IDA plug-in *apihashes* was able to correctly
    identify and annotate the ROR-13–hashed data. Hashing will be discussed in greater
    detail in [Chapter 16](chapter16.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Summary</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, you learned about several anti-disassembly techniques malware
    might employ to protect itself from malware analysts and their tools. Deobfuscating
    assembly code is a challenging task that requires a high level of technical skill
    and knowledge of a malware’s behavior and characteristics. Compounding this challenge
    is the fact that many of these techniques are very simple for malware authors
    to implement, thanks to special code compilers, obfuscators, and tools such as
    packers. It’s often much easier for malware authors to implement anti-disassembly
    measures than it is for reverse engineers to circumvent them, but fighting back
    against such techniques is crucial to understanding the malware’s behavior and
    functionality. As an analyst, you should use the range of tools and techniques
    at your disposal to deobfuscate malware code and reveal its true intentions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we’ll discuss another anti-reversing technique that some
    malware implements to thwart dynamic code analysis: anti-debugging.'
  prefs: []
  type: TYPE_NORMAL
