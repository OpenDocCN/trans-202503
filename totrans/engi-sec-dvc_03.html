<html><head></head><body>
<div id="sbo-rt-content"><h2 class="h2" id="ch02"><span epub:type="pagebreak" id="page_27"/><strong><span class="big">2</span><br/>CRYPTOGRAPHY</strong></h2>
<div class="image1"><img alt="Image" height="252" src="../images/common.jpg" width="252"/></div>
<p class="noindent">The guarantees and powers of cryptographic algorithms often sound like magic. A layperson isn’t able to verify any of these properties and neither are most engineers. In some cases, even cryptographers can’t prove the security of a scheme, but they assume or believe that the underlying mathematical problem is hard to solve. Nevertheless, cryptographic algorithms are necessary tools that every developer and architect should know how to use.</p>
<p class="indent">The word <em>cryptography</em> comes from the combination of the Greek words <em>kryptós</em> and <em>gráphein</em>, which translate to <em>secret writing</em>. Nowadays, however, cryptography is much more than the protection of confidential messages. It’s also used to protect the integrity of files, to derive reliable fingerprints of gigabytes of data, and to sign documents and code digitally.</p>
<p class="indent">This chapter provides a pragmatic overview of modern cryptographic algorithms and their practical properties while keeping mathematical formulas at a minimum. We’ll start with some basic principles, then take a peek at typical symmetric algorithms and hash functions. A look at the intriguing field of asymmetric crypto concludes the chapter.</p>
<h3 class="h3" id="ch00lev1_15"><span epub:type="pagebreak" id="page_28"/><strong>Kerckhoffs’s Principle</strong></h3>
<p class="noindent">Auguste Kerckhoffs was a Dutch cryptographer in the 19th century. In the security community, he’s known for his proposals to improve practical cryptography in the French military. Among the six recommendations he published in 1883, one became famously known as <em>Kerckhoffs’s principle</em>: “The system must not require secrecy and can be stolen by the enemy without causing trouble.”</p>
<p class="indent">For cryptographic algorithms, this principle means that procedures like encryption, decryption, or signing should not be kept secret and that no one should rely on this secrecy to guarantee security. The only secret in the system should be a secret cryptographic key.</p>
<p class="indent">Today, this point doesn’t seem worth mentioning because all relevant crypto algorithms are standardized on a national or international level, and all are publicly available for everyone to read and analyze. However, when it comes to engineering software and devices, some developers still break with this principle. They invent their own “crypto” procedures and argue that security is achieved “because nobody knows how it works.” They sometimes do this for performance reasons, but more often it’s the result of a lack of solid crypto knowledge. However, the phrase “can be stolen by the enemy” could also be interpreted as “can be reverse engineered by an attacker,” which would break the security of such a “solution.”</p>
<p class="indent">If you catch yourself considering the implementation of a custom function probably including some magic values and XOR operations to achieve security, stop thinking about it immediately! It’s called <em>security by obscurity</em> and it will only get you into trouble.</p>
<h3 class="h3" id="ch00lev1_16"><strong>Levels of Security</strong></h3>
<p class="noindent">Cryptographic algorithms have several parameters and properties that describe and differentiate them, but one is central: their <em>security level</em> that’s indicated by a certain bit length—for example, 64-bit, 80-bit, or 256-bit. This practical gauge allows you to compare algorithms and their cryptographic strength. But what does it actually mean if a specific algorithm has a 128-bit security level?</p>
<p class="indent">The level describes the effort an attacker needs to expend in order to break the algorithm’s protection goal. Usually, that effort involves testing large sets of data for a correct solution, such as a secret decryption key. If an algorithm has a 128-bit security level, the <em>search space</em> for an attacker is 128 bits large, which means that the attacker has to perform a maximum of 2<sup>128</sup> tries in order to identify the needle in the haystack.</p>
<p class="indent">For well-designed symmetric ciphers, the key length can be translated directly into an algorithm’s security level. However, security levels are subject to change if cryptographers find algorithmic flaws. In that case, the algorithm’s security level might become significantly less than the key length.</p>
<p class="indent">In addition, keep in mind that attackers continuously make performance gains. Modern <em>brute-force</em> attacks make use of thousands of cloud instances <span epub:type="pagebreak" id="page_29"/>to efficiently search for a key. In recent years, attacks on 64-bit secrets have been successful, increasing the need for a solid choice of security level.</p>
<p class="indent">If you want to engineer secure and long-lasting devices, keep up with the current recommendations of crypto security levels (see <em><a href="https://www.keylength.com">https://www.keylength.com</a></em>). As a rule of thumb at the time of writing, a 128-bit security level is considered suitable for practical security engineering, and 256-bit is typically used for high-security applications.</p>
<div class="note">
<p class="notet"><strong><span class="notes">WARNING</span></strong></p>
<p class="notep"><em>Although the security level of symmetric ciphers often equals their key length, that’s not always the case. In addition, security levels for asymmetric crypto are completely different; keys with 2,048 bits might offer only 112-bit security, for example, as you’ll see later in this chapter.</em></p>
</div>
<h3 class="h3" id="ch00lev1_17"><strong>Symmetric Ciphers</strong></h3>
<p class="noindent">The origin of symmetric cryptography dates back to the famous Roman named Caesar, who is said to have used a simple letter-substitution cipher to make messages incomprehensible. Since then, the basic principle of symmetric crypto hasn’t changed. It follows the idea that a <em>plaintext</em> message can be encrypted to a <em>ciphertext</em> by using the encryption algorithm <span class="literal">Encrypt</span><span class="literal">()</span> and a <em>cryptographic key</em>, as illustrated in <a href="ch02.xhtml#ch02fig01">Figure 2-1</a>.</p>
<div class="image"><img alt="Image" height="152" id="ch02fig01" src="../images/02fig01.jpg" width="864"/></div>
<p class="figcap"><em>Figure 2-1: The basic principle of symmetric cryptography</em></p>
<p class="indent">The decryption operation <span class="literal">Decrypt</span><span class="literal">()</span> uses <em>the same secret key</em> to reverse the encryption and yield the original message, hence the term <em>symmetriccryptography</em>.</p>
<h4 class="h4" id="ch00lev2_18"><strong><em>Data Encryption Standard</em></strong></h4>
<p class="noindent">Fast-forward 2,000 years. In many cases, symmetric encryption is now handled by <em>block ciphers</em> that take one block of plaintext and encrypt it to a block of ciphertext. One of the first publicly standardized block ciphers was the <em>Data Encryption Standard (DES)</em>, also known as the <em>Data Encryption Algorithm (DEA)</em>. It’s based on a so-called <em>Feistel network</em> and has only a 56-bit key. Today, with dedicated hardware, this key space can be completely searched within hours, which makes it absolutely insecure for modern applications.</p>
<p class="indent"><em>Triple DES (3DES)</em> is an extension of DES that uses three 56-bit keys and applies DES three times to a plaintext or ciphertext. Given the total key length of 168 bits, the block size of 64 bits, and known cryptographic weaknesses, 3DES is considered to achieve only a 112-bit security level and should no longer be used in new designs.</p>
<div class="note">
<p class="notet"><span epub:type="pagebreak" id="page_30"/><strong><span class="notes">WARNING</span></strong></p>
<p class="notep"><em>Some modern crypto libraries still provide DES and 3DES. However, if you don’t have very good reasons—for example, indispensable backward compatibility—do not use any DES-based algorithm.</em></p>
</div>
<h4 class="h4" id="ch00lev2_19"><strong><em>Advanced Encryption Standard</em></strong></h4>
<p class="noindent">The first choice for symmetric encryption is currently the <em>Advanced Encryption Standard (AES)</em>, originally named <em>Rijndael</em>. This successor of DES was standardized as Federal Information Processing Standard (FIPS) 197 and ISO/IEC 18033-3 after a cryptographic competition process that was organized by NIST lasted from 1997 to 2000. AES is based on a substitution-permutation network (SPN), has a block length of 128 bits, and can be operated with three key lengths: 128-bit, 192-bit, and 256-bit.</p>
<p class="indent">As shown in <a href="ch02.xhtml#ch02fig02">Figure 2-2</a>, AES operates on a 4×4 byte matrix, known as the <em>AES state</em>.</p>
<div class="image"><img alt="Image" height="277" id="ch02fig02" src="../images/02fig02.jpg" width="277"/></div>
<p class="figcap"><em>Figure 2-2: A matrix visualization of the AES state</em></p>
<p class="indentb">Depending on the selected key size, this state is processed for a certain number of rounds: 10 for 128-bit keys, 12 for 192-bit keys, and 14 for 256-bit keys. Here’s the basic encryption process based on the main AES functions:</p>
<p class="hanga"><strong>Key expansion</strong>    The original key is expanded to multiple 128-bit subkeys, one for each round plus an initial one.</p>
<p class="hanga"><strong>Initial round</strong>    As a preparation step, the function <span class="literal">AddRoundKey</span><span class="literal">()</span> is applied to the input plaintext to obtain a new state.</p>
<p class="hanga"><strong>Main rounds</strong>    Depending on the key lengths, 9, 11, or 13 main rounds are performed with the following operations happening consecutively: <span class="literal">SubBytes</span><span class="literal">()</span>, <span class="literal">ShiftRows</span><span class="literal">()</span>, <span class="literal">MixColumns</span><span class="literal">()</span>, and <span class="literal">AddRoundKey</span><span class="literal">()</span>.</p>
<p class="hanga"><strong>Final round</strong>    In the last round, only <span class="literal">SubBytes</span><span class="literal">()</span>, <span class="literal">ShiftRows</span><span class="literal">()</span>, and <span class="literal">AddRoundKey</span><span class="literal">()</span> are called. <span class="literal">MixColumns</span><span class="literal">()</span> is omitted.</p>
<p class="indentt"><span epub:type="pagebreak" id="page_31"/>The four operations that enable this strong encryption are pretty simple. The <span class="literal">SubBytes()</span> function substitutes each byte in the AES state with a corresponding byte resulting from a lookup table called an <em>S-box</em>, as shown in <a href="ch02.xhtml#ch02fig03">Figure 2-3</a>.</p>
<div class="image"><img alt="Image" height="219" id="ch02fig03" src="../images/02fig03.jpg" width="687"/></div>
<p class="figcap"><em>Figure 2-3: The</em> <span class="codeitalic1">SubBytes()</span> <em>transformation</em></p>
<p class="indent"><a href="ch02.xhtml#ch02fig04">Figure 2-4</a> shows that the <span class="literal">ShiftRows()</span> transformation shifts the second row of the AES state matrix 1 byte to the left, the third row 2 bytes to the left, and the fourth row 3 bytes to the left. The first row remains unchanged.</p>
<div class="image"><img alt="Image" height="219" id="ch02fig04" src="../images/02fig04.jpg" width="687"/></div>
<p class="figcap"><em>Figure 2-4: The</em> <span class="codeitalic1">ShiftRows()</span> <em>transformation</em></p>
<p class="indent">The <span class="literal">MixColumns()</span> operation applies a linear transformation to each column of the AES state matrix, as depicted in <a href="ch02.xhtml#ch02fig05">Figure 2-5</a>. This yields 4 resulting bytes representing the new state of each column, respectively.</p>
<div class="image"><img alt="Image" height="219" id="ch02fig05" src="../images/02fig05.jpg" width="687"/></div>
<p class="figcap"><em>Figure 2-5: The</em> <span class="codeitalic1">MixColumns()</span> <em>transformation</em></p>
<p class="indent">Every round, the <span class="literal">AddRoundKey()</span> operation XORs each byte of the AES state with the corresponding byte of a given round key, as illustrated in <a href="ch02.xhtml#ch02fig06">Figure 2-6</a>.</p>
<div class="image"><span epub:type="pagebreak" id="page_32"/><img alt="Image" height="471" id="ch02fig06" src="../images/02fig06.jpg" width="687"/></div>
<p class="figcap"><em>Figure 2-6: The</em> <span class="codeitalic1">AddRoundKey()</span> <em>transformation</em></p>
<p class="indent">For decryption, the order of subkeys is reversed, and the inverse functions of <span class="literal">SubBytes()</span>, <span class="literal">ShiftRows()</span>, <span class="literal">MixColumns()</span>, and <span class="literal">AddRoundKey()</span> are called.</p>
<p class="indent">After more than 20 years and extensive research, nobody has discovered an attack on the AES architecture that has practical relevance. It’s available in all major crypto software libraries, and systems as small as 8-bit microcontrollers can use it with reasonable performance. AES is used for disk encryption in laptops, but also for payload encryption in secure internet communication. Whenever it comes to symmetric encryption, you should choose AES unless you have serious reasons not to do so.</p>
<h3 class="h3" id="ch00lev1_18"><strong>Modes of Operation</strong></h3>
<p class="noindent">Since AES is a block cipher, it naturally encrypts or decrypts only a single block, but many applications have much more input data than just one 128-bit block. Therefore, AES has to be used in a certain <em>mode of operation</em> that defines the procedures to encrypt and decrypt multiple blocks of data. The modes introduced here are defined in NIST’s <em>Special Publication 800-38A</em>.</p>
<h4 class="h4" id="ch00lev2_20"><strong><em>Electronic Codebook Mode</em></strong></h4>
<p class="noindent">Some of you might wonder, “Why not just encrypt the data block by block?” That trivial approach is exactly what the <em>Electronic Codebook (ECB) mode</em> does. It takes the first 128 bits of a message as the first plaintext block, encrypts it to the first 128 bits of ciphertext, and continues in the same way with as many chunks of 128-bit data as available, as shown in <a href="ch02.xhtml#ch02fig07">Figure 2-7</a>.</p>
<div class="image"><span epub:type="pagebreak" id="page_33"/><img alt="Image" height="228" id="ch02fig07" src="../images/02fig07.jpg" width="852"/></div>
<p class="figcap"><em>Figure 2-7: Encryption in ECB mode</em></p>
<p class="indent">However, the problem with this approach is that equal input data blocks are encrypted to equal ciphertext blocks. Therefore, the relation between blocks, which can also carry sensitive information, is preserved. <a href="ch02.xhtml#ch02fig08">Figure 2-8</a> illustrates this phenomenon.</p>
<div class="image"><img alt="Image" height="228" id="ch02fig08" src="../images/02fig08.jpg" width="915"/></div>
<p class="figcap"><em>Figure 2-8: Comparing ECB and Counter (CTR) modes</em></p>
<p class="indent">When images are encrypted in ECB mode, the plaintext pixels with the same values are still mapped to ciphertext pixels with identical values. The image information is still comprehensible. For other operation modes, such as Counter mode, things look different, as explained in “Counter Mode” on <a href="ch02.xhtml#ch00lev2_22">page 34</a>.</p>
<h4 class="h4" id="ch00lev2_21"><strong><em>Cipher Block Chaining Mode</em></strong></h4>
<p class="noindent">The <em>Cipher Block Chaining (CBC) mode</em> breaks the relation between plaintext and ciphertext by XORing the ciphertext of the first block with the plaintext of the second block, and so on. <a href="ch02.xhtml#ch02fig09">Figure 2-9</a> shows the basic principle.</p>
<div class="image"><img alt="Image" height="331" id="ch02fig09" src="../images/02fig09.jpg" width="891"/></div>
<p class="figcap"><em>Figure 2-9: Encryption in CBC mode</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_34"/>From a security point of view, CBC mode is significantly better than ECB mode, but it has a new drawback: the dependency between subsequent encryptions makes parallel implementations less efficient, which limits performance.</p>
<h4 class="h4" id="ch00lev2_22"><strong><em>Counter Mode</em></strong></h4>
<p class="noindent">An interesting mode that doesn’t permit a relation between ciphertexts but facilitates high-performance, multicore implementations is called <em>Counter (CTR) mode</em>. As illustrated in <a href="ch02.xhtml#ch02fig010">Figure 2-10</a>, the plaintext blocks themselves aren’t encrypted, but the concatenation of a <em>nonce (number used once)</em> and a counter value starting at 0.</p>
<div class="image"><img alt="Image" height="316" id="ch02fig010" src="../images/02fig10.jpg" width="868"/></div>
<p class="figcap"><em>Figure 2-10: Encryption in CTR mode</em></p>
<p class="indent">The result of this encryption is then XORed with the plaintext to obtain a ciphertext. For every further plaintext block, the counter value is incremented by one to support changing ciphertexts, as shown in <a href="ch02.xhtml#ch02fig08">Figure 2-8</a>c. This approach even provides another advantage: both encryption and decryption utilize the <span class="literal">Encrypt()</span> function of the used block cipher. There’s no need to implement <span class="literal">Decrypt()</span>.</p>
<p class="indent">In contrast to ECB mode, CBC and CTR modes require an additional input parameter: an <em>initialization vector (IV)</em> or a nonce. The rationale for both is to make every encryption unique, so they should never be used twice. Further, decryption is possible only if the receiver also has access to the corresponding IV or nonce. But since it doesn’t carry confidential data, transmitting it in cleartext is okay along with the ciphertext.</p>
<div class="note">
<p class="notet"><strong><span class="notes">WARNING</span></strong></p>
<p class="notep"><em>In practice, just setting an IV or a nonce to 0 or a fixed random number is tempting. However, doing so will significantly weaken the strength of this cryptographic primitive. Spend the additional effort to implement a suitable generator for unique values.</em></p>
</div>
<p class="indent">Together with the operation modes CBC and CTR, AES enjoys great popularity. However, other, more interesting symmetric ciphers might be helpful if you have special requirements. For example, the modern stream ciphers Salsa20 and ChaCha20, developed by cryptographer Daniel J. Bernstein, <span epub:type="pagebreak" id="page_35"/>have simple designs and provide high performance in pure software implementations. If your hardware doesn’t support AES but you need to get the highest performance possible, these algorithms might be worth looking at.</p>
<h3 class="h3" id="ch00lev1_19"><strong>Hash Functions</strong></h3>
<p class="noindent">Hash functions are somewhat exotic in the pool of cryptographic algorithms. On their own, they don’t aim for one of the classic protection goals. Their objective is to map more or less arbitrarily large input data to a fixed-length, binary sequence called a <em>hash value</em>, or <em>digest</em>.</p>
<p class="indentb">However, the design of such functions isn’t trivial. They have to fulfill a set of strong requirements:</p>
<p class="hanga"><strong>Preimage resistance</strong>    The term <em>preimage</em> refers to the correct input data to a hash function that maps to a given hash value. This requirement says that an attacker shouldn’t be able to find such suitable input data for an existing hash value. This is why hash functions are also called <em>one-way functions</em>. Nobody should be able to invert them.</p>
<p class="hanga"><strong>Second preimage resistance</strong>    Further, a malicious actor who has access to a message and its hash value shouldn’t be able to find a <em>second preimage</em>—namely, another message that maps to the same hash.</p>
<p class="hanga"><strong>Collision resistance</strong>    Naturally, hash-value collisions must exist because the input space of a hash function is larger than its output space. The strongest assumption for hash functions is that finding any two messages that map to the same hash value should be <em>practically impossible</em>.</p>
<p class="indentt">By design, hash functions don’t use a secret key, which means that everyone can use them and apply them to all data at hand. Therefore, we have to determine the security level of hash functions differently. The security level is described as the amount of difficulty in finding collisions, which is again a kind of search-space problem, similar to finding the correct key for an encryption algorithm.</p>
<p class="indent">Based on the so-called <em>birthday paradox</em> and the <em>rho method</em>, cryptographers have shown that, for well-designed hash functions, we can estimate the security level to be half of their output size. For example, for a hash function with 160-bit output, the security level estimate is around 80-bit.</p>
<p class="indent">At this point, you might wonder why we need hash functions and their cryptographic mapping process for device security. The reason is simple: they’re part of many security applications like digital signature generation and verification, key-derivation algorithms, secure password storage, and many more.</p>
<p class="indent">The first practical implementations of hash functions emerged in the 1990s. MD4, MD5, and SHA-1 are three prominent representatives. However, in the meantime, researchers have discovered ways to find collisions for those three (and others), so you shouldn’t use those legacy algorithms in modern designs anymore.</p>
<p class="indent"><span epub:type="pagebreak" id="page_36"/>Currently, the most widely used family of hash functions is SHA-2, the successor to SHA-1. It’s described in the <em>FIPS 180-4</em> standard and has four members: SHA-224, SHA-256, SHA-384, and SHA-512. The numbers represent the output lengths of these functions, so SHA-224 is very similar to SHA-256 except for different initial values and the truncation of the final hash value to 224 bits. The same applies for SHA-384 in relation to SHA-512.</p>
<p class="indent">SHA-256 processes 512 bits (sixteen 32-bit words) in 64 rounds. It exhibits a 128-bit security level against collisions and is, therefore, a secure and efficient option. SHA-512 is intended for high-security areas like federal and military purposes. It works on 1,024 bits (sixteen 64-bit words) for 80 rounds and exhibits a lower performance compared to SHA-256.</p>
<p class="indent">Since the SHA-2 family is based on an architecture similar to MD5 and SHA-1, cryptographers are skeptical about its long-term security. In 2007, NIST announced a cryptographic competition in order to find a candidate to be standardized as SHA-3. One important requirement was that the design of the algorithm should be based on primitives other than SHA-2. Five years later, the <em>Keccak</em> algorithm was named as the winning hash function. Subsequently, it has been published as the new SHA-3 standard in <em>FIPS 202</em>.</p>
<p class="indent">SHA-3 is also available in four versions: SHA3-224, SHA3-256, SHA3-384, and SHA3-512. Again, the lengths of their output values in bits is denoted by the numbers after the hyphen in their names. Their performance and security level is comparable to those of their SHA-2 counterparts, but they’re based on a completely different algorithmic foundation, as intended by NIST.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Even if SHA-3 is the newer standard, you don’t need to migrate from SHA-2 to SHA-3 soon. They are comparable, so you are free to decide which to use depending on the libraries you need and application requirements you have.</em></p>
</div>
<h3 class="h3" id="ch00lev1_20"><strong>Message Authentication Codes</strong></h3>
<p class="noindent">A common misconception about encryption is that it protects against manipulation. It doesn’t. Even if you use AES and a state-of-the-art mode of operation, and an attacker can’t read anything from the resulting ciphertext, that attacker is still able to manipulate single bits or whole messages without being detected by the block cipher. Encryption protects only confidentiality, not integrity.</p>
<p class="indent">A <em>message authentication code (MAC)</em>, also known as a <em>message integrity code (MIC)</em>, is another primitive from the symmetric cryptography tool belt, and it’s meant to protect message integrity and authenticity. It creates an <em>authentication tag</em> from a message and a secret key. Afterward, everyone in possession of the secret key can verify the correctness of a message and its corresponding authentication tag.</p>
<p class="indent">A popular method for generating MACs is a <em>hash-based message authentication code (HMAC)</em>. The HMAC construction, also known as a <em>keyed hash function</em>, is defined in RFC 2104. The following formula shows its composition:</p>
<p class="center"><em>HMAC</em> = <em>hash</em>((<em>key</em> ⊕ <em>opad</em>) ∥ <em>hash</em>((<em>key</em> ⊕ <em>ipad</em>) ∥ <em>message</em>))</p>
<p class="indent"><span epub:type="pagebreak" id="page_37"/>The <em>inner padding (ipad)</em> is a byte string, <span class="literal">0x3636...36</span>, containing the same number of bytes as the input block size of the used hash function. It is XORed with a key of at least the security level of the underlying hash function. The result is concatenated with the message to protect before it is hashed altogether. The digest of this operation is then appended to the XOR between the same key and the <em>outer padding (opad)</em>, a byte string <span class="literal">0x5c5c...5c</span> of the same length as the ipad. Hashing the resultant bytes leads to the final HMAC value.</p>
<p class="indent">As an example, if SHA-256 is chosen as an HMAC’s hash function, the cryptographic algorithm is then called HMAC-SHA-256. The length of the inner and outer padding is 512 bits, or 64 bytes. The key should be at least 128 bits long, and the HMAC length is 256 bits, or 32 bytes.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>In practice, you might come across HMAC constructions that are built upon MD5 or SHA-1. Even if collision attacks have been demonstrated for these hash functions, they’re still valid to be used for practical HMAC implementations because an attacker would have to acquire an enormous number of authentication tags resulting from the same single secret key to break a specific instance.</em></p>
</div>
<p class="indent">A <em>cipher-based message authentication code (CMAC)</em> uses a block cipher in CBC mode to compute MACs. A variant that’s based on AES, called <em>AES-CMAC</em>, is specified in RFC 4493. There, the message to protect is processed with AES in CBC mode except for the last message block, which is specifically treated for security reasons. The final ciphertext is taken as the authentication tag, and all other ciphertexts are discarded.</p>
<p class="indent">This solution isn’t as popular as the HMAC construction, but it might be interesting from a performance point of view, especially on devices that have built-in AES accelerators.</p>
<h3 class="h3" id="ch00lev1_21"><strong>Authenticated Encryption</strong></h3>
<p class="noindent">For secure communication, confidentiality, integrity, and authenticity are common protection goals. In the previous sections, we considered how we can use block ciphers and MACs to achieve these goals, but two practical questions still remain: “How do we combine them?” and “Can combinations of ciphers and MACs be more efficient than using them separately?”</p>
<h4 class="h4" id="ch00lev2_23"><strong><em>Strategies and Requirements</em></strong></h4>
<p class="noindentb">When combining encryption and MAC generation, we can use three strategies. All three assume the use of secure ciphers and MAC algorithms and that each of them uses its own key, but differ in the order of the performed operations:</p>
<p class="hanga"><strong>Encrypt-and-MAC</strong>    This approach generates a ciphertext and an authentication tag from the same plaintext in parallel, which could yield a performance advantage. However, applying a MAC algorithm to plaintext might lead to information leakage about the plaintext by the <span epub:type="pagebreak" id="page_38"/>authentication tag because MAC algorithms are not designed to protect the confidentiality of their input data. However, for modern MACs like HMAC-SHA-256, this problem doesn’t exist. A second issue is that the ciphertext’s integrity isn’t protected. An altered ciphertext has to be decrypted first to detect the manipulation, which could allow an attacker to exploit implementation weaknesses in the decryption routine.</p>
<p class="hanga"><strong>MAC-then-encrypt</strong>    In this variant, an authentication tag is generated from the plaintext and appended to it. The result is then encrypted to obtain the final ciphertext. In this case, the MAC algorithm can’t leak any information, but the ciphertext can still be manipulated without a possibility to detect it before decryption.</p>
<p class="hanga"><strong>Encrypt-then-MAC</strong>    This is a strong strategy for integrity and confidentiality protection of messages. First, the plaintext is encrypted before the MAC is generated from the resulting ciphertext. With this approach, the authentication tag can’t leak any information about the plaintext, and at the same time, we can verify the correctness of the ciphertext bits before decrypting the given data.</p>
<p class="indentt">Crypto practitioners are always on the lookout for performance gains because security measures should have as little performance overhead as possible. Therefore, it’s not surprising that the field of <em>authenticated encryption (AE)</em> emerged from the combination of ciphers and MACs to enhance processing speed.</p>
<p class="indent">In comparison to “normal” ciphers, AE algorithms take plaintext and compute both ciphertext and an authentication tag during encryption. At decryption, the integrity of the ciphertext and authentication tag are verified before proceeding.</p>
<p class="indent">An interesting extension of AE is called <em>authenticated encryption with associated data (AEAD)</em>, which allows you to integrate additional plaintext data into the process of generating the authentication tag. Examples are sequence numbers or metadata that don’t require confidentiality. The integrity of this associated data is achieved while binding it to the yielded ciphertext.</p>
<h4 class="h4" id="ch00lev2_24"><strong><em>Galois Counter Mode</em></strong></h4>
<p class="noindent">Today, the most popular AEAD algorithm is the AES cipher operated in the special <em>Galois Counter mode (GCM)</em>, which follows the encrypt-then-MAC principle and is specified in NIST’s <em>Special Publication 800-38D</em>. <a href="ch02.xhtml#ch02fig011">Figure 2-11</a> depicts its basic functionality.</p>
<div class="image"><span epub:type="pagebreak" id="page_39"/><img alt="Image" height="922" id="ch02fig011" src="../images/02fig11.jpg" width="848"/></div>
<p class="figcap"><em>Figure 2-11: An authenticated encryption in GCM</em></p>
<p class="indent">The confidentiality protection is very similar to CTR mode, except GCM doesn’t use the result of the first encryption to process plaintext, but rather does it in the final step of authentication-tag generation. The MAC generation is based on the hash function <span class="literal">GHASH</span>, which basically consists of a series of multiplications in a binary Galois field with a fixed parameter, the <em>hash subkey</em>. This subkey is derived by encrypting the all-zeros plaintext block with the AES key used for encryption.</p>
<p class="indent">The nonce or initialization vector of GCM is meant to be a unique 96-bit binary string. GCM is pretty fragile regarding nonce reuse, which means that an attacker can forge authentication tags if they have access to two authentication tags that were generated using the same key and nonce. Therefore, the implementation of a robust nonce generation is essential for GCM.</p>
<p class="indent"><span epub:type="pagebreak" id="page_40"/>Besides AES-GCM, you might encounter many more AE algorithms in the field. Examples are the Counter with CBC-MAC (CCM) mode as detailed in NIST’s <em>Special Publication 800-38C</em> and the Offset Codebook (OCB) mode designed by Phil Rogaway. The combination of the stream cipher ChaCha20 and the MAC algorithm Poly1305, both designed by Bernstein, also serves as a common AEAD solution. It’s especially efficient in software-only implementations and has been specified in RFC 8439.</p>
<p class="indent">Further, the CAESAR competition (<em><a href="https://competitions.cr.yp.to/caesar-submissions.xhtml">https://competitions.cr.yp.to/caesar-submissions.xhtml</a></em>) that ran from 2013 to 2019 yielded another set of innovative AEAD designs—for example, lightweight implementations on resource-constrained devices or high-performance applications.</p>
<h3 class="h3" id="ch00lev1_22"><strong>Asymmetric Cryptography</strong></h3>
<p class="noindent">In contrast to using a single secret key, the basic idea of <em>asymmetric cryptography</em> is having a pair of keys and using each key for only a distinct operation that complements the other. For example, everyone uses one key, called a <em>public key</em>, to encrypt data (<a href="ch02.xhtml#ch02fig012">Figure 2-12</a>). The second key, called a <em>private key</em>, belongs to a single entity, and only that entity is able to decrypt the previously generated ciphertext by using its private key. Asymmetric cryptosystems are also known as <em>public-key cryptography</em>.</p>
<div class="image"><img alt="Image" height="152" id="ch02fig012" src="../images/02fig12.jpg" width="864"/></div>
<p class="figcap"><em>Figure 2-12: Encryption with asymmetric cryptography</em></p>
<p class="indent">However, asymmetric cryptography is useful for more than confidentiality protection. The private-key operation can also generate a <em>digital signature</em>, which is a kind of checksum for given data that only the unique private key of a specific entity can compute. Everyone in possession of the corresponding public key would be able to verify this signature, which protects not only the protected data’s authenticity but also its integrity, because manipulations of the data or signature would lead to a verification failure. <a href="ch02.xhtml#ch02fig013">Figure 2-13</a> illustrates the basic idea.</p>
<div class="image"><span epub:type="pagebreak" id="page_41"/><img alt="Image" height="340" id="ch02fig013" src="../images/02fig13.jpg" width="833"/></div>
<p class="figcap"><em>Figure 2-13: The generation and verification of a digital signature</em></p>
<p class="indent">These fundamentally different opportunities have paved the way for many security features we’ve come to take for granted, like secure communication over the internet. To understand the basics of the two most popular representatives of asymmetric cryptography, there is no way around a little bit of math, as I’ll show in the next section.</p>
<h3 class="h3" id="ch00lev1_23"><strong>The RSA Cryptosystem</strong></h3>
<p class="noindent">The first and still most common asymmetric crypto scheme was published in 1977 and is named after its inventors: <em>Rivest-Shamir-Adleman (RSA)</em>. To achieve the typical asymmetry between public and private operations, RSA implements a <em>trapdoor function</em>. With this approach, you can transform data A to data B easily, but deriving data A from data B is practically impossible unless you know the trapdoor.</p>
<h4 class="h4" id="ch00lev2_25"><strong><em>Basic RSA Math</em></strong></h4>
<p class="noindent">RSA is based on modular arithmetic, which means integer calculations that wrap around if they reach a limit called the <em>modulus</em>. The following formula describes all the magic behind RSA encryption:</p>
<p class="center"><em>y</em> = <em>x<sup>e</sup></em> mod <em>n</em></p>
<p class="indent">The <em>modular exponentiation</em> of the <em>x</em> plaintext and <em>e</em>, the <em>public exponent</em>, compute the <em>y</em> ciphertext. The <em>n</em> denotes the modulus.</p>
<p class="indent">Decryption works in a very similar way:</p>
<p class="center"><em>x</em> = <em>y<sup>d</sup></em> mod <em>n</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_42"/>The modular exponentiation processes the <em>y</em> ciphertext with <em>d</em>, the <em>private exponent</em>, to obtain the <em>x</em> plaintext. However, the naive way of exponentiation, which means performing <em>d</em> – 1 multiplications by <em>y</em>, is completely impossible for <em>d</em> being a number with thousands of bits. You can overcome this obstacle with an algorithm called <em>square-and-multiply</em>. That algorithm basically operates bit by bit on the binary representation of the exponent. In every step, the algorithm performs a squaring operation, but if a given bit is 1, it carries out an additional multiplication, making RSA a practically usable crypto mechanism.</p>
<p class="indent">The numbers <em>n</em> and <em>e</em> are usually considered part of the public key, and <em>d</em> corresponds to the private key in RSA. Their described behavior is possible only because <em>d</em> and <em>e</em> have a special relation that is established during RSA key generation. In its first step, two large prime numbers <em>p</em> and <em>q</em> have to be chosen randomly. Their multiplication leads to the modulus <em>n</em> = <em>pq</em>. Using <em>n</em>, you can derive the result of Euler’s phi function Φ(<em>n</em>):</p>
<p class="center">Φ(<em>n</em>) = (<em>p</em> – 1)(<em>q</em> – 1) = <em>pq</em> – <em>p</em> – <em>q</em> + 1 = (<em>n</em> + 1) – (<em>p</em> + <em>q</em>)</p>
<p class="indent">This value is essential for the RSA cryptosystem and its security because the inverse relation between <em>e</em> and <em>d</em> is achieved in a group modulo Φ(<em>n</em>):</p>
<p class="center"><em>ed</em> mod Φ(<em>n</em>) = 1</p>
<p class="indent">In practice, <em>e</em> = 65537 = (10000000000000001)<sub>2</sub> is a common choice because of its shortness and the low number of 1 bits, both contributing to higher performance with the square-and-multiply algorithm. After <em>e</em> is chosen, the final step of key generation is to compute <em>d</em> as the inverse of <em>e</em> modulo Φ(<em>n</em>).</p>
<p class="indent">Knowing these details, it might become clearer why RSA is often mentioned in the same sentence with the <em>integer factorization problem</em>. This mathematical consideration suggests that finding the factors of large numbers is difficult. The modulus <em>n</em> would be such a large product. RSA is secure because it’s hard to find <em>p</em> and <em>q</em> from a given <em>n</em>. However, if someone discovers a solution to this problem, an adversary could calculate Φ(<em>n</em>) from the factorized values <em>p</em> and <em>q</em> and compute the inverse of <em>e</em> modulo Φ(<em>n</em>), and RSA would be broken.</p>
<p class="indent">Compared to symmetric schemes, the mathematical basis of the RSA cryptosystem makes it more difficult to estimate its security level. In <em>Special Publication 800-57</em> from 2020, crypto experts from NIST judged the security levels of RSA as listed in <a href="ch02.xhtml#ch02tab01">Table 2-1</a>.</p>
<p class="tabcap" id="ch02tab01"><strong>Table 2-1:</strong> Security Estimation of RSA</p>
<table class="table-h">
<colgroup>
<col style="width:50%"/>
<col style="width:50%"/>
</colgroup>
<thead>
<tr>
<th class="tab_th"><strong>Security level</strong></th>
<th class="tab_th"><strong>Key size</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="bg1">≤ 80-bit</td>
<td class="bg1">1,024-bit</td>
</tr>
<tr>
<td class="bg">112-bit</td>
<td class="bg">2,048-bit</td>
</tr>
<tr>
<td class="bg1">128-bit</td>
<td class="bg1">3,072-bit</td>
</tr>
<tr>
<td class="bg">192-bit</td>
<td class="bg">7,680-bit</td>
</tr>
<tr>
<td class="bg1">256-bit</td>
<td class="bg1">15,360-bit</td>
</tr>
</tbody>
</table>
<p class="indent"><span epub:type="pagebreak" id="page_43"/>Two important properties are obvious. The required key sizes are much longer than the achieved security level. The relation between them isn’t linear, but the security level rises significantly more slowly in comparison to the invested key bits. At the time of writing, 2,048-bit is a common setting, but for long-term usage, 4,096-bit RSA keys are recommended.</p>
<h4 class="h4" id="ch00lev2_26"><strong><em>Real-World RSA Usage</em></strong></h4>
<p class="noindent">The basic structure of RSA, however, is not perfectly suitable for practical encryption because attackers in possession of two ciphertexts would be able to create a new ciphertext that is the correct encryption of the multiplication of the two original plaintexts. The <em>Optimal Asymmetric Encryption Padding (OAEP)</em> scheme was developed to avoid this weakness. In connection with RSA, it’s called <em>RSA-OAEP</em> or <em>RSAES-OAEP</em> and is specified in NIST’s <em>Special Publication 800-56B</em>.</p>
<p class="indent">In a nutshell, OAEP uses a random string and two hash functions to process the plaintext, often a symmetric key, and generates a padded plaintext version that is subsequently used for RSA encryption. For decryption, the ciphertext is decrypted as in standard RSA, but then the initial message and random value have to be recovered by using the two hash functions mentioned before. Finally, the computation result has to be verified for its correct structure before you can use the plaintext.</p>
<p class="indent">A similar problem also exists for digital signatures with the basic RSA equations. Based on a valid signature for a specifically prepared message, attackers would be able to create a valid signature for a message of their choice. The <em>Probabilistic Signature Scheme (PSS)</em> defined as RSASSA-PSS (RSA Signature Scheme with Appendix) in RFC 3447 prevents such attacks.</p>
<p class="indent">PSS injects additional random padding into the input data of the signature scheme—namely, the hash value of the message to be signed. Again, two hash functions and a predefined encoding are necessary to generate a padded version of the message’s hash. During verification, the intermediate values have to be restored and the padding has to be checked for correctness in order to validate a signature.</p>
<h3 class="h3" id="ch00lev1_24"><strong>Diffie-Hellman Key Exchange</strong></h3>
<p class="noindent">When only symmetric cryptography was available, people had to exchange keys over <em>secure channels</em>—in person, with sealed letters, or over an already protected communication line. The process was pretty inconvenient and had several practical pitfalls.</p>
<p class="indent">Luckily, in 1976, Whitfield Diffie and Martin Hellman published their idea on how to establish a <em>shared secret</em> between two parties that are able to communicate only over an <em>insecure channel</em>, which is now commonly known as the <em>Diffie-Hellman (DH) key exchange</em>. Instead of generating a key at a specific location and then applying a <em>key-transport</em> mechanism (for example, RSA encryption), DH creates the shared key by using a <em>key-agreement</em> protocol between two entities.</p>
<h4 class="h4" id="ch00lev2_27"><span epub:type="pagebreak" id="page_44"/><strong><em>The Mathematical Beauty</em></strong></h4>
<p class="noindent">The math behind DH is based on a group <img alt="Image" class="inline" height="26" src="../images/common-01.jpg" width="23"/>, where all operations are performed modulo a prime <em>p</em> and the primitive element is denoted as <em>g</em>. <a href="ch02.xhtml#ch02fig014">Figure 2-14</a> illustrates the process of establishing a shared secret.</p>
<div class="image"><img alt="Image" height="415" id="ch02fig014" src="../images/02fig14.jpg" width="855"/></div>
<p class="figcap"><em>Figure 2-14: The steps in a Diffie-Hellman key exchange</em></p>
<p class="indent">First, both parties, commonly named Alice and Bob, choose secret numbers <em>a</em> and <em>b</em>, respectively <span class="ent">➊</span>. Then, they derive the corresponding public values <em>A</em> and <em>B</em> <span class="ent">➋</span> and exchange them <span class="ent">➌</span>. Afterward, they raise the public value of the other party to the power of their own private value <span class="ent">➍</span> to obtain the shared secret <em>k<sub>AB</sub></em>.</p>
<p class="indent">The security of DH relies on the <em>discrete logarithm problem (DLP)</em>: it’s hard to obtain <em>a</em> from <em>A</em> = <em>g<sup>a</sup></em> mod <em>p</em>. Deriving the private number <em>a</em> from the publicly transferred value <em>A</em> clearly would break the security of this protocol. However, since that’s practically impossible, attackers eavesdropping on the DH protocol don’t receive any helpful information. The achieved security level in relation to DH key sizes is practically the same as for RSA.</p>
<h4 class="h4" id="ch00lev2_28"><strong><em>Man-in-the-Middle Attacks</em></strong></h4>
<p class="noindent">This basic version of DH is also called <em>anonymous Diffie-Hellman</em> because Alice and Bob can’t verify each other’s identity. This fact can be exploited by an adversary through a <em>man-in-the-middle (MITM)</em> attack: a malicious actor intercepts the communication between the original parties, drops their exchange of public values <em>A</em> and <em>B</em>, and instead performs one DH protocol run with Alice and one with Bob. In the end, Alice and Bob think that their key agreement was successful and they can communicate securely. However, they now both share a key with the attacker, who is able to read and manipulate all information flowing between them.</p>
<p class="indent">The solution to this problem is the introduction of <em>authenticated Diffie-Hellman</em>, which is based on the assumption that Alice and Bob each have a <span epub:type="pagebreak" id="page_45"/>long-term public-key pair they can use to prove their identities to each other by exchanging digitally signed values of <em>A</em> and <em>B</em>. In this case, an MITM attacker would be unable to slip in between without being noticed. In variations of this approach, other protocol data is signed and verified, but it’s always essential to authenticate the other party before computing and using the shared secret.</p>
<p class="indent">A second property of DH is that you shouldn’t regard the values <em>a</em> and <em>b</em> as long-term keys. Reusing them for multiple key-agreement runs violates the common requirement of <em>perfect forward secrecy (PFS)</em>. This means that session keys established during a key exchange should still be secure, even if long-term keys are compromised in the future. You should consider the private numbers <em>a</em> and <em>b</em> to be <em>ephemeral keys</em> and use them only once. The corresponding version of DH is often called <em>Diffie-Hellman Ephemeral (DHE)</em>.</p>
<p class="indent">You can find details on Diffie-Hellman variants and other key-agreement schemes in NIST’s <em>Special Publication 800-56A</em>.</p>
<h3 class="h3" id="ch00lev1_25"><strong>Elliptic-Curve Cryptography</strong></h3>
<p class="noindent">RSA and DH provide many meaningful mechanisms for asymmetric cryptography, but they come with two strong downsides: long keys and significant performance demand. The field of <em>elliptic-curve cryptography (ECC)</em>, founded in 1985, promised to provide asymmetric cryptography with noticeably reduced drawbacks.</p>
<p class="indent">However, about 20 years passed before it was widely used in practice. The math behind ECC is rather complex compared to RSA and DH, and the adoption of ECC was impeded by the Certicom company, which held a series of patents that had to be licensed in case of ECC usage. Luckily, most of those patents have expired by now.</p>
<h4 class="h4" id="ch00lev2_29"><strong><em>The Math Behind the Curves</em></strong></h4>
<p class="noindent">In a nutshell, <em>elliptic curves</em> are considered to be a group of points with x- and y-coordinates—for example, denoted as <em>P</em>(<em>x</em>, <em>y</em>). The values of <em>x</em> and <em>y</em> are integers of a group modulo a prime <em>p</em>, often denoted as <em>GF</em>(<em>p</em>), a <em>Galois field</em>. The equation of an elliptic curve describes all the points that are part of it.</p>
<p class="indent">In cryptography, only a few curve equations are of practical relevance. The following is used for <em>Weierstrass curves</em> like P-256 standardized by NIST and has parameters <em>a</em> and <em>b</em>:</p>
<p class="center"><em>x</em><sup>2</sup> = <em>x</em><sup>3</sup> + <em>ax</em> + <em>b</em></p>
<p class="indent"><em>Montgomery curves</em> use parameters <em>A</em> and <em>B</em>, and they’re especially known because of the prominent member Curve25519. The following equation describes them:</p>
<p class="center"><em>By</em><sup>2</sup> = <em>x</em><sup>3</sup> + <em>Ax</em><sup>2</sup> + <em>x</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_46"/><em>Edwards curves</em>, with their parameter <em>d</em>, are another interesting type of curve, and Ed448-Goldilocks is based on it. Here’s the general equation for these curves:</p>
<p class="center"><em>x</em><sup>2</sup> + <em>y</em><sup>2</sup> = 1 + <em>dx</em><sup>2</sup><em>y</em><sup>2</sup></p>
<p class="indentb">You can process points on elliptic curves in three ways:</p>
<p class="hanga"><strong>Point addition</strong>    Add two points <em>P</em> and <em>Q</em> to obtain a new point <em>R</em> on the same curve: <em>R</em> = <em>P</em> + <em>Q</em>.</p>
<p class="hanga"><strong>Point doubling</strong>    Multiply a given point <em>P</em> by 2 to obtain a new point <em>R</em>: <em>R</em> = 2<em>P</em>.</p>
<p class="hanga"><strong>Scalar multiplication</strong>    Take a point <em>P</em> and multiply it with an integer (scalar) <em>k</em> to yield a new curve point <em>R</em>: <em>R</em> = <em>kP</em>.</p>
<p class="indentt">The scalar multiplication in ECC is similar to the modular exponentiation for RSA. Also, the naive approach to scalar multiplication, which means adding a point <em>k</em> – 1 times, is infeasible for <em>k</em> being a large number with hundreds of bits. Therefore, a similar algorithm to square-and-multiply, namely <em>double-and-add</em>, has to be used to compute it efficiently. Putting it simply, <em>k</em> is processed bit by bit, and for every bit position, a point doubling is performed. If a bit is 1, an extra point addition is executed. Altogether, this enables the practical usage of ECC crypto primitives.</p>
<p class="indent">Elliptic curves are designed in a way that the <em>elliptic-curve discrete logarithm problem (ECDLP)</em> is difficult. The name suggests that it’s similar to the DLP that’s the foundation of DH, and it is. However, in the ECC world, you can describe the problem as finding the scalar <em>k</em> given points <em>P</em> and <em>R</em> = <em>kP</em>. <a href="ch02.xhtml#ch02tab02">Table 2-2</a>, derived from NIST’s <em>Special Publication 800-57</em> from 2022, shows the striking difference of the ECDLP compared to the underlying problems of RSA and DH.</p>
<p class="tabcap" id="ch02tab02"><strong>Table 2-2:</strong> Security Estimation of ECC</p>
<table class="table-h">
<colgroup>
<col style="width:25%"/>
<col style="width:25%"/>
<col style="width:50%"/>
</colgroup>
<thead>
<tr>
<th class="tab_th"><strong>Security level</strong></th>
<th class="tab_th"><strong>Key size</strong></th>
<th class="tab_th"><strong>Key size of RSA/DH (for comparison)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="bg1">≤ 80-bit</td>
<td class="bg1">160-bit</td>
<td class="bg1">1,024-bit</td>
</tr>
<tr>
<td class="bg">112-bit</td>
<td class="bg">224-bit</td>
<td class="bg">2,048-bit</td>
</tr>
<tr>
<td class="bg1">128-bit</td>
<td class="bg1">256-bit</td>
<td class="bg1">3,072-bit</td>
</tr>
<tr>
<td class="bg">192-bit</td>
<td class="bg">384-bit</td>
<td class="bg">7,680-bit</td>
</tr>
<tr>
<td class="bg1">256-bit</td>
<td class="bg1">512-bit</td>
<td class="bg1">15,360-bit</td>
</tr>
</tbody>
</table>
<p class="indent">ECC achieves the same security level with much lower key sizes. Additionally, with increasing key lengths, the corresponding security level rises <em>linearly</em>, so doubling the curve size from 256-bit to 512-bit also leads to twice the security level.</p>
<h4 class="h4" id="ch00lev2_30"><span epub:type="pagebreak" id="page_47"/><strong><em>The Agony of Choice</em></strong></h4>
<p class="noindent">In contrast to many other cryptographic algorithms, ECC requires an implementer to choose not only a key size but also a specific elliptic curve to be used. Certain mathematical requirements have to be fulfilled by “safe” curves, which is why it’s reasonable to choose one from the common, standardized options that have undergone rigorous analysis.</p>
<p class="indent">On the other hand, a criterion that you can consider in the selection process is the origin of the curve parameters. Although the US National Security Agency (NSA) created the prime curve P-256, and the NIST standardized it in 2000, it’s one of the most popular curves in practice. Its parameter <em>b</em> is a 256-bit number, and only the NSA knows how and why it was chosen. The same is true for the other NIST curves: P-192, P-224, P-384, and P-521. It might not be a critical issue, but maybe a relevant one, for devices operating in critical infrastructures.</p>
<p class="indent">Curve25519 is currently the most popular and most trustworthy elliptic curve. It was proposed by Bernstein in 2006 and is prominent because of two properties. First, it has a strong focus on high performance in software implementations. Second, it doesn’t rely on randomly chosen or obscure curve parameters. In the future, Edwards curves like Ed448-Goldilocks and Curve41417 also might be of interest because they offer a security level above 200-bit.</p>
<h4 class="h4" id="ch00lev2_31"><strong><em>Practical Applications of ECC</em></strong></h4>
<p class="noindent">One of the most common applications of ECC is a digital signature based on the <em>Elliptic-Curve Digital Signature Algorithm (ECDSA)</em> as defined in <em>FIPS 186-5</em>. The basic setting for this use case is that two parties have agreed on a specific curve and its parameters. The signing entity holds the private key <em>d</em>, a secret integer, and the verifier has access to the corresponding public key <em>P</em> = <em>dG</em>, where <em>G</em> is the base point of the selected curve.</p>
<p class="indent">For signature generation, the signer hashes the message, chooses a random ephemeral key, and processes both together to obtain a unique signature consisting of two values with a total size of twice the curve order—for example, 512 bits, or 64 bytes, for a 256-bit curve. (The details of the verification process are rather complex and beyond the scope of this book.)</p>
<p class="indent">In general, ECDSA signatures are preferable to RSA signatures for performance and security reasons, except for a single case: if the signature verification has the highest priority, and signature generation happens only rarely—for example, when signing a firmware image once in the development process—and verification is time-critical because it happens during the device’s boot process.</p>
<p class="indent">Besides digital signatures, ECC is an inherent part of modern key-exchange and key-agreement schemes as described in NIST’s <em>Special Publication 800-56A</em>. They’re also known as <em>Elliptic-Curve Diffie-Hellman (ECDH)</em> and <em>Elliptic-Curve Diffie-Hellman Ephemeral (ECDHE)</em>. There, the modular exponentiation of DH is replaced by a scalar multiplication based on an elliptic curve. The rest is pretty similar to DH. Again, this leads to a significant <span epub:type="pagebreak" id="page_48"/>performance gain compared to classical DH, which is especially interesting when you need to perform a high number of key-agreement handshakes regularly, such as a server handling lots of connections.</p>
<p class="indent">Last but not least, you can use ECC for public-key encryption, but it’s rarely used in practice. The <em>Elliptic-Curve Integrated Encryption Scheme (ECIES)</em> is meant for exactly that purpose. In a nutshell, it uses a recipient’s public key to generate a shared ECDH secret and derives a symmetric key from it. This key is then used to encrypt a message by an AE cipher, producing a ciphertext and an authentication tag.</p>
<h3 class="h3" id="ch00lev1_26"><strong>Summary</strong></h3>
<p class="noindent">This chapter started off with crypto fundamentals like Kerckhoffs’s principle that a cryptographic key should be the only secret in a cryptosystem, followed by a discussion that security levels are merely a description of the potential search space an attacker has to face.</p>
<p class="indent">I covered the area of symmetric encryption based on the popular AES algorithm and common operation modes in detail because it’s omnipresent in security. Hash functions like SHA-256, integrity-protecting MAC algorithms, and efficient AE schemes like AES-GCM complete the modern tool-box of symmetric cryptography.</p>
<p class="indent">The introduction of asymmetric cryptography based on RSA and DH has enabled amazing possibilities to protect communication and devices: public-key encryption, digital signatures, and secure key agreements over insecure channels. Further, the field of ECC has enhanced the performance of these mechanisms significantly.</p>
<p class="indent"><em>Post-quantum cryptography</em> goes beyond the scope of this book, but it might be a topic that will challenge existing asymmetric crypto schemes in the future, and it will be inevitable if a universal quantum computer is built. NIST’s standardization process for post-quantum cryptography (<em><a href="https://csrc.nist.gov/projects/post-quantum-cryptography">https://csrc.nist.gov/projects/post-quantum-cryptography</a></em>) is still ongoing but worth following.</p>
<p class="indent">If you’re interested in learning more about the inner workings of cryptography, Jean-Philippe Aumasson’s <em>Serious Cryptography</em> (No Starch Press, 2017; second edition forthcoming) and <em>Understanding Cryptography</em> by Christof Paar and Jan Pelzl (Springer, 2009) are good resources.</p>
</div></body></html>