- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Overfitting and Underfitting
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合与欠拟合
- en: '![](Images/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/chapterart.png)'
- en: Whether we’re a person or a computer, learning general rules about a subject
    from a finite set of examples is a tough challenge. If we don’t pay enough attention
    to the details of the examples, our rules will be too general to be of much use
    when we’re considering new data. On the other hand, if we pay too much attention
    to the details in the examples, our rules will be too specific, and again we’ll
    do a bad job at evaluating new data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是人还是计算机，从有限的例子中学习一个主题的通用规则都是一个艰难的挑战。如果我们不够重视例子中的细节，我们的规则将过于笼统，以至于在处理新数据时用处不大。另一方面，如果我们过于关注例子中的细节，我们的规则就会过于具体，同样在评估新数据时效果不好。
- en: These phenomena are respectively called *underfitting* and *overfitting*. The
    more common and troublesome problem of the two is overfitting, and if unchecked,
    it can leave us with a system that’s all but useless. We control overfitting and
    rein it in with techniques known collectively as *regularization*.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这些现象分别被称为*欠拟合*和*过拟合*。其中更为常见且令人头疼的问题是过拟合，如果不加以控制，它可能会导致我们得到一个几乎无用的系统。我们通过被统称为*正则化*的技术来控制过拟合并加以遏制。
- en: In this chapter we look at the causes of overfitting and underfitting, and how
    to address them. Finally, we wrap up the chapter by seeing how to use Bayesian
    methods to fit a straight line to a bunch of data points.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将探讨过拟合和欠拟合的原因，以及如何应对这些问题。最后，我们将通过使用贝叶斯方法将一条直线拟合到一组数据点上来总结本章内容。
- en: Finding a Good Fit
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找合适的匹配
- en: When our system learns from the training data so well that it does poorly when
    presented with new data, we say that it’s *overfitting*. When it doesn’t learn
    from the training data well enough and does poorly when presented with new data,
    we say that it’s *underfitting*. Since overfitting is usually a harder problem,
    we’ll look at it first.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的系统从训练数据中学习得非常好，但在面对新数据时表现不佳时，我们称之为*过拟合*。当它没有从训练数据中学得足够好，在面对新数据时表现糟糕时，我们称之为*欠拟合*。由于过拟合通常是一个更难解决的问题，我们将首先讨论它。
- en: Overfitting
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过拟合
- en: Let’s approach our discussion of overfitting with a metaphor. Suppose we’ve
    been invited to a big open-air wedding where we know almost nobody. Over the course
    of the afternoon, we drift through the gathering guests, exchanging introductions
    and small talk. We’ve decided to make an effort to remember people’s names, so
    each time we meet someone, we make up some kind of mental association between
    their appearance and their name (Foer 2012; Proctor 1978). One of the people we
    meet is a fellow named Walter who has a big walrus mustache. We make a mental
    picture of Walter as a walrus and try to make that picture stick in our minds.
    Later, we meet someone named Erin, and we notice she’s wearing beautiful turquoise
    earrings. We make a mental picture of her earrings that have been shortened in
    one direction, so *earring* becomes *Erin*. We make a similar mental image for
    everyone we meet, and as we mingle and bump into some of the same people again,
    we remember their names with ease. The system is working great.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个比喻来讨论过拟合。假设我们被邀请参加一个大型的户外婚礼，而我们几乎不认识任何人。在整个下午的时间里，我们在聚会的客人中游走，进行介绍和寒暄。我们决定努力记住每个人的名字，因此每次遇到某人时，我们都会在他们的外貌和名字之间建立某种心理联想（Foer
    2012；Proctor 1978）。我们遇到的其中一位叫沃尔特，他有着一副大海象胡须。我们将沃尔特想象成一只海象，并试图让这个形象在脑海中留下深刻印象。之后，我们遇到一位叫艾琳的人，我们注意到她戴着美丽的绿松石耳环。我们将她的耳环想象成一个在某个方向上被缩短的形状，所以*耳环*变成了*艾琳*。我们对每一个遇到的人都做类似的心理联想，当我们再次与一些同样的人相遇时，我们轻松地记住了他们的名字。系统运作得非常好。
- en: That evening at the reception we encounter lots of new people. At one point
    we bump into someone with a big walrus mustache. We smile and say, “Hi again,
    Walter!” only to get a confused expression. This is Bob, someone we haven’t met
    before. The same thing can happen repeatedly. We might be introduced to someone
    with beautiful earrings, but this is Susan, not Erin. The problem is that our
    mental pictures have misled us. It’s not that we didn’t learn people’s names properly,
    because we did. We just learned them in a way that worked only for the people
    in the original group and didn’t generalize when we met more people.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: To associate someone’s appearance with their name, we need some kind of connection
    between the two ideas. The more robust that connection, the better we can be at
    recognizing that person in a new context, even if they’re wearing a hat or glasses
    or something else that alters their appearance. In the case of our wedding, we
    learned people’s names by connecting them to a single idiosyncratic feature. The
    problem is that when we met someone else with that same feature at the reception,
    we had no way to determine that this was someone new.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: At the pre-wedding party, we thought we were doing well because when we evaluated
    our performance using the training data (the names of people at the wedding),
    we got most of the results right. If we focused on the number of successes, we
    say that we achieved a high *training accuracy*. If we focus instead on the number
    of failures, we’d say we had a low *training error* (or *training loss*). But
    when we then went to the reception and needed to evaluate new data (the names
    of the additional people we met), our *generalization accuracy* was low, or equivalently,
    our *generalization error* (or *generalization loss*) was high.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: We saw an example of this same problem in Chapter 8, where we erroneously identified
    a husky on a couch as being a Yorkshire terrier, because we used the couch as
    our only cue for identifying the breed of the dog on it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Our errors with both people and dogs were due to overfitting. In other words,
    we learned how to classify the data in front of us, but we used specific details
    in that data, rather than learning general rules that would apply to new data
    as well.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning systems are really good at overfitting. Sometimes we say that
    they’re good at *cheating*. If there’s some quirk in the input data that helps
    the system get the correct result, it finds and exploits that quirk, like our
    story in Chapter 8 of how a system was supposed to be solving the hard problem
    of finding camouflaged tanks in photos of trees but probably was taking the easy
    way out and simply noting whether the sky was sunny or cloudy.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: We can take two actions to control overfitting. First, we can catch when the
    rules get too specific and stop the learning process at that moment. Second, using
    *regularization* methods, we can delay the onset of overfitting by encouraging
    the system to keep learning general rules as long as possible. We’ll look at each
    approach in a moment.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以采取两种措施来控制过拟合。首先，我们可以在规则过于具体时停止学习过程。其次，通过使用*正则化*方法，我们可以通过鼓励系统尽可能长时间地学习一般规则来推迟过拟合的发生。稍后我们将分别讨论这两种方法。
- en: Underfitting
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 欠拟合
- en: The opposite of overfitting is underfitting. In contrast to overfitting, which
    results from using rules that are too precise, underfitting describes the situation
    when our rules are too vague or generic. At the wedding party, we might underfit
    by creating a rule that says, “people wearing pants are named Walter.” Although
    this is accurate for one particular piece of data, this rule is not going to generalize
    well!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合的对立面是欠拟合。与过拟合不同，过拟合是由于使用了过于精确的规则，欠拟合描述的是当我们的规则过于模糊或通用时的情况。在婚礼聚会上，我们可能会通过创建一个规则来欠拟合：“穿裤子的人叫沃尔特”。虽然这对于某一特定数据是准确的，但这个规则并不能很好地推广！
- en: Underfitting is usually much less of a problem in practice than overfitting.
    We can often cure underfitting just by using more training data. With more examples,
    the system can work out better rules for understanding each piece of data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与过拟合相比，欠拟合在实际中通常不是一个大问题。我们通常可以通过使用更多的训练数据来解决欠拟合问题。通过更多的示例，系统可以为每一条数据找到更好的理解规则。
- en: Detecting and Addressing Overfitting
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测和解决过拟合
- en: How do we know when we’ve started to overfit our data? Suppose that we’re using
    a validation set to estimate a system’s generalization error after each epoch
    (when we’re done training, as usual, we use the one-time test set to get a more
    reliable generalization error). The error made by the system in response to the
    validation data is called the *validation error*. It’s an estimate of the errors
    the system will make when it’s deployed, which is called the *generalization error.*
    When the validation error flattens out, or starts to become worse, while the training
    error is improving, we’re overfitting. That’s our cue to stop learning. [Figure
    9-1](#figure9-1) shows the idea visually.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们怎么知道何时开始过拟合数据呢？假设我们使用验证集在每个训练周期后估计系统的泛化误差（像往常一样，当我们完成训练时，我们使用一次性测试集来获得更可靠的泛化误差）。系统对验证数据产生的误差称为*验证误差*。它是系统部署时将产生的误差的估计，这称为*泛化误差*。当验证误差趋于平稳或开始变得更糟，而训练误差在改善时，我们就出现了过拟合。这是我们停止学习的信号。[图
    9-1](#figure9-1)形象地展示了这一点。
- en: '![F09001](Images/F09001.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![F09001](Images/F09001.png)'
- en: 'Figure 9-1: The training and validation errors both go down steadily near the
    start of training, but after a certain point, the validation error starts to increase
    while the training error continues to decrease, signaling overfitting.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-1：训练误差和验证误差在训练初期都稳步下降，但在某个节点之后，验证误差开始上升，而训练误差继续下降，标志着过拟合的发生。
- en: In [Figure 9-1](#figure9-1), note that the training error continues to decreaseas
    we move into the zone of overfitting, where the validation error is going up.
    That’s because we’re still learning from the training data, but now we’re learning
    information specific to that data, rather than general rules. It’s the performance
    on the validation set that lets us see that this is happening, because our validation
    error (estimating our generalization error) is getting worse. The longer we train
    like this, the worse our system will perform when we deploy it.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 9-1](#figure9-1)中，请注意，随着我们进入过拟合区域，训练误差继续下降，而验证误差开始上升。这是因为我们仍然在从训练数据中学习，但现在我们学到的是特定于该数据的信息，而不是一般规则。正是验证集上的表现让我们看到了这一点，因为我们的验证误差（估算我们的泛化误差）在变得更糟。我们这样训练的时间越长，系统在部署时的表现就会越差。
- en: Let’s see this in action. Suppose that a store’s owner subscribes to a service
    that provides her with background music. The company provides a variety of streams
    with music at different tempos, and they’ve given her a control that lets her
    choose the tempo of the music at any time. Rather than setting the tempo once
    at the start of the day and forgetting about it, she’s been finding herself adjusting
    it frequently through the day, and it’s become a distracting chore. She’s hired
    us to build a system that automatically adjusts the music throughout the day,
    the way she wants it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个实际应用。假设某家商店的店主订阅了一项背景音乐服务。该公司提供了多种不同节奏的音乐流，并且提供了一个控制器，允许店主随时选择音乐的节奏。她并非每天早上设定好节奏后就不再理会，而是发现自己在一天中频繁调整节奏，这变成了一项令人分心的琐事。于是，她聘请了我们为她建立一个系统，自动根据她的需求调整一天中的音乐。
- en: The first step is to gather data. So, the next morning, we sit across from the
    controls and watch. Each time she adjusts the tempo, we note the time and new
    setting. Our collected data are shown in [Figure 9-2](#figure9-2).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是收集数据。第二天早上，我们坐在控制器前观察。每次她调整节奏时，我们记录下时间和新的设置。我们收集的数据如[图9-2](#figure9-2)所示。
- en: '![F09002](Images/F09002.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![F09002](Images/F09002.png)'
- en: 'Figure 9-2: Our recorded data shows the tempo chosen by our store owner each
    time she adjusted it during the day.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-2：我们记录的数据展示了店主在一天中每次调整节奏时所选择的节奏。
- en: Back in our labs that evening, we fit a curve to the data, as in [Figure 9-3](#figure9-3).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 那天晚上，我们回到实验室，将曲线拟合到数据中，如[图9-3](#figure9-3)所示。
- en: '![F09003](Images/F09003.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![F09003](Images/F09003.png)'
- en: 'Figure 9-3: A curve to fit to the data of [Figure 9-2](#figure9-2)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-3：一条适合[图9-2](#figure9-2)数据的曲线
- en: This curve is very wiggly, but we might reason that it’s a good solution, because
    it does a good job of matching her recorded choices. The next morning, we program
    the system to follow this pattern. By the middle of the afternoon the owner is
    complaining because the tempo of the music is changing too often and too dramatically.
    It’s distracting her customers.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这条曲线非常弯曲，但我们可能会推测它是一个好的解决方案，因为它很好地匹配了她记录的选择。第二天早上，我们编程让系统按照这个模式进行。到下午中时，店主抱怨音乐的节奏变化得太频繁且太剧烈，分散了顾客的注意力。
- en: This curve is overfitting the data as a result of matching the observed values
    too precisely. Her choices on the day we measured the data were based on the particular
    songs that were playing on that day. Because the service doesn’t play the same
    songs at the same time every day, we don’t want to reproduce the data from that
    one day’s observations so closely. By accommodating every bump and wiggle, we’re
    paying too much attention to the idiosyncrasies in the training data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这条曲线过度拟合了数据，因为它过于精确地匹配了观察到的数值。我们测量数据的那天，她的选择是基于当天播放的特定歌曲。由于服务并不是每天在同一时间播放相同的歌曲，我们不希望如此紧密地重现那一天的观测数据。通过适应每一个波动和曲线，我们过分关注了训练数据中的个性化特征。
- en: It would be great if we could watch her choices for several more days and use
    all of that data to come up with a more general plan, but she doesn’t want us
    taking up room in her store again. The data we have is all we’re going to get.
    We want a schedule with less variation, so the next night we reduce the accuracy
    of our match to the data. We aim for something that doesn’t jump around as much
    as before and get the gentle curve of [Figure 9-4](#figure9-4).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能再观察她的选择几天，并利用所有这些数据制定一个更通用的计划，那就太好了，但她不希望我们再次占用她店里的空间。我们拥有的数据就是我们能得到的全部。我们希望制定一个变化较小的计划，所以第二天晚上我们减少了与数据匹配的精确度。我们的目标是做出一个不像之前那样波动太大的计划，得到如[图9-4](#figure9-4)所示的平滑曲线。
- en: '![F09004](Images/F09004.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![F09004](Images/F09004.png)'
- en: 'Figure 9-4: A gentle curve for matching our tempo data'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-4：用于匹配我们节奏数据的平滑曲线
- en: We find the next day that our client still isn’t satisfied because this curve
    is much too coarse and ignores important features like her desire to use slower
    tempos in the morning and more upbeat songs in the afternoon. This curve is underfitting
    the data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们第二天发现，客户仍然不满意，因为这条曲线太粗糙，忽略了重要的特征，比如她早上希望使用较慢的节奏，下午则希望使用更有活力的歌曲。这条曲线未能很好地拟合数据。
- en: What we want is a solution that’s not trying to match all of the data exactly
    but is getting a good feeling for the general trends. We want something that’s
    not too precise a match, or too loose, but “just right.” The next day, we set
    up the system according to the curve in [Figure 9-5](#figure9-5).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要的是一个不试图精确匹配所有数据，而是能够很好地把握总体趋势的解决方案。我们希望这个解决方案既不会过于精确，也不会过于松散，而是“恰到好处”。第二天，我们根据[图9-5](#figure9-5)中的曲线设置了系统。
- en: '![F09005](Images/F09005.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![F09005](Images/F09005.png)'
- en: 'Figure 9-5: A curve that matches our tempo data well enough, but not too well'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-5：一条足够匹配我们的节奏数据的曲线，但又不至于过度匹配
- en: Our client is happy with this curve and the tempos of the songs it chooses over
    the day. We’ve found a good compromise between underfitting and overfitting. In
    this example, finding the best curve was a matter of personal taste, but later
    on we’ll see algorithmic ways to find this sweet spot between underfitting and
    overfitting.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的客户对这条曲线和它选择的歌曲节奏感到满意。我们在欠拟合和过拟合之间找到了一个很好的折衷。在这个例子中，找到最佳曲线是个人品味的问题，但稍后我们将看到一些算法方法，帮助我们找到欠拟合和过拟合之间的最佳平衡点。
- en: '[Figure 9-6](#figure9-6) shows another example of overfitting, this time in
    classifying two categories of two-dimensional (2D) points.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9-6](#figure9-6)展示了另一个过拟合的例子，这次是在对二维（2D）点进行分类时出现的。'
- en: '![F09006](Images/F09006.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![F09006](Images/F09006.png)'
- en: 'Figure 9-6: A likely case of overfitting. (Inspired by Bullinaria 2015.)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-6：一个可能的过拟合情况。（灵感来源于Bullinaria 2015。）
- en: On the left side of [Figure 9-6](#figure9-6), we have one circular point deep
    in square territory, resulting in a complicated boundary curve. We call this kind
    of isolated point an *outlier*, and it’s natural to treat it with suspicion. Maybe
    this is the result of a measuring or recording error, or maybe it’s just one very
    unusual piece of perfectly valid data. Getting more data would give us a better
    sense of which case describes this oddity, but if all we have is this one set
    of data to work with, we need to decide what to do. By drawing the boundary to
    accommodate this one data point, we risk misclassifying some future data points
    as blue circles, even though they were solidly inside the brown square region,
    because they landed on the blue side of this strange boundary curve. It might
    be better to prefer a simpler curve like that on the right of [Figure 9-6](#figure9-6),
    and accept this one point as an error.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图9-6](#figure9-6)的左侧，我们看到一个圆形点位于正方形区域的深处，导致了一个复杂的边界曲线。我们称这种孤立的点为*异常点*，并且自然会对它保持怀疑态度。也许这是由于测量或记录错误造成的，或者这只是一个非常不寻常但完全有效的数据点。获取更多的数据可以帮助我们更好地理解这种异常现象的情况，但如果我们只有这一组数据，我们需要决定如何处理它。通过绘制边界来适应这个数据点，我们有可能错误地将一些未来的数据点归类为蓝色圆形，尽管它们实际上位于棕色正方形区域内部，因为它们落在了这个奇怪的边界曲线的蓝色一侧。也许更好的做法是选择[图9-6](#figure9-6)右侧的简单曲线，并接受这个点为一个错误。
- en: Now that we’ve seen what overfitting looks like, let’s look at how we can prevent
    it from happening.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了过拟合的样子，让我们看看如何防止它的发生。
- en: Early Stopping
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 早期停止
- en: Generally speaking, when we start training our model, we are underfitting. The
    model won’t have seen enough examples yet to figure out how to handle them properly,
    so its rules are general and vague.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，当我们开始训练模型时，通常是欠拟合的。模型还没有看到足够的例子来弄清楚如何正确处理它们，因此它的规则是广泛和模糊的。
- en: As we train more and the model refines its boundaries, the training and validation
    errors both typically drop. To discuss this, let’s repeat [Figure 9-1](#figure9-1)
    for convenience here as [Figure 9-7](#figure9-7).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 随着训练的进行，模型不断调整边界，训练误差和验证误差通常都会下降。为了方便讨论，我们在这里重复[图9-1](#figure9-1)，作为[图9-7](#figure9-7)。
- en: '![F09007](Images/F09007.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![F09007](Images/F09007.png)'
- en: 'Figure 9-7: A repeat of [Figure 9-1](#figure9-1) for convenience'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-7：为了方便起见，重复[图9-1](#figure9-1)
- en: At some point, we’ll find that although the training error is continuing to
    drop, the validation error is starting to rise (it may go flat for a while first).
    Now we’re overfitting. The training error is dropping because we’re getting more
    and more details right. But we’re now tuning our results too much to the training
    data, and the generalization error (or its estimate, the validation error) is
    going up.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个时刻，我们会发现，虽然训练误差持续下降，但验证误差开始上升（可能首先会保持平稳一段时间）。现在我们进入了过拟合阶段。训练误差在下降，因为我们越来越多地正确地处理了细节。但我们现在过度调整了结果，以适应训练数据，导致泛化误差（或其估计值——验证误差）上升。
- en: 'From this analysis we can come up with a good guiding principle: *when we start
    overfitting, stop training*. That is, when we get to around 28 epochs in [Figure
    9-7](#figure9-7), and we find that the validation error is going up even as training
    error is dropping, we should stop training. This technique of ending training
    just as the validation error starts to rise is called *early stopping*, since
    we’re stopping our training process before the training error has reached zero.
    It may be helpful to think of this idea as *last-minute stopping*, since we’re
    training for as long as we can, only stopping when we’ve found the best representation
    of our data without overfitting.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个分析中，我们可以得出一个好的指导原则：*当我们开始过拟合时，停止训练*。也就是说，当我们在[图 9-7](#figure9-7)中达到大约28个epoch，并且发现验证误差开始上升，而训练误差仍在下降时，我们应该停止训练。这种在验证误差开始上升时结束训练的技巧叫做*提前停止*，因为我们在训练误差尚未降到零时就停止了训练过程。把这个想法称为*最后时刻停止*可能更有帮助，因为我们尽可能地训练，直到找到没有过拟合的最佳数据表示，然后才停止训练。
- en: In practice, our error measurements are rarely as smooth as the idealized curves
    in [Figure 9-7](#figure9-7). They tend to be noisy and may even go the “wrong”
    way for short periods, so it can be hard to find the exact right place to stop.
    Most library functions for early stopping offer a few variables that let us tell
    them to implicitly smooth out these error curves so they can detect when the validation
    error really is rising and not just experiencing a momentary increase.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们的误差测量通常不像[图 9-7](#figure9-7)中的理想曲线那样平滑。它们往往会有噪声，甚至可能在短时间内出现“错误”的变化方向，因此很难找到完全正确的停止时机。大多数用于提前停止的库函数都提供了几个变量，允许我们让它们隐式地平滑这些误差曲线，以便在验证误差真正上升时能检测到，而不是仅仅经历短暂的增加。
- en: Regularization
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 正则化
- en: We always want to squeeze as much information as we can out of our training
    data, stopping just short of overfitting. Early stopping ends learning when the
    validation error starts rising, but what if there was a way to delay that phenomenon,
    so we can train longer and continue to push down both training and validation
    errors?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们总是希望尽可能从训练数据中提取信息，直到接近过拟合为止。提前停止在验证误差开始上升时结束学习，但如果有办法延迟这一现象，让我们可以训练更久，并继续降低训练误差和验证误差呢？
- en: By analogy, consider cooking a turkey in the oven. If we just put the turkey
    in a pan and cook it on high heat, the outside eventually starts to burn. But
    say we want to cook the turkey for longer, without burning it. One way to do this
    is to wrap it in aluminum foil. The foil delays the onset of burning, letting
    us cook the turkey for longer.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 类比来说，考虑在烤箱里烤火鸡。如果我们只是将火鸡放在一个锅里，并用高温烹饪，它的外部最终会烧焦。但假设我们想要把火鸡烤得更久，而又不想让它烧焦。一个方法是将其包裹在铝箔中。铝箔延缓了烧焦的发生，使我们可以烤得更久。
- en: The techniques that delay the onset of overfitting are collectively known as
    *regularization methods*, or simply *regularization*. Remember that the computer
    doesn’t know that it’s overfitting. When we ask it to learn from the training
    data, it learns from that data as well as it can. It doesn’t know when it crosses
    the line from “good knowledge of the input data” to “overly specific knowledge
    of this particular input data,” so it’s up to us to manage the issue.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟过拟合发生的技术统称为*正则化方法*，或简称*正则化*。请记住，计算机并不知道它正在过拟合。当我们要求它从训练数据中学习时，它会尽可能地从数据中学习。它并不知道何时从“对输入数据的良好理解”跨越到“对这个特定输入数据的过度特定理解”，所以管理这个问题完全由我们来处理。
- en: A popular way to perform regularization, or delay the start of overfitting,
    is to limit the values of the parameters used by the classifier. Conceptually,
    the core argument for why this staves off overfitting is that by keeping all of
    the parameters to small numbers, we prevent any one of them from dominating (Domke
    2008). This makes it harder for the classifier to become dependent on specialized,
    narrow idiosyncrasies.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的正则化方法，或者说延迟过拟合开始的方法，是限制分类器所使用的参数的值。从概念上讲，为什么这种方法能够延迟过拟合的核心理由是，通过将所有参数的值保持在较小的数字范围内，我们防止了任何一个参数占主导地位（Domke
    2008）。这使得分类器不容易依赖于特殊的、狭窄的特征。
- en: To see this, think back to our example of remembering people’s names. When we
    memorized the name of Walter, who wore a walrus mustache, that one piece of information
    dominated everything else we remembered. The other facts we could have learned
    from looking at him included that he was a man, he was almost six feet tall, he
    had long gray hair, he had a big smile and a low voice, he wore a dark-red shirt
    with brown buttons, and so on. But instead, we focused on his mustache, and ignored
    all these other useful cues. Later, when we saw a completely different person
    with a walrus mustache, that one feature dominated all the others and we mistook
    that person for Walter.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一点，回想一下我们记住人名的例子。当我们记住了沃尔特这个名字时，他有一副海象胡子，这个信息主导了我们记住的所有其他信息。我们还可以从他的外貌中学到其他的事实，比如他是个男性，身高接近六英尺，长着灰色的长发，有着大大的微笑和低沉的声音，穿着一件深红色的衬衫，扣子是棕色的，等等。但相反，我们专注于他的胡子，忽略了其他所有有用的线索。后来，当我们看到另一个拥有海象胡子的完全不同的人时，那一特征主导了其他所有特征，我们把那个人误认为是沃尔特。
- en: If we force all of the features we notice to have values in roughly the same
    range, then “has a walrus mustache” doesn’t get the chance to dominate, and the
    other features continue to matter when we remember the name of a new person. Regularization
    techniques make sure that no one parameter, or no small set of parameters, dominates
    all the others.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们强制要求我们注意到的所有特征都在大致相同的范围内，那么“有海象胡子”就不会有机会主导，其他特征在我们记住新人的名字时仍然会发挥作用。正则化技术确保没有任何一个参数，或者一小组参数，能够主导其他所有参数。
- en: Note that we’re not trying to set all the parameters to the *same* value, which
    would make them useless. We’re just trying to make sure they’re all in roughly
    the same range. Pushing the parameters down to small values allows us to learn
    longer and extract more information from our training data before overfitting
    occurs.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们并不是试图将所有参数设置为*相同*的值，这样会使它们变得毫无用处。我们只是想确保它们都在大致相同的范围内。将参数推到较小的值可以让我们学习更长时间，并在发生过拟合之前从训练数据中提取更多信息。
- en: The best amount of regularization to apply varies from one learner and dataset
    to the next, so we usually have to try out a few values and see what works best.
    We specify the amount of regularization to apply with a hyperparameter that’s
    traditionally written as a lowercase Greek λ (lambda), though sometimes other
    letters are used. Most commonly, larger values of λ mean more regularization.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 应用正则化的最佳量因学习器和数据集的不同而有所变化，因此我们通常需要尝试几个值，看看哪一个最有效。我们通过一个超参数来指定应用的正则化量，传统上这个超参数写作小写希腊字母λ（lambda），不过有时也使用其他字母。通常来说，较大的λ值意味着更多的正则化。
- en: Keeping the parameter values small also usually means that the classifier’s
    boundary curves don’t get as complex and wiggly as they otherwise could. We can
    use the regularization parameter λ to choose how complex we want our boundary
    to be. High values give us smooth boundaries, whereas low values let the boundary
    fit more precisely to the data it’s looking at.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 保持参数值较小通常意味着分类器的边界曲线不会像它本来可能那样复杂和波动。我们可以使用正则化参数λ来选择我们希望边界有多复杂。较高的值给我们平滑的边界，而较低的值让边界更加精确地拟合它所看的数据。
- en: In later chapters we’ll work with learning architectures that have multiple
    layers of processing. Such systems can use additional, specialized regularization
    techniques called *dropout*, *batchnorm*, *layer norm*, and *weight regularization*
    that can help control overfitting on those types of architectures. All of these
    methods are designed to prevent any elements of the network from dominating the
    results.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在后面的章节中，我们将处理具有多层处理结构的学习架构。这些系统可以使用额外的、专门的正则化技术，如*dropout*、*batchnorm*、*layer
    norm*和*weight regularization*，这些技术有助于控制这些类型架构的过拟合。所有这些方法的设计目的是防止网络的任何元素主导最终结果。
- en: Bias and Variance
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏差与方差
- en: The statistical terms *bias* and *variance* are intimately related to underfitting
    and overfitting, and often they come up when those topics are discussed. We can
    say that bias measures the tendency of a system to consistently learn the wrong
    things, and variance measures its tendency to learn irrelevant details (Domingos
    2015). Another way to think of these is that a large amount of bias means that
    a system is prejudiced toward a particular kind of result, and a large amount
    of variance means that the answers returned by the system are too specific to
    the data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: We’re going to take a graphical approach to these two ideas by discussing them
    in terms of 2D curves. These curves might be the solutions to a regression problem,
    like our earlier task of setting the tempo for a store’s background music over
    time. Or the curves could be the boundary curves between two regions of the plane,
    as in a classification problem. The ideas of bias and variance are not limited
    to any one type of algorithm, or to 2D data. But we’ll stick to 2D curves because
    we can draw and interpret them. Let’s focus on finding a good fit to an underlying
    noisy curve and see how the ideas of bias and variance let us describe how our
    algorithms behave.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Matching the Underlying Data
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s suppose that an atmospheric researcher friend of ours has come to us for
    some help. She’s measured the wind speed at a certain spot at the top of a mountain,
    at the same time, every day, for several months. Her measured data is in [Figure
    9-8](#figure9-8).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '![F09008](Images/F09008.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-8: Wind speed over time as measured by an atmospheric scientist. In
    this data there’s a clear underlying curve, but there’s also plenty of noise (base
    curve inspired by Macskassy 2008).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: She believes that the data she’s measured is the sum of an *idealized curve*,
    which is the same from year to year, and *noise*, which accounts for unpredictable
    day-to-day fluctuations. The data she measured is called a *noisy curve*, since
    it’s the sum of the idealized curve and the noise. [Figure 9-9](#figure9-9) shows
    the idealized curve and the noise that, when added together, make [Figure 9-8](#figure9-8).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '![F09009](Images/F09009.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-9: The data from [Figure 9-8](#figure9-8) split into two pieces. Left:
    The underlying “idealized” curve we seek. Right: The noise that nature added to
    the idealized curve to give us the noisy, measured data. Note that the two graphs
    have different vertical scales.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Our atmospheric researcher believes that she has a good model for describing
    the noise (maybe it follows the uniform or Gaussian distributions we saw in Chapter
    2). But her description of the noise is statistical, so she can’t use it to fix
    her day-to-day measurements. In other words, if she knew the exact values of the
    noise on the right of [Figure 9-9](#figure9-9), she could subtract them from the
    measurements in [Figure 9-8](#figure9-8) to get at her goal, the clean curve on
    the left of [Figure 9-9](#figure9-9). But she doesn’t know those noise values.
    She has a statistical model that can generate lots of curves like those on the
    right of [Figure 9-9](#figure9-9), but she doesn’t have the specific values that
    correspond to her data.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Here’s one approach to cleaning up the noisy data. We can go back to the noisy
    data in [Figure 9-8](#figure9-8) and try to fit a smooth curve to it (Bishop 2006).
    By choosing the complexity of the curve to be wiggly enough to follow the data,
    but not so wiggly that it tries to match each point exactly, we hope to get a
    pretty fair match to the general shape of the curve, which is a good starting
    point for finding the underlying smooth curve.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways to fit a smooth curve to noisy data. [Figure 9-10](#figure9-10)
    shows one such curve. The little wiggle at the right end is typical of the sort
    of curve we used, which tends to jump around a bit near the edges of the dataset.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: That doesn’t look too far off. But can we do better?
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Let’s apply the ideas of bias and variance to the problem of finding the idealized
    curve. The idea is inspired by the method of bootstrapping that we discussed in
    Chapter 2, but we won’t actually use the bootstrapping technique.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '![F09010](Images/F09010.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-10: Fitting our noisy data with a curve using a curve-fitting algorithm'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Let’s make 50 versions of the original noisy data, but each version contains
    just 30 points selected randomly, without replacement. The first five of these
    reduced datasets are shown in [Figure 9-11](#figure9-11).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '![F09011](Images/F09011.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-11: Five of the 50 smaller versions of our noisy starting data. Each
    version consists of 30 samples chosen from the original data without replacement.
    These are the first five versions, with the chosen points shown as green dots,
    and the original, noisy data shown in gray for reference.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try matching each of these sets of points with simple curves and then
    complex curves, and compare the results in terms of bias and variance.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: High Bias, Low Variance
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ll first fit our data with simple, smooth curves. Because we’ve selected
    these qualities ahead of time, we expect that all of our resulting curves will
    look about the same. The curves that fit our five sets of data in [Figure 9-11](#figure9-11)
    are shown in [Figure 9-12](#figure9-12).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '![F09012](Images/F09012.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-12: Fitting simple curves to our first five sets of points in [Figure
    9-11](#figure9-11)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: As expected, the curves are all simple and similar. Because these curves are
    very similar to one another, we say that this collection of curves is showing
    a *high bias*. The *bias* here refers to the predetermined preference for a simple
    shape. Because the curves are so simple, each one lacks the flexibility to pass
    through more than a few of its points at the most.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: The *variance* refers to how much the curves vary, or differ, from one to the
    next. To see the variance of these high-bias curves, we can draw all 50 curves
    on top of one another, as in [Figure 9-13](#figure9-13).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '![F09013](Images/F09013.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-13: The curves for all 50 of our 30-point samples from the original
    data, overlaid on one another'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: As expected, the curves are quite similar. We say that they demonstrate low
    variance.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: To sum up, this collection of curves has a high bias, because they all have
    about the same shape, and a low variance, because the individual curves aren’t
    being influenced much by the data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Low Bias, High Variance
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now let’s try reducing our constraint that the curves need to be simple. That
    lets us fit complex curves to our data, so that each one comes closer to matching
    its green points. [Figure 9-14](#figure9-14) shows these curves applied to our
    first five sets of data. Compared to [Figure 9-12](#figure9-12), these curves
    are much wigglier, with multiple hills and valleys. Though they still don’t pass
    directly through too many points, they come a lot closer to them.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '![F09014](Images/F09014.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-14: The complex curves created for the first five sets of points from
    our noisy data'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Since the shapes of these curves are more complex and flexible, they’re more
    influenced by the data than by any starting assumptions. Because we are placing
    fewer constraints on the curve shapes, we say that the collection has *low bias*.
    On the other hand, they’re quite different from one another. We can see this by
    drawing all 50 curves on top of one another, as shown in [Figure 9-15](#figure9-15).
    Because the curves veer off wildly at the start and end, we also show an expanded
    vertical scale that covers those big swings.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![F09015](Images/F09015.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-15: The complex curves fit to our 50 sets of data. The plot on the
    right shows the entire vertical scale of the curves.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: These curves don’t all follow the same shape, so they have low bias. Furthermore,
    they are quite different from one another, and each is strongly influenced by
    its data, so the collection has *high variance*.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Comparing Curves
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s recap our curve fitting experiment so far.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Our atmospheric scientist asked us for a curve that matches the underlying idealized
    curve in her data. We created 50 small sets of points, randomly extracted from
    her original, noisy data. When we fit simple, smooth curves to those sets of points,
    the curves consistently missed most of the data points. That set of curves had
    a high bias, or a predisposition to a particular result (smooth and simple). The
    curves were not much influenced by the data they were intended to match, so that
    set of curves had a low variance.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, when we fit complex and wiggly curves to these sets of points,
    the curves were able to fit to the data and came much closer to most of the points.
    Because they were influenced more by the data than by any predisposition to a
    particular shape, that set of curves had a low bias. But the adaptability of the
    curves means that they were all significantly different from one another. In other
    words, that set of curves had a high variance.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: So, the first set had high bias and low variance, and the second set has low
    bias and high variance.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, we’d like curves with a low bias (so we’re not imposing our preconceived
    ideas on their possible shapes), and low variance (so our different curves all
    create roughly the same match to the original, noisy data). Unfortunately, in
    most real situations, as either measure goes down, the other goes up. This means
    it’s up to us to find the best *bias-variance tradeoff* for each specific situation.
    We’ll come back to this issue in a moment.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Notice that bias and variance are properties of *families*, or collections,
    of curves. It doesn’t make sense to discuss the bias and variance of a single
    curve. Bias and variance often come up in machine learning discussions as ways
    to describe the complexity or power of a model or algorithm.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: We can now see how bias and variance help us describe underfitting and overfitting.
    In the beginning of training, as the system tries to find the right way to represent
    the training data, it’s producing general rules, or underfitting. If these rules
    are boundaries between classes of data, they have the form of curves. If we train
    on multiple similar but different datasets, we’ll see curves that are simple in
    shape and like one another. That is, they have high bias and low variance.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Later in training, the curves for each dataset are more complicated. There are
    fewer preconditions on their shape, so they have low bias, and they can closely
    match the training data, so they have high variance. When we let a system train
    for too long, the high-variance curves start following the input data too tightly,
    causing overfitting.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 9-16](#figure9-16) shows the tradeoff of bias and variance graphically.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '![F09016](Images/F09016.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-16: Top row: Four curves we’d like to match. Middle row: Using curves
    with high bias and low variance. Bottom row: Curves with low bias and high variance.
    The far-right image in the bottom two rows shows the four curves superimposed.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: In the middle row, high bias gives us nice, simple curves (which avoid overfitting),
    but their low variance means they can’t match the data very well. In the bottom
    row, low bias lets the curves better match the data, but their high variance means
    that the curves can match too well (which risks overfitting).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: In general, neither bias nor variance is inherently better or worse than the
    other, so we shouldn’t always be tempted to find, say, the solution with the lowest
    possible bias or variance. In some applications, high bias or high variance may
    be acceptable. For instance, if we know that our training set is absolutely representative
    of all future data, then we don’t care about the variance and instead aim for
    the lowest possible bias, since matching that training set perfectly is just what
    we want. On the other hand, if we know that our training set is not a good representative
    of future data (but it’s the best we have at the moment), we may not care about
    bias, since matching this lousy dataset isn’t important, but we want the lowest
    variance we can get so that we have the best chance of at least doing something
    reasonable on future data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: In general, we need to find the right balance between these two measures in
    a way that works best for the goals of any particular project, given the specific
    algorithm and data we’re working with.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Fitting a Line with Bayes’ Rule
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bias and variance are a useful way to characterize how well a family of curves
    fits their data. Recalling our discussion of the frequentist and Bayesian philosophies
    from Chapter 4, we can say that bias and variance are inherently frequentist ideas.
    That’s because the notions of bias and variance rely on drawing multiple values
    from a source of data. We don’t rely too much on any single curve. Instead, we
    use averaging of all the curves to find the “true” answer that each curve approximates.
    Those ideas fit the frequentist approach very well.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: By contrast, the Bayesian approach to fitting data asserts that the results
    can only be described in a probabilistic way. We list out all the ways to match
    our data that we think are possible and attach a probability to each one. As we
    gather more data, we gradually eliminate some of those descriptions and thereby
    make the remaining ones more probable, but we never get to a single, absolute
    answer.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see this in practice. Our discussion is based on a visualization from
    *Pattern Recognition and Machine Learning* (Bishop 2006). We’ll use Bayes’ Rule
    to find a nice approximation of the noisy data atmospheric data we saw in [Figure
    9-8](#figure9-8). Rather than fit a complicated curve to our data, we restrict
    ourselves to straight lines. That’s only because doing so lets us show everything
    with 2D plots and diagrams. In fact, we stick to lines that are *mostly horizontal*.
    Again, this is just so we can draw nice diagrams that don’t require higher dimensions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The method for curve fitting with Bayes’ Rule can use complex curves, or sheets
    in space, or even shapes with hundreds of dimensions. We will use straight lines
    that are mosty horizontal only because that choice keeps the pictures simple.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: We’ll be working with multiple lines at once, so it would be great to find a
    compact way to represent different groups of lines without drawing them all.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: The trick will be to describe every line with two numbers. The first tells us
    how much the line is tilted from being perfectly horizontal, which gives us a
    line in any orientation. The second number tells us how much to move the line
    up and down.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: The first number is the *slope*. A horizontal line has a slope of 0\. As the
    line rotates clockwise, as in [Figure 9-17](#figure9-17), the slope increases.
    As the line rotates counterclockwise, the slope decreases.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: When the line is perfectly diagonal, the slope is either 1 or –1\. As it rotates
    to steeper orientations, the slope increases quickly until it reaches infinity
    for a perfectly vertical line. We can take steps to avoid this problem, but it
    only makes the discussion more complicated. So for the sake of simplicity, we
    will limit our attention to lines that have a slope between –2 and 2, which lie
    in the green zone in [Figure 9-17](#figure9-17).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '![f09017](Images/f09017.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-17: A horizontal line has a slope of 0\. As the line rotates counterclockwise,
    the slope increases. As it rotates clockwise, the slope decreases. We will only
    use lines with slopes that fall in the light-green region.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: The second number that describes a line is the *Y intercept*. This merely moves
    the whole line up or down as a whole. This number tells us the value of the line
    when X is zero. In other words, it’s the value of the line as it crosses, or intercepts,
    the Y axis. [Figure 9-18](#figure9-18) illustrates the idea. Again for simplicity
    we’ll restrict our focus to lines with a Y intercept in the range [–2, 2], tinted
    green in [Figure 9-18](#figure9-18).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '![f09018](Images/f09018.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-18: The Y intercept tells us the Y value of the line when it crosses
    the Y axis, regardless of its slope. We’ll just use lines that have a Y intercept
    between –2 and 2.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Given any line, we can measure its orientation to get a value for its slope,
    and observe where it crosses the Y axis to get the value of the Y intercept. That’s
    everything we need to describe the line. We can show this as a point in a new
    2D grid where the axes are labeled *slope* and *Y intercept*. Let’s call this
    an *SI* diagram, standing for slope-intercept. A normal diagram will be just an
    XY diagram. We can also say that the SI diagram plots lines in *SI space*, and
    the XY diagram shows lines in *XY space*(also called *Cartesian space*).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 9-19](#figure9-19) shows a few lines in both XY and SI diagrams.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Mathematicians call these two ways of looking at the same thing a *dual representation*,
    and there’s a lot to be said about such things. We’ll stick to just what we need
    for our discussion of fitting a line using Bayes’ Rule.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '![f09019](Images/f09019.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-19: Left: Three lines in XY space. Right: Each line drawn as a dot
    in SI space.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Something interesting happens when we arrange a set of points in SI space along
    a line. When we draw their corresponding lines in XY space, they all meet at the
    same XY point. [Figure 9-20](#figure9-20) shows this in action. This is true any
    time our SI points lie on a line.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '![f09020](Images/f09020.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-20: Two examples of placing dots in SI space along a line. Their corresponding
    lines will always meet at a single point in XY space.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: As we look for the best line to fit our data, we know it probably won’t be able
    to go through all the points. But we’d like it to come close. So instead of placing
    dots in SI space, let’s assign every possible line a probability from 0 to 1,
    indicating how likely it is to be the line we’re looking for. [Figure 9-21](#figure9-21)
    shows the idea (in [Figure 9-21](#figure9-21), and the figures to come, we scale
    up the probability values as needed so that they’re easier to read).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![f09021](Images/f09021.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-21: Left: A point in XY space. Middle: Every point in the SI graph
    is assigned a probability from 0 to 1 (blue to purple), telling us how close that
    line comes to the point. We show some representative lines with black dots. Right:
    The black dots in the middle figure drawn as their lines in XY space. Note that
    they all pass through our original red dot, or come close to it.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now return to the problem we want to solve: finding the best straight
    line approximation for a noisy set of data. Let’s start with an arbitrary, broad
    Gaussian bump in SI space as a prior, as in the top left of [Figure 9-22](#figure9-22).
    This says that any line might be our answer, but those in the bright purple region
    are the most likely. We’ve chosen some points in this graph according to their
    probabilities, and drawn them in the upper right. We’re getting a lot of very
    different lines, confirming our very vague prior when it comes to choosing lines.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '![f09022](Images/f09022.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-22: Top left: A prior in SI space, along with some points chosen from
    that probability distribution. Top right: Those points drawn as lines in XY space.
    Second and third rows: Like the top row, but with smaller priors.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: We can see in [Figure 9-22](#figure9-22) that as the prior becomes smaller,
    we get a more refined choice of lines. So we’d hope that Bayes’ Rule will follow
    this kind of change, and give us a small posterior (or prior) resulting in a small
    collection of lines that can fit our data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Now we’re ready to use Bayes’ Rule to match our data! [Figure 9-23](#figure9-23)
    shows the process.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '![f09023](Images/f09023.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-23: Fitting a straight line through our data with Bayes’ Rule (figure
    inspired by Bishop 2006)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through what’s happening in [Figure 9-23](#figure9-23) row by row.
    In row 1, we show our prior, or our starting guess of the distribution of straight
    lines that will fit our data. We arbitrarily chose a Gaussian with its center
    in the middle. This prior means that we’re guessing that our data is mostly likely
    fit by a straight line that is horizontal and has a Y intercept of 0\. That is,
    it’s the X axis itself. But the Gaussian goes all the way out to the edges (it
    doesn’t quite reach 0 anywhere in the diagram), so any of our available lines
    are possible. We could look at the data and pick a better starting prior, but
    this one is simple and, because it has at least some probability for every line
    we’ll consider as a candidate, it’s an acceptable start.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: The image on the right of row 1 shows 20 lines picked at random from this prior,
    with more probable lines being more likely to be picked.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: The left image in row 2 shows our noisy dataset, and a point picked at random,
    shown in red. The likelihood diagram for all lines that go through (or near) that
    point is shown to its right. Now we apply Bayes’ Rule, and multiply the prior
    in row 1 by the likelihood in row 2\.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: The result is the left figure in row 3\. This is the posterior, or the result
    of multiplying each point in the prior (how likely we thought that line was),
    with the corresponding point in the new point’s likelihood (how likely it is that
    each line fits this piece of data). We’re not showing the Bayes’ Rule step of
    dividing by the evidence because we’re scaling our pictures to span the whole
    range of colors, so this is really a scaled version of the posterior. For simplicity,
    let’s refer to it as the posterior anyway.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the posterior on line 3 is a new 2D distribution, represented by
    a new blob. To its right we see another 20 lines drawn at random from that distribution.
    We can see a big empty space near the top of the figure that wasn’t there in row
    1\. The system has learned from this one step of Bayes’ Rule that none of the
    lines that pass through that space are likely to match the data we’ve seen. The
    posterior from line 3 becomes our new prior for the next data point that comes
    along.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: In row 4 we pick a new data point from the input, again shown in red. To its
    right is the likelihood for lines with respect to this point. In row 5 we apply
    Bayes’ Rule again and multiply our prior (the posterior from line 3) with the
    likelihood from row 4 to get a new posterior. Notice that the posterior has shrunk
    in size, telling us that the collection of lines that probably fit both points
    is smaller than the collection that fits just the first one. To the right, we
    show lines drawn from this distribution. Notice how much they’ve grouped together
    in the same general direction as the two points we just learned from.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: We repeat the process again with a new point and likelihood in line 6, and a
    new posterior and set of lines in line 7\. The lines from this posterior are looking
    very similar, and the trend seems to be approaching a good fit to our data. By
    using more and more points, we get an increasingly limited range of probable lines.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: We can see from this example why Bayes’ Rule is so useful in training a learning
    system. Think of our training data as the points on the curve, and the evolving
    prior as the output from our system. As we provide the system with more samples
    (in this case, points), the system is able to fine-tune itself to deliver the
    response we’re looking for.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: It might be tempting to look at the lines in the bottom right of [Figure 9-21](#figure9-21)
    and apply our ideas of bias and variance to them, but that’s not thinking like
    a Bayesian. In the Bayesian framework, these aren’t a family of lines that approximate
    some true answer that we can discover by using various forms of averaging. Instead,
    a Bayesian sees all of these lines as accurate and correct, but with different
    probabilities. Computing the bias and variance of lines drawn from this collection
    is possible, but not meaningful in a Bayesian sense.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Both the frequentist and Bayesian approaches let us fit lines (or curves) to
    data. They just take very different attitudes and use different mechanisms, giving
    us two different ways to find good answers to our problem.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this chapter, we looked at a few ways in which a learning system can fail
    to generalize. When a learning system underperforms because the curves are not
    good fits to the data, we are underfitting. When a learning system underperforms
    on new data, but excels on the training data, we are overfitting: the system has
    learned too many of the quirks and idiosyncrasies of the training data. We saw
    how we can prevent overfitting by watching training and validation performance
    and using regularization methods. We ended the chapter by considering bias and
    variance’s relationship to overfitting, and seeing how we can fit a straight line
    to noisy data using Bayes’ Rule.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll look at data and how we can properly prepare it for
    our learning systems.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
