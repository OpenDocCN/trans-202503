- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Statistical Functions in SQL
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: In this chapter, we’ll explore SQL statistical functions along with guidelines
    for using them. A SQL database usually isn’t the first tool a data analyst chooses
    when they need to do more than calculate sums and averages. Typically, the software
    of choice is a full-featured statistics package, such as SPSS or SAS, the programming
    languages R or Python, or even Excel. But you don’t have to discount your database.
    Standard ANSI SQL, including PostgreSQL’s implementation, offers powerful stats
    functions and capabilities that reveal a lot about your data without having to
    export your dataset to another program.
  prefs: []
  type: TYPE_NORMAL
- en: Statistics is a vast subject worthy of its own book, so we’ll only skim the
    surface here. Nevertheless, you’ll learn how to apply high-level statistical concepts
    to help you derive meaning from your data using a new dataset from the US Census
    Bureau. You’ll also learn to use SQL to create rankings, calculate rates using
    data about business establishments, and smooth out time-series data using rolling
    averages and sums.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Census Stats Table
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s return to one of my favorite data sources, the US Census Bureau. This
    time, you’ll use county data from the 2014–2018 American Community Survey (ACS)
    5-Year Estimates, another product from the bureau.
  prefs: []
  type: TYPE_NORMAL
- en: Use the code in [Listing 11-1](#listing11-1) to create the table `acs_2014_2018_stats`
    and import the CSV file *acs_2014_2018_stats.csv*. The code and data are available
    with all the book’s resources via [https://nostarch.com/practical-sql-2nd-edition/](https://nostarch.com/practical-sql-2nd-edition/).
    Remember to change `C:\YourDirectory\` to the location of the CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 11-1: Creating a 2014–2018 ACS 5-Year Estimates table and importing
    data'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `acs_2014_2018_stats` table has seven columns. The first three 1 include
    a unique `geoid` that serves as the primary key, the name of the `county`, and
    the state name `st`. Both `county` and `st` carry the `NOT NULL` constraint because
    each row should contain a value. The next four columns display certain percentages
    2 I derived for each county from estimates in the ACS release, plus one more economic
    indicator:'
  prefs: []
  type: TYPE_NORMAL
- en: '**`pct_travel_60_min`**'
  prefs: []
  type: TYPE_NORMAL
- en: The percentage of workers ages 16 and older who commute more than 60 minutes
    to work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**`pct_bachelors_higher`**'
  prefs: []
  type: TYPE_NORMAL
- en: The percentage of people ages 25 and older whose level of education is a bachelor’s
    degree or higher. (In the United States, a bachelor’s degree is usually awarded
    upon completing a four-year college education.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**`pct_masters_higher`**'
  prefs: []
  type: TYPE_NORMAL
- en: The percentage of people ages 25 and older whose level of education is a master’s
    degree or higher. (In the United States, a master’s degree is the first advanced
    degree earned after completing a bachelor’s degree.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**`median_hh_income`**'
  prefs: []
  type: TYPE_NORMAL
- en: The county’s median household income in 2018 inflation-adjusted dollars. As
    you learned in Chapter 6, a median value is the midpoint in an ordered set of
    numbers, where half the values are larger than the midpoint and half are smaller.
    Because averages can be skewed by a few very large or very small values, government
    reporting on economic data, such as income, tends to use medians.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We include a `CHECK` constraint 3 to ensure that the figures for the bachelor’s
    degree are equal to or higher than those for the master’s degree, because in the
    United States, a bachelor’s degree is earned before or concurrently with a master’s
    degree. A county showing the opposite could indicate data imported incorrectly
    or a column mislabeled. Our data checks out: upon import, there are no errors
    showing a violation of the `CHECK` constraint.'
  prefs: []
  type: TYPE_NORMAL
- en: We use the `SELECT` statement 4 to view all 3,142 rows imported, each corresponding
    to a county surveyed in this census release.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll use statistics functions in SQL to better understand the relationships
    among the percentages.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring Correlation with corr(Y, X)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Correlation* describes the statistical relationship between two variables,
    measuring the extent to which a change in one is associated with a change in the
    other. In this section, we’ll use the SQL `corr(``Y``,` `X``)` function to measure
    what relationship exists, if any, between the percentage of people in a county
    who’ve attained a bachelor’s degree and the median household income in that county.
    We’ll also determine whether, according to our data, a better-educated population
    typically equates to higher income and, if it does, the strength of that relationship.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, some background. The *Pearson correlation coefficient* (generally denoted
    as *r*) measures the strength and direction of a *linear relationship* between
    two variables. Variables that have a strong linear relationship cluster along
    a line when graphed on a scatterplot. The Pearson value of *r* falls between −1
    and 1; either end of the range indicates a perfect correlation, whereas values
    near zero indicate a random distribution with little correlation. A positive *r*
    value indicates a *direct relationship*: as one variable increases, the other
    does too. When graphed, the data points representing each pair of values in a
    direct relationship would slope upward from left to right. A negative *r* value
    indicates an *inverse* *relationship*: as one variable increases, the other decreases.
    Dots representing an inverse relationship would slope downward from left to right
    on a scatterplot.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 11-1](#table11-1) provides general guidelines for interpreting positive
    and negative *r* values, although different statisticians may offer different
    interpretations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11-1: Interpreting Correlation Coefficients'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Correlation coefficient (+/−)** | **What it could mean** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | No relationship |'
  prefs: []
  type: TYPE_TB
- en: '| .01 to .29 | Weak relationship |'
  prefs: []
  type: TYPE_TB
- en: '| .3 to .59 | Moderate relationship |'
  prefs: []
  type: TYPE_TB
- en: '| .6 to .99 | Strong to nearly perfect relationship |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Perfect relationship |'
  prefs: []
  type: TYPE_TB
- en: In standard ANSI SQL and PostgreSQL, we calculate the Pearson correlation coefficient
    using `corr(``Y``,` `X``)`. It’s one of several *binary aggregate functions* in
    SQL and is so named because these functions accept two inputs. The input `Y` is
    the *dependent variable* whose variation depends on the value of another variable,
    and `X` is the *independent variable* whose value doesn’t depend on another variable.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use `corr(``Y``,` `X``)` [PRE1]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
