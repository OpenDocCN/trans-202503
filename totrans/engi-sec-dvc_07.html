<html><head></head><body>
<div id="sbo-rt-content"><h2 class="h2" id="ch05"><span epub:type="pagebreak" id="page_85"/><strong><span class="big">5</span><br/>CONFIDENTIAL DATA STORAGE AND SECURE MEMORY</strong></h2>
<div class="image1"><img alt="Image" height="252" src="../images/common.jpg" width="252"/></div>
<p class="noindent">Embedded systems store and process a variety of data. Some of this data is trivial because it is the same on many platforms or can be guessed or derived easily. However, a certain amount of data, usually known as <em>sensitive</em>, <em>secret</em>, or <em>confidential</em> data, requires careful treatment.</p>
<p class="indent">The information that this data carries is valuable, and its disclosure would likely lead to negative consequences. One example is <em>intellectual property</em> forged into software algorithms, proprietary protocols, and application content. Further, <em>cryptographic material</em> like secret keys and passwords contain critical information by nature. A device’s <em>lifetime data</em> like sensor data, log entries, and sent or received messages might also fit into this category.</p>
<p class="indent">This chapter starts by looking at data that should be stored in a confidential manner and the dilemma of how to keep secrets in embedded systems. Next, I’ll describe your options for storing confidential data from the OS level to the hardware to obfuscated software, and the corresponding pros and cons. A case study in this chapter will then walk through using encrypted file containers on an embedded system running Linux.</p>
<h3 class="h3" id="ch00lev1_41"><span epub:type="pagebreak" id="page_86"/><strong>Confidential Data</strong></h3>
<p class="noindent">The identification of confidential data and the awareness of related threats is always the first step toward its protection. The following examples are meant to create the necessary mindset.</p>
<p class="indent">Imagine that your research department invents a superefficient engine-control algorithm that runs a car on significantly less fuel than competing products. Although you probably filed a patent, that might not be enough to protect your device from piracy and copycats. The value of the invention becomes reality only if you implement it in your control device. There, it’s likely available as a compiled software executable or maybe as part of a kernel module. Both are stored in the device’s filesystem, and if an attacker can read the filesystem, they can reverse engineer your algorithm and directly benefit from your research investment. This situation is clearly one you’ll want to avoid, which means you must protect the confidentiality of the control algorithm’s implementation.</p>
<p class="indent">Some household and consumer devices contain a lot of media content like pictures and videos, and their production is anything but cheap. Storing them in plain sight in a device’s filesystem is rarely a good idea. Attackers might copy them, upload them to their favorite online platform, and reuse them for their own purposes, which could not only cause financial losses but also damage the reputation of your product and company.</p>
<p class="indent">At first glance, the need to protect cryptographic material seems to go without saying. However, many devices store the private keys corresponding to their certificate-based authentication in their standard filesystems. Reading and copying these keys opens the door for impersonation attacks. In addition, especially on the application level, the passwords that control user authentication are sometimes stored in plaintext within configuration files or software binaries. Of course, extracting a password allows an adversary to authenticate successfully with the device because the credential wasn’t stored in a way that protects confidentiality.</p>
<p class="indent">In some cases, the really interesting data is generated during a device’s lifetime. Think, for example, of the privacy implications for biometric data that a product may collect through fingerprint readers or location data that creates movement profiles of users. This information often has a high confidentiality requirement, maybe even by laws like the European GDPR. Failure of protection can lead to fines up to €20 million or 4 percent of a company’s total global turnover.</p>
<p class="indent">Stored data history in a device can reveal even more. For example, in industrial production environments, the data history might allow attackers to reconstruct machine utilization and output figures, which could be valuable information for competitors. Again, confidentiality protection would be a crucial device feature.</p>
<p class="indent">Almost every modern device contains data that deserves confidentiality protection. Make sure to keep that in mind when doing your threat and risk analysis.</p>
<h3 class="h3" id="ch00lev1_42"><span epub:type="pagebreak" id="page_87"/><strong>The Dilemma of Keeping Secrets on Embedded Systems</strong></h3>
<p class="noindent">Embedded systems often include a toxic combination of properties. First, they have to be able to boot and run without user interaction, which means that everything relevant for correct operation has to be stored within the device, including all secrets. Second, attackers can usually obtain a device for themselves and analyze it thoroughly. This analysis includes not only network-based investigations but also physical eavesdropping on communication lines within the product and the extraction of nonvolatile memory contents like firmware images and filesystem partitions for reverse-engineering purposes. From a theoretical point of view, confidentiality protection for secrets in a device that can be analyzed on all levels can’t be guaranteed.</p>
<p class="indent">However, from a more pragmatic perspective, the question always is, “How much effort does an adversary have to spend to reach a comprehensive understanding of the device at hand, including its secrets?”</p>
<p class="indent">Let’s consider the intellectual property example I mentioned previously. Imagine you’re responsible for keeping the software implementation of a highly sophisticated algorithm secret, although it has to be stored and used within your device. Some people might immediately think that reading the firmware from flash memory, identifying the executable, and reverse engineering the algorithm is highly complicated, so they assume they don’t need any protection measures.</p>
<p class="indent">That assumption might be true for attackers like script kiddies. However, consider criminals seeking financial gain. For them, dumping flash memory and mounting a filesystem doesn’t seem like too much work. Further, free and open source tools like Radare2 and Ghidra enable everybody with interest to do at least basic software reverse engineering. If confidentiality has an increased priority in your product, these attackers should definitely be in scope.</p>
<p class="indent">Of course, some cases are much simpler to attack. For devices that store their firmware on removable media like a microSD card that many off-the-shelf laptops can read, flash dumping isn’t even necessary. If the confidential information, such as an RSA private key, is stored in a directly reusable format like Privacy-Enhanced Mail (PEM), an “attack” could be performed in no time, even by a script kiddie. Also, not every executable even needs to be reverse engineered. <em>Code lifting attacks</em>, for example, just take the binary as is, copy it to another device, and run it. If it fulfills its purpose, there’s no need to access its proprietary details.</p>
<h3 class="h3" id="ch00lev1_43"><strong>Secure Filesystem Approaches</strong></h3>
<p class="noindent">At this point, you might wonder, “Is there such a thing as an encrypted file-system? That would solve all our problems.” There is, but it doesn’t make the problem go away completely. Three common options are available that provide confidentiality protection for files: encrypted stacked filesystems, native filesystem encryption, and encrypted block devices.</p>
<h4 class="h4" id="ch00lev2_51"><span epub:type="pagebreak" id="page_88"/><strong><em>Encrypted Stacked Filesystems</em></strong></h4>
<p class="noindent">A <em>stacked filesystem</em> is an additional filesystem structure on top of an existing one, which means that standard filesystems like ext3 aren’t touched and the encryption happens in a layer above. In this case, the content and the names of files are encrypted—for example, for all files in a specific directory. However, the number of files and their metadata is readable.</p>
<p class="indent">Stacking filesystems also comes with a certain performance overhead, and filenames might be subject to additional restrictions. For years, EncFS, which uses the Filesystem in Userspace (FUSE) framework, has been a popular and easy-to-use example of this approach, but it seems that development has stalled. An aspiring successor might be gocryptfs.</p>
<p class="indent">A competitor that operates in kernel space is eCryptfs. While eCryptfs might be a bit harder to configure, it exhibits better performance in certain cases. However, its development is also stalled. File-based encryption (FBE) with stacked filesystems seems to be out of fashion.</p>
<h4 class="h4" id="ch00lev2_52"><strong><em>Native Filesystem Encryption</em></strong></h4>
<p class="noindent">Today, filesystems like ext4, F2FS, and UBIFS directly support the encrypted storage of files. Compared to filesystem stacking, this allows for more efficient integration and operation.</p>
<p class="indent">Popular users of this native FBE approach include the Android and Chrome OSs. The underlying features are implemented in the Linux kernel and use the kernel’s crypto API for encryption. The user-space tool for configuring and managing encrypted directories is called <span class="literal">fscrypt</span>.</p>
<h4 class="h4" id="ch00lev2_53"><strong><em>Encrypted Block Devices</em></strong></h4>
<p class="noindent">File-based approaches always leave folder structures and metadata unencrypted. A common way to avoid this information leakage is <em>full-disk encryption (FDE)</em>. In Linux, this means that the encryption layer lies below the filesystem, on the block device level. It doesn’t matter whether this block device is a whole disk, a partition, or a file container; it’s encrypted as a whole, and its content isn’t distinguishable from random information.</p>
<p class="indent">The most common representative of this class for Linux is <span class="literal">dm-crypt</span>, which is based on the device mapper infrastructure and uses the kernel’s crypto API. The <span class="literal">cryptsetup</span> user-space tool can create encrypted volumes, and it supports the popular Linux Unified Key Setup (LUKS) container format that enables various key-management functionalities for encrypted volumes.</p>
<p class="indent">The TrueCrypt successor VeraCrypt is another popular tool, which, for example, also enables the chaining of two ciphers to enhance decryption resistance.</p>
<h4 class="h4" id="ch00lev2_54"><span epub:type="pagebreak" id="page_89"/><strong><em>Recommendations</em></strong></h4>
<p class="noindent">Encrypted data storage clearly doesn’t have a lack of options. Whether FDE or FBE fits your needs largely depends on your device and its corresponding security requirements.</p>
<p class="indent">If, from your point of view, the location, number, and size of files already convey sensitive information to an attacker, FDE is probably the solution that leads to the highest possible security. However, FBE offers more flexibility—for example, for hosting a heterogeneous set of files within the same filesystem so that some data is always available and readable to all processes, but confidential data is decrypted selectively per directory. It could also have application-specific keys, which allows for more fine-grained confidentiality protection.</p>
<h4 class="h4" id="ch00lev2_55"><strong><em>The Passphrase</em></strong></h4>
<p class="noindent">No matter which implementation you choose, one big problem will always remain: all the tools require a passphrase to either directly unlock protected directories and volumes or to unlock a key file subsequently used to unlock encrypted data. Even the word <em>passphrase</em> indicates that this concept is meant for users to enter credentials as we do on our PCs at boot time.</p>
<p class="indent">However, most embedded systems don’t have active users sitting in front of them, able to enter a passphrase to unlock hard-disk encryption when booting up. The usual next question is, “Where to hide the secret that unlocks encryption?”</p>
<h3 class="h3" id="ch00lev1_44"><strong>Secure Memory in Hardware</strong></h3>
<p class="noindent">Every now and then, I hear people (and companies) say that <em>secure memory</em> implemented in hardware is the solution to the embedded system credentials problem. However, that’s only partially true.</p>
<p class="indent">One advantage of hardware-based secure memory is that it implements a strong physical segmentation between the classic nonvolatile memory, where the firmware is stored, and a dedicated security module, which can be reached only by a specific interface. Further, it allows for tamper detection or resistance, and the stored bits might be buried deep inside a chip, making hardware attacks difficult and requiring sophisticated equipment.</p>
<p class="indent">However, this approach also has downsides. Most obviously, only small amounts of data, usually cryptographic keys, can be stored in such protected memory. In addition, these secrets often <em>have to leave</em> the security module to serve their purpose, like unlocking a LUKS container. In such cases, attackers might capture the keys on their way over a communication line.</p>
<p class="indent"><span epub:type="pagebreak" id="page_90"/>In the past, this issue has been practically exploited when external security modules transferred secrets to a main CPU and adversaries eavesdropped on the physical PCB traces. Other attacks actively communicate with the secure memory and, for example, ask it to encrypt, decrypt, or sign arbitrary data for an attacker. So merely <em>having</em> a secure memory doesn’t enhance your device’s security significantly; it also must be <em>integrated</em> securely.</p>
<p class="indent">As usual, whether the use of secure memory makes sense depends on the specific application and implementation details. Often, it at least adds another layer of required attacker knowledge—namely, observing secure memory communication at device runtime instead of “only” extracting secrets from firmware or filesystems. Let’s consider the options regarding secure memory.</p>
<h4 class="h4" id="ch00lev2_56"><strong><em>External Secure Memory</em></strong></h4>
<p class="noindent">The “traditional” way of adding a secure memory device to your design is by integrating a dedicated microchip to your device’s PCB and connecting it to the main microprocessor. The most prominent player in this area is the Trusted Platform Module (TPM).</p>
<p class="indent">You can purchase discrete TPMs from a variety of manufacturers like Infineon, NXP, and ST. They’re well established in the PC world because Microsoft Windows made them a hard requirement. A basic use case is that a user can unlock a TPM key, which is then used to unlock volumes protected by BitLocker. Of course, this is a simplified view of the process, and that’s where the problem comes in.</p>
<p class="indent">A TPM is much more than secure memory. It comes with authorization layers, with key hierarchies, and with a specification that’s more than 1,000 pages for the current TPM version. Although tools are available to make use of TPMs under Linux, like <span class="literal">tpm2-tools</span> and <span class="literal">ibm-tss</span>, using a TPM seems to be too complex for average products and development teams.</p>
<p class="indent">Fortunately, secure microcontroller manufacturers provide interesting alternatives that target automotive, industrial, and IoT applications. Similar to a TPM, products like Infineon’s OPTIGA Trust X, NXP’s Edge-Lock SE050 family, and Microchip’s ATECC608B come with a broad set of crypto algorithms, from symmetric ciphers like AES, to hash functions and HMACs, to asymmetric crypto like RSA and ECDSA. Of course, they also provide secure memory for cryptographic keys. Their promise is that these devices require much less integration effort for IoT products.</p>
<p class="indent">In summary, a TPM used only as secure memory is like breaking a butterfly on a wheel. Leaner alternatives might be more suitable for the embedded system world. However, when deciding whether to use a dedicated hardware security module, you should also consider the topics of secure device identity and secure communication, as discussed in <a href="ch06.xhtml#ch06">Chapters 6</a> and <a href="ch07.xhtml#ch07">7</a>. In any case, make sure you understand the implications that secret keys might be communicated over interfaces accessible to physical attackers.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>The TPM 2.0 specification provides a means to encrypt the communication between host CPU and TPM, which adds complexity for attackers but also for engineers.</em></p>
</div>
<h4 class="h4" id="ch00lev2_57"><span epub:type="pagebreak" id="page_91"/><strong><em>Internal Secure Memory</em></strong></h4>
<p class="noindent">In contrast to discrete hardware components that have to be designed in and soldered to a PCB, security modules and secure storage facilities are already deeply integrated into the main CPU of a device.</p>
<p class="indent">Known as <em>integrated TPMs</em> or <em>firmware TPMs</em>, these alternatives to dedicated hardware TPMs are offered by chip vendors like AMD and Intel. Besides reduced PCB integration costs, the striking advantage of this concept is that on-chip communication is much harder to capture than signals running across a PCB. Of course, the complexity issue of TPMs stays the same.</p>
<p class="indent">On the other side, modern SoCs often offer one-time programmable (OTP) memory that can be used to store at least a master key. A common example is the cascaded encryption concept of NXP’s i.MX series. There, an OTP master key (OTPMK) is programmed to the device during production. Subsequently, this key is used to encrypt a data encryption key (DEK) to obtain a so-called DEK <em>binary large object (BLOB)</em>. In turn, developers can then use the DEK to encrypt application data.</p>
<p class="indent"><a href="ch05.xhtml#ch05fig01">Figure 5-1</a> shows the procedure running on a device from the master key OTP reading to the application data decryption.</p>
<div class="image"><img alt="Image" height="268" id="ch05fig01" src="../images/05fig01.jpg" width="837"/></div>
<p class="figcap"><em>Figure 5-1: The decryption cascade from NXP’s i.MX series</em></p>
<p class="indent">This procedure adds security to a device because keys and confidential data are not stored in plaintext and, at the same time, the necessary keys are loaded directly to the device’s cryptographic acceleration and assurance module (CAAM) where the decryption is performed, which means only the decrypted user data leaves this internal module at runtime.</p>
<h3 class="h3" id="ch00lev1_45"><strong>Secrets in Application Code</strong></h3>
<p class="noindent">Additional hardware or security-enhanced main CPUs are not always an option because of their cost or because legacy hardware can no longer be upgraded. Is storing the keys in plain view inevitable? Not necessarily.</p>
<p class="indent">We can still move keys from the structured field of a filesystem into the more crowded form of an executable. Again, this approach demands further capability from potential attackers—namely, binary reverse engineering. Even if adversaries learn that a specific executable is responsible for unlocking an encrypted volume, they can’t extract the unlocking key immediately.</p>
<div class="note">
<p class="notet"><span epub:type="pagebreak" id="page_92"/><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Yes, security by obscurity is actually appearing in a security engineering book. At some point in real-world device engineering, you have to clutch at straws.</em></p>
</div>
<p class="indent">The term that describes such countermeasures is <em>obfuscation</em>. Its sole purpose is to make software reverse engineering harder, and this can be accomplished in several ways:</p>
<ul>
<li class="noindent">Replace common operations with complex but equivalent ones</li>
<li class="noindent">Overcomplicate control flow by rearranging command order without breaking functionality</li>
<li class="noindent">Insert redundant, unnecessary code and data</li>
<li class="noindent">Store parts of the code or data in encrypted or encoded form and decrypt or decode it only at runtime</li>
<li class="noindent">Add randomness to data structures and control flows</li>
<li class="noindent">Integrate anti-debugging measures that thwart analysis</li>
<li class="noindent">Split secrets into multiple parts, store them in different places, and assemble them only at runtime</li>
</ul>
<p class="indent">This list isn’t comprehensive, and each bullet point can be implemented in a variety of ways and with many degrees of creativity. If you can’t do it yourself, tools are available that provide automatic code obfuscation functionality. However, such tools must be treated with caution because each given obfuscation tool might also have a corresponding counterpart, a <em>deobfuscation</em> tool, that reverts the added complexity and leaves attackers with code they can analyze much more efficiently.</p>
<p class="indent">In 2002, an idea called <em>white-box cryptography</em> appeared in academic discussions as a way to overcome the problem of hiding secrets in software. This approach aims to perform cryptographic operations in software without revealing the underlying secret. That means the used cryptographic key diffuses into the operations of a crypto algorithm.</p>
<p class="indent">The first concepts of white-box cryptography transformed ciphers with hardcoded keys into key-dependent table lookups and injected random values into the internal calculations that would mask data at some point and demask it later. However, not surprisingly, this led to significant overhead in binary size and performance, and those implementations were also broken by cryptanalysis. Although academia has not yet found a perfect solution to the problem, many software companies use some kind of white-box cryptography in their products—for example, in mobile apps allowing users to download the binary and analyze it.</p>
<p class="indent">No matter whether you apply custom obfuscation, commercial tools, or academic white-box crypto approaches, you should always keep in mind one attacker approach when hiding secrets in software binaries: code lifting. In these cases, binaries are used “as is”—for example, to unlock a LUKS container. The secret key itself isn’t of interest to attackers if they just have to use the executable as a key to an encrypted vault. This might happen in place, or the file of interest might be extracted and executed in an attacker-controlled environment.</p>
<h3 class="h3" id="ch00lev1_46"><span epub:type="pagebreak" id="page_93"/><strong>Secure Password Storage</strong></h3>
<p class="noindent">Password-based authentication is a common method for verifying legitimate users at login, but it’s also used to unlock encrypted volumes and containers. Naturally, passwords are confidential data. Storing them in plaintext within a file or an executable for comparison during verification makes an attacker’s life easy. Once extracted, they can be used successfully to access confidential data. However, traditional encryption, as discussed as a protection measure for other classes of data, is usually not appropriate here. The specific verification process of passwords allows for implementing a different secure storage approach: <em>password hashes</em>.</p>
<p class="indent">The one-way property of hash functions is useful in prohibiting attackers from retrieving a password from its hash value, even if extracted from the device. The verification still works because a given password can be efficiently hashed and compared to the stored value. However, in this trivial case, attackers could precompute <em>rainbow tables</em>, which are large collections of hash values for millions of passwords, maybe even all possible passwords with, for example, 10 characters. To protect against such attacks, a random <em>salt</em> is added to the password-hashing process that makes every hash unique and renders all rainbow tables useless.</p>
<p class="indent">Linux currently, still by default, uses a function based on SHA-512 hashes to generate salted user-password hashes. Also, the Password-Based Key Derivation Function 2 (PBKDF2) was standardized more than 20 years ago in RFC 2898. It’s based on HMACs using hash functions like SHA-1, SHA-256, or SHA-512. Both approaches are definitely better than plaintext password storage, but modern attackers use graphics processing units (GPUs), FPGAs, and dedicated application-specific integrated circuits (ASICs) to break password hashes literally with brute force.</p>
<p class="indent">Therefore, for future-proof products, the use of modern representatives of this field is recommended. Typical examples are scrypt, standardized in RFC 7914 from 2016; its successor yescrypt; and Argon2, which won the Password Hashing Competition in 2015. These algorithms share the common goal of enhancing cracking resistance by parameterizable password-hashing algorithms that consider dimensions like computation time, necessary memory, and required number of parallel CPU threads, which is meant to discourage even attackers who have access to a variety of hardware resources and computing capacity.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Even if confidentiality is the main protection goal for a password, the consequences of someone being able to change it are severe. Replacing the password hash of the root user with one of a known password is a pretty common attack that opens all doors for an adversary. You should seriously consider integrity protection for password storage, as discussed in <a href="ch08.xhtml#ch08">Chapter 8</a>.</em></p>
</div>
<h3 class="h3" id="ch00lev1_47"><strong>Case Study: Encrypted File Containers on Linux</strong></h3>
<p class="noindent">In this case study, let’s assume that one of your legacy devices doesn’t have any secure storage for confidential data implemented. While visiting an <span epub:type="pagebreak" id="page_94"/>international fair, members of your engineering team recognize that a currently unknown competitor uses one of your proprietary GUI applications and the associated media content that you produced with great effort to fit the needs of your target audience.</p>
<p class="indent">Back home, you discuss the issue with your team and management. After an initial investigation, it becomes clear that stealing the data required nothing more than opening your device and reading the contents from flash memory, which your competitor obviously succeeded in doing. To limit future damages, you decide to establish at least a basic protection by using LUKS containers. Your current flash memory device has a capacity of 256MB. The basic Linux system and all associated tools occupy roughly 136MB. Your proprietary executables together with their data and configuration files sum up to roughly 19MB, while the high-quality video content consumes 73MB.</p>
<p class="indent">You want to protect the latter two classes of data. Because memory requirements are rather tight on your platform and you’d like to separate code from media, you plan on creating a 25MB container for executables and files containing intellectual property, and a 90MB container for video files.</p>
<h4 class="h4" id="ch00lev2_58"><strong><em>Crypto Benchmarking</em></strong></h4>
<p class="noindent">As a first step, you add <span class="literal">cryptsetup</span> to your device’s root filesystem to be able to work with LUKS containers. You also enable <span class="literal">CONFIG_CRYPTO_SERPENT</span> and <span class="literal">CONFIG_CRYPTO_TWOFISH</span> in your Linux kernel config because you’ve heard that <span class="literal">cryptsetup</span> supports them and you wonder whether they might outperform AES on your STM32MP157F SoC. <a href="ch05.xhtml#ch05list01">Listing 5-1</a> shows the results of <span class="literal">cryptsetup</span>’s own performance-benchmarking tool.</p>
<pre class="pre"># <span class="codestrong1">cryptsetup benchmark</span>&#13;
# Tests are approximate using memory only (no storage IO).&#13;
PBKDF2-sha1        59148 iterations per second for 256-bit key&#13;
PBKDF2-sha256      92695 iterations per second for 256-bit key&#13;
PBKDF2-sha512      58618 iterations per second for 256-bit key&#13;
PBKDF2-ripemd160   49201 iterations per second for 256-bit key&#13;
PBKDF2-whirlpool   14021 iterations per second for 256-bit key&#13;
argon2i       4 iterations, 65536 memory, 4 parallel threads (CPUs)&#13;
              for 256-bit key (requested 2000 ms time)&#13;
argon2id      4 iterations, 65536 memory, 4 parallel threads (CPUs)&#13;
              for 256-bit key (requested 2000 ms time)&#13;
#     Algorithm |       Key |      Encryption |      Decryption&#13;
        aes-cbc        128b        36.9 MiB/s        36.8 MiB/s&#13;
    serpent-cbc        128b         9.0 MiB/s        10.4 MiB/s&#13;
    twofish-cbc        128b        11.1 MiB/s        12.0 MiB/s&#13;
        aes-cbc        256b        36.9 MiB/s        37.0 MiB/s&#13;
    serpent-cbc        256b         9.1 MiB/s        10.5 MiB/s&#13;
    twofish-cbc        256b        11.3 MiB/s        12.0 MiB/s<span epub:type="pagebreak" id="page_95"/>&#13;
        aes-xts        256b        18.4 MiB/s        17.0 MiB/s&#13;
    serpent-xts        256b         9.0 MiB/s        10.4 MiB/s&#13;
    twofish-xts        256b        11.5 MiB/s        12.0 MiB/s&#13;
        aes-xts        512b        15.3 MiB/s        13.1 MiB/s&#13;
    serpent-xts        512b         9.6 MiB/s        10.5 MiB/s&#13;
    twofish-xts        512b        12.0 MiB/s        12.0 MiB/s</pre>
<p class="list-title" id="ch05list01"><em>Listing 5-1: The benchmarking results offered by</em> <span class="codeitalic1">cryptsetup</span></p>
<p class="indent">At first, this output shows that multiple functions for password storage are analyzed to give you an idea about which parameters of the specific function might be reasonable choices for your device. You want to set parameters like iteration count to values that lead to acceptable performance on your device (for example, unlocking within two seconds) but leave an attacker with maximum cracking effort. In this case, since you don’t have specific requirements, you stick with the default of LUKS2 volumes: Argon2.</p>
<p class="indent">The encryption/decryption benchmark shows that AES is the fastest algorithm no matter whether you use it in CBC mode or XTS (XEX-Based Tweaked-Codebook Mode with Ciphertext Stealing). It also seems that AES-CBC performance is accelerated by the STM32MP157F crypto hardware. On the other hand, XTS is the default and recommended operation mode for <span class="literal">cryptsetup</span> and hard disk encryption in general. Since you highly value performance and don’t want the container encryption to impact any device functionality, you choose AES-CBC, and since there’s practically no difference between 128-bit and 256-bit keys, you go with a 256-bit key.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>You might wonder how XTS can use 512-bit keys with AES. In short, it doesn’t! It requires two keys (in this case, two 256-bit keys, which add up to 512 bits), but the security level is 256-bit.</em></p>
</div>
<h4 class="h4" id="ch00lev2_59"><strong><em>Container Creation</em></strong></h4>
<p class="noindent">After determining the crypto parameters, you can start by creating random files and corresponding key files for your two containers. The container for executables takes 25MB, and the one for media is based on a 90MB file, as shown in <a href="ch05.xhtml#ch05list02">Listing 5-2</a>. Both keys are initialized with 32 bytes, which equals 256 bits.</p>
<pre class="pre"># <span class="codestrong1">dd if=/dev/urandom of=executables.enc bs=1M count=25</span>&#13;
# <span class="codestrong1">dd if=/dev/urandom of=media.enc bs=1M count=90</span>&#13;
# <span class="codestrong1">dd if=/dev/urandom of=executables.key bs=32 count=1</span>&#13;
# <span class="codestrong1">dd if=/dev/urandom of=media.key bs=32 count=1</span></pre>
<p class="list-title" id="ch05list02"><em>Listing 5-2: A random initialization of containers and key files</em></p>
<p class="indent">In the next step, as shown in <a href="ch05.xhtml#ch05list03">Listing 5-3</a>, you use <span class="literal">cryptsetup</span> to provide the basic structure of a LUKS container via the <span class="literal">luksFormat</span> command.</p>
<pre class="pre"><span epub:type="pagebreak" id="page_96"/># <span class="codestrong1">cryptsetup -q -v --type luks2 --cipher=aes-cbc-essiv:sha256</span>&#13;
    <span class="codestrong1">luksFormat executables.enc executables.key</span>&#13;
# <span class="codestrong1">cryptsetup -q -v --type luks2 --cipher=aes-cbc-essiv:sha256</span>&#13;
    <span class="codestrong1">luksFormat media.enc media.key</span></pre>
<p class="list-title" id="ch05list03"><em>Listing 5-3: The creation of LUKS2 containers</em></p>
<p class="indent">Since you want to use Argon2 for passphrase verification, and you’d like to enjoy the robustness that comes with a second header copy in LUKS2, you select the second version of the header format with <span class="literal">--type luks2</span>. The earlier choice of AES in CBC mode with encrypted salt-sector initialization vector (ESSIV) is configured using <span class="literal">--cipher=aes-cbc-essiv:sha256</span>.</p>
<p class="indent">At this point, the containers and their structures are ready, but you can’t store anything in these virtual vaults yet. The file containers need to be unlocked by <span class="literal">luksOpen</span> to create an ext3 filesystem inside. Note that after unlocking the LUKS container, as shown in <a href="ch05.xhtml#ch05list04">Listing 5-4</a>, it is mapped to the device <em>/dev/mapper/dm_exec_enc</em>, which is then mounted to the newly created directory <em>/mnt/exec_enc</em>. The same can be done for the encrypted media container with device <em>/dev/mapper/dm_media_enc</em> and mount point <em>/mnt/media _enc</em>, respectively.</p>
<pre class="pre"><span class="codestrong1"># cryptsetup -v --key-file=executables.key luksOpen executables.enc dm_exec_enc</span>&#13;
<span class="codestrong1"># mke2fs -t ext3 /dev/mapper/dm_exec_enc</span>&#13;
<span class="codestrong1"># mkdir /mnt/exec_enc</span>&#13;
<span class="codestrong1"># mount /dev/mapper/dm_exec_enc /mnt/exec_enc</span></pre>
<p class="list-title" id="ch05list04"><em>Listing 5-4: Unlocking a container for filesystem creation and mounting</em></p>
<p class="indent">It seems like you’re almost finished. Let’s use <span class="literal">luksDump</span>, as shown for the executables’ container in <a href="ch05.xhtml#ch05list05">Listing 5-5</a>, to check whether the right properties are set.</p>
<pre class="pre"># <span class="codestrong1">cryptsetup luksDump executables.enc</span>&#13;
...&#13;
Keyslots:&#13;
  0: luks2&#13;
    Key:        256 bits&#13;
    Priority:   normal&#13;
    Cipher:     aes-cbc-essiv:sha256&#13;
    Cipher key: 256 bits&#13;
    PBKDF:      argon2id&#13;
    Time cost:  4&#13;
    Memory:     65536&#13;
    Threads:    2&#13;
...</pre>
<p class="list-title" id="ch05list05"><em>Listing 5-5: Double-checking container properties</em></p>
<p class="indent">The output completely matches our requirements.</p>
<h4 class="h4" id="ch00lev2_60"><span epub:type="pagebreak" id="page_97"/><strong><em>Efficiency Analysis</em></strong></h4>
<p class="noindent">Before you start populating the filesystem, let’s take one last glance at the efficiency of this construction. The <span class="literal">fdisk</span> and <span class="literal">df</span> tools will help you understand how much memory is lost for the LUKS header and how much overhead is introduced by the ext3 filesystem. <a href="ch05.xhtml#ch05list06">Listing 5-6</a> has the details.</p>
<pre class="pre"># <span class="codestrong1">fdisk -l /dev/mapper/dm_exec_enc</span>&#13;
Disk /dev/mapper/dm_exec_enc: 9 MiB, 9437184 bytes, 2304 sectors&#13;
...&#13;
# <span class="codestrong1">df -hT /dev/mapper/dm_exec_enc</span>&#13;
Filesystem              Type  Size  Used Avail Use% Mounted on&#13;
/dev/mapper/dm_exec_enc ext3  4.5M   28K  4.0M   1% /mnt/exec_enc&#13;
# <span class="codestrong1">fdisk -l /dev/mapper/dm_media_enc</span>&#13;
Disk /dev/mapper/dm_media_enc: 74 MiB, 77594624 bytes, 18944 sectors&#13;
...&#13;
# <span class="codestrong1">df -hT /dev/mapper/dm_media_enc</span>&#13;
Filesystem               Type  Size  Used Avail Use% Mounted on&#13;
/dev/mapper/dm_media_enc ext3   66M   28K   62M   1% /mnt/media_enc</pre>
<p class="list-title" id="ch05list06"><em>Listing 5-6: An efficiency check regarding memory usage</em></p>
<p class="indent">Unfortunately, this didn’t turn out as planned. The 25MB container has only 4MB of space left to store data, and the other one with a size of 90MB leaves you with 62MB. It’s clearly visible that the difference between the sizes of the containers and their corresponding devices in the device mapper infrastructure is approximately 16MB. Actually, if you had studied the LUKS documentation thoroughly, you’d have known that the headers of LUKS1 and LUKS2 consume 2MB and 16MB, respectively. While that’s not an issue for hard disks with hundreds of gigabytes, it might turn out to be a pain point for memory-constrained embedded systems.</p>
<p class="indent">You can solve the issue by using LUKS1 headers and going without the LUKS2 improvements, which would be acceptable in practice, or even by using the “plain mode” of <span class="literal">cryptsetup</span> that doesn’t store any metadata in memory. The latter choice might be the most efficient but comes with significant management limitations. LUKS1 would probably be a reasonable choice.</p>
<p class="indent"><a href="ch05.xhtml#ch05list06">Listing 5-6</a> also shows that the ext3 filesystem reduces the available memory because of necessary allocation tables and journal data. However, for static storage of executables, configuration files, and media content, journaling might not be necessary, and you could also deploy an ext2 filesystem to squeeze out more bytes of available memory.</p>
<p class="indent">After repeating the whole process while changing <span class="literal">luks2</span> to <span class="literal">luks1</span> and <span class="literal">ext3</span> to <span class="literal">ext2</span>, the situation looks different, as shown in <a href="ch05.xhtml#ch05list07">Listing 5-7</a>.</p>
<pre class="pre"># <span class="codestrong1">fdisk -l /dev/mapper/dm_exec_enc</span>&#13;
Disk /dev/mapper/dm_exec_enc: 23 MiB, 24117248 bytes, 47104 sectors&#13;
...&#13;
<span epub:type="pagebreak" id="page_98"/>&#13;
# <span class="codestrong1">df -hT /dev/mapper/dm_exec_enc</span>&#13;
Filesystem              Type  Size  Used Avail Use% Mounted on&#13;
/dev/mapper/dm_exec_enc ext2   22M   14K   21M   1% /mnt/exec_enc&#13;
# <span class="codestrong1">fdisk -l /dev/mapper/dm_media_enc</span>&#13;
Disk /dev/mapper/dm_media_enc: 88 MiB, 92274688 bytes, 180224 sectors&#13;
...&#13;
# <span class="codestrong1">df -hT /dev/mapper/dm_media_enc</span>&#13;
Filesystem               Type  Size  Used Avail Use% Mounted on&#13;
/dev/mapper/dm_media_enc ext2   81M   14K   77M   1% /mnt/media_enc</pre>
<p class="list-title" id="ch05list07"><em>Listing 5-7: The memory usage efficiency with LUKS1 and ext2</em></p>
<p class="indent">A loss of 4MB and 13MB, respectively, still occurs, but the remaining space just fulfills the requirements of this case study.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>If you find yourself in a similar situation in real life but can’t reach your requirements, you can still think about switching to native filesystem encryption (for example, with ext4), or you can use compressed read-only filesystems like CramFS and SquashFS.</em></p>
</div>
<p class="indent">After solving these unexpected, non-security-related problems, the final question of how to securely unlock the created containers remains. Since you don’t have a secure element within your device and your main CPU doesn’t provide OTP memory for this purpose, you may decide to hide the unlocking process in an executable within your <em>initramfs</em>, which is executed at boot. To be clear, you won’t win a prize for “security by design” with such an approach, but it might set the bar higher for successful attacks.</p>
<p class="indent">You can consider including hardware-based system identifiers, as described in <a href="ch06.xhtml#ch06">Chapter 6</a>, to derive a device-unique unlocking secret instead of a global software-only solution that can be emulated easily off-device. Further, you might implement secret sharing methods like splitting the key-file contents into multiple pieces and dynamically combining them to obtain the final secret at runtime, which at least hampers simple static analysis attacks. In any case, you have to be aware that an attacker who obtained root privileges is able to circumvent all of that and access the decrypted filesystem at runtime. And for the next product generation, you’ll make secure storage a priority from day one.</p>
<h3 class="h3" id="ch00lev1_48"><strong>Read-Out Protection as a Low-Cost Solution</strong></h3>
<p class="noindent">Some small embedded systems are low cost, don’t have a secure memory, aren’t able to run Linux, and can’t afford external secure elements at all. These devices might be based on microcontrollers running a real-time operating system (RTOS) or even only bare-metal software.</p>
<p class="indent">However, even those cases might have data that deserves a certain level of confidentiality protection. Since these devices often store all their code and data within internal flash memory, restricting read access to flash memory might be a simple yet effective measure to protect sensitive information. <span epub:type="pagebreak" id="page_99"/>The activation of <em>read-out protection</em>—for example, by burning the corresponding fuses—leads to a device that can execute the internally stored code but denies requests to extract its nonvolatile memory contents.</p>
<p class="indent">Even so, be aware that physical attackers with suitable equipment can circumvent these basic protection features of low-cost microcontrollers and get access to your confidential data.</p>
<h3 class="h3" id="ch00lev1_49"><strong>Summary</strong></h3>
<p class="noindent">This chapter covered several classes of data that might require confidentiality protection, from intellectual property to media content to cryptographic secrets. Unfortunately, no perfect solution exists for storing such sensitive data in embedded systems. One reason for this dilemma is that, in comparison to a PC, embedded systems have no active users who keep the master secrets in their brains to enter them whenever needed.</p>
<p class="indent">Since all secrets have to be available in the same device at all times, the only thing we can do is hide those secrets in well-protected places, like secure elements, internal OTP memory, or within obfuscated software. All these solutions aim to increase the barriers an attacker has to break down for a successful compromise, but each comes with its own advantages and drawbacks.</p>
<p class="indent">Many approaches push secret disclosure and usage to the runtime phase of a device, which requires an adversary to take control of certain parts of a running device or even to execute custom code. Therefore, the quality and success of confidentiality protection have a strong relation to the runtime integrity of a device, which we’ll discuss in <a href="ch08.xhtml#ch08">Chapter 8</a>.<span epub:type="pagebreak" id="page_100"/></p>
</div></body></html>