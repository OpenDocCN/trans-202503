["```\n; Listing 11-1\n\n; CPUID Demonstration.\n\n        option  casemap:none\n\nnl          =       10\n\n            .const\nttlStr      byte    \"Listing 11-1\", 0\n\n            .data\nmaxFeature  dword   ?\nVendorID    byte    14 dup (0)\n\n            .code\n            externdef printf:proc\n\n; Return program title to C++ program:\n\n            public  getTitle\ngetTitle    proc\n            lea     rax, ttlStr\n            ret\ngetTitle    endp\n\n; Used for debugging:\n\nprint       proc\n            push    rax\n            push    rbx\n            push    rcx\n            push    rdx\n            push    r8\n            push    r9\n            push    r10\n            push    r11\n\n            push    rbp\n            mov     rbp, rsp\n            sub     rsp, 40\n            and     rsp, -16\n\n            mov     rcx, [rbp + 72]   ; Return address\n            call    printf\n\n            mov     rcx, [rbp + 72]\n            dec     rcx\nskipTo0:    inc     rcx\n            cmp     byte ptr [rcx], 0\n            jne     skipTo0\n            inc     rcx\n            mov     [rbp + 72], rcx\n\n            leave\n            pop     r11\n            pop     r10\n            pop     r9\n            pop     r8\n            pop     rdx\n            pop     rcx\n            pop     rbx\n            pop     rax\n            ret\nprint       endp\n\n; Here is the \"asmMain\" function.\n\n            public  asmMain\nasmMain     proc\n            push    rbx\n            push    rbp\n            mov     rbp, rsp\n sub     rsp, 56         ; Shadow storage\n\n            xor     eax, eax\n            cpuid\n            mov     maxFeature, eax\n            mov     dword ptr VendorID, ebx \n            mov     dword ptr VendorID[4], edx \n            mov     dword ptr VendorID[8], ecx\n\n            lea     rdx, VendorID\n            mov     r8d, eax\n            call    print\n            byte    \"CPUID(0): Vendor ID='%s',  \"\n            byte    \"max feature=0%xh\", nl, 0\n\n; Leaf function 1 is available on all CPUs that support\n; CPUID, no need to test for it. \n\n            mov     eax, 1\n            cpuid\n            mov     r8d, edx\n            mov     edx, ecx\n            call    print\n            byte    \"cpuid(1), ECX=%08x, EDX=%08x\", nl, 0\n\n; Most likely, leaf function 7 is supported on all modern CPUs\n; (for example, x86-64), but we'll test its availability nonetheless.\n\n            cmp     maxFeature, 7\n            jb      allDone\n\n            mov     eax, 7\n            xor     ecx, ecx\n            cpuid\n            mov     edx, ebx\n            mov     r8d, ecx\n            call    print\n            byte    \"cpuid(7), EBX=%08x, ECX=%08x\", nl, 0\n\nallDone:    leave\n            pop     rbx\n            ret     ; Returns to caller\nasmMain     endp\n            end\n```", "```\nC:\\>**build listing11-1**\n\nC:\\>**echo off**\n Assembling: listing11-1.asm\nc.cpp\n\nC:\\>**listing11-1**\nCalling Listing 11-1:\nCPUID(0): Vendor ID='GenuineIntel', max feature=0dh\ncpuid(1), ECX=ffba2203, EDX=1f8bfbff\ncpuid(7), EBX=00000281, ECX=00000000\nListing 11-1 terminated\n```", "```\nC:\\>**listing11-1**\nCalling Listing 11-1:\nCPUID(0): Vendor ID='GenuineIntel', max feature=016h\ncpuid(1), ECX=fffa3203, EDX=1f8bfbff\ncpuid(7), EBX=d09f47bb, ECX=00000000\nListing 11-1 terminated\n```", "```\n; Test for extended bit manipulation instructions \n; (BMI1 and BMI2):\n\n            and     ebx, 108h       ; Test bits 3 and 8\n            cmp     ebx, 108h       ; Both must be set\n            jne     Unsupported\n            call    print\n            byte    \"CPU supports BMI1 & BMI2\", nl, 0\n            jmp     allDone \n\nUnsupported:\n            call    print\n            byte    \"CPU does not support BMI1 & BMI2 \"\n            byte    \"instructions\", nl, 0\n\nallDone:    leave\n            pop     rbx\n            ret     ; Returns to caller\nasmMain     endp\n```", "```\nC:\\>**build listing11-2**\n\nC:\\>**echo off**\n Assembling: listing11-2.asm\nc.cpp\n\nC:\\>**listing11-2**\nCalling Listing 11-2:\nCPUID(0): Vendor ID='GenuineIntel', max feature=0dh\ncpuid(1), ECX=ffba2203, EDX=1f8bfbff\ncpuid(7), EBX=00000281, ECX=00000000\nCPU does not support BMI1 & BMI2 instructions\nListing 11-2 terminated\n```", "```\nC:\\>**listing11-2**\nCalling Listing 11-2:\nCPUID(0): Vendor ID='GenuineIntel', max feature=016h\ncpuid(1), ECX=fffa3203, EDX=1f8bfbff\ncpuid(7), EBX=d09f47bb, ECX=00000000\nCPU supports BMI1 & BMI2\nListing 11-2 terminated\n```", "```\n`segname`  segment `readonly` `alignment` '`class`'\n         statements\n`segname`  ends\n```", "```\ndseg64  segment align(64)\nobj64   oword   0, 1, 2, 3   ; Starts on 64-byte boundary\nb       byte    0            ; Messes with alignment\n        align   32           ; Sets alignment to 32 bytes\nobj32   oword   0, 1         ; Starts on 32-byte boundary\ndseg64  ends\n```", "```\nalign 16\n```", "```\navxData    segment  align(32)\n           align    32    ; This is actually redundant here\nsomeData   oword    0, 1  ; 256 bits of data\n             .\n             .\n             .\navxData    ends\n```", "```\navx2Data   segment  align(64)\nsomeData   oword    0, 1, 2, 3  ; 512 bits of data\n             .\n             .\n             .\navx2Data   ends\n```", "```\nSIMDData   segment  align(64)\nsseData    oword    0    ; 64-byte-aligned is also 16-byte-aligned\n           align    32   ; Alignment for AVX data\navxData    oword    0, 1 ; 32 bytes of data aligned on 32 bytes\n           align    64\navx2Data   oword    0, 1, 2, 3  ; 64 bytes of data\n             .\n             .\n             .\nSIMDData   ends\n```", "```\nsseproc     proc\nsseptr      equ     <[rbp - 8]>\navxptr      equ     <[rbp - 16]>\navx2ptr     equ     <[rbp - 24]>\n            push    rbp\n            mov     rbp, rsp\n            sub     rsp, 160\n\n; Load RAX with an address 64 bytes\n; above the current stack pointer. A\n; 64-byte-aligned address will be somewhere\n; between RSP and RSP + 63.\n\n            lea     rax, [rsp + 63]\n\n; Mask out the LO 6 bits of RAX. This\n; generates an address in RAX that is\n; aligned on a 64-byte boundary and is\n; between RSP and RSP + 63:\n\n            and     rax, -64 ; 0FFFF...FC0h\n\n; Save this 64-byte-aligned address as\n; the pointer to the AVX2 data:\n\n            mov     avx2ptr, rax\n\n; Add 64 to AVX2's address. This skips\n; over AVX2's data. The address is also\n; 64-byte-aligned (which means it is\n; also 32-byte-aligned). Use this as\n; the address of AVX's data:\n\n            add     rax, 64\n            mov     avxptr, rax\n\n; Add 32 to AVX's address. This skips\n; over AVX's data. The address is also\n; 32-byte-aligned (which means it is\n; also 16-byte-aligned). Use this as\n; the address of SSE's data:\n\n            add     rax, 32\n            mov     sseptr, rax\n             .\n             . `Code that accesses the`\n             . `AVX2, AVX, and SSE data`\n             . `areas using avx2ptr`,\n             . `avxptr, and sseptr`\n\n            leave\n            ret\nsseproc     endp\n```", "```\nmovd `xmm`[*n*], `reg`32/`mem`32\nmovq `xmm`[*n*], `reg`64/`mem`64\n```", "```\nmovd `reg`[32]/`mem`[32], `xmm`n\nmovq `reg`[64]/`mem`[64], `xmm`n\n```", "```\nmovq `xmm`n, `xmm`n\n```", "```\nvmovd `xmm`n, `reg`[32]/`mem`[32]\nvmovd `reg`[32]/`mem`[32], `xmm`n\nvmovq `xmm`n, `reg`[64]/`mem`[64]\nvmovq `reg`[64]/`mem`[64], `xmm`n\n```", "```\nmovaps `xmm`n, `mem`[128]    vmovaps `xmm`n, `mem`[128]    vmovaps `ymm`n, `mem`[256]\nmovaps `mem`[128], `xmm`n    vmovaps `mem`[128], `xmm`n    vmovaps `mem`[256], `ymm`n\nmovaps `xmm`n, `xmm`n     vmovaps `xmm`n, `xmm`n     vmovaps `ymm`n, `ymm`n\nmovapd `xmm`n, `mem`[128]    vmovapd `xmm`n, `mem`[128]    vmovapd `ymm`n, `mem`[256]\nmovapd `mem`[128], `xmm`n    vmovapd `mem`[128], `xmm`n    vmovapd `mem`[256], `ymm`n\nmovapd `xmm`n, `xmm`n     vmovapd `xmm`n, `xmm`n     vmovapd `ymm`n, `ymm`n\nmovdqa `xmm`n, `mem`[128]    vmovdqa `xmm`n, `mem`[128]    vmovdqa `ymm`n, `mem`[256]\nmovdqa `mem`[128], `xmm`n    vmovdqa `mem`[128], `xmm`n    vmovdqa `mem`[256], `ymm`n\nmovdqa `xmm`n, `xmm`n     vmovdqa `xmm`n, `xmm`n     vmovdqa `ymm`n, `ymm`n\n```", "```\n; Listing 11-3\n\n; Performance test for packed versus unpacked\n; instructions. This program times aligned accesses.\n\n        option  casemap:none\n\nnl          =       10\n\n            .const\nttlStr      byte    \"Listing 11-3\", 0\n\ndseg        segment align(64) 'DATA'\n\n; Aligned data types:\n\n            align   64\nalignedData byte    64 dup (0)\ndseg        ends\n\n            .code\n            externdef printf:proc\n\n; Return program title to C++ program:\n\n            public  getTitle\ngetTitle    proc\n            lea     rax, ttlStr\n            ret\ngetTitle    endp\n\n; Used for debugging:\n\nprint       proc\n\n; Print code removed for brevity.\n; See Listing 11-1 for actual code.\n\nprint       endp\n\n; Here is the \"asmMain\" function.\n\n            public  asmMain\nasmMain     proc\n            push    rbx\n            push    rbp\n            mov     rbp, rsp\n            sub     rsp, 56         ; Shadow storage\n\n            call    print\n            byte    \"Starting\", nl, 0\n\n            mov     rcx, 4000000000 ; 4,000,000,000\n            lea     rdx, alignedData\n            mov     rbx, 0\nrptLp:      mov     rax, 15\nrptLp2:     movaps  xmm0, xmmword ptr [rdx + rbx * 1]\n            movapd  xmm0, real8 ptr   [rdx + rbx * 1]\n            movdqa  xmm0, xmmword ptr [rdx + rbx * 1]\n            vmovaps ymm0, ymmword ptr [rdx + rbx * 1]\n            vmovapd ymm0, ymmword ptr [rdx + rbx * 1]\n            vmovdqa ymm0, ymmword ptr [rdx + rbx * 1]\n            vmovaps zmm0, zmmword ptr [rdx + rbx * 1]\n            vmovapd zmm0, zmmword ptr [rdx + rbx * 1]\n\n            dec     rax\n            jns     rptLp2\n\n            dec     rcx\n            jnz     rptLp\n\n            call    print\n            byte    \"Done\", nl, 0\n\nallDone:    leave\n            pop     rbx\n ret     ; Returns to caller\nasmMain     endp\n            end\n```", "```\n; Listing 11-4\n\n; Performance test for packed versus unpacked\n; instructions. This program times unaligned accesses. \n\n        option  casemap:none\n\nnl          =       10\n\n            .const\nttlStr      byte    \"Listing 11-4\", 0\n\ndseg        segment align(64) 'DATA'\n\n; Aligned data types:\n\n            align   64\nalignedData byte    64 dup (0)\ndseg        ends\n\n            .code\n            externdef printf:proc\n\n; Return program title to C++ program:\n\n            public  getTitle\ngetTitle    proc\n            lea     rax, ttlStr\n            ret\ngetTitle    endp\n\n; Used for debugging:\n\nprint       proc\n\n; Print code removed for brevity.\n; See Listing 11-1 for actual code.\n\nprint       endp\n\n; Here is the \"asmMain\" function.\n\n            public  asmMain\nasmMain     proc\n            push    rbx\n            push    rbp\n            mov     rbp, rsp\n sub     rsp, 56         ; Shadow storage\n\n            call    print\n            byte    \"Starting\", nl, 0\n\n            mov     rcx, 4000000000 ; 4,000,000,000\n            lea     rdx, alignedData\nrptLp:      mov     rbx, 15\nrptLp2:\n            movups  xmm0, xmmword ptr [rdx + rbx * 1]\n            movupd  xmm0, real8 ptr   [rdx + rbx * 1]\n            movdqu  xmm0, xmmword ptr [rdx + rbx * 1]\n            vmovups ymm0, ymmword ptr [rdx + rbx * 1]\n            vmovupd ymm0, ymmword ptr [rdx + rbx * 1]\n            vmovdqu ymm0, ymmword ptr [rdx + rbx * 1]\n            vmovups zmm0, zmmword ptr [rdx + rbx * 1]\n            vmovupd zmm0, zmmword ptr [rdx + rbx * 1]\n            dec     rbx\n            jns     rptLp2\n\n            dec     rcx\n            jnz     rptLp\n\n            call    print\n            byte    \"Done\", nl, 0\n\nallDone:    leave\n            pop     rbx\n            ret     ; Returns to caller\nasmMain     endp\n            end\n```", "```\nmovlps  `xmm`[dest], `mem`[64]\nmovlps  `mem`[64],  `xmm`[src]\nvmovlps `xmm`[dest], `xmm`[src], `mem`[64]\nvmovlps `mem`[64],  `xmm`[src]\n```", "```\nmovhps `xmm`n, `mem`[64]\nmovhps `mem`[64], `xmm`n\nmovhpd `xmm`n, `mem`[64]\nmovhpd `mem`[64], `xmm`n\n```", "```\nr4m         real4   1.0, 2.0, 3.0, 4.0\nr8m         real8   1.0, 2.0\n              .\n              .\n              .\n            movhps  xmm0, qword ptr r4m2\n            movhpd  xmm0, r8m\n```", "```\nvmovhps `xmm`[dest], `xmm`[src], `mem`[64]\nvmovhps `mem`[64],  `xmm`[src]\nvmovhpd `xmm`[dest], `xmm`[src], `mem`[64]\nvmovhpd `mem`[64],  `xmm`[src]\n```", "```\nr4m         real4   1.0, 2.0, 3.0, 4.0\nr8m         real8   1.0, 2.0\n              .\n              .\n              .\n            vmovhps xmm0, xmm1, r4m\n            vmovhpd xmm0, xmm1, r8m\n```", "```\nmovlhps  `xmm`[dest], `xmm`[src]\nvmovlhps `xmm`[dest], `xmm`[src1], `xmm`[src2]\n```", "```\nmovhlps `xmm`[dest], `xmm`[src]\n```", "```\nvmovhlps `xmm`[dest], `xmm`[src1], `xmm`[src2]\n```", "```\nmovshdup  `xmm`[dest], `mem`[128]/`xmm`[src]\nvmovshdup `xmm`[dest], `mem`[128]/`xmm`[src]\nvmovshdup `ymm`[dest], `mem`[256]/`ymm`[src]\n```", "```\nmovsldup  `xmm`[dest], `mem`[128]/`xmm`[src]\nvmovsldup `xmm`[dest], `mem`[128]/`xmm`[src]\nvmovsldup `ymm`[dest], `mem`[256]/`ymm`[src]\n```", "```\nmovddup `xmm`[dest], `mem`[64]/`xmm`[src]\n```", "```\nmovddup  `xmm`[dest], `mem`[64]/`xmm`[src]\nvmovddup `ymm`[dest], `mem`[256]/`ymm`[src]\n```", "```\nlddqu  `xmm`[dest], `mem`[128]\nvlddqu `xmm`[dest], `mem`[128]\nvlddqu `ymm`[dest], `mem`[256]\n```", "```\npshufb `xmm`[dest], `xmm`/`mem`[128]\n```", "```\nvpshufb `xmm`[dest], `xmm`[src], `xmm`[index]/`mem`[128]\nvpshufb `ymm`[dest], `ymm`[src], `ymm`[index]/`mem`[256]\n```", "```\npshufd  `xmm`[dest], `xmm`[src]/`mem`[128], `imm`[8]\nvpshufd `xmm`[dest], `xmm`[src]/`mem`[128], `imm`[8]\nvpshufd `ymm`[dest], `ymm`[src]/`me`m[256], `imm`[8]\n```", "```\npshuflw  `xmm`[dest], `xmm`[src]/`mem`[128], `imm`[8]\npshufhw  `xmm`[dest], `xmm`[src]/`mem`[128], `imm`[8]\n\nvpshuflw `xmm`[dest], `xmm`[src]/`mem`[128], `imm`[8]\nvpshufhw `xmm`[dest], `xmm`[src]/`mem`[128], `imm`[8]\n\nvpshuflw `ymm`[dest], `ymm`[src]/`mem`[256], `imm`[8]\nvpshufhw `ymm`[dest], `ymm`[src]/`mem`[256], `imm`[8]\n```", "```\nshufps `xmm`[src1/dest], `xmm`[src2]/`mem`[128], `imm`[8]\nshufpd `xmm`[src1/dest], `xmm`[src2]/`mem`[128], `imm`[8]\n```", "```\nshufps xmm0, xmm1, 0E4h  ; 0E4h = 11 10 01 00\n```", "```\nvshufps `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128], `imm`[8]\nvshufpd `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128], `imm`[8]\n\nvshufps `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256], `imm`[8]\nvshufpd `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256], `imm`[8]\n```", "```\nunpcklps `xmm`[dest], `xmm`[src]/`mem`[128]\nunpckhps `xmm`[dest], `xmm`[src]/`mem`[128]\n```", "```\nvunpcklps `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvunpckhps `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\n\nvunpcklps `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\nvunpckhps `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n```", "```\npunpcklbw  `xmm`[dest], `xmm`[src]\npunpcklbw  `xmm`[dest], `mem`[src]\npunpckhbw  `xmm`[dest], `xmm`[src]\npunpckhbw  `xmm`[dest], `mem`[src]\npunpcklwd  `xmm`[dest], `xmm`[src]\npunpcklwd  `xmm`[dest], `mem`[src]\npunpckhwd  `xmm`[dest], `xmm`[src]\npunpckhwd  `xmm`[dest], `mem`[src]\npunpckldq  `xmm`[dest], `xmm`[src]\npunpckldq  `xmm`[dest], `mem`[src]\npunpckhdq  `xmm`[dest], `xmm`[src]\npunpckhdq  `xmm`[dest], `mem`[src]\npunpcklqdq `xmm`[dest], `xmm`[src]\npunpcklqdq `xmm`[dest], `mem`[src]\npunpckhqdq `xmm`[dest], `xmm`[src]\npunpckhqdq `xmm`[dest], `mem`[src]\n```", "```\nvpunpcklbw  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpunpckhbw  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpunpcklwd  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpunpckhwd  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpunpckldq  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpunpckhdq  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpunpcklqdq `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpunpckhqdq `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\n```", "```\nvpunpcklbw  `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\nvpunpckhbw  `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\nvpunpcklwd  `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\nvpunpckhwd  `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\nvpunpckldq  `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\nvpunpckhdq  `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\nvpunpcklqdq `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\nvpunpckhqdq `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n```", "```\npextrb  `reg`[32], `xmm`[src], `imm`[8]   ; imm[8] = 0 to 15\npextrb  `reg`[64], `xmm`[src], `imm`[8]   ; imm[8] = 0 to 15\npextrb  `mem`[8], `xmm`[src], `imm`[8]    ; imm[8] = 0 to 15\nvpextrb `reg`[32], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 15\nvpextrb `reg`[64], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 15\nvpextrb `mem`[8], `xmm`[src], `imm`[8]   ; imm[8] = 0 to 15\n\npextrw  `reg`[32], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 7\npextrw  `reg`[64], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 7\npextrw  `mem`[16], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 7\nvpextrw `reg`[32], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 7\nvpextrw `reg`[64], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 7\nvpextrw `mem`[16], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 7\n\npextrd  `reg`[32], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 3\npextrd  `mem`[32], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 3\nvpextrd `mem`[64], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 3\nvpextrd `reg`[32], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 3\nvpextrd `reg`[64], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 3\nvpextrd `mem`[32], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 3\n\npextrq  `reg`[64], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 1\npextrq  `mem`[64], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 1\nvpextrq `reg`[64], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 1\nvpextrq `mem`[64], `xmm`[src], `imm`[8]  ; imm[8] = 0 to 1\n```", "```\npinsrb  `xmm`[dest], `reg`[32], `imm`[8]          ; imm[8] = 0 to 15\npinsrb  `xmm`[dest], `mem`[8], `imm`[8]           ; imm[8] = 0 to 15\nvpinsrb `xmm`[dest], `xmm`[src2], `reg`[32], `imm`[8]   ; imm[8] = 0 to 15\nvpinsrb `xmm`[dest], `xmm`[src2], `mem`[8], `imm`[8]    ; imm[8] = 0 to 15\n\npinsrw  `xmm`dest, `reg`32, `imm`8          ; imm[*8*] = 0 to 7\npinsrw  `xmm`[dest], `mem`[16], `imm`[8]          ; imm[8] = 0 to 7\nvpinsrw `xmm`[dest], `xmm`[src2], `reg`[32], `imm`[8]  ; imm[8] = 0 to 7\nvpinsrw `xmm`[dest], `xmm`[src2], `mem`[16], `imm`[8]  ; imm[8] = 0 to 7\n\npinsrd  `xmm`[dest], `reg`[32], `imm`[8]          ; imm[8] = 0 to 3\npinsrd  `xmm`[dest], `mem`[32], `imm`[8]          ; imm[8] = 0 to 3\nvpinsrd `xmm`[dest], `xmm`[src2], `reg`[32], `imm`[8]  ; imm[8] = 0 to 3\nvpinsrd `xmm`[dest], `xmm`[src2], `mem`[32], `imm`[8]  ; imm[8] = 0 to 3\n\npinsrq  `xmm`[dest], `reg`[64], `imm`[8]          ; imm[8] = 0 to 1\npinsrq  `xmm`[dest], `xmm`[src2], `mem`[64], `imm`[8]  ; imm[8] = 0 to 1\nvpinsrq `xmm`[dest], `xmm`[src2], `reg`[64], `imm`[8]  ; imm[8] = 0 to 1\nvpinsrq `xmm`[dest], `xmm`[src2], `mem`[64], `imm`[8]  ; imm[8] = 0 to 1\n```", "```\nextractps  `reg`[32], `xmm`[src], `imm`[8]\nextractps  `mem`[32], `xmm`[src], `imm`[8]\nvextractps `reg`[32], `xmm`[src], `imm`[8]\nvextractps `mem`[32], `xmm`[src], `imm`[8]\n```", "```\ninsertps  `xmm`[dest], `xmm`[src], `imm`[8]\ninsertps  `xmm`[dest], `mem`[32], `imm`[8]\nvinsertps `xmm`[dest], `xmm`[src1], `xmm`[src2], `imm`[8]\nvinsertps `xmm`[dest], `xmm`[src1], `mem`[32], `imm`[8]\n```", "```\nandpd   `xmm`[dest], `xmm`[src]/`mem`[128]\nvandpd  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvandpd  `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n\nandnpd  `xmm`[dest], `xmm`[src]/`mem`[128]\nvandnpd `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvandnpd `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n\norpd    `xmm`[dest], `xmm`[src]/`mem`[128]\nvorpd   `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvorpd   `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n\nxorpd   `xmm`[dest], `xmm`[src]/`mem`[128]\nvxorpd  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvxorpd  `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n```", "```\nptest  `xmm`[src1], `xmm`[src2]/`mem`[128]\nvptest `xmm`[src1], `xmm`[src2]/`mem`[128]\nvptest `ymm`[src1], `ymm`[src2]/`mem`[256]\n```", "```\npslldq  `xmm`[dest], `imm`[8]\nvpslldq `xmm`[dest], `xmm`[src], `imm`[8]\nvpslldq `ymm`[dest], `ymm`[src], `imm`[8]\npsrldq  `xmm`[dest], `imm`[8]\nvpsrldq `xmm`[dest], `xmm`[src], `imm`[8]\nvpsrldq `ymm`[dest], `ymm`[src], `imm`[8]\n```", "```\n`shift`  `xmm`[dest], `imm`[8]\n`shift`  `xmm`[dest], `xmm`[src]/`mem`[128]\n`vshift` `xmm`[dest], `xmm`[src], `imm`[8]\n`vshift` `xmm`[dest], `xmm`[src], `mem`[128]\n`vshift` `ymm`[dest], `ymm`[src], `imm`[8]\n`vshift` `ymm`[dest], `ymm`[src], `xmm`/`mem`[128]\n```", "```\nphaddw `xmm`[dest], `xmm`[src]/`mem`[128]\n```", "```\ntemp[0 to 15]    = `xmm`[dest][0 to 15]        + `xmm`[dest][16 to 31]\ntemp[16 to 31]   = `xmm`[dest][32 to 47]       + `xmm`[dest][48 to 63]\ntemp[32 to 47]   = `xmm`[dest][64 to 79]       + `xmm`[dest][80 to 95]\ntemp[48 to 63]   = `xmm`[dest][96 to 111]      + `xmm`[dest][112 to 127]\ntemp[64 to 79]   = `xmm`[src]/`mem`[128][0 to 15]   + `xmm`[src]/`mem`[128][16 to 31]\ntemp[80 to 95]   = `xmm`[src]/`mem`[128][32 to 47]  + `xmm`[src]/`mem`[128][48 to 63]\ntemp[96 to 111]  = `xmm`[src]/`mem`[128][64 to 79]  + `xmm`[src]/`mem`[128][80 to 95]\ntemp[112 to 127] = `xmm`[src]/`mem`[128][96 to 111] + `xmm`[src]/`mem`[128][112 to 127]\n`xmm`[dest] = temp\n```", "```\nvphaddw `xmm`dest, `xmm`src1, `xmm`src2/`mem`128\n```", "```\n`xmm`[dest][0 to 15]    = `xmm`[src1][0 to 15]         + `xmm`[src1][16 to 31]\n`xmm`[dest][16 to 31]   = `xmm`[src1][32 to 47]        + `xmm`[src1][48 to 63]\n`xmm`[dest][32 to 47]   = `xmm`[src1][64 to 79]        + `xmm`[src1][80 to 95]\n`xmm`[dest][48 to 63]   = `xmm`[src1][96 to 111]       + `xmm`[src1][112 to 127]\n`xmm`[dest][64 to 79]   = `xmm`[src2]/`mem`[128][0 to 15]   + `xmm`[src2]/`mem`[128][16 to 31]\n`xmm`[dest][80 to 95]   = `xmm`[src2]/`mem`[128][32 to 47]  + `xmm`[src2]/`mem`[128][48 to 63]\n`xmm`[dest][96 to 111]  = `xmm`[src2]/`mem`[128][64 to 79]  + `xmm`[src2]/`mem`[128][80 to 95]\n`xmm`[dest][111 to 127] = `xmm`[src2]/`mem`[128][96 to 111] + `xmm`[src2]/`mem`[128][112 to 127]\n```", "```\nvphaddw `ymm`dest, `ymm`src1, `ymm`src2/`mem`256\n```", "```\n`ymm`[dest][0 to 15]    = SRC1[16 to 31]   + SRC1[0 to 15]\n`ymm`[dest][16 to 31]   = SRC1[48 to 63]   + SRC1[32 to 47]\n`ymm`[dest][32 to 47]   = SRC1[80 to 95]   + SRC1[64 to 79]\n`ymm`[dest][48 to 63]   = SRC1[112 to 127] + SRC1[96 to 111]\n`ymm`[dest][64 to 79]   = SRC2[16 to 31]   + SRC2[0 to 15]\n`ymm`[dest][80 to 95]   = SRC2[48 to 63]   + SRC2[32 to 47]\n`ymm`[dest][96 to 111]  = SRC2[80 to 95]   + SRC2[64 to 79]\n`ymm`[dest][112 to 127] = SRC2[112 to 127] + SRC2[96 to 111]\n`ymm`[dest][128 to 143] = SRC1[144 to 159] + SRC1[128 to 143]\n`ymm`[dest][144 to 159] = SRC1[176 to 191] + SRC1[160 to 175]\n`ymm`[dest][160 to 175] = SRC1[208 to 223] + SRC1[192 to 207]\n`ymm`[dest][176 to 191] = SRC1[240 to 255] + SRC1[224 to 239]\n`ymm`[dest][192 to 207] = SRC2[144 to 159] + SRC2[128 to 143]\n`ymm`[dest][208 to 223] = SRC2[176 to 191] + SRC2[160 to 175]\n`ymm`[dest][224 to 239] = SRC2[208 to 223] + SRC2[192 to 207]\n`ymm`[dest][240 to 255] = SRC2[240 to 255] + SRC2[224 to 239]\n```", "```\nphaddd `xmm`[dest], `xmm`[src]/`mem`[128]\n```", "```\ntemp[0 to 31]   = `xmm`[dest][0 to 31]       + `xmm`[dest][32 to 63]\ntemp[32 to 63]  = `xmm`[dest][64 to 95]      + `xmm`[dest][96 to 127]\ntemp[64 to 95]  = `xmm`[src]/`mem`[128][0 to 31]  + `xmm`[src]/`mem`[128][32 to 63]\ntemp[96 to 127] = `xmm`[src]/`mem`[128][64 to 95] + `xmm`[src]/`mem`[128][96 to 127]\n`xmm`[dest] = temp\n```", "```\nvphaddd `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\n```", "```\n`xmm`dest[0 to 31]     = `xmm`src1[0 to 31]        + `xmm`src1[32 to 63]\n`xmm`dest[32 to 63]    = `xmm`src1[64 to 95]       + `xmm`src1[96 to 127]\n`xmm`dest[64 to 95]    = `xmm`src2/`mem`128[0 to 31]  + `xmm`src2/`mem`128[32 to 63]\n`xmm`dest[96 to 127]   = `xmm`src2/`mem`128[64 to 95] + `xmm`src2/`mem`128[96 to 127]\n(`ymm`dest[128 to 255] = 0)\n```", "```\nvphaddd `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n```", "```\n`ymm`[dest][0 to 31]    = `ymm`[src1][32 to 63]         + `ymm`[src1][0 to 31]\n`ymm`[dest][32 to 63]   = `ymm`[src1][96 to 127]        + `ymm`[src1][64 to 95]\n`ymm`[dest][64 to 95]   = `ymm`[src2]/mem[128][32 to 63]   + `ymm`[src2]/`mem`[128][0 to 31]\n`ymm`[dest][96 to 127]  = `ymm`[src2]/mem[128][96 to 127]  + `ymm`[src2]/`mem`[128][64 to 95]\n`ymm`[dest][128 to 159] = `ymm`[src1][160 to 191]       + `ymm`[src1][128 to 159]\n`ymm`[dest][160 to 191] = `ymm`[src1][224 to 255]       + `ymm`[src1][192 to 223]\n`ymm`[dest][192 to 223] = `ymm`[src2]/`mem`[128][160 to 191] + `ymm`[src2]/`mem`[128][128 to 159]\n`ymm`[dest][224 to 255] = `ymm`[src2]/`mem`[128][224 to 255] + `ymm`[src2]/`mem`[128][192 to 223]\n```", "```\nphaddsw  `xmm`[dest], `xmm`[src]/`mem`[128]\nvphaddsw `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvphaddsw `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n```", "```\npmuldq   `xmm`[dest], `xmm`/`mem`[128]\nvpmuldq  `xmm`[dest], `xmm`[src1], `xmm`/`mem`[128]\nvpmuldq  `ymm`[dest], `ymm`[src1], `ymm`/`mem`[256]\n\npmuludq  `xmm`[dest], `xmm`/`mem`[128]\nvpmuludq `xmm`[dest], `xmm`[src1], `xmm`/`mem`[128]\nvpmuludq `ymm`[dest], `ymm`[src1], `ymm`/`mem`[256]\n```", "```\npclmulqdq  `xmm`[dest], `xmm`/`mem`[128], `imm`[8]\nvpclmulqdq `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128], `imm`[8]\n```", "```\npavgb  `xmm`[dest], `xmm`/`mem`[128]\nvpavgb `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpavgb `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\npavgw  `xmm`[dest], `xmm`/`mem`[128]\nvpavgw `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpavgw `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n```", "```\npm`xxyz`  `xmm`[dest], `xmm`[src]/`mem`[128]\nvpm`xxyz` `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpm`xxyz` `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n```", "```\npabsb  `xmm`[dest], `xmm`[src]/`mem`[128]\nvpabsb `xmm`[dest], `xmm`[src]/`mem`[128]\nvpabsb `ymm`[dest], `ymm`[src]/`mem`[256]\n\npabsw  `xmm`[dest], `xmm`[src]/`mem`[128]\nvpabsw `xmm`[dest], `xmm`[src]/`mem`[128]\nvpabsw `ymm`[dest], `ymm`[src]/`mem`[256]\n\npabsd  `xmm`[dest], `xmm`[src]/`mem`[128]\nvpabsd `xmm`[dest], `xmm`[src]/`mem`[128]\nvpabsd `ymm`[dest], `ymm`[src]/`mem`[256]\n```", "```\nif source lane value is less than zero then\n    negate the corresponding destination lane\nelse if source lane value is equal to zero\n    set the corresponding destination lane to zero\nelse \n    leave the corresponding destination lane unchanged\n```", "```\npsignb  `xmm`[dest], `xmm`[src]/`mem`[128]\nvpsignb `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpsignb `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n\npsignw  `xmm`[dest], `xmm`[src]/`mem`[128]\nvpsignw `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpsignw `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n\npsignd  `xmm`[*dest*], `xmm`[*src*]/`mem`[*128*]\nvpsignd `xmm`[*dest*], `xmm`[*src1*], `xmm`[*src2*]/`mem`[*128*]\nvpsignd `ymm`[*dest*], `ymm`[*src1*], `ymm`[*src2*]/`mem`[*256*]\n```", "```\npcmpeqb `xmm`[dest], `xmm`[src]/`mem`[128]  ; Compares 16 bytes\npcmpeqw `xmm`[dest], `xmm`[src]/`mem`[128]  ; Compares 8 words\npcmpeqd `xmm`[dest], `xmm`[src]/`mem`[128]  ; Compares 4 dwords\npcmpeqq `xmm`[dest], `xmm`[src]/`mem`[128]  ; Compares 2 qwords\n```", "```\n`xmm`[dest][`lane`] = `xmm`[dest][`lane`] == `xmm`[src]/`mem`[128][`lane`]\n```", "```\npcmpgtb `xmm`[dest], `xmm`[src]/`mem`[128]  ; Compares 16 bytes\npcmpgtw `xmm`[dest], `xmm`[src]/`mem`[128]  ; Compares 8 words\npcmpgtd `xmm`[dest], `xmm`[src]/`mem`[128]  ; Compares 4 dwords\npcmpgtq `xmm`[dest], `xmm`[src]/`mem`[128]  ; Compares 2 qwords\n```", "```\n`xmm`[dest][`lane`] = `xmm`[dest][`lane`] > `xmm`[src]/`mem`[128][`lane`]\n```", "```\nvpcmpeqb `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]  ; Compares 16 bytes\nvpcmpeqw `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]  ; Compares 8 words\nvpcmpeqd `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]  ; Compares 4 dwords\nvpcmpeqq `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]  ; Compares 2 qwords\n\nvpcmpgtb `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]  ; Compares 16 bytes\nvpcmpgtw `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]  ; Compares 8 words\nvpcmpgtd `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]  ; Compares 4 dwords\nvpcmpgtq `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]  ; Compares 2 qwords\n```", "```\n`xmm`[dest][`lane`] = `xmm`[src1][`lane`] == `xmm`[src2]/`mem`[128][`lane`]\n`xmm`[dest][`lane`] = `xmm`[src1][`lane`] >  `xmm`[src2]/`mem`[128][`lane`]\n```", "```\nvpcmpeqb `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]  ; Compares 32 bytes\nvpcmpeqw `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]  ; Compares 16 words\nvpcmpeqd `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]  ; Compares 8 dwords\nvpcmpeqq `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]  ; Compares 4 qwords\n\nvpcmpgtb `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]  ; Compares 32 bytes\nvpcmpgtw `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]  ; Compares 16 words\nvpcmpgtd `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]  ; Compares 8 dwords\nvpcmpgtq `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]  ; Compares 4 qwords\n```", "```\n`ymm`[dest][`lane`] = `ymm`[src1][`lane`] == `ymm`[src2]/`mem`[256][`lane`]\n`ymm`[dest][`lane`] = `ymm`[src1][`lane`] >  `ymm`[src2]/`mem`[256][`lane`]\n```", "```\npmovmskb  `reg`, `xmm`[src]\nvpmovmskb `reg`, `xmm`[src]\nvpmovmskb `reg`, `ymm`[src]\n```", "```\npcmpeqb  xmm0, xmm1\npmovmskb eax,  xmm0\n```", "```\npcmpeqw  xmm0, xmm1\npmovmskb eax, xmm0\nmov      cl, 0     ; Put result here\nshr      ax, 1     ; Shift out lane 7 result\nrcl      cl, 1     ; Shift bit into CL\nshr      ax, 1     ; Ignore this bit\nshr      ax, 1     ; Shift out lane 6 result\nrcl      cl, 1     ; Shift lane 6 result into CL\nshr      ax, 1     ; Ignore this bit\nshr      ax, 1     ; Shift out lane 5 result\nrcl      cl, 1     ; Shift lane 5 result into CL\nshr      ax, 1     ; Ignore this bit\nshr      ax, 1     ; Shift out lane 4 result\nrcl      cl, 1     ; Shift lane 4 result into CL\nshr      ax, 1     ; Ignore this bit\nshr      ax, 1     ; Shift out lane 3 result\nrcl      cl, 1     ; Shift lane 3 result into CL\nshr      ax, 1     ; Ignore this bit\nshr      ax, 1     ; Shift out lane 2 result\nrcl      cl, 1     ; Shift lane 2 result into CL\nshr      ax, 1     ; Ignore this bit\nshr      ax, 1     ; Shift out lane 1 result\nrcl      cl, 1     ; Shift lane 1 result into CL\nshr      ax, 1     ; Ignore this bit\nshr      ax, 1     ; Shift out lane 0 result\nrcl      cl, 1     ; Shift lane 0 result into CL\n```", "```\npcmpeqw  xmm0, xmm1\npmovmskb eax, xmm0\nshr      al, 1     ; Move odd bits to even positions\nand      al, 55h   ; Zero out the odd bits, keep even bits\nand      ah, 0aah  ; Zero out the even bits, keep odd bits\nor       al, ah    ; Merge the two sets of bits\n```", "```\nvpacksswb  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpackuswb  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpackssdw  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvpackusdw  `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\n```", "```\n`instr`ps `xmm`[dest], `xmm`[src]/`mem`[128]\n`instr`pd `xmm`[dest], `xmm`[src]/`mem`[128]\n```", "```\n`xmm`[dest][`lane`] = `xmm`[dest][`lane`] `op` `xmm`[src]/`mem`[128][`lane`]\n```", "```\nv`instr`ps `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128] ; For dyadic operations\nv`instr`pd `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128] ; For dyadic operations\nv`instr`ps `xmm`[dest], `xmm`[src]/`mem`[128]          ; For monadic operations\nv`instr`pd `xmm`[dest], `xmm`[src]/`mem`[128]          ; For monadic operations\n```", "```\n`xmm`[dest][`lane`] = `xmm`[src1][`lane`] `op` `xmm`[src2]/`mem`[128][`lane`]\n```", "```\nv`instr`ps `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256] ; For dyadic operations\nv`instr`pd `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256] ; For dyadic operations\nv`instr`ps `ymm`[dest], `ymm`[src]/`mem`[256]          ; For monadic operations\nv`instr`pd `ymm`[dest], `ymm`[src]/`mem`[256]          ; For monadic operations\n```", "```\n`ymm`[dest][`lane`] = `ymm`[src1][`lane`] `op` `ymm`[src]/`mem`[256][`lane`]\n```", "```\nhaddps  `xmm`[dest], `xmm`[src]/`mem`[128]\nvhaddps `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvhaddps `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\nhaddpd  `xmm`[dest], `xmm`[src]/`mem`[128]\nvhaddpd `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvhaddpd `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n\nhsubps  `xmm`[dest], `xmm`[src]/`mem`[128]\nvhsubps `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvhsubps `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\nhsubpd  `xmm`[dest], `xmm`[src]/`mem`[128]\nvhsubpd `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128]\nvhsubpd `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256]\n```", "```\ncmpps  `xmm`[dest], `xmm`[src]/`mem`[128], `imm`[8]\nvcmpps `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128], `imm`[8]\nvcmpps `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256], `imm`[8]\n\ncmppd  `xmm`[dest], `xmm`[src]/`mem`[128], `imm`[8]\nvcmppd `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128], `imm`[8]\nvcmppd `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256], `imm`[8]\n```", "```\ncmpeqps  xmm0, xmm1\n```", "```\ncmpps  xmm0, xmm1, 0       ; Compare xmm0 to xmm1 for equality\n```", "```\nvcmpps `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128], `imm`[8]\nvcmpps `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256], `imm`[8]\n\nvcmppd `xmm`[dest], `xmm`[src1], `xmm`[src2]/`mem`[128], `imm`[8]\nvcmppd `ymm`[dest], `ymm`[src1], `ymm`[src2]/`mem`[256], `imm`[8]\n```", "```\nmovmskps  `reg`, `xmm`[src]\nmovmskpd  `reg`, `xmm`[src] \nvmovmskps `reg`, `ymm`[src]\nvmovmskpd `reg`, `ymm`[src]\n```", "```\n cmpeqpd  xmm0, xmm1\n         movmskpd rax,  xmm0      ; Moves 2 bits into RAX\n         lea      rcx,  jmpTable\n         jmp      qword ptr [rcx][rax*8]\n\njmpTable qword    nene\n         qword    neeq\n         qword    eqne\n         qword    eqeq\n```", "```\ncmpLp:  mov  al, [rsi]\n        cmp  al, someByteValue\n        je   foundByte\n        inc  rsi\n        test rsi, 0Fh\n        jnz  cmpLp\n `Use SSE instructions here, as RSI is now 16-byte-aligned` \n```", "```\n and  rsi, -16\n```", "```\n sub      rsi, 16\ncmpLp:     add      rsi, 16\n           movdqa   xmm0, xmm2   ; XMM2 contains bytes to test\n           pcmpeqb  xmm0, [rsi]\n           pmovmskb eax, xmm0\n           ptest    eax, eax\n           jz       cmpLp\n```", "```\n-1 << (startAdrs & 0xF)  ; Note: -1 is all 1 bits\n```", "```\n mov    rcx, rsi\n           and    rsi, -16   ; Align to 16 bits\n           and    ecx, 0fH   ; Strip out offset of start of data\n           mov    ebx, -1    ; 0FFFFFFFFh – all 1 bits\n           shl    ebx, cl    ; Create mask\n\n; Special case for the first 1 to 16 bytes:\n\n           movdqa   xmm0, xmm2\n           pcmpeqb  xmm0, [rsi]\n           pmovmskb eax, xmm0\n           and      eax, ebx\n           jnz      foundByte\ncmpLp:     add      rsi, 16\n           movdqa   xmm0, xmm2   ; XMM2 contains bytes to test\n           pcmpeqb  xmm0, [rsi]\n           pmovmskb eax, xmm0\n           test     eax, eax\n           jz       cmpLp\nfoundByte:\n `Do whatever needs to be done when the block of 16 bytes`\n `contains at least one match between the bytes in XMM2`\n `and the data at RSI` \n```", "```\nmovss  xmm0, r4var\npshufd xmm0, xmm0, 0    ; Lanes 3, 2, 1, and 0 from lane 0\n```", "```\nmovsd  xmm0, r8var\npshufd xmm0, xmm0, 44h  ; Lane 0 to lanes 0 and 2, 1 to 1, and 3\n```", "```\nmovddup xmm0, r8var\n```", "```\nmovzx  eax, byteToCopy\nmovd   xmm0, eax\npxor   xmm1, xmm1   ; Mask to copy byte 0 throughout\npshufb xmm0, xmm1\n```", "```\nmovzx     eax, byteToCopy\nmov       ah, al\nmovd      xmm0, eax\npunpcklbw xmm0, xmm0    ; Copy bytes 0 and 1 to 2 and 3\npshufd    xmm0, xmm0, 0 ; Copy LO dword throughout\n```", "```\npxor xmm0, xmm0\n```", "```\npcmpeqb xmm0, xmm0\n```", "```\npxor    xmm0, xmm0\npcmpeqb xmm1, xmm1\npsubb   xmm0, xmm1   ; 0 - (-1) is (1)\n```", "```\npxor    xmm0, xmm0\npcmpeqb xmm1, xmm1\npsubb   xmm0, xmm1\npslld   xmm0, 7         ; 01h -> 80h in each byte\n```", "```\n; For 16-bit lanes:\n\npcmpeqd  xmm0, xmm0     ; Set all bits to 1\npsrlw    xmm0, 16 - `n`   ; Clear top 16 - `n` bits of xmm0\n\n; For 32-bit lanes:\n\npcmpeqd  xmm0, xmm0     ; Set all bits to 1\npsrld    xmm0, 32 - `n`   ; Clear top 16 - `n` bits of xmm0\n\n; For 64-bit lanes:\n\npcmpeqd  xmm0, xmm0     ; Set all bits to 1\npsrlq    xmm0, 64 - `n`   ; Clear top 16 - `n` bits of xmm0\n```", "```\n; For 16-bit lanes:\n\npcmpeqd  xmm0, xmm0     ; Set all bits to 1\npsllw    xmm0, `n`        ; Clear bottom `n` bits of xmm0\n\n; For 32-bit lanes:\n\npcmpeqd  xmm0, xmm0     ; Set all bits to 1\npslld    xmm0, `n`        ; Clear bottom `n` bits of xmm0\n\n; For 64-bit lanes:\n\npcmpeqd  xmm0, xmm0     ; Set all bits to 1\npsllq    xmm0, `n`        ; Clear bottom `n` bits of xmm0\n```", "```\n; setXBit - Sets bit `n` in SSE register xReg.\n\nsetXBit  macro   xReg, n\n         pcmpeqb xReg, xReg   ; Set all bits in xReg\n         psrlq   xReg, 63     ; Set both 64-bit lanes to 01h\n         if      n lt 64\n         psrldq  xReg, 8      ; Clear the upper lane\n         else\n         pslldq  xReg, 8      ; Clear the lower lane\n         endif\n         if      (n and 3fh) ne 0\n         psllq   xReg, (n and 3fh)\n         endif\n         endm\n```", "```\nsetXBit xmm0, `n`      ; Set bit `n` in XMM1 to 1 without\npor     xmm1, xmm0   ; affecting any other bits\n```", "```\nsetXBit xmm0, `n`            ; Clear bit `n` in XMM1 without\nvpandn  xmm1, xmm0, xmm1   ; affecting any other bits\n```", "```\nsetXBit xmm0, `n`      ; Invert bit `n` in XMM1 without\npxor    xmm1, xmm0   ; affecting any other bits\n```", "```\nsetXBit xmm0, `n`      ; Test bit `n` in XMM1\nptest   xmm1, xmm0\njnz     bitNisSet    ; Fall through if bit `n` is clear\n```", "```\n; Remember, psllq shifts bits, not bytes.\n; If bit `n` is not in bit position 7 of a given\n; byte, then move it there. For example, if `n` = 0, then\n; (7 - (0 and 7)) is 7, so psllq moves bit 0 to bit 7.\n\nmovdqa   xmm0, xmm1\nif       7 - (`n` and 7)\npsllq    xmm0, 7 - (`n` and 7)\nendif\n\n; Now that the desired bit to test is sitting in bit position\n; 7 of *some* byte, use pmovmskb to extract all bit 7s into AX:\n\npmovmskb eax, xmm0\n\n; Now use the (integer) test instruction to test that bit:\n\ntest    ax, 1 shl (`n` / 8)\njnz     bitNisSet\n```", "```\n dec rcx\nblkLoop:  inc rcx\n          mov eax, [r8][rcx * 4]\n          cmp eax, [r9][rcx * 4]\n          je  theyreEqual\n          cmp eax, sentinelValue\n          jne blkLoop\n```", "```\n sub r8, 4\n          sub r9, 4\nblkLoop:  add r8, 4\n add r9, 4\n          mov eax, [r8]\n          cmp eax, [r9]\n          je  theyreEqual\n          cmp eax, sentinelValue\n          jne blkLoop\n```", "```\n sub r9, r8            ; R9 = R9 - R8\n          sub r8, 4\nblkLoop:  add r8, 4\n          mov eax, [r8]\n          cmp eax, [r9][r8 * 1] ; Address = R9 + R8\n          je  theyreEqual\n          cmp eax, sentinelValue\n          jne blkLoop\n```", "```\n; Assume R9 and R8 point at (32-byte-aligned) arrays of 20 double values.\n; Assume R10 points at a (32-byte-aligned) destination array of 20 doubles.\n\n          sub     r9, r8     ; R9 = R9 - R8\n          sub     r10, r8    ; R10 = R10 – R8\n          sub     r8, 32\n mov     ecx, 5     ; Vector with 20 (5 * 4) double values\naddLoop:  add     r8, 32\n          vmovapd ymm0, [r8]\n          vaddpd  ymm0, ymm0, [r9][r8 * 1] ; Address = R9 + R8\n          vmovapd [r10][r8 * 1], ymm0      ; Address = R10 + R8\n          dec     ecx\n          jnz     addLoop\n```", "```\naddLoop:  add     r8, 32\n          vmovupd ymm0, [r8]\n          vmovupd ymm1, [r9][r8 * 1]  ; Address = R9 + R8\n          vaddpd  ymm0, ymm0, ymm1\n          vmovupd [r10][r8 * 1], ymm0 ; Address = R10 + R8\n          dec     ecx\n          jnz     addLoop\n```", "```\nmovdqa   xmm0, [r8]\npcmpeqd  xmm0, [r9]\npmovmskb eax, xmm0\nand      eax, 0ffh     ; Mask out the last 8 compares\ncmp      eax, 0ffh\nje       matchedData\n```", "```\nmov  eax, r9d\nand  eax, 0fffh\ncmp  eax, 0ff0h\nja   willCrossPage\n```", "```\nAVXSupport  =     10000000h              ; Bit 28\n\nprint       proc\n\n; Preserve all the volatile registers\n; (be nice to the assembly code that\n; calls this procedure):\n\n            push    rax\n            push    rbx                  ; CPUID messes with EBX\n            push    rcx\n            push    rdx\n            push    r8\n            push    r9\n            push    r10\n            push    r11\n\n; Reserve space on the stack for the AVX/SSE registers.\n; Note: SSE registers need only 96 bytes, but the code\n; is easier to deal with if we reserve the full 128 bytes\n; that the AVX registers need and ignore the extra 64\n; bytes when running SSE code.\n\n            sub     rsp, 192\n\n; Determine if we have to preserve the YMM registers:\n\n            mov     eax, 1\n            cpuid\n            test    ecx, AVXSupport      ; Test bits 19 and 20\n            jnz     preserveAVX\n\n; No AVX support, so just preserve the XXM0 to XXM3 registers:\n\n            movdqu  xmmword ptr [rsp + 00], xmm0\n            movdqu  xmmword ptr [rsp + 16], xmm1\n            movdqu  xmmword ptr [rsp + 32], xmm2\n            movdqu  xmmword ptr [rsp + 48], xmm3\n            movdqu  xmmword ptr [rsp + 64], xmm4\n            movdqu  xmmword ptr [rsp + 80], xmm5\n            jmp     restOfPrint\n\n; YMM0 to YMM3 are considered volatile, so preserve them:\n\npreserveAVX: \n            vmovdqu ymmword ptr [rsp + 000], ymm0\n            vmovdqu ymmword ptr [rsp + 032], ymm1\n            vmovdqu ymmword ptr [rsp + 064], ymm2\n            vmovdqu ymmword ptr [rsp + 096], ymm3\n vmovdqu ymmword ptr [rsp + 128], ymm4\n            vmovdqu ymmword ptr [rsp + 160], ymm5\n\nrestOfPrint:\n        `The rest of the print function goes here`\n```", "```\n .data\nprint     qword   choosePrint\n```", "```\n; On first call, determine if we support AVX instructions\n; and set the \"print\" pointer to point at print_AVX or\n; print_SSE:\n\nchoosePrint proc\n            push    rax             ; Preserve registers that get\n            push    rbx             ; tweaked by CPUID\n            push    rcx\n            push    rdx\n\n            mov     eax, 1\n            cpuid\n            test    ecx, AVXSupport ; Test bit 28 for AVX\n            jnz     doAVXPrint\n\n            lea     rax, print_SSE  ; From now on, call\n            mov     print, rax      ; print_SSE directly\n\n; Return address must point at the format string\n; following the call to this function! So we have\n; to clean up the stack and JMP to print_SSE.\n\n            pop     rdx\n            pop     rcx\n            pop     rbx\n pop     rax\n            jmp     print_SSE\n\ndoAVXPrint: lea     rax, print_AVX  ; From now on, call\n            mov     print, rax      ; print_AVX directly\n\n; Return address must point at the format string\n; following the call to this function! So we have\n; to clean up the stack and JMP to print_AUX.\n\n            pop     rdx\n            pop     rcx\n            pop     rbx\n            pop     rax\n            jmp     print_AVX\n\nchoosePrint endp\n```", "```\ncall print\nbyte \"Hello, world!\", nl, 0\n```", "```\n; Listing 11-5\n\n; Generic print procedure and dynamically\n; selecting CPU features.\n\n        option  casemap:none\n\nnl          =       10\n\n; SSE4.2 feature flags (in ECX):\n\nSSE42       =       00180000h       ; Bits 19 and 20\nAVXSupport  =       10000000h       ; Bit 28\n\n; CPUID bits (EAX = 7, EBX register)\n\nAVX2Support  =      20h             ; Bit 5 = AVX\n\n            .const\nttlStr      byte    \"Listing 11-5\", 0\n\n            .data\n            align   qword\nprint       qword   choosePrint     ; Pointer to print function\n\n; Floating-point values for testing purposes:\n\nfp1         real8   1.0\nfp2         real8   2.0\nfp3         real8   3.0\nfp4         real8   4.0\nfp5         real8   5.0\n\n            .code\n            externdef printf:proc\n\n; Return program title to C++ program:\n\n            public  getTitle\ngetTitle    proc\n            lea     rax, ttlStr\n            ret\ngetTitle    endp\n\n***************************************************************\n\n; print - \"Quick\" form of printf that allows the format string to\n;         follow the call in the code stream. Supports up to five\n;         additional parameters in RDX, R8, R9, R10, and R11.\n\n; This function saves all the Microsoft ABI–volatile,\n; parameter, and return result registers so that code\n; can call it without worrying about any registers being\n; modified (this code assumes that Windows ABI treats\n; YMM4 to YMM15 as nonvolatile).\n\n; Of course, this code assumes that AVX instructions are\n; available on the CPU.\n\n; Allows up to 5 arguments in:\n\n;  RDX - Arg #1\n;  R8  - Arg #2\n;  R9  - Arg #3\n;  R10 - Arg #4\n;  R11 - Arg #5\n\n; Note that you must pass floating-point values in\n; these registers, as well. The printf function\n; expects real values in the integer registers. \n\n; There are two versions of this function, one that\n; will run on CPUs without AVX capabilities (no YMM\n; registers) and one that will run on CPUs that\n; have AVX capabilities (YMM registers). The difference\n; between the two is which registers they preserve\n; (print_SSE preserves only XMM registers and will\n; run properly on CPUs that don't have YMM register\n; support; print_AVX will preserve the volatile YMM\n; registers on CPUs with AVX support).\n\n; On first call, determine if we support AVX instructions\n; and set the \"print\" pointer to point at print_AVX or\n; print_SSE:\n\nchoosePrint proc\n            push    rax             ; Preserve registers that get\n            push    rbx             ; tweaked by CPUID\n            push    rcx\n            push    rdx\n\n            mov     eax, 1\n            cpuid\n            test    ecx, AVXSupport ; Test bit 28 for AVX\n            jnz     doAVXPrint\n\n            lea     rax, print_SSE  ; From now on, call\n            mov     print, rax      ; print_SSE directly\n\n; Return address must point at the format string\n; following the call to this function! So we have\n; to clean up the stack and JMP to print_SSE.\n\n            pop     rdx\n            pop     rcx\n pop     rbx\n            pop     rax\n            jmp     print_SSE\n\ndoAVXPrint: lea     rax, print_AVX  ; From now on, call\n            mov     print, rax      ; print_AVX directly\n\n; Return address must point at the format string\n; following the call to this function! So we have\n; to clean up the stack and JMP to print_AUX.\n\n            pop     rdx\n            pop     rcx\n            pop     rbx\n            pop     rax\n            jmp     print_AVX\n\nchoosePrint endp\n\n; Version of print that will preserve volatile\n; AVX registers (YMM0 to YMM3):\n\nprint_AVX   proc\n\n; Preserve all the volatile registers\n; (be nice to the assembly code that\n; calls this procedure):\n\n            push    rax\n            push    rbx\n            push    rcx\n            push    rdx\n            push    r8\n            push    r9\n            push    r10\n            push    r11\n\n; YMM0 to YMM7 are considered volatile, so preserve them:\n\n            sub     rsp, 256\n            vmovdqu ymmword ptr [rsp + 000], ymm0\n            vmovdqu ymmword ptr [rsp + 032], ymm1\n            vmovdqu ymmword ptr [rsp + 064], ymm2\n            vmovdqu ymmword ptr [rsp + 096], ymm3\n            vmovdqu ymmword ptr [rsp + 128], ymm4\n            vmovdqu ymmword ptr [rsp + 160], ymm5\n            vmovdqu ymmword ptr [rsp + 192], ymm6\n            vmovdqu ymmword ptr [rsp + 224], ymm7\n\n            push    rbp\n\nreturnAdrs  textequ <[rbp + 328]>\n\n            mov     rbp, rsp\n            sub     rsp, 128\n and     rsp, -16\n\n; Format string (passed in RCX) is sitting at\n; the location pointed at by the return address,\n; load that into RCX:\n\n            mov     rcx, returnAdrs\n\n; To handle more than 3 arguments (4 counting\n; RCX), you must pass data on stack. However, to the\n; print caller, the stack is unavailable, so use\n; R10 and R11 as extra parameters (could be just\n; junk in these registers, but pass them just\n; in case):\n\n            mov     [rsp + 32], r10\n            mov     [rsp + 40], r11\n            call    printf\n\n; Need to modify the return address so\n; that it points beyond the zero-terminating byte.\n; Could use a fast strlen function for this, but\n; printf is so slow it won't really save us anything.\n\n            mov     rcx, returnAdrs\n            dec     rcx\nskipTo0:    inc     rcx\n            cmp     byte ptr [rcx], 0\n            jne     skipTo0\n            inc     rcx\n            mov     returnAdrs, rcx\n\n            leave\n            vmovdqu ymm0, ymmword ptr [rsp + 000]\n            vmovdqu ymm1, ymmword ptr [rsp + 032]\n            vmovdqu ymm2, ymmword ptr [rsp + 064]\n            vmovdqu ymm3, ymmword ptr [rsp + 096]\n            vmovdqu ymm4, ymmword ptr [rsp + 128]\n            vmovdqu ymm5, ymmword ptr [rsp + 160]\n            vmovdqu ymm6, ymmword ptr [rsp + 192]\n            vmovdqu ymm7, ymmword ptr [rsp + 224]\n            add     rsp, 256\n            pop     r11\n            pop     r10\n            pop     r9\n            pop     r8\n            pop     rdx\n            pop     rcx\n            pop     rbx\n            pop     rax\n            ret\nprint_AVX   endp\n\n; Version that will run on CPUs without\n; AVX support and will preserve the\n; volatile SSE registers (XMM0 to XMM3):\n\nprint_SSE   proc\n\n; Preserve all the volatile registers\n; (be nice to the assembly code that\n; calls this procedure):\n\n            push    rax\n            push    rbx\n            push    rcx\n            push    rdx\n            push    r8\n            push    r9\n            push    r10\n            push    r11\n\n; XMM0 to XMM3 are considered volatile, so preserve them:\n\n            sub     rsp, 128\n            movdqu  xmmword ptr [rsp + 00],  xmm0\n            movdqu  xmmword ptr [rsp + 16],  xmm1\n            movdqu  xmmword ptr [rsp + 32],  xmm2\n            movdqu  xmmword ptr [rsp + 48],  xmm3\n            movdqu  xmmword ptr [rsp + 64],  xmm4\n            movdqu  xmmword ptr [rsp + 80],  xmm5\n            movdqu  xmmword ptr [rsp + 96],  xmm6\n            movdqu  xmmword ptr [rsp + 112], xmm7\n\n            push    rbp\n\nreturnAdrs  textequ <[rbp + 200]>\n\n            mov     rbp, rsp\n            sub     rsp, 128\n            and     rsp, -16\n\n; Format string (passed in RCX) is sitting at\n; the location pointed at by the return address,\n; load that into RCX:\n\n            mov     rcx, returnAdrs\n\n; To handle more than 3 arguments (4 counting\n; RCX), you must pass data on stack. However, to the\n; print caller, the stack is unavailable, so use\n; R10 and R11 as extra parameters (could be just\n; junk in these registers, but pass them just\n; in case):\n\n            mov     [rsp + 32], r10\n            mov     [rsp + 40], r11\n            call    printf\n\n; Need to modify the return address so\n; that it points beyond the zero-terminating byte.\n; Could use a fast strlen function for this, but\n; printf is so slow it won't really save us anything.\n\n            mov     rcx, returnAdrs\n            dec     rcx\nskipTo0:    inc     rcx\n            cmp     byte ptr [rcx], 0\n            jne     skipTo0\n            inc     rcx\n            mov     returnAdrs, rcx\n\n            leave\n            movdqu  xmm0, xmmword ptr [rsp + 00] \n            movdqu  xmm1, xmmword ptr [rsp + 16] \n            movdqu  xmm2, xmmword ptr [rsp + 32] \n            movdqu  xmm3, xmmword ptr [rsp + 48] \n            movdqu  xmm4, xmmword ptr [rsp + 64] \n            movdqu  xmm5, xmmword ptr [rsp + 80] \n            movdqu  xmm6, xmmword ptr [rsp + 96] \n            movdqu  xmm7, xmmword ptr [rsp + 112] \n            add     rsp, 128\n            pop     r11\n            pop     r10\n            pop     r9\n            pop     r8\n            pop     rdx\n            pop     rcx\n            pop     rbx\n            pop     rax\n            ret\nprint_SSE   endp \n\n***************************************************************\n\n; Here is the \"asmMain\" function.\n\n            public  asmMain\nasmMain     proc\n            push    rbx\n            push    rsi\n            push    rdi\n            push    rbp\n            mov     rbp, rsp\n            sub     rsp, 56         ; Shadow storage\n\n; Trivial example, no arguments:\n\n            call    print\n            byte    \"Hello, world!\", nl, 0\n\n; Simple example with integer arguments:\n\n            mov     rdx, 1          ; Argument #1 for printf\n            mov     r8, 2           ; Argument #2 for printf\n mov     r9, 3           ; Argument #3 for printf\n            mov     r10, 4          ; Argument #4 for printf\n            mov     r11, 5          ; Argument #5 for printf\n            call    print\n            byte    \"Arg 1=%d, Arg2=%d, Arg3=%d \"\n            byte    \"Arg 4=%d, Arg5=%d\", nl, 0\n\n; Demonstration of floating-point operands. Note that\n; args 1, 2, and 3 must be passed in RDX, R8, and R9.\n; You'll have to load parameters 4 and 5 into R10 and R11.\n\n            mov     rdx, qword ptr fp1\n            mov     r8,  qword ptr fp2\n            mov     r9,  qword ptr fp3\n            mov     r10, qword ptr fp4\n            mov     r11, qword ptr fp5\n            call    print\n            byte    \"Arg1=%6.1f, Arg2=%6.1f, Arg3=%6.1f \"\n            byte    \"Arg4=%6.1f, Arg5=%6.1f \", nl, 0\n\nallDone:    leave\n            pop     rdi\n            pop     rsi\n            pop     rbx\n            ret     ; Returns to caller\nasmMain     endp\n            end\n```", "```\nC:\\>**build listing11-5**\n\nC:\\>**echo off**\n Assembling: listing11-5.asm\nc.cpp\n\nC:\\>**listing11-5**\nCalling Listing 11-5:\nHello, World!\nArg 1=1, Arg2=2, Arg3=3 Arg 4=4, Arg5=5\nArg1=   1.0, Arg2=   2.0, Arg3=   3.0 Arg4=   4.0, Arg5=   5.0\nListing 11-5 terminated\n```", "```\ninclude  `source_filename`\n```", "```\ninclude print.inc\n```"]