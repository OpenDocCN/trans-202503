- en: Chapter 2. Statistical Power and Underpowered Statistics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章. 统计功效与统计不足
- en: You’ve seen how it’s possible to miss real effects by not collecting enough
    data. You might miss a viable medicine or fail to notice an important side effect.
    So how do you know how much data to collect?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到，如果没有收集足够的数据，可能会错过真实的效应。你可能会错过一种有效的药物，或未能注意到一个重要的副作用。那么，如何知道收集多少数据呢？
- en: The concept of *statistical power* provides the answer. The power of a study
    is the probability that it will distinguish an effect of a certain size from pure
    luck. A study might easily detect a huge benefit from a medication, but detecting
    a subtle difference is much less likely.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*统计功效*的概念提供了答案。研究的功效是其区分某一特定效应与纯粹运气的概率。一项研究可能很容易发现药物的巨大效益，但发现微小的差异则远不容易。'
- en: The Power Curve
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 功效曲线
- en: Suppose I’m convinced that my archnemesis has an unfair coin. Rather than getting
    heads half the time and tails half the time, it’s biased to give one outcome 60%
    of the time, allowing him to cheat at incredibly boring coin-flipping betting
    games. I suspect he’s cheating—but how to *prove* it?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我确信我的宿敌有一枚不公平的硬币。与其每次正面和反面各占一半，它偏向于60%的时间出现某一面，这让他能够在无聊的抛硬币赌博游戏中作弊。我怀疑他在作弊——但是如何*证明*这一点呢？
- en: I can’t just take the coin, flip it 100 times, and count the heads. Even a perfectly
    fair coin won’t always get 50 heads, as the solid line in [Figure 2-1](ch02.html#probability_of_getting_different_numbers
    "Figure 2-1. The probability of getting different numbers of heads if you flip
    a fair coin (solid line) or biased coin (dashed line) 100 times. The biased coin
    gives heads 60% of the time.") shows.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我不能仅仅拿起硬币，抛掷100次，然后统计正面朝上的次数。即使是完全公平的硬币，也不一定每次都会出现50次正面朝上，正如[图2-1](ch02.html#probability_of_getting_different_numbers
    "图2-1. 抛掷公平硬币（实线）或有偏硬币（虚线）100次时，出现不同次数正面朝上的概率。偏向正面的硬币60%的时间是正面。")中所示的实线所显示的那样。
- en: '![The probability of getting different numbers of heads if you flip a fair
    coin (solid line) or biased coin (dashed line) 100 times. The biased coin gives
    heads 60% of the time.](httpatomoreillycomsourcenostarchimages2181905.png.jpg)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![抛掷公平硬币（实线）或有偏硬币（虚线）100次时，出现不同次数正面朝上的概率。偏向正面的硬币60%的时间是正面。](httpatomoreillycomsourcenostarchimages2181905.png.jpg)'
- en: Figure 2-1. The probability of getting different numbers of heads if you flip
    a fair coin (solid line) or biased coin (dashed line) 100 times. The biased coin
    gives heads 60% of the time.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图2-1. 抛掷公平硬币（实线）或有偏硬币（虚线）100次时，出现不同次数正面朝上的概率。偏向正面的硬币60%的时间是正面。
- en: 'Even though 50 heads is the most likely outcome, it still happens less than
    10% of the time. I’m also reasonably likely to get 51 or 52 heads. In fact, when
    flipping a fair coin 100 times, I’ll get between 40 and 60 heads 95% of the time.
    On the other hand, results far outside this range are unlikely: with a fair coin,
    there’s only a 1% chance of obtaining more than 63 or fewer than 37 heads. Getting
    90 or 100 heads is almost impossible.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 即使50次正面朝上是最可能的结果，它仍然不到10%的概率发生。我同样有合理的可能性得到51次或52次正面。事实上，在抛掷公平硬币100次时，95%的概率正面朝上的次数会在40到60次之间。另一方面，远远超出这个范围的结果不太可能出现：使用公平硬币时，得到超过63次或少于37次正面的概率仅为1%。得到90次或100次正面几乎是不可能的。
- en: Compare this to the dashed line in [Figure 2-1](ch02.html#probability_of_getting_different_numbers
    "Figure 2-1. The probability of getting different numbers of heads if you flip
    a fair coin (solid line) or biased coin (dashed line) 100 times. The biased coin
    gives heads 60% of the time."), showing the probability of outcomes for a coin
    biased to give heads 60% of the time. The curves do overlap, but you can see that
    an unfair coin is much more likely to produce 70 heads than a fair coin is.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 将此与[图2-1](ch02.html#probability_of_getting_different_numbers "图2-1. 抛掷公平硬币（实线）或有偏硬币（虚线）100次时，出现不同次数正面朝上的概率。偏向正面的硬币60%的时间是正面。")中的虚线进行比较，虚线显示的是硬币偏向正面60%的概率分布。两条曲线有重叠，但你可以看到不公平的硬币比公平的硬币更可能出现70次正面。
- en: Let’s work out the math. Say I run 100 trials and count the number of heads.
    If the result isn’t exactly 50 heads, I’ll calculate the probability that a *fair*
    coin would have turned up a deviation of that size or larger. That probability
    is my *p* value. I’ll consider a *p* value of 0.05 or less to be statistically
    significant and hence call the coin unfair if *p* is smaller than 0.05.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来计算一下数学问题。假设我进行了100次试验并统计了正面朝上的次数。如果结果不是恰好50次正面，我会计算一个*公平*硬币出现如此大偏差或更大偏差的概率。这个概率就是我的*p*值。如果*p*值小于0.05，我会认为它具有统计学意义，因此如果*p*值小于0.05，我就会认为这枚硬币是不公平的。
- en: How likely am I to find out a coin is biased using this procedure? A *power
    curve*, as shown in [Figure 2-2](ch02.html#power_curves_for_100_and_1comma000_coin
    "Figure 2-2. The power curves for 100 and 1,000 coin flips, showing the probability
    of detecting biases of different magnitudes. The vertical line indicates a 60%
    probability of heads."), can tell me. Along the horizontal axis is the coin’s
    true probability of getting heads—that is, how biased it is. On the vertical axis
    is the probability that I will conclude the coin is rigged.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我通过这种方法找到硬币是否存在偏差的可能性有多大？一个*功效曲线*，如[图2-2](ch02.html#power_curves_for_100_and_1comma000_coin
    "图2-2. 100次和1,000次硬币翻转的功效曲线，显示不同偏差大小的检测概率。垂直线表示正面朝上的概率为60%。")中所示，可以告诉我。横轴表示硬币正面朝上的真实概率——即它的偏差程度。纵轴表示我得出结论认为硬币被操控的概率。
- en: 'The *power* for any hypothesis test is the probability that it will yield a
    statistically significant outcome (defined in this example as *p* < 0.05). A fair
    coin will show between 40 and 60 heads in 95% of trials, so for an *unfair* coin,
    the power is the probability of a result *outside* this range of 40–60 heads.
    The power is affected by three factors:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 任何假设检验的*功效*是指其得出统计学显著结果的概率（在本例中定义为*p* < 0.05）。公平硬币在95%的试验中会显示出40到60次正面，因此对于不公平硬币，功效就是出现*超出*这个40到60次正面范围的结果的概率。功效受三个因素的影响：
- en: '****The size of the bias you’re looking for.**** A huge bias is much easier
    to detect than a tiny one.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '****你正在寻找的偏差的大小。**** 一个巨大的偏差比一个微小的偏差更容易检测。'
- en: '****The sample size.**** By collecting more data (more coin flips), you can
    more easily detect small biases.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '****样本大小。**** 通过收集更多的数据（更多的硬币翻转），你可以更容易地检测到小的偏差。'
- en: '****Measurement error.**** It’s easy to count coin flips, but many experiments
    deal with values that are harder to measure, such as medical studies investigating
    symptoms of fatigue or depression.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '****测量误差。**** 计数硬币翻转很容易，但许多实验涉及的是更难测量的值，例如医学研究中调查疲劳或抑郁症状。'
- en: '![The power curves for 100 and 1,000 coin flips, showing the probability of
    detecting biases of different magnitudes. The vertical line indicates a 60% probability
    of heads.](httpatomoreillycomsourcenostarchimages2181907.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![100次和1,000次硬币翻转的功效曲线，显示不同偏差大小的检测概率。垂直线表示正面朝上的概率为60%。](httpatomoreillycomsourcenostarchimages2181907.png)'
- en: Figure 2-2. The power curves for 100 and 1,000 coin flips, showing the probability
    of detecting biases of different magnitudes. The vertical line indicates a 60%
    probability of heads.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2-2. 100次和1,000次硬币翻转的功效曲线，显示不同偏差大小的检测概率。垂直线表示正面朝上的概率为60%。
- en: Let’s start with the size of the bias. The solid line in [Figure 2-2](ch02.html#power_curves_for_100_and_1comma000_coin
    "Figure 2-2. The power curves for 100 and 1,000 coin flips, showing the probability
    of detecting biases of different magnitudes. The vertical line indicates a 60%
    probability of heads.") shows that if the coin is rigged to give heads 60% of
    the time, I have a 50% chance of concluding that it’s rigged after 100 flips.
    (That is, when the true probability of heads is 0.6, the power is 0.5.) The other
    half of the time, I’ll get fewer than 60 heads and fail to detect the bias. With
    only 100 flips, there’s just too little data to *always* separate bias from random
    variation. The coin would have to be incredibly biased—yielding heads more than
    80% of the time, for example—for me to notice nearly 100% of the time.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从偏差的大小开始。[图2-2](ch02.html#power_curves_for_100_and_1comma000_coin "图2-2.
    100次和1,000次硬币翻转的功效曲线，显示不同偏差大小的检测概率。垂直线表示正面朝上的概率为60%。")中的实线显示，如果硬币被调整为60%的几率出现正面，那么在100次翻转后，我有50%的机会得出结论认为硬币是作弊的。（也就是说，当正面出现的真实概率为0.6时，功效为0.5。）另一半时间，我会得到少于60次正面的结果，并无法检测到偏差。仅仅100次翻转，数据量太少，*总是*无法将偏差与随机波动区分开来。如果硬币有极大的偏差——例如，正面超过80%的概率——我几乎能在100%的情况下发现这个偏差。
- en: Another problem is that even if the coin is perfectly fair, I will falsely accuse
    it of bias 5% of the time. I’ve designed my test to interpret outcomes with *p*
    < 0.05 as a sign of bias, but those outcomes *do* happen even with a fair coin.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是，即使硬币是完全公平的，我也会有5%的概率错误地指责它存在偏差。我设计的测试是将*P*值小于0.05的结果解释为偏差的迹象，但即使硬币是公平的，这些结果*确实*会发生。
- en: 'Fortunately, an increased sample size improves the sensitivity. The dashed
    line shows that with 1,000 flips, I can easily tell whether the coin is rigged.
    This makes sense: it’s overwhelmingly unlikely that I could flip a fair coin 1,000
    times and get more than 600 heads. I’ll get between 469 and 531 95% of the time.
    Unfortunately, I don’t really have the time to flip my nemesis’s coin 1,000 times
    to test its fairness. Often, performing a sufficiently powerful test is out of
    the question for purely practical reasons.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，增加样本量可以提高敏感性。虚线显示，当进行1,000次投掷时，我可以轻松判断硬币是否被操控。这是有道理的：如果我能够公平地投掷硬币1,000次并且得到超过600次正面，那么这种情况几乎是不可能的。我会有95%的几率得到469到531次正面。很不幸，我并没有时间去测试我的死对头的硬币是否公平，进行1,000次投掷。通常，由于纯粹的实际原因，进行一个足够强大的测试是不现实的。
- en: Now counting heads and tails is easy, but what if I were instead administering
    IQ tests? An IQ score does not measure an underlying “truth” but instead can vary
    from day to day depending on the questions on the test and the mood of the subject,
    introducing random noise to the measurements. If you were to compare the IQs of
    two groups of people, you’d see not only the normal variation in intelligence
    from one person to the next but also the random variation in *individual* scores.
    A test with high variability, such as an IQ test requiring subjective grading,
    will have relatively less statistical power.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，计算正面和反面很简单，但如果我正在进行智商测试呢？智商得分并不衡量一个潜在的“真相”，而是根据测试中的问题和受试者的心情，每天都会有所不同，从而引入了随机噪声。如果你要比较两组人的智商，你不仅会看到每个人之间的正常智力差异，还会看到*个体*得分中的随机变化。像需要主观评分的智商测试这样高变异性的测试，其统计功效相对较低。
- en: 'More data helps distinguish the signal from the noise. But this is easier said
    than done: many scientists don’t have the resources to conduct studies with adequate
    statistical power to detect what they’re looking for. They are doomed to fail
    before they even start.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的数据有助于区分信号和噪声。但这说起来容易做起来难：许多科学家没有足够的资源来进行具有足够统计功效的研究，以便检测他们所要寻找的东西。它们在开始之前就注定会失败。
- en: The Perils of Being Underpowered
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 功效不足的危险
- en: Consider a trial testing two different medicines, Fixitol and Solvix, for the
    same condition. You want to know which is safer, but side effects are rare, so
    even if you test both medicines on 100 patients, only a few in each group will
    suffer serious side effects. Just as it is difficult to tell the difference between
    two coins that turn up 50% heads and 51% heads, the difference between a 3% and
    4% side effect rate is difficult to discern. If four people taking Fixitol have
    serious side effects and only three people taking Solvix have them, you can’t
    say for sure whether the difference is due to Fixitol.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下一个试验，测试两种不同的药物Fixitol和Solvix治疗同一种病症。你想知道哪种药物更安全，但副作用很少见，因此即使你在100名患者身上测试这两种药物，每组中只有少数人会遭遇严重副作用。就像很难分辨一个硬币50%正面和51%正面之间的区别一样，3%和4%的副作用率之间的差异也很难察觉。如果四名服用Fixitol的患者出现严重副作用，而只有三名服用Solvix的患者出现副作用，你不能确定这种差异是否是由于Fixitol所致。
- en: If a trial isn’t powerful enough to detect the effect it’s looking for, we say
    it is *underpowered*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个试验的功效不足以检测出它所寻找的效果，我们称之为*功效不足*。
- en: You might think calculations of statistical power are essential for medical
    trials; a scientist might want to know how many patients are needed to test a
    new medication, and a quick calculation of statistical power would provide the
    answer. Scientists are usually satisfied when the statistical power is 0.8 or
    higher, corresponding to an 80% chance of detecting a real effect of the expected
    size. (If the true effect is actually larger, the study will have greater power.)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能认为，统计功效的计算对于医学试验是至关重要的；科学家可能想知道需要多少患者来测试一种新药，而快速的统计功效计算可以提供答案。通常，当统计功效达到0.8或更高时，科学家们会感到满意，这对应于80%的几率检测到预期大小的实际效果。（如果真实效果实际上更大，研究的功效将更强。）
- en: However, few scientists ever perform this calculation, and few journal articles
    even mention statistical power. In the prestigious journals *Science* and *Nature*,
    fewer than 3% of articles calculate statistical power before starting their study.^([1](apa.html#ch02en1))
    Indeed, many trials conclude that “there was no statistically significant difference
    in adverse effects between groups,” without noting that there was insufficient
    data to detect any but the largest differences.^([2](apa.html#ch02en2)) If one
    of these trials was comparing side effects in two drugs, a doctor might erroneously
    think the medications are equally safe, when one could very well be much more
    dangerous than the other.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，很少有科学家进行这样的计算，也很少有期刊文章提到统计功效。在著名期刊*Science*和*Nature*中，不到3%的文章在开始研究前计算统计功效。^([1](apa.html#ch02en1))
    事实上，许多试验得出的结论是“组间不良反应差异无统计学意义”，却没有指出数据不足以检测出任何差异，除了最大差异之外。^([2](apa.html#ch02en2))
    如果这些试验之一是在比较两种药物的副作用，医生可能错误地认为这些药物是同样安全的，而实际上其中一种药物可能比另一种药物危险得多。
- en: Maybe this is a problem only for rare side effects or only when a medication
    has a weak effect? Nope. In one sample of studies published in prestigious medical
    journals between 1975 and 1990, more than four-fifths of randomized controlled
    trials that reported negative results didn’t collect enough data to detect a *25%
    difference* in primary outcome between treatment groups. That is, even if one
    medication reduced symptoms by 25% more than another, there was insufficient data
    to make that conclusion. And nearly *two-thirds* of the negative trials didn’t
    have the power to detect a 50% difference.^([3](apa.html#ch02en3))
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 也许这个问题只存在于稀有副作用的情况下，或者仅在药物效果较弱时才会出现？并不是。在一项发表于1975至1990年间的著名医学期刊的研究样本中，超过五分之四的随机对照试验报告的负面结果没有收集足够的数据来检测治疗组之间主要结果的*25%差异*。也就是说，即使某种药物的症状减轻程度比另一种药物高出25%，也没有足够的数据得出这个结论。而且，几乎*三分之二*的负面试验没有足够的能力检测出50%的差异。^([3](apa.html#ch02en3))
- en: 'A more recent study of trials in cancer research found similar results: only
    about half of published studies with negative results had enough statistical power
    to detect even a large difference in their primary outcome variable.^([4](apa.html#ch02en4))
    Less than 10% of these studies explained why their sample sizes were so poor.
    Similar problems have been consistently seen in other fields of medicine.^([5](apa.html#ch02en5)),^([6](apa.html#ch02en6))'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最近一项关于癌症研究中的试验的研究发现了类似的结果：只有大约一半的负面结果研究具有足够的统计功效来检测出其主要结果变量中的大差异。^([4](apa.html#ch02en4))
    这些研究中不到10%解释了为什么它们的样本量如此之小。类似的问题在其他医学领域也持续存在。^([5](apa.html#ch02en5)),^([6](apa.html#ch02en6))
- en: In neuroscience, the problem is even worse. Each individual neuroscience study
    collects such little data that the median study has only a 20% chance of being
    able to detect the effect it’s looking for. You could compensate for this by aggregating
    data collected across several papers all investigating the same effect. But since
    many neuroscience studies use animal subjects, this raises a significant ethical
    concern. If each study is underpowered, the true effect will likely be discovered
    only after many studies using many animals have been completed and analyzed—using
    far more animal subjects than if the study had been done properly in the first
    place.^([7](apa.html#ch02en7)) An ethical review board should not approve a trial
    if it knows the trial is unable to detect the effect it is looking for.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经科学领域，这个问题更为严重。每项神经科学研究收集的数据如此有限，以至于中位数研究只有20%的机会能够检测到它所寻找的效应。你可以通过汇总多篇研究中收集的数据来弥补这一点，前提是这些研究都在调查相同的效应。但是，由于许多神经科学研究使用动物作为实验对象，这就引发了重大的伦理问题。如果每项研究的统计功效不足，那么只有在完成并分析了多项涉及大量动物的研究之后，才能发现真实的效应——这比如果研究在一开始就进行得当所使用的动物数量要多得多。^([7](apa.html#ch02en7))
    如果伦理审查委员会知道某项试验无法检测到它所要寻找的效应，就不应批准该试验。
- en: Wherefore Poor Power?
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么统计功效这么差？
- en: Curiously, the problem of underpowered studies has been known for decades, yet
    it is as prevalent now as it was when first pointed out. In 1960 Jacob Cohen investigated
    the statistical power of studies published in the *Journal of Abnormal and Social
    Psychology*^([8](apa.html#ch02en8)) and discovered that the average study had
    only a power of 0.48 for detecting medium-sized effects.^([[4](#ftn.ch02fn01a)])
    His research was cited hundreds of times, and many similar reviews followed, all
    exhorting the need for power calculations and larger sample sizes. Then, in 1989,
    a review showed that in the decades since Cohen’s research, the average study’s
    power had actually *decreased*.^([9](apa.html#ch02en9)) This decrease was because
    of researchers becoming aware of another problem, the issue of multiple comparisons,
    and compensating for it in a way that reduced their studies’ power. (I will discuss
    multiple comparisons in [Chapter 4](ch04.html "Chapter 4. The P Value and the
    Base Rate Fallacy"), where you will see that there is an unfortunate trade-off
    between a study’s power and multiple comparison correction.)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 奇怪的是，低功效研究的问题已经存在了几十年，但如今仍然像最初被指出时那样普遍存在。1960年，雅各布·科恩（Jacob Cohen）研究了发表在《异常与社会心理学期刊》上的研究的统计功效^([8](apa.html#ch02en8))，并发现平均研究的功效仅为0.48，用于检测中等效应。^([[4](#ftn.ch02fn01a)])
    他的研究被引用了数百次，随后进行了许多类似的评论，所有这些评论都强调了功效计算和更大样本量的必要性。然后，在1989年，一项回顾性研究显示，在科恩研究后的几十年里，平均研究的功效实际上*下降*了。^([9](apa.html#ch02en9))
    这种下降是因为研究人员意识到另一个问题，即多重比较问题，并通过一种降低研究功效的方式进行补偿。（我将在[第4章](ch04.html "第4章. P值与基数谬误")中讨论多重比较问题，在那里你会看到研究的功效和多重比较校正之间有一个不幸的权衡。）
- en: So why are power calculations often forgotten? One reason is the discrepancy
    between our intuitive feeling about sample sizes and the results of power calculations.
    It’s easy to think, “Surely these are enough test subjects,” even when the study
    has abysmal power. For example, suppose you’re testing a new heart attack treatment
    protocol and hope to cut the risk of death in half, from 20% to 10%. You might
    be inclined to think, “If I don’t see a difference when I try this procedure on
    50 patients, clearly the benefit is too small to be useful.” But to have 80% power
    to detect the effect, you’d actually need *400* patients—200 in each control and
    treatment group.^([10](apa.html#ch02en10)) Perhaps clinicians just don’t realize
    that their adequate-seeming sample sizes are in fact far too small.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么功效计算常常被忽视呢？一个原因是我们直观上对于样本量的感觉与功效计算结果之间存在差异。人们很容易想，“这些受试者应该足够了，”即使研究的功效极差。例如，假设你正在测试一种新的心脏病发作治疗方案，期望将死亡风险从20%降低到10%。你可能会倾向于认为，“如果在50名患者中使用这种治疗方法没有看到差异，显然效果太小，不值得应用。”但为了达到80%的功效来检测这个效果，你实际上需要*400*名患者——每组控制和治疗各200人。^([10](apa.html#ch02en10))
    也许临床医生并没有意识到，看似足够的样本量实际上远远不够。
- en: 'Math is another possible explanation for why power calculations are so uncommon:
    analytically calculating power can be difficult or downright impossible. Techniques
    for calculating power are not frequently taught in intro statistics courses. And
    some commercially available statistical software does not come with power calculation
    functions. It is possible to avoid hairy mathematics by simply simulating thousands
    of artificial datasets with the effect size you expect and running your statistical
    tests on the simulated data. The power is simply the fraction of datasets for
    which you obtain a statistically significant result. But this approach requires
    programming experience, and simulating realistic data can be tricky.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 数学也是功效计算如此罕见的另一个可能解释：分析计算功效可能很困难，甚至是完全不可能的。计算功效的技术通常不会在初级统计课程中教授。而且一些市售的统计软件并不包含功效计算功能。通过简单地模拟成千上万的数据集（这些数据集具有你预期的效应大小），并在模拟数据上运行统计测试，你可以避免复杂的数学计算。功效就是你获得统计显著结果的数据集所占的比例。但这种方法需要编程经验，而且模拟真实数据也可能比较棘手。
- en: Even so, you’d think scientists would notice their power problems and try to
    correct them; after five or six studies with insignificant results, a scientist
    might start wondering what she’s doing wrong. But the average study performs not
    one hypothesis test but many and so has a good shot at finding *something* significant.^([11](apa.html#ch02en11))
    As long as this significant result is interesting enough to feature in a paper,
    the scientist will not feel that her studies are underpowered.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 即便如此，你会认为科学家会注意到他们的功效问题并尝试纠正它；经过五六项没有显著结果的研究后，科学家可能会开始怀疑自己做错了什么。但一项平均水平的研究不会进行一次假设检验，而是进行许多检验，因此有很大机会发现*某种*显著结果。^([11](apa.html#ch02en11))
    只要这个显著结果足够有趣，足以在论文中展示，科学家就不会觉得自己的研究功效不足。
- en: The perils of insufficient power do not mean that scientists are lying when
    they state they detected no significant difference between groups. But it’s misleading
    to assume these results mean there is no *real* difference. There may be a difference,
    even an important one, but the study was so small it’d be lucky to notice it.
    Let’s consider an example we see every day.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 电力不足的危险并不意味着科学家在声明他们未发现两组之间有显著差异时是在撒谎。但假设这些结果意味着没有*真正的*差异是误导的。可能确实存在差异，甚至是一个重要的差异，但研究样本太小，发现这一差异的几率微乎其微。让我们考虑一个我们每天都能看到的例子。
- en: Wrong Turns on Red
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 红灯右转的误区
- en: In the 1970s, many parts of the United States began allowing drivers to turn
    right at a red light. For many years prior, road designers and civil engineers
    argued that allowing right turns on a red light would be a safety hazard, causing
    many additional crashes and pedestrian deaths. But the 1973 oil crisis and its
    fallout spurred traffic agencies to consider allowing right turns on red to save
    fuel wasted by commuters waiting at red lights, and eventually Congress required
    states to allow right turns on red, treating it as an energy conservation measure
    just like building insulation standards and more efficient lighting.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在1970年代，美国的许多地方开始允许驾驶员在红灯时右转。在此之前的许多年里，道路设计师和土木工程师曾争论，允许红灯右转会成为安全隐患，导致更多的交通事故和行人死亡。但1973年的石油危机及其后果促使交通机构考虑允许红灯右转，以节省由于通勤者在红灯前等待而浪费的燃料，最终国会要求各州允许红灯右转，将其视为一种节能措施，就像建筑隔热标准和更高效的照明一样。
- en: Several studies were conducted to consider the safety impact of the change.
    In one, a consultant for the Virginia Department of Highways and Transportation
    conducted a before-and-after study of 20 intersections that had begun to allow
    right turns on red. Before the change, there were 308 accidents at the intersections;
    after, there were 337 in a similar length of time. But this difference was not
    statistically significant, which the consultant indicated in his report. When
    the report was forwarded to the governor, the commissioner of the Department of
    Highways and Transportation wrote that “we can discern no significant hazard to
    motorists or pedestrians from implementation” of right turns on red.^([12](apa.html#ch02en12))
    In other words, he turned *statistical* insignificance into *practical* insignificance.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有几项研究调查了这一变化对安全性的影响。在一项研究中，弗吉尼亚州公路与交通部的顾问对20个开始允许红灯右转的交叉口进行了前后对比研究。在变化之前，这些交叉口发生了308起事故；而在相似时间段之后，这一数字增加到了337起。但这一差异在统计学上并不显著，顾问在报告中指出了这一点。当报告被转交给州长时，公路与交通部的专员写道：“我们没有发现实施红灯右转对驾驶员或行人造成显著危害。”^([12](apa.html#ch02en12))
    换句话说，他把*统计学*上的不显著性转化为了*实际*上的不显著性。
- en: 'Several subsequent studies had similar findings: small increases in the number
    of crashes but not enough data to conclude these increases were significant. As
    one report concluded,'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 随后的几项研究得出了类似的结论：事故数量略有增加，但数据不足以得出这些增加是显著的结论。正如一份报告总结的那样，
- en: There is no reason to suspect that pedestrian accidents involving RT operations
    (right turns) have increased after the adoption of [right turn on red].
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 没有理由怀疑，在采纳[红灯右转]后，涉及RT操作（右转）的行人事故是否有所增加。
- en: Of course, these studies were underpowered. But more cities and states began
    to allow right turns on red, and the practice became widespread across the entire
    United States. Apparently, no one attempted to aggregate these many small studies
    to produce a more useful dataset. Meanwhile, more pedestrians were being run over,
    and more cars were involved in collisions. Nobody collected enough data to show
    this conclusively until several years later, when studies finally showed that
    among incidents involving right turns, collisions were occurring roughly 20% more
    frequently, 60% more pedestrians were being run over, and twice as many bicyclists
    were being struck.^([13](apa.html#ch02en13)),^([14](apa.html#ch02en14)),^([[5](#ftn.ch02fn02a)])
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这些研究的样本量不足。但越来越多的城市和州开始允许红灯时右转，且这一做法在整个美国变得广泛。显然，没有人试图将这些小规模研究的数据汇总，以生成一个更有用的数据集。与此同时，越来越多的行人被撞倒，更多的车辆发生了碰撞。直到几年后，才有研究显示，在涉及右转的事故中，碰撞发生的频率大约增加了20%，行人被撞的比例增加了60%，骑自行车的人被撞的数量翻倍了。^([13](apa.html#ch02en13)),^([14](apa.html#ch02en14)),^([[5](#ftn.ch02fn02a)])
- en: Alas, the world of traffic safety has learned little from this example. A 2002
    study, for example, considered the impact of paved shoulders on the accident rates
    of traffic on rural roads. Unsurprisingly, a paved shoulder reduced the risk of
    accident—but there was insufficient data to declare this reduction statistically
    significant, so the authors stated that the cost of paved shoulders was not justified.
    They performed no cost-benefit analysis because they treated the insignificant
    difference as meaning there was no difference at all, despite the fact that they
    had collected data suggesting that paved shoulders improved safety! The evidence
    was not strong enough to meet their desired *p* value threshold.^([12](apa.html#ch02en12))
    A better analysis would have admitted that while it is plausible that shoulders
    have no benefit at all, the data is also consistent with them having substantial
    benefits. That means looking at *confidence intervals*.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 可惜，交通安全领域从这个例子中学到的东西不多。例如，2002年的一项研究考虑了铺设路肩对乡村道路交通事故率的影响。不出所料，铺设路肩减少了事故的风险——但由于数据不足，无法宣称这种减少具有统计学意义，因此作者认为铺设路肩的成本不值得。因为他们将微小的差异视为没有差异，所以没有进行成本效益分析，尽管他们收集到的数据表明铺设路肩确实改善了安全性！证据并不强大到能达到他们期望的*p*值门槛。^([12](apa.html#ch02en12))
    一个更好的分析应该承认，虽然路肩没有任何好处是有可能的，但这些数据同样也支持它们具有显著好处的可能性。这意味着要考虑*置信区间*。
- en: Confidence Intervals and Empowerment
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 置信区间与赋能
- en: 'More useful than a statement that an experiment’s results were statistically
    insignificant is a confidence interval giving plausible sizes for the effect.
    Even if the confidence interval includes zero, its width tells you a lot: a narrow
    interval covering zero tells you that the effect is most likely small (which may
    be all you need to know, if a small effect is not practically useful), while a
    wide interval clearly shows that the measurement was not precise enough to draw
    conclusions.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 比起声明实验结果在统计学上不显著，更有用的是给出一个置信区间，提供关于效应的可能大小。即使置信区间包含零，其宽度也能告诉你很多信息：如果置信区间很窄且包含零，就意味着效应很可能很小（如果小效应在实际应用中不重要，那可能就是你需要知道的全部）；而如果置信区间很宽，则明显表明测量不够精确，无法得出结论。
- en: Physicists commonly use confidence intervals to place bounds on quantities that
    are not significantly different from zero. In the search for a new fundamental
    particle, for example, it’s not helpful to say, “The signal was not statistically
    significant.” Instead, physicists can use a confidence interval to place an upper
    bound on the rate at which the particle is produced in the particle collisions
    under study and then compare this result to the competing theories that predict
    its behavior (and force future experimenters to build yet bigger instruments to
    find it).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 物理学家通常使用置信区间来界定那些与零无显著差异的量。例如，在寻找新基本粒子的过程中，单纯说“信号在统计学上不显著”并没有帮助。相反，物理学家可以利用置信区间来对粒子在研究中的碰撞过程中产生的速率设定一个上限，然后将这个结果与预测其行为的竞争理论进行比较（并迫使未来的实验者建造更大的仪器来发现它）。
- en: Thinking about results in terms of confidence intervals provides a new way to
    approach experimental design. Instead of focusing on the power of significance
    tests, ask, “How much data must I collect to measure the effect to my desired
    precision?” Even a powerful experiment can nonetheless produce significant results
    with extremely wide confidence intervals, making its results difficult to interpret.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以置信区间的角度来看待结果为实验设计提供了一种新的思路。与其专注于显著性检验的功效，不如问问自己：“我需要收集多少数据才能以我想要的精度测量这个效应？”即使是一个强大的实验，也可能会产生显著的结果，但其置信区间极宽，使得结果难以解释。
- en: Of course, the sizes of our confidence intervals vary from one experiment to
    the next because our data varies from experiment to experiment. Instead of choosing
    a sample size to achieve a certain level of power, we choose a sample size so
    the confidence interval will be suitably narrow 99% of the time (or 95%; there’s
    not yet a standard convention for this number, called the *assurance*, which determines
    how often the confidence interval must beat our target width).^([16](apa.html#ch02en16))
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们的置信区间的大小因实验而异，因为我们的数据在不同的实验中会有所不同。与其选择一个样本量来达到某个功效水平，不如选择一个样本量，使得置信区间在99%的情况下（或95%；目前对于这个数字没有标准约定，它被称为*保证*，决定了置信区间必须达到目标宽度的频率）足够狭窄。^([16](apa.html#ch02en16))
- en: Sample size selection methods based on assurance have been developed for many
    common statistical tests, though not for all; it is a new field, and statisticians
    have yet to fully explore it.^([17](apa.html#ch02en17)) (These methods go by the
    name *accuracy in parameter estimation*, or *AIPE*.) Statistical power is used
    far more often than assurance, which has not yet been widely adopted by scientists
    in any field. Nonetheless, these methods are enormously useful. Statistical significance
    is often a crutch, a catchier-sounding but less informative substitute for a good
    confidence interval.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 基于保证的样本大小选择方法已经为许多常见的统计检验开发出来，尽管并非所有方法都已覆盖；这是一个新的领域，统计学家们尚未完全探索它。^([17](apa.html#ch02en17))（这些方法被称为*参数估计的准确性*，或称为*AIPE*。）统计功效远比保证方法使用得更为广泛，而保证方法在任何领域的科学家中还没有得到广泛采用。尽管如此，这些方法仍然极为有用。统计显著性常常是一种拐杖，虽然听起来更吸引人，但却是一个不太信息丰富的替代品，无法替代一个好的置信区间。
- en: Truth Inflation
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 真相膨胀
- en: Suppose Fixitol reduces symptoms by 20% over a placebo, but the trial you’re
    using to test it is too small to have adequate statistical power to detect this
    difference reliably. We know that small trials tend to have varying results; it’s
    easy to get 10 lucky patients who have shorter colds than usual but much harder
    to get 10,000 who all do.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 假设Fixitol在安慰剂上减少了20%的症状，但你用来测试它的试验样本量太小，无法可靠地检测到这个差异。我们知道小规模的试验结果往往有所不同；很容易遇到10个幸运的病人，他们的感冒比平时要轻，但要找到10,000个病人都如此就要困难得多。
- en: Now imagine running many copies of this trial. Sometimes you get unlucky patients,
    so you don’t notice any statistically significant improvement from your drug.
    Sometimes your patients are exactly average and the treatment group has their
    symptoms reduced by 20%—but you don’t have enough data to call this a statistically
    significant increase, so you ignore it. Sometimes the patients are lucky and have
    their symptoms reduced by much more than 20%, so you stop the trial and say, “Look!
    It works!” You can plot these outcomes in [Figure 2-3](ch02.html#if_you_run_your_trial_thousands_of_times
    "Figure 2-3. If you run your trial thousands of times, you will see a broad distribution
    of effect sizes in terms of percent reduction in symptoms. The vertical dotted
    line indicates the effect size which is large enough to be statistically significant.
    The true improvement is 20%, but you see effects from 10% losses to 50% gains.
    Only the lucky trials are statistically significant, exaggerating the effect size."),
    which shows the probability that each trial will yield a certain effect size estimate.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设你运行多个相同的试验。有时你可能碰到运气不佳的病人，因此没能从药物中看到任何统计学显著的改善。有时你的病人恰好是平均水平，治疗组的症状减少了20%——但你没有足够的数据来称其为统计学上显著的增加，所以你忽视了它。有时病人运气很好，症状减少的幅度远超过20%，于是你终止试验并宣称，“看！它有效！”你可以在[图2-3](ch02.html#if_you_run_your_trial_thousands_of_times
    "图2-3. 如果你运行数千次试验，你将看到效果大小在症状减轻百分比方面的广泛分布。垂直虚线表示足够大以达到统计学显著性的效应大小。真实的改善是20%，但你会看到从10%的损失到50%的收益。只有幸运的试验是统计学显著的，从而夸大了效应大小。")中绘制这些结果，图中展示了每次试验会产生某种效应大小估计的概率。
- en: '![If you run your trial thousands of times, you will see a broad distribution
    of effect sizes in terms of percent reduction in symptoms. The vertical dotted
    line indicates the effect size which is large enough to be statistically significant.
    The true improvement is 20%, but you see effects from 10% losses to 50% gains.
    Only the lucky trials are statistically significant, exaggerating the effect size.](httpatomoreillycomsourcenostarchimages2181909.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![如果你将试验进行数千次，你会看到效果大小在症状百分比减少方面呈广泛分布。垂直虚线表示效果大小足够大，以至于具有统计学意义。真实的改善是20%，但你看到的效果从10%的损失到50%的增益不等。只有幸运的试验才具有统计学意义，从而夸大了效果大小。](httpatomoreillycomsourcenostarchimages2181909.png)'
- en: Figure 2-3. If you run your trial thousands of times, you will see a broad distribution
    of effect sizes in terms of percent reduction in symptoms. The vertical dotted
    line indicates the effect size which is large enough to be statistically significant.
    The true improvement is 20%, but you see effects from 10% losses to 50% gains.
    Only the lucky trials are statistically significant, exaggerating the effect size.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图2-3。如果你将试验进行数千次，你会看到效果大小在症状百分比减少方面呈广泛分布。垂直虚线表示效果大小足够大，以至于具有统计学意义。真实的改善是20%，但你看到的效果从10%的损失到50%的增益不等。只有幸运的试验才具有统计学意义，从而夸大了效果大小。
- en: You’ve correctly concluded Fixitol is effective, but you’ve inflated the size
    of its effect because your study was underpowered.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你正确地得出结论，Fixitol是有效的，但由于你的研究统计功效不足，你夸大了它的效果大小。
- en: 'This effect, known as *truth inflation*, *type M error* (*M* for magnitude),
    or the *winner’s curse*, occurs in fields where many researchers conduct similar
    experiments and compete to publish the most “exciting” results: pharmacological
    trials, epidemiological studies, gene association studies (“gene A causes condition
    B”), and psychological studies often show symptoms, along with some of the most-cited
    papers in the medical literature.^([18](apa.html#ch02en18)),^([19](apa.html#ch02en19))
    In fast-moving fields such as genetics, the earliest published results are often
    the most extreme because journals are most interested in publishing new and exciting
    results. Follow-up studies tend to show much smaller effects.^([20](apa.html#ch02en20))'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这种效应被称为*真相膨胀*、*M型错误*（*M*代表大小）或*赢家的诅咒*，发生在许多研究者进行相似实验并竞争发表最“激动人心”结果的领域：药理学试验、流行病学研究、基因关联研究（“基因A导致B病”）和心理学研究经常表现出症状，并且是医学文献中被引用最多的论文之一。^([18](apa.html#ch02en18)),^([19](apa.html#ch02en19))
    在基因学等快速发展的领域中，最早发表的结果往往是最极端的，因为期刊最希望发表新颖且激动人心的结果。后续研究通常显示出更小的效果。^([20](apa.html#ch02en20))
- en: Consider also that top-ranked journals, such as *Nature* and *Science*, prefer
    to publish studies with groundbreaking results—meaning large effect sizes in novel
    fields with little prior research. This is a perfect combination for chronic truth
    inflation. Some evidence suggests a correlation between a journal’s impact factor
    (a rough measure of its prominence and importance) and the factor by which its
    studies overestimate effect sizes. Studies that produce less “exciting” results
    are closer to the truth but less interesting to a major journal editor.^([21](apa.html#ch02en21)),^([22](apa.html#ch02en22))
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 还要考虑到，顶级期刊，如*《自然》*和*《科学》*，倾向于发表具有突破性结果的研究——也就是说，在少有前期研究的创新领域中，效果大小较大的研究。这是慢性真相膨胀的完美组合。有证据表明，期刊的影响因子（衡量期刊知名度和重要性的粗略指标）与其研究高估效果大小的倍数之间存在相关性。那些产生较少“激动人心”结果的研究更接近真实，但对主要期刊编辑来说则不那么有趣。^([21](apa.html#ch02en21)),^([22](apa.html#ch02en22))
- en: 'When a study claims to have detected a large effect with a relatively small
    sample, your first reaction should not be “Wow, they’ve found something big!”
    but “Wow, this study is underpowered!”^([23](apa.html#ch02en23)) Here’s an example.
    Starting in 2005, Satoshi Kanazawa published a series of papers on the theme of
    gender ratios, culminating with “Beautiful Parents Have More Daughters.” He followed
    up with a book discussing this and other “politically incorrect truths” he’d discovered.
    The studies were popular in the press at the time, particularly because of the
    large effect size they reported: Kanazawa claimed the most beautiful parents have
    daughters 52% of the time, but the least attractive parents have daughters only
    44% of the time.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当一项研究声称通过相对较小的样本检测到一个大效应时，你的第一反应不应该是“哇，他们发现了什么重大结果！”而应该是“哇，这项研究的统计功效不足！”^([23](apa.html#ch02en23))
    这是一个例子。从2005年开始，金泽发布了一系列关于性别比例的论文，最终以“美丽的父母有更多女儿”作为高潮。他随后出版了一本书，讨论了这一主题以及他发现的其他“政治不正确的真理”。当时这些研究在媒体中很受欢迎，特别是因为它们报告了较大的效应大小：金泽声称最美丽的父母有52%的概率会有女儿，而最不吸引人的父母只有44%的概率会有女儿。
- en: To biologists, a small effect—perhaps one or two percentage points—would be
    plausible. The *Trivers–Willard Hypothesis* suggests that if parents have a trait
    that benefits girls more than boys, then they will have more girls than boys (or
    vice versa). If you assume girls benefit more from beauty than boys, then the
    hypothesis would predict beautiful parents would have, on average, slightly more
    daughters.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对生物学家来说，一个小的效应——也许一两个百分点——是可信的。*特里弗斯-威拉德假说*表明，如果父母有一种对女孩比对男孩更有利的特征，那么他们将会有更多的女孩而非男孩（反之亦然）。如果你假设女孩比男孩更能从美貌中受益，那么该假说将预测美丽的父母平均会有更多的女儿。
- en: But the effect size claimed by Kanazawa was extraordinary. And as it turned
    out, he committed several errors in his statistical analysis. A corrected regression
    analysis found that his data showed attractive parents were indeed 4.7% more likely
    to have girls—but the confidence interval stretched from 13.3% more likely to
    3.9% *less* likely.^([23](apa.html#ch02en23)) Though Kanazawa’s study used data
    from nearly 3,000 parents, the results were not statistically significant.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 但金泽声称的效应大小是异常大的。结果证明，他在统计分析中犯了几个错误。一项修正后的回归分析发现，他的数据确实显示吸引人的父母更可能有女孩，几率高达4.7%——但置信区间从13.3%更可能到3.9%*更不*可能。^([23](apa.html#ch02en23))
    尽管金泽的研究使用了近3,000个父母的数据，但这些结果并不具有统计学意义。
- en: Enormous amounts of data would be needed to reliably detect a small difference.
    Imagine a more realistic effect size—say, 0.3%. Even with 3,000 parents, an observed
    difference of 0.3% is far too small to distinguish from luck. You’d be lucky to
    obtain a statistically significant result just 5% of the time. These results will
    be those that exaggerate the true effect by at least a factor of 20, and 40% of
    them will produce a wild overestimate in favor of boys instead of girls.^([23](apa.html#ch02en23))
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 检测小差异需要大量的数据。想象一下一个更现实的效应大小——比如0.3%。即便有3,000个父母，观察到0.3%的差异也远远小到无法与运气区分开来。你可能幸运地仅有5%的概率获得统计学显著的结果。这些结果将至少将真实效应夸大20倍，而40%的结果将会产生一个极端的误差，支持男孩而非女孩。^([23](apa.html#ch02en23))
- en: So even if Kanazawa had performed a perfect statistical analysis, he still would
    have occasionally gotten lucky with a paper like “Engineers Have More Sons, Nurses
    Have More Daughters”^([[6](#ftn.ch02fn03a)]) and given a wild overestimate of
    a true, tiny effect. Studies of the size he conducted are simply *incapable* of
    detecting effects of the size you’d expect in advance. A prior power analysis
    would have told him this.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 即使金泽进行了完美的统计分析，他仍然可能偶尔会碰运气，得到像“工程师有更多儿子，护士有更多女儿”这样的论文^([[6](#ftn.ch02fn03a)])，并对真实的微小效应做出过高的估计。他进行的这种规模的研究根本*无法*检测出你事先预期的效应大小。事先的功效分析本可以告诉他这一点。
- en: Little Extremes
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小的极端值
- en: Truth inflation arises because small, underpowered studies have widely varying
    results. Occasionally you’re bound to get lucky and have a statistically significant
    but wildly overestimated result. But this wide variation can cause trouble even
    when you’re not performing significance tests. Suppose you’re in charge of public
    school reform. As part of your research into the best teaching methods, you look
    at the effect of school size on standardized test scores. Do smaller schools perform
    better than larger schools? Should you try to build many small schools or a few
    large schools?
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 真实性膨胀的出现是因为小规模、能力不足的研究结果差异很大。偶尔，你可能会很幸运地得出一个统计上显著但严重高估的结果。但这种广泛的波动即便在没有进行显著性测试的情况下也会带来麻烦。假设你负责公立学校改革。在你研究最佳教学方法时，你调查了学校规模对标准化测试成绩的影响。小学校的表现是否优于大规模学校？你应该尝试建造许多小学校还是几所大学校？
- en: To answer this question, you compile a list of the highest-performing schools
    you have. The average school has about 1,000 students, but the top-scoring 10
    schools are almost all smaller than that. It seems that small schools do the best,
    perhaps because teachers can get to know students and help them individually.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，你列出了你所知道的表现最好的学校。平均学校有大约1000名学生，但得分最高的10所学校几乎都比这个数字小。看起来，小学校的表现最好，也许是因为教师能更好地了解每个学生，并为他们提供个别帮助。
- en: Then you take a look at the worst-performing schools, expecting them to be large
    urban schools with thousands of students and overworked teachers. Surprise! They’re
    all small schools too.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你看看那些表现最差的学校，原本以为它们是大城市的学校，学生有成千上万，老师们超负荷工作。结果却让你惊讶！它们其实也是小学校。
- en: What’s going on? Well, take a look at the plot of test scores versus school
    size in [Figure 2-4](ch02.html#schools_with_more_students_have_less_ran "Figure 2-4. Schools
    with more students have less random variation in their test scores. This data
    is simulated but based on real observations of Pennsylvania public schools.").
    Smaller schools have wider variation in test scores because they have fewer students.
    With fewer students, there are fewer data points to establish the “true” performance
    of the teachers; a few anomalous scores can sway the school’s average significantly.
    As schools get larger, test scores vary less and in fact *increase* on average.^([24](apa.html#ch02en24))
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 怎么回事呢？看看[图2-4](ch02.html#schools_with_more_students_have_less_ran "图2-4。学生人数更多的学校在测试分数上具有较少的随机波动。这些数据是模拟的，但基于对宾夕法尼亚州公立学校的真实观察。")中测试成绩与学校规模的关系图。小学校的测试成绩波动较大，因为它们的学生人数较少。学生少意味着用于确定教师“真实”表现的数据点也少；少数异常成绩可能会显著影响学校的平均成绩。随着学校规模增大，测试成绩的波动变小，实际上平均成绩反而*提高*了。^([24](apa.html#ch02en24))
- en: '![Schools with more students have less random variation in their test scores.
    This data is simulated but based on real observations of Pennsylvania public schools.](httpatomoreillycomsourcenostarchimages2181911.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![学生人数更多的学校在测试分数上具有较少的随机波动。这些数据是模拟的，但基于对宾夕法尼亚州公立学校的真实观察。](httpatomoreillycomsourcenostarchimages2181911.png)'
- en: Figure 2-4. Schools with more students have less random variation in their test
    scores. This data is simulated but based on real observations of Pennsylvania
    public schools.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图2-4。学生人数更多的学校在测试分数上具有较少的随机波动。这些数据是模拟的，但基于对宾夕法尼亚州公立学校的真实观察。
- en: 'Another example: in the United States, counties with the lowest rates of kidney
    cancer tend to be Midwestern, Southern, and Western rural counties. Why might
    this be? Maybe rural people get more exercise or inhale less-polluted air. Or
    perhaps they just lead less stressful lives.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子：在美国，肾癌发病率最低的县通常是中西部、南部和西部的农村县。为什么会这样呢？也许是农村人运动量更多，或者吸入的空气污染较少。又或者他们的生活压力较小。
- en: On the other hand, counties with the *highest* rates of kidney cancer tend to
    be Midwestern, Southern, and Western rural counties.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，肾癌发病率*最高*的县通常是中西部、南部和西部的农村县。
- en: The problem, of course, is that rural counties have the smallest populations.
    A single kidney cancer patient in a county with 10 residents gives that county
    the highest kidney cancer rate in the nation. Small counties hence have much more
    variation in kidney cancer rates simply because they have so few residents.^([25](apa.html#ch02en25))
    The confidence intervals for their cancer rates are correspondingly larger.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，问题在于农村县的居民人数最少。一个只有10名居民的县里有一个肾癌患者，这个县的肾癌发病率就成了全国最高的。因此，小县城的肾癌发病率有更大的波动，仅仅因为它们的居民数量太少。^([25](apa.html#ch02en25))
    这些县的癌症发病率的置信区间也相应较大。
- en: 'A popular strategy to fight this problem is called *shrinkage*. For counties
    with few residents, you can “shrink” the cancer rate estimates toward the national
    average by taking a weighted average of the county cancer rate with the national
    average rate. When the county has few residents, you weight the national average
    strongly; when the county is large, you weight the county strongly. Shrinkage
    is now common practice in constructing cancer rate maps, among other applications.^([[7](#ftn.ch02fn04a)])
    Unfortunately, it biases results in the opposite direction: small counties with
    truly abnormal cancer rates are estimated to have rates much closer to the national
    average than they are.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 应对这一问题的一个流行策略叫做*收缩*。对于居民较少的县，可以通过将县的癌症率和全国平均癌症率的加权平均值作为估计值，从而将癌症率估算值“收缩”到全国平均水平。当县的居民较少时，更加重视全国平均值的权重；而当县的居民较多时，则更加重视该县的数据。收缩方法现在已成为构建癌症率地图等应用中的常见做法。^([[7](#ftn.ch02fn04a)])
    不幸的是，这种方法会使结果偏向相反的方向：小县的癌症率如果与全国平均值相差较大，估算值往往会被推测得更接近全国平均水平。
- en: 'There’s no single fix to this problem. The best alternative is to sidestep
    it altogether: rather than estimating rates by county, you could use congressional
    districts, which in the United States are designed to have roughly equal populations.
    Congressional districts are much larger than counties, though, and frequently
    they have strange shapes because of gerrymandering. Maps based on districts may
    not be statistically misleading but are still difficult to interpret.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题没有单一的办法。最佳的替代方案是完全避免这种做法：与其按县估算癌症率，不如使用国会选区，在美国，国会选区是设计为人口大致相等的。尽管如此，国会选区通常比县要大，而且由于选区划分的影响，形状经常很奇怪。基于选区的地图虽然在统计学上不易产生误导，但仍然很难进行解释。
- en: Of course, enforcing equal sample sizes isn’t always an option. Online shopping
    sites, for instance, need to sort products based on customer ratings, but they
    can’t force equal numbers of customers to rate every product. Another example
    is a discussion website like reddit, which can sort comments by user ratings;
    comments can receive vastly different numbers of votes depending on when or where
    or by whom they were posted. Shrinkage is helpful in dealing with these situations.
    An online store can use a weighted average of a product’s ratings and some global
    average. Products with few ratings will be treated as generically average, while
    products with thousands of votes are sorted by their true individual ratings.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，强制要求样本量相等并不总是可行的。例如，在线购物网站需要根据顾客评分对产品进行排序，但它们无法强制每个产品获得相同数量的顾客评分。另一个例子是像reddit这样的讨论网站，它可以根据用户评分对评论进行排序；评论可能会因发布的时间、地点或发布者的不同而获得大相径庭的投票数。在这种情况下，收缩方法非常有帮助。在线商店可以使用产品评分的加权平均值和一些全球平均值来处理这种情况。评分较少的产品将被视为普通平均水平，而有成千上万投票的产品则根据其真实的个别评分进行排序。
- en: For sites like reddit that have simple up-and-down votes rather than star ratings,
    one alternative is to generate a confidence interval for the fraction of positive
    votes. The interval starts wide when a comment has only a few votes and narrows
    to a definite value (“70% of voters like this comment”) as comments accumulate;
    sort the comments by the bottom bound of their confidence intervals. New comments
    start near the bottom, but the best among them accumulate votes and creep up the
    page as the confidence interval narrows. And because comments are sorted by the
    proportion of positive votes rather than the total number, new comments can compete
    with those that have already accumulated thousands of votes.^([26](apa.html#ch02en26)),^([27](apa.html#ch02en27))
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像reddit这样使用简单的上下投票而不是星级评分的网站，一种替代方法是为正面投票的比例生成置信区间。当评论只有少量投票时，区间开始较宽；随着评论的积累，区间逐渐收窄至一个确定值（“70%的投票者喜欢这条评论”）；按照置信区间的下限对评论进行排序。新的评论开始时通常排在最底部，但其中最受欢迎的评论会积累投票并随着置信区间的收窄逐渐上升到页面上。而且，由于评论是按正面投票的比例而不是总投票数排序的，新评论可以与那些已经积累了数千票的评论竞争。^([26](apa.html#ch02en26)),^([27](apa.html#ch02en27))
- en: Tips
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Calculate the statistical power when designing your study to determine the appropriate
    sample size. Don’t skimp. Consult a book like Cohen’s classic *Statistical Power
    Analysis for the Behavioral Sciences* or talk to a statistical consultant. If
    the sample size is impractical, be aware of the limitations of your study.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在设计研究时，计算统计功效以确定适当的样本量。不要节省这方面的开支。可以参考像Cohen的经典著作*《行为科学中的统计功效分析》*，或向统计学顾问咨询。如果样本量不切实际，要清楚了解研究的局限性。
- en: 'When you need to measure an effect with precision, rather than simply testing
    for significance, use assurance instead of power: design your experiment to measure
    the hypothesized effect to your desired level of precision.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你需要精确测量一个效应，而不仅仅是测试显著性时，使用置信度而非功效：设计你的实验以测量假设效应，直到达到你所需的精确度。
- en: Remember that “statistically insignificant” does not mean “zero.” Even if your
    result is insignificant, it represents the best available estimate given the data
    you have collected. “Not significant” does not mean “nonexistent.”
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请记住，“统计上不显著”并不意味着“零”。即使你的结果不显著，它也代表了基于你收集的数据的最佳估计。“不显著”并不意味着“不存在”。
- en: Look skeptically on the results of clearly underpowered studies. They may be
    exaggerated due to truth inflation.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对明显样本不足的研究结果持怀疑态度。这些结果可能由于事实膨胀而被夸大。
- en: Use confidence intervals to determine the range of answers consistent with your
    data, regardless of statistical significance.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用置信区间来确定与你的数据一致的答案范围，而不管其统计显著性。
- en: When comparing groups of different sizes, compute confidence intervals. These
    will reflect the additional certainty you have in larger groups.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在比较不同大小的组时，计算置信区间。这些区间将反映在较大组中你拥有的更多确定性。
- en: '* * *'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^([[4](#ch02fn01a)]) Cohen defined “medium-sized” as a 0.5-standard-deviation
    difference between groups.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ^([[4](#ch02fn01a)]) Cohen将“中等大小”定义为组间的0.5标准差差异。
- en: '^([[5](#ch02fn02a)]) It is important to note that accidents involving right
    turns are rare: these changes amount to fewer than 100 deaths per year in the
    United States.^([15](apa.html#ch02en15)) A 60% increase in a small number is still
    small—but nonetheless, a statistical error kills dozens of people each year!'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ^([[5](#ch02fn02a)]) 需要注意的是，涉及右转的事故很少发生：这些变化每年在美国造成的死亡人数不到100人。^([15](apa.html#ch02en15))
    即便是小范围内60%的增长仍然是微小的——但统计错误每年依然导致数十人死亡！
- en: ^([[6](#ch02fn03a)]) A real paper, which he published in 2005 in the *Journal
    of Theoretical Biology*.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ^([[6](#ch02fn03a)]) 这是他于2005年在*理论生物学杂志*上发表的真实论文。
- en: ^([[7](#ch02fn04a)]) However, shrinkage is usually implemented using more sophisticated
    methods than a simple weighted average.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ^([[7](#ch02fn04a)]) 然而，收缩通常采用比简单加权平均值更复杂的方法实现。
