<html><head></head><body>
<div id="sbo-rt-content" class="calibre1"><section aria-labelledby="ch8" epub:type="chapter" role="doc-chapter">
<span aria-label="305" epub:type="pagebreak" id="pg_305" role="doc-pagebreak"/>
<hgroup>
<h2 class="title" id="ch8">
<span class="tpt"><span class="sans_dogma_ot_bold_b_">8</span></span>
<span class="ct"><span class="sans_dogma_ot_bold_b_">THE GENETIC ALGORITHM</span></span>
</h2>
</hgroup>
<figure class="opener"><img alt="" class="opener1" height="380" src="../images/icon.jpg" width="381"/>
</figure>
<p class="chapterintro">Many wonders of modern science were inspired by nature. Airplane and glider designs were based on the flight of birds. Camouflage—a tactic for survival—derives from mimicry, a form of antipredator adaptation. The hooked barbs of a thistle led to the invention of Velcro. Even rather dull-looking termite mounds teach us about natural ventilation and cooling, an idea used in modern architecture.</p>
<p class="tx">The world of computing is no different. The exciting field of machine learning, especially deep learning, is inspired by how the human brain processes information. By copying natural strategies that evolved over millions of years, we’ve developed algorithms to solve problems that were previously thought to be unsolvable with traditional mathematical tools.</p>
<p class="tx">In this chapter and the next, you’ll learn how these nature-inspired algorithms work, about their advantages and limitations, and how to <span aria-label="306" epub:type="pagebreak" id="pg_306" role="doc-pagebreak"/>implement them in Kotlin. This chapter focuses on the genetic algorithm, an evolutionary process–based method. The next chapter covers particle swarm optimization and ant colony systems, two methods that mimic the behavior of biological agents or species. For each method, I’ll start with the key concepts and then show you how to code and apply them to real-world problems.</p>
<section aria-labelledby="sec1" epub:type="division">
<h3 class="h"><span id="sec1"/><span id="h1-49"/><span class="sans_futura_std_bold_b_">Nature-Inspired Algorithms</span></h3>
<p class="tni">Nature-inspired computing refers to observing how nature solves complex biological or physical problems and then applying similar strategies to contemporary scientific, engineering, or management problems. The core of nature-inspired computing is <i class="calibre9">nature-inspired algorithms (NIAs)</i>, which rely on strategies learned from nature.</p>
<p class="tx">Biology-based NIAs can be observed in natural processes, such as the evolution of a species or the functioning of neurons in the human brain. These processes led to the development of genetic algorithms and deep neural networks. Individual and collective behaviors of members (or <i class="calibre9">agents</i>) of a population can also form the basis for new NIAs. For example, the foraging behavior of ants around their colony inspired the ant colony optimization algorithm. Whereas ants tend to work independently without any explicit collaboration with other members of the colony, the behavior of a large school of fish or birds indicates swarm intelligence, which has led to the development of the particle swarm optimization algorithm.</p>
<p class="tx">Even nonliving natural processes involve embedded strategies optimized for meeting certain goals. Examples of such algorithms include gravitational search (based on Newton’s law of gravity) and simulated annealing (based on thermodynamics). In general, these algorithms serve as powerful tools for optimizing various processes or systems, resulting in significant gains in efficiency and cost savings.</p>
<p class="tx">Before going into detail on genetic algorithms, I’ll introduce the concepts of optimization and global solutions. Additionally, I’ll highlight instances where NIAs prove more effective than traditional mathematical tools for solving real-world problems.</p>
<section aria-labelledby="sec2" epub:type="division">
<h4 class="h1"><span id="sec2"/><span id="h2-129"/><span class="sans_futura_std_bold_condensed_oblique_">The Optimization Problem</span></h4>
<p class="tni">NIAs are well suited to solving optimization problems, in which we want to find the best solution of all possible solutions. To solve such problems, we minimize or maximize an <i class="calibre9">objective function</i>, a mathematical expression that represents the goal of what we want to achieve through optimization. It is expressed in terms of one or more <i class="calibre9">decision variables</i>, quantities we can adjust to optimize the objective function.</p>
<p class="tx">For real-world problems, the decision variables will be bounded. Additional constraints may limit and define the decision space within which the optimal solution must be found.</p>
<p class="tx">Let’s consider a simple example with only one bounded decision variable:</p>
<figure class="img4"><span class="epub"><math alttext="Equation" display="inline"><mrow><mtext>Minimize</mtext><mtext> </mtext><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>x</mi><mn>2</mn></msup><mo>−</mo><mn>2</mn></mrow></math> (8.1)<span class="sblock"/><math alttext="Equation" display="inline"><mrow><mo>−</mo><mn>3</mn><mo>≤</mo><mi>x</mi><mo>≤</mo><mn>3</mn></mrow></math></span>
<span class="mobi"><img alt="" class="img1" height="120" src="../images/eq8-1.jpg" width="1389"/></span></figure>
<p class="tx">In Equation 8.1, <i class="calibre9">f</i>(<i class="calibre9">x</i>) is an objective function of a single variable <i class="calibre9">x</i>. Our goal is to find the value of <i class="calibre9">x</i> for which <i class="calibre9">f</i>(<i class="calibre9">x</i>) will be minimum, provided <i class="calibre9">x</i> stays within ±3.</p>
<p class="tx">Since <i class="calibre9">x</i> in this case has an exponent of 2, <i class="calibre9">x</i><sup class="calibre8">2</sup> will always be positive (irrespective of whether <i class="calibre9">x</i> is positive or negative) and will continue to increase as <i class="calibre9">x</i> increases in absolute terms. Therefore, the right-hand side of Equation 8.1 will have the smallest value when <i class="calibre9">x</i> = 0. In other words, the optimal solution (marked by an asterisk) for this problem is <i class="calibre9">x</i>* = 0, and the corresponding optimum value of the function is <i class="calibre9">f</i>(<i class="calibre9">x</i>)* = –2.</p>
<p class="tx"><a href="chapter8.xhtml#fig8-1" class="calibre2">Figure 8-1</a> shows a visual representation of this function, which takes the shape of a parabola with its vertex at (0, –2). We can also visually confirm that <i class="calibre9">f</i>(<i class="calibre9">x</i>) has its minimum at point C (the vertex of the parabola).</p>
<figure class="img"><img alt="" class="img2" height="757" id="fig8-1" src="../images/Figure8-1.jpg" width="938"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 8-1: The optimal value for a parabolic function</span></p></figcaption>
</figure>
<p class="tx">A property of this function allows us to identify the optimal solution without knowing its exact location. The dashed lines touching the function at points A, B, and C in <a href="chapter8.xhtml#fig8-1" class="calibre2">Figure 8-1</a> show the <i class="calibre9">slope</i>, also called the <i class="calibre9">gradient</i>, of the function at those locations. The slope of a function measures how much the value of a function changes when the value of the decision variable changes by a small amount. Notice that the gradient at point C, where the function value is minimum, is 0 (the dashed line is horizontal). Thus, if we randomly started our search for the optimal solution at point A, we could have moved in the direction of decreasing gradient (for example, from A to B or from B to C) until the gradient becomes 0. If we continue to move beyond the vertex to the opposite side, the slope will change its direction <span aria-label="308" epub:type="pagebreak" id="pg_308" role="doc-pagebreak"/>and start increasing. This will cause the function value to increase, and we’ll move away from the optimal solution.</p>
<p class="tx">For a function that is smooth (no kinks) and continuous (no jumps) and has only one maximum or minimum within the decision space, the gradient-based search strategy will always work in finding the <i class="calibre9">global optimum</i>— the best possible solution for a given problem. In fact, for a well-behaved function like this, we can find the optimal solution by simply setting the slope of the function with respect to the decision variable (called the derivative in differential calculus) to 0 and solving the resulting equation for the optimal solution. This approach will also work for functions with two or more decision variables as long as the function is <i class="calibre9">well behaved</i>, meaning it is both smooth and continuous.</p>
<p class="tx">Things get messier when we deal with a multimodal function with multiple locations where the gradient is 0, as shown in <a href="chapter8.xhtml#fig8-2" class="calibre2">Figure 8-2</a>.</p>
<figure class="img"><img alt="" class="img2" height="922" id="fig8-2" src="../images/Figure8-2.jpg" width="970"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 8-2: Local and global minima for a univariate function</span></p></figcaption>
</figure>
<p class="tx"><a href="chapter8.xhtml#fig8-2" class="calibre2">Figure 8-2</a> shows four local minima at points A, C, D, and E, and one global minimum at point B within the decision space. In a situation like this, whether an algorithm based on gradient descent will converge to the global minimum depends on the point from which we start the search. Nothing guarantees that we’ll find the global minimum unless we make multiple attempts from different starting points (initial conditions).</p>
<p class="tx">For a better appreciation of the challenge involved when we try to find global optima for a multivariate function, consider the graph in <a href="chapter8.xhtml#fig8-3" class="calibre2">Figure 8-3</a>. This shows the results of the two-variable Eggholder function, discussed further in the final project of this chapter. For a problem like this, a simple gradient-based algorithm can easily get stuck at one of the many local minima. To make things worse, the equations defining such functions are <span aria-label="309" epub:type="pagebreak" id="pg_309" role="doc-pagebreak"/>typically not differentiable, and we cannot use calculus-based tools to estimate the global optima.</p>
<figure class="img"><img alt="" class="img1" height="935" id="fig8-3" src="../images/Figure8-3.jpg" width="1113"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 8-3: The Eggholder function with numerous local minima</span></p></figcaption>
</figure>
<p class="tx">Functions of two decision variables have a silver lining, however: we can create 3D plots of these functions for a bounded decision space. Based on a visual inspection of the surface or contour plots, it may then be possible to narrow down the search space to a number of smaller subzones where we can conduct an extensive local search to uncover the global minima (more than one global minimum could exist).</p>
<p class="tx">What about functions of higher dimensions? In fact, complex real-world optimization problems can have hundreds of decision variables. It is not humanly possible to conceive what a function of several hundred variables might look like in a <i class="calibre9">hyperspace</i> (a higher-dimensional space beyond human comprehension). Our best bet for identifying an optimal or near-optimal solution in a hyperspace is to conduct a broad-based search combining <i class="calibre9">heuristics</i> (special knowledge about the nature of the problem) and <i class="calibre9">randomization</i> (selecting initial conditions or intermediate values randomly). This strategy is likely to allow the algorithm to escape local optima and find solutions that are superior to what a pure random search might reveal. We typically repeat this process numerous times and accept the best-so-far solution as a proxy for the unknown global optima.</p>
<p class="tx">Even when looking for an optimal combination of decision variables that can have only discrete values (whole numbers), the brute-force approach of trying out all possible combinations normally doesn’t work in higher dimensions. This is because the number of combinations may be so large that it is practically impossible to complete that search in a reasonable <span aria-label="310" epub:type="pagebreak" id="pg_310" role="doc-pagebreak"/>amount of time. It’s in this context that nature-inspired algorithms come to our rescue.</p>
</section>
<section aria-labelledby="sec3" epub:type="division">
<h4 class="h1"><span id="sec3"/><span id="h2-130"/><span class="sans_futura_std_bold_condensed_oblique_">When to Use NIAs</span></h4>
<p class="tni">Compared to traditional mathematical tools, NIAs are less sensitive to the nature or complexity of the optimization problem. An objective function may be nonlinear, nonsmooth, multidimensional, and multimodal, but these attributes are not a big concern for NIAs (though we still have to choose the right tool from the basket of options). NIAs are especially suitable for solving very large optimization problems and finding near-optimal solutions without expending too many resources (such as computational time or energy use).</p>
<p class="tx">Traditional optimization methods, whether they employ a gradient descent algorithm or not, are deterministic: if we start the search from a given point, we’ll always reach the same solution or approximation after a given number of steps. This feature makes deterministic algorithms more prone to getting stuck at local optima because no built-in freedom exists to explore a different path unless the initial condition is changed.</p>
<p class="tx">NIAs, on the other hand, are <i class="calibre9">stochastic</i>, meaning that their results cannot be predicted beforehand. This is because NIAs typically have multiple built-in steps that rely on random selection. For the same initial condition, a stochastic algorithm can produce very different results. This innate ability to randomly choose a different path allows NIAs to avoid getting stuck at local optima and to eventually find the global or near-global optima.</p>
<p class="tx">In addition, some NIAs are based on the efforts of agents that operate independently (for example, ants in the ant colony optimization algorithm). This allows us to implement the algorithm so that it can benefit from parallel processing to improve computational efficiency.</p>
<p class="tx">In sum, we can use NIAs to solve large, complex, multidimensional optimization problems for which no known analytical solutions exist or for which such solutions cannot be found due to the nature of the problem. However, NIAs are not the ideal choice for solving the many optimization problems that can be efficiently solved using deterministic methods (for example, using linear or integer programming or various graph search algorithms).</p>
</section>
</section>
<section aria-labelledby="sec4" epub:type="division">
<h3 class="h"><span id="sec4"/><span id="h1-50"/><span class="sans_futura_std_bold_b_">An Overview of the Genetic Algorithm</span></h3>
<p class="tni">The genetic algorithm is among the best-known NIAs. It is modeled after the biological evolution of species driven by both the sexual reproduction of parents, who contribute genetic materials, and natural selection (survival of the fittest). In addition to inheriting genes from its parents, the offspring’s <i class="calibre9">chromosomes</i> (collections of genes) undergo random alterations called <i class="calibre9">mutation</i> that introduce new features to its gene pool. The offspring is then subjected to a selection process based on its <i class="calibre9">fitness</i> (a measure of how well an individual contributes to reaching a certain goal) before it is allowed to reproduce. The process eventually leads to a generation of individuals with a significantly enhanced gene pool.</p>
<p class="tx"><span aria-label="311" epub:type="pagebreak" id="pg_311" role="doc-pagebreak"/><a href="chapter8.xhtml#fig8-4" class="calibre2">Figure 8-4</a> shows the main components of the genetic algorithm.</p>
<figure class="img"><img alt="" class="img2" height="1049" id="fig8-4" src="../images/Figure8-4.jpg" width="951"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 8-4: The key components of the genetic algorithm</span></p></figcaption>
</figure>
<p class="tx">All genetic algorithms start with a population of randomly created individuals. Each individual is essentially a potential solution represented by its gene pool. These individuals are evaluated and screened based on their fitness, which we attempt to maximize or minimize until a termination condition is met. Otherwise, we choose a batch of individuals with better fitness values who are then allowed to mate, produce offspring, and replace their parents as the next generation. I’ll explain these steps further in the upcoming sections.</p>
</section>
<section aria-labelledby="sec5" epub:type="division">
<h3 class="h"><span id="sec5"/><span id="h1-51"/><span class="sans_futura_std_bold_b_">Genetic Operators</span></h3>
<p class="tni">Genetic operators include the three core components of genetic algorithms—selection, crossover, and mutation—that work in tandem and allow the algorithm to converge toward a solution. <i class="calibre9">Selection</i> refers to the process of choosing an individual from a population based on their fitness (their potential contribution to finding the optimal solution). Selection may involve the entire population or a subset of the population, as individuals are drawn at random based on specific strategies. <i class="calibre9">Crossover</i> involves combining genetic materials from parents to create offspring. In the genetic algorithm, it always involves two parents and is therefore a binary operator. <i class="calibre9">Mutation</i> is a random alteration of an individual’s genetic information. It is a unary operator because it is applied to one individual at a time.</p>
<section aria-labelledby="sec6" epub:type="division">
<span aria-label="312" epub:type="pagebreak" id="pg_312" role="doc-pagebreak"/>
<h4 class="h1"><span id="sec6"/><span id="h2-131"/><span class="sans_futura_std_bold_condensed_oblique_">Selection</span></h4>
<p class="tni">The selection operation ensures that better genes are passed on from one generation to the next. The implementation of this process may vary depending on the problem, but the end goal is to select two parents (chromosomes) to participate in the reproduction through crossover. The commonly used strategies for selection include tournament, roulette wheel, and rank-based selection.</p>
<section aria-labelledby="sec7" epub:type="division">
<h5 class="h2"><span id="sec7"/><span id="h3-57"/><span class="sans_futura_std_bold_b_">Tournament</span></h5>
<p class="tx">The tournament selection process is based on running fitness-based competitions among randomly selected individuals, as shown in <a href="chapter8.xhtml#fig8-5" class="calibre2">Figure 8-5</a>.</p>
<figure class="img"><img alt="" class="img1" height="558" id="fig8-5" src="../images/Figure8-5.jpg" width="1165"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 8-5: Using tournaments to select parents</span></p></figcaption>
</figure>
<p class="tx">To create a new child, the process starts by randomly selecting four individuals grouped into two pairs. From each pair, the individual with better fitness is selected as a parent. The process selects two parents per round who will reproduce via crossover (explained later) to give birth to an offspring.</p>
</section>
<section aria-labelledby="sec8" epub:type="division">
<h5 class="h2"><span id="sec8"/><span id="h3-58"/><span class="sans_futura_std_bold_b_">Roulette Wheel</span></h5>
<p class="tx">As the name implies, roulette wheel selection is comparable to spinning a dial on a board divided into segments. The area of these segments is proportional to the relative fitness of the members of the population from which parents are to be chosen. Let me explain the process with a numerical example, as shown in <a href="chapter8.xhtml#tab8-1" class="calibre2">Table 8-1</a>.</p>
<span aria-label="313" epub:type="pagebreak" id="pg_313" role="doc-pagebreak"/>
<p class="tt" id="tab8-1"><span class="sans_futura_std_bold_b_"><span class="sans_futura_std_bold_b_">Table 8-1:</span></span> <span class="sans_futura_std_book_">Roulette Wheel Data</span></p>
<table class="basic-table">
<thead class="calibre13">
<tr class="calibre14">
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Individual</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Fitness</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Relative fitness (RF)</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Cumulative RF</span></p></th>
</tr>
</thead>
<tbody class="calibre15">
<tr class="calibre16">
<td class="tbf"><p class="tableheader"><span class="sans_futura_std_book_">P1</span></p></td>
<td class="tbf"><p class="tableheader"><span class="sans_futura_std_book_">12</span></p></td>
<td class="tbf"><p class="tableheader"><span class="sans_futura_std_book_">0.286</span></p></td>
<td class="tbf"><p class="tableheader"><span class="sans_futura_std_book_">0.286</span></p></td>
</tr>
<tr class="calibre14">
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">P2</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">5</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">0.119</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">0.405</span></p></td>
</tr>
<tr class="calibre16">
<td class="tb"><p class="tableheader"><span class="sans_futura_std_book_">P3</span></p></td>
<td class="tb"><p class="tableheader"><span class="sans_futura_std_book_">8</span></p></td>
<td class="tb"><p class="tableheader"><span class="sans_futura_std_book_">0.190</span></p></td>
<td class="tb"><p class="tableheader"><span class="sans_futura_std_book_">0.595</span></p></td>
</tr>
<tr class="calibre14">
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">P4</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">10</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">0.238</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">0.833</span></p></td>
</tr>
<tr class="calibre16">
<td class="tb"><p class="tableheader"><span class="sans_futura_std_book_">P5</span></p></td>
<td class="tb"><p class="tableheader"><span class="sans_futura_std_book_">4</span></p></td>
<td class="tb"><p class="tableheader"><span class="sans_futura_std_book_">0.095</span></p></td>
<td class="tb"><p class="tableheader"><span class="sans_futura_std_book_">0.929</span></p></td>
</tr>
<tr class="calibre14">
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">P6</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">3</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">0.071</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">1.000</span></p></td>
</tr>
<tr class="calibre16">
<td class="tbl"><p class="tableheader"><span class="sans_futura_std_book_">SUM =</span></p></td>
<td class="tbl"><p class="tableheader"><span class="sans_futura_std_book_">42</span></p></td>
<td class="tbl"><p class="tableheader"><span class="sans_futura_std_book_">1.000</span></p></td>
<td class="tbl"/>
</tr>
</tbody>
</table>
<p class="tx"><a href="chapter8.xhtml#fig8-6" class="calibre2">Figure 8-6</a> shows the graphical representation of the example in <a href="chapter8.xhtml#tab8-1" class="calibre2">Table 8-1</a>.</p>
<figure class="img"><img alt="" class="img2" height="843" id="fig8-6" src="../images/Figure8-6.jpg" width="957"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 8-6: Selecting parents using the roulette wheel method</span></p></figcaption>
</figure>
<p class="tx">In this example, we consider a population of six individuals, P1 through P6. Their fitness values are given in the second column of <a href="chapter8.xhtml#tab8-1" class="calibre2">Table 8-1</a>. The relative fitness (RF) values are calculated by dividing individual fitness values by the sum of all individual fitness values (for example, RF for P1 = 12/42). The last column represents the cumulative RF (CRF), which is created by adding all RF values up to a certain row. For example, the CRF corresponding to P2 = 0.286 + 0.119 = 0.405. The last CRF, which is the sum of all individual RF values, will be 1.0. In the roulette wheel scheme, RF values are used as proxy probabilities for individuals to be selected at random when an unbiased virtual dial is spun.</p>
<p class="tx">In <a href="chapter8.xhtml#fig8-6" class="calibre2">Figure 8-6</a>, these six individuals are represented by six different segments whose areas are the same as their RF values (shown next to the individual names). To implement the roulette wheel method, we draw a random number between 0 and 1 from a uniform distribution, which has the same effect as spinning the dial. (This is done programmatically by using the <span class="sans_thesansmonocd_w5regular_">random()</span> method in the standard Kotlin math library.) Let’s say that the value of this random number is 0.68, equivalent to having the dial stop inside the fourth segment (between CRFs of 0.595 and 0.833). Based on this draw, we would select P4 as parent 1 and repeat the process one more time to choose parent 2.</p>
</section>
<section aria-labelledby="sec9" epub:type="division">
<span aria-label="314" epub:type="pagebreak" id="pg_314" role="doc-pagebreak"/>
<h5 class="h2"><span id="sec9"/><span id="h3-59"/><span class="sans_futura_std_bold_b_">Rank-Based Selection</span></h5>
<p class="tx">The third selection method, rank-based selection, is very similar to the roulette wheel method. Here, we order the individuals in ascending or descending order, depending on the problem, and assign each individual a rank based on their fitness. If two or more individuals have the same fitness, they are assigned an average value (based on their positions in the ordered list) as their rank. Finally, the ranks are used to calculate RF values and select the mating parents as we would using the roulette wheel scheme.</p>
</section>
</section>
<section aria-labelledby="sec10" epub:type="division">
<h4 class="h1"><span id="sec10"/><span id="h2-132"/><span class="sans_futura_std_bold_condensed_oblique_">Crossover</span></h4>
<p class="tni">The crossover operation is designed to intermix the genes of two parents to create one or two offspring who become members of the next generation. As with the selection operator, many ways of splitting the chromosomes and recombining the genes are available. <a href="chapter8.xhtml#fig8-7" class="calibre2">Figure 8-7</a> shows the schema for a simple but effective approach to this operation, called a single-point crossover.</p>
<figure class="img"><img alt="" class="img3" height="576" id="fig8-7" src="../images/Figure8-7.jpg" width="739"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 8-7: The single-point crossover operation</span></p></figcaption>
</figure>
<p class="tx">We start the process by identifying two parents through the selection operation. These parents would normally have chromosomes consisting of different genes. In the example in <a href="chapter8.xhtml#fig8-7" class="calibre2">Figure 8-7</a>, both parents have chromosomes made of binary genes denoted by 0 or 1. Parent 1’s genes are shown as white cells, whereas parent 2’s genes are gray cells.</p>
<p class="tx">The first step of the crossover operation is to draw a random integer from a uniform distribution between 1 and the number of genes minus 1, which would be between 1 and 5 (inclusive) in our example. Let’s say the integer drawn is 4. We’d then split chromosomes of both parents at this location (between the fourth and fifth genes shown in <a href="chapter8.xhtml#fig8-7" class="calibre2">Figure 8-7</a>). Finally, we’d swap the split parts by adding the last two genes from parent 2 to parent 1 (the two gray cells of child 1) and adding the last two genes from parent 1 to parent 2 (the two white cells of child 2).</p>
<p class="tx">In this example, we used two parents to create two children. However, we could also decide to produce only one child per iteration to keep the algorithm simple and easy to code. For <i class="calibre9">real-coded genes</i>—genes represented by real numbers—a crossover operation will produce only one child <span aria-label="315" epub:type="pagebreak" id="pg_315" role="doc-pagebreak"/>because of the way the method is implemented. We’ll discuss real-coded genes further in the final project of this chapter.</p>
<p class="tx">Many other types of crossover operations, such as multipoint crossover and ordered crossover, exist. For real-coded genes used in mathematical function optimization, crossover operations could be based on an arithmetic, geometric, or weighted mean of fitness values.</p>
</section>
<section aria-labelledby="sec11" epub:type="division">
<h4 class="h1"><span id="sec11"/><span id="h2-133"/><span class="sans_futura_std_bold_condensed_oblique_">Mutation</span></h4>
<p class="tni">Mutation involves randomly changing the values of genes or, for real-coded genes, adding a small noise to those values before adding a child to the next generation. Mutation is applied to every gene in the chromosome one at a time. First, we randomly draw a real number between 0 and 1 and compare that with a mutation threshold (probability), typically set to a very small value. If the random value drawn is less than or equal to the mutation threshold, we alter the genetic content for that gene. For a binary chromosome where the genes are either 1 or 0 (indicating inclusion or exclusion of some entity in the solution), this alteration is conducted by flipping the gene value from 0 to 1 or vice versa.</p>
<p class="tx"><a href="chapter8.xhtml#fig8-8" class="calibre2">Figure 8-8</a> visually explains this process.</p>
<figure class="img"><img alt="" class="img3" height="510" id="fig8-8" src="../images/Figure8-8.jpg" width="592"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 8-8: Mutation in a binary chromosome</span></p></figcaption>
</figure>
<p class="tx">In <a href="chapter8.xhtml#fig8-8" class="calibre2">Figure 8-8</a>, the second and fifth genes have been randomly selected for mutation. Given that these are binary genes, their gene values have been flipped from 0 to 1.</p>
</section>
<section aria-labelledby="sec12" epub:type="division">
<h4 class="h1"><span id="sec12"/><span id="h2-134"/><span class="sans_futura_std_bold_condensed_oblique_">Elitism</span></h4>
<p class="tni">Before we move on to tackling our first genetic algorithm project, I’ll introduce one more important concept—<i class="calibre9">elitism</i>. This technique involves sorting the current population based on their fitness, then adding a fraction of that sorted population to the next generation before attempting crossover and mutation. This operation is called elitism because it favors the fittest individuals. Elitism generally helps reduce the number of computations needed to locate the optimal solution because it protects some of the best chromosomes from getting altered or diluted by crossover and mutation operations.</p>
<p class="headaexercise" id="pre-33"><span aria-label="316" epub:type="pagebreak" id="pg_316" role="doc-pagebreak"/><span class="sans_dogma_ot_bold_b_15-n">Project 33: Evolve Gibberish into Shakespeare</span></p>
<p class="tni">In our first coding project, we’ll create a population with random collections of genes as their chromosomes. We’ll then use a genetic algorithm to refine those chromosomes until one of the individuals becomes as eloquent as Shakespeare and repeats Hamlet’s famous line “To be, or not to be: that is the question,” expressed in its gene sequence!</p>
</section>
<section aria-labelledby="sec13" epub:type="division">
<h4 class="h1"><span id="sec13"/><span id="h2-135"/><span class="sans_futura_std_bold_condensed_oblique_">The Strategy</span></h4>
<p class="tni">To solve this problem, we’ll create a population of size 100. No hard-and-fast rule applies on this, and a bit of experimentation is required to estimate a reasonable size for a given problem. Many factors are at play that will determine the convergence rate of the algorithm, including population size, the way the genetic operators are implemented, and the stopping condition. One possible strategy is to start with a smaller population size and then gradually increase it until further improvements in the solution become negligible.</p>
<p class="tx">Next, we need to determine the size of the chromosomes. For this specific problem, each individual’s chromosome will have 42 genes—the length of the text we aim to reproduce using the algorithm. These genes will be randomly selected from a pool of 87 genes, which in this case is a collection of alphanumeric characters (including punctuation and parentheses). Since our goal is to exactly match the target text, this collection includes both uppercase and lowercase letters.</p>
<p class="tx">In our genetic algorithm implementation, we’ll use elitism and tournament-based selection as our operators. Additionally, we’ll employ a single-point crossover scheme. For mutation, we will use a threshold of 1/42 to ensure that on average one gene will mutate for each new child created via crossover.</p>
</section>
<section aria-labelledby="sec14" epub:type="division">
<h4 class="h1"><span id="sec14"/><span id="h2-136"/><span class="sans_futura_std_bold_condensed_oblique_">The Code</span></h4>
<p class="tni">The overall structure of the code closely resembles the general structure of the genetic algorithm described in <a href="chapter8.xhtml#fig8-4" class="calibre2">Figure 8-4</a>. We’ll discuss each of its components in the following sections.</p>
<section aria-labelledby="sec15" epub:type="division">
<h5 class="h2"><span id="sec15"/><span id="h3-60"/><span class="sans_futura_std_bold_b_">Global Declarations</span></h5>
<p class="tni">In this code segment, we create a data class, and declare and/or set required global parameters and collections. We also create two mutable lists of data objects to store population states for the current and next generations.</p>
<pre class="calibre10"><code class="calibre11">data class Solution(
    val chromosome: String,
    val fitness: Int
)

<span aria-label="annotation1" class="codeannotated_codeannotation">❶</span> val TARGET = "To be, or not to be: that is the question."
<span aria-label="annotation2" class="codeannotated_codeannotation">❷</span> val VALID_GENES: String =
<span aria-label="317" epub:type="pagebreak" id="pg_317" role="doc-pagebreak"/>    "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ" + // letters
            "1234567890" +                                   // numbers
            ", .-;:_!/?#%&amp;()={[]}$*@\"\'"                    // symbols
val chromosomeLength = TARGET.length
val POP_SIZE = 100
val MAX_GEN = 1000
val ELITISM = 0.15
val eliteSize = (POP_SIZE * ELITISM).toInt()
<span aria-label="annotation3" class="codeannotated_codeannotation">❸</span> val MUTATION_THRESHOLD = 1.0/chromosomeLength

val population: MutableList&lt;Solution&gt; = mutableListOf()
val nextgen: MutableList&lt;Solution&gt; = mutableListOf()</code></pre>
<p class="tx">Let’s walk through this segment step by step. At the top of the block, we create a <span class="sans_thesansmonocd_w5regular_">Solution</span> object (data class) that will be used to create the individuals who will make up the population and undergo genetic alterations.</p>
<p class="tx">Next, we define the target string or the desired end state for the fittest individual in the population <span aria-label="annotation1" class="codeannotation">❶</span>. The target string has 42 characters (including spaces), which are stored in a string named <span class="sans_thesansmonocd_w5regular_">TARGET</span>. The target string is built from a pool of genes—characters that we typically use while composing phrases in English. This gene pool is saved as <span class="sans_thesansmonocd_w5regular_">VALID_GENES</span> <span aria-label="annotation2" class="codeannotation">❷</span>.</p>
<p class="tx">We set the population size (<span class="sans_thesansmonocd_w5regular_">POP_SIZE</span>) to 100 and the number of generations (<span class="sans_thesansmonocd_w5regular_">MAX_GEN</span>) to 1,000. We also employ elitism. Fifteen percent of the population (the top 15 fittest individuals) will be automatically included in the next generation. The remaining members of the next generation will be produced through selection, crossover, and mutation. The threshold for mutation has been set to <span class="sans_thesansmonocd_w5regular_">1.0/chromosomeLength</span> <span aria-label="annotation3" class="codeannotation">❸</span> so that on average 1 gene out of 42 will undergo mutation per offspring. (You may need to adjust this rule of thumb for other optimization problems. For example, you may have to explicitly set the mutation threshold from 1 to 3 percent when too few genes exist in the chromosome.)</p>
<p class="tx">The last two lines create two mutable lists of type <span class="sans_thesansmonocd_w5regular_">Solution</span>, which store the individuals belonging to the current generation (<span class="sans_thesansmonocd_w5regular_">population</span>) and to the next generation (<span class="sans_thesansmonocd_w5regular_">nextgen</span>).</p>
</section>
<section aria-labelledby="sec16" epub:type="division">
<h5 class="h2"><span id="sec16"/><span id="h3-61"/><span class="sans_futura_std_bold_b_">Initializing Population and Fitness Evaluation</span></h5>
<p class="tni">The initial population is created by making a call to the <span class="sans_thesansmonocd_w5regular_">initPopulation()</span> function, which in turn relies on the <span class="sans_thesansmonocd_w5regular_">getFitness()</span> helper function.</p>
<pre class="calibre10"><code class="calibre11">fun initPopulation() {
    // Initialize a population of POP_SIZE individuals.
    for (i in 0 until POP_SIZE) {
        var chromosome = ""
        for (j in 0 until chromosomeLength) {
           <span aria-label="annotation1" class="code_codeannotation">❶</span> chromosome += VALID_GENES.random()
        }
        // Calculate fitness of the new chromosome.
        val fitness = getFitness(chromosome)
        // Add the new individual to the population.
      <span aria-label="annotation2" class="code_codeannotation">❷</span> population += Solution(chromosome, fitness)
    }
<span aria-label="318" epub:type="pagebreak" id="pg_318" role="doc-pagebreak"/>    // Sort population (in place) in descending order.
    population.sortByDescending {it.fitness}
    println("\nBest solution from initial population:")
    println(population[0].toString())
    println("\n... initPopulation done ...\n")
}

fun getFitness(chromosome: String): Int {
    var fitness = 0
    val pairs = TARGET.zip(chromosome)
    for (pair in pairs) {
      <span aria-label="annotation3" class="code_codeannotation">❸</span> if (pair.first == pair.second)
                 fitness += 1
    }
    return fitness
}</code></pre>
<p class="tx">The <span class="sans_thesansmonocd_w5regular_">initPopulation()</span> function creates the number of individuals specified by <span class="sans_thesansmonocd_w5regular_">POP_SIZE</span> (100, in this case) whose chromosomes are created by randomly picking individual genes (all 42 of them) from the supplied gene pool, <span class="sans_thesansmonocd_w5regular_">VALID_GENES</span> <span aria-label="annotation1" class="codeannotation">❶</span>. Once the chromosome is complete, its fitness is evaluated by calling the <span class="sans_thesansmonocd_w5regular_">getFitness()</span> function. A new <span class="sans_thesansmonocd_w5regular_">Solution</span> is created using the chromosome and fitness value and then added to the <span class="sans_thesansmonocd_w5regular_">population</span> <span aria-label="annotation2" class="codeannotation">❷</span>.</p>
<p class="tx">Before exiting this function, we sort the population in descending order and print the best solution from the initial population. This presorting is needed to check for the termination condition and implement elitism for the first generation inside the <span class="sans_thesansmonocd_w5regular_">runGA()</span> function. For subsequent generations, sorting is done at the end of each iteration inside <span class="sans_thesansmonocd_w5regular_">runGA()</span>.</p>
<p class="tx">Within the <span class="sans_thesansmonocd_w5regular_">getFitness()</span> function, we create a list named <span class="sans_thesansmonocd_w5regular_">pairs</span> of type <span class="sans_thesansmonocd_w5regular_">Pair&lt;Char, Char&gt;</span> and calculate the fitness value for the given chromosome based on pair-wise comparisons. For each matching gene, fitness is incremented by 1 <span aria-label="annotation3" class="codeannotation">❸</span>. If a chromosome matches the target string exactly, it will have a maximum fitness value of 42.</p>
</section>
<section aria-labelledby="sec17" epub:type="division">
<h5 class="h2"><span id="sec17"/><span id="h3-62"/><span class="sans_futura_std_bold_b_">The Driver Function</span></h5>
<p class="tni">In the code block for the <span class="sans_thesansmonocd_w5regular_">runGA()</span> function, we implement the core components of the genetic algorithm. This includes iterating over multiple generations, checking for the termination condition, and creating the next generation by using elitism, selection, crossover, and mutation—the entire collection of genetic operators.</p>
<pre class="calibre10"><code class="calibre11">fun runGA() {

    // Iterate for a specified number of generations.
  <span aria-label="annotation1" class="code_codeannotation">❶</span> for (generation in 1 .. MAX_GEN) {

        // Step 1: Check for termination condition.
      <span aria-label="annotation2" class="code_codeannotation">❷</span> if (population[0].fitness &gt;= chromosomeLength) {
            println("\n*** Target reached at generation = " +
                    "${generation - 1} ***\n")
<span aria-label="319" epub:type="pagebreak" id="pg_319" role="doc-pagebreak"/>            break
        }

        // Step 2: Implement elitism.
      <span aria-label="annotation3" class="code_codeannotation">❸</span> selectElites()

        // Step 3: Implement crossover and mutation.
      <span aria-label="annotation4" class="code_codeannotation">❹</span> for (i in eliteSize until POP_SIZE) {
            // Select parents for crossover.
            val parent1 = tournament()
            val parent2 = tournament()

            // Produce a child by using crossover and mutation.
            val child = crossover(parent1, parent2)

            // Add the child to nextgen.
            nextgen += child
        }

        // Step 4: Transfer nextgen to the current population.
      <span aria-label="annotation5" class="code_codeannotation">❺</span> for (i in nextgen.indices)
            population[i] = nextgen[i].copy()

        // Step 5: Clear nextgen for the next iteration.
        nextgen.clear()

        // Step 6: Sort population in descending order (in place).
       <span aria-label="annotation6" class="code_codeannotation">❻</span> population.sortByDescending {it.fitness}

        // Step 7 (optional): Print the best solution per generation.
        val formatString = "%5d %44s %4d"
      <span aria-label="annotation7" class="code_codeannotation">❼</span> println(formatString.format(generation,
            population[0].chromosome, population[0].fitness))
    }
}</code></pre>
<p class="tx">The outermost <span class="sans_thesansmonocd_w5regular_">for</span> loop <span aria-label="annotation1" class="codeannotation">❶</span> runs the genetic processes for the specified number of generations. Inside this loop, we first check for the termination condition by comparing the best fitness value from the current <span class="sans_thesansmonocd_w5regular_">population</span> with the maximum possible fitness <span aria-label="annotation2" class="codeannotation">❷</span>. If the condition is met, the program terminates after printing a message that it has reached the target. If the condition is not met, we implement elitism by calling the <span class="sans_thesansmonocd_w5regular_">selectElites()</span> function <span aria-label="annotation3" class="codeannotation">❸</span>, discussed in detail in the next section.</p>
<p class="tx">We then move on to the first inner <span class="sans_thesansmonocd_w5regular_">for</span> loop <span aria-label="annotation4" class="codeannotation">❹</span>, which creates the remaining members of the next generation by selecting new parents by tournament, creating a child by calling the <span class="sans_thesansmonocd_w5regular_">crossover()</span> function (which also applies mutation to the newly created chromosome, as discussed in the next section), and then adding the child to the mutable <span class="sans_thesansmonocd_w5regular_">nextgen</span> list.</p>
<p class="tx">We use a second inner <span class="sans_thesansmonocd_w5regular_">for</span> loop <span aria-label="annotation5" class="codeannotation">❺</span> to individually copy the next-generation solutions (<span class="sans_thesansmonocd_w5regular_">nextgen</span>) to <span class="sans_thesansmonocd_w5regular_">population</span> before <span class="sans_thesansmonocd_w5regular_">nextgen</span> is cleared for the next iteration. Notice that given the simple structure of the <span class="sans_thesansmonocd_w5regular_">Solution</span> data class, the <span class="sans_thesansmonocd_w5regular_">copy()</span> method applied to the elements of <span class="sans_thesansmonocd_w5regular_">nextgen</span> creates a deep copy and prevents cross-referencing between <span class="sans_thesansmonocd_w5regular_">population</span> and <span class="sans_thesansmonocd_w5regular_">nextgen</span>. In addition, transferring <span aria-label="320" epub:type="pagebreak" id="pg_320" role="doc-pagebreak"/><span class="sans_thesansmonocd_w5regular_">nextgen</span> values to <span class="sans_thesansmonocd_w5regular_">population</span> at the end of each iteration eliminates the need to store multiple generations of solutions, which saves a lot of memory.</p>
<p class="tx">In the final segment of the outermost <span class="sans_thesansmonocd_w5regular_">for</span> loop, we sort the newly updated <span class="sans_thesansmonocd_w5regular_">population</span> in descending order <span aria-label="annotation6" class="codeannotation">❻</span> and print three key values per generation: the iteration number, the chromosome with the best fitness, and the corresponding fitness <span aria-label="annotation7" class="codeannotation">❼</span>.</p>
</section>
<section aria-labelledby="sec18" epub:type="division">
<h5 class="h2"><span id="sec18"/><span id="h3-63"/><span class="sans_futura_std_bold_b_">The Operator Functions</span></h5>
<p class="tni">The <span class="sans_thesansmonocd_w5regular_">runGA()</span> function relies on several operator functions that perform the key genetic operations.</p>
<pre class="calibre10"><code class="calibre11">fun selectElites() {
    // Assign top eliteSize individuals to nextgen.
  <span aria-label="annotation1" class="code_codeannotation">❶</span> for (i in 0 until eliteSize)
         nextgen += population[i].copy()
}

fun tournament(): Solution {
    // random sampling with replacement
    // Use the entire population, including elites.
    val candidate1 = population.random().copy()
    val candidate2 = population.random().copy()
    // Return the winner of the tournament.
  <span aria-label="annotation2" class="code_codeannotation">❷</span> return if (candidate1.fitness &gt;= candidate2.fitness) candidate1
               else candidate2
}

fun crossover(parent1: Solution, parent2: Solution): Solution {
    // random single-point split crossover
    val split = (1 until chromosomeLength).random()

    // Use slice to extract segments from a string.
  <span aria-label="annotation3" class="code_codeannotation">❸</span> val crossChromosome =
        parent1.chromosome.slice(0 until split) +
                parent2.chromosome.slice(split until chromosomeLength)

    // Apply mutation to crossChromosome.
  <span aria-label="annotation4" class="code_codeannotation">❹</span> val newChromosome = mutation(crossChromosome)

  <span aria-label="annotation5" class="code_codeannotation">❺</span> return Solution(newChromosome, getFitness(newChromosome))
}

fun mutation(crossChromosome: String): String {
    // A String object is immutable in Kotlin.
    // Create a char array whose elements can be modified.
    val chars = crossChromosome.toCharArray()
    for (i in 0 until chromosomeLength) {
      <span aria-label="annotation6" class="code_codeannotation">❻</span> if ((0..1000).random()/1000.0 &lt;= MUTATION_THRESHOLD)
            chars[i] = VALID_GENES.random()
    }
  <span aria-label="annotation7" class="code_codeannotation">❼</span> return String(chars)
}</code></pre>
<p class="tx"><span aria-label="321" epub:type="pagebreak" id="pg_321" role="doc-pagebreak"/>The <span class="sans_thesansmonocd_w5regular_">selectElites()</span> function is a one-liner. It promotes the top 15 individuals (<span class="sans_thesansmonocd_w5regular_">eliteSize</span> = 15) from the current generation to the next generation without subjecting them to further genetic processes <span aria-label="annotation1" class="codeannotation">❶</span>.</p>
<p class="tx">The <span class="sans_thesansmonocd_w5regular_">tournament()</span> function randomly picks two individuals from the current population and returns the winner of the competition based on their fitness values <span aria-label="annotation2" class="codeannotation">❷</span>.</p>
<p class="tx">The <span class="sans_thesansmonocd_w5regular_">crossover()</span> function takes in two parents as arguments, splits their chromosomes at a random location, and combines the split parts from both parents to create a new chromosome for the offspring <span aria-label="annotation3" class="codeannotation">❸</span>. Next, this newly created chromosome (<span class="sans_thesansmonocd_w5regular_">crossChromosome</span>) is passed to the <span class="sans_thesansmonocd_w5regular_">mutation()</span> function <span aria-label="annotation4" class="codeannotation">❹</span>, which returns the final chromosome saved as <span class="sans_thesansmonocd_w5regular_">newChromosome</span>. A single offspring is then returned once the fitness value for the newly created chromosome is calculated by making a call to <span class="sans_thesansmonocd_w5regular_">getFitness()</span> <span aria-label="annotation5" class="codeannotation">❺</span>.</p>
<p class="tx">Finally, the <span class="sans_thesansmonocd_w5regular_">mutation()</span> function applies mutation to randomly selected genes. It first converts the chromosome from a string object to a character array because strings are immutable in Kotlin. The mutation operation, triggered by the <span class="sans_thesansmonocd_w5regular_">MUTATION_THRESHOLD</span> parameter <span aria-label="annotation6" class="codeannotation">❻</span>, is applied to each gene in the chromosome. Once the mutation operation is done, the character array is converted back to a string and returned as the new (mutated) chromosome <span aria-label="annotation7" class="codeannotation">❼</span>.</p>
</section>
<section aria-labelledby="sec19" epub:type="division">
<h5 class="h2"><span id="sec19"/><span id="h3-64"/><span class="sans_futura_std_bold_b_">The main() Function</span></h5>
<p class="tni">The <span class="sans_thesansmonocd_w5regular_">main()</span> function simply prints a few key problem-specific parameters and makes two function calls to finish the job.</p>
<pre class="calibre10"><code class="calibre11">fun main() {
    println("\n*** Text-matching using the genetic algorithm ***\n")
    println("Target string: $TARGET")
    println("Population size: $POP_SIZE, Generations: $MAX_GEN, " +
            "Chromosome length: $chromosomeLength")
    println("Mutation threshold: $MUTATION_THRESHOLD")

    // Initialize the population.
    initPopulation()
    // Run the genetic algorithm.
    runGA()
}</code></pre>
<p class="tx">The first call to <span class="sans_thesansmonocd_w5regular_">initPopulation()</span> initializes the current population with random chromosomes. The second call to <span class="sans_thesansmonocd_w5regular_">runGA()</span> conducts the necessary genetic operations.</p>
</section>
</section>
<section aria-labelledby="sec20" epub:type="division">
<h4 class="h1"><span id="sec20"/><span id="h2-137"/><span class="sans_futura_std_bold_condensed_oblique_">The Result</span></h4>
<p class="tni">Each time you run this program, it will take a different number of iterations to exactly match the target string. This is because we’re using a stochastic method that depends on many internal levels of random selection. This is a very helpful feature for solving large real-world problems that may not have a deterministic or known solution.</p>
<p class="tx"><span aria-label="322" epub:type="pagebreak" id="pg_322" role="doc-pagebreak"/>Here is some sample output from the program:</p>
<pre class="calibre10"><code class="calibre11">*** Text-matching using the genetic algorithm ***

Target string: To be, or not to be: that is the question.
Population size: 100, Generations: 1000, Chromosome length: 42
Mutation threshold: 0.023809523809523808

Best solution from initial population:
Solution(chromosome=u[n_ebJvtj=J[h5j{bNx:BhPch'qyM/)3RVz"K_]P:, fitness=3)

... initPopulation done ...

    1   u[n_ebJvtj=J[h5j{bNx:BhPch'qyM/)3RVz"K_]P:   3
    2   c_g-i1KpZQn[[qXq%hwp:,shb]7k?PEL_ol @izl.    4
    3   C@eSnKo7T_b6o@thqvgL Kh=FU[(&amp;bCF{veDP"4/d    5
    4   C@eSnKo7T_b6o@thqvgL Kh=FU[(&amp;bCF{veDP"4/d    5
    5   rnkFi6Z8U /NP An%d]m&amp;vSZSS{&amp;6F/e=qJ9*iio#k   6
    6   yT;_e}Jvtj=J[h5j{bNx:BhPch[(&amp;bF qJS @iz/d    7
    7   yT;_e}Jvtj=J[h5j{bNx:BhPch[(&amp;bF qJS @iz/d    7
    8   342y"BZo@_b6o@thqvgL Kh=FD[(&amp;bCFqJSq@izl.    8
    9   342y"BZo@_b6o@thqvgL Kh=FD[(&amp;bCFqJSq@izl.    8
   10   p42y"BZo;bTcXxD?{bNL BhPcU[(&amp;bCF{veDPiol.    9
   11   342y"aZo@_b6o@thqvgL Kh=FD[(?/e qJ9*iio#k   10
   12   =[eSnKo8U XNP thqvgL Kh=FD[(?/e qJ9*iio#k   11

<var class="calibre18">--snip--</var>

  370   To be, or not to be: that i(the question.   41
  371   To be, or not to be: that i(the question.   41
  372   To be, or not to be: that i(the question.   41
  373   To be, or not to be: that i(the question.   41
  374   To be, or not to be: that i(the question.   41
  375   To be, or not to be: that i(the question.   41
  376   To be, or not to be: that i(the question.   41
  377   To be, or not to be: that i(the question.   41
  378   To be, or not to be: that i(the question.   41
  379   To be, or not to be: that is the question.  42

*** Target reached at generation = 379 ***</code></pre>
<p class="tx">In this instance, starting with chromosomes that had no resemblance to the target string, it took 379 generations for the algorithm to re-create the target string exactly. We haven’t made any attempt to fine-tune the global parameter values to increase the speed of convergence, yet the code converges to the optimal solution almost instantly (the processing time will depend on the configuration of your device). Pretty impressive!</p>
<span aria-label="323" epub:type="pagebreak" id="pg_323" role="doc-pagebreak"/>
<aside aria-label="box-40" class="box2">
<p class="boxtitle" id="box-40"><span class="sans_futura_std_bold_b_">EXERCISE</span></p>
<p class="boxfirst"><span class="sans_futura_std_book_">Modify the</span> <span class="sans_thesansmonocd_w5regular_">crossover()</span> <span class="sans_futura_std_book_">function to create and return two children rather than one child. You’ll now need half as many calls to the</span> <span class="sans_thesansmonocd_w5regular_">crossover()</span> <span class="sans_futura_std_book_">function to create the next generation. This will, among other things, require you to modify the inner</span> <span class="sans_thesansmonocd_w5regular_">for</span> <span class="sans_futura_std_book_">loop of the</span> <span class="sans_thesansmonocd_w5regular_">runGA()</span> <span class="sans_futura_std_book_">function. While this will reduce the number of computations, its impact on the efficiency of the algorithm is not certain. You can run both versions of the program by using the same set of global parameters to test whether one version consistently outperforms the other. To be sure, solve several test problems instead of just one.</span></p>
</aside>
<p class="headaexercise" id="pre-34"><span class="sans_dogma_ot_bold_b_15-n">Project 34: Solve the Knapsack Problem</span></p>
<p class="tni">You’re likely familiar with Noah’s ark, the vessel Noah and his followers built to save themselves from a great deluge. The challenge that Noah faced was massive: he had to build a vessel of unprecedented size and choose who or what to take on board. To a mathematician, this latter decision is a classic example of an optimization problem where one tries to maximize the value of the objects that can be accommodated within a limited space.</p>
<p class="tx">Let’s build a miniature version of this challenge and solve it using the genetic algorithm. We’ll name this project Jonah’s ark. Jonah lives in a flood plain that faces the risk of flash floods. Jonah knows he must be ready to leave the area at short notice. His quickest route to safety involves using a small-engine boat to get away from the rising river through a tributary beyond the reach of flood waters. Of course, the boat is small and can carry only so many items without sinking. Jonah must decide which of the valuable objects in his possession he should take with him without exceeding the capacity of the boat.</p>
<p class="tx">Jonah was able to come up with a short list of the 12 objects most valuable to him—which is still too many to take on board. Now he needs to figure out which combination of those objects he should choose so that their total worth (sum of assigned values) to him will be maximized without exceeding the capacity of his boat.</p>
</section>
<section aria-labelledby="sec21" epub:type="division">
<h4 class="h1"><span id="sec21"/><span id="h2-138"/><span class="sans_futura_std_bold_condensed_oblique_">The Strategy</span></h4>
<p class="tni">The Jonah’s ark problem is a variation of what is known in mathematics as the <i class="calibre9">knapsack problem</i>:</p>
<blockquote class="calibre17">
<p class="extractpara">Let <span class="copyright_italic">n</span> be the number of objects one has to choose from. Let <b class="calibre6"><i class="calibre9">V</i></b> = [<span class="copyright_italic">v</span><sub class="calibre21">1</sub>, <span class="copyright_italic">v</span><sub class="calibre21">2</sub>, . . . , <span class="copyright_italic">v</span><span class="epub-i-sub1">n</span>] be the list of values (worth) of those objects and <b class="calibre6"><i class="calibre9">W</i></b> = [<span class="copyright_italic">w</span><sub class="calibre21">1</sub>, <span class="copyright_italic">w</span><sub class="calibre21">2</sub>, . . . , <span class="copyright_italic">w</span><span class="epub-i-sub1">n</span>] be the list of weights of those objects. Also, let <b class="calibre6"><i class="calibre9">W</i></b><span class="epub-i-sub1">max</span> be the maximum weight that the knapsack can carry. The goal is to find a subset of <span class="copyright_italic">m</span> objects so <span aria-label="324" epub:type="pagebreak" id="pg_324" role="doc-pagebreak"/>that the sum of values for that subset is maximized while ensuring that the sum of corresponding weights remains ≤ <b class="calibre6"><i class="calibre9">W</i></b><span class="epub-i-sub1">m</span><sub class="calibre21">ax</sub>.</p>
</blockquote>
<p class="tx">We’ll leverage the genetic algorithm to address this problem. It’s evident that we’ll have to make changes to the problem definition part of the code. First, given that Jonah now has a choice among 12 distinct objects, we’ll set the number of chromosomes to 12. Each gene in the chromosome will assume a binary value, where 1 signifies the inclusion of an object in the solution and 0 denotes its exclusion. We’ll also calculate the fitness of a solution differently based on which objects are included and their respective values and weights. I’ll explain this further when we discuss the related code segment.</p>
<p class="tx">One important consideration is the composition of the initial population. We need to ensure that the initial population has some diversity. If all genes are randomly assigned, we might get a population with zero fitness. This would make crossover useless, and we would be relying solely on mutation, which is a very slow process. Therefore, while initiating the population, we’ll force each member to have a nonzero fitness.</p>
<p class="tx">Before we start coding, we need to address a few technical considerations. First, we’ll adopt a 0-1 approach to solve this problem, meaning we’ll either include an object or completely exclude it in the solution. We’re not allowed to take a fraction of an object (and a fraction of its value). Second, we assume that we have only one copy of each object, so we cannot repeat any object in our solution. Third, we assume that we have only one knapsack to fill.</p>
</section>
<section aria-labelledby="sec22" epub:type="division">
<h4 class="h1"><span id="sec22"/><span id="h2-139"/><span class="sans_futura_std_bold_condensed_oblique_">The Code</span></h4>
<p class="tni">We developed a fully functional genetic algorithm program in <span><a href="chapter8.xhtml#pre-33" class="calibre2">Project 33</a></span>. For the most part, we’ll reuse that code and make a few adjustments needed to describe and solve the knapsack problem (or the Jonah’s ark problem).</p>
<section aria-labelledby="sec23" epub:type="division">
<h5 class="h2"><span id="sec23"/><span id="h3-65"/><span class="sans_futura_std_bold_b_">Problem Definition and Global Parameters</span></h5>
<p class="tni">This code segment is composed of an import statement, data class declarations, the creation of a list of items to choose from, global parameters, and the creation of mutable lists to track population states for both the current and the next generations, as well as the best solutions from each generation.</p>
<pre class="calibre10"><code class="calibre11">import kotlin.math.roundToInt

// Define required data classes.
data class Solution(val chromosome: IntArray, val fitness: Int)
data class Item(val value: Int, val weight: Int)

// Define the basket of items.
<span aria-label="annotation1" class="codeannotated_codeannotation">❶</span> private val items: List&lt;Item&gt; = listOf(
    Item(75, 15),
    Item(55, 32),
    Item(50, 30),
    Item(68, 43),
    Item(62, 54),
<span aria-label="325" epub:type="pagebreak" id="pg_325" role="doc-pagebreak"/>    Item(45, 38),
    Item(68, 62),
    Item(84, 85),
    Item(87, 87),
    Item(95, 83),
    Item(35, 21),
    Item(63, 53)
)
val chromosomeLength = items.size
<span aria-label="annotation2" class="codeannotated_codeannotation">❷</span> val maxWeight = 175

// global parameters and declarations
val POP_SIZE = 25
val MAX_GEN = 30
val ELITISM = 0.1
val eliteSize = (POP_SIZE * ELITISM).toInt()

// Limit the mutation threshold value to three decimal places.
<span aria-label="annotation3" class="codeannotated_codeannotation">❸</span> val MUTATION_THRESHOLD =
       ((1.0/chromosomeLength)*1000.0).roundToInt() / 1000.0

val population: MutableList&lt;Solution&gt; = mutableListOf()
val nextgen: MutableList&lt;Solution&gt; = mutableListOf()
val bestSolutions: MutableList&lt;Solution&gt; = mutableListOf()</code></pre>
<p class="tx">The code segment begins with a single import statement for the <span class="sans_thesansmonocd_w5regular_">roundToInt()</span> method that we’ll use shortly. We then define two simple data classes, <span class="sans_thesansmonocd_w5regular_">Solution</span> and <span class="sans_thesansmonocd_w5regular_">Item</span>, which are used to create individual members of the population and objects with their key attributes (value and weight). Notice that we’re creating the chromosome as an integer array and not as a string, as in <span><a href="chapter8.xhtml#pre-33" class="calibre2">Project 33</a></span>.</p>
<blockquote class="calibre17">
<p class="note"><span class="sans_dogma_ot_bold_b_15-n">NOTE</span></p>
</blockquote>
<p class="note-txt"><i class="calibre9">Depending on your IDE, you might encounter a “weak warning” while declaring the first data class of this project (</i><span class="sans_thesansmonocd_w5regular_italic_">Solution</span><i class="calibre9">). This is because we’re using a property with an</i> <span class="sans_thesansmonocd_w5regular_italic_">Array</span> <i class="calibre9">type (</i><span class="sans_thesansmonocd_w5regular_italic_">chromosome</span><i class="calibre9">) in a data class (</i><span class="sans_thesansmonocd_w5regular_italic_">Solution</span><i class="calibre9">). While this warning indicates potential issues for certain use cases, it does not apply to the problems discussed in this chapter and the next. If you find the warning bothersome, an alternative approach would be to use regular classes instead of data classes. In that case, you can manually add necessary custom methods that a data class generates automatically, such as</i> <span class="sans_thesansmonocd_w5regular_italic_">copy()</span> <i class="calibre9">and</i> <span class="sans_thesansmonocd_w5regular_italic_">toString()</span><i class="calibre9">. I encourage you to experiment with this approach as a further learning opportunity.</i></p>
<p class="tx">Next, we create a <span class="sans_thesansmonocd_w5regular_">List</span> of type <span class="sans_thesansmonocd_w5regular_">Item</span> with the 12 objects <span aria-label="annotation1" class="codeannotation">❶</span>. The capacity limit for the boat (<span class="sans_thesansmonocd_w5regular_">maxWeight</span>) is set to 175 units <span aria-label="annotation2" class="codeannotation">❷</span> (we’ll assume this is in addition to Jonah’s own weight).</p>
<p class="tx">Given the relatively small number of objects to choose from, we’ve set the population size (<span class="sans_thesansmonocd_w5regular_">POP_SIZE</span>) to 25 and the number of generations (<span class="sans_thesansmonocd_w5regular_">MAX_GEN</span>) to a modest 30. Elitism has been set to 0.1, or 10 percent. The <span class="sans_thesansmonocd_w5regular_">MUTATION_THRESHOLD</span> value is set a bit differently (its value is rounded off to three significant digits after the decimal point) <span aria-label="annotation3" class="codeannotation">❸</span>, but it still complies with the rule of thumb.</p>
<p class="tx"><span aria-label="326" epub:type="pagebreak" id="pg_326" role="doc-pagebreak"/>Note that the mutation threshold can be rounded to a few decimal places without affecting the results. This can speed up the calculations for more complex problems that need larger populations and longer runs to converge.</p>
<p class="tx">The last three lines of code create three mutable lists to store members of the current and next generations and the set of best solutions picked from successive generations.</p>
</section>
<section aria-labelledby="sec24" epub:type="division">
<h5 class="h2"><span id="sec24"/><span id="h3-66"/><span class="sans_futura_std_bold_b_">Initializing Population and Fitness Evaluation</span></h5>
<p class="tni">This section differs in just a few ways to what we developed for <span><a href="chapter8.xhtml#pre-33" class="calibre2">Project 33</a></span>.</p>
<pre class="calibre10"><code class="calibre11">fun initPopulation() {
    // Initialize a population of valid solutions (of nonzero fitness).
    // Each solution is represented by a chromosome.

    for (person in 0 until POP_SIZE) {
      <span aria-label="annotation1" class="code_codeannotation">❶</span> val chromosome = IntArray(chromosomeLength)

        var not_done = true
      <span aria-label="annotation2" class="code_codeannotation">❷</span> while (not_done) {
            for (gene in 0 until chromosomeLength) {
                chromosome[gene] = (0..1).random()
            }
            val fitness = getFitness(chromosome)
          <span aria-label="annotation3" class="code_codeannotation">❸</span> if (fitness &gt; 0) {
                population += Solution(chromosome, fitness)
                not_done = false
            }
        }
    }
    // Sort population (in place) in descending order.
    population.sortByDescending {it.fitness}

    println("\nBest solution from initial population:")
    print(population[0].chromosome.contentToString())
    println(" " + (-population[0].fitness).toString())
    println("\n... initPopulation done ...\n")
}

fun getFitness(chromosome: IntArray): Int {
    // Get sum of values and weights.
  <span aria-label="annotation4" class="code_codeannotation">❹</span> val sumValue  = (chromosome.zip(items) {c, item -&gt; c * item.value}).sum()
  <span aria-label="annotation5" class="code_codeannotation">❺</span> val sumWeight = (chromosome.zip(items) {c, item -&gt; c * item.weight}).sum()

    return if (sumWeight &lt;= maxWeight) sumValue else 0
}</code></pre>
<p class="tx">Within the <span class="sans_thesansmonocd_w5regular_">initPopulation()</span> function, we first create each chromosome as an integer array <span aria-label="annotation1" class="codeannotation">❶</span>. This is because we’re allowing only binary gene values (0 or 1) in individual chromosomes. Initially, all the genes will be set to 0 while the chromosome is initialized. We then randomly change these <span aria-label="327" epub:type="pagebreak" id="pg_327" role="doc-pagebreak"/>values to 1 and 0 inside a <span class="sans_thesansmonocd_w5regular_">while</span> loop <span aria-label="annotation2" class="codeannotation">❷</span>. Further, we add only solutions that have nonzero or positive fitness values to the initial population <span aria-label="annotation3" class="codeannotation">❸</span>. This will help us get started with a better set of chromosomes and avoid a situation where all initial solutions have zero fitness values, which is difficult to improve on!</p>
<p class="tx">The remaining part of the function is the same as before—we’re sorting the initial population to get it ready for elitism inside the <span class="sans_thesansmonocd_w5regular_">runGA()</span> function and printing out the current best solution from the initial population.</p>
<p class="tx">The helper function <span class="sans_thesansmonocd_w5regular_">getFitness()</span> receives a chromosome as its parameter and evaluates its fitness. It calculates the fitness as the weighted sum of values (<span class="sans_thesansmonocd_w5regular_">sumValue</span>), where weights are the genes from the chromosome <span aria-label="annotation4" class="codeannotation">❹</span>. It also calculates the weighted sum of weights as <span class="sans_thesansmonocd_w5regular_">sumWeight</span> <span aria-label="annotation5" class="codeannotation">❺</span>. If the sum of weights ≤ <span class="sans_thesansmonocd_w5regular_italic_">W</span><span class="sans_thesansmonocd_w5regular_italic_sub_">max</span>, the function returns the chromosome’s fitness; otherwise, 0 is returned.</p>
<p class="tx">As mentioned earlier, we must ensure that both <span class="sans_thesansmonocd_w5regular_">sumWeight</span> ≤ <span class="sans_thesansmonocd_w5regular_italic_">W</span><span class="sans_thesansmonocd_w5regular_italic_sub_">max</span> and <span class="sans_thesansmonocd_w5regular_">sumValue</span> &gt; 0. We enforce the former condition in this function. The latter is enforced inside the <span class="sans_thesansmonocd_w5regular_">while</span> loop of the <span class="sans_thesansmonocd_w5regular_">initPopulation()</span> function. A chromosome is used only if its fitness, as returned by the <span class="sans_thesansmonocd_w5regular_">getFitness()</span> function, is greater than zero <span aria-label="annotation3" class="codeannotation">❸</span>.</p>
</section>
<section aria-labelledby="sec25" epub:type="division">
<h5 class="h2"><span id="sec25"/><span id="h3-67"/><span class="sans_futura_std_bold_b_">The Driver Function</span></h5>
<p class="tni">We likewise need to make only minor changes to this part of the code, which was developed for <span><a href="chapter8.xhtml#pre-33" class="calibre2">Project 33</a></span>. First, we’ll delete the termination condition at the beginning. For knapsack problems, the optimal solution is generally unknown beforehand. We have to run the code several times to get a sense of what the best solution might be. Second, we’ll now save the best solutions from all generations in a list and pick the best overall solution from that list as the potential optimal solution.</p>
<p class="tx">Here is the revised code for the <span class="sans_thesansmonocd_w5regular_">runGA()</span> function:</p>
<pre class="calibre10"><code class="calibre11">fun runGA() {
    // Run the algorithm for a specified number of generations.
    for (generation in 1 .. MAX_GEN) {

        // Step 1: Implement elitism.
        selectElites()

        // Step 2: Implement crossover and mutation.
        for (i in eliteSize until POP_SIZE) {
            // Select parents for crossover.
            val parent1 = tournament()
            val parent2 = tournament()

            // Produce a child by using crossover and mutation.
            val child = crossover(parent1, parent2)
            // Add child to nextgen.
            nextgen += child
        }
<span aria-label="328" epub:type="pagebreak" id="pg_328" role="doc-pagebreak"/>        // Step 3: Transfer nextgen to the current population.
        for (i in nextgen.indices)
            population[i] = nextgen[i].copy()

        // Step 4: Clear nextgen for the next iteration.
        nextgen.clear()

        // Step 5: Sort the population in descending order (in place).
        population.sortByDescending {it.fitness}

        // Step 6: Add the fittest solution to bestSolutions.
      <span aria-label="annotation1" class="code_codeannotation">❶</span> bestSolutions += population[0]

        // Step 7 (optional): Print the fittest solution.
      <span aria-label="annotation2" class="code_codeannotation">❷</span> printSolution(generation, population[0])
    }
}</code></pre>
<p class="tx">Apart from deleting the termination condition based on the fitness value, both of the revisions to the code are at the end of the code segment. First, the fittest solution from each generation is now added to the mutable <span class="sans_thesansmonocd_w5regular_">bestSolutions</span> list <span aria-label="annotation1" class="codeannotation">❶</span>. Second, we’ve added a new print function called <span class="sans_thesansmonocd_w5regular_">printSolution()</span> <span aria-label="annotation2" class="codeannotation">❷</span> to tidy up the printing without adding clutter to <span class="sans_thesansmonocd_w5regular_">runGA()</span>. This function simply formats and prints the generation number along with the chromosome and fitness of the fittest solution for each generation.</p>
<pre class="calibre10"><code class="calibre11">fun printSolution(generation: Int, solution: Solution) {
    val str1 = "%04d".format(generation).padEnd(10, ' ')
    val (c, f) = solution
    val str2 = c.contentToString()
    val str3 = f.toString().padStart(6, ' ')
    println(str1 + str2 + str3)
}</code></pre>
<p class="tx">This function prints a line composed of three substrings. The first substring represents the generation or iteration number. We assign 10 character spaces for this, of which 4 are allocated for displaying the number; the remaining spaces will be added after the number as padding (white spaces). The second substring simply contains the sequence of 12 genes converted into a string. The third substring contains the fitness value. We assign six spaces for the number, of which up to three will be used to display the fitness value; the remaining spaces will be added as padding in front of the characters displaying the fitness value.</p>
</section>
<section aria-labelledby="sec26" epub:type="division">
<h5 class="h2"><span id="sec26"/><span id="h3-68"/><span class="sans_futura_std_bold_b_">The Operator Functions</span></h5>
<p class="tni">We’ll skip discussing the <span class="sans_thesansmonocd_w5regular_">selectElites()</span> and <span class="sans_thesansmonocd_w5regular_">tournament()</span> functions as no changes are required to use them in this example (you can copy them from <span><a href="chapter8.xhtml#pre-33" class="calibre2">Project 33</a></span>). However, we have a different chromosome structure for the <span aria-label="329" epub:type="pagebreak" id="pg_329" role="doc-pagebreak"/>knapsack problem and additional constraints to satisfy. This means we’ll have to make changes to the <span class="sans_thesansmonocd_w5regular_">crossover()</span> and <span class="sans_thesansmonocd_w5regular_">mutation()</span> functions.</p>
<pre class="calibre10"><code class="calibre11">fun crossover(parent1: Solution, parent2: Solution): Solution {
    // random single-point split and crossover
  <span aria-label="annotation1" class="code_codeannotation">❶</span> val split = (1 until chromosomeLength).random()

    // Use copyOfRange() to extract elements from an array.
    // .copyOfRange(a,b): a = start index, b = not inclusive
    val arr1 = parent1.chromosome.copyOfRange(0, split)
    val arr2 = parent2.chromosome.copyOfRange(split, chromosomeLength)

  <span aria-label="annotation2" class="code_codeannotation">❷</span> val newChromosome = arr1 + arr2

    // Apply in-place mutation to the new chromosome.
  <span aria-label="annotation3" class="code_codeannotation">❸</span> mutation(newChromosome)

  <span aria-label="annotation4" class="code_codeannotation">❹</span> return Solution(newChromosome, getFitness(newChromosome))
}

fun mutation(newChromosome: IntArray) {
    // Carry out in-place mutation.
    for (i in 0 until chromosomeLength) {
        if ((0..1000).random()/1000.0 &lt;= MUTATION_THRESHOLD) {
            // Simplest way to flip values between 0 and 1 is i = 1 - i.
          <span aria-label="annotation5" class="code_codeannotation">❺</span> newChromosome[i] = (1 - newChromosome[i])
        }
    }
    // nothing to return
}</code></pre>
<p class="tx">As before, the <span class="sans_thesansmonocd_w5regular_">crossover()</span> function starts with randomly locating a point to split the chromosomes <span aria-label="annotation1" class="codeannotation">❶</span>. We use the <span class="sans_thesansmonocd_w5regular_">copyRangeOf()</span> method to copy different ranges of genes from parent 1 and parent 2 because the chromosomes are of type <span class="sans_thesansmonocd_w5regular_">IntArray</span> instead of <span class="sans_thesansmonocd_w5regular_">String</span>. The new chromosome is created by combining the first part of parent 1 with the second part of parent 2 (creating one child per crossover) <span aria-label="annotation2" class="codeannotation">❷</span>.</p>
<p class="tx">Next, we call the <span class="sans_thesansmonocd_w5regular_">mutation()</span> function to mutate this newly created chromosome in place <span aria-label="annotation3" class="codeannotation">❸</span>. Since arrays are passed by reference (memory location) rather than by value, all the genetic alterations will be applied directly to the selected elements of <span class="sans_thesansmonocd_w5regular_">newChromosome</span>, and we don’t need to return a separate mutated chromosome to the calling function.</p>
<p class="tx">Once this step is complete, a new child (<span class="sans_thesansmonocd_w5regular_">Solution</span>) is created and returned by using the newly created chromosome and its fitness <span aria-label="annotation4" class="codeannotation">❹</span>.</p>
<p class="tx">Finally, the <span class="sans_thesansmonocd_w5regular_">mutation()</span> function scans every gene in the chromosome and applies mutation to a gene by comparing a random number between 0 and 1 with the <span class="sans_thesansmonocd_w5regular_">MUTATION_THRESHOLD</span>. When the condition is met, it flips the value of the gene from 0 to 1 or vice versa <span aria-label="annotation5" class="codeannotation">❺</span>.</p>
</section>
<section aria-labelledby="sec27" epub:type="division">
<span aria-label="330" epub:type="pagebreak" id="pg_330" role="doc-pagebreak"/>
<h5 class="h2"><span id="sec27"/><span id="h3-69"/><span class="sans_futura_std_bold_b_">The main() Function</span></h5>
<p class="tni">The <span class="sans_thesansmonocd_w5regular_">main()</span> function for this project is similar to that of <span><a href="chapter8.xhtml#pre-33" class="calibre2">Project 33</a></span>, with one additional call to <span class="sans_thesansmonocd_w5regular_">printBestSolution()</span> to print the best overall solution. Here is the code snippet including the print function:</p>
<pre class="calibre10"><code class="calibre11">fun main() {
    println("\n*** Solving the 0-1 knapsack problem " +
            "using the genetic algorithm ***\n")
    println("Population size: $POP_SIZE, Generations: $MAX_GEN")
    println("Number of items to pick from: $chromosomeLength")
    println("Mutation threshold: $MUTATION_THRESHOLD")

    // Initialize the population.
    initPopulation()
    // Run the genetic algorithm.
    runGA()
    // Print the best overall solution.
    printBestSolution()
}

fun printBestSolution() {
  <span aria-label="annotation1" class="code_codeannotation">❶</span> bestSolutions.sortByDescending {it.fitness}
    println("\nBest solution found after $MAX_GEN generations:")

  <span aria-label="annotation2" class="code_codeannotation">❷</span> val (chromosome, fitness) = bestSolutions[0]
  <span aria-label="annotation3" class="code_codeannotation">❸</span> val sumWeight = (chromosome.zip(items)
                       {c, item -&gt; c * item.weight}).sum()
    println(bestSolutions[0].toString())
    println("Sum of weights: $sumWeight   Sum of values: $fitness")
}</code></pre>
<p class="tx">The <span class="sans_thesansmonocd_w5regular_">main()</span> function is very short. It starts with printing key global parameters, then calls <span class="sans_thesansmonocd_w5regular_">initPopulation()</span> to create the initial population of solutions and the driver function <span class="sans_thesansmonocd_w5regular_">runGA()</span> to run the genetic algorithm that we’ve customized for the knapsack problem. Finally, it prints the best overall solution by calling the <span class="sans_thesansmonocd_w5regular_">printBestSolution()</span> function.</p>
<p class="tx">Next, the <span class="sans_thesansmonocd_w5regular_">bestSolutions</span> list is sorted in descending order so that the first item represents the best overall solution <span aria-label="annotation1" class="codeannotation">❶</span>. The properties of this item are then deconstructed as chromosome and fitness <span aria-label="annotation2" class="codeannotation">❷</span>. Finally, the sum of weights of the objects in this optimal (or near-optimal) solution is calculated as a weighted sum, the weights being the individual gene values (0, 1) <span aria-label="annotation3" class="codeannotation">❸</span>. The last line prints the sum of weights and fitness for the best overall solution.</p>
</section>
</section>
<section aria-labelledby="sec28" epub:type="division">
<h4 class="h1"><span id="sec28"/><span id="h2-140"/><span class="sans_futura_std_bold_condensed_oblique_">The Result</span></h4>
<p class="tni">The following sample output from a run of the code provides an indication of what to expect when you run the code:</p>
<pre class="calibre10"><code class="calibre11"><span aria-label="331" epub:type="pagebreak" id="pg_331" role="doc-pagebreak"/>*** Solving the 0-1 knapsack problem using the genetic algorithm ***

Population size: 25, Generations: 30
Number of items to pick from: 12
Mutation threshold: 0.083

Best solution from initial population:
Solution(chromosome=[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1], fitness=285)

... initPopulation done

0001      [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1]   285
0002      [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1]   285
0003      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0004      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0005      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0006      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0007      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0008      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0009      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0010      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0011      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0012      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0013      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0014      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0015      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0016      [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]   296
0017      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0018      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0019      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0020      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0021      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0022      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0023      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0024      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0025      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0026      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0027      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0028      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0029      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311
0030      [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]   311

Best solution found after 30 generations:
Solution(chromosome=[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1], fitness=311)
Sum of weights: 173   Sum of values: 311</code></pre>
<p class="tx">The optimal solution for Jonah is to choose objects 1, 2, 3, 4, and 12, which will give Jonah a combined value of 311 units. The total weight of the optimal choice is 173 units, just shy of the maximum allowable weight of 175 units.</p>
<p class="tx"><span aria-label="332" epub:type="pagebreak" id="pg_332" role="doc-pagebreak"/>How do we know that no better solutions exist? In this case, you can verify the solution by using a brute-force approach—generating all possible combinations and checking corresponding sums of values and weights. I encourage you to search online for relevant tools or code examples you can use to confirm that 311 is indeed the best value Jonah can get under the circumstances.</p>
<p class="tx">Again, remember that the genetic algorithm is a stochastic algorithm, meaning no two runs will produce identical results. Moreover, nothing guarantees that for a given set of parameter values, the algorithm will consistently converge to the optimal solution every time you run the program. You may have to run the program multiple times or adjust the program parameters to eventually locate the optimal solution.</p>
<p class="tx">On the other hand, genetic algorithms can help solve real-world combinatorial problems with hundreds of decision variables, where checking all possible combinations for the global optimal solution is impractical or impossible. They take far less time and require significantly less computational effort to generate near-optimal solutions.</p>
<aside aria-label="box-41" class="box2">
<p class="boxtitle" id="box-41"><span class="sans_futura_std_bold_b_">EXERCISE</span></p>
<p class="boxfirst"><span class="sans_futura_std_book_">In the previous two projects, we’ve used the tournament selection method for choosing parents for reproduction. We also discussed a couple of other selection methods: roulette wheel and rank-based selection.</span></p>
<p class="box1"><span class="sans_futura_std_book_">For this exercise, develop a new function called</span> <span class="sans_thesansmonocd_w5regular_">rouletteWheel()</span> <span class="sans_futura_std_book_">based on the roulette wheel selection algorithm, and incorporate that in the</span> <span class="sans_thesansmonocd_w5regular_">runGA()</span> <span class="sans_futura_std_book_">function to solve the Jonah’s ark problem. Use the same problem-specific parameters used in <a href="chapter8.xhtml#pre-34" class="calibre2">Project 34</a>.</span></p>
<p class="boxlast"><span class="sans_futura_std_book_">Based on the results, reflect on whether using roulette wheel selection results in a quicker convergence to the global optimum. In this context, quicker means finding the global optimum with fewer iterations.</span></p>
</aside>
<p class="headaexercise" id="pre-35"><span class="sans_dogma_ot_bold_b_15-n">Project 35: Optimize a Multivariate Function with the Genetic Algorithm</span></p>
<p class="tni">In this final project, we’ll learn how to apply the genetic algorithm to multivariate function optimization. The only requirement for the function is that it be defined in terms of the independent variables within the decision space. In contrast to gradient-based algorithms, this function does not have to be smooth or differentiable.</p>
<p class="tx">We’ll use a sufficiently challenging two-dimensional function known as the Eggholder function, defined by two independent variables: <i class="calibre9">x</i><sub class="calibre19">1</sub> and <i class="calibre9">x</i><sub class="calibre19">2</sub>.</p>
<figure class="img4"><span class="epub"><math alttext="Equation" display="inline"><mrow><mi>f</mi><mo stretchy="false">(</mo><mtext>x</mtext><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mn>47</mn><mo stretchy="false">)</mo><mi>sin</mi><mfenced><mrow><msqrt><mrow><mfenced close="|" open="|"><mrow><mfrac><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><mn>2</mn></mfrac><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mn>47</mn></mrow></mfenced></mrow></msqrt></mrow></mfenced><mo>−</mo><msub><mi>x</mi><mn>1</mn></msub><mi>sin</mi><msqrt><mrow><mfenced close="|" open="|"><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mn>47</mn><mo stretchy="false">)</mo></mrow></mfenced></mrow></msqrt></mrow></math> (8.2)</span>
<span class="mobi"><img alt="" class="img1" height="84" src="../images/eq8-2.jpg" width="1381"/></span></figure>
<p class="tx"><span aria-label="333" epub:type="pagebreak" id="pg_333" role="doc-pagebreak"/>We’ll find the minimum value of this function in the decision space defined as follows:</p>
<figure class="img4"><span class="epub"><math alttext="Equation" display="inline"><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><mo stretchy="false">[</mo><mo>−</mo><mn>512</mn><mo>,</mo><mn>512</mn><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext>for</mtext><mtext> </mtext><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mtext> </mtext><mn>2</mn></mrow></math></span>
<span class="mobi"><img alt="" class="img1" height="43" src="../images/pg333.jpg" width="1389"/></span></figure>
<p class="tx">As shown earlier in <a href="chapter8.xhtml#fig8-3" class="calibre2">Figure 8-3</a>, the Eggholder function has a very complex shape with numerous peaks and troughs. Because of this, deterministic gradient-based algorithms will have a hard time finding the global minimum. Deterministic search attempts will usually get stuck at local optima unless we use a hybrid approach that incorporates some random search features. In contrast, given enough diversity (population size) and time (number of generations), a genetic algorithm can locate the global minimum fairly quickly for this problem.</p>
</section>
<section aria-labelledby="sec29" epub:type="division">
<h4 class="h1"><span id="sec29"/><span id="h2-141"/><span class="sans_futura_std_bold_condensed_oblique_">The Strategy</span></h4>
<p class="tni">To implement function optimization in a genetic algorithm, the decision variables are treated as individual genes, meaning the two-variable Eggholder function will have two genes. This time, however, these genes will be represented as real numbers, including fractions, instead of characters (as in <span><a href="chapter8.xhtml#pre-33" class="calibre2">Project 33</a></span>) or binary values (as in <span><a href="chapter8.xhtml#pre-34" class="calibre2">Project 34</a></span>).</p>
<p class="tx">We also need to address the fact that this is a minimization problem, not a maximization problem as in the previous two projects. In those cases, the goal was to find a solution with the greatest fitness, whereas now we want to find the solution with the smallest fitness. Fortunately, we can easily handle this case by multiplying the objective function by –1. This adjustment allows us to continue using the existing code developed for maximization problems. Notably, if we were to switch back to a maximization problem, we could use the same code without needing to multiply the objective function by –1.</p>
<p class="tx">Finally, we need a new way to implement mutation for function optimization. In previous projects, we introduced mutation by randomly replacing a character or a binary value, but that approach does not make sense for a real number. Digits in a real number cannot be arbitrarily replaced, as their relative position within the number has additional significance. Therefore, for real-valued genes, mutation is introduced as a small noise that is randomly added to or subtracted from the genes (we still use a probability threshold). The magnitude of the noise is calculated as a small fraction of the range for a specific gene (decision variable). By doing so, we can properly scale the magnitude of the noise or mutation without having to worry about the underlying units used for the corresponding decision variable in the function.</p>
</section>
<section aria-labelledby="sec30" epub:type="division">
<h4 class="h1"><span id="sec30"/><span id="h2-142"/><span class="sans_futura_std_bold_condensed_oblique_">The Code</span></h4>
<p class="tni">The code for function optimization has the same general structure as Projects 33 and 34. It is worth reiterating that for minimization of the objective function, we’ll have to multiply it by –1, whereas for maximization no alteration to the objective function is needed.</p>
<section aria-labelledby="sec31" epub:type="division">
<span aria-label="334" epub:type="pagebreak" id="pg_334" role="doc-pagebreak"/>
<h5 class="h2"><span id="sec31"/><span id="h3-70"/><span class="sans_futura_std_bold_b_">Problem Definition and Global Parameters</span></h5>
<p class="tni">This code segment includes the import block, a data class, global parameters, and several collections of mutable lists:</p>
<pre class="calibre10"><code class="calibre11">// import block
import kotlin.math.sin
import kotlin.math.sqrt
import kotlin.math.abs
import kotlin.math.pow
import kotlin.math.min
import kotlin.math.max
import kotlin.random.Random

// Define required data classes.
data class Solution(
  <span aria-label="annotation1" class="code_codeannotation">❶</span> val chromosome: DoubleArray,
    val fitness: Double)

// global parameters and declarations
<span aria-label="annotation2" class="codeannotated_codeannotation">❷</span> val getFitness = :: eggHolder

<span aria-label="annotation3" class="codeannotated_codeannotation">❸</span> val chromosomeLength = 2    // number of independent variables
val bounds = arrayOf(doubleArrayOf(-512.0, 512.0),
                     doubleArrayOf(-512.0, 512.0))
val varRange = doubleArrayOf(bounds[0][1] - bounds[0][0],
                             bounds[1][1] - bounds[1][0])
val POP_SIZE = 100
val MAX_GEN = 200
<span aria-label="annotation4" class="codeannotated_codeannotation">❹</span> val MUTATION_THRESHOLD = 0.5    // On average, 1 of 2 genes will mutate.
val MUTATION_FACTOR = 0.02
val ELITISM = 0.1
val eliteSize = (POP_SIZE * ELITISM).toInt()

val population: MutableList&lt;Solution&gt; = mutableListOf()
val nextgen: MutableList&lt;Solution&gt; = mutableListOf()
val bestSolutions: MutableList&lt;Solution&gt; = mutableListOf()</code></pre>
<p class="tx">The code segment begins by importing the necessary math functions to calculate the function value or fitness. Remember to import only the methods you need, instead of importing all of them using an <span class="sans_thesansmonocd_w5regular_">import kotlin.math.*</span> statement. We then declare the chromosome to be of type <span class="sans_thesansmonocd_w5regular_">DoubleArray</span> <span aria-label="annotation1" class="codeannotation">❶</span> to deal with real-coded genes.</p>
<p class="tx">We also define <span class="sans_thesansmonocd_w5regular_">getFitness</span> as a variable and assign it a reference to the Eggholder function <span aria-label="annotation2" class="codeannotation">❷</span>. This approach allows us to define other functions later. And to use those, we simply need to reassign <span class="sans_thesansmonocd_w5regular_">getFitness</span> to the desired function.</p>
<p class="tx">Because the Eggholder function is a function of two independent variables (<i class="calibre9">x</i><sub class="calibre19">1</sub> and <i class="calibre9">x</i><sub class="calibre19">2</sub>), we will need two real-coded genes per chromosome <span aria-label="annotation3" class="codeannotation">❸</span>.</p>
<p class="tx">The next two lines set the bounds for the decision variables and calculate the range for each. For real-coded genes, the magnitude of mutation is <span aria-label="335" epub:type="pagebreak" id="pg_335" role="doc-pagebreak"/>typically set to a small value relative to the range of the decision variables. This approach has the benefit of being scale independent.</p>
<p class="tx">The remaining part of the code segment is similar to that of previous projects. This time, the population is composed of 100 individuals (<span class="sans_thesansmonocd_w5regular_">POP_SIZE</span>), and it will evolve for 200 generations (<span class="sans_thesansmonocd_w5regular_">MAX_GEN</span>). The <span class="sans_thesansmonocd_w5regular_">MUTATION_THRESHOLD</span> is now set to 0.5 <span aria-label="annotation4" class="codeannotation">❹</span>, in line with the practice of setting the mutation probability equal to the inverse of the number of genes.</p>
<p class="tx">Of course, we could’ve tried many other combinations of parameter values. The values used in this code segment were chosen based on a number of trials to ensure that the global minima for the Eggholder function can be found quickly.</p>
</section>
<section aria-labelledby="sec32" epub:type="division">
<h5 class="h2"><span id="sec32"/><span id="h3-71"/><span class="sans_futura_std_bold_b_">Initializing Population and Fitness Evaluation</span></h5>
<p class="tni">The general organization of this code snippet is very similar to that of the two previous projects, with a few problem-specific adjustments:</p>
<pre class="calibre10"><code class="calibre11">fun initPopulation() {
    // Initialize a population of valid solutions (genes within bounds).
    // Each solution is represented by a chromosome.

    for (person in 0 until POP_SIZE) {
      <span aria-label="annotation1" class="code_codeannotation">❶</span> val x = DoubleArray(chromosomeLength)
        for (i in 0 until chromosomeLength) {
            // The first argument is inclusive, but the second one is not.
            // It's possible to add a small bias term to the upper bounds.
          <span aria-label="annotation2" class="code_codeannotation">❷</span> x[i] = Random.nextDouble(bounds[i][0], bounds[i][1])
        }
        population += Solution(x, getFitness(x))
    }

    // Sort the population (in place) in descending order.
    population.sortByDescending {it.fitness}

    println("\nBest solution from initial population:")
  <span aria-label="annotation3" class="code_codeannotation">❸</span> println(population[0].toString())
    println("\n... initPopulation done ...\n")
}
fun eggHolder(x: DoubleArray): Double {
    val c1 = (x[1] + 47)
    val c2 = sin(sqrt(abs(0.5 * x[0] + c1)))
    val c3 = x[0] * sin(sqrt(abs(x[0] - c1)))

    // Multiply by -1 ONLY for minimization problems.
  <span aria-label="annotation4" class="code_codeannotation">❹</span> return -1.0 * (-c1 * c2 - c3)
}</code></pre>
<p class="tx">We generate the chromosome as a <span class="sans_thesansmonocd_w5regular_">DoubleArray</span> with two elements (<i class="calibre9">x</i>[0] will be gene 1, and <i class="calibre9">x</i>[1] will be gene 2) <span aria-label="annotation1" class="codeannotation">❶</span>. We then initialize the genes randomly, ensuring they stay within their respective bounds (defined by the decision space) <span aria-label="annotation2" class="codeannotation">❷</span>. The rest of the code segment assigns the solutions to the <span aria-label="336" epub:type="pagebreak" id="pg_336" role="doc-pagebreak"/>mutable list <span class="sans_thesansmonocd_w5regular_">population</span>, sorts the population in descending order, and prints the best solution from the initial population <span aria-label="annotation3" class="codeannotation">❸</span>.</p>
<p class="tx">As mentioned earlier, this code doesn’t include a <span class="sans_thesansmonocd_w5regular_">getFitness</span> function; instead, we had pointed <span class="sans_thesansmonocd_w5regular_">getFitness</span> to the <span class="sans_thesansmonocd_w5regular_">eggHolder()</span> function, which returns the value of the objective function (fitness). For convenience, we’ve broken down the objective function given by Equation 8.2 into three parts, which are later combined to calculate the fitness value <span aria-label="annotation4" class="codeannotation">❹</span>. Notice that we’re multiplying the fitness by –1 before returning the value to <span class="sans_thesansmonocd_w5regular_">getFitness</span>. Doing so enables us to use the code developed for maximization problems to solve a minimization problem.</p>
<p class="tx">We’ll skip reviewing the <span class="sans_thesansmonocd_w5regular_">runGA()</span> function as it is identical to the one used for <span><a href="chapter8.xhtml#pre-34" class="calibre2">Project 34</a></span>. The same goes for the <span class="sans_thesansmonocd_w5regular_">selectElites()</span> and <span class="sans_thesansmonocd_w5regular_">tournament()</span> functions. Therefore, we’ll move straight to the <span class="sans_thesansmonocd_w5regular_">crossover()</span> and <span class="sans_thesansmonocd_w5regular_">mutation()</span> functions.</p>
</section>
<section aria-labelledby="sec33" epub:type="division">
<h5 class="h2"><span id="sec33"/><span id="h3-72"/><span class="sans_futura_std_bold_b_">Operator Functions for Crossover and Mutation</span></h5>
<p class="tni">We’ll now move on to the two key operator functions performing crossover and mutation to examine the differences introduced for the real-coded genes.</p>
<pre class="calibre10"><code class="calibre11">fun crossover(parent1: Solution, parent2: Solution): Solution {
    // Select a random weight within (0-1).
    // This could be generated separately for x- and y-components.
  <span aria-label="annotation1" class="code_codeannotation">❶</span> val s = (0..1000).random()/1000.0

    // Generate randomly weighted genes.
    var x1 = parent1.chromosome[0]*s + parent2.chromosome[0]*(1-s)
    var x2 = parent1.chromosome[1]*s + parent2.chromosome[1]*(1-s)

    // Check that new genes stay within bounds (decision space).
    x1 = min(max(x1, bounds[0][0]), bounds[0][1])
    x2 = min(max(x2, bounds[1][0]), bounds[1][1])

    // Compose the new chromosome.
  <span aria-label="annotation2" class="code_codeannotation">❷</span> val xNew = doubleArrayOf(x1, x2)
    // Mutate the new chromosome.
  <span aria-label="annotation3" class="code_codeannotation">❸</span> mutation(xNew)

  <span aria-label="annotation4" class="code_codeannotation">❹</span> return Solution(xNew, getFitness(xNew))
}

fun mutation(xNew: DoubleArray) {
    for (i in 0 until chromosomeLength) {
        if (((0..1000).random() / 1000.0) &lt;= MUTATION_THRESHOLD) {
            // Get the random sign factor.
          <span aria-label="annotation5" class="code_codeannotation">❺</span> val sign = if ((0..100).random()/100.0 &lt;= 0.5) -1 else 1
          <span aria-label="annotation6" class="code_codeannotation">❻</span> xNew[i] += sign * varRange[i] * MUTATION_FACTOR
            xNew[i] =  min(max(xNew[i], bounds[i][0]), bounds[i][1])
        }
    }
    // nothing to return
}</code></pre>
<p class="tx"><span aria-label="337" epub:type="pagebreak" id="pg_337" role="doc-pagebreak"/>The purpose of the crossover function for real-valued genes remains the same: to produce a new chromosome for the child by using genetic materials from the parents. Several methods are available for creating the new chromosome or genes. In this example, we’re using a random-weighted scheme based on a randomly selected value <i class="calibre9">s</i> between 0 and 1 <span aria-label="annotation1" class="codeannotation">❶</span>. (If we used a fixed weight, <span class="sans_thesansmonocd_w5regular_">s=0.5</span>, that would be equivalent to using the arithmetic average of the gene values from two parents to create a new gene.)</p>
<p class="tx">We use the weighted average scheme to generate two new genes (<span class="sans_thesansmonocd_w5regular_">x1</span> and <span class="sans_thesansmonocd_w5regular_">x2</span>) and ensure that these values are within the bounds of the decision variables. We then compose the new chromosome <span class="sans_thesansmonocd_w5regular_">xNew</span> as a <span class="sans_thesansmonocd_w5regular_">DoubleArray</span>, with two genes as its elements <span aria-label="annotation2" class="codeannotation">❷</span>.</p>
<p class="tx">Next, we call the <span class="sans_thesansmonocd_w5regular_">mutation()</span> function to mutate this newly created chromosome in place <span aria-label="annotation3" class="codeannotation">❸</span>. Since arrays are passed by reference (memory location), mutations can be directly applied to the elements (genes) of the array, and we don’t need to return anything to the calling function. Once mutation is applied, a new child (<span class="sans_thesansmonocd_w5regular_">Solution</span>) is created and returned using the newly created chromosome and its fitness <span aria-label="annotation4" class="codeannotation">❹</span>.</p>
<p class="tx">The <span class="sans_thesansmonocd_w5regular_">mutation()</span> function, similar to <span><a href="chapter8.xhtml#pre-34" class="calibre2">Project 34</a></span>, scans each gene and mutates it if a random number between 0 and 1 is less than <span class="sans_thesansmonocd_w5regular_">MUTATION_THRESHOLD</span>. It randomly picks the sign of the mutation (positive or negative) <span aria-label="annotation5" class="codeannotation">❺</span> and calculates the value as the sign times the decision variable’s range times <span class="sans_thesansmonocd_w5regular_">MUTATION_FACTOR</span> <span aria-label="annotation6" class="codeannotation">❻</span>. It also ensures that the mutated genes are within the bounds of the corresponding decision variables.</p>
<p class="tx">Before we proceed to the <span class="sans_thesansmonocd_w5regular_">main()</span> function, we need to adjust the <span class="sans_thesansmonocd_w5regular_">printSolution()</span> function from <span><a href="chapter8.xhtml#pre-34" class="calibre2">Project 34</a></span>. It now takes a solution with a chromosome of type <span class="sans_thesansmonocd_w5regular_">DoubleArray</span> instead of an <span class="sans_thesansmonocd_w5regular_">IntArray</span>. Use the following updated function in your code:</p>
<pre class="calibre10"><code class="calibre11">fun printSolution(generation: Int, solution: Solution) {
    val str1 = "%04d".format(generation).padEnd(10, ' ')
    val (c, f) = solution
    val str2 = "%5.7f".format(c[0]).padEnd(14, ' ')
    val str3 = "%5.7f".format(c[1]).padEnd(14, ' ')

    // Multiply f (fitness) by -1 for minimization (for display only).
    val str4 = "%5.4f".format(-f)

    println(str1 + str2 + str3 + str4)
}</code></pre>
<p class="tx">You can review this code and compare it with the program output as an exercise, since you are familiar with these helper functions.</p>
</section>
<section aria-labelledby="sec34" epub:type="division">
<h5 class="h2"><span id="sec34"/><span id="h3-73"/><span class="sans_futura_std_bold_b_">The main() Function</span></h5>
<p class="tni">The code snippet for the <span class="sans_thesansmonocd_w5regular_">main()</span> function, including the <span class="sans_thesansmonocd_w5regular_">printBestSolution()</span> function, is likewise similar to the <span class="sans_thesansmonocd_w5regular_">main()</span> functions in previous projects.</p>
<pre class="calibre10"><code class="calibre11"><span aria-label="338" epub:type="pagebreak" id="pg_338" role="doc-pagebreak"/>fun main() {
    println("\n*** Real-valued function optimization using " +
            "the genetic algorithm ***\n")
    println("Number of dimensions: $chromosomeLength")
    println("Population size: $POP_SIZE, Generations: $MAX_GEN")
    println("Elitism: $ELITISM")
    println("Mutation threshold: $MUTATION_THRESHOLD")
    println("Mutation factor: $MUTATION_FACTOR")

    // Initialize the population.
    initPopulation()
    // Run the genetic algorithm.
    runGA()
    // Print the best overall solution.
    printBestSolution()
}

fun printBestSolution() {
    // Sort the bestSolutions to get the best-so-far solution.
    bestSolutions.sortByDescending {it.fitness}
    println("\nBest solution found after $MAX_GEN generations:")

    // Deconstruct for printing with formatting.
    val (chromosome, fitness) = bestSolutions[0]

    // Format and print the best-so-far properties.
    for (i in chromosome.indices) {
        print("chromosome[$i]: ")
        println("%5.8f".format(chromosome[i]))
    }
    println("Fitness: " + "%5.5f".format(-fitness))
}</code></pre>
<p class="tx">The <span class="sans_thesansmonocd_w5regular_">main()</span> function starts by printing key global parameters. It then calls <span class="sans_thesansmonocd_w5regular_">initPopulation()</span> to initialize the population and launches the driver function <span class="sans_thesansmonocd_w5regular_">runGA()</span> to carry out function minimization using a genetic algorithm.</p>
<p class="tx">In the <span class="sans_thesansmonocd_w5regular_">printBestSolution()</span> function, we format and print the two real-valued genes on the same line by using a <span class="sans_thesansmonocd_w5regular_">for</span> loop. Finally, we print the negative fitness value to get the correct sign for the minimum fitness.</p>
</section>
</section>
<section aria-labelledby="sec35" epub:type="division">
<h4 class="h1"><span id="sec35"/><span id="h2-143"/><span class="sans_futura_std_bold_condensed_oblique_">The Result</span></h4>
<p class="tni">We’re now ready to run the code and examine the results. If you use the same global parameter values that I have used for this project, you are likely to get the global optimal solution within five to seven attempts. Let’s look at a sample output:</p>
<pre class="calibre10"><code class="calibre11">*** Real-valued function optimization using a genetic algorithm ***

Number of dimensions: 2
Population size: 100, Generations: 200
Elitism: 0.1
<span aria-label="339" epub:type="pagebreak" id="pg_339" role="doc-pagebreak"/>Mutation threshold: 0.5
Mutation factor: 0.02

Best solution from initial population:
[439.9192360610284, 466.3475628354653] -809.6304961876202

... initPopulation done ...

0001      439.91923606   466.34756284   -809.63050
0002      439.91923606   466.34756284   -809.63050
0003      439.91923606   466.34756284   -809.63050
0004      421.26042117   431.81770471   -838.23597
0005      421.26042117   431.81770471   -838.23597

<var class="calibre18">--snip--</var>

0190      512.00000000   404.23184036   -959.64066
0191      512.00000000   404.23184036   -959.64066
0192      512.00000000   404.23184036   -959.64066
0193      512.00000000   404.23184036   -959.64066
0194      512.00000000   404.23184036   -959.64066
0195      512.00000000   404.23184036   -959.64066
0196      512.00000000   404.23184036   -959.64066
0197      512.00000000   404.23184036   -959.64066
0198      512.00000000   404.23184036   -959.64066
0199      512.00000000   404.23184036   -959.64066
0200      512.00000000   404.23184036   -959.64066

Best solution found after 200 generations:
chromosome[0]: 512.00000000
chromosome[1]: 404.23184036
Fitness: -959.64066</code></pre>
<p class="tx">The first section of the results shows the global parameters used for solving this problem—population size (100) and number of generations (200). Elitism is set to 0.1, or 10 percent. We used a mutation threshold of 0.5 because we have two genes, but we could have used a lower threshold if this threshold caused the best solutions to oscillate rather than converge. Due to the presence of many near-optimal solutions within the decision space of this problem, a higher-than-usual mutation threshold may have helped the algorithm to get out of local minima and explore other regions.</p>
<p class="tx">The initial best fitness value was –809.63, which is not that close to the global minimum of –959.64 located after 117 iterations (not shown in the partial output above). Once this value was reached, the best solution remained unchanged until the program ended after completing the maximum number of iterations.</p>
<p class="tx">We can see from the last part of the results that the optimal solution is located at <i class="calibre9">x</i><sub class="calibre19">1</sub> = 512.0 and <i class="calibre9">x</i><sub class="calibre19">2</sub> = 404.23. <a href="chapter8.xhtml#fig8-9" class="calibre2">Figure 8-9</a> shows this point as a white half-circle near the top-right corner of the contour plot of the Eggholder function.</p>
<span aria-label="340" epub:type="pagebreak" id="pg_340" role="doc-pagebreak"/>
<figure class="img"><img alt="" class="img2" height="816" id="fig8-9" src="../images/Figure8-9.jpg" width="1031"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 8-9: The contour plot of the Eggholder function</span></p></figcaption>
</figure>
<p class="tx">In this case, the global solution is literally on the right-hand boundary of the decision space in <a href="chapter8.xhtml#fig8-10" class="calibre2">Figure 8-10</a>. The grayscale bar indicates that the darker regions are troughs and the lighter regions are peaks. Clearly, the fitness values are close to the global minima in many cases (based on the darkness of the shade). This is why it is so difficult to find the global minima for the Eggholder function.</p>
<p class="tx"><a href="chapter8.xhtml#fig8-10" class="calibre2">Figure 8-10</a> shows the convergence pattern for this problem. The fitness value improves in a stepwise manner with the number of generations (iterations) until it reaches the global minima.</p>
<figure class="img"><img alt="" class="img2" height="803" id="fig8-10" src="../images/Figure8-10.jpg" width="1153"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 8-10: The convergence pattern for the Eggholder function using the genetic algorithm</span></p></figcaption>
</figure>
<p class="tx"><span aria-label="341" epub:type="pagebreak" id="pg_341" role="doc-pagebreak"/>We’ll revisit this problem using particle swarm optimization (another NIA) and draw the corresponding convergence pattern in the next chapter. You’ll see that while both methods are capable of identifying the global optima, particle swarm optimization will do that much quicker!</p>
</section>
</section>
<section aria-labelledby="sec36" epub:type="division">
<h3 class="h"><span id="sec36"/><span id="h1-52"/><span class="sans_futura_std_bold_b_">Stopping Condition for Genetic Algorithms</span></h3>
<p class="tni">When solving real-world optimization problems, we often lack knowledge of the global optimal solution. Consequently, we cannot directly use it as a stopping condition. To address this challenge, we can employ several strategies. In this section, I’ll discuss commonly used approaches for defining stopping conditions in genetic algorithms.</p>
<p class="tx">First, the stopping condition can be implemented as the maximum number of generations, as we’ve done for all three projects on the genetic algorithm. In general, you wouldn’t know how many iterations it might take to solve a previously unsolved problem. This will depend on the nature of the problem, the global parameter values, and the specific schemes used for various operator functions. You’ll have to gradually adjust the number of iterations (along with other parameters) to find a combination of values that works for the problem at hand. Interestingly, we can use the genetic algorithm to find optimal combinations of global parameters. In the field of deep learning, the genetic algorithm has been used to optimize global parameters and quickly train neural networks that produce high-quality results.</p>
<p class="tx">Second, you could stop the algorithm from iterating if the best solution’s fitness does not show noticeable improvements for several generations (for example, very little or no improvement over the past 30 or 50 generations). This will require additional coding to track improvements dynamically, but this can be a strategy to let the algorithm stop automatically, even when the maximum number of iterations has not been reached.</p>
<p class="tx">Third, for certain types of problems, you may be able to set a target for the fitness and have the program terminate once that target is reached (recall that we had a text-matching target for the first project). When the target is difficult to reach, you could also terminate the program when a predetermined percentage of that target is reached (instead of matching the target exactly).</p>
<p class="tx">A lot more could be said about genetic algorithms, and researchers are frequently developing new adaptive or hybrid strategies and finding new applications. If you are interested in the state of the art, I suggest reviewing recent journal articles on the application of the genetic algorithm in your field of interest.</p>
<span aria-label="342" epub:type="pagebreak" id="pg_342" role="doc-pagebreak"/>
<aside aria-label="box-42" class="box2">
<p class="boxtitle" id="box-42"><span class="sans_futura_std_bold_b_">EXERCISE</span></p>
<p class="boxfirst"><span class="sans_futura_std_book_">One well-known crossover strategy used in genetic algorithms is called blend crossover (BLX). Given two genes</span> <span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">1</span> <span class="sans_futura_std_book_">and</span> <span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">2</span> <span class="sans_futura_std_book_">from parent 1 and parent 2, respectively, and assuming that</span> <span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">1</span> <span class="sans_futura_std_book_">&lt;</span> <span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">2</span><span class="sans_futura_std_book_">, BLX randomly creates a gene in the range of [</span><span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">1</span> <span class="sans_futura_std_book_">–</span> <span class="sans_futura_std_book_oblique_"><span lang="el" xml:lang="el">α</span></span> <span class="sans_futura_std_book_">* (</span><span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">2</span> <span class="sans_futura_std_book_">–</span> <span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">1</span><span class="sans_futura_std_book_">),</span> <span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">2</span> <span class="sans_futura_std_book_">+</span> <span class="sans_futura_std_book_oblique_"><span lang="el" xml:lang="el">α</span></span> <span class="sans_futura_std_book_">* (</span><span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">2</span> <span class="sans_futura_std_book_">–</span> <span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">1</span><span class="sans_futura_std_book_">)]. The value of</span> <span class="sans_futura_std_book_oblique_"><span lang="el" xml:lang="el">α</span></span> <span class="sans_futura_std_book_">lies between 0 and 1 (inclusive). When</span> <span class="sans_futura_std_book_oblique_"><span lang="el" xml:lang="el">α</span></span> <span class="sans_futura_std_book_">= 0, this strategy becomes the same as the random weighted scheme used in <a href="chapter8.xhtml#pre-35" class="calibre2">Project 35</a>. When</span> <span class="sans_futura_std_book_oblique_"><span lang="el" xml:lang="el">α</span></span> <span class="sans_futura_std_book_">= 0.5, the random value will be chosen from a range of 2 * (</span><span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">2</span> <span class="sans_futura_std_book_">–</span> <span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">1</span><span class="sans_futura_std_book_">). This is the recommended value based on empirical results. Finally,</span> <span class="sans_futura_std_book_oblique_"><span lang="el" xml:lang="el">α</span></span> <span class="sans_futura_std_book_">= 1 will result in choosing the random value from a range of 3 * (</span><span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">2</span> <span class="sans_futura_std_book_">–</span> <span class="sans_futura_std_book_oblique_">x</span><span class="sans_futura_std_book_sub_">1</span><span class="sans_futura_std_book_">).</span></p>
<p class="box1"><span class="sans_futura_std_book_">For this exercise, develop a new function called</span> <span class="sans_thesansmonocd_w5regular_">crossoverBLX()</span> <span class="sans_futura_std_book_">based on this scheme (use</span> <span class="sans_futura_std_book_oblique_"><span lang="el" xml:lang="el">α</span></span> <span class="sans_futura_std_book_">= 0.5). Solve the Eggholder problem using this new crossover function for the set of parameters used in <a href="chapter8.xhtml#pre-35" class="calibre2">Project 35</a></span><span class="sans_futura_std_book_">. Does the use of BLX result in a quicker convergence to the global optimum compared with the random weighted scheme?</span></p>
</aside>
<p class="tx">In <span><a href="chapter8.xhtml#pre-35" class="calibre2">Project 35</a></span>, we revised the code developed for function maximization to handle a minimization problem. However, changing the code back and forth can easily lead to errors. Therefore, in the next exercise you will develop new code to directly handle function minimization problems.</p>
<aside aria-label="box-43" class="box2">
<p class="boxtitle" id="box-43"><span class="sans_futura_std_bold_b_">EXERCISE</span></p>
<p class="boxfirst"><span class="sans_futura_std_book_">Modify the previously developed code so that it can directly handle a minimization problem. As a hint, you’ll have to change the selection method that chooses the solution with the smallest fitness instead of choosing the one with the greatest fitness. Additionally, whenever you sort the population, such as to facilitate elitism or to identify the best solution from a generation, you must sort in ascending order and pick the first solution which will have the smallest fitness value.</span></p>
<p class="box1"><span class="sans_futura_std_book_">If you want to use the roulette wheel scheme for a minimization problem, you’ll need to add code to deal with negative fitness values that may arise. This is because relative fitness values, which are calculated from actual fitness values, are used as proxy probabilities in the roulette wheel scheme, and probabilities cannot be negative. This issue can be handled by rescaling the fitness values so that the smallest fitness value becomes zero (or a small positive number). One alternative to using the roulette wheel or tournament selection is to use a rank-based selection where the chromosome with the smallest fitness value will be assigned the highest rank.</span></p>
<p class="boxlast"><span class="sans_futura_std_book_">Happy coding!</span></p>
</aside>
</section>
<section aria-labelledby="sec37" epub:type="division">
<span aria-label="343" epub:type="pagebreak" id="pg_343" role="doc-pagebreak"/>
<h3 class="h"><span id="sec37"/><span id="h1-53"/><span class="sans_futura_std_bold_b_">Summary</span></h3>
<p class="tni">In this chapter, you explored the fascinating world of nature-inspired algorithms, computational methods that mimic natural phenomena to solve complex problems. One key feature of these algorithms is that they are stochastic in nature: they exploit built-in randomness to tackle problems that are intractable or too complex for conventional methods. You learned about the benefits and challenges of using nature-inspired algorithms and focused on one of the most popular and powerful examples: the genetic algorithm.</p>
<p class="tx">The genetic algorithm is inspired by the process of natural evolution and uses a population of candidate solutions that undergo selection, crossover, and mutation to find the best solution for a given problem. You learned several ways to implement these operations and adjust the parameters of the algorithm to achieve the best performance. You also applied genetic algorithms to three different projects in order to:</p>
<ul class="ul1">
<li class="listbullet1">Generate a target string from a random population of characters</li>
<li class="listbullet1">Maximize the value of items in a knapsack with a limited capacity</li>
<li class="listbullet1">Find the global optimum solution for a real-valued and highly complex multivariate objective function</li>
</ul>
<p class="tx">In addition, you completed a set of exercises that cover additional techniques for the crossover operation and dedicated methods for solving minimization problems directly. By the end of this chapter, you gained a solid understanding of the theory and practice of genetic algorithms, and how they can be used to solve various types of optimization problems.</p>
</section>
<section aria-labelledby="sec38" epub:type="division">
<h3 class="h"><span id="sec38"/><span id="h1-54"/><span class="sans_futura_std_bold_b_">Resources</span></h3>
<p class="reference">Brownlee, Jason. <i class="calibre9">Clever Algorithms: Nature-Inspired Programming Recipes</i>. Electronic version, June 16, 2012. <i class="calibre9"><a href="https://github.com/clever-algorithms/CleverAlgorithms" class="calibre2">https://github.com/clever-algorithms/CleverAlgorithms</a></i>.</p>
<p class="reference">Buontempo, Frances. <i class="calibre9">Genetic Algorithms and Machine Learning for Programmers</i>. Raleigh, NC: The Pragmatic Bookshelf, 2019.</p>
<p class="reference">Gen, Mitsuo, and Runwei Cheng. <i class="calibre9">Genetic Algorithms and Engineering Optimization</i>. New York: John Wiley &amp; Sons, 2000.</p>
<p class="reference">Goldberg, David. <i class="calibre9">Genetic Algorithms in Search, Optimization and Machine Learning</i>. Reading, MA: Addison-Wesley Professional, 1989.</p>
<p class="reference">Haupt, Randy L., and Sue Ellen Haupt. <i class="calibre9">Practical Genetic Algorithms</i>. 2nd ed. Hoboken, NJ: John Wiley &amp; Sons, 2004.</p>
<p class="reference">Yang, Xin-She. <i class="calibre9">Nature-Inspired Optimization Algorithms</i>. 2nd ed. London: Academic Press, 2021.</p>
</section>
</section>
</div></body></html>