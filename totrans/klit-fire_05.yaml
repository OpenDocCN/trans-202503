- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building and Protecting Momentum
  prefs: []
  type: TYPE_NORMAL
- en: This book mainly focuses on big projects. When I discuss upgrades, I’m not talking
    about running a package manager to install the latest versions of your dependencies.
    When I mention deprecations, I’m not talking about versioning your API. Much of
    the advice in this book will work regardless of project size, but it is primarily
    intended for big ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 3 covered developing strategy around the engineering challenge posed
    by your legacy system. In that chapter, I described the shape and nature of different
    types of approaches and how to look at such a challenge holistically. This chapter
    describes a similar approach from the organizational side: how to create a plan
    that builds momentum and keeps teams focused and optimistic even as the work becomes
    difficult.'
  prefs: []
  type: TYPE_NORMAL
- en: The funny thing about big legacy modernization projects is that technologists
    suddenly seem drawn to strategies that they know do not work in other contexts.
    Few modern software engineers would forgo Agile development to spend months planning
    exactly what an architecture should look like and try to build a complete product
    all at once. And yet, when asked to modernize an old system, suddenly everyone
    is breaking things down into sequential phases that are completely dependent on
    one another.
  prefs: []
  type: TYPE_NORMAL
- en: Agile approaches to legacy challenges are not well publicized. Any number of
    books are available that describe how you build software. A few exist that cover
    how to maintain software, and even fewer have been published that explain how
    to tackle the challenges of rebuilding software when it has been left to rot or
    was built wrong in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: In truth, what works when rebuilding a system is not all that different from
    what worked to build it in the first place. You need to keep the scope small,
    and you need to iterate on your successes. This might seem unnecessary, because
    the old system and its history have defined all your requirements for you. Assuming
    you fully understand the requirements because an existing system is operational
    is a critical mistake. One of the advantages of building a new system is that
    the team is more aware of the unknowns. Existing systems can be a distraction.
    The software team treats the full-featured implementation of it as the MVP, no
    matter how large or how complex that existing system actually is. It’s simply
    too much information to manage. People become overwhelmed, and they get discouraged
    and demoralized. The project stalls and reinforces the notion that the modernization
    work is impossible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Momentum Builder: The Bliss of Measurable Problems'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a couple different ways to restrict scope when an existing system
    looms in the background. The most straightforward approach is to define an MVP
    from the existing system’s array of features. Pare it down into a lighter-weight
    version of itself that becomes the first iteration and then gradually add back
    features. While sensible, this strategy requires discipline and strong leadership.
    All users of the existing system will naturally see the features they use as the
    most critical and lobby to get them scheduled for the earliest possible iteration.
    The process becomes political very quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, I prefer to restrict the scope by defining one measurable problem we
    are trying to solve. Building a modern infrastructure is not a goal. Different
    people naturally are going to disagree on which standards and best practices should
    be enforced and on how strongly they should be enforced. Few real-life systems
    completely conform to an ideal; there are always at least one or two places in
    systems where a nonstandard approach was used to make a specific function or integration
    work. Everyone knows these compromises exist and that they probably will continue
    to exist in some form or another in the new system, but it’s unlikely the organization
    will be able to agree on when and where to introduce them.
  prefs: []
  type: TYPE_NORMAL
- en: But if all the work is structured around one critical problem that you can measure
    and monitor, these conversations become much easier. You start by looking for
    as many opportunities as possible to make the problem better and prioritize them
    by amount of estimated impact. When there is a disagreement on approach or technology,
    the criteria for the decision becomes “Which one moves the needle further?”
  prefs: []
  type: TYPE_NORMAL
- en: Legacy modernization projects go better when the individuals contributing to
    them feel comfortable being autonomous and when they can adapt to challenges and
    surprises as they present themselves because they understand what the priorities
    are. The more decisions need to go up to a senior group—be that VPs, enterprise
    architects, or a CEO—the more delays and bottlenecks appear. The more momentum
    is lost, and people stop believing success is possible. When people stop believing
    success is possible, they stop bringing their best to work. Measurable problems
    empower team members to make decisions. Everyone has agreed that metric X needs
    to be better; any actions taken to improve metric X need not be run up the chain
    of command.
  prefs: []
  type: TYPE_NORMAL
- en: Measurable problems create clearly articulated goals. Having a goal means you
    can define what kind of value you expect the project to add and whom that value
    will benefit most. Will modernization make things faster for customers? Will it
    improve scaling so you can sign bigger clients? Will it save people’s lives? Or,
    will it just mean that someone gets to give a conference talk or write an article
    about switching from technology A to technology B?
  prefs: []
  type: TYPE_NORMAL
- en: Anatomy of the Measurable Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s natural to want to approach architecture in a holistic way. Our minds love
    order and patterns, the neatness of everything being consistent and well thought
    out. But systems are like houses; they never really stay perfectly clean for long.
    The very act of using something forces it to change. You have less memory and
    less storage, your hardware decays, and you’ve added new features, which mean
    more lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: Good modernization work needs to suppress that impulse to create elegant comprehensive
    architectures up front. You can have your neat and orderly system, but you won’t
    get it from designing it that way in the beginning. Instead, you’ll build it through
    iteration.
  prefs: []
  type: TYPE_NORMAL
- en: The measurable problem is what will guide your teams through the modernization
    effort. When the legacy system was new, its footprint and the team that ran it
    were both small. As the system grew, internal politics grew with it. In some cases,
    entire business units were born or rearranged to follow the pattern of the technology.
    Getting all those people to agree and march in the same direction is difficult.
    The strength of the measurable problem is that it is objective and irrefutable,
    and therefore, it helps the team navigate the internal politics they have inherited
    from the existing system. People can and will disagree on whether the measurable
    problem is the right problem to solve, but that shifts the burden of mediating
    those disagreements away from the engineering team and toward the senior executive
    who signed off on focusing modernization activities on that measurable problem
    in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: The last benefit of measurable problems is that positive results are not linked
    to feature launches. When the team tries to create an MVP from an existing system,
    the organization will pressure them to achieve feature parity with the existing
    system as quickly as possible. Success or failure becomes tied to launches, which
    encourages cut corners and technical debt.
  prefs: []
  type: TYPE_NORMAL
- en: In all likelihood, the business side of the organization does not understand
    what’s wrong with the existing system. Rolling out features they already have
    is not something they will celebrate. To build momentum behind a modernization
    effort, it’s essential to communicate how modernizing will improve the status
    quo. Defining a measurable problem explains to the business side of the organization
    how the existing system could be better. Once the metrics and criteria are defined,
    any given action either moves the needle in a positive direction or doesn’t. Missteps
    are easier to identify, define, and correct. Everyone in the organization can
    figure out how things are going by looking at the metrics.
  prefs: []
  type: TYPE_NORMAL
- en: But how does one identify a good measurable problem?
  prefs: []
  type: TYPE_NORMAL
- en: The easiest candidates are ones that reflect the business or mission goals of
    the organization. If you’re thinking about rearchitecting a system and cannot
    tie the effort back to some kind of business goal, you probably shouldn’t be doing
    it at all.
  prefs: []
  type: TYPE_NORMAL
- en: When I was working for the government, one of the most inspiring projects I
    saw was the effort to modernize the immigration system enough to meet a stretch
    goal for refugee resettlement the Obama administration had set. The system itself,
    even just the subset that concerned refugees, was large and complex. Engineers
    were overwhelmed by the scope of it and the problems that it experienced from
    time to time.
  prefs: []
  type: TYPE_NORMAL
- en: But the challenge of this particular project was not to make that whole system
    better; it was to get that whole system to process a specific type of application
    faster. Defining the goal in this way created a much clearer scope for the effort.
    The team started by doing an analysis of where the bottlenecks in application
    processing were, and then they began precision-targeting those areas, seeking
    only to make iterative improvements. Conversations about prioritization focused
    on what changes were likely to increase the number of applications processed—numbers
    anyone on the team could look at and refer to as needed. As they worked toward
    this specific goal, the team passed up a lot of opportunities to make much needed
    infrastructure changes, because doing so would not produce the results where they
    needed them.
  prefs: []
  type: TYPE_NORMAL
- en: At first glance, this approach might seem unwise or even irresponsible, but
    the number-one killer of big efforts is not technical failure. It’s loss of momentum.
    To be successful at those long-term rearchitecting challenges, the team needs
    to establish a feedback loop that continuously builds on and promotes their track
    record of success. When it became clear that the refugee team was not only going
    to reach the stretch goal—a number that many felt was impossible—but that they
    were actually going to overshoot it by a few thousand people, other teams that
    were better positioned to make those much needed infrastructure changes started
    coming to work with renewed energy. Don’t lose sight of the fact that modernization
    projects are long and typically involve coordinating multiple teams. Being strategically
    narrow-minded to demonstrate value and build momentum is not a bad idea.
  prefs: []
  type: TYPE_NORMAL
- en: Good measurable problems have to be focused on problems that your engineers
    give a shit about. Number of refugees saved from ISIS was an easy goal to rally
    people around. In all likelihood, you won’t be able to say your database migration
    is going to do that, but engineers feel passionate about other things. Talk to
    them and figure out what those are.
  prefs: []
  type: TYPE_NORMAL
- en: 'Momentum Killer: The Team Cannot Agree'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When I moved from being an individual contributor to running engineering teams,
    my role in technical conversations shifted. I saw better outcomes when I focused
    on facilitating a productive conversation rather than vying to be the decision-maker.
    Have you ever found yourself in a meeting that felt like it was running around
    in circles? Meetings where people seemed to be competing to see who could predict
    the most obscure potential failure? Meetings where past decisions were relitigated
    and everyone walked away less certain as to what the next steps were? Facilitating
    technical conversations is more important than being the decision-maker because
    unproductive and frustrating meetings demoralize teams.
  prefs: []
  type: TYPE_NORMAL
- en: Because large systems are typically complex, out of control meetings can derail
    decision-making about the technology that backs them. Measurable problems help
    people prioritize what improvements to make and in which order, but when it comes
    to the nitty-gritty implementation details, it is not always possible to predict
    which options will have the biggest impact. Reasonable people are going to disagree,
    but pointless arguments need to be defused before they do too much damage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Define a Scope'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The best way to handle dysfunctional decision-making meetings is to prevent
    them from happening in the first place by defining and enforcing a scope. I usually
    start meetings by listing the desired outcomes, the outcomes I would be satisfied
    with, and what’s out of scope for this decision. I may even write this information
    on a whiteboard or put it in a PowerPoint slide for reference. What do we want
    to accomplish in this meeting? If we get stuck, what other outcomes would be acceptable?
    Sometimes a team cannot agree because there is an actual blocker to agreement—a
    gray area that requires more research, for example. If that happens, what is the
    smallest decision we could make and still feel like the meeting was productive?
  prefs: []
  type: TYPE_NORMAL
- en: Once the meeting has a scope, I define areas that we should be able to agree
    are outside that scope. Often out-of-scope issues are decisions that are neither
    blockers nor dependencies. The hard ones do seem to be related to in-scope issues,
    so when in doubt, the team needs to be able to articulate clearly how our in-scope
    decisions are affected by the issue being raised. For example, I had an engineering
    team that was charged with creating a seamless platform where engineers could
    run commands and have the heavy lifting of building, configuring, and deploying
    done for them. At the same time, the organization was also thinking about phasing
    out one programming language in favor of another. To accomplish the first goal,
    we needed to make a few decisions about the architecture of the tool. Would we
    build a suite of separate tools, or would we build one tool that we could add
    functionality to? Whatever design pattern we chose could have been done equally
    well in either language, so any debate about programming languages would bring
    us no closer to reaching a decision on what we wanted the meeting to be about.
    Discussions about programming languages were out of scope. Although the issue
    would ultimately affect implementation of the design pattern we selected, it was
    neither a blocker nor a dependency when picking the pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'With my engineers, I set the expectation that to have a productive, free-flowing
    debate, we need to be able to sort comments and issues into in-scope and out-of-scope
    quickly and easily as a team. I call this technique “true but irrelevant,” because
    I can typically sort meeting information into three buckets: things that are true,
    things that are false, and things that are true but irrelevant. Irrelevant is
    just a punchier way of saying out of scope.'
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of thinking about comments made during meetings as true, false,
    or true but irrelevant is not to discourage people from bringing up irrelevant
    details. When we think of contributions only in terms of true or false, we put
    pressure on individuals to save face by fighting to have the validity of their
    irrelevant facts acknowledged. By encouraging people to think about their comments
    as in-scope and out-of-scope, we’re saying that the engineer speaking raised a
    valid point that should be considered in a different conversation.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, relevancy is often difficult for any one person to determine.
    You don’t want engineers to self-censor for fear of bringing up something that’s
    out of scope. They might incorrectly assume something is out of scope because
    they have incomplete information. If they fail to raise the issue because they
    associate the true but irrelevant bucket with failure, they may fail to point
    out actual problems. A great meeting is not a meeting where no one ever mentions
    anything out of scope; it’s one where out-of-scope comments are quickly identified
    as such by the team and dispatched before they have derailed the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Check for Conflicting Optimization Strategies'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Even with a carefully defined scope, engineers might bump heads anyway. A quick
    trick when two capable engineers cannot seem to agree on a decision is to ask
    yourself what each one is optimizing for with their suggested approach. Remember,
    technology has a number of trade-offs where optimizing for one characteristic
    diminishes another important characteristic. Examples include security versus
    usability, coupling versus complexity, fault tolerance versus consistency, and
    so on, and so forth. If two engineers really can’t agree on a decision, it’s usually
    because they have different beliefs about where the ideal optimization between
    two such poles is.
  prefs: []
  type: TYPE_NORMAL
- en: Looking for absolute truths in situations that are ambiguous and value-based
    is painful. Sometimes it helps just to highlight the fact that the disagreement
    is really over what to optimize for, rather than pure technical correctness. What
    is the impact of each optimization? Can the negative effects of over-optimizing
    in one direction be mitigated?
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Perform Time-Boxed Experiments'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If the disagreement is in scope and isn’t a matter of conflicting optimization
    strategies, the best way to settle it is by creating time-boxed experiments. Find
    a way to try each approach on a small sample size with a clear evaluation date
    and specific success criteria defined in advance. Becoming good at experiments
    is valuable for practically any organization. It’s the basis of iteration—you
    build something, collect data on how it is performing, modify it to improve performance,
    and start the cycle over. This is how effective technology is built, so engineering
    teams should get comfortable using it to make hard decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Momentum Killer: A History of Failure'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Odds are good that the modernization effort you’re working on now is not the
    first attempt. Companies that successfully maintain their technology over time
    usually do not need to engage in a big modernization project after all. They are
    able to keep up through incremental change and regular maintenance. If you are
    running a team tasked with just cleaning up the debt and migrating onto more suitable
    technologies, it means the existing organization has failed to adapt.
  prefs: []
  type: TYPE_NORMAL
- en: Your specific situation might have a history of failure that is much deeper
    than slacking off on regular maintenance. Is this even the first modernization
    project? If not, each prior effort likely has left scar tissue on the organization
    that you need to consider. The more false starts a project has had, the harder
    it is to build the momentum necessary to succeed.
  prefs: []
  type: TYPE_NORMAL
- en: The first deliverables of a modernization effort have to take this history of
    failure into account. People aren’t pessimistic and uninspired by legacy modernization
    projects because they don’t care or don’t realize that modernization is important.
    They often feel that way because they are convinced that success is impossible
    after experiencing a number of failures.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, I have yet to find a group of engineers who didn’t want to
    believe they could reach a better state. It’s surprisingly easy to change people’s
    minds about the inevitability of failure when you demonstrate that success is
    possible.
  prefs: []
  type: TYPE_NORMAL
- en: Inspired and motivated engineering teams run smoother and more productive modernization
    processes, so design your modernization strategy around front-loading value. What
    changes will produce the most immediate positive impact?
  prefs: []
  type: TYPE_NORMAL
- en: I once worked for an organization that was facing a major challenge around the
    breakup of its monolith. The organization wanted to build a standardized platform
    that product engineering teams could use to deploy services to production easily—a
    reasonable ambition—but the product itself was three monoliths crammed onto a
    single VM. It was a monolith of monoliths, if you will. At the time it had been
    built, that architecture fit the business case, but in the years that followed,
    the organization had seen explosive growth. By the time I got there, the architecture
    didn’t make sense anymore.
  prefs: []
  type: TYPE_NORMAL
- en: This organization was facing two problems. First, the platform initiative and
    the monolith breakup were blocking each other. The product teams did not want
    to break up their monolith into services until they could deploy on a platform.
    Understandably, they did not want to put something on a release pipeline only
    to have to migrate it off when the platform arrived. The platform group, on the
    other hand, could not build a platform without requirements set by the product
    teams. They had to be able to build with the real needs of real services in mind—services
    that did not exist because they had not been broken off the monolith yet.
  prefs: []
  type: TYPE_NORMAL
- en: The second problem was that the organization had actually tried both sides of
    this process before and failed at them, multiple times. It had tried to build
    a platform and had migrated some small, unimportant services that could be split
    off with minimum redesign. It had tried this at least three times by my estimation,
    each time losing momentum and failing to finish.
  prefs: []
  type: TYPE_NORMAL
- en: The organization had also tried to break up the monolith several times. Each
    time, it became overwhelmed by the complexity of the task. Splitting monoliths
    is rarely, if ever, only about copying and pasting some code into a different
    repository. When software is designed to be coupled, engineers usually take advantage
    of that fact and build on the easy access that coupling provides. In this case,
    that meant their testing suites had a high concentration of end-to-end tests over
    unit tests. It meant multiple components were accessing the same data store and
    sharing responsibilities over the same information. When their tightly coupled
    monolith became decoupled services, the tests would break, and a plan for keeping
    the data consistent between services would need to be developed.
  prefs: []
  type: TYPE_NORMAL
- en: Now facing their fourth attempt, optimism was pretty low. Everybody wanted to
    see the project be successful, but no one wanted to be the first team to invest
    the work only to be left holding the bag when the effort fell apart once again.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prominent engineers on the platform group were asked to come up with a plan.
    They spent weeks collecting data and interviewing teams and eventually pitched
    the following compromise: they would pull the three monoliths onto their own release
    channels with their own VMs, thereby ensuring that the platform could support
    everything the product needed without requiring the product team to split anything
    immediately.'
  prefs: []
  type: TYPE_NORMAL
- en: The problem with this plan was that it didn’t actually make anything better.
    Now instead of one release cycle with an owner and an orderly schedule determining
    when code hit each region and environment, the organization would have three release
    cycles with no one owning them. Every deploy would have to be carefully coordinated
    across multiple teams so that changes did not accidentally hit production for
    one monolith early or late.
  prefs: []
  type: TYPE_NORMAL
- en: It wasn’t going to lower costs either. Commercial cloud providers charge per
    time usage of each VM. Three separate sets of VMs meant the proposed plan would
    easily double or even triple the organization’s hosting expenses.
  prefs: []
  type: TYPE_NORMAL
- en: I wasn’t even sure it would get off the ground. My team had been working hard
    redesigning a service that appeared to be fully separate to go onto the platform,
    and we were finding all sort of weird places where components were integrated
    in unexpected ways.
  prefs: []
  type: TYPE_NORMAL
- en: What was the value of putting three monoliths on separate release channels?
  prefs: []
  type: TYPE_NORMAL
- en: When I asked that question, the engineers thought I was asking what the value
    of breaking up the monolith was. It took several conversations before I could
    get them to understand that I wasn’t questioning their goal. I was questioning
    their starting point. Starting with tripling the number of VMs would make updates
    more complicated for product teams and would increase spending unnecessarily.
    Why would the organization continue to invest in the process of breaking up the
    monolith if its first experiences with that process made work harder and more
    expensive?
  prefs: []
  type: TYPE_NORMAL
- en: The hard problems around legacy modernization are not technical problems; they’re
    people problems. The technology is usually pretty straightforward. Keeping people
    focused and motivated through the months or years it takes to finish the job is
    hard. To do this, you need to provide significant value right away, as soon as
    possible, so that you overcome people’s natural skepticism and get them to buy
    in. The important word in the phrase proof of concept is *proof*. You need to
    prove to people that success is possible and worth doing.
  prefs: []
  type: TYPE_NORMAL
- en: The more an organization has failed at something, the more proof it needs that
    modernization will bring value. When there’s a history of failure, that first
    step has to provide enough value to build the momentum necessary to be successful.
    The obvious problem with that is it means there’s a natural upper bound. There
    is a point where cynicism is so high, no single first step will ever provide enough
    value to prove the project will work.
  prefs: []
  type: TYPE_NORMAL
- en: Then what?
  prefs: []
  type: TYPE_NORMAL
- en: 'Momentum Builder: Inspiring Urgency'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you find yourself in this situation, you have a little due diligence to do
    first. The first question to ask is does this particular migration actually add
    any value at all? Or are we migrating because there’s a new shiny technology in
    front of us? After all, monoliths are not universally bad. Plenty of successful
    companies run monoliths.
  prefs: []
  type: TYPE_NORMAL
- en: If you believe the migration does add value, the next question to ask yourself
    is will leadership make a commitment to prioritizing it? Sometimes you get lucky,
    and the change is one with a hard deadline and real consequences for it slipping.^([1](#c05-footnote-1))
  prefs: []
  type: TYPE_NORMAL
- en: But if leadership isn’t prioritizing it and if you believe the migration has
    real business value but you’re weighted down with the cynicism of repeated failures,
    what you need is a crisis. Value is relative, after all. When things are working
    well and money is coming in, engineers can tolerate a multitude of sins. When
    things are bad, the perception of value added by nearly any change goes up. Dealing
    with crisis alters the organization’s internal calculus around risk.
  prefs: []
  type: TYPE_NORMAL
- en: When I was working in government, we would reach the upper bound on the value
    scale frequently. Some of the systems were so old, efforts to modernize them had
    literally been passed from generation to generation. Having a crisis became an
    essential component of how my teams operated—to the point that we might delay
    talking to an agency for a few weeks or months just to see whether a crisis would
    pop up that we could hook into.
  prefs: []
  type: TYPE_NORMAL
- en: Occasionally, I went as far as looking for a crisis to draw attention to. This
    usually didn’t require too much effort. Any system more than five years old will
    have at least a couple major things wrong with it. It didn’t mean lying, and it
    didn’t mean injecting problems where they didn’t exist. Instead, it was a matter
    of storytelling—taking something that was unreported and highlighting its potential
    risks. These problems *were* problems, and my analysis of their potential impact
    was always truthful, but some of them could have easily stayed buried for months
    or years without triggering a single incident.
  prefs: []
  type: TYPE_NORMAL
- en: My favorite place to start was with security, followed by system stability.
    One does not need much technical literacy to understand the impact and consequences
    of getting those issues wrong. There are also areas where even the best technical
    teams struggle from time to time, so you’re unlikely to come up empty-handed if
    you look for a potential crisis on either these two fronts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Protecting Momentum: A Quota on Big Decisions'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you’ve done all the work of assessing the situation and organizing
    around it, you don’t want to let the organization itself undermine that work.
    People mean well, but any kind of change is risky, and saying yes to risk is difficult.
    Never fear. You can set the stage to get a yes to organizational change rather
    than a no.
  prefs: []
  type: TYPE_NORMAL
- en: First, you need to learn to talk about what you are doing in a way that minimizes
    the number of big decisions that need to be made—particularly big decisions that
    include changes in process or anything that would need multiple stakeholders to
    sign off on and many rounds of approvals to change.
  prefs: []
  type: TYPE_NORMAL
- en: Decisions that require consulting many stakeholders are obviously difficult
    and painful to manage. People will naturally want to avoid them. Therefore, the
    more big decisions your proposal seems to include, the more likely people are
    going to want to slow down or delay it a quarter.
  prefs: []
  type: TYPE_NORMAL
- en: You may think that by giving projects fancy names, projecting budgets, and settling
    staffing questions up front you are being diligent, and you are! But you’re also
    making the project look like a series of big decisions, which for audiences insulated
    from the day-to-day pain of legacy systems seems too risky. Consider different
    ways of talking about the same project for different audiences. Some audiences
    will appreciate detailed planning, and other audiences will appreciate a high-level
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'Look for the following when you need to prune the number of big decisions that
    have to be made to move forward:'
  prefs: []
  type: TYPE_NORMAL
- en: Existing programs, projects, or technology These are the best off-by-one errors.
    Riding the coattails of an already approved solution removes the need to seek
    out those approvals yourself.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Advantageous regulation You can eliminate a big decision by making it seem like
    it was already made, but you can also eliminate a big decision by making it seem
    like the organization doesn’t have a choice. Compliance, particularly around security,
    is a great place to look, because those rules often come with specific deadlines
    when they must be done or the organization loses certifications, funding, and,
    potentially, clients.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ambiguous approval process The saying “Ask for forgiveness, not permission”
    is popular among the startup crowd, but let’s face it, you’re better off asking
    for forgiveness if it’s believable that you might have been acting in good faith.
    If you’re bypassing a well-documented and well-known approval process, the outcome
    is less likely to end favorably than when the process is ambiguous or nonexistent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Protecting Momentum: Calculating Opportunity Costs'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Value add isn’t always a matter of technical outcomes. More often than not,
    business outcomes provide a clearer path to prioritization. Business outcomes
    could be profits, but if you’re working for a mission-driven organization, business
    outcomes could also be people served or impact observed. When running a multiyear
    modernization project, buy-in from the business side is essential. You can’t rely
    on them understanding the technical outcomes, so you should know how to illustrate
    the value of business outcomes by calculating opportunity costs.
  prefs: []
  type: TYPE_NORMAL
- en: For those not familiar with the concept, an *opportunity cost* is money lost
    by not doing something because you have chosen another opportunity instead. Typically,
    opportunity costs are expressed in expected profits not realized, but in the context
    of legacy systems, we usually think of opportunity costs in terms of money saved.
  prefs: []
  type: TYPE_NORMAL
- en: Opportunity costs are better as thought experiments than actual calculations.
    If it were possible to calculate accurately how much time and money we were going
    to spend on each potential approach to upgrading an existing system (or upgrading
    it versus leaving it be and building new features), maintaining legacy systems
    would be easy. But opportunity costs are useful in getting people to communicate
    their assumptions and build a case for why the organization should do what we
    want them to do. To provide value, estimates of opportunity cost need not be accurate.
    They need only provide insightful context of the trade-offs proposed by a given
    decision.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating opportunity costs isn’t just about making more profitable decisions.
    It gives the team data with which to justify the modernization activity to a wide
    variety of stakeholders. Investing in the health of your technology makes sense
    to everyone only when the technology is visibly failing, and by that point, the
    problem is much larger and much harder to solve. Senior management tends to be
    skeptical of any kind of cleanup activity—fearing that it will slow the organization’s
    velocity unnecessarily.
  prefs: []
  type: TYPE_NORMAL
- en: My first big project at Auth0 was getting a handle on our notifications system.
    Auth0 was maintaining a shared email server for testing and development purposes
    only. Nevertheless, customers occasionally neglected to move on to a dedicated
    provider when going to production even though plenty of free options were available.
    Customers were rate-limited on the shared provider precisely because it was not
    intended for production, but when they hit their limit, we dumped their email
    into a retry queue so that they could be sent at a later point.
  prefs: []
  type: TYPE_NORMAL
- en: We assumed—wrongly as it turned out—that customers would go over their quota
    gradually, as a result of natural traffic growth. Had this been the case, retrying
    email over time would have made sense. A handful of email messages get delayed,
    and as those delays become more common, it nudges the customer onto a dedicated
    provider instead. In reality, customers were much more likely to catapult over
    the limit with activities that would trigger email to all of their users—hundreds
    if not thousands of emails all at once.
  prefs: []
  type: TYPE_NORMAL
- en: That created a situation where the retry queue would fill up to the point where
    20 workers would need hours of processing just to clear the messages. It affected
    the performance of the service for everyone and set off a page to whoever was
    on call—all over a bunch of email that most of the time no one actually wanted
    delivered in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: We decided to change the way rate-limiting worked so that instead of retrying
    email, the shared provider would drop them when the limit was exhausted. That
    was a lot of migration work, and not only did we have to change the rate-limiting
    algorithm, but we also had to change the technology that was doing the rate-limiting
    in the first place. Our existing rate-limiting solution was in the process of
    being replaced by another solution. We needed to change our architecture and then
    figure out a backward-compatible strategy for our on-premises customers who upgraded
    at a slower cadence than cloud customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'All of this was a lot of work, and our motivation for investing in it was very
    personal: when the retry queue filled up, it paged someone on our team to go fix
    it. This was both annoying and disruptive. The interruption was made doubly frustrating
    by the fact that the official resolution to this issue in our playbook was to
    drop all the email in the retry queue anyway. It seemed pointless to ask a human
    to wake up at 3 am to do what a computer should be able to do automatically.'
  prefs: []
  type: TYPE_NORMAL
- en: What we didn’t think about until we were in the middle of the change is how
    much money not trying to send hundreds of thousands of pointless emails was going
    to save us. We got a certain number of email messages per month from the company
    that ran the shared email server for us. When we went over that limit, our account
    with this provider automatically bought 50,000 more emails for $20 and sent us
    an alert letting us know it had done so. When we started rolling out this change,
    we were receiving about 10 such alerts a day, or $200 in additional email. A single
    incident might cost us anywhere from $1,000 to $2,000.
  prefs: []
  type: TYPE_NORMAL
- en: When the changes went live, we literally saved the organization tens of thousands
    of dollars just by getting rid of email that our customers didn’t want sent in
    the first place. The whole project had been a huge win, but the cost savings gave
    us political capital that we could spend both to justify why we hadn’t spent that
    time adding new features and to get buy-in for similar maintenance work later.
  prefs: []
  type: TYPE_NORMAL
- en: It can be tricky getting started with opportunity costs because the number of
    potential opportunities to calculate can seem infinite. Remember that opportunity
    costs are thought experiments and rhetorical devices. You don’t need to list the
    costs of everything your team might be doing, just the activities that strengthen
    the case for what you want to be doing. This means highlighting how activities
    with high prioritization might be more expensive than the organization is assuming
    and describing in business-friendly language how much value there is to be gained
    by doing things the way you’d like them to be done.
  prefs: []
  type: TYPE_NORMAL
- en: When looking for the right opportunities to compare against, consider activities
    from these three general categories.
  prefs: []
  type: TYPE_NORMAL
- en: The Cost of Not Adding New Features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This cost typically is calculated by estimating profits or impact of new features.
    It is larger in small organizations where the development team may not be big
    enough to have broken out into distinct units. Shipping a new feature with a small
    organization locks up a greater percentage of the total staff, which means they
    are not available to do modernization work or contribute to other projects.
  prefs: []
  type: TYPE_NORMAL
- en: The pressure to delay maintenance work on legacy systems in favor of new features
    and products is constant at most organizations. There’s never a good time for
    it, although it always seems that if the organization could just get through the
    latest challenge, things will calm down and the cleanup can begin. To avoid endless
    procrastination, try to align the new features with the goal state. For example,
    if migrating from a monolith to services, you might want to use the new feature
    to identify the first service to peel off.
  prefs: []
  type: TYPE_NORMAL
- en: The Cost of Not Fixing Something Else
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Legacy systems rarely have only one thing wrong with them. Each step in the
    modernization process is a decision between problems that could be fixed with
    the same time and energy. I’ve already described various methods for choosing
    what to fix and when. Opportunity costs are really about selling the strategy
    up the chain of command. Doing this is easier if the organization has defined
    *service-level objectives**(SLOs**)* or has *service-level agreements (SLAs**)*.
    Both SLOs and SLAs equate performance levels with consumer value. SLAs may go
    as far as defining a specific monetary amount the customer can be reimbursed when
    performance dips below a specific level.
  prefs: []
  type: TYPE_NORMAL
- en: 'SLOs and SLAs help the team prioritize fixes by how much pain the problem is
    causing for users. They are a good thing to have even if you feel confident that
    you won’t need to justify what you modernize and when. But if you do have to justify
    your strategy, you should be able to study historical data and project under what
    conditions a given system or part of a system might violate its SLO. Often this
    is heavily influenced by scale, so it’s a good opportunity to leverage the business
    side’s ambition to your advantage: look at what level of growth the business is
    expecting and calculate opportunity costs based on how that level of growth will
    affect SLOs.'
  prefs: []
  type: TYPE_NORMAL
- en: The Cost of Not Deprecating in Favor of a Different Solution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a particularly difficult cost to calculate because deprecations do not
    complete all at once. For a period of time during a migration or modernization,
    it’s likely that an organization will be maintaining both the old solution and
    the modern one, especially if the new solution requires code changes to be deployed.
    So, in addition to the cost of either purchasing or developing the new solution,
    you have to factor in the cost of decommissioning the old solution. How many teams
    does that affect? What are they not working on while they make those changes?
    What is the long-term maintenance burden of the old solution versus the new one?
    Depending on whether the new solution is hosted/software as a service (SaaS) or
    just a new custom-built tool, the considerations could look very different.
  prefs: []
  type: TYPE_NORMAL
