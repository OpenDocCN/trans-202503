- en: '**6'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MACHINE LEARNING**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The goal of machine learning is to train models to generate correct outputs
    when given previously unseen inputs. This is usually done by repeatedly presenting
    the model with a collection of known inputs and outputs until the model succeeds
    in properly assigning outputs to inputs, or *learns*.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll explore randomness in machine learning by building two
    datasets for histology slides and images of handwritten digits. As we’ll learn,
    randomness is essential to building suitable machine learning datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll explore randomness in neural networks—the driving force behind the
    AI revolution. We’ll restrict ourselves to traditional neural network architectures;
    randomness is just as important, if not more so, when working with advanced models.
  prefs: []
  type: TYPE_NORMAL
- en: After neural networks come *extreme learning machines*, simple neural networks
    that fundamentally depend on randomness. Unlike their grown-up cousins, extreme
    learning machines don’t require extensive training, but instead rely on the power
    of randomness to do most of the learning for them.
  prefs: []
  type: TYPE_NORMAL
- en: '*Random forests* close out the chapter, and are also critically dependent on
    randomness for their success.'
  prefs: []
  type: TYPE_NORMAL
- en: I’ll point out where randomness appears as we move through the chapter. Randomness
    is central to the success of machine learning, from your favorite smart speaker
    to the self-driving car you may (someday soon) be riding in.
  prefs: []
  type: TYPE_NORMAL
- en: '**Datasets**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In machine learning, we train models from sample data. Therefore, we must build
    datasets before beginning our explorations. Randomness plays a critical role in
    this process.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll build two datasets. The first consists of measurements of cells from histology
    slides that hopefully enable the model to learn whether the tissue sample is benign
    (class 0) or malignant (class 1).
  prefs: []
  type: TYPE_NORMAL
- en: 'The second dataset consists of 28×28-pixel grayscale images of handwritten
    digits: 1, 4, 7, and 9\. The images aren’t stored in the usual format; rather,
    they’re unraveled into vectors where the first row is followed by the second,
    and so on, to map the 28×28 pixels to 784-element vectors.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Histology Slide Data***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Machine learning etiquette dictates that training a model requires a minimum
    of two datasets. The first is the *training set*, a collection of pairs, (***x***,
    *y*), where ***x*** are input vectors and *y* are the corresponding output labels.
    The second is a *test set*, of the same kind as the training set, but it’s not
    used until training is complete. The model’s performance on the test set decides
    how well it’s learned.
  prefs: []
  type: TYPE_NORMAL
- en: The *raw* directory holds the *bc_data.npy* and *bc_labels.npy* files. The first
    is a dataset that contains a two-dimensional NumPy array of 569 rows and 30 columns.
    Each row is a *sample*, and each column a *feature*. The 30 elements of a sample
    represent 10 measurements of three different cells on the histology slide. The
    second file contains the label, 0 for benign and 1 for malignant. There’s a one-to-one
    correspondence between the rows of the data and the labels. Therefore, row 0 of
    *bc_data.npy* represents features from a benign sample, while row 2 has features
    from a malignant sample because the first element of the vector in *bc_labels.npy*
    is a 0, and the third is a 1.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll build two datasets from the 569 samples, using a 70/30 split, meaning
    70 percent of the samples are for training (398) and the remaining 30 percent
    for testing (171).
  prefs: []
  type: TYPE_NORMAL
- en: As machine learning models are notoriously slow to learn, we should be concerned
    that 398 samples are not enough to condition the model. We want more data, but
    don’t have any more; what are we to do?
  prefs: []
  type: TYPE_NORMAL
- en: Randomness comes to our aid. We can *augment* the data by creating fake samples
    that, plausibly, come from the same source as our training data. We’ll apply random
    alterations to the existing data—enough to make it different, but not so much
    that the labels are no longer accurate. Data augmentation is a powerful part of
    modern machine learning that helps models learn not to pay too much attention
    to the particulars of the training set, but instead seek more general characteristics
    that differentiate between the classes.
  prefs: []
  type: TYPE_NORMAL
- en: Before we augment the training samples, we need to standardize the data. Many
    machine learning models have difficulty with features that have different ranges.
    For example, one feature might sit in the range [0, 2] while another uses [–30,000,
    30,000]. To bring both features into the same relative range, we subtract the
    mean value of each feature and then divide by the standard deviation of the features.
    After this transformation, each feature has a mean value close to zero and a standard
    deviation of one.
  prefs: []
  type: TYPE_NORMAL
- en: We have standardized features that we’ve split into two disjoint groups, one
    for training and one for testing. We’re now ready to augment the training data
    by employing *principal component analysis (PCA)*. If we were able to plot the
    data in 30 dimensions, we’d see that it’s spread out in some directions more than
    others. PCA finds these directions and, in effect, rotates the 30-dimensional
    coordinate system so that the first coordinate aligns with the direction where
    there’s the most variation in the data, then the second coordinate with the next,
    and so on. This means that later coordinates are less important in representing
    the data (though perhaps not in distinguishing between classes). We’ll take advantage
    of this decreasing importance in directions to randomly alter the coordinate directions,
    producing training data similar to the original but not identical. By making small
    changes, we can be (reasonably) confident that the new data represents an instance
    of the original class.
  prefs: []
  type: TYPE_NORMAL
- en: The code we need is in *build_bc_data.py*. Let’s walk through the important
    bits, beginning with loading the raw data and separating it into train and test
    ([Listing 6-1](ch06.xhtml#ch06list01)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-1: Splitting the raw histology data*'
  prefs: []
  type: TYPE_NORMAL
- en: First, we fix NumPy’s pseudorandom number seed so the same dataset is built
    each time the code is run. Generally, altering NumPy’s seed this way is not a
    good idea, as it affects *all* code using NumPy, even inside other modules (like
    the scikit-learn modules we’ll use later in the chapter). However, in this case,
    we’ll take the risk.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we load the raw data and labels before standardizing ➊. We want the mean
    value of each feature. The columns of `x` are the features, requiring the use
    of `axis=0`. This keyword applies the function, `mean`, across the rows of `x`,
    thereby delivering a 30-element vector where each element is the mean of the corresponding
    column of `x`.
  prefs: []
  type: TYPE_NORMAL
- en: We subtract this mean from each sample, or each row of `x`. With NumPy’s broadcast
    rules, we can do this automatically, with no looping required. NumPy is smart
    enough to see that we’re attempting to subtract a 30-element vector from a 2D
    array where the second dimension is 30, so it performs the subtraction and repeats
    it for each row.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we divide the mean-subtracted data by the standard deviation of each feature.
    Again, `axis=0` lets us apply the function across the rows. Because of NumPy’s
    broadcast rules, the division is applied down the rows of `x` to produce the final,
    standardized dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The next three lines randomize the dataset by assigning `i` to a random permutation
    of the numbers 0 through 568\. NumPy’s `argsort` function doesn’t sort a vector,
    but instead returns the sequence of indices that would sort it. The following
    two lines apply this permutation to both `x` and `y` to scramble the data and
    the labels in sync.
  prefs: []
  type: TYPE_NORMAL
- en: The final five lines split the raw dataset into training sets (`xtrn`, `ytrn`)
    and testing sets (`xtst`, `ytst`). Note that we split the dataset before augmenting;
    if we split it after, augmented versions of a sample will likely end up in the
    test set, thereby making the model seem better than it is.
  prefs: []
  type: TYPE_NORMAL
- en: We’re now in a position to augment the data. First, we need to learn the principal
    components of the raw data, then we build a new training set where each original
    sample is kept, along with nine augmented versions of that sample.
  prefs: []
  type: TYPE_NORMAL
- en: In [Listing 6-2](ch06.xhtml#ch06list02), scikit-learn supplies `PCA`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-2: Using PCA to learn the principal components*'
  prefs: []
  type: TYPE_NORMAL
- en: The `PCA` class follows scikit-learn’s standard approach of defining an instance
    of a class before calling `fit` on that instance. We set the number of components
    to the number of features in the dataset (30).
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use the trained `pca` object in a loop to build a new training set of
    augmented samples, as shown in [Listing 6-3](ch06.xhtml#ch06list03).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-3: Augmenting the samples*'
  prefs: []
  type: TYPE_NORMAL
- en: The new training data is in `newx` and `newy`. Each existing training sample
    will be accompanied by nine augmented versions of it, so the new training set
    will have 3,980 samples instead of a mere 398.
  prefs: []
  type: TYPE_NORMAL
- en: The loop constructs the dataset in blocks of 398 samples. The first pass stores
    the original data, and subsequent passes call `generateData` to return a new,
    augmented version of the samples in the original dataset. The order of the new
    samples is identical to the original, meaning the labels are in the same order
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: In [Listing 6-4](ch06.xhtml#ch06list04), the function `generateData` applies
    the PCA transformation and alters the least important coordinate directions beginning
    with `start` (24).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-4: Applying PCA*'
  prefs: []
  type: TYPE_NORMAL
- en: PCA is a reversible transformation. The `generateData` function alters the PCA
    components by adding a small, normally distributed value to each one beginning
    with component 24 (out of 30). When the inverse transform uses the altered components,
    the resulting values (`b`), a block of 398 samples, are no longer identical to
    the original. These augmented versions build the next block of the new dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The new training dataset is in `newx` and `newy`, but the order of the samples
    is not random because it was built in blocks. Therefore, we perform a final randomization
    before writing the train and test datasets to disk ([Listing 6-5](ch06.xhtml#ch06list05)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-5: Storing the augmented datasets*'
  prefs: []
  type: TYPE_NORMAL
- en: The histology training and test datasets are now ready for use. We applied randomness
    multiple times to scramble the order of the data and to alter the principal components
    to build augmented versions of the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '***Handwritten Digits***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the first great successes of the deep learning revolution involved correctly
    identifying objects in images. While the dataset we’ll build isn’t very advanced
    comparably, it is part of MNIST, a larger, workhorse dataset commonly used in
    machine learning. We’ll build a dataset consisting of handwritten 1s, 4s, 7s,
    and 9s. I selected these four digits because even humans often confuse one for
    another, so we might expect a machine learning model to do the same (time will
    tell).
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6-1](ch06.xhtml#ch06fig01) shows samples of each digit type.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/06fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-1: Sample digits, where 1s and 7s are often confused, as are 4s and
    9s*'
  prefs: []
  type: TYPE_NORMAL
- en: The images are 28×28-pixel grayscale, with each pixel an integer in [0, 255].
    We’ll work with the digits as 784-element vectors (28 × 28 = 784). I collected
    the digits and their labels in the files *mnist_data.npy* and *mnist_labels.npy*,
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: The raw digits dataset is relatively small, with 100 samples of each digit;
    we split the raw data to have 50 train and 50 test samples. We’ll augment each
    image multiple times to expand the size of the training set.
  prefs: []
  type: TYPE_NORMAL
- en: We used PCA to augment the histology data, but because we’re working with images
    here, we’ll apply basic image processing transformations to randomly produce slightly
    altered versions of each training image. In particular, we’ll rotate each image
    in the range [–3, 3] degrees; about 10 percent of the time, we’ll zoom the image
    to [0.8, 1.2] times its original size while maintaining a final size of 28×28
    pixels by cropping or embedding a smaller image inside a blank 28×28 image.
  prefs: []
  type: TYPE_NORMAL
- en: The code we need is in *build_mnist_dataset.py*. While it mirrors the code that
    built the histology dataset, differences include splitting the raw data 50/50
    between train and test, storing the unaugmented training data, and augmenting
    the training data 20 times instead of 10 times, resulting in an augmented training
    set of 4,200 samples (200 original plus 20 more for each original sample); see
    [Listing 6-6](ch06.xhtml#ch06list06).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-6: Augmenting the digit images*'
  prefs: []
  type: TYPE_NORMAL
- en: The original 200 training samples (`xtrn`, `ytrn`) are examined, one by one.
    First, we add the original image to the augmented output (`newx`, `newy`). Then,
    we add 20 augmented versions of the same image by making repeated calls to `augment`
    ➊. After adding the augmented images, we scramble the entire training set again
    to mix the order of the images ➋.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 6-7](ch06.xhtml#ch06list07) shows the code to augment images.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-7: Augmenting an image*'
  prefs: []
  type: TYPE_NORMAL
- en: The input image (`x`), a NumPy vector, is first reshaped into a 28×28-element
    two-dimensional array, `im`. Next, two `if` statements ask whether a random value
    is less than 0.5 or 0.1\. The first, executed 50 percent of the time, applies
    a random rotation of the image by some value in the range [–3, 3] degrees. Notice
    the use of `rotate` from `scipy.ndimage`. The `reshape=False` keyword forces `rotate`
    to return an output array that’s the same size as the input array.
  prefs: []
  type: TYPE_NORMAL
- en: The second `if` statement, executed 10 percent of the time, uses `zoom` to magnify
    the image by a random scale factor in [0.8, 1.2], meaning the zoomed image is
    anywhere from 80 to 120 percent the size of the original. The code after the call
    to `zoom` ensures the output image is still 28×28 pixels by either embedding the
    smaller image in a blank 28×28 image or selecting the central 28×28 pixels if
    magnifying beyond 100 percent. The newly augmented image is returned after unraveling
    it and transformed back into a 784-element vector.
  prefs: []
  type: TYPE_NORMAL
- en: The code in *build_mnist_dataset.py* stores the smaller, unaugmented training
    set and the augmented training set. The file *mnist_test.py* uses `sklearn`’s
    `MLPCLassifier`—which we’ll learn about soon—to train 40 models using the training
    sets, keeping the overall accuracy of each. The models use default values and
    a single hidden layer of 100 nodes. The mean accuracy for the unaugmented dataset
    was 87.3 percent, while augmented training data led to a mean overall accuracy
    of 90.3 percent, a statistically significant difference, thereby delivering evidence
    that the random augmentation process aids training models. It may seem tedious
    to spend this section detailing how the datasets are constructed, but it’s hard
    to overemphasize the importance randomness plays in the process. Dataset construction
    is so crucial to modern machine learning that competitions are held where the
    models are fixed and good dataset construction is required to produce winning
    results (search for “Data-Centric AI Competition”).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our datasets, let’s put them to the test.
  prefs: []
  type: TYPE_NORMAL
- en: '**Neural Networks**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *neural network* is a set of nodes that, layer by layer, successively transforms
    an input to an output. Network nodes accept multiple inputs and produce a single
    output, an operation sufficiently similar to the operation of a biological neuron
    that the name “neural network” has persisted. Neural networks are not artificial
    brains; rather, they are feed-forward, directed, acyclic *graphs*, a data structure
    commonly used in computer science.
  prefs: []
  type: TYPE_NORMAL
- en: The operation of the network transforms an input to an output; in other words,
    neural networks are a type of function, ***y*** = *f*(***x***; ***θ***). Training
    the neural network means locating ***θ***, the set of parameters causing the network
    to perform as desired.
  prefs: []
  type: TYPE_NORMAL
- en: '***Anatomy Analysis***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If a neural network is a set of nodes working in layers, then it makes sense
    to begin with a node. See [Figure 6-2](ch06.xhtml#ch06fig02).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/06fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-2: A neural network node*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data flows from left to right. The inputs (*x*), either the input to the network
    or the output of a previous network layer, are multiplied by *weights* (*w*) and
    summed along with a *bias* (*b*) before passing the total to an *activation* function
    (*h*) to produce the output, *a*. In symbols:'
  prefs: []
  type: TYPE_NORMAL
- en: '*a* = *h*(*w*[0]*x*[0] + *w*[1]*x*[1] + *w*[2]*x*[2] + *b*)'
  prefs: []
  type: TYPE_NORMAL
- en: The activation function is nonlinear, or some function beyond *x* to the first
    power. Modern networks often use *rectified linear unit (ReLU)* activation functions,
    which output the input unless the input is less than zero, in which case the output
    is zero, *h* = max(0, *x*).
  prefs: []
  type: TYPE_NORMAL
- en: A network layer consists of a collection of nodes that, collectively, receive
    the output of the previous layer as their inputs and produce new output, one per
    node, passed to the next layer. Each node in a layer receives each input; in graph
    terms, the network is *fully connected*.
  prefs: []
  type: TYPE_NORMAL
- en: Data flows through the network, layer by layer, to the output. In this way,
    the network maps input ***x*** to output ***y***. The output is often a vector,
    but can be a scalar, *y*.
  prefs: []
  type: TYPE_NORMAL
- en: Moving data through a neural network is most easily accomplished by representing
    the weights between layers as a matrix and the biases as a vector. This representation
    automatically applies each input to each node and activation function, thereby
    reducing the entire layer operation to a matrix multiplied by a vector plus another
    vector passed to a vector version of the activation function. Training means learning
    a set of matrices for the weights, one matrix per layer, and a set of bias vectors,
    one per layer.
  prefs: []
  type: TYPE_NORMAL
- en: The weights and biases, which live on the connections between the nodes of the
    layers, are the parameters of ***θ***; these are the things the network learns
    during training. This is analogous to fitting a curve, but in this case, the function
    is determined by the architecture of the network. Unlike curve fitting, training
    a neural network usually doesn’t involve reducing the error on the training set
    to zero. Instead, the goal is to coax the network to learn weights and biases
    that make the network generally applicable to new inputs. After all, the entire
    point of training the model is to use it with new, unknown inputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'A detailed discussion of neural network training is beyond our present scope,
    as our goal is to understand randomness’s role in the process. If you’re interested
    in learning more about neural networks, I recommend my book *Practical Deep Learning:
    A Python-Based Introduction* (2021), also available from No Starch Press. Remember
    that the training process produces a specific set of weights and biases that tailor
    the network to the problem at hand.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Randomness***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Randomness is critically important at the beginning of the training process,
    in the selection of the initial weights and biases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Training a neural network follows this general algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Randomly initialize the weights and biases of the network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pass a randomly selected subset of the training data through the network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a measure of the error between the network’s output and the desired output
    to update the weights and biases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat from step 2 until training is done (however decided).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this section, we’re concerned with step 1\. Steps 2 and 3 involve a *loss
    function*, a measure of the mistakes the network has made, and a two-step process
    to update the weights and biases: *backpropagation* and *gradient descent*. The
    former uses the chain rule from differential calculus to determine how each weight
    and bias value contributes to the error, and the latter uses the gradient formed
    from those measures to alter the weights and biases to minimize the loss function.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Initialization***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It was only in 2010–2012 that deep neural networks (with many layers) exploded
    on the scene. One of the factors contributing to this was the realization that
    previous algorithms for initializing the weights and biases of models were relatively
    poor; better options exist.
  prefs: []
  type: TYPE_NORMAL
- en: We will explore these options by employing the `MLPCLassifier` class from `sklearn`
    to implement a traditional neural network. *MLP* stands for *multilayer perceptron*,
    with “perceptron” being an old name for a neural network (I recommend searching
    for Frank Rosenblatt and his Perceptron machine—fascinating research that was
    not sufficiently appreciated in its time).
  prefs: []
  type: TYPE_NORMAL
- en: '**Initializing the Network**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The `MLPClassifier` class includes an internal method, `_init_coef`, which is
    responsible for assigning the initial weights and biases. We will subclass `MLPClassifier`
    and override this method, allowing us to alter the initialization approach while
    still taking advantage of everything else the `MLPClassifier` has to offer. Take
    a look at [Listing 6-8](ch06.xhtml#ch06list08).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-8: Overriding the initialization method*'
  prefs: []
  type: TYPE_NORMAL
- en: The subclass overrides scikit-learn’s approach ➋ with three other approaches.
    The method returns a weight matrix and a bias vector for a layer that has `fan_in`
    inputs and `fan_out` outputs. The `dtype` parameter specifies the data type, typically
    32- or 64-bit floating point.
  prefs: []
  type: TYPE_NORMAL
- en: By default, scikit-learn uses *Glorot initialization*. We get it by calling
    the superclass version of the method ➋. Glorot initialization depends on the number
    of inputs and outputs and is one of the initialization approaches leading to improved
    model performance. At least, that’s the claim. We’ll put it to the test.
  prefs: []
  type: TYPE_NORMAL
- en: Another modern initialization approach is *He initialization* ➎, which is suitable
    for networks using ReLU activation functions. He initialization depends on a matrix
    of samples from a normal distribution with a mean of 0 and a standard deviation
    of 1\. We get that here via the embedded `normvec` function ➊, which permits us
    to use our `RE` class. We’ll see precisely how momentarily.
  prefs: []
  type: TYPE_NORMAL
- en: We initialize classical neural networks through the use of small uniformly distributed
    ➌ or normally distributed ➍ random values. The first draws random samples from
    a uniform distribution, [–0.005, 0.005]. The second uses normally distributed
    samples scaled by 0.005\. Both approaches are intuitively reasonable, but, as
    we’ll see, they are not ideal.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `normal` function returns a normally distributed sample with a mean value
    of `mu` and a standard deviation of 1\. A normal distribution selects samples
    symmetrically around the mean; return to [Figure 1-1](ch01.xhtml#ch01fig01) on
    [page 4](ch01.xhtml#ch01fig01) as an example. NumPy provides a function to select
    samples from a normal distribution, but we want to use our `RE` class, so we need
    to define a function that creates normally distributed samples from the uniformly
    distributed samples `RE` returns. We can use the Box-Muller transformation introduced
    in [Chapter 1](ch01.xhtml):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0184-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here *u*[1] and *u*[2] are uniformly distributed samples in [0, 1), precisely
    what `RE` returns (how convenient!).
  prefs: []
  type: TYPE_NORMAL
- en: 'The code implementing `normal` requires explanation. Note the indentation on
    the final line: it’s not part of `normal`, but refers to it immediately after
    its definition.'
  prefs: []
  type: TYPE_NORMAL
- en: The Box-Muller transformation equations use a pair of uniform samples to produce
    a pair of normally distributed samples. While we can ask `RE` objects to return
    a pair of uniform samples, we want `normal` to return only one normally distributed
    sample when called. We can generate two samples and throw one away, or carefully
    try to preserve both. This way, each call to `normal` returns a single sample
    and generates new samples only when required. Accomplishing this requires `normal`
    to preserve state between calls. The Python way to do this is to use a class,
    but that seems a bit overkill. Instead, we’ll make use of the fact that Python
    functions are objects; we can add new attributes (member variables) to objects
    at will. We’ll define `normal` as a Python function and then immediately add a
    `state` variable to it initialized to `False`—the final line in [Listing 6-8](ch06.xhtml#ch06list08).
  prefs: []
  type: TYPE_NORMAL
- en: When we call `normal`, the `state` variable has a value, `False`. This value
    persists between calls because it’s an attribute of the `normal` function, which
    uses the value of `state` to decide whether to generate two new samples and return
    the first caching the second, or to return the second. If `state` is `True`, return
    the second sample, `z2`, after multiplying it by the desired standard deviation
    (`sigma`) and adding the mean value (`mu`). Then set `state` to `False`. If `state`
    is `False`, get two uniform samples from `rng` and use them to calculate two normal
    samples, `z1` and `z2`. Cache `z2` and return `z1`, properly scaled and offset.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use `Classifier` we create a neural network using scikit-learn and add two
    new attributes: `init_scheme` to specify the desired initialization scheme, and
    `rng`, an instance of `RE`, to allow access to the different randomness sources
    we’ve developed throughout the book.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Experimenting with Initialization**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s experiment with `Classifier` and neural network initialization. Along
    the way, we’ll set up a scikit-learn training session.
  prefs: []
  type: TYPE_NORMAL
- en: The code we need is in *init_test.py*. It loads the digits dataset created previously
    and trains 12 models using each initialization scheme. Training multiple models
    for each is essential because initialization is random; for example, we might
    get a bad dice roll for one initialization scheme when it’s actually a good approach.
    Averaging the results from multiple models lets us apply statistical tests.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 6-9](ch06.xhtml#ch06list09) shows the beginning of the main part of
    *init_test.py*.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-9: Setting up the initialization experiment*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The imports make the `Classifier` class available, along with `RE` and two
    statistical tests: the t-test and the *Mann-Whitney U* test, a nonparametric version
    of the t-test. *Nonparametric tests* make no assumptions about the data and are
    harder to satisfy. I often consider both together to account for the possibility
    that the t-test results are invalid because the data isn’t normally distributed—a
    fundamental assumption of the t-test.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we load the digits dataset, first the training (`xtrn`) followed by the
    test (`xtst`). We divide the data by 256 to map it from [0, 255] to [0, 1).
  prefs: []
  type: TYPE_NORMAL
- en: The following code paragraph accumulates the output of `Run` for initialization
    scheme 0\. The return value is the overall accuracy of a model using scikit-learn’s
    Glorot initialization. Similar code captures the accuracy for the other four initialization
    schemes.
  prefs: []
  type: TYPE_NORMAL
- en: We then transform the results for all schemes into means and standard errors
    before printing, as in [Listing 6-10](ch06.xhtml#ch06list010).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-10: Reporting the results*'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we run the statistical tests to compare one initialization scheme against
    another. Theoretically, we might expect initialization scheme 3 (He) to be the
    best performing, so we compare it (`init3`) with each of the others and report
    the corresponding p-values (the “u” is the p-value for the Mann-Whitney U test);
    see [Listing 6-11](ch06.xhtml#ch06list011).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-11: Running the statistical tests*'
  prefs: []
  type: TYPE_NORMAL
- en: The statistical tests, `ttest_ind` and `mannwhitneyu`, first return their respective
    test statistics and then their associated p-value. The p-value tells us the probability
    that we’ll measure the difference in the means between the two sets of accuracies,
    given the two sets are from the same distribution. The smaller the p-value, the
    less likely the two sets are from the same distribution, thereby giving us confidence
    that the difference observed is real.
  prefs: []
  type: TYPE_NORMAL
- en: '**Training the Network**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The code to configure and train a neural network is in the `Run` function, as
    in [Listing 6-12](ch06.xhtml#ch06list012).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-12: Training a neural network*'
  prefs: []
  type: TYPE_NORMAL
- en: Here’s where we begin to appreciate the power of scikit-learn. The arguments
    to `Run` include which initialization scheme to use, [0, 3], followed by the train
    and test datasets. First, we create the neural network by creating an instance
    of `Classifier`, our subclass of scikit-learn’s `MLPClassifier`. By default, the
    neural network uses a ReLU activation function, which is what we want. It also
    trains until training no longer improves things or `max_iter` passes through the
    entire training set. Each pass through is known as an *epoch*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `hidden_layer_sizes` keyword defines the architecture of the model. We
    know the input has 784 elements and the output 4 because there are four classes,
    the digits 1, 4, 7, and 9\. The layers between the input and output are hidden;
    we’re specifying two: the first with 100 nodes and the second with 50.'
  prefs: []
  type: TYPE_NORMAL
- en: Before training, we need to set the initialization scheme (`init_scheme`) and
    define `rng`, an instance of `RE`, using the default of PCG64 and floating-point
    values in [0, 1).
  prefs: []
  type: TYPE_NORMAL
- en: Train the neural network with `clf.fit(xtrn,ytrn)`, in which the `fit` method
    accepts the input vectors (`xtrn`) and the associated labels (`ytrn`). When the
    method returns, the model is trained and has found values for all the weights
    and biases (***θ***).
  prefs: []
  type: TYPE_NORMAL
- en: '**Evaluating the Network**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When given the test data (`xtst`), `predict` generates a set of predicted class
    labels, `pred`—a vector of the same length as `ytst`, the known class labels.
    We compare the two to evaluate the model by building a *confusion matrix*. The
    rows of the confusion matrix represent the known, true class labels. The columns
    are the model’s assigned labels. The matrix elements are counts of the number
    of times each possible pairing of the true label and assigned label happened.
    A perfect classifier will always assign correct labels, meaning the confusion
    matrix will be diagonal. Any counts off the main diagonal represent errors.
  prefs: []
  type: TYPE_NORMAL
- en: The `Confusion` function generates a confusion matrix, and overall accuracy,
    from a set of known and predicted labels; see [Listing 6-13](ch06.xhtml#ch06list013).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-13: Creating a confusion matrix*'
  prefs: []
  type: TYPE_NORMAL
- en: The confusion matrix (`cm`) is a 4×4 matrix because there are four classes.
    The most important line updates `cm` by indexing first by the known class label
    (`y`) and then by the assigned class label (`p`). Adding one counts each time
    that particular pairing of the true class label and assigned label occurs.
  prefs: []
  type: TYPE_NORMAL
- en: The overall accuracy is either the number of times the known and assigned labels
    matched or the sum along the main diagonal divided by the sum of all matrix elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running *init_test.py* takes a few minutes. My run produced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The first block displays the mean accuracy over the 12 models for each initialization
    scheme (mean ± SE). Glorot and He initialization averaged 92.7 and 92.5 percent,
    respectively. The older uniform and normal initialization strategies achieved
    90.0 and 90.1 percent, respectively. These are large differences, but are they
    statistically significant? For that, look at the second block of results.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing He initialization (`init3`) with Glorot (`init0`) returns p-values
    of about 0.5 for both the t-test and Mann-Whitney U. Such p-values strongly indicate
    that there is no difference between either approach.
  prefs: []
  type: TYPE_NORMAL
- en: Now, look at the p-values comparing He initialization with the older methods.
    They are virtually zero, implying the difference in mean accuracy is very likely
    real—He and Glorot initialization both lead to significantly better performing
    models. Modern deep learning is vindicated. While there was never any doubt, it’s
    beneficial to confirm directly rather than take it purely on faith.
  prefs: []
  type: TYPE_NORMAL
- en: '**Extreme Learning Machines**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An *extreme learning machine* is a simple, single, hidden-layer neural network.
    What distinguishes an extreme learning machine from a traditional neural network
    is the source of the weights and biases.
  prefs: []
  type: TYPE_NORMAL
- en: To map an input vector through the first hidden layer of a neural network involves
    a weight matrix, ***W***, and a bias vector, ***b***
  prefs: []
  type: TYPE_NORMAL
- en: '***z*** = *h*(***Wx*** + ***b***)'
  prefs: []
  type: TYPE_NORMAL
- en: where ***x*** and ***z*** are vectors, and *h* is the activation function that
    accepts a vector input and produces a vector output.
  prefs: []
  type: TYPE_NORMAL
- en: In a traditional neural network, ***W*** and ***b*** are learned in the training
    process. In an extreme learning machine, ***W*** and ***b*** are generated randomly,
    with no regard for the training data. Random matrices are (sometimes) capable
    of mapping inputs, like the digit images as vectors, to a new space where it’s
    easier to separate the classes.
  prefs: []
  type: TYPE_NORMAL
- en: If we use the equation to map all training data, the output of the hidden layer
    (***z***) becomes a matrix (***Z***) with as many rows as there are training samples
    and as many columns as there are nodes in the hidden layer. In other words, the
    random ***W*** matrix and ***b*** bias vector have produced a new version of the
    training data, ***Z***.
  prefs: []
  type: TYPE_NORMAL
- en: The random weight matrix and bias vector link the input and the hidden layer.
    To finish building the neural network, we need a weight matrix between the hidden
    layer’s output and the model’s output; there is no bias vector in this case. Learning
    happens here, but we need to take a detour to see it.
  prefs: []
  type: TYPE_NORMAL
- en: The training dataset consists of input samples and associated class labels,
    [0, 3]. Many machine learning models don’t use integer class labels, but transform
    the labels into *one-hot vectors*. For example, if there are four classes, the
    one-hot vector has four elements, all 0 except for the element corresponding to
    the class label, which is 1\. If the class label is 2, then the one-hot vector
    is {0, 0, 1, 0}. Likewise, if the class label is 0, the one-hot vector is {1,
    0, 0, 0}. To finish building the extreme learning machine, we need the training
    set class labels in this form. I assume that the labels are so transformed for
    the remainder of this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'As one-hot vectors, the class labels become a matrix, ***Y***, with as many
    rows as there are training samples and as many columns as there are classes. A
    linear mapping from the output of the hidden layer, ***Z***, to the known labels
    (as one-hot vectors), ***Y***, uses a matrix, ***B***:'
  prefs: []
  type: TYPE_NORMAL
- en: '***Y*** = ***BZ***'
  prefs: []
  type: TYPE_NORMAL
- en: We want to find ***B*** as the second weight matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Because we know ***Z*** by pushing the training data through the hidden layer
    and ***Y***, the known labels, we generate ***B*** via
  prefs: []
  type: TYPE_NORMAL
- en: '***YZ***^(–1) = ***B***'
  prefs: []
  type: TYPE_NORMAL
- en: where ***Z***^(–1) is the inverse of the matrix ***Z***. Multiplying by the
    inverse of a matrix is akin to multiplying by the reciprocal of a scalar value;
    they cancel each other. To find the inverse of ***Z***, we need the Moore-Penrose
    pseudoinverse, which NumPy provides in its linear algebra module, `linalg`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now have all we need to build the extreme learning machine:'
  prefs: []
  type: TYPE_NORMAL
- en: Select a weight matrix, ***W***, and bias vector, ***b***, at random.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pass the training data through the first hidden layer, ***Z*** = *h*(***WX***
    + ***b***), where ***X*** and ***Z*** are now matrices, one row for each training
    sample.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the output weight matrix, ***B*** = ***YZ***^(–1), using the pseudoinverse
    of ***Z***, the output of the hidden layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use ***W***, ***b***, and ***B*** as the weights and biases of the extreme learning
    machine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is rather abstract. Let’s make it concrete in code.
  prefs: []
  type: TYPE_NORMAL
- en: '***Implementation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The file *elm.py* implements an extreme learning machine and applies it to the
    digits dataset. [Listing 6-14](ch06.xhtml#ch06list014) shows the `train` function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-14: Defining an extreme learning machine*'
  prefs: []
  type: TYPE_NORMAL
- en: The first line sets `inp` to the number of features in the training data, here
    784\. The next two lines define the smallest training feature value (`m`) and
    the difference between that and the largest (`d`).
  prefs: []
  type: TYPE_NORMAL
- en: The following two lines generate the random weight matrix and bias vector, ***W***i
    (`w0`) and ***b*** (`b0`), by randomly sampling in the range of the training data,
    [*m*, *m* + *d*]. Again, ***W*** and ***b*** are completely random, but fixed
    once selected.
  prefs: []
  type: TYPE_NORMAL
- en: The final piece of the extreme learning machine is ***B*** (`w1`), which is
    found by passing the training data through the hidden layer
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: where `activation` is the selected activation function (*h*()).
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, to define ***B***, we multiply ***YZ***^(–1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The return value for the function is the defined and trained extreme learning
    machine: `(w0,b0,w1)`. Let’s take it for a test drive.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Testing***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The file *elm.py*, from which we extracted `train`, trains an extreme learning
    machine to classify the digits dataset using a user-supplied number of nodes in
    the hidden layer. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We use the Mersenne Twister pseudorandom generator to build a machine with 200
    hidden layer nodes. The output shows the confusion matrix and the overall accuracy,
    83.5 percent. The confusion matrix is almost diagonal, which is a good sign.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s scrutinize the confusion matrix. The rows represent the true class labels
    from top to bottom, ones, fours, sevens, and nines. The columns, from left to
    right, are the model’s assigned class label (we’ll see how soon). Looking at the
    top row, of the 50 ones in the test dataset, the model called a one a one 49 times,
    but once called it a seven.
  prefs: []
  type: TYPE_NORMAL
- en: The model had the most difficulty with nines, the final row of the confusion
    matrix. The model got it right 37 out of 49 times, but it called it a seven 6
    times and a four 5 times. Only once did the model confuse a nine for a one.
  prefs: []
  type: TYPE_NORMAL
- en: The `train` function creates the extreme learning machine. To use it, we need
    `predict`, as shown in [Listing 6-15](ch06.xhtml#ch06list015).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-15: Prediction with an extreme learning machine*'
  prefs: []
  type: TYPE_NORMAL
- en: We pull the weight matrices and bias vector from the supplied model, and then
    pass the test data through the hidden layer and, finally, the output layer. The
    `activation` variable is set to the specific activation function currently in
    use—by default, the ReLU. We’ll experiment with different activation functions
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The output of `predict` is a two-dimensional matrix with as many rows as are
    in `xtst` (200) and as many columns as there are classes (4). For example, the
    output of predict for the first test sample (`xtst[0]`) is
  prefs: []
  type: TYPE_NORMAL
- en: 0.19551782, 0.90971894, 0.05398019, –0.06542743
  prefs: []
  type: TYPE_NORMAL
- en: 'and the first known test label, as a one-hot vector, is:'
  prefs: []
  type: TYPE_NORMAL
- en: 0, 1, 0, 0
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice the largest value in the model’s output vector is at index 1, as is
    the largest for the one-hot label. In other words, the first test sample belongs
    to class 1 (four), and the model successfully predicted class 1 as the most likely
    class. The last output value is negative: the model is not outputting a probability,
    but a decision function value where the largest is the most likely class label,
    even if we don’t have a true probability associated with that value.'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, to construct a confusion matrix, we will need code like [Listing
    6-16](ch06.xhtml#ch06list016).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-16: Building a confusion matrix for an extreme learning machine*'
  prefs: []
  type: TYPE_NORMAL
- en: The `confusion` function returns the confusion matrix and overall accuracy,
    but instead of directly using the values in `ytst` and `prob`, we apply NumPy’s
    `argmax` function to return the index of the largest value in the four-element
    vectors.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 6-17](ch06.xhtml#ch06list017) shows the remainder of *elm.py*, which
    loads the digit data-sets, scaling them by 256, and then trains and tests the
    extreme learning machine with three lines of code.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-17: Training and testing an extreme learning machine*'
  prefs: []
  type: TYPE_NORMAL
- en: The `nodes` parameter is the number of nodes in the hidden layer as read from
    the command line.
  prefs: []
  type: TYPE_NORMAL
- en: How sensitive is the extreme learning machine to the number of nodes in the
    hidden layer? That’s a good question.
  prefs: []
  type: TYPE_NORMAL
- en: By default, the code in *elm.py* uses a ReLU activation function. However, the
    file defines several other activation functions. In this section, we’ll explore
    each in combination with differing numbers of hidden layer nodes to find whether
    there’s a best combination.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ReLU activation function uses NumPy’s `maximize` function, which returns
    the largest of the two arguments, element by element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We’re not constrained to use only the ReLU. Classically, neural networks made
    heavy use of the sigmoid and hyperbolic tangent functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Both of these functions return S-shaped curves. I added a factor of 0.01 to
    scale *x* in the sigmoid and hyperbolic tangent. This is not usually done, but
    it was necessary here to prevent overflow errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'For fun, I defined several other activation functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Let’s test the activation functions as the number of nodes in the hidden layer
    is varied from 10 to 400\. The code is in *elm_test.py*. It makes use of the `train`,
    `predict`, and `confusion` functions. The main loop looks like [Listing 6-18](ch06.xhtml#ch06list018).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-18: Testing activation functions and hidden layer sizes*'
  prefs: []
  type: TYPE_NORMAL
- en: Fifty extreme learning machines are trained for each combination of activation
    function and hidden layer size, tracking the overall accuracy (`acc`). Notice
    the assignment of `act` to `activation`. Functions may be freely assigned to variables
    in Python and then used when the variable is referenced (as in `train`).
  prefs: []
  type: TYPE_NORMAL
- en: Run *elm_test.py* by passing it a randomness source (I used MT19937). When it
    finishes, run *elm_test_results.py* to parse the output and generate a plot like
    that of [Figure 6-3](ch06.xhtml#ch06fig03) showing the mean accuracy by hidden
    layer size and activation function. Error bars are present but small.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/06fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-3: Extreme learning machine performance as a function of the hidden
    layer size and activation function*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6-3](ch06.xhtml#ch06fig03)’s most obvious statement is that *y* = *x*³
    is a lousy activation function, as it always results in inferior models compared
    to the others. Another interesting observation is that the activation functions
    follow the same shape: a rapid increase in model accuracy as the number of nodes
    in the hidden layer increases, followed by a maximum and a slower decline. The
    difference between activation functions is slight, especially near the maximum
    of 100 hidden nodes; however, the hyperbolic tangent came out on top in this run.
    In fact, `tanh` wins for most runs, so it’s fair to say that for this particular
    dataset, an extreme learning machine using `tanh` and 100 nodes in the hidden
    layer is the way to go.'
  prefs: []
  type: TYPE_NORMAL
- en: The identity activation function, *f*(***x***) = ***x***, eschews nonlinearity;
    all the performance comes from the linear top layer mapping the hidden layer output
    to the predictions per class.
  prefs: []
  type: TYPE_NORMAL
- en: '***Reckless Swarm Optimizations***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An extreme learning machine’s attraction is the incredible speed with which
    a model is trained compared to all the calculations necessary to train a traditional
    neural network of the same size. Sure, the first model might not be that good,
    but trying a few times in a row and keeping the best-performing model seems a
    reasonable thing to do. I can imagine a scenario where an autonomous system might
    want to train a model quickly in response to rapidly changing input data.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the random part of the extreme learning machine—that is, the weight
    matrix and bias vector from the input to the hidden layer—made me wonder: Might
    we be able to learn the weight matrix and bias vector via a swarm optimization
    instead? Would this work, and if so, might it be any better than the random versions?
    My thought is clearly missing the point that extreme learning machines are meant
    to use random weights and biases, but I want to know if swarm optimization might
    prove helpful, even if vastly more computationally intensive than traditional
    neural network training.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The true challenge is the dimensionality of the problem. Our inputs are 784-element
    vectors. We learned that 100 nodes in the hidden layer seems a good thing to have,
    so the total dimensionality of the weight matrix and bias vector is:'
  prefs: []
  type: TYPE_NORMAL
- en: 784 × 100 + 100 = 78,500
  prefs: []
  type: TYPE_NORMAL
- en: We’ll be asking the swarms to search a space of 78,500 dimensions to come up
    with a good position, one that leads to a model with the highest accuracy. That’s
    a tall order.
  prefs: []
  type: TYPE_NORMAL
- en: The code I experimented with is in *elm_swarm.py*. I won’t walk through it,
    but you’ll see it follows similar optimization code from earlier chapters. The
    objective function uses each particle position as a weight matrix and bias vector,
    and then learns the output weight matrix and evaluates the model on the test set
    to produce an overall accuracy. Therefore, each call to the `Evaluate` method
    results in a trained and tested model.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the code, use a command line like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Here, differential evolution (`de`) searches for a model with `tanh` activation
    functions and 100 hidden layer nodes. The swarm has 20 particles and runs for
    60 iterations before reporting the final confusion matrix and accuracy. The best
    model is stored in the file *de.pkl*. The current best accuracy is shown on each
    iteration, so you can watch the swarm learn. Run *elm_swarm.py* without arguments
    to see all options.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the previous command produced the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The per-iteration best accuracy is shown along with the mean distance between
    the particles in the swarm. If the swarm is converging, this distance shrinks
    during the search, as it does here. The distance between two swarm particles uses
    the formula to find the distance between two points in two-dimensional or three-dimensional
    space
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0196-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: but extended to 78,500 dimensions. The result is still a scalar.
  prefs: []
  type: TYPE_NORMAL
- en: After 60 iterations, the swarm located a weight and bias vector leading to a
    93 percent overall accuracy on the held-out test set. There were four swarm best
    updates. A second run, using GWO for 600 iterations, found a model with 94 percent
    overall accuracy. In that run, the swarm collapsed from an initial inter-particle
    distance of around 90 to less than 1 by the time it reached iteration 600\. There
    were eight swarm best updates.
  prefs: []
  type: TYPE_NORMAL
- en: I conducted runs of *elm_swarm.py* for all algorithms, five runs for each. [Table
    6-1](ch06.xhtml#ch06tab01) displays the resulting average accuracies.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-1:** Average Model Accuracies for Each Optimization Algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: '| Algorithm | Accuracy (mean ± SE) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| GWO | 0.9260 ± 0.0087 |'
  prefs: []
  type: TYPE_TB
- en: '| Differential evolution | 0.9200 ± 0.0016 |'
  prefs: []
  type: TYPE_TB
- en: '| Bare-bones PSO | 0.9190 ± 0.0019 |'
  prefs: []
  type: TYPE_TB
- en: '| Jaya | 0.9180 ± 0.0034 |'
  prefs: []
  type: TYPE_TB
- en: '| GA | 0.9170 ± 0.0058 |'
  prefs: []
  type: TYPE_TB
- en: '| RO | 0.9170 ± 0.0025 |'
  prefs: []
  type: TYPE_TB
- en: '| PSO | 0.9160 ± 0.0024 |'
  prefs: []
  type: TYPE_TB
- en: The results are not statistically significantly different, but the ranking from
    best to worst is typical (except PSO). The GWO standard error of the mean is larger
    because one search found a model with an accuracy of 95.5 percent, the highest
    I encountered.
  prefs: []
  type: TYPE_NORMAL
- en: How many runs of *elm.py* do we need, on average, to find a model that meets
    or exceeds a given accuracy? The file *elm_brute.py* generates extreme learning
    machine after extreme learning machine, for up to a given maximum number of iterations,
    attempting to find a model that meets or exceeds the specified test set accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Structurally, *elm_brute.py* is a tweak to *elm.py* to do the model creation
    and testing in a loop and then report the performance if successful or note that
    it wasn’t able to meet the accuracy threshold. Running *elm_brute.py* for different
    thresholds, 10 runs for each with a maximum of 2,000 iterations, produced [Table
    6-2](ch06.xhtml#ch06tab02).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-2:** Number of Models Tried to Achieve a Given Accuracy'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Target accuracy** | **Mean** | **Min** | **Max** | **Successes** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0.70 | 1 | 1 | 1 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.75 | 1 | 1 | 1 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.80 | 1 | 1 | 1 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.85 | 2.2 | 1 | 6 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.90 | 147.2 | 15 | 270 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.91 | 504.2 | 87 | 1,174 | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.915 | 858.4 | 69 | 1,710 | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| 0.92 | 788.3 | 74 | 1,325 | 4 |'
  prefs: []
  type: TYPE_TB
- en: The first column shows the target accuracy. Any model meeting or exceeding this
    accuracy is considered a success. The mean number of models needed to find one
    at or above the threshold comes next, followed by the minimum and maximum numbers.
    Finally, the number of successful runs at that threshold, out of 10, is shown.
  prefs: []
  type: TYPE_NORMAL
- en: Targets at or below 85 percent are easy to find, averaging a little more than
    two searches. At the 90 percent threshold, however, there is a sudden jump requiring
    the creation of about 150 models on average. The minimum of 15 and the maximum
    of 270 implies a long tail to the distribution of the number of models tested.
  prefs: []
  type: TYPE_NORMAL
- en: Above 90 percent, the mean number of models increases again, rather dramatically,
    including long tails of up to 1,710 for 91.5 percent. The number of successful
    searches also goes down, implying that 2,000 iterations were an insufficient maximum
    in most cases to find a model with 92 percent or greater accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: We now have two different approaches. The first blindly tries to find a suitable
    model by randomly assigning weights and biases and then testing over and over—a
    brute force approach. The second uses a principled swarm search to locate the
    weights and biases, and is more successful. For example, the previous swarm approach
    used 1,220 candidate models to find one with an accuracy of 93 percent, and a
    run of *elm_brute.py* needed 21,680 candidates to find a model with an accuracy
    of 93.5 percent.
  prefs: []
  type: TYPE_NORMAL
- en: It’s impressive that the swarm techniques can find good models while searching
    such a high-dimensional space. The approach isn’t practical without seriously
    reengineering the code to be orders of magnitude faster, but that we achieved
    any level of success is fascinating.
  prefs: []
  type: TYPE_NORMAL
- en: Extreme learning machines are a prime example of randomness in action. Their
    structure invites experimentation, so please experiment. If you discover something
    interesting, let me know. In the meantime, let’s move on to our last example of
    randomness in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: '**Random Forests**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *random forest* is a collection (or ensemble) of *decision trees*. We’ll define
    these terms shortly. The ideas behind random forests were developed in the 1990s
    and brought together by Breiman in his appropriately named 2001 paper, “Random
    Forests.” Hence they have some history behind them. Decision trees themselves
    are even older, dating from the early 1960s. Let’s begin there.
  prefs: []
  type: TYPE_NORMAL
- en: '***Decision Trees***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A decision tree is a machine learning model consisting of a series of yes or
    no questions asked not of a person, but of a feature vector. The sequence of answers
    for that feature vector moves through the tree from the root node to a leaf, a
    terminal node. We then assign the class label associated with the leaf to the
    input feature vector.
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees have the benefit of interpretability—by their very operation,
    they explain themselves. Neural networks can’t easily explain themselves, an issue
    that’s given birth to *Explainable AI (XAI)*, a subfield of modern deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees are best understood with an example, for which we’ll use a tiny
    dataset of two measurements of three species of iris flowers. The dataset is two-dimensional;
    there are two features with 150 samples total. We’ll use the first 100 for training
    the decision tree and the remaining 50 for testing. As the dataset has only two
    dimensions, we can plot its features by class; see [Figure 6-4](ch06.xhtml#ch06fig04).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/06fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-4: The iris features*'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 6-4](ch06.xhtml#ch06fig04), circles represent class 0, squares class
    1, and diamonds class 2\. Class 0 is well separated from the other two classes,
    which overlap considerably. Therefore, we might expect the decision tree classifier
    to do well with class 0 and be most often confused by class 1 and class 2.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s build a decision tree for this dataset. The code I’m using, which also
    generates [Figure 6-4](ch06.xhtml#ch06fig04), is in the file *iris_tree.py*. It
    uses scikit-learn’s `DecisionTreeClassifier` class and limits the depth of the
    tree to three. As with most scikit-learn classes, the `fit` method uses the training
    data and the `predict` method uses the test data. The output of *iris_tree.py*
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This is a confusion matrix and has an overall accuracy of 74 percent. Class
    0 was perfectly classified, 18 out of 18, while the decision tree labeled most
    of class 1 as class 2.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6-5](ch06.xhtml#ch06fig05) shows what the tree looks like.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/06fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-5: The iris decision tree*'
  prefs: []
  type: TYPE_NORMAL
- en: The tree’s root is at the top. Each box is a node, and the first line of each
    box contains a question—in this case, “Is *x*[0] ≤ 5.45?” or is feature 0 less
    than or equal to 5.45? If the answer is yes, move to the left; otherwise, move
    to the right. Then consider the question in that node. Continue this process until
    you reach a *leaf*, or a node with no children.
  prefs: []
  type: TYPE_NORMAL
- en: The value part of a node indicates the number of training samples of each class
    present at that node. For example, the leftmost leaf node has `value=[1,0,0]`,
    meaning only one member of class 0 is present at this node. Therefore, any path
    leading to this node assigns class 0 to the input feature vector. Likewise, the
    leaf immediately to the right is labeled `[0,5,0]`, so feature vectors leading
    to this node are assigned to class 1\. Finally, the leaf second from the right
    is labeled `[1,18,24]`, meaning one class 0 training sample landed in this node,
    as did 24 samples of class 2\. The majority rules when more than one class is
    represented, so this node assigns feature vectors to class 2.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two other lines in each node: samples and the Gini index. The former
    is the sum of the values vector, the number of training samples present at that
    node. The decision tree algorithm uses the Gini index to split nodes; we won’t
    go into details here, but you can check out the scikit-learn documentation to
    learn more.'
  prefs: []
  type: TYPE_NORMAL
- en: Classically, decision trees are deterministic; the same dataset generates the
    same decision tree. Scikit-learn modifies this behavior somewhat, but by fixing
    the pseudorandom seed, which I do recklessly in *iris_tree.py*, we can generate
    a repeatable tree. We’ll assume going forward that decision trees are entirely
    deterministic.
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees explain themselves. For example, an input feature vector of {5.6,
    3.3} will traverse the path in [Figure 6-6](ch06.xhtml#ch06fig06).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/06fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-6: A path through the decision tree*'
  prefs: []
  type: TYPE_NORMAL
- en: This is an example of class 0 because feature 0 is between 5.45 and 5.75, and
    feature 1 is greater than 3.25.
  prefs: []
  type: TYPE_NORMAL
- en: The deterministic nature of decision trees led to the development of random
    forests. The decision tree for a particular dataset either works well or doesn’t;
    they tend to *overfit* the data, being too sensitive to the particulars of the
    training set and not sensitive enough to the general characteristics of the type
    of data the model might encounter—at least not as sensitive as we’d like. In other
    words, they might do well on the training set and less well on everything else.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s learn how we can curtail the decision tree’s penchant for overfitting
    by introducing randomness.
  prefs: []
  type: TYPE_NORMAL
- en: '***Additional Randomness***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Three techniques turn a solitary decision tree into a forest of decision trees,
    or a random forest. The first is *bagging*, which generates many new datasets
    by sampling the original dataset with replacement (called *bootstrapping*). The
    second uses random subsets of the available features for each new, bootstrapped
    dataset, and the third is *ensembling*, the creation of multiple models that somehow
    vote or otherwise combine their output. Let’s review these techniques before putting
    them together to grow random forests.
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating Datasets with Bagging**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: I have a dataset with 100 samples, feature 0 from the iris dataset. The values
    are measurements from a parent distribution, a population from which this particular
    collection of values is a sample. The sample has a mean value of 5.85, which we
    can take as an *estimate* of the population mean, but not necessarily the actual
    value. Over what range of values do we expect, with 95 percent confidence, to
    find the actual population mean?
  prefs: []
  type: TYPE_NORMAL
- en: We have only one set of 100 values, but we’ll use bootstrapping to generate
    another set, taken randomly from the first and allowing for the possibility of
    selecting the same sample more than once. This is known as “sampling with replacement.”
    We now have two collections of samples, both plausibly from the parent population.
    We can repeat this process many times to generate many sets, each of which has
    a mean value. Then, with the collection of mean values, we use NumPy’s `quantile`
    function to estimate the 95 percent confidence range.
  prefs: []
  type: TYPE_NORMAL
- en: The file *bootstrap.py* implements this process. It loads the iris training
    set, keeping only feature 0, and then generates 10,000 bootstrap datasets, keeping
    the mean value of each. To get the 95 percent confidence interval, we need to
    know the 2.5 percent and 97.5 percent quantile values. A quantile provides the
    percentiles for a dataset. The 50th percentile is the median, the middle value
    once the data has been sorted. The 25th percentile means that 25 percent of the
    data is below this value, while the 75th percentile means that 75 percent of the
    data is under this value.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the 95 percent confidence range, we want the values where 95 percent
    of the data is between them, implying we need to exclude 5 percent of the data:
    the bottom and top 2.5 percents. For that, we need the 2.5th and 97.5th percentiles,
    both of which we find courtesy of NumPy. Let’s review the code, shown in [Listing
    6-19](ch06.xhtml#ch06list019).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-19: Bootstrapping confidence intervals*'
  prefs: []
  type: TYPE_NORMAL
- en: First, load the iris training data, keeping feature 0 (`x`). Then generate 10,000
    bootstrap versions of `x` tracking the mean of each. Use `quantile` to find the
    lower (`L`) and upper (`U`) confidence interval bounds before reporting them.
  prefs: []
  type: TYPE_NORMAL
- en: The `bootstrap` function creates `n`, a vector of the same length as `x` where
    each value is an integer in the range 0 through `len(x)-1`. These are indices
    into `x` where it’s possible the same index appears more than once—a sample with
    replacement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each run of *bootstrap.py* produces a slightly different range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This output indicates that the true population mean is, with 95 percent confidence,
    between 5.694 and 6.009\. Without the bootstrap process, we couldn’t know this
    range from a single set of measurements. If we made assumptions about the shape
    of the distribution, that it’s normal or follows a t-distribution, then we could
    make an estimate; by bootstrapping, we don’t need to assume normally distributed
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping is a helpful technique to get confidence intervals when building
    random forests because each bootstrapped dataset is a plausible collection of
    measurements. In that sense, the bootstrapped datasets are newly acquired datasets
    for training a model. Bagging is the process of using bootstrapped datasets to
    train multiple decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: '**Combining Models with Ensembling**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Bagging helps because each decision tree is trained on a slightly different
    dataset; anything causing overfitting in one training set is hopefully compensated
    for in another.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll make an ensemble of decision trees with bagging, in which we train multiple
    models using bootstrapped datasets and average their predictions to see if it
    improves results over ordinary decision trees. We’ll use the histology dataset
    from the beginning of this chapter. The file *bagging.py* trains a user-supplied
    number of decision trees, each with a different bootstrapped version of the histology
    dataset. We’ll then apply each model to the histology test data and average the
    resulting predictions to produce an ensemble output. Averaging model output is
    one approach to ensembling; we’ll use another, voting, later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the relevant code in [Listing 6-20](ch06.xhtml#ch06list020).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-20: Using bagging to build an ensemble of decision trees*'
  prefs: []
  type: TYPE_NORMAL
- en: The code defines a `Bootstrap` function, loads the histology train and test
    datasets, creates and trains multiple decision trees using bootstrapped training
    sets, and makes predictions on the test data before averaging the results to create
    a final, aggregate set of predictions.
  prefs: []
  type: TYPE_NORMAL
- en: The first `for` loop creates a decision tree object (that is, an instance of
    `DecisionTreeClassifier`). If `bag` is true, it trains the tree using a bootstrapped
    version of the training data. If `bag` is false, it uses the entire dataset each
    time (no bagging). The `Bootstrap` function needs to select both the feature vectors
    and the proper label.
  prefs: []
  type: TYPE_NORMAL
- en: The next loop creates `preds`, a list of predictions for each decision tree.
    Each tree was trained on a different bootstrapped dataset, so if `bag` is true,
    the predictions will have slightly different errors. Turning `preds` into a NumPy
    array lets us average down the rows to get a single vector that’s the average
    of all tree outputs for each test sample (the columns). We want to assign a class
    label, 0 or 1, to the average, so we add 0.5 and then use `floor` to round to
    the nearest integer (0 or 1).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, a call to `Confusion` builds the confusion matrix and overall accuracy,
    which later code (not shown) displays.
  prefs: []
  type: TYPE_NORMAL
- en: 'One run of *bagging.py*, using a collection of 60 trees and bagging, returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The overall ensemble accuracy was 92.98 percent. The accuracies of the first
    six decision trees are also shown. Your runs will produce different output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the code again with no bagging returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This is a significantly worse outcome.
  prefs: []
  type: TYPE_NORMAL
- en: I ran *bagging.py* 30 times, first with bagging and again without. The respective
    mean accuracies were 92.73 percent and 89.77 percent, with a p-value of less than
    10^(–10) using the Mann-Whitney U test. Bagging has a dramatic effect on the quality
    of the models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bootstrapped training sets and ensembling make up two-thirds of a random forest.
    Now let’s add the remaining third: random feature sets.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Using Random Feature Sets**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The final ingredient in a random forest is to use random subsets of the available
    features. Traditionally, the number of features we’ll use is the square root of
    the available features. For example, the histology dataset has 30 features, so
    we’ll use 5, selected randomly, whenever we want a bootstrapped dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Select a bootstrapped dataset using five randomly selected features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train a decision tree using this dataset. Keep it and the specific set of features
    selected (for testing).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat step 1 and step 2 for each tree in the forest.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply each tree to the test data using only the features that the tree expects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Average the results across the test set to get the final predictions from the
    random forest.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In code, adding random feature selection is only a minor tweak to the bagging
    example; take a look at *forest.py*. [Listing 6-21](ch06.xhtml#ch06list021) shows
    the relevant changes from *bagging.py*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 6-21: Implementing a random forest*'
  prefs: []
  type: TYPE_NORMAL
- en: First, we must modify `Bootstrap` to select not only a random sampling of the
    training set (`n`) but also a random set of features (`nf` leading to `m`). The
    particular features extracted must be returned so we can use them at test time.
  prefs: []
  type: TYPE_NORMAL
- en: The second paragraph trains the trees as before, but drags `m` along for the
    ride. Finally, at test time, we apply each tree to `xtst` after keeping only the
    proper subset of features. The output of *forest.py* is identical to that of *bagging.py*,
    minus the first six individual tree accuracies.
  prefs: []
  type: TYPE_NORMAL
- en: I ran the code 30 times using 60 trees, as before, to get the mean accuracies
    in [Table 6-3](ch06.xhtml#ch06tab03). I’ve included previous mean accuracies to
    show the improvement as each phase of the random forest is added.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-3:** Mean Accuracy by Model Type'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Mean accuracy** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| No bagging | 89.47% |'
  prefs: []
  type: TYPE_TB
- en: '| Bagging, ensembling | 92.98% |'
  prefs: []
  type: TYPE_TB
- en: '| Bagging, ensembling, random features | 95.25% |'
  prefs: []
  type: TYPE_TB
- en: All random forest steps combined led to a significant improvement over a simple
    decision tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you might expect, scikit-learn also supports random forests via the `RandomForestClassifier`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The `RandomForestClassifier` class supports all three tricks plus additional
    tricks; see the scikit-learn documentation. Training 30 instances of `RandomForestClassifier`
    using 60 trees and all defaults results in a mean accuracy of 96.55 percent, which
    is even better than *forest.py*.
  prefs: []
  type: TYPE_NORMAL
- en: '***Models Combined with Voting***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Before we leave this section, let’s investigate how the size of the forest affects
    performance. For this experiment, we’ll switch to the MNIST digits dataset. Also,
    instead of averaging each model’s output, we’ll vote to assign class labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code we want is in *forest_mnist.py*. Built on *forest.py*, it loops over
    different sized forests to determine the mean accuracy for 20 models with that
    many trees. The output is a plot, but before we examine it, let’s review how to
    implement voting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The first code paragraph captures the predictions for each tree in the forest.
    The second creates `pred`, a vector that holds the most commonly selected class
    label across each model for each test sample. To get the winner for test sample
    `i`, we first use `bincount` to count how often each label appears for all models
    (the rows of `preds`) and then use `argmax` to return the index of the class label
    with the highest count. Ties go to the first occurrence of the highest value,
    that is, the lower index. Breaking ties this way might introduce a slight bias
    toward lower class labels, but we can live with that—consider it a systematic
    error as all forest sizes are likewise affected.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6-7](ch06.xhtml#ch06fig07) illustrates how the accuracy changes with
    forest size.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/06fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-7: Mean accuracy on the digits dataset as a function of forest size*'
  prefs: []
  type: TYPE_NORMAL
- en: At first, increasing the number of trees helps, but eventually, saturation sets
    in, producing diminishing returns as the forest grows.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Machine learning is a vast and critically important field. Here are some exercises
    related to the topics of this chapter to help you enhance your machine learning
    expertise and intuition:'
  prefs: []
  type: TYPE_NORMAL
- en: We augmented the digits dataset rather conservatively, with small rotations
    and zooming. Other image processing options might help improve the performance
    of the models in this chapter. Experiment with them by adding other options to
    the `augment` function in *build_mnist_dataset.py*. The `Image` and `ImageFilter`
    classes in Python’s `PIL` module might be helpful. Use `Image.fromarray` to convert
    a NumPy array of `dtype` uint8 to a PIL image. To go the other way, pass the `Image`
    object to `np.array`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Classifier` subclass of `MLPClassifier`, used by *init_test.py*, defines
    multiple approaches to initializing a neural network. Add new ones to see how
    they affect results. What happens if all weight matrices are initially zero or
    some constant value? What about when the bias vectors are zero? Consider experimenting
    with the beta distribution (`np.random.beta`), as adjusting its two parameters
    can generate samples with a wide range of shapes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The extreme learning machine uses a randomly generated weight matrix and bias
    vector to map the input to the first hidden layer. The selection method we used
    in this chapter is commonly found in the literature. What happens if you alter
    this method and select random values according to a nonuniform distribution? Consider
    `np.random.normal` (or the `RE`-based version) along with the beta distribution.
    Is there much of an effect?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a two-layer extreme learning machine where `w0`, `w1`, `b0`, and `b1`
    are randomly selected. The final weight matrix, now `w2`, will be learned as before
    from the output of the second hidden layer. Compare the performance to the single-layer
    version.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You’ll find files in the *datasets* directory beginning with *mnist_14x14*.
    They contain 14×14-pixel versions of all MNIST digits, [0, 9]. Try them in place
    of the four-digit version used throughout the chapter. How well do the various
    models perform?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modify *elm_brute.py* to track the number of all tested models over many runs
    for the same accuracy. Then use `np.histogram` and Matplotlib to plot histograms
    for a fixed accuracy (like 0.92). What shape do they have? Does the shape make
    sense to you?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We largely ignored scikit-learn’s `RandomForestClassifier` in favor of our homegrown
    version. Explore scikit-learn’s approach in more detail by reading through the
    documentation page for the class and experimenting with the different options.
    Consider using both the histology and digits datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run *rf_vs_mlp.py* followed by *rf_vs_mlp_results.py*. (Some patience is required.)
    Consider the output, which demonstrates how scaling the input feature vectors
    affects model performance. Which type of model is sensitive to the relative ranges
    of the features, the neural network or the random forest? Why might that be? Think
    about what a neural network is trying to do and compare that to the individual
    decision trees of the random forest. Why might one type of model care about the
    feature ranges while the other might not?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This chapter explored the importance of randomness in machine learning when
    building datasets, both in terms of ordering the samples during training and in
    augmenting existing samples with plausible new ones to enlarge the type of data
    from which models learn.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we considered the initialization of neural networks. We subclassed scikit-learn’s
    `MLPClassifier` to override its initialization method, allowing us to add alternate
    initialization approaches. We then examined their effect on model performance.
  prefs: []
  type: TYPE_NORMAL
- en: Following this, we explored extreme learning machines, a subtype of neural networks
    that employs randomness as one of its essential components. We learned how these
    machines perform on our datasets, then considered the effect of hidden layer size
    and activation function. We concluded the section by replacing the random weight
    matrix and bias vector with ones learned by a swarm optimization exercise. We
    discovered that swarm algorithms could generate models with performance beyond
    what most extreme learning machines provide (for the same architecture).
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we experimented with random forests, a collection of decision trees.
    We learned what decision trees are and how to build a random forest from collections
    of decision trees employing bagging, ensemble voting, and random feature selection.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter takes a break from the practical to enhance our lives through
    generative art.
  prefs: []
  type: TYPE_NORMAL
