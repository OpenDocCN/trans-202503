- en: Chapter 1. An Introduction to Statistical Significance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 统计显著性简介
- en: Much of experimental science comes down to measuring differences. Does one medicine
    work better than another? Do cells with one version of a gene synthesize more
    of an enzyme than cells with another version? Does one kind of signal processing
    algorithm detect pulsars better than another? Is one catalyst more effective at
    speeding a chemical reaction than another?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数实验科学归结于测量差异。某种药物是否比另一种更有效？某一版本基因的细胞是否比另一版本的细胞合成更多的酶？某种信号处理算法是否比另一种更有效地检测脉冲星？某种催化剂是否比另一种更有效地加速化学反应？
- en: We use statistics to make judgments about these kinds of differences. We will
    always observe *some* difference due to luck and random variation, so statisticians
    talk about *statistically significant* differences when the difference is larger
    than could easily be produced by luck. So first we must learn how to make that
    decision.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用统计学来判断这些差异。由于运气和随机变异，我们总会观察到*一些*差异，因此统计学家提到*统计显著*的差异时，是指这种差异大到不容易由运气产生。所以首先我们必须学会如何做出这个判断。
- en: The Power of p Values
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: p值的威力
- en: Suppose you’re testing cold medicines. Your new medicine promises to cut the
    duration of cold symptoms by a day. To prove this, you find 20 patients with colds,
    give half of them your new medicine, and give the other half a placebo. Then you
    track the length of their colds and find out what the average cold length was
    with and without the medicine.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在测试感冒药物。你新的药物承诺能将感冒症状的持续时间缩短一天。为了证明这一点，你找到20名感冒的患者，一半给他们服用新药，另一半给他们服用安慰剂。然后你追踪他们的感冒时长，并计算在有药和没有药的情况下，感冒的平均时长是多少。
- en: But not all colds are identical. Maybe the average cold lasts a week, but some
    last only a few days. Others might drag on for two weeks or more. It’s possible
    that the group of 10 patients who got the genuine medicine in your study all came
    down with really short colds. How can you prove that your medicine works, rather
    than just proving that some patients got lucky?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 但并不是所有感冒都是一样的。也许平均感冒持续一周，但有些可能只持续几天，其他的可能会拖延两周或更长时间。你研究中的10名接受了有效药物治疗的患者可能都得了非常短的感冒。你如何证明你的药物有效，而不是仅仅证明有些患者运气好？
- en: 'Statistical hypothesis testing provides the answer. If you know the distribution
    of typical cold cases—roughly how many patients get short colds, long colds, and
    average-length colds—you can tell how likely it is that a random sample of patients
    will all have longer or shorter colds than average. By performing a *hypothesis
    test* (also known as a *significance test*), you can answer this question: “Even
    if my medication were completely ineffective, what are the chances my experiment
    would have produced the observed outcome?”'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 统计假设检验提供了答案。如果你知道典型感冒案例的分布——大致有多少患者感冒时间短，多少患者感冒时间长，多少患者感冒时间正常——你就能判断一个随机样本中的患者感冒时间比平均值长或短的概率有多大。通过进行*假设检验*（也叫*显著性检验*），你可以回答这样一个问题：“即使我的药物完全无效，我的实验产生当前观察结果的几率有多大？”
- en: If you test your medication on only one person, it’s not too surprising if her
    cold ends up being a little shorter than usual. Most colds aren’t perfectly average.
    But if you test the medication on 10 million patients, it’s pretty unlikely that
    all those patients will just happen to get shorter colds. More likely, your medication
    actually works.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只在一个人身上测试药物，那么她的感冒比平时稍微短一点也不算太令人惊讶。大多数感冒并不是完全平均的。但如果你在1000万名患者身上测试该药物，那么所有这些患者恰好都得到了更短的感冒的可能性就非常小了。更可能的情况是，你的药物实际上有效。
- en: Scientists quantify this intuition with a concept called the *p value*. The
    *p* value is the probability, under the assumption that there is no true effect
    or no true difference, of collecting data that shows a difference equal to or
    more extreme than what you actually observed.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 科学家通过一个叫做*p值*的概念来量化这种直觉。*p值*是指在假设没有真正效果或没有真正差异的前提下，收集到的数据显示出的差异，是否等于或超过你实际观察到的极端差异的概率。
- en: So if you give your medication to 100 patients and find that their colds were
    a day shorter on average, then the *p* value of this result is the chance that
    if your medication didn’t actually do anything, their average cold would be a
    day shorter than the control group’s by luck alone. As you might guess, the *p*
    value depends on the size of the effect—colds that are shorter by four days are
    less common than colds that are shorter by just one day—as well as on the number
    of patients you test the medication on.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果你将药物给100名患者，并发现他们的感冒平均缩短了一天，那么这个结果的*p*值是指，如果你的药物实际上没有任何效果，感冒的平均时间比对照组短一天的可能性仅仅是运气的结果。正如你可能猜到的那样，*p*值取决于效应的大小——感冒缩短四天的情况比感冒缩短一天的情况要少见——以及你测试药物的患者数量。
- en: Remember, a *p* value is not a measure of how right you are or how important
    a difference is. Instead, think of it as a measure of surprise. If you assume
    your medication is ineffective and there is no reason other than luck for the
    two groups to differ, then the smaller the *p* value, the more surprising and
    lucky your results are—or your assumption is wrong, and the medication truly works.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，*p*值不是衡量你有多正确或差异有多重要的标准。相反，把它看作是惊讶的衡量标准。如果你假设你的药物无效，且除运气外没有任何理由让两个组之间有所不同，那么*p*值越小，结果就越令人惊讶和幸运——或者你的假设是错误的，药物确实有效。
- en: 'How do you translate a *p* value into an answer to this question: “Is there
    really a difference between these groups?” A common rule of thumb is to say that
    any difference where *p* < 0.05 is statistically significant. The choice of 0.05
    isn’t because of any special logical or statistical reasons, but it has become
    scientific convention through decades of common use.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如何将*p*值转化为这个问题的答案：“这些组之间真的存在差异吗？”一个常见的经验法则是，当*p* < 0.05时，差异是统计显著的。选择0.05并不是因为有什么特别的逻辑或统计原因，而是经过几十年的常用，已成为科学界的惯例。
- en: 'Notice that the *p* value works by assuming there is no difference between
    your experimental groups. This is a counterintuitive feature of significance testing:
    if you want to prove that your drug works, you do so by showing the data is *in*consistent
    with the drug *not* working. Because of this, *p* values can be extended to any
    situation where you can mathematically express a hypothesis you want to knock
    down.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，*p*值的工作方式是假设你的实验组之间没有差异。这是显著性检验的一个反直觉特性：如果你想证明你的药物有效，你需要通过展示数据与药物*无效*不一致来证明。由于这个原因，*p*值可以扩展到任何你能用数学方式表达的假设，你想推翻它。
- en: But *p* values have their limitations. Remember, *p* is a measure of surprise,
    with a smaller value suggesting that you should be more surprised. It’s not a
    measure of the size of the effect. You can get a tiny *p* value by measuring a
    huge effect—“This medicine makes people live four times longer”—or by measuring
    a tiny effect with great certainty. And because any medication or intervention
    usually has *some* real effect, you can always get a statistically significant
    result by collecting so much data that you detect extremely tiny but relatively
    unimportant differences. As Bruce Thompson wrote,
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，*p*值有其局限性。记住，*p*值是惊讶的衡量标准，值越小，意味着你应该越感到惊讶。它不是效应大小的衡量标准。你可以通过测量一个巨大的效应——“这种药物让人活得长四倍”——或者通过以极高的准确性测量一个微小的效应，得到一个很小的*p*值。而且，因为任何药物或干预通常都会有*某些*实际效果，你总是可以通过收集大量数据，检测出极其微小但相对不重要的差异，从而获得统计显著的结果。正如布鲁斯·汤普森所写，
- en: Statistical significance testing can involve a tautological logic in which tired
    researchers, having collected data on hundreds of subjects, then conduct a statistical
    test to evaluate whether there were a lot of subjects, which the researchers already
    know, because they collected the data and know they are tired. This tautology
    has created considerable damage as regards the cumulation of knowledge.^([1](apa.html#ch01en1))
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 统计显著性检验可能涉及一个自我循环的逻辑，疲惫的研究人员在收集了数百名受试者的数据后，再进行统计检验，以评估是否有足够多的受试者，而这些研究人员已经知道这一点，因为他们收集了数据并知道自己很疲劳。这种自我循环的逻辑在知识积累方面造成了相当大的损害。^([1](apa.html#ch01en1))
- en: In short, statistical significance does not mean your result has any *practical*
    significance. As for statistical *in*significance, it doesn’t tell you much. A
    statistically insignificant difference could be nothing but noise, or it could
    represent a real effect that can be pinned down only with more data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，统计显著性并不意味着你的结果具有任何*实际*意义。至于统计*不*显著，它并不能告诉你太多。一个统计上不显著的差异可能只是噪音，或者它可能代表一个真实的效应，只不过需要更多的数据才能确认。
- en: There’s no mathematical tool to tell you whether your hypothesis is true or
    false; you can see only whether it’s consistent with the data. If the data is
    sparse or unclear, your conclusions will be uncertain.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何数学工具能告诉你你的假设是对还是错；你只能看它是否与数据一致。如果数据稀疏或不清晰，你的结论将会不确定。
- en: Psychic Statistics
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 心理统计学
- en: 'Hidden beneath their limitations are some subtler issues with *p* values. Recall
    that a *p* value is calculated under the assumption that luck (not your medication
    or intervention) is the only factor in your experiment, and that *p* is defined
    as the probability of obtaining a result equal to *or more extreme* than the one
    observed. This means *p* values force you to reason about results that never actually
    occurred—that is, results more extreme than yours. The probability of obtaining
    such results depends on your experimental design, which makes *p* values “psychic”:
    two experiments with different designs can produce identical data but different
    *p* values because the *unobserved* data is different.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在其局限性背后，*p* 值存在一些更微妙的问题。回想一下，*p* 值是在假设幸运（而不是你的药物或干预）是实验中唯一因素的前提下计算的，而 *p* 的定义是得到一个结果等于*或更极端*的概率。这意味着
    *p* 值迫使你去推理那些实际上没有发生的结果——也就是说，比你观察到的结果更极端的结果。得到这些结果的概率取决于你的实验设计，这使得 *p* 值变得“心理学化”：两个设计不同的实验可能产生相同的数据，但
    *p* 值不同，因为*未观察到*的数据是不同的。
- en: Suppose I ask you a series of 12 true-or-false questions about statistical inference,
    and you correctly answer 9 of them. I want to test the hypothesis that you answered
    the questions by guessing randomly. To do this, I need to compute the chances
    of you getting *at least* 9 answers right by simply picking true or false randomly
    for each question. Assuming you pick true and false with equal probability, I
    compute *p* = 0.073.^([[3](#ftn.ch01fn02a)]) And since *p* > 0.05, it’s plausible
    that you guessed randomly. If you did, you’d get 9 or more questions correct 7.3%
    of the time.^([2](apa.html#ch01en2))
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我问你一系列12个关于统计推断的真/假问题，你正确回答了其中9个。我想检验你是否是通过随机猜测来回答这些问题。为此，我需要计算你通过随机选择真或假来回答每个问题时，至少答对9个问题的概率。假设你以相等的概率选择真或假，我计算得出
    *p* = 0.073。^([[3](#ftn.ch01fn02a)]) 由于 *p* > 0.05，因此有可能是你在随机猜测。如果是的话，你7.3%的时间会答对9个或更多的问题。^([2](apa.html#ch01en2))
- en: But perhaps it was not my original plan to ask you only 12 questions. Maybe
    I had a computer that generated a limitless supply of questions and simply asked
    questions until you got 3 wrong. Now I have to compute the probability of you
    getting 3 questions wrong after being asked 15 or 20 or 47 of them. I even have
    to include the remote possibility that you made it to 175,231 questions before
    getting 3 questions wrong. Doing the math, I find that *p* = 0.033\. Since *p*
    < 0.05, I conclude that random guessing would be unlikely to produce this result.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 但或许最初我并没有打算只问你12个问题。也许我有一台计算机，它能够生成无限数量的问题，并且不停地问问题，直到你答错了3个。现在，我必须计算你在被问了15、20或47个问题后，答错3个问题的概率。甚至，我还得考虑一个极小的可能性，那就是你在答错3个问题之前，已经回答了175,231个问题。做这个数学计算后，我发现
    *p* = 0.033。由于 *p* < 0.05，我得出结论，随机猜测不太可能得到这个结果。
- en: 'This is troubling: two experiments can collect identical data but result in
    different conclusions. Somehow, the *p* value can read your intentions.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这很麻烦：两个实验可以收集相同的数据，但得出不同的结论。某种程度上，*p* 值似乎能读取你的意图。
- en: Neyman-Pearson Testing
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内曼-皮尔逊检验
- en: To better understand the problems of the *p* value, you need to learn a bit
    about the history of statistics. There are two major schools of thought in statistical
    significance testing. The first was popularized by R.A. Fisher in the 1920s. Fisher
    viewed *p* as a handy, informal method to see how surprising a set of data might
    be, rather than part of some strict formal procedure for testing hypotheses. The
    *p* value, when combined with an experimenter’s prior experience and domain knowledge,
    could be useful in deciding how to interpret new data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解*p*值的问题，你需要了解一点统计学的历史。统计显著性检验中有两种主要的思维方式。第一种是由R.A.费舍尔在1920年代提出并普及的。费舍尔将*p*值视为一种便捷的、非正式的方法，用来查看一组数据的惊讶程度，而不是某种严格的正式假设检验程序的一部分。*p*值结合实验者的先前经验和领域知识时，可能在决定如何解释新数据时非常有用。
- en: After Fisher’s work was introduced, Jerzy Neyman and Egon Pearson tackled some
    unanswered questions. For example, in the cold medicine test, you can choose to
    compare the two groups by their means, medians, or whatever other formula you
    might concoct, so long as you can derive a *p* value for the comparison. But how
    do you know which is best? What does “best” even mean for hypothesis testing?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在费舍尔的工作引入后，耶日·内曼和埃贡·皮尔森解决了一些未解答的问题。例如，在感冒药物测试中，你可以选择通过均值、中位数或其他你可能编造的公式来比较两组，只要你能够得出一个*
    p *值来进行比较。但你怎么知道哪个方法最好呢？在假设检验中，“最好”到底意味着什么？
- en: 'In science, it is important to limit two kinds of errors: *false positives*,
    where you conclude there is an effect when there isn’t, and *false negatives*,
    where you fail to notice a real effect. In some sense, false positives and false
    negatives are flip sides of the same coin. If we’re too ready to jump to conclusions
    about effects, we’re prone to get false positives; if we’re too conservative,
    we’ll err on the side of false negatives.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学中，限制两种错误非常重要：*假阳性*，即你得出一个效果存在的结论，但实际并没有效果；以及*假阴性*，即你未能注意到一个真实的效果。从某种意义上讲，假阳性和假阴性是同一枚硬币的两面。如果我们太容易对效果做出结论，我们就容易得到假阳性；如果我们过于保守，我们则容易犯假阴性错误。
- en: Neyman and Pearson reasoned that although it’s impossible to eliminate false
    positives and negatives entirely, it *is* possible to develop a formal decision-making
    process that will ensure false positives occur only at some predefined rate. They
    called this rate α, and their idea was for experimenters to set an α based upon
    their experience and expectations. So, for instance, if we’re willing to put up
    with a 10% rate of false positives, we’ll set α = 0.1\. But if we need to be more
    conservative in our judgments, we might set α at 0.01 or lower. To determine which
    testing procedure is best, we see which has the lowest false negative rate for
    a given choice of α.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 内曼和皮尔森认为，尽管完全消除假阳性和假阴性是不可能的，但*的确*可以制定一个正式的决策过程，确保假阳性仅在某个预定义的比例下发生。他们将这个比例称为α，他们的想法是让实验者根据经验和预期设定一个α。例如，如果我们愿意接受10%的假阳性率，我们将设定α
    = 0.1。但是，如果我们需要在判断上更加保守，我们可能会将α设置为0.01或更低。为了确定哪种测试程序最好，我们需要看在给定的α选择下，哪种方法具有最低的假阴性率。
- en: How does this work in practice? Under the Neyman–Pearson system, we define a
    *null hypothesis*—a hypothesis that there is no effect—as well as an *alternative
    hypothesis*, such as “The effect is greater than zero.” Then we construct a test
    that compares the two hypotheses, and determine what results we’d expect to see
    were the null hypothesis true. We use the *p* value to implement the Neyman-Pearson
    testing procedure by rejecting the null hypothesis whenever *p* < α. Unlike Fisher’s
    procedure, this method deliberately does not address the strength of evidence
    in any one particular experiment; now we are interested in only the decision to
    reject or not. The size of the *p* value isn’t used to compare experiments or
    draw any conclusions besides “The null hypothesis can be rejected.” As Neyman
    and Pearson wrote,
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程在实践中如何运作？在内曼–皮尔森系统下，我们定义一个*原假设*——即没有效果的假设——以及一个*备择假设*，例如“效果大于零”。然后我们构建一个比较这两个假设的测试，并确定如果原假设为真，我们期望看到的结果。我们使用*p*值来执行内曼-皮尔森检验程序，当*p*
    < α时拒绝原假设。与费舍尔的方法不同，这种方法故意不处理任何单一实验中的证据强度；现在我们仅关注是否拒绝原假设的决定。*p*值的大小不用于比较实验或得出任何结论，除了“可以拒绝原假设”。正如内曼和皮尔森所写，
- en: We are inclined to think that as far as a particular hypothesis is concerned,
    no test based upon the theory of probability can by itself provide any valuable
    evidence of the truth or falsehood of that hypothesis.
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们倾向于认为，就某个特定假设而言，任何基于概率理论的测试都不能单独提供该假设的真假证据。
- en: ''
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: But we may look at the purpose of tests from another view-point. Without hoping
    to know whether each separate hypothesis is true or false, we may search for rules
    to govern our behaviour with regard to them, in following which we insure that,
    in the long run of experience, we shall not be too often wrong.^([3](apa.html#ch01en3))
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但我们也可以从另一个角度来看待测试的目的。我们无需希望知道每一个假设是否真实，我们可以寻找一些规则来指导我们在这些假设上的行为，遵循这些规则能确保我们在长期的经验中不会经常出错。^([3](apa.html#ch01en3))
- en: Although Neyman and Pearson’s approach is conceptually distinct from Fisher’s,
    practicing scientists often conflate the two.^([4](apa.html#ch01en4)),^([5](apa.html#ch01en5)),^([6](apa.html#ch01en6))
    The Neyman-Pearson approach is where we get “statistical significance,” with a
    prechosen *p* value threshold that guarantees the long-run false positive rate.
    But suppose you run an experiment and obtain *p* = 0.032\. If your threshold was
    the conventional *p* < 0.05, this is statistically significant. But it’d also
    have been statistically significant if your threshold was *p* < 0.033\. So it’s
    tempting—and a common misinterpretation—to say “My false positive rate is 3.2%.”
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Neyman和Pearson的方法在概念上与Fisher的方法不同，实践中的科学家常常将两者混淆。^([4](apa.html#ch01en4)),^([5](apa.html#ch01en5)),^([6](apa.html#ch01en6))
    Neyman-Pearson方法就是我们得到“统计显著性”的方法，这种方法有一个预先选定的* p *值阈值，保证长期的假阳性率。但是假设你进行了一项实验并获得了*
    p * = 0.032。如果你的阈值是传统的* p * < 0.05，那么这个结果就是统计显著的。但如果你的阈值是* p * < 0.033，它依然是统计显著的。所以这就很诱人——也是一种常见的误解——说“我的假阳性率是3.2%。”
- en: But that doesn’t make sense. A single experiment does not have a false positive
    rate. The false positive rate is determined by your *procedure*, not the result
    of any single experiment. You can’t claim each experiment had a false positive
    rate of exactly *p*, whatever that turned out to be, when you were using a procedure
    to get a long-run false positive rate of α.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 但这样说是不合理的。单个实验并没有假阳性率。假阳性率是由你的*程序*决定的，而不是单个实验的结果。你不能声称每个实验的假阳性率就是* p *，无论最终结果是多少，因为你使用的程序是为了获得长期的假阳性率α。
- en: Have Confidence in Intervals
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对区间保持信心
- en: Significance tests tend to receive lots of attention, with the phrase “statistically
    significant” now part of the popular lexicon. Research results, especially in
    the biological and social sciences, are commonly presented with *p* values. But
    *p* isn’t the only way to evaluate the weight of evidence. *Confidence intervals*
    can answer the same questions as *p* values, with the advantage that they provide
    more information and are more straightforward to interpret.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 显著性测试往往会受到很多关注，“统计显著”这一术语现在已经成为流行语。研究结果，尤其是在生物学和社会科学领域，通常会呈现* p *值。但* p *并不是评估证据权重的唯一方式。*置信区间*可以回答与*
    p *值相同的问题，且具有更多信息并且更易于解释的优点。
- en: A confidence interval combines a point estimate with the uncertainty in that
    estimate. For instance, you might say your new experimental drug reduces the average
    length of a cold by 36 hours and give a 95% confidence interval between 24 and
    48 hours. (The confidence interval is for the *average* length; individual patients
    may have wildly varying cold lengths.) If you run 100 identical experiments, about
    95 of the confidence intervals will include the true value you’re trying to measure.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间将一个点估计与该估计的不确定性结合在一起。例如，你可能会说你的新实验药物能减少感冒的平均持续时间36小时，并给出95%的置信区间，介于24小时到48小时之间。（该置信区间是针对*平均*持续时间的；每个病人的感冒持续时间可能会有很大的差异。）如果你进行100次相同的实验，约95个置信区间会包含你想要测量的真实值。
- en: A confidence interval quantifies the uncertainty in your conclusions, providing
    vastly more information than a *p* value, which says nothing about effect sizes.
    If you want to test whether an effect is significantly different from zero, you
    can construct a 95% confidence interval and check whether the interval includes
    zero. In the process, you get the added bonus of learning how precise your estimate
    is. If the confidence interval is too wide, you may need to collect more data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间量化了你结论中的不确定性，提供的信息比*p*值要丰富得多，因为*p*值根本没有关于效应大小的任何信息。如果你想检验一个效应是否显著不同于零，你可以构建一个95%的置信区间，并检查该区间是否包含零。在这个过程中，你还可以获得额外的好处，了解你的估计有多精确。如果置信区间太宽，你可能需要收集更多的数据。
- en: For example, if you run a clinical trial, you might produce a confidence interval
    indicating that your drug reduces symptoms by somewhere between 15 and 25 percent.
    This effect is statistically significant because the interval doesn’t include
    zero, and now you can assess the importance of this difference using your clinical
    knowledge of the disease in question. As when you were using *p* values, this
    step is important—you shouldn’t trumpet this result as a major discovery without
    evaluating it in context. If the symptom is already pretty innocuous, maybe a
    15–25% improvement isn’t too important. Then again, for a symptom like spontaneous
    human combustion, you might get excited about *any* improvement.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你进行临床试验，你可能会得出一个置信区间，表明你的药物能将症状减少15%到25%之间。这个效应是统计显著的，因为该区间不包括零，现在你可以根据你对相关疾病的临床知识来评估这个差异的重要性。就像你使用*p*值时一样，这一步是很重要的——你不应该在没有在上下文中评估的情况下就宣称这个结果是一个重大发现。如果症状已经相当无害，也许15%到25%的改善并不那么重要。另一方面，对于像自发性人类自燃这样的症状，你可能会对*任何*改善感到兴奋。
- en: 'If you can write a result as a confidence interval instead of as a *p* value,
    you should.^([7](apa.html#ch01en7)) Confidence intervals sidestep most of the
    interpretational subtleties associated with *p* values, making the resulting research
    that much clearer. So why are confidence intervals so unpopular? In experimental
    psychology research journals, 97% of research papers involve significance testing,
    but only about 10% ever report confidence intervals—and most of those don’t use
    the intervals as supporting evidence for their conclusions, relying instead on
    significance tests.^([8](apa.html#ch01en8)) Even the prestigious journal *Nature*
    falls short: 89% of its articles report *p* values without any confidence intervals
    or effect sizes, making their results impossible to interpret in context.^([9](apa.html#ch01en9))
    One journal editor noted that “*p* values are like mosquitoes” in that they “have
    an evolutionary niche somewhere and [unfortunately] no amount of scratching, swatting
    or spraying will dislodge them.”^([10](apa.html#ch01en10))'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你能将结果写成置信区间，而不是*p*值，那么你应该这么做。^([7](apa.html#ch01en7)) 置信区间避开了与*p*值相关的大部分解释性细节，使得研究结果更加清晰。那么，为什么置信区间如此不受欢迎呢？在实验心理学研究期刊中，97%的研究论文涉及显著性检验，但只有大约10%的论文报告了置信区间——而且这些论文中的大部分并没有将置信区间作为支持其结论的证据，而是依赖于显著性检验。^([8](apa.html#ch01en8))
    即便是享有盛誉的期刊*Nature*也未能做到：89%的文章报告了*p*值，但没有任何置信区间或效应量，导致其结果在上下文中无法解读。^([9](apa.html#ch01en9))
    一位期刊编辑指出，“*p*值就像蚊子”，因为它们“有一个进化上的生态位，而且[不幸的是]无论怎么抓、拍打或喷洒，都无法把它们赶走。”^([10](apa.html#ch01en10))
- en: One possible explanation is that confidence intervals go unreported because
    they are often embarrassingly wide.^([11](apa.html#ch01en11)) Another is that
    the peer pressure of peer-reviewed science is too strong—it’s best to do statistics
    the same way everyone else does, or else the reviewers might reject your paper.
    Or maybe the widespread confusion about *p* values obscures the benefits of confidence
    intervals. Or the overemphasis on hypothesis testing in statistics courses means
    most scientists don’t know how to calculate and use confidence intervals.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能的解释是，置信区间未被报告，因为它们通常过于宽泛，令人尴尬。^([11](apa.html#ch01en11)) 另一个原因是同行评审的压力过大——最好按照大家都在做的方式进行统计，否则审稿人可能会拒绝你的论文。或者，可能是关于*p*值的广泛混淆掩盖了置信区间的好处。又或者，统计学课程中过度强调假设检验意味着大多数科学家不知道如何计算和使用置信区间。
- en: 'Journal editors have sometimes attempted to enforce the reporting of confidence
    intervals. Kenneth Rothman, an associate editor at the *American Journal of Public
    Health* in the mid-1980s, began returning submissions with strongly worded letters:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 期刊编辑们有时试图强制要求报告置信区间。1980年代中期，作为《*美国公共卫生杂志*》的副主编，肯尼斯·罗思曼开始返回投稿并附上措辞严厉的信件：
- en: All references to statistical hypothesis testing and statistical significance
    should be removed from the paper. I ask that you delete *p* values as well as
    comments about statistical significance. If you do not agree with my standards
    (concerning the inappropriateness of significance tests), you should feel free
    to argue the point, or simply ignore what you may consider to be my misguided
    view, by publishing elsewhere.^([12](apa.html#ch01en12))
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所有涉及统计假设检验和统计显著性的内容都应从论文中删除。我要求你删除*p*值以及关于统计显著性的评论。如果你不同意我的标准（关于显著性检验不恰当的观点），你可以自由地辩论这一点，或者干脆忽略我可能被认为是错误的观点，选择在其他地方发表。^([12](apa.html#ch01en12))
- en: During Rothman’s three-year tenure as associate editor, the fraction of papers
    reporting solely *p* values dropped precipitously. Significance tests returned
    after his departure, although subsequent editors successfully encouraged researchers
    to report confidence intervals as well. But despite reporting confidence intervals,
    few researchers discussed them in their articles or used them to draw conclusions,
    preferring instead to treat them merely as significance tests.^([12](apa.html#ch01en12))
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在罗思曼担任副主编的三年期间，仅报告*p*值的论文比例急剧下降。虽然在他离开后，显著性检验又重新出现，但随后的编辑们成功地鼓励研究人员同时报告置信区间。然而，尽管报告了置信区间，少数研究人员在他们的文章中讨论这些区间或使用它们来得出结论，而更倾向于仅仅将它们视为显著性检验的一部分。^([12](apa.html#ch01en12))
- en: Rothman went on to found the journal *Epidemiology*, which had a strong statistical
    reporting policy. Early on, authors familiar with significance testing preferred
    to report *p* values alongside confidence intervals, but after 10 years, attitudes
    had changed, and reporting only confidence intervals became common practice.^([12](apa.html#ch01en12))
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 罗思曼随后创办了期刊《*流行病学*》，该期刊有着严格的统计报告政策。刚开始时，习惯于显著性检验的作者更倾向于在报告置信区间的同时报告*p*值，但经过10年后，态度发生了变化，仅报告置信区间成为了常见的做法。^([12](apa.html#ch01en12))
- en: Perhaps brave (and patient) journal editors can follow Rothman’s example and
    change statistical practices in their fields.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 或许勇敢（且耐心的）期刊编辑可以效仿罗思曼（Rothman）的例子，改变他们领域中的统计实践。
- en: '* * *'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^([[3](#ch01fn02a)]) I used a probability distribution known as the *binomial
    distribution* to calculate this result. In the next paragraph, I’ll calculate
    *p* using a different distribution, called the *negative binomial distribution*.
    A detailed explanation of probability distributions is beyond the scope of this
    book; we’re more interested in how to interpret *p* values rather than how to
    calculate them.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ^([[3](#ch01fn02a)]) 我使用一种叫做*二项分布*的概率分布来计算这个结果。在下一段中，我将使用另一种分布，称为*负二项分布*，来计算*p*值。本书的重点不在于概率分布的详细解释；我们更关心如何解释*p*值，而不是如何计算它们。
