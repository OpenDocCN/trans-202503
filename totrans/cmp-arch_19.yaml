- en: '**16**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**FUTURE ARCHITECTURES**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Image](../images/f0397-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Historically, looking at academic research that’s close to transitioning to
    industry tends to accurately predict what will happen over the next decade. At
    present, research is still mostly done on semiconductor-based technologies, but
    there are some researchers looking at alternatives. While it’s hard to predict
    much further than a decade ahead, we’ll look at some current ideas that might
    one day go somewhere beyond the present electricity-based computing age. We’ll
    go roughly in order of uncertainty, starting with some close-to-market developments
    associated with the current “new golden age” of architecture, then traveling through
    research labs studying optical and DNA architectures, neural architectures, and
    quantum computing, and finally moving on to speculative ideas based on more distant
    theories of physics.
  prefs: []
  type: TYPE_NORMAL
- en: The New Golden Age
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Architecture is cool again! In the 2010s, trends like the maker, open source,
    and “mindful design” movements helped drive the resurgence of interest in architecture.
    Rebelling against the prepackaged black-box interfaces sold to them, artists,
    innovators, hipsters, and steampunks instead chose to gain greater understanding,
    control, and satisfaction over the technology in their lives by opening up these
    boxes and looking at and modifying what’s inside. In the professional world, commercial
    architecture careers over the next decade seem likely to focus on low-cost, low-power
    embedded and smart systems rather than desktops, laptops, and servers.
  prefs: []
  type: TYPE_NORMAL
- en: The 2010s was also a decade of parallelization and centralized computing, with
    computation moving off the desktop into the “cloud” of dedicated centralized computing
    and data centers. It’s widely expected that the next step in computer evolution
    will be the disappearance of desktops and even laptops, replaced by a multitude
    of small, low-power devices all around the real world that are in constant communication
    with the cloud, relaying data to the cloud for processing. Smartphones and tablets
    are early versions of this, but we expect to see even cheaper and smaller devices
    all over the real world, enabling smart homes, smart farms, and smart cities.
  prefs: []
  type: TYPE_NORMAL
- en: A recent trend identified by Hennessy and Patterson is the demand for custom,
    domain-specific architectures. In this view, GPUs and NPUs are only the beginning
    of a new wave of custom silicon designed to accelerate specific, single tasks.
    It’s likely that architects will work on these designs as part of larger teams—for
    example, working more closely with machine learning engineers and cryptographers
    to understand and accelerate their algorithms. This would create a cultural shift
    in computer science, bringing architects back into the mainstream, and requiring
    everyone else to understand and interact with their work as they did in the 1980s.
  prefs: []
  type: TYPE_NORMAL
- en: '*Open Source Architectures*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the first time in architectural history, open source thinking has extended
    into the creation of fully open source hardware and software tooling stacks—RISC-V,
    BOOM, and Chisel—for professional-quality, state-of-the-art chip design. Along
    with new affordable FPGAs, these enable anyone to access equipment that was previously
    only available to a handful of secretive and elite architecture companies. Now
    almost anyone can be the creator of anything and see and hack the entire stack,
    from the level of transistors to operating systems. Now is thus the best time
    to be involved in architecture—even better than the 8-bit days, when hackers could
    see the ISAs but were still only customers of their chipmakers.
  prefs: []
  type: TYPE_NORMAL
- en: Open source hardware designs have even started to appear for entire consumer
    PCs, such as the ARM-based Olimex TERES laptop, which users often modify through
    PCB design software and 3D printing. Open source interest is also being driven
    by end users, who are feeling increasingly uneasy about the proprietary architecture
    of individual CPUs that may be back-doored at the digital logic level. For example,
    Intel has been accused of hiding and running an entire operating system based
    on MINIX inside its processors, which can communicate with its Intel home to say
    potentially anything about what the machine is doing. Open source architectures
    may become standard and expected—an architectural revolution analogous to the
    open source software revolution of the 2000s.
  prefs: []
  type: TYPE_NORMAL
- en: While large-scale fabrication is only possible in expensive fab plants, a few
    companies are large enough to make new masks and fabricate experimental chips
    on a fairly regular basis. These big companies sometimes now allow researchers
    and hobbyists to fabricate their own real ASICs for free or low cost by including
    their designs in an otherwise unused corner of their masks and wafers (for example,
    *[https://developers.google.com/silicon](https://developers.google.com/silicon)*).
    There’s also been recent progress allowing makers to fabricate their own simpler
    chips in their garages using open source hardware methods. Sam Zeloof pioneered
    this approach and in 2021 was able to place and connect 1,200 transistors on a
    chip—about half the number used in the Intel 4004.
  prefs: []
  type: TYPE_NORMAL
- en: 'Openness is also becoming an issue in the cloud. There are currently significant
    concerns around moving from desktop computing—where everyone owns their own computer—to
    the 2020s cloud, where the computers are owned by a small number of large, powerful
    companies. This has raised some questions: who will control these computers and
    the data on them, and how can users be sure that their computations and data aren’t
    being spied on or resold by these companies or other actors?'
  prefs: []
  type: TYPE_NORMAL
- en: These concerns might drive new architecture trends. The *open cloud* concept
    calls for replacing corporate clouds hosted in dedicated computing centers with
    a shared, loose, decentralized, federated network of ordinary citizens’ machines,
    in their homes. Everyone will have a small, always-on server in their home, a
    cross between a high-end router, NAS drive, and Intel NUC. These servers will
    enable non-technical home internet users to easily host their own websites and
    media streams. They’ll also enable fully open source search engines (YaCy), social
    media (Mastodon), video storage and streaming (PeerTube), video conferences (Matrix),
    and physical goods marketplaces (OpenBazaar) to replace big tech equivalents by
    distributing their computations and using cryptographic methods and currencies
    to ensure trust. The FreedomBox website already has a working software distribution
    that you can run today on your Raspberry Pi to do some of this. New architectures
    may be needed to optimize for these use cases.
  prefs: []
  type: TYPE_NORMAL
- en: While hackers and makers can now get their hands on these nice tools, big companies
    with big resources aren’t standing still. They continue to develop smaller and
    more advanced systems to try to stay ahead, as we’ll see next.
  prefs: []
  type: TYPE_NORMAL
- en: '*Atomic-Scale Transistors*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We saw in [Chapter 4](ch04.xhtml) that Moore’s law for clock speed is over,
    but Moore’s law for silicon transistor density is still holding up. The density
    law can’t go on forever either, though, because we’ll hit a point where a transistor
    is the same size as an atom, and then it will be impossible to go any smaller
    with semiconductors. Quantum effects will also kick in as we approach this point,
    leading to inherent uncertainties about where things are and what they represent.
    Moore’s law for density suggests this will occur around 2060.
  prefs: []
  type: TYPE_NORMAL
- en: IBM can currently manipulate single atoms into simple shapes. For example, [Figure
    16-1](ch16.xhtml#ch16fig1) shows an electron microscope image of a copper surface
    in which each dot is a single atom, placed and read with their technology.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0400-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-1: IBM manipulates single atoms to create images*'
  prefs: []
  type: TYPE_NORMAL
- en: The fuzzy, wave-like quality of this image is due to quantum effects. At this
    scale, it becomes inherently uncertain where the atoms are and how they’re moving
    around. These atoms don’t yet function as transistors or computers, but they can,
    for example, be used for data storage, and IBM would eventually like to develop
    the technology toward single atom–based computation.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get to this scale, but after conventional semiconductors hit fundamental
    size limits, nanotechnologies such as carbon nanotubes and graphene might be used
    to build smaller transistors; this is a current research area. In 2022, researchers
    at Tsinghua University fabricated a graphene transistor about the size of a single
    carbon atom, running millions of times faster than silicon.
  prefs: []
  type: TYPE_NORMAL
- en: '*3D Silicon Architectures*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Classical chip layouts were 2D, with a good bit of graph theory and complexity
    theory needed to optimize the design and minimize the wiring. As we saw in [Figure
    4-19](ch04.xhtml#ch04fig19), current CPUs can be made with a few layers of *overlapping*
    copper wires, whose 3D structure greatly reduces the wiring. Modern chips still
    place transistors in a single layer, on the base of the chip, but allow several
    (typically 2 to 10) layers of wires to be formed on top, insulated from one another
    by filler materials.
  prefs: []
  type: TYPE_NORMAL
- en: It’s possible that today’s basic layering technologies will grow incrementally
    to add more and more layers of wires and transistors, culminating in a move from
    2D silicon chips to fully 3D silicon cubes.
  prefs: []
  type: TYPE_NORMAL
- en: However, silicon cubes will create issues around power supplies and heat, requiring
    something analogous to the brain’s blood supply system mixed around the computing
    elements to get energy in and heat out of the dense 3D structure. We don’t currently
    know how this should be done. The chip design community has, for living memory,
    been so focused on 2D layout concerns that it’s not clear how it could move to
    thinking in 3D.
  prefs: []
  type: TYPE_NORMAL
- en: RAM usually has lower usage and heat requirements than processing because most
    of the time it just sits there doing nothing in a serial computer. Therefore,
    it’s easier to make 3D RAM than it is to make 3D CPUs. There have been recent
    commercial attempts at 3D RAM, such as Micron’s Hybrid Memory Cube.
  prefs: []
  type: TYPE_NORMAL
- en: One source of inspiration for 3D CPU design might come from today’s *Minecraft*
    gaming community. *Minecraft* can act as a Church-powerful computer, using its
    redstone elements as switches. Fans have already constructed several functioning
    CPU components inside it, looking similar to [Figure 4-19](ch04.xhtml#ch04fig19),
    and even whole CPUs such as “ANDROSII.” Unlike previous generations, these players
    have grown up with *Minecraft*’s inherent three-dimensionality, so instead of
    laying out their processors on 2D circuit boards or ICs, they’ve instinctively
    evolved inherently 3D architectures to optimize their layouts, completely free
    from manufacturing constraints and the 2D thinking built into the silicon industry.
  prefs: []
  type: TYPE_NORMAL
- en: '*10,000-Year Memory*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: What will happen to your data when you die? Will anyone be able to read your
    files or view your videos thousands of years into the future? Or even 10 years
    into the future?
  prefs: []
  type: TYPE_NORMAL
- en: The clay tablets from 4,000 years ago that we saw earlier ([Figure 1-5](ch01.xhtml#ch01fig5))
    are still perfectly readable. Paper was an advance over clay tablets in terms
    of speed and capacity, but it doesn’t survive as long. As memory technology has
    advanced and miniaturized, it’s gotten faster and increased its capacity, but
    at the expense of robustness, both to physical decay and to “bit rot” or other
    technological incompatibilities. All the tertiary and offline storage options
    we’ve seen will decay in 100 years. Commercial data centers keep data “alive”
    by continually copying it to new physical media. Spinning hard disks break and
    are replaced; tapes and optical discs decay and are replaced. But this relies
    on continual attention by human maintainers, employed by a company that continues
    to exist and doesn’t go bankrupt or get bought out by new owners who don’t want
    to continue maintaining it.
  prefs: []
  type: TYPE_NORMAL
- en: Research efforts are currently underway to find longer-term storage options
    as durable as clay tablets, but at modern data sizes. M-disc is a recent optical
    disc format, backward compatible with Blu-ray, that is claimed to store 100GB
    for 1,000 years. In 2018, the Arch Mission Foundation deposited a DVD-sized nickel
    disk onto the moon’s surface, containing a full backup of Wikipedia and other
    documents deemed useful for rebooting humanity in the event of total data loss
    on Earth. They claim it will last for at least 10,000 years. Glass laser nanostructuring,
    as developed at the University of Southampton, may store 350TB in a 1-inch cube
    of very hard glass, with a 14 billion–year lifetime. It’s a similar idea to the
    3D markings you see in glass trophies, etched deep inside their structure with
    lasers.
  prefs: []
  type: TYPE_NORMAL
- en: Lasers might also be used to perform computations, as in optical architectures;
    we’ll turn to these now.
  prefs: []
  type: TYPE_NORMAL
- en: Optical Architectures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ve mostly looked at computers that are based on the flow of electrons. Electrons
    have mass, so they must travel slower than the speed of light. Energy is also
    required to give momentum to their mass so that they can move around. Light, on
    the other hand, has no mass, so it moves faster than electrons, at the speed of
    light (about 300 million meters per second). As this is the physical speed limit
    of everything in the universe, since the 1960s researchers have asked whether
    we can compute with light instead of electrons. Like electrons in electricity,
    light comes in discrete units called *photons*, and the engineering field that
    studies how to manipulate them is called *photonics*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Optical Transistors*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The speed of electric current is different from the speed of electrons themselves;
    current usually flows with each electron only moving a small distance, pushing
    the next electron forward in the circuit. Electrons moving through wire are in
    a complex environment with many collisions as they bump around, backward and forward,
    in random walks. The speed of individual electrons drifting along wire is thus
    very slow, around 1 meter per hour, while the speed of the current in copper wire
    can be around 90 percent of the speed of light in a vacuum. Thus, a naive expectation
    that light will compute much faster than electrons seems overly optimistic; switching
    over our entire hardware technology for just a 10 percent speedup, from 90 percent
    to 100 percent of light speed, seems not so useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, optical systems have different advantages: there’s higher throughput
    and lower energy consumption than when using electrons because of the lower noise
    in light propagation. That’s why we already use light for routine high-bandwidth,
    long-distance networking—that is, fiber optics. Optical computing doesn’t seem
    so far-fetched when you remember that most of your internet and phone traffic
    is already sent around the world via fiber optics.'
  prefs: []
  type: TYPE_NORMAL
- en: The difference between mere information transfer and actual computation is that
    in computation, data elements need to physically interact with one another via
    some kind of device analogous to a transistor, which in turn would build up logic
    gates and the rest of the architectural hierarchy. The key problem for optical
    computing, however, is that photons don’t naturally interact with one another.
    In physics terms, they’re bosons rather than fermions, which means that if two
    of them “collide” they just go straight through each other instead of bouncing
    off each other. This is great for optical communication, but not for optical computing.
  prefs: []
  type: TYPE_NORMAL
- en: To make an optical transistor, we thus need some form of electro-optical hybrid
    technology, in which photons can interact with electrons and vice versa to perform
    computation. Transferring energy between photons and electrons is slow, however,
    and uses up energy. Such devices currently exist in large photonics labs, made
    of lasers and precision equipment on optical tables. These systems fill whole
    rooms and implement only a few hybrid optical-electronic transistors. Their scale
    is reminiscent of early electronic computers of the early 20th century. But like
    those large electronic computers, research also aims to miniaturize them once
    the basic principles are worked out, probably via photolithography (chip masking)
    processes similar to the ones used to make conventional electronics; current plans
    involve using silicon as the electronics substrate, similar to conventional chips.
  prefs: []
  type: TYPE_NORMAL
- en: '*Optical Correlators*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'An *optical correlator* (or *4f system*) is a special case of optical computation
    that has become very practical in the last few years. Rather than being Church
    powerful, an optical correlator is used for a single purpose: to implement and
    speed up a single algorithm, the *discrete Fourier transform (DFT)*. The DFT converts
    streams of spatial and time-series data, such as in sound and video codecs, into
    frequency-based representations. It uses this equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0403-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For audio signals, the DFT results correspond roughly to the underlying frequencies
    that generated the signals. For images and video, they correspond roughly to different
    textures useful in recognition and compression. This is such a basic operation,
    and used so heavily, that it’s worth optimizing it with dedicated hardware, as
    is currently done by many CISC and DSP instructions.
  prefs: []
  type: TYPE_NORMAL
- en: 'A key computational property of the DFT is that it speeds up the common operation
    of convolution (or filtering). For one-dimensional signals, convolution is defined
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0403-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *N* is the length of the signal *y*. Implementing this equation directly
    results in an *O*(*N*²) algorithm, though the *fast Fourier transform (FFT)* is
    a faster *O*(*N* log *N*) algorithm based on a mathematically equivalent rearrangement
    of the equation. The FFT is the fastest known implementation of DFT for a serial
    computer; it’s been described as “the most important numerical algorithm of our
    lifetime.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Convolution in the source domain is equivalent to multiplication in the Fourier
    domain. So rather than convolve two raw signals in the raw domain, it can be faster
    to Fourier transform them both, multiply these transforms together, and use a
    final DFT to convert back into the raw domain:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0403-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: When a single ray of laser light goes through a single tiny hole, it’s *diffracted*
    to produce a diffraction pattern of light on the other side. It can be shown that
    if this light signal is passed through a lens, positioned at its focal length
    *f* from the image, then at the same distance *f* on the other side of the lens,
    an image is formed that happens to be the DFT of the original image. This was
    an unexpected and coincidental property of the mathematics of diffraction and
    lensing, but once discovered it provided an ultra-fast, *O*(1) physical device
    to compute DFTs at the speed of light.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have this Fourier image, *X*, we can implement convolution in *O*(1)
    by multiplying pointwise by the DFT of our filter, *Y*. We precompute *Y* offline
    and manufacture a physical filter—just like the colored filters put in front of
    theater stage lights to change their properties. For most DSP applications, such
    as video processing, we’ll want to apply the same filter *y* to many images *x*
    in a rapid sequence, so we have to compute *Y* only once. Passing the light image
    *X* through this physical filter has the effect of multiplying it by *Y*, equivalent
    to convolution *x* ∗ *y* in the raw domain. The DFT is self-inverse, so to obtain
    the final convolution we pass this image through a second lens, of the same focal
    length, again positioned at distance *f* from both its input and output. The final
    result can then be viewed as an image at distance 4*f* from the original input
    (hence the name *4f system*). The complete system, illustrated in [Figure 16-2](ch16.xhtml#ch16fig2),
    computes the entire convolution for fixed *Y* in *O* (1) time, at the speed of
    light.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0404-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-2: A 4f filter structure*'
  prefs: []
  type: TYPE_NORMAL
- en: This structure has been known since the 1960s but has only recently become practical
    by piggybacking off well-funded commercial smartphone screen technology. It requires
    a way to filter laser light through very small but high-resolution images, both
    to create the initial input image *x*, and to create changeable filter patterns
    *Y*. *Spatial light modulators (SLMs)* are a similar display technology to 4K
    smartphone displays, originally developed for use in high-end digital overhead
    projectors. SLMs from these projectors can be taken almost off the shelf and used
    to create fast, efficient input and filter displays for 4f filters. To complete
    the setup, an image sensor is also needed to read off the final convolved image.
    Smartphone digital camera CMOS sensors have been developed, almost symmetrically
    with display technology, to provide similar resolutions and frame rates required,
    and can again be used almost off the shelf. Systems built from these components
    at the time of writing might use 4 megapixels at 15 kHz frame rates.
  prefs: []
  type: TYPE_NORMAL
- en: '*Optical Neural Networks*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Practical optical correlators have become available at the same time that deep
    learning has revolutionized commercial machine learning. Deep learning has so
    far consisted of running 1970s neural network algorithms on fast, parallel GPU
    architectures. In many cases, however, it could be massively accelerated using
    optical correlators. This is because many problems, especially object recognition
    in images and video, have a spatially invariant structure, meaning the properties
    of images don’t vary significantly based on which part of the image is being looked
    at; similar objects are found at all locations around the image. This structure
    enables *convolutional neural networks (CNNs)* to use the same weights in all
    nodes within each layer of the network. Mathematically, the effect of this is
    that each network layer can be viewed as performing a convolution of the layer’s
    inputs with a single weight vector. Computing these convolutions thus becomes
    the main workhorse operation of these neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: The first practical demonstration of an optical CNN was in 2018, and UK company
    Optalysys is now commercializing this technology by producing prototypes of consumer
    optical correlators, as shown in [Figure 16-3](ch16.xhtml#ch16fig3).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0405-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-3: An optical correlator PCIe card*'
  prefs: []
  type: TYPE_NORMAL
- en: This device can now be plugged into a desktop PCIe slot to replace GPUs for
    deep learning and other applications.
  prefs: []
  type: TYPE_NORMAL
- en: DNA Architectures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Beginning around 2000, labs have investigated *DNA computing* as a way to solve
    hard computation problems using massive biological parallelism. DNA molecules,
    as found in living cells, may be viewed (depending on one’s conception of representation)
    as performing computations, and it’s been shown that they can encode and efficiently
    solve computationally NP-hard problems such as the traveling salesperson problem.
    To understand DNA computing, we’ll need a bit of background information.
  prefs: []
  type: TYPE_NORMAL
- en: DNA (deoxyribonucleic acid) is the “source code” for life on Earth. In cellular
    organisms, every cell contains a complete copy of the whole organism’s code (genome)
    in a set of large double-helix molecules (chromosomes) inside the cell nucleus.
  prefs: []
  type: TYPE_NORMAL
- en: 'Small parts (genes) of the information encoded in the DNA molecule are copied
    (transcribed) onto RNA (ribonucleic acid) molecules, which then move out of the
    nucleus and form construction sites for particular protein molecules to be built.
    These protein molecules build up the actual body of the organism. This process
    is known as the *central dogma* of molecular biology: DNA makes RNA; RNA makes
    proteins.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each rung of DNA’s double-helix ladder is formed from a matching pair of *nucleotides*,
    small (around 20 atoms) organic molecules of which there are four types: A, T,
    C, and G. Each has one partner to make pairs: A and T go together; C and G go
    together. Humans have 23 chromosomes containing a total of about 3 gigapairs of
    nucleotides. DNA thus uses a base 4 data representation with symbols A, T, C,
    and G, and the source code for the human genome is about 6 gigabits. This is a
    similar size to an operating system, and like an operating system, the human genome
    has been distributed on a single CD-ROM.'
  prefs: []
  type: TYPE_NORMAL
- en: DNA technology used to be expensive; for example, it took $100 million to sequence
    the first human genome in 2001\. But it has recently rapidly fallen in price,
    reaching $1,000 in 2015 and $100 in 2023\. This decline in price means the time
    is ripe to consider DNA as a medium for computation.
  prefs: []
  type: TYPE_NORMAL
- en: '*Synthetic Biology*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Rather than using DNA to store source code for making proteins, as in nature,
    *synthetic biologists* can use DNA to represent, edit, select, and copy arbitrary
    data. This enables Church computers to be constructed using DNA data representation
    and processing.
  prefs: []
  type: TYPE_NORMAL
- en: ATCG strings of DNA can be edited via cutting, splicing, and inserting symbols,
    as in an ASCII text editor. This is done using custom enzymes that promote the
    desired reactions. A small set of these enzymes is now well known and can be used
    routinely to perform these operations.
  prefs: []
  type: TYPE_NORMAL
- en: As for the strings themselves, it’s now surprisingly easy to produce your own
    arbitrary sequences of DNA, which can then be used to store and compute in base
    4 as a string of ATCG symbols. It can almost now be done at home using a modified
    consumer inkjet printer, with its usual cyan, magenta, yellow, and black (CMYK)
    inks replaced by solutions of ATCG molecules. DNA manufacturing can also be performed
    on industrial-chemistry scales, making huge numbers of identical or related molecules
    in a liquid the size of a swimming pool. Consider that just a glass of water contains
    around 10^(24) water molecules, more than all the bits of data in the world.
  prefs: []
  type: TYPE_NORMAL
- en: Information can be read back from physical DNA using electrophoresis, the same
    technique used for DNA fingerprinting in crime scene investigations. The *polymerase
    chain reaction (PCR)* also provides a method to select and copy one particular
    strand of DNA from a large solution of different strands, the equivalent of extracting
    a substring from a string.
  prefs: []
  type: TYPE_NORMAL
- en: '*DNA Computing*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Computationally, PCR provides a fast search algorithm. If we can make a liquid
    containing billions of strands, each encoding a different candidate answer to
    a computational problem, then we can use PCR to quickly pick out and read off
    the correct answer.
  prefs: []
  type: TYPE_NORMAL
- en: PCR is a chain reaction, meaning it continues to run and to expand its effects
    exponentially over time. If the mixture contains just a single DNA strand containing
    the search string, then that strand will be copied, then each of the copies will
    also be copied, and so on, until almost the whole liquid ends up full of billions
    of copies of the answer. This means that a sample of the liquid analyzed by electrophoresis
    will almost certainly show the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: In 1994, Leonard Adelman successfully used DNA computations to solve a seven-city
    traveling salesperson problem. The traveling salesperson is a classic NP-hard
    problem that asks for the shortest route someone can take to visit each of *N*
    cities and return home, given a matrix of distances between them. Adelman represented
    the identity of each city with a short DNA string, then represented routes as
    strings concatenating these identifiers.
  prefs: []
  type: TYPE_NORMAL
- en: As in standard traveling salesperson formulations, the shortest route question
    was reformulated as an *O*
  prefs: []
  type: TYPE_NORMAL
- en: '*(n*) series of Boolean questions of the form “Does there exist a route with
    length less than *n*?” This question, along with the distance metrics between
    the cities, was encoded as a primer, which binds only to DNA strands representing
    routes with the desired property (having a length less than *n*). For each *n*,
    a chemical solution was prepared consisting of many copies of strands of every
    possible route, in a human-scale vat. The primer was mixed in, then PCR applied
    to amplify any successful result. Electrophoresis was used to read off the results.
    This was able to find shortest routes for *N* = 7 cities.'
  prefs: []
  type: TYPE_NORMAL
- en: This doesn’t mean that *P* = *NP* for DNA computers; in time, this is *O* (*n*),
    but it still requires exponential resources in the number of molecules. It’s just
    that with DNA there are a lot of molecules available. DNA is thus able to solve
    much larger instances of NP-hard problems than other technologies, but like all
    technologies, there will exist problem sizes that are still too large due to the
    nature of NP-hardness.
  prefs: []
  type: TYPE_NORMAL
- en: Current research is trying to move DNA computing architectures out of vats in
    biology labs and into miniaturized biochemical chips that will operate more like
    normal silicon computers. DNA computing seems unlikely to replace electronics
    for day-to-day computing tasks, such as running desktop applications, but it might
    become useful as co-processing in scientific computing for solving large, hard
    computational problems.
  prefs: []
  type: TYPE_NORMAL
- en: Neural Architectures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Neuroscience has been an important influence on architecture since at least
    John von Neumann’s *Draft Report on the EDVAC*, which used many neural ideas as
    direct inspiration. Hardware neural networks have been researched for many decades,
    but the 2010s saw them take off spectacularly with the GPUs used for deep learning.
    In the 2020s, NPUs began to appear on mobile phones and in the cloud for machine
    learning. Computational neuro-science research continues and may inspire radically
    different computer architectures, beyond current neural networks used in deep
    learning. As with all computer architectures, we’ll here consider the brain’s
    architecture on multiple levels of hierarchy, from its equivalents of transistors,
    through neurons (brain cells), up to its equivalent of computer design.
  prefs: []
  type: TYPE_NORMAL
- en: '*Transistors vs. Ion Channels*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Recall that a transistor is a digital switch, about 10 nm in diameter in modern
    chips. It has an input and output, and if you activate the switch, current flows
    between them. We’ve seen that transistors work by balancing several chemical and
    physical forces, and the switch tips this balance to allow the current to flow.
    Transistors (and chips in general) are made from semiconductors based around silicon,
    which makes four chemical bonds with neighboring atoms. Really understanding transistors
    needs chemistry and quantum mechanics.
  prefs: []
  type: TYPE_NORMAL
- en: The brain analog of the transistor isn’t the neuron but the *ion channel*, which
    is a subcomponent of a neuron, as shown in [Figure 16-4](ch16.xhtml#ch16fig4).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0408-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-4: An ion channel, in closed (left) and open (right) states. Ligands
    (3) bind to the channel (1) to open it, allowing ions (2) to flow through it.*'
  prefs: []
  type: TYPE_NORMAL
- en: Ion channels are single-molecule digital switches, also about 10 nm in diameter,
    made from proteins and built into the membranes of neurons. Depending on their
    switching state, they either allow or don’t allow certain chemicals to flow between
    the inside and the outside of the neuron. Their switching states are determined
    by the balance of electrical and chemical forces, which can be tipped when another
    chemical binds to the ion channel, or when a voltage is applied to it.
  prefs: []
  type: TYPE_NORMAL
- en: Ion channels (and brains in general) are based around carbon, which makes four
    chemical bonds with neighboring atoms. As with transistors, really understanding
    ion channels needs chemistry and quantum mechanics.
  prefs: []
  type: TYPE_NORMAL
- en: '*Logic Gates vs. Neurons*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Neurons ([Figure 16-5](ch16.xhtml#ch16fig5)) are usually considered as the basic
    unit of computation in brains.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0409-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-5: A neuron*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Neurons are about 1 µm in diameter. Computationally, they’re built from many
    ion channels. They also have many other cellular structures needed to support
    their existence and power requirements. They function as boxes that take a number
    of digital inputs and give one digital output, somewhat like the multi-input AND
    gate seen in [Figure 6-2](ch06.xhtml#ch06fig2). A multi-input AND gate’s function
    can be written mathematically using a Boolean algebra equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0409-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *b* is the Boolean “sum squashing function”:'
  prefs: []
  type: TYPE_NORMAL
- en: '*b* (*x*) = (*x* ≥ *N*)'
  prefs: []
  type: TYPE_NORMAL
- en: Logic gates such as a multi-input AND are clocked, so their inputs and outputs
    are considered valid only for short periods of time, until the next computation
    begins.
  prefs: []
  type: TYPE_NORMAL
- en: 'In simple computational models, as typically used in current machine learning
    neural networks—and coded as a GPU kernel as in [Chapter 15](ch15.xhtml)—a single
    neuron’s function is assumed to be given by the equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0409-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here the *w*s are adjustable weight values modified during learning, and *f*
    is the same squashing function:'
  prefs: []
  type: TYPE_NORMAL
- en: '*f* (*x*) = (*x* ≥ *N*)'
  prefs: []
  type: TYPE_NORMAL
- en: This notation assumes that one of the inputs is set permanently to 1, rather
    than containing any actual data. This special input is known as a *bias* or *affinating*
    input; it’s needed to make most neural network models work.
  prefs: []
  type: TYPE_NORMAL
- en: Neurons typically “fire” for short periods of time, so their inputs and outputs
    are considered valid only for short periods of time until the next computation
    begins. Unlike logic gates, there is typically a lot of noise in neurons, which
    can be modeled by adding random numbers to their inputs. Some models consider
    this noise to be an important probabilistic aspect of their computation.
  prefs: []
  type: TYPE_NORMAL
- en: This is a very simple model of neuron function, and close relations of it work
    well for current machine learning applications, such as the *f* = *reLU* GPU neuron
    we built in [Chapter 15](ch15.xhtml). However, real biological neurons come in
    hundreds of different shapes and sizes that may have much more complex behaviors,
    and these have been argued to include more complex computations such as summations,
    multiplications, divisions, exponentiation, logarithms, temporal memory, and filtering.
    This school of thought emphasizes the complexity of neurons as whole living and
    computing cells in themselves, and reminds us of the complex computations performed
    by other single cells such as bacteria and sponge cells.
  prefs: []
  type: TYPE_NORMAL
- en: '*Copper Wires vs. Chemical Signals*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s compare the wiring in the brain with the wiring in a chip. In a chip,
    we use photolithography to first lay down layers of transistors on a 2D plane.
    In modern chips, we then lay down a few overlapping layers of copper wire on top
    of the transistors to make connections between them, as we saw in [Figure 4-19](ch04.xhtml#ch04fig19).
    Communication over these wires is very fast and accurate, as it’s purely electrical.
    Messages are digital, meaning the wire is either high or low voltage, which can
    be viewed as representing 1 or 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'Neurons are usually long, extended cells, including a long *axon* component
    that functions as a wire to carry information around the physical brain. Human
    axons range from 1 µm to 2 m long—the longest are the axons in the neurons connecting
    your toe to your brain. Communication is slow and noisy, as messages travel along
    axons via a complex biochemical process involving ion channels opening and closing
    to move chemicals in and out of the cell. When the end of the axon connects to
    another neuron (at a joint called a *synapse*), there’s a second biochemical process
    in which chemicals released from the first cell travel into the second one. Messages
    are digital: the axon is either firing or not firing, which can be viewed as representing
    1 or 0\. Architecturally, a whole neuron is thus analogous to a logic gate with
    a single long output wire.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Simple Machines vs. Cortical Columns*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The next architectural level is the simple machines level. In human-designed
    computers, simple machines are made from several logic gates that together perform
    some single useful function. There are many different standard simple machines,
    such as adders, decoders, and registers, each specialized for a particular task.
    Typical simple machines can be laid out with TTL chips, as we saw in [Figure 5-13](ch05.xhtml#ch05fig13).
  prefs: []
  type: TYPE_NORMAL
- en: This is the least understood level of brain architecture, and therefore the
    most exciting topic for scientific research. Some researchers argue that the human
    cortex consists entirely of repeated *cortical column* microcircuits, each composed
    of a few hundred or thousand instances of a handful of different types of biological
    neuron, occupying a cylinder around 20 µm in diameter and 2 mm in depth.
  prefs: []
  type: TYPE_NORMAL
- en: The neurons forming the cortical column microcircuit are arranged across six
    distinct layers of cortex and always connected in the same specific way, as shown
    in [Figure 16-6](ch16.xhtml#ch16fig6). We know the connectivity between the populations
    of the different types of neurons here, but not the connectivity between individual
    neurons or the weights of the connections. There’s at least some superficial similarity
    between the structure in [Figure 16-6](ch16.xhtml#ch16fig6) and the RAM seen in
    [Figure 6-22](ch06.xhtml#ch06fig22).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0411-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-6: The cortical microcircuit architecture*'
  prefs: []
  type: TYPE_NORMAL
- en: Some computer scientists have speculated that these microcircuits might function
    as building blocks of probabilistic or other calculations. The precise wiring
    of the module circuit remains unclear and requires advances in brain imaging technology
    before we can run a “debugger” on it to learn what it’s actually doing. Unlike
    with digital logic microcircuits, there appears to be only this one cortical microcircuit,
    which is used all over the cortex. Reverse engineering the cortical microcircuit
    is one of the biggest science challenges of the 21st century. It needs computer
    architects and their experience to help suggest computational functions, alongside
    biological neuroscientists to collect data and link to their biological knowledge,
    and physicists to design new experimental equipment able to see this data. Nobel
    Prizes seem likely for those who crack its code.
  prefs: []
  type: TYPE_NORMAL
- en: '*Chips vs. Cortex*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At the highest level of structure, the cortex is surprisingly similar to chips.
    This is because they’re both laid out in 2D planes, and composed of tens of fairly
    independent modules with connections between them. For chips, we’re used to seeing
    2D layouts such as in [Figure 11-5](ch11.xhtml#ch11fig5). For brains, it’s less
    obvious because the 2D sheet of the cortex is crumpled like a discarded piece
    of paper into three dimensions. It can easily be uncrumpled, though, and spread
    out across a 2D surface to show its true structure ([Figure 16-7](ch16.xhtml#ch16fig7)).
    It’s this sheet that contains the six-layer microcircuits discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0412-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-7: The cortex appears three-dimensional (left), but uncrumpled it
    becomes a 2D sheet, like a paper page or silicon chip (right). The modules, known
    as Brodmann areas, are labeled with numbers.*'
  prefs: []
  type: TYPE_NORMAL
- en: The modules of cortex are known as *areas*, and most have been associated with
    particular functions and activities, such as vision, hearing, touch, and planning.
    Within each module, connectivity always follows the cortical microcircuit architecture
    and (arguably) a columnar structure, (arguably) with strong connectivity within
    each column and weaker connectivity between columns. Most modules have large bundles
    of axons that send output information to other modules. Projections are always
    from and to the same layers within these modules, as part of the microcircuit.
    We know which modules send outputs to which others, but not the detailed connectivity
    of which neurons connect to which within them.
  prefs: []
  type: TYPE_NORMAL
- en: This is all very like chip architectures, which also often have tens of modular
    components, each having strong connections within them, and more limited bundles
    of connections flowing between them. Modern chips have several layers of 3D-printed
    copper wires to connect components together, sharing the brain’s basic plan of
    a 2D layout with 3D connections linking different areas. A big difference, though,
    is that all the component areas of the brain share the same internal architecture
    of layers and columns, while the component areas of chips usually contain completely
    different designs.
  prefs: []
  type: TYPE_NORMAL
- en: '*Parallel vs. Serial Computation*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Consider how modules are connected together in a CPU or a cortex. CPUs are inherently
    serial machines, designed to execute programs of instructions in sequence. As
    such, a CPU has a clearly defined “top” of its design hierarchy, the control unit,
    that acts as the executive telling all the other modules what to do and when to
    do it; we saw this in [Figure 7-13](ch07.xhtml#ch07fig13).
  prefs: []
  type: TYPE_NORMAL
- en: A cortex also has a hierarchy, with frontal areas thought to be involved in
    executive control and posterior (rear) areas more involved in running perception
    and action. Perception and action for each sense (vision, touch, and so on) are
    known to consist of hierarchies of areas; for example, lower visual areas process
    edges and corners, and higher ones detect faces and named people. These areas
    all run in parallel, and they’re composed of columns that also all run in parallel.
    The frontal areas seem to coordinate the overall activity, but the perception
    and action areas can function by themselves when the frontal areas are damaged.
  prefs: []
  type: TYPE_NORMAL
- en: None of these modules are active unless triggered by the *thalamus*, which in
    this context looks and acts somewhat like a CPU control unit, and can be seen
    in the lower part of [Figure 16-6](ch16.xhtml#ch16fig6).
  prefs: []
  type: TYPE_NORMAL
- en: While the modules relay information directly to one another, they also communicate
    with regions of the thalamus that appear to mirror their structure and act to
    turn them on and off and resolve conflicts between them.
  prefs: []
  type: TYPE_NORMAL
- en: When you introspect your own subjective experience of computing solutions to
    complex high-level perception and action-planning problems, it may appear that
    your brain is operating like a serial machine, imagining and testing out different
    hypotheses and actions in a sequence. This observation can be supported by the
    more objective evidence that other humans take *O(N)* time for such tasks when
    timed in a lab. Internally, however, we also think of the brain as a massively
    parallel system, with all its neurons potentially in use simultaneously. This
    is similar to thinking of the CPU first as a serial processor, then thinking of
    it as a massively parallel digital logic circuit in which all its billions of
    transistors are potentially in use simultaneously. Outside the brain and CPU,
    both have external modules, whether connected by a spinal cord or a bus.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *hippocampus* is a special part of the cortex: it sits right at the top
    of the hierarchy, and its microcircuit is a little different from the rest. Instead
    of having cortical layers that process data to send up to higher regions, the
    hippocampus has different layers, called DG, CA1, and CA3, that include feedback
    connections, connecting what would usually be outputs back into themselves. Rather
    than send computations up to more abstract layers of processing, they’re sent
    through *time* to the same, functionally highest, area of the cortex. Computational
    architectures have been developed based on the hippocampus, on the assumption
    that it’s used as a form of spatiotemporal memory. These architectures enable
    robots to navigate and map the space and objects around them.'
  prefs: []
  type: TYPE_NORMAL
- en: Architects have been intrigued and inspired by the brain throughout the electronic
    era. Current interest in deep learning has brought some of these links into mainstream
    architectures, such as the neural processing units now found in many phones. These
    architectures are loosely based on models of neurons and on hierarchical cortical
    areas. But we’ve seen here that real brains include much additional complexity—ion
    channels, cortical microcircuits, and emergent serial computation from parallel
    structures—that may provide inspiration for further developments. It’s common
    for philosophers to debate whether any silicon-based simulation of brain structures
    could fully replicate human intelligence or consciousness. Those arguing against
    typically invoke properties of physics that don’t usually appear in silicon, such
    as quantum effects. However, computer scientists have begun to explore computing
    with some of these effects too, as we’ll see in the next sections.
  prefs: []
  type: TYPE_NORMAL
- en: Quantum Architectures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Quantum computing is based on the physics of quantum mechanics, which is famously
    strange and counterintuitive. In quantum mechanics, objects no longer have precise
    locations or velocities; rather, they exist in wave-like states that range over
    many possible locations and velocities. These states define the probabilities
    of actually seeing the object at one of these locations or velocities when you
    look at it. Quantum concepts are genuinely mind-blowing, and will radically change
    your whole view of reality, causation, and time.
  prefs: []
  type: TYPE_NORMAL
- en: A full presentation of quantum mechanics or quantum computing is beyond the
    scope of this book. Here I can only give a flavor of the concepts and a glimpse
    at what the basic equations look like. It’s worth pointing out, however, that
    modern quantum computing can be studied with little or no reference to the usual
    presentation of quantum mechanics given in physics, making the field somewhat
    easier to approach. In particular, computer science is a mostly discrete subject,
    dealing with 0s, 1s, and sums, rather than the continuous real numbers and integrals
    typical of quantum mechanics. The discretized mathematics used in quantum computing
    requires only high school linear and matrix algebra, complex numbers, and probability.
  prefs: []
  type: TYPE_NORMAL
- en: '*A Cartoon Version of Quantum Mechanics*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The following is *not a correct presentation of quantum mechanics* and is intended
    only as a cartoon to introduce some key concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that objects in the world don’t just exist in a single state at a time.
    For example, a cat inside a box may at the same time be both standing up, being
    alive, and also lying down, being dead. This famous example is known as *the superposed
    cat*. Suppose that the cat is locked inside the box along with a piece of radioactive
    material. Radioactive material decays completely at random: its behavior can’t
    be predicted in any way. A radiation decay detector is placed next to it, and
    connects to a mechanism that releases poison gas into the box, killing the cat
    if radiation is detected and leaving it alive if not.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You leave this experimental apparatus alone for, say, 10 minutes. You might
    know something about the strength of the radiation, so you can say that after
    10 minutes there’s some probability, say 20 percent, that a decay has taken place
    and the cat is dead, and some other probability, say 80 percent, that it hasn’t
    taken place and the cat is alive. We might represent the current “state” of the
    cat by a distribution such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Cat* = {*alive* : 0.8, *dead* : 0.2}'
  prefs: []
  type: TYPE_NORMAL
- en: Classically—that is, without considering quantum mechanics—you would normally
    think of this distribution as being a property of your own *knowledge* rather
    than a property of the *world*. You would assume that the cat is actually in only
    one state or the other, either alive or dead. It’s just that your brain doesn’t
    know which, so *it* (your brain) contains a model carrying the two states and
    the probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: In quantum mechanics this is absolutely and demonstrably *not* the case. The
    two versions of the cat aren’t only in your head but are also both actually out
    there in the world in some sense. Roughly, we imagine two versions of reality—one
    where the cat is alive and one in which it’s dead—existing together until the
    moment you open the box. When that moment comes, reality “decides” which state
    will be the actual one, randomly but according to the probabilities, and the other
    state goes away forever. We say that your act of observing the cat changes its
    state, from existing as two versions with probabilities to existing as a single
    version.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the basic idea, let’s take a look at the math version. You
    aren’t expected to understand all of the math symbols, technical terms, or commands
    used in the rest of this section. If you happen to be familiar with linear algebra
    and complex numbers, then you can follow the details, but otherwise it’s okay
    just to glance over them to get a flavor of the field.
  prefs: []
  type: TYPE_NORMAL
- en: '*The Math Version of Quantum Mechanics*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The correct presentation of quantum mechanics consists of four rules; superposition,
    observation, action, and combination.
  prefs: []
  type: TYPE_NORMAL
- en: '**Rule of Superposition**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Objects exist in a *superposition* of states, each with a complex number amplitude
    whose squared moduli sum to 1\. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0415-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![Image](../images/f0415-02.jpg) and the rows of the vector represent
    the amplitudes of the cat being dead (binary state 0) and alive (binary state
    1), respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '**Rule of Observation**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When you observe states in a basis, they collapse to one of the basis states
    of the observation basis, at random, according to the moduli of their *squared*
    amplitudes. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0416-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: These results are always real numbers between 0 and 1, representing the probabilities
    of observing each possibility.
  prefs: []
  type: TYPE_NORMAL
- en: '**Rule of Action**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Any physical action, including computation, performed on the system—apart from
    observation—is modeled by a unitary matrix. The matrix operates on the state by
    ordinary matrix multiplication. For example, the action of a NOT gate is modeled
    by a matrix that swaps the dead and live states’ amplitudes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0416-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, the NOT matrix, like all unitary matrices, preserves the property of state
    vectors that the sum of their probabilities, from the rule of observation, is
    1.
  prefs: []
  type: TYPE_NORMAL
- en: '**Rule of Combination**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The state of two objects considered together is the joint state formed by the
    tensor product of the individuals:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0416-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The |⟩ notation used in quantum mechanics and quantum computation is called
    *ket notation*. For discrete computer scientists, this simply denotes a column
    vector, which in other subjects is sometimes denoted by underlining, using an
    arrow, or using bold. The name comes from a pun on the word *bracket*. Inner products
    are sometimes written ⟨***a***| ***b*** ⟩ = ***a^Tb***, which is called a “braket.”
    If we write ⟨***a***| = ***a ^T*** and |*b*⟩ = ***b***, then we can call these
    two new symbols the “bra” and the “ket,” which together make a “braket.”
  prefs: []
  type: TYPE_NORMAL
- en: '*Quantum Registers of Qubits*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Could we exploit the apparent existence of interacting parallel realities as
    a form of parallel computation? If we could distribute computational work across
    the parallel realities, as we would more normally distribute across multiple CPUs
    in a single reality, and then somehow find a way to combine the results into the
    single reality in which we happen to be ourselves, then we could exploit the vast
    additional computational resources in those other realities. We could build a
    single CPU and have it compute many things at once across the parallel realities,
    instead of needing to build many CPUs. This idea, first proposed by Richard Feynman
    in 1988, is the beginning of quantum computing.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the superposed cat. We could use the cat’s aliveness and dead-ness
    as a 1-bit data representation via the encoding *dead* = 0 and *alive* = 1\. Call
    this a *qubit*, for *quantum bit*. We could then build an *N*-bit register by
    placing *N* of these cats-in-boxes in a row, to store words, as in a classical
    register based on flip-flops. Until we open the boxes in the register, there are
    multiple realities in which the cats inside them are alive and dead. When we open
    them, we see just one version of reality and that becomes the reality we experience
    ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: Like a classical register, an *N*-qubit quantum register has 2^(*^N*) possible
    states. Each of these states of the whole register can exist at the same time
    in a “parallel world.” This is a much larger set of states than just the *N* cats.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can play with this using a quantum computer simulator such as QCF (Quantum
    Computing Functions). In QCF, you can begin by creating non-superposed register
    states, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The resulting output shows a state vector for a 3-bit register that’s entirely
    in the 011 state (representing the decimal number 3). There’s zero amplitude of
    being in the zeroth state 000; zero amplitude of being in the first state, 001;
    zero amplitude of being in the second state, 010; full amplitude, 1, of being
    in the third state, 011; and zero amplitude of the other states, up to the seventh,
    111.
  prefs: []
  type: TYPE_NORMAL
- en: 'QCF also has a command to create similar, non-superposed states directly from
    the decimal numbers being represented; for example, to create a 3-bit register
    entirely in the state representing decimal 5, use this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'So far, these are only the same single states that a classical 3-bit register
    could exist in. Next, we can simulate a register in a superposition of both of
    these states at the same time, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To simulate a measurement (observation) of this register, we can do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This will randomly produce one of the following two outputs, with probabilities
    given by the squared amplitudes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The individual qubits’ states aren’t independent; they’re *entangled*. In our
    QCF example, the first two observed bits must read either 01 or 10; they can’t
    read 11 or 00\. Therefore, if you look at the first bit initially and see a 0,
    it means you’ll see a 1 if you later look at the second bit, and vice versa. This
    remains the case even if the qubits are physically transported millions of miles
    apart before either observation.
  prefs: []
  type: TYPE_NORMAL
- en: The register in our example may be modeled as existing in eight (that is, 2
    binary digits ^ 3 bits) states at the same time, across a set of eight “parallel
    worlds.” The number of worlds grows exponentially with register size; for example,
    a 64-bit quantum register has 2^(64) ≈ 2 × 10^(19) states, the same number as
    the number of addresses in the entire address space of a 64-bit machine, existing
    all at the same time in a single register.
  prefs: []
  type: TYPE_NORMAL
- en: 'Physicists usually don’t like to talk in terms of “parallel worlds.” Instead,
    they prefer to “shut up and calculate” to predict the outcome of a particular
    scenario: it’s all just math once they’ve been given a system to analyze. To *create*
    new quantum programs, however, it’s useful for computer scientists to think of
    each state of the register existing in a parallel world. Thinking in this way
    helps you to visualize what you’re creating and suggests ideas for what to create
    next.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Computation Across Worlds*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The amplitudes, but not the contents, of the states can affect one another
    in certain ways that are very limited by the rules of quantum mechanics, enabling
    interaction between the parallel worlds during computation. The billion-dollar
    question in quantum computing is always: how do we read back the results? We observe
    only *one* of the parallel worlds, and the one we get is random, so we need to
    find mechanisms that ensure either that the result we want to see exists in all
    of the worlds, or that the world we observe happens to be the one with a single
    copy of the result in it.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, we might try to parallelize the traveling salesperson problem by
    superposing a register so that each world has part of the register encoding a
    different possible route. Within each world, we then calculate the length of that
    route and store it in another part of the register. Then we answer a question
    such as “Does this route have a length less than 5?” and store the result as a
    single bit in a third part of the register. But our task is to answer a question
    about the whole set of possible routes, such as “Does any route have length less
    than 5?” This is a function of the information stored in all of the worlds.
  prefs: []
  type: TYPE_NORMAL
- en: Finding ways to get that information all into one place that we’re guaranteed,
    or even just likely, to see when we make an observation forms the hard part of
    quantum algorithm design, and as far as we know, these ways all introduce large
    computational complexity overheads. As a result (again, as far as we know), quantum
    computers aren’t able to make *P = NP*, but they *are* able to speed up *NP* problems
    to lower complexities within *NP*. Most quantum algorithms, such as *Grover’s
    algorithm*, work by gradually updating state amplitudes so that all worlds that
    we don’t want to see cancel each other out, and only the world that we do want
    to see remains with a large probability of appearing in the actual world. This
    is a similar approach to DNA computing’s PCR, which also performs computing over
    time to amplify the desired solution at the expense of the others. Some researchers
    believe that quantum computers will provide a general speedup of ![Image](../images/f0419-01.jpg)
    via this approach, but theory is still needed to confirm this.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few particular problems, such as breaking public key cryptography,
    that are known to have larger speedups due to their structures being especially
    close matches to the quantum laws. Finding and classifying these special cases
    is a current research topic.
  prefs: []
  type: TYPE_NORMAL
- en: '*Practical Quantum Architectures*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Small-scale quantum computers, having just a few qubits, have been successfully
    constructed and demonstrated to prove that the concept works. The main barrier
    to larger practical quantum computers is *decoherence*. This is the problem that
    *any* interaction between a superposed system and anything in the rest of the
    world tends to spread out the superposition into that thing and then into the
    rest of the world. The amount of superposition behaves roughly like a fixed resource,
    so once it leaks out of your computer it’s gone and it can’t be used in your computation
    anymore. Quantum engineers are working hard to design ways to isolate quantum
    systems from all outside influence. This is a somewhat similar problem to nuclear
    fusion, in which we set off a nuclear explosion and then try to use magnets to
    keep it controlled and contained from its surroundings.
  prefs: []
  type: TYPE_NORMAL
- en: '*Adiabatic quantum computing* is sometimes reported in the media—notably by
    the company D-Wave Systems, which has successfully sold devices to Google and
    the US government—as successfully performing quantum computing with 1,000 bits
    or more. However, adiabatic quantum computing isn’t quantum computing in the sense
    we’ve discussed. It’s a different physical process based on a very different mathematical
    model that assumes time is continuous rather than discrete, so that an infinite
    number of observations can be made in any given time interval. Completely opposite
    to quantum computing, it relies on observations (or decoherence, in some views)
    taking place continually, rather than trying to shield the system from them; the
    observations form the essential part of the actual computation. Many quantum computing
    researchers are highly skeptical of these claims, noting that there’s a long history
    of cranks in normal computer science claiming to have made *P = NP* via models
    that similarly assume infinite amounts of computation performed in finite time
    intervals.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Rose’s law* has been proposed as a quantum version of Moore’s law, hypothesizing
    that the number of qubits in working quantum computers is currently doubling every
    two years.'
  prefs: []
  type: TYPE_NORMAL
- en: Future Physics Architectures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Beyond what’s currently called quantum computing, we might more generally turn
    to modern physics and ask what else it’s discovered that might also be made into
    computing machinery.
  prefs: []
  type: TYPE_NORMAL
- en: Our best current theory of physics, the *Standard Model*, is based on *quantum
    field theory (QFT)*, which combines quantum mechanics with special (but not general)
    relativity to model reality as comprising a set of fields that each cover space
    and interact with one another. Each field corresponds roughly to one type of particle,
    and as in basic quantum mechanics, its amplitudes are those of finding a particle
    there if we look for it. Unlike basic quantum mechanics, the fields are also able
    to represent probabilities of finding multiple particles at locations, and it’s
    possible for these particles to interact and transform into one another in various
    ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Standard Model specifies particular fields and interactions to make a quantum
    field theory with 17 types of particle. (More accurately: the fields are a gauge
    quantum field containing the internal symmetries of the unitary product group
    *SU*(3) × *SU*(2) × *U*(1), and the 17 particle types emerge as patterns across
    several of these fields.) The Standard Model has been tested experimentally since
    the 1960s and hasn’t changed since then. CERN confirmed the final Higgs field
    in 2012\. A few anomalies are now known that suggest a better model might one
    day be found.'
  prefs: []
  type: TYPE_NORMAL
- en: Particle accelerators such as CERN have perfected the ability to not only observe
    but also control individual particles of the fields. Beams of different types
    of particles can be reliably produced, collided with each other or with test objects,
    and the individual particles flying out of the collision observed.
  prefs: []
  type: TYPE_NORMAL
- en: Particle physics has thus given rise to particle engineering, in which this
    technology is reused not to do science but to build practical engineered systems
    for other purposes. Governments have funded particle physics for many decades,
    not for inherent interest in what the world is made of, but because of weaponization
    potential. The beams firing around CERN can kill anything in their path. American
    1980s BEAR experiments put an accelerator in space, able to produce and fire beams
    over huge distances, trying to destroy satellites—and eventually ground targets—with
    laser-like precision. Accelerators and detectors are also being repurposed for
    treating brain cancer. By firing proton beams through the brain and detecting
    changes in their speeds, we can infer tumor structures with higher accuracy and
    less damage than other methods. Once these are known, beam strength can be turned
    up to destroy the tumors, again more accurately than with other methods.
  prefs: []
  type: TYPE_NORMAL
- en: Now that particle engineering has begun to develop, it’s natural to ask if,
    like mechanical, electrical, and electronic engineering before it, it can be used
    to construct new computer hardware. It might one day be possible to use particles
    other than electrons and photons from the Standard Model to store and compute
    with data—for example, creating a Higgs boson–based computer. Such computers might
    be constructed by accelerating particles, then using their interactions to form
    computations, perhaps as microscopic billiard ball logic gates, such as seen in
    [Chapter 5](ch05.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: QFT isn’t a complete theory of physics, because it omits gravity, which is instead
    modeled by Einstein’s *general relativity (GR)*. GR is incompatible with QFT because,
    unlike QFT, it allows space and time to change shape, bending around mass. We
    rely on relativistic engineering every day—for example, for time correction among
    GPS satellites, to correct for warping of telescope images, and to correct paths
    for missions to Mars and elsewhere. As predicted by Einstein, gravitational waves
    were observed in 2016, and are now becoming a new tool for astronomy. These effects
    are small and subtle. In contrast, while engineering systems to actively manipulate
    and exploit bending space-time is possible in theory, it requires astronomical
    scales of energy and mass. It may take centuries or millennia, or be impossible,
    to obtain these. Gödel’s “closed timelike curves” can occur in GR if space-time
    loops around on itself to form a “wormhole” shortcut path between perhaps engineerable
    points in time and space, including backward time travel.
  prefs: []
  type: TYPE_NORMAL
- en: Observers in GR may see events occur in different temporal orders depending
    on where they are and how they move. The notion of a sequential *program* becomes
    problematic if observers can’t agree on the order in which instructions are executed,
    with later stages of execution appearing to cause earlier ones. Time runs at different
    speeds for different GR observers, so if we live on a large mass, we could make
    a computer run faster by sending it far away from this mass. However, accelerating
    and decelerating it for this journey have the opposite effect of slowing its time,
    which would need to be balanced against any gains.
  prefs: []
  type: TYPE_NORMAL
- en: '*Hypercomputation* theorists have claimed theoretical machines with formal
    powers stronger than Church computers. They could use GR to predict their own
    future behavior by looking at their own past in a closed timelike curve, and thus
    solve the halting problem. This would require a radical update of our concept
    of computation.'
  prefs: []
  type: TYPE_NORMAL
- en: QFT and GR famously don’t fit together, so we have no working “Grand Unified
    Theory” (GUT) to explain the structure of reality. Current attempts include “string
    theory/M-theory,” “loop quantum gravity,” and “twistor theory,” but none actually
    work yet. Some of these theories postulate the existence of extra dimensions.
    Some theories try to model a “graviton” as an additional particle, to treat gravity
    similarly to the other forces in the Standard Model. This might be of interest
    for computation, because any gravitons must have zero mass and travel at the speed
    of light, like photons, but must also be able to interact with each other, unlike
    photons. This would avoid the non-interaction problem of speed-of-light photonic
    computers.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, discoveries about galaxy and galaxy supercluster structure and motion
    are challenging both QFT and relativity. Observations appear to require either
    the invention of new “dark matter” and “dark energy” particles, such as “axions,”
    or the replacement of relativity with a new theory. If we find that the world
    is made from superstrings, twistors, gravitons, or axions, then we can also look
    for ways to use their properties to represent data and perform computation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A new golden age of architecture is upon us. There’s never been a better time
    to get involved in architecture, both as a user and as an architect. Open source
    hardware and software now enables you to design and build serious CPUs at home,
    and to contribute them to the community.
  prefs: []
  type: TYPE_NORMAL
- en: Taking the long view of computing history, as in [Chapter 1](ch01.xhtml), suggests
    that modern ICs are just one of many possible computing technologies that come
    and go. The end of Moore’s law for clock speed has already forced us to move to
    parallel architectures, but Moore’s law for transistor density must also end as
    we reach scales of single atoms and quantum effects. This may force us to switch
    to entirely new technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Optical computing is limited by photons’ non-interactivity with one another,
    though at least in the special case of convolution filters it’s possible to make
    use of interactions within their waves, which are a coincidentally good fit to
    current deep learning computations.
  prefs: []
  type: TYPE_NORMAL
- en: DNA computing seems unlikely to appear on consumer desktops, but may have a
    niche for solving large one-off NP-hard problems. Your university or public transportation
    timetable might one day be optimized by a swimming pool full of DNA.
  prefs: []
  type: TYPE_NORMAL
- en: The human brain continues to inspire new architecture ideas. Going beyond current
    deep learning architectures, it could lead to ideas for micro-circuit-based simple
    machines and the emergence of serial behavior from massively parallel systems.
  prefs: []
  type: TYPE_NORMAL
- en: Quantum computing is now a well-understood theory, but with research still progressing
    around its difficult implementation and only a theoretical understanding of what
    speedups it can provide. Quantum computing is based on quantum mechanics, which
    has been superseded by QFT and perhaps by attempts at GUTs. Some of these theories
    are still glints in physicists’ eyes, but as with every other technology, from
    rocks to gears to silicon chips, they may also one day form the basis for future
    computer architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Crank Speedups**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You could solve any computation problem in 1 second of wall clock time using
    an Analytical Engine if you assume that you can turn its crank at arbitrary higher
    and higher speeds. Why would that not work? What might this tell us about adiabatic
    quantum computing claims?
  prefs: []
  type: TYPE_NORMAL
- en: '**Challenging**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Download QCF from *[https://github.com/charles-fox/qcf](https://github.com/charles-fox/qcf)*
    and work through the examples shown in the “Quantum Architectures” section on
    [page 414](ch16.xhtml#lev335).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: QCF comes with a longer tutorial that builds up to running Grover’s algorithm;
    work through this.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Which technology do you think will yield practical new computers first: quantum,
    optical, DNA, neural, or other? Write a blog post articulating why.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For DIY fabrication, see Stephen Cass, “The Garage Fab,” *IEEE Spectrum* 55,
    no. 1 (2018): 17–18.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For graphene transistors, see F. Wu et al., “Vertical MoS2 Transistors with
    Sub-1-nm Gate Lengths,” *Nature* 603 (2022): 259–264.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An example of 3D integrated circuits is Vasilis Pavlidis, Ioannis Savidis,
    and Eby Friedman, *Three-Dimensional Integrated Circuit Design*, 2nd ed. (Burlington:
    Morgan Kaufmann, 2017).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For details of 10,000-year storage, see J. Zhang et al., “5D Data Storage by
    Ultrafast Laser Nanostructuring in Glass,” paper presented at CLEO: Science and
    Innovations, San Jose, June 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a general introduction to optical computing, see Jürgen Jahns and Sing
    H. Lee, eds., *Optical Computing Hardware* (Boston: Academic Press, 1994).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For details of deep learning with optical correlators, see J. Chang et al.,
    “Hybrid Optical-Electronic Convolutional Neural Networks with Optimized Diffractive
    Optics for Image Classification,” *Scientific Reports* 8, no. 12324 (2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a popular science introduction to DNA computing, see Martyn Amos, *Genesis
    Machines: The New Science of Biocomputation* (London: Atlantic Books, 2006).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For details of the traveling salesperson problem with DNA computing, see J.
    Lee et al., “Solving Traveling Salesman Problems with DNA Molecules Encoding Numerical
    Values,” *BioSystems* 781, no. 3 (2004): 39–47.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For details of DNA inkjet printing, see T. Goldmann and J. Gonzalez, “DNA-Printing:
    Utilization of a Standard Inkjet Printer for the Transfer of Nucleic Acids to
    Solid Supports,” *Journal of Biochemical and Biophysical Methods* 42, no. 3 (2000):
    105–110.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The definitive text on quantum computing is Michael A. Nielsen and Isaac L.
    Chuang, *Quantum Computation and Quantum Information* (Cambridge: Cambridge University
    Press, 2000).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the origin of quantum computing, including links to heat, energy, and information
    issues in computing, see Richard Feynman, *The Feynman Lectures on Computation*
    (London: Westview Press, 1996).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For an overview of biological neural architectures, see Larry Swanson, *Brain
    Architecture: Understanding the Basic Plan* (Oxford: Oxford University Press,
    2011).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the definitive guide to the many complex computations by single neurons,
    beyond simple models, see Christof Koch, *Biophysics of Computation* (Oxford:
    Oxford University Press, 1999).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For examples of advanced computations performed by single-cell organisms, see
    R. Lahoz-Beltra, J. Navarro, P. Marijuan, “Bacterial Computing: A Form of Natural
    Computing and Its Applications,” *Frontiers in Microbiology* 5, no. 101 (2014).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See *[https://ai.googleblog.com/2021/06/a-browsable-petascale-reconstruction-of.html](https://ai.googleblog.com/2021/06/a-browsable-petascale-reconstruction-of.html)*
    for an interactive 3D view of human cortical microcircuit connectivity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a popular science introduction to future physics, see Brian Greene, *The
    Elegant Universe: Superstrings, Hidden Dimensions, and the Quest for the Ultimate
    Theory* (New York: Vintage, 2000).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
