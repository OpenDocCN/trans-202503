- en: '22'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '22'
- en: Generative Adversarial Networks
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: '![](Images/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/chapterart.png)'
- en: Generating data is exciting. It lets us produce new paintings, songs, and sculptures
    that have a resemblance to their inputs. In Chapter 18 we saw how to use autoencoders
    to generate new data that was like the training data. In this chapter we explore
    a completely different approach to data generation. The type of system we look
    at is called a *Generative Adversarial Network*, or *GAN*. It’s based on a clever
    strategy where two different deep networks are pitted against one another, with
    the goal of getting one network to create new samples that are not from the training
    data, but are so much like the training data that the other network can’t tell
    the difference.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 生成数据是令人兴奋的。它让我们能够创作出新的画作、歌曲和雕塑，这些作品与它们的输入数据相似。在第18章中，我们看到如何使用自动编码器生成与训练数据相似的新数据。在这一章中，我们将探索一种完全不同的数据生成方法。我们研究的系统类型称为*生成对抗网络*，简称*GAN*。它基于一种巧妙的策略，通过让两个不同的深度网络相互对抗，目标是让一个网络创造出新的样本，这些样本不是来自训练数据，但足够像训练数据，以至于另一个网络无法分辨。
- en: The GAN method is actually a technique for training a network that generates
    new data. That trained generator is just a neural network like any other, and
    the method we used to train it isn’t relevant anymore. But the language of the
    field frequently refers to a generator trained with the GAN method as a GAN itself.
    It’s a bit weird to name something not for what it does, but for how it learned
    to do its job, but we do. Thus we use the GAN technique to train a generator,
    which is often called a generator, but also often called a GAN.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 方法实际上是一种训练生成新数据的网络的技术。训练后的生成器就像任何其他神经网络一样，而我们用来训练它的方法已经不再重要了。但该领域的语言通常将使用
    GAN 方法训练的生成器本身称为 GAN。虽然这种命名方式有点奇怪，因为它是根据网络学习如何完成任务的方式来命名的，而不是根据它的实际功能，但我们就是这么做的。因此，我们使用
    GAN 技术来训练生成器，这个生成器通常被称为生成器，但也经常被称为 GAN。
- en: Let’s begin our discussion of the GAN method by looking at how a two-person
    team can learn to forge money by helping each other learn. Then we can replace
    the two people with neural networks. One of these networks becomes better and
    better at spotting forgeries, and the other becomes better and better at making
    forgeries. When the training process is over, the forger is able to make as many
    new and different bills as we like, and the detector can’t reliably distinguish
    counterfeits from real bills. The process works for any kind of data, from pictures
    of dogs to the sound of someone speaking.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从讨论 GAN 方法开始，首先看看一个由两个人组成的小组如何通过互相帮助学习伪造钞票。然后，我们可以将这两个人替换成神经网络。其中一个网络变得越来越擅长识别伪钞，另一个则变得越来越擅长制作伪钞。当训练过程结束时，伪造者能够制作出任意数量的新钞票，并且判别器无法可靠地区分伪钞和真钞。这一过程适用于任何类型的数据，从狗的图片到某人说话的声音。
- en: We’ll see how to build, train, and use these coupled networks to synthesize
    new data, using different kinds of layers. We wrap up the chapter by discussing
    issues to look out for when training and using the data-generating part of these
    networks.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到如何构建、训练并使用这两个网络来合成新数据，使用不同类型的层。章节最后，我们会讨论在训练和使用这些网络生成数据时需要注意的问题。
- en: Forging Money
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伪造钞票
- en: The usual way to introduce a GAN is by analogy to a counterfeiting operation.
    We will present a variation on the typical presentation to better expose the key
    ideas.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍生成对抗网络（GAN）通常通过类比伪造操作来进行。我们将展示一种变体的典型介绍方式，以更好地揭示关键思想。
- en: The story begins with two conspirators, Glenn and Dawn. Glenn’s name starts
    with G because he plays the role of the *generator*, in this case forging new
    money. Dawn’s name begins with D because she plays the role of the *discriminator*,
    in this case tasked with determining whether any given bill is real or one of
    Glenn’s forgeries. Glenn and Dawn are going to both improve over time, thereby
    pushing the other to improve as well.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 故事开始于两位共谋者，Glenn 和 Dawn。Glenn 的名字以 G 开头，因为他扮演的是*生成器*的角色，在这种情况下是伪造新钞票。Dawn 的名字以
    D 开头，因为她扮演的是*判别器*的角色，负责判断某张钞票是否真实，或者是 Glenn 伪造的。Glenn 和 Dawn 都会随着时间的推移不断改进，从而推动彼此的改进。
- en: As the generator, Glenn sits in a back room all day, meticulously creating metal
    plates and printing false currency. Dawn is the quality-control half of the operation.
    It’s her job to take a mixed-up pile of real bills along with Glenn’s forgeries,
    and decide which is which. The penalty for forgeries in their country is life
    in prison, so they’re both highly motivated to produce bills that nobody can tell
    from the real thing. Let’s say that the currency of their country is called the
    Solar, and they want to counterfeit the 10,000 Solar bill.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 作为伪钞制造者，Glenn整天坐在后面的房间里，仔细制作金属版并印刷假币。Dawn是质量控制的一部分。她的工作是将一堆混合的真钞与Glenn的伪钞一起检查，分辨哪个是真哪个是假。伪钞在他们国家的刑罚是终身监禁，所以他们都非常有动力制造出没人能分辨的钞票。假设他们国家的货币叫做Solar，他们想要伪造10,000
    Solar钞票。
- en: An important thing to note is that all 10,000 Solar bills are not the same.
    At the very least, each bill has a unique serial number. But real bills are also
    scuffed, folded, drawn on, torn, dirtied, and otherwise handled. Since new, crisp
    bills stand out, Glenn and Dawn want to produce currency that looks just like
    all the other, worn currency in circulation so that it blends in and doesn’t catch
    anyone’s eye. And like real bills, every counterfeit bill should look unique.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，所有的10,000 Solar钞票都不相同。至少，每一张钞票都有一个独特的序列号。但真正的钞票也会被刮伤、折叠、涂画、撕裂、弄脏，或者以其他方式被处理过。由于崭新的钞票显眼，Glenn和Dawn希望制造出看起来和流通中的其他旧钞票一模一样的货币，这样它才能融入其中，不引人注意。就像真正的钞票一样，每一张伪造钞票也应该看起来独特。
- en: 'In a real situation, Glenn and Dawn would surely start off with a huge stack
    of real bills, and pore over every detail, learning everything they could. But
    we’re just using their operation as a metaphor, so we’re going to put in some
    restrictions to make this situation better match the algorithms this chapter is
    dedicated to. First, let’s simplify things a little and say that we only care
    about one side of the bill. Second, we’re not going to give Glenn and Dawn each
    a stack of bills to study before they begin. In fact, let’s assume that neither
    Dawn nor Glenn has any idea what a real 10,000 Solar bill looks like. Clearly
    this is going to make things a *lot* harder. We’ll justify this in a moment. The
    one thing we do give them goes to Glenn: a big stack of blank rectangles of paper
    that match the shape and size of a 10,000 Solar bill.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际情况下，Glenn和Dawn肯定会从一大堆真钞开始，仔细查看每一个细节，尽可能地学习所有信息。但我们只把他们的操作作为一个隐喻，因此我们会设置一些限制，使这个情况更符合本章讨论的算法。首先，我们简化一下，假设我们只关心钞票的一面。其次，我们不会给Glenn和Dawn每人一堆钞票让他们在开始之前研究。事实上，假设Dawn和Glenn都不知道真正的10,000
    Solar钞票长什么样。显然，这会让事情变得*更加*困难。稍后我们会对此做出解释。唯一给他们的东西是Glenn：一大堆空白矩形纸张，形状和大小与10,000
    Solar钞票相匹配。
- en: They each follow a daily routine. Every morning, Glenn sits down and makes a
    few forgeries using all the information he has so far. In the beginning, he doesn’t
    know anything, so he may just splash different colors of inks around on the paper.
    Or maybe he draws some faces or numbers. He basically just draws random stuff.
    At the same time, Dawn goes to the bank and withdraws a stack of real 10,000 Solar
    notes. Very lightly, she writes the word *Real* on the back of each one in pencil.
    Then, when Glenn is done, she collects Glenn’s forgeries for the day and writes
    the word *Fake* lightly on the back of each. She then shuffles the two piles together.
    [Figure 22-1](#figure22-1) shows the idea.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 他们各自遵循着日常的例行公事。每天早上，Glenn坐下来，利用他目前拥有的所有信息制作一些伪钞。一开始，他什么都不知道，所以他可能只是随便在纸上涂抹不同颜色的墨水。或者也许他画一些面孔或数字。他基本上就是随便画一些东西。与此同时，Dawn去银行取出一堆真钞，轻轻地在每一张背面用铅笔写下*Real*字样。然后，当Glenn做完时，她收集起当天的伪钞，并在每张背面轻轻写下*Fake*字样。接着，她将这两堆钞票混合在一起。[图22-1](#figure22-1)展示了这一过程。
- en: '![f22001](Images/f22001.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![f22001](Images/f22001.png)'
- en: 'Figure 22-1: Dawn gets real bills from the bank and forgeries from Glenn, shuffles
    them together (the pile in the middle), and sorts them into real and fake.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-1：Dawn从银行拿到真钞，拿到Glenn的伪钞后，把它们混合在一起（中间的堆），然后分成真钞和假钞。
- en: Now Dawn does her main job. One by one, she goes through the bills, and without
    looking at the backs, she categorizes each one as real or fake. Let’s say she
    asks herself, “Is this bill real?” We call an answer of “yes” a *positive* response
    to that bill and an answer of “no” a *negative* response to that bill.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'Dawn carefully sorts her starting stack into two piles: the reals and the fakes.
    Since each bill can be real or fake, there are four possibilities, summarized
    in [Figure 22-2](#figure22-2).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![f22002](Images/f22002.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22-2: When Dawn examines a bill, it might be real or fake, and she might
    declare it to be real or fake. This gives us four combinations.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: When Dawn looks at a bill, if it’s real and she says it’s real, then her “positive”
    decision is accurate, and we have a true positive (TP). If the bill is real but
    her decision is “negative” (she thinks it’s fake), then it’s a false negative
    (FN). If the bill is fake but she thinks it’s real, that’s a false positive (FP).
    Finally, if it’s fake and she correctly identifies it as fake, that’s a true negative
    (TN). In all cases but true positive, either Dawn or Glenn uses that example to
    improve their work.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Learning from Experience
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ve mentioned that Dawn and Glenn are just human stand-ins for the neural
    networks called the *discriminator* and *generator*, respectively.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: 'The discriminator is a classifier. It places each input into one of two classes:
    real or fake. When the prediction is wrong, that network’s error function has
    a large value. We then train the discriminator in the usual way with backprop
    and optimization, so that the class is more likely to be right the next time.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 'The generator’s job is quite different. It never sees the training data at
    all. Instead, we give it a random input (like a list of a few hundred numbers),
    and from that it produces an output. That’s all it does. If the discriminator
    thinks that output is real (that is, from the training set), then the generator
    got away with this forgery and doesn’t need to improve. But if the discriminator
    catches the output as fake (that is, synthetic, or from the generator), then the
    generator gets an error signal and we use backprop and optimization so that it
    moves away from results like this one that get caught by the discriminator. Each
    time we run the generator, we give it new, random, starting values. The generator
    has a daunting task: turn this small list of numbers into an output that fools
    the discriminator. For example, the intended output could be a song that sounds
    like it was written by Bach, a piece of speech that sounds like a person, a face
    that looks like a person, or a used piece of currency that’s worth 10,000 Solars.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: How can we possibly train such a system? The generator never sees the data it’s
    trying to emulate, so it can’t learn from it. It only knows when it’s wrong.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The approach that works surprisingly well is trial and error. We start out,
    as described earlier, with a generator and a discriminator that are both entirely
    untrained. When we give the discriminator some data, it basically just assigns
    each piece of data to a random class. At the same time, the generator is making
    random output. They’re both flailing and essentially producing meaningless outputs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 出人意料的有效方法是通过试错法。我们一开始，如前所述，使用一个完全未经训练的生成器和鉴别器。当我们给鉴别器一些数据时，它基本上只是将每一项数据分配给一个随机类别。与此同时，生成器也在随机生成输出。它们都在摸索，本质上输出的是毫无意义的结果。
- en: Slowly, though, the discriminator starts to learn, because we’re giving it the
    proper labels for the data it’s classifying. And as the discriminator gets a little
    better, the generator tries a bunch of different variations on its output until
    something gets past the discriminator (that is, the discriminator thinks it was
    real data, and not from the generator). The generator hangs onto that as its best
    work so far. Then the discriminator gets a little better, and in turn, the generator
    gets a little better. As time goes on, the tiny improvements in each network accumulate,
    until the discriminator is very sensitive to the differences between real and
    generated data, and the generator is very skilled at making those differences
    as small as possible.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，鉴别器会慢慢开始学习，因为我们为它提供了正确的标签来标注它分类的数据。随着鉴别器的表现逐渐提高，生成器尝试不同的输出变体，直到某个变体能通过鉴别器的检测（即，鉴别器认为它是来自真实数据，而非生成器的输出）。生成器将这个输出视为它迄今为止的最佳作品。然后，鉴别器进一步提高，生成器也随之进步。随着时间的推移，每个网络中的微小改进会累积，直到鉴别器对真实数据和生成数据之间的差异非常敏感，而生成器也非常擅长尽量缩小这些差异。
- en: Forging with Neural Networks
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 与神经网络的结合
- en: '[Figure 22-2](#figure22-2) showed the four possible situations that can arise
    after Dawn makes a decision for each bill. Let’s look more closely at how we train
    the discriminator and generator in such a way that they each force the other to
    improve. Note that this discussion is meant to cover the concepts, so we will
    proceed one sample at a time. In practice, we often implement these ideas in ways
    that are more complex, but more efficient (for example, by training in mini-batches
    rather than one sample at a time).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[图22-2](#figure22-2)展示了在Dawn为每张钞票做出决定后可能出现的四种情况。让我们更仔细地看看如何训练鉴别器和生成器，使它们互相推动对方改进。请注意，本讨论旨在讲解这些概念，因此我们将逐个样本地进行阐述。实际上，我们通常会以更复杂但更高效的方式实现这些想法（例如，通过批量训练，而不是逐个样本地训练）。'
- en: Let’s look more closely at the four possibilities in [Figure 22-2](#figure22-2)
    in flowchart form.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看[图22-2](#figure22-2)中四种可能情况的流程图形式。
- en: Starting with the true positive case, the discriminator correctly reports that
    the image of a real bill at its input is, indeed, a real bill. Since this is just
    what we want the discriminator to do in this case, there’s no learning to be done.
    [Figure 22-3](#figure22-3) shows this process graphically.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从真正的正例开始，鉴别器正确地报告输入的真实钞票图像确实是一张真实的钞票。由于这正是我们希望鉴别器在这种情况下执行的操作，因此无需进行学习。[图22-3](#figure22-3)通过图形方式展示了这个过程。
- en: '![f22003](Images/f22003.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![f22003](Images/f22003.png)'
- en: 'Figure 22-3: In the true positive (TP) case, the discriminator (D) receives
    a real bill and correctly predicts it to be real. Nothing needs to happen as a
    result.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-3：在真正的正例（TP）情况下，鉴别器（D）接收到一张真实的钞票并正确预测它为真实钞票。结果不需要进行任何操作。
- en: Next, we have the false negative, when the discriminator incorrectly declares
    a real bill to be a fake. As a result, the discriminator needs to learn more about
    real bills so it doesn’t repeat this error. [Figure 22-4](#figure22-4) shows the
    situation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是错误的负例，当鉴别器错误地将真实钞票判断为假钞时。此时，鉴别器需要更多地学习真实钞票的特征，以避免重复此错误。[图22-4](#figure22-4)展示了这种情况。
- en: '![f22004](Images/f22004.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![f22004](Images/f22004.png)'
- en: 'Figure 22-4: We get a false negative (FN) when the bill is real but the discriminator
    says it’s a fake. The discriminator needs to learn more about real bills so it
    doesn’t repeat this mistake.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-4：当钞票为真但鉴别器判断为假时，我们会得到一个错误的负例（FN）。鉴别器需要更多地学习真实钞票的特征，以避免重复此错误。
- en: The false positive case comes when the discriminator gets fooled by the generator
    and declares a forged bill to be real. In this case, the discriminator needs to
    study the bill more carefully and find any errors or inaccuracies so that it won’t
    get fooled again. [Figure 22-5](#figure22-5) shows how this goes.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 假阳性情况发生在判别器被生成器欺骗，错误地判断伪造的钞票为真实的情况下。在这种情况下，判别器需要更加仔细地检查钞票，找出任何错误或不准确的地方，以免再次被欺骗。[图
    22-5](#figure22-5)展示了这个过程。
- en: '![f22005](Images/f22005.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![f22005](Images/f22005.png)'
- en: 'Figure 22-5: In the false positive (FP) situation, the discriminator receives
    a fake bill from the generator but classifies it as real. To force the generator
    to get even better, the discriminator learns from its mistake so that this particular
    forgery won’t sneak through again.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22-5：在假阳性（FP）情况下，判别器接收到生成器的伪钞，但将其误判为真实钞票。为了迫使生成器变得更好，判别器从自己的错误中学习，以防止这张伪钞再次通过。
- en: Finally, the true negative case is when the discriminator correctly identifies
    a forgery. In this case, shown in [Figure 22-6](#figure22-6), the generator needs
    to learn how to improve its output.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，真实负例的情况是当判别器正确识别出伪钞时。在这种情况下，如[图 22-6](#figure22-6)所示，生成器需要学习如何改进其输出。
- en: Note that out of these four possibilities, one of them (TP) has no effect on
    either network, two of them (FN and FP) cause the discriminator to improve its
    ability to recognize real and fake bills, and only one (TN) causes the generator
    to learn and avoid repeating mistakes.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这四种可能性中，其中一种（TP）对任何网络都没有影响，另外两种（FN 和 FP）促使判别器提高识别真实和伪钞的能力，而只有一种（TN）促使生成器学习并避免重复错误。
- en: '![f22006](Images/f22006.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![f22006](Images/f22006.png)'
- en: 'Figure 22-6: In the true negative (TN) scenario, we give the discriminator
    a fake bill from the generator, and the discriminator correctly identifies it
    as fake. In this case, the generator learns that its output was not good enough,
    and it has to improve its forging skills.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22-6：在真实负例（TN）场景中，我们给判别器一张来自生成器的伪钞，判别器正确地将其识别为伪钞。在这种情况下，生成器意识到其输出不够好，必须提高其伪造技能。
- en: A Learning Round
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一次学习回合
- en: Let’s now assemble the feedback loops from the last section into a single step
    of training for both the discriminator and the generator. Generally, we repeat
    a set of four steps over and over. In each step, we give the discriminator either
    a real or fake bill, and then based on its response, follow one of the four flowcharts
    we just saw.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将上一节的反馈回路汇总成判别器和生成器的单一训练步骤。一般来说，我们会反复执行这四个步骤。在每个步骤中，我们给判别器提供一张真实的或伪造的钞票，然后根据其反应，遵循我们刚才看到的四个流程图之一。
- en: First we train the discriminator, then the generator, then the discriminator
    again, and then the generator again. The idea is to test for each of the three
    situations in which one or the other network needs to learn. The true negative
    case, where the generator learns, is repeated twice for reasons we’ll get to in
    a moment. [Figure 22-7](#figure22-7) summarizes the four steps.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 首先我们训练判别器，然后是生成器，再然后是判别器，最后是生成器。这个过程的目的是测试在每种情况下，哪个网络需要学习。真实负例的情况，即生成器学习的情形，会重复两次，原因稍后会解释。[图
    22-7](#figure22-7)总结了这四个步骤。
- en: '![f22007](Images/f22007.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![f22007](Images/f22007.png)'
- en: 'Figure 22-7: The four steps of a learning round'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22-7：学习回合的四个步骤
- en: First, in part (a), we try to learn from false negatives. We give the discriminator
    a random bill from the dataset of real bills. If it misclassifies it as a forgery,
    we tell the discriminator to learn from that mistake.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在部分 (a) 中，我们尝试从假阴性中学习。我们给判别器一张来自真实钞票数据集的随机钞票。如果它错误地将其归类为伪钞，我们会告诉判别器从这个错误中学习。
- en: Second, in part (b), we look for true negatives. We give some random numbers
    to the generator, produce a fake bill, and hand that to the discriminator. If
    the discriminator catches the forgery, we tell the generator, which attempts to
    learn to produce a better forgery.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，在部分 (b) 中，我们寻找真实负例。我们给生成器一些随机数字，生成一张伪钞，并交给判别器。如果判别器识别出伪造行为，我们会告诉生成器，生成器尝试学习如何制作更好的伪钞。
- en: Third, in part (c), we look for false positives. We give a new batch of random
    values to the generator and have it produce a new, fake bill, which we hand to
    the discriminator. If the discriminator is fooled and says the bill is real, the
    discriminator learns from its mistake.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，在部分 (c) 中，我们寻找假阳性。我们给生成器一组新的随机值，让它生成一张新的伪钞，然后交给判别器。如果判别器被欺骗并认为钞票是真的，那么判别器将从这个错误中学习。
- en: Finally, in part (d), we repeat the true negative test from the second step.
    We give new random numbers to the generator, make a new fake bill, and if the
    discriminator catches the forgery, the generator learns.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在第（d）部分，我们重复第二步中的真正负样本测试。我们为生成器提供新的随机数，生成一张新的伪钞，如果判别器识破了伪钞，生成器就会学习。
- en: The reason for repeating the generator’s learning step twice is that practice
    has shown that in many cases, the most efficient learning schedule is to update
    both networks at roughly the same rate. Since the discriminator learns from two
    types of errors, while the generator learns from only one, we double the number
    of learning opportunities for the generator, allowing both to learn at about the
    same pace.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 重复生成器学习步骤两次的原因是，实践表明，在许多情况下，最有效的学习计划是以大致相同的速率更新这两个网络。因为判别器从两种类型的错误中学习，而生成器只从一种错误中学习，所以我们将生成器的学习机会加倍，从而使两个网络能够大致以相同的速度进行学习。
- en: Through this process, the discriminator gets better and better at identifying
    real bills and spotting the errors in the counterfeits, and the generator, in
    turn, gets better and better at finding out how to create a counterfeit that cannot
    be spotted. This pair of networks, taken together, make up a single GAN. We can
    picture the two networks in a “learning battle” (Geitgey 2017). As the discriminator
    gets better and better at spotting fakes, the generator must get correspondingly
    better to get one through, causing the discriminator to get better at finding
    the forgery, causing the generator to get even better at making fakes, and so
    on.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个过程，判别器在识别真钞和发现伪钞错误方面变得越来越好，而生成器则相应地在如何制造无法被识破的伪钞方面变得越来越擅长。这对网络一起构成了一个完整的
    GAN。我们可以将这两个网络想象成一场“学习之战”（Geitgey 2017）。随着判别器在识别伪钞方面变得越来越精准，生成器必须相应地变得更好，才能通过判别器的检测，这反过来又促使判别器在发现伪造时变得更强，生成器则变得更擅长制造伪钞，依此类推。
- en: The ultimate goal is to have a discriminator that is as good as it can be, with
    deep and broad knowledge of every aspect of the real data, and yet also have a
    generator that can still get forgeries past the discriminator. That tells us that
    the counterfeits, despite being different from the real examples, are statistically
    indistinguishable from them, which was our goal all along.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最终目标是让判别器达到最佳状态，对真实数据的每个方面都有深入广泛的了解，同时生成器依然能成功地欺骗判别器。这告诉我们，尽管伪钞与真实样本不同，但它们在统计上与真实样本无法区分，这正是我们一直以来的目标。
- en: Why Adversarial?
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么是对抗性？
- en: The name *Generative Adversarial Network (GAN)* may seem strange in light of
    the preceding description. The two networks we just described seem to be cooperative,
    not adversarial. The choice of *adversarial* comes from looking at the situation
    in a slightly different way. Instead of the cooperation we described between Dawn
    and Glenn, we can imagine that Dawn is a detective with the police, and Glenn
    is working alone. To make the metaphor work, we have to also imagine that there’s
    some way for Glenn to discover which of his forged bills were detected (perhaps
    he has an accomplice in Dawn’s office who forwards this information to him).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*生成对抗网络（GAN）* 这个名称，在前述描述的背景下可能显得有些奇怪。我们刚刚描述的两个网络似乎是合作的，而非敌对的。选择*对抗性*一词，来自于以稍微不同的方式看待问题。我们可以将
    Dawn 想象成一名与警方合作的侦探，而 Glenn 则是独自行动。为了使这个比喻成立，我们还必须假设 Glenn 能通过某种方式得知哪些伪造的钞票被识破（也许他在
    Dawn 的办公室有一个同谋，能够将这些信息转发给他）。'
- en: If we picture the forger and the detective as opposed to one another, then indeed
    they are adversarial. This was how the subject of GANs was phrased in the original
    paper on the subject (Goodfellow et al. 2014). The adversarial view doesn’t change
    anything about how we set up or train the networks, but it offers a different
    way to think about them (Goodfellow 2016).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将伪造者和侦探视为对立的两方，那么它们确实是敌对的。这也是原始论文中对生成对抗网络（GANs）主题的表述方式（Goodfellow 等人，2014）。这种对抗性视角并不会改变我们如何设置或训练网络，但它提供了不同的思考方式（Goodfellow
    2016）。
- en: The word *adversarial* comes from a branch of mathematics called *game theory*
    (Watson 2013), in which we view the discriminator and generator as opponents in
    a game of deception and detection.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*对抗性*一词来源于一种叫做*博弈论*的数学分支（Watson 2013），在这种理论中，我们将判别器和生成器视为在一场欺骗与识别的博弈中的对手。'
- en: The field of game theoryis devoted to studying how competitors can maximize
    their advantages (Chen, Lu, and Vekhter 2016; Myers 2002). Our goal with GAN training
    is to develop each network to its peak ability, despite the other network’s abilities
    to thwart it. Game theorists call this state a *Nash equilibrium* (Goodfellow
    2016).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 博弈论的研究领域致力于研究竞争者如何最大化他们的优势（Chen, Lu, 和 Vekhter 2016； Myers 2002）。我们在GAN训练中的目标是使每个网络达到其最高能力，尽管其他网络能够抵挡它。博弈论学者称这一状态为*Nash均衡*（Goodfellow
    2016）。
- en: Now that we know the general technique for training, let’s see how to actually
    build a discriminator and a generator.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了训练的基本技巧，接下来我们看看如何实际构建一个鉴别器和一个生成器。
- en: Implementing GANs
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现GAN
- en: 'When we talk about GANs, we’re discussing three distinct networks: the discriminator,
    the generator, and the generator and the discriminator together. We saw two of
    these structures in [Figure 22-7](#figure22-7). In part (a) we had just the discriminator.
    In parts (b) through (d) we had the generator and discriminator combined. As we’ll
    see later, when training is done and we want to make new data, we discard the
    discriminator and use just the generator by itself.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论GAN时，我们讨论的是三个不同的网络：鉴别器、生成器以及生成器和鉴别器的组合。我们在[图22-7](#figure22-7)中看到了这两种结构。在（a）部分只有鉴别器，在（b）到（d）部分则是生成器和鉴别器结合的结构。正如我们稍后将看到的那样，当训练完成后，我们要生成新数据时，会丢弃鉴别器，仅使用生成器。
- en: It’s usually clear from context which of these networks is being discussed.
    As mentioned earlier, when someone speaks of a GAN, they usually mean only the
    trained generator, after it’s been taught by the adversarial process. The word
    GAN is used flexibly in the field. It can refer to the training method we just
    described, or the combined generator-discriminator network used during training,
    or the standalone generator that we end up with after training. Often people say
    that they will “train a GAN,” meaning that they will use the GAN method to train
    a generator that might then itself be called a GAN. It’s not as confusing as it
    sounds, as the right interpretation is usually clear from context.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 通常可以从上下文中明确知道正在讨论的是哪一个网络。如前所述，当提到GAN时，通常指的是训练后的生成器，在它经过对抗过程的训练之后。GAN这个词在该领域使用非常灵活。它既可以指我们刚才描述的训练方法，也可以指训练过程中使用的生成器-鉴别器组合网络，或者指训练后我们得到的独立生成器。通常人们会说他们将“训练一个GAN”，意思是他们将使用GAN方法来训练一个生成器，随后这个生成器本身可能会被称作GAN。听起来可能有些困惑，但通常从上下文中可以清晰地理解正确的解释。
- en: Enough background! Let’s build and train a GAN.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 够多的背景知识了！让我们开始构建和训练一个GAN。
- en: The Discriminator
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 鉴别器
- en: The discriminator is the simplest of the three models, as shown in [Figure 22-8](#figure22-8).
    It takes a sample as input, and its output is a single value that reports the
    network’s confidence that the input is from the training set rather than an attempted
    forgery.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴别器是三种模型中最简单的，如[图22-8](#figure22-8)所示。它以一个样本作为输入，输出一个单一值，表示网络对输入是来自训练集而非伪造尝试的置信度。
- en: '![f22008](Images/f22008.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![f22008](Images/f22008.png)'
- en: 'Figure 22-8: The block diagram of a discriminator'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-8：鉴别器的框图
- en: 'There aren’t any other restrictions on how we make the discriminator. It can
    be shallow or deep and use any kinds of layers: fully connected layers, convolutional
    layers, recurrent layers, transformers, and so on. In our currency forging example,
    the input is an image of a bill, and the output is a real number reflecting the
    network’s decision. A value of 1 means that the discriminator is sure that the
    input is a real bill, and a value of 0 means that the discriminator is sure that
    it’s a fake. A value of 0.5 means that the discriminator just can’t tell either
    way.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们如何制作鉴别器并没有其他限制。它可以是浅层的或深层的，并且可以使用任何类型的层：全连接层、卷积层、递归层、转换器等等。在我们伪钞制作的例子中，输入是钞票的图像，输出是一个实数，反映网络的判断。值为1意味着鉴别器确定输入是一个真实的钞票，值为0意味着鉴别器确定它是伪钞。值为0.5意味着鉴别器无法判断。
- en: The Generator
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成器
- en: The generator takes a bunch of random numbers as input. The output of the generator
    is a synthetic sample. The block diagram is in [Figure 22-9](#figure22-9).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器接受一堆随机数作为输入。生成器的输出是一个合成样本。其框图见[图22-9](#figure22-9)。
- en: '![f22009](Images/f22009.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![f22009](Images/f22009.png)'
- en: 'Figure 22-9: The block diagram for a generator'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-9：生成器的框图
- en: As with the discriminator, there aren’t any constraints on how we build the
    generator. It can be shallow or deep, and use any kinds of layers we like.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 与判别器一样，生成器的构建没有任何约束。它可以是浅层的或深层的，使用我们喜欢的任何类型的层。
- en: In our example of forging currency, the output would be an image.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们伪造货币的例子中，输出将是一个图像。
- en: The loss function for the generator of [Figure 22-9](#figure22-9) all by itself
    is irrelevant, and in some implementations, we never even define one. As we’ll
    see in the next section, we train the generator by hooking it up to the discriminator,
    so the generator learns from the loss function for the combined network.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[图22-9](#figure22-9)中生成器的损失函数本身是无关紧要的，在某些实现中，我们甚至从未定义过一个。正如我们在下一节中将看到的那样，我们通过将生成器与判别器连接起来训练生成器，因此生成器从组合网络的损失函数中学习。'
- en: Once our GAN is fully trained, we often discard the discriminator and keep the
    generator. After all, the discriminator’s purpose was to train the generator so
    that we could use it to make new data. When the generator has been disconnected
    from the discriminator, we can use the generator to make an unlimited amount of
    new data for us to use any way we like.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的GAN完全训练好，我们通常会丢弃判别器，只保留生成器。毕竟，判别器的目的是训练生成器，以便我们可以用它来生成新数据。当生成器与判别器断开连接时，我们可以使用生成器无限制地生成新数据，供我们随意使用。
- en: Now that we have the block diagrams of the generator and discriminator, we can
    look more closely at the actual training process. With that in place, we’ll look
    at implementations of both networks. Then we’ll train them and see how they do.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了生成器和判别器的框图，我们可以更仔细地查看实际的训练过程。在那之后，我们将查看两个网络的实现。然后我们将训练它们，看看它们的表现如何。
- en: Training the GAN
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练GAN
- en: Let’s now look at how to train our GAN. We’ll expand the four steps in the learning
    round shown in [Figure 22-7](#figure22-7) to show where the updates get applied.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下如何训练我们的GAN。我们将扩展[图22-7](#figure22-7)中学习轮次的四个步骤，展示更新应用的位置。
- en: Our first step is to look for false negatives, so we feed real bills to the
    discriminator, as in [Figure 22-10](#figure22-10). In this step, we don’t involve
    the generator at all. The error function here is designed to punish the discriminator
    if it reports a real bill as a fake. If that happens, the error drives a backpropagation
    step through the discriminator, updating its weights, so that it gets better at
    recognizing real bills.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是寻找假阴性，所以我们将真实的钞票输入到判别器中，如[图22-10](#figure22-10)所示。在这一步，我们完全不涉及生成器。此时，误差函数的设计是，如果判别器错误地将真实钞票分类为假币，它会受到惩罚。如果发生这种情况，误差将驱动通过判别器的反向传播步骤，更新其权重，使其更擅长识别真实钞票。
- en: '![f22010](Images/f22010.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![f22010](Images/f22010.png)'
- en: 'Figure 22-10: In the false negative step, the discriminator is hooked up to
    an error function that punishes it for categorizing a real bill as a fake.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-10：在假阴性步骤中，判别器连接到一个误差函数，如果它将真实钞票错误地分类为假币，就会受到惩罚。
- en: The second step looks for true negatives. In this step, we hook up the output
    of the generator directly to the input of the discriminator to create one big
    model. We start with random numbers going into the generator, as shown in [Figure
    22-11](#figure22-11). The generator’s output is a fake bill, which is then fed
    to the discriminator. The error function is designed to have a large value if
    this fake bill is correctly identified as fake, meaning that the generator got
    caught making a forgery.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是寻找真实的负样本。在这一步，我们将生成器的输出直接连接到判别器的输入，形成一个大模型。我们从输入随机数到生成器开始，如[图22-11](#figure22-11)所示。生成器的输出是伪钞，然后将其输入到判别器中。误差函数的设计是，如果这个伪钞被正确识别为假币，则它的值较大，意味着生成器被抓到制造伪钞。
- en: '![f22011](Images/f22011.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![f22011](Images/f22011.png)'
- en: 'Figure 22-11: In the true negative step, random numbers feed the generator,
    which produces a fake bill. If the discriminator labels it as fake, we push gradients
    through the discriminator, but only update the generator.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-11：在真实负样本步骤中，随机数输入到生成器，生成一个伪钞。如果判别器将其标记为假币，我们就通过判别器推送梯度，但只更新生成器。
- en: In [Figure 22-11](#figure22-11) we’ve grayed-out the update step for the discriminator,
    yet the arrow labeled Update is apparently going through the discriminator. What’s
    going on here is that our Update arrow combines backprop and optimization. Recall
    that backprop computes the gradient for each weight but doesn’t actually change
    anything. It’s the optimization step that updates the weights, based on their
    gradients. In [Figure 22-11](#figure22-11), we want to apply optimization to the
    generator, which means we need to find its gradients. But because backprop computes
    the gradients from the end of the network to the start, the only way to find the
    gradients in the generator is to first compute them for the discriminator. Although
    we find the gradients in both networks, we only change the weights in the generator.
    We say that the discriminator is *frozen*, meaning that its weights are not changed,
    even though we computed their gradients. This insures that at any given time,
    we’re training only the generator or only the discriminator.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图22-11](#figure22-11)中，我们将判别器的更新步骤灰显处理，然而标记为“更新”的箭头显然还是通过了判别器。这里发生的事情是，我们的“更新”箭头同时包含了反向传播和优化。回想一下，反向传播计算每个权重的梯度，但并不会实际改变任何东西。真正更新权重的是优化步骤，它基于梯度来更新权重。在[图22-11](#figure22-11)中，我们希望对生成器进行优化，这意味着我们需要找到它的梯度。但由于反向传播是从网络的末端计算到起始端的，找到生成器的梯度的唯一方法是首先计算判别器的梯度。尽管我们在两个网络中都计算了梯度，但我们只会改变生成器中的权重。我们说判别器是*冻结*的，意味着它的权重不会被改变，即使我们计算了它们的梯度。这确保了在任何给定时刻，我们只训练生成器或只训练判别器。
- en: Improving the generator’s weights lets it learn to better fool the discriminator.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 改进生成器的权重可以让它更好地欺骗判别器。
- en: Now we look for false positives. We generate a fake bill and punish the discriminator
    if it classifies it as real, as in [Figure 22-12](#figure22-12).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们寻找假阳性。我们生成一个假钞，并在判别器将其分类为真实时惩罚它，如[图22-12](#figure22-12)所示。
- en: '![f22012](Images/f22012.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![f22012](Images/f22012.png)'
- en: 'Figure 22-12: In the false positive step, we give the discriminator a fake
    bill. If it classifies it as real, then we update the discriminator to better
    spot the fakes.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-12：在假阳性步骤中，我们给判别器一个假钞。如果它将其分类为真实钞票，那么我们更新判别器，使其更好地识别假钞。
- en: Finally, we repeat the true negative step of [Figure 22-11](#figure22-11), so
    that both the discriminator and generator have two opportunities to get updated
    in each round of training.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们重复[图22-11](#figure22-11)中的真实负例步骤，这样每轮训练中，判别器和生成器都有两次更新的机会。
- en: GANs in Action
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GANs 实战
- en: Enough theory! Let’s build a GAN system and train it. We’ll pick something very
    simple so that we can draw meaningful illustrations of the process in 2D.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 够了，理论！让我们构建一个GAN系统并训练它。我们选择一个非常简单的例子，这样我们可以在2D中绘制出有意义的过程插图。
- en: Let’s picture all the samples in our training set as a cloud of points in some
    abstract space. After all, each sample is ultimately a list of numbers, and we
    can treat those as coordinates in a space that has as many dimensions as there
    are numbers. Our set of “real” samples will be points that belong to a 2D cloud
    that has a Gaussian distribution. Recall from Chapter 2 that a Gaussian curve
    has a big bump in the center, so we expect most of our points to be near the bump,
    with fewer and fewer points as we move outward. Each sample is a single point
    from that distribution. Let’s center the 2D blob at (5,5), and give it a standard
    deviation of 1\. [Figure 22-13](#figure22-13) shows this distribution.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把训练集中的所有样本想象成一个点云，位于某个抽象的空间中。毕竟，每个样本最终都是一个数字列表，我们可以将这些数字视为空间中的坐标，空间的维度与数字的数量相同。我们的“真实”样本集合将是属于一个二维云的点，该云具有高斯分布。回想一下第2章，高斯曲线在中心有一个大的峰值，因此我们期望大多数点位于峰值附近，随着向外扩展，点的数量会逐渐减少。每个样本都是该分布中的一个点。让我们将二维云的中心定在(5,5)，并赋予其标准差为1。[图22-13](#figure22-13)展示了这个分布。
- en: '![f22013](Images/f22013.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![f22013](Images/f22013.png)'
- en: 'Figure 22-13: Our starting distribution is a Gaussian bump centered at (5,5)
    with a standard deviation of 1\. Left: The blob in 3D. Right: A circle showing
    the location of one standard deviation of the blob in 2D, and some representative
    points randomly drawn from this distribution.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-13：我们的起始分布是一个以(5,5)为中心、标准差为1的高斯峰。左图：3D中的云。右图：一个圆圈显示二维中一个标准差位置的云，以及从这个分布中随机抽取的一些代表性点。
- en: Our generator will try to learn how to turn the random numbers that it’s given
    into points that seem to belong to this distribution. The goal is to do that so
    well that the discriminator can’t tell real points from synthetic ones created
    by the generator. In other words, we want the generator to take in random numbers
    and produce output points that *could* have been the result of drawing random
    points from our original Gaussian bump centered at (5,5).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的生成器将尝试学习如何将其给定的随机数转化为看似属于此分布的点。目标是做到如此之好，以至于判别器无法分辨真实点和生成器生成的合成点。换句话说，我们希望生成器接受随机数并生成可能来自我们原始高斯分布中心（5,5）附近的随机点的输出。
- en: Given only a single point, as in [Figure 22-14](#figure22-14), it’s a challenge
    for the discriminator to say with any certainty if it’s an original sample drawn
    from our Gaussian distribution or a synthetic sample created by the generator.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 仅给定一个点，如[图 22-14](#figure22-14)所示，判别器很难确定它是否是从我们的高斯分布中提取的真实样本，还是生成器创建的合成样本。
- en: '![f22014](Images/f22014.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![f22014](Images/f22014.png)'
- en: 'Figure 22-14: We have a single sample and we want to determine if it was drawn
    from the Gaussian distribution.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22-14：我们有一个单一的样本，我们想要判断它是否是从高斯分布中提取的。
- en: 'We can make things easier on the discriminator by using an old friend from
    Chapter 15: the mini-batch (or often just the batch). Rather than run one sample
    at a time through the system, we can run through a lot of them, often a power
    of two in the range 32 to 128\. Given a whole bunch of points, it’s easier to
    decide if they were plucked from our Gaussian cloud or not. [Figure 22-15](#figure22-15)
    shows a few sets of points that the generator might produce. We hope that the
    distributor will be able to easily realize that these points are unlikely to have
    been drawn from our original distribution.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用第 15 章中的一个老朋友：小批量（或通常称为批量）来简化判别器的任务。与其每次只运行一个样本，我们可以一次运行大量样本，通常是 32
    到 128 之间的 2 的幂。给定一大堆点，判定它们是否来自我们的高斯云就容易多了。[图 22-15](#figure22-15)展示了生成器可能生成的几组点。我们希望判别器能轻松意识到这些点不太可能来自我们原始的分布。
- en: '![f22015](Images/f22015.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![f22015](Images/f22015.png)'
- en: 'Figure 22-15: Some sets of points that are unlikely to have been the result
    of picking random values from our starting Gaussian'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22-15：一些不太可能是从我们的起始高斯分布中随机挑选的结果的点集
- en: We want our generator to produce points more like the those on the right of
    [Figure 22-13](#figure22-13) than any of those in [Figure 22-15](#figure22-15).
    And we want the discriminator to classify the sets of points in [Figure 22-15](#figure22-15)
    as fakes, since they’re so unlikely to have been part of the original Gaussian
    data.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望我们的生成器生成的点更像[图 22-13](#figure22-13)右侧的那些点，而不是[图 22-15](#figure22-15)中的任何点。我们还希望判别器能够将[图
    22-15](#figure22-15)中的点集分类为假样本，因为这些点不太可能来自原始的高斯数据。
- en: Building a Discriminator and Generator
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建判别器和生成器
- en: Let’s build discriminator and generator networks for this problem. Because our
    original distribution (the 2D Gaussian bump) is so simple, our networks can be
    simple also.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为这个问题构建判别器和生成器网络。由于我们的原始分布（二维高斯分布）非常简单，我们的网络也可以相应地简单。
- en: A word of warning before we dig into the mechanics, though. GANs are famous
    for being finicky and sensitive. They are notoriously hard to train (Achlioptas
    et al. 2018). Minor changes in the architecture of the generator or discriminator,
    or even small changes to some of the hyperparameters (such as learning rates or
    dropout rates) can turn a practically useless GAN into a star performer, and vice
    versa. Worse, we have to train not one network but two, *and* get them to work
    together, so the number of choices of hyperparameters to search through and fine-tune
    can become overwhelming (Bojanowski et al. 2019). So, while we develop a GAN,
    it’s essential to experiment using the specific data we want to learn from and
    try to home in on a good design and good hyperparameters as quickly as we can.
    This often means trying lots of little experiments with small excerpts from the
    training data, as we hunt for good networks and hyperparameters.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: In the following discussion, we skip the many dead-ends and badly performing
    models that we tried. Instead, we’ll jump right to models that we found work well
    for this dataset. It’s very possible that with further changes, or perhaps even
    just small tweaks in the right places, we could significantly improve the architectures
    we show (that is, enable them to learn faster and more accurately).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with a simple generator, shown in [Figure 22-16](#figure22-16).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '![f22016](Images/f22016.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22-16: A simple generator. It takes in four random numbers and computes
    an (x,y) pair.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: The model takes in four random values, uniformly selected from the range 0 to
    1\. We start with a fully connected layer with 16 neurons and a leaky ReLU activation
    (recall from Chapter 13 that a leaky ReLU is like a normal ReLU, but instead of
    returning 0 for negative values it scales them by a small number, here 0.1).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by another fully connected layer with just two neurons and
    no activation function. And that’s it for the generator. The two values that are
    produced are the x and y coordinates of a point.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: We’re asking quite a lot of these two layers with only 18 neurons and 54 weights.
    We want them to learn how to convert a set of four uniformly distributed random
    numbers into a 2D point that could have been drawn from a Gaussian cloud with
    a center at (5,5) and a standard deviation of 1, but we’ll never tell it anything
    about that goal. We only tell it when a mini-batch of its points isn’t a credible
    match to what we want, and leave it to the neurons to figure out where they went
    wrong and how to make it right.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Our discriminator is in [Figure 22-17](#figure22-17).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '![f22017](Images/f22017.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22-17: A simple discriminator. It takes in an (x,y) point and tells
    us if it’s real or fake.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: This starts with two layers of the same form as the start of the generator.
    Each is a fully connected layer of 16 neurons with a leaky ReLU activation. At
    the end is a fully connected layer with just 1 neuron and a sigmoid activation
    function. The output is a single number with the network’s confidence that the
    input is from the same dataset as the training data.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这从两个与生成器开始部分相同的层开始。每一层都是一个包含16个神经元的全连接层，并使用泄漏ReLU激活函数。最后是一个包含1个神经元并带有sigmoid激活函数的全连接层。输出是一个单一的数字，表示网络对输入是否来自与训练数据相同数据集的信心。
- en: Finally, we put the generator and discriminator together to make the combined
    model, which is sometimes referred to as the *generator-discriminator*. [Figure
    22-18](#figure22-18) shows this combination.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将生成器和判别器组合在一起，形成组合模型，有时被称为*生成器-判别器*。[图 22-18](#figure22-18)展示了这种组合。
- en: '![f22018](Images/f22018.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![f22018](Images/f22018.png)'
- en: 'Figure 22-18: Putting the generator and discriminator together.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22-18：将生成器和判别器组合在一起。
- en: Since the generator presents an (*x*,*y*) pair at its output, and the discriminator
    takes an (*x*,*y*) pair at its input, the two networks go together perfectly.
    The generator’s input is a set of four random numbers, and the discriminator’s
    output tells us how likely it is that the point created by the generator is from
    the training set’s distribution.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 由于生成器在其输出中呈现一个(*x*,*y*)对，判别器在其输入中接收一个(*x*,*y*)对，因此这两个网络完全匹配。生成器的输入是一组四个随机数，而判别器的输出告诉我们生成器创建的点是否来自训练集的分布。
- en: It’s important to keep in mind that the models marked “generator” and “discriminator”
    in [Figure 22-18](#figure22-18) are not copies of the models in [Figure 22-16](#figure22-16)
    and [Figure 22-17](#figure22-17), but they are in fact the *very same models*,
    just connected together one after the other to make one big model. In other words,
    there’s just one generator model and one discriminator model. When we make the
    combined model of [Figure 22-18](#figure22-18), we just chain together those two
    existing models. Modern deep-learning libraries let us make multiple models out
    of shared components for just this kind of application. Using the same models
    in these different configurations makes sense, since the combined model needs
    to use the most up-to-date versions of the generator and discriminator.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，[图 22-18](#figure22-18)中标记为“生成器”和“判别器”的模型并不是[图 22-16](#figure22-16)和[图
    22-17](#figure22-17)中的模型的副本，而实际上它们是*完全相同的模型*，只是一个接一个地连接在一起，组成了一个大模型。换句话说，只有一个生成器模型和一个判别器模型。当我们构建[图
    22-18](#figure22-18)中的组合模型时，我们只是将这两个现有模型链接在一起。现代深度学习库允许我们通过共享组件构建多个模型，正是为了这种应用。使用这些不同配置中的相同模型是有意义的，因为组合模型需要使用生成器和判别器的最新版本。
- en: Training Our Network
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练我们的网络
- en: When we train the generator using the combined model of [Figure 22-18](#figure22-18),
    *we don’t want to train the discriminator as well*. We saw this in [Figure 22-11](#figure22-11)
    where we grayed out the discriminator during the update step. We need to run backprop
    through the discriminator, since it’s part of the network, and helps create the
    gradients for the generator, but we only apply the update step to the weights
    in the generator.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用[图 22-18](#figure22-18)中的组合模型训练生成器时，*我们不希望同时训练判别器*。我们在[图 22-11](#figure22-11)中看到过这种情况，当时我们在更新步骤中将判别器灰显。我们需要通过判别器进行反向传播，因为它是网络的一部分，并帮助为生成器创建梯度，但我们只会对生成器中的权重应用更新步骤。
- en: Remember that we want to train the discriminator and generator in alternating
    passes. If we were to apply backprop to the entire network of [Figure 22-18](#figure22-18),
    then we’d update the weights in the discriminator as well as the generator. Because
    we want to train both models at about the same rate, and we know we’re going to
    train the discriminator separately (since it also needs to be trained on real
    data), we want to tell our library to update the weights in the generator *only*.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们希望交替训练判别器和生成器。如果我们对[图 22-18](#figure22-18)中的整个网络应用反向传播，那么我们会同时更新判别器和生成器中的权重。因为我们希望以大致相同的速率训练这两个模型，并且我们知道我们将单独训练判别器（因为它也需要在真实数据上进行训练），所以我们希望告诉我们的库只更新生成器中的权重*而不是*判别器。
- en: The mechanics for controlling whether or not a layer should have its weights
    updated are library specific, but generally speaking, they use terms like *freeze*,
    *lock*, or *disable* to prevent updates on a given layer. Then we can *unfreeze*,
    *unlock*, or *enable* updates later when we train the discriminator, and we want
    those layers to be able to learn.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 控制是否更新某一层权重的机制是与库相关的，但通常来说，它们使用像*冻结*、*锁定*或*禁用*这样的术语来防止在特定层上进行更新。然后，当我们训练判别器时，如果我们希望这些层能够学习，就可以*解冻*、*解锁*或*启用*更新。
- en: To summarize the training process, we start with a mini-batch of points from
    the training set. We then follow the four-stage process in [Figure 22-7](#figure22-7),
    training the discriminator and generator alternately.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 总结训练过程时，我们从训练集中的一个小批量点开始。然后，我们按照[图22-7](#figure22-7)中的四阶段过程，交替训练判别器和生成器。
- en: Testing Our Network
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试我们的网络
- en: Let’s look at some results. To train our GAN, we made a training set by drawing
    10,000 random points from our starting Gaussian distribution. Then we trained
    the networks using mini-batches of 32 points. Running all 10,000 points through
    the system makes up one epoch.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一些结果。为了训练我们的GAN，我们通过从起始的高斯分布中随机抽取10,000个点来创建训练集。然后，我们使用32个点的小批量训练网络。将所有10,000个点通过系统处理一次就是一轮训练。
- en: Results for epochs 1 through 13 are shown in [Figure 22-19](#figure22-19).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 第1到第13轮的结果见于[图22-19](#figure22-19)。
- en: '![f22019](Images/f22019.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![f22019](Images/f22019.png)'
- en: 'Figure 22-19: Our simple GAN in action. The blue points are the original dataset.
    The orange points were produced by the generator. Read the plots left to right,
    top to bottom. Epoch 0 refers to results after the first epoch of training.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-19：我们简单的GAN在运行中。蓝色点是原始数据集，橙色点是生成器产生的。图表的阅读顺序是从左到右，从上到下。第0轮指的是训练的第一轮结果。
- en: Our starting Gaussian is shown with blue points, and a blue circle showing its
    mean and standard variation. The distribution that is being learned by the GAN
    is shown in orange, with an ellipse showing the center and standard deviation
    of the mini-batch of points that were generated. The plots show the results after
    0 to 10 epochs of training, and then epoch 13\. To keep the plots legible, we
    only show a randomly selected subset of the original and generated data in each
    plot.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的初始高斯分布通过蓝色点表示，并且有一个蓝色圆圈显示其均值和标准差。GAN学习到的分布用橙色表示，并且有一个椭圆显示生成的小批量点的中心和标准差。图表展示了从0到10轮训练后的结果，以及第13轮的结果。为了保持图表的清晰，我们在每个图表中只显示原始数据和生成数据的随机子集。
- en: We can see that after one epoch, the GAN’s generated points form a smudgy line
    in the southwest-northeast direction, roughly centered around (1,1). With each
    epoch of training, they move closer to the original data’s center and shape. Around
    epoch 4 the generated samples overshoot the center, and become increasingly elliptical
    rather than circular. But they come back and correct both qualities, until the
    match is looking very good by epoch 13.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在一轮训练后，GAN生成的点在西南-东北方向形成了一条模糊的线，大致集中在(1,1)附近。随着每一轮训练，它们越来越接近原始数据的中心和形状。在第4轮左右，生成的样本超出了中心，并且变得越来越椭圆，而不是圆形。但它们最终回到并纠正了这两种特性，到第13轮时，匹配效果非常好。
- en: '[Figure 22-20](#figure22-20) shows the loss curves for the discriminator and
    generator.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[图22-20](#figure22-20)展示了判别器和生成器的损失曲线。'
- en: '![F22020](Images/F22020.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![F22020](Images/F22020.png)'
- en: 'Figure 22-20: The loss for our GAN. They seem to meet and remain at a value
    a little above the ideal of 0.5.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-20：我们的GAN损失值。它们似乎趋于并保持在一个略高于理想值0.5的位置。
- en: Ideally the discriminator would plateau at about 0.5, meaning that it was never
    sure whether an input was from the real dataset or produced by the generator.
    In this tiny example, it got pretty close.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，判别器的损失值应该在大约0.5处平稳，这意味着它永远不能确定输入是来自真实数据集还是由生成器生成的。在这个小示例中，它非常接近0.5。
- en: DCGANs
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DCGANs
- en: We said that we could build our discriminator and generator using any kind of
    architecture we like. Up to this point, our simple models have been made of dense
    layers that performed nicely for our little 2D dataset. But if we want to work
    with images, then we’d probably prefer to use convolutional layers since, as we
    saw in Chapter 16, they’re well suited to processing images. A GAN that’s built
    from multiple convolution layers has its own acronym, *DCGAN*, standing for *Deep
    Convolutional Generative Adversarial Network*.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过，我们可以使用任何架构来构建判别器和生成器。到目前为止，我们的简单模型由密集层组成，能够很好地处理我们的二维小型数据集。但如果我们想处理图像，那么我们可能更倾向于使用卷积层，因为正如我们在第
    16 章所看到的，卷积层非常适合处理图像。由多个卷积层构建的 GAN 被称为*DCGAN*，代表*深度卷积生成对抗网络*。
- en: Let’s train a DCGAN on the MNIST data we’ve seen in previous chapters. We’ll
    use a model proposed by Gildenblat (2020). The generator and discriminator are
    shown in [Figure 22-21](#figure22-21).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在之前章节中使用过的 MNIST 数据上训练一个 DCGAN。我们将使用 Gildenblat（2020）提出的模型。生成器和判别器见[图 22-21](#figure22-21)。
- en: '![f22021](Images/f22021.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![f22021](Images/f22021.png)'
- en: 'Figure 22-21: Top: The discriminator of a DCGAN for MNIST. Bottom: The generator.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22-21：上：用于 MNIST 的 DCGAN 判别器。下：生成器。
- en: In this network, we’re using explicit downsampling (or pooling) layers in the
    discriminator and upsampling (or expanding) layers in the generator rather than
    making them part of the convolution steps because that’s how the network was originally
    proposed. The circle with a dot inside it in the generator is a batchnorm layer,
    which helps to prevent overfitting. The little 3D box after the tanh activation
    function is a *reshaping* layer that converts the 1D tensor coming out of the
    second fully connected layer into a 3D tensor, appropriate for the following upsampling
    and convolution layers. We trained with a standard binary cross entropy loss function
    and a Nesterov SGD optimizer set to a learning rate of 0.0005 and a momentum of
    0.9.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个网络中，我们在判别器中使用了显式的下采样（或池化）层，在生成器中使用了上采样（或扩展）层，而不是将它们作为卷积步骤的一部分，因为这就是网络最初提出的方式。生成器中带有圆点的圆形是一个批标准化层，它有助于防止过拟合。tanh
    激活函数后的那个小 3D 方框是一个*重塑*层，它将从第二个全连接层输出的 1D 张量转换为 3D 张量，以便进行后续的上采样和卷积层处理。我们使用标准的二元交叉熵损失函数和设置了学习率为
    0.0005、动量为 0.9 的 Nesterov SGD 优化器进行训练。
- en: The second dense layer in the generator uses 6,272 neurons. This number might
    seem mysterious, but it gives the generator and discriminator equal amounts of
    data to work with. The output of the second downsampling layer in the discriminator
    has a shape of 7 × 7 × 128, or 6,272 elements. By giving the second fully connected
    layer in the generator 6,272 values, we can provide a tensor of the same shape
    to its first upsampling layer. In other words, the end of the convolution stage
    of the discriminator is a tensor of shape 7 × 7 × 128, so we provide a tensor
    of shape 7 × 7 × 128 to the start of the convolution stages of the generator.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器中的第二个密集层使用了 6,272 个神经元。这个数字看起来可能有些神秘，但它使得生成器和判别器能够处理相等数量的数据。判别器中第二个下采样层的输出形状是
    7 × 7 × 128，即 6,272 个元素。通过给生成器中的第二个全连接层提供 6,272 个值，我们可以为其第一个上采样层提供一个相同形状的张量。换句话说，判别器的卷积阶段结束时是一个形状为
    7 × 7 × 128 的张量，因此我们为生成器的卷积阶段开始提供一个形状为 7 × 7 × 128 的张量。
- en: The discriminator and the generator both follow roughly the same steps, but
    in opposite order.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器和生成器遵循大致相同的步骤，但顺序相反。
- en: The results of the generator after one epoch of training are pretty unintelligible,
    as we might expect. [Figure 22-22](#figure22-22) shows what they look like.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一个训练周期后，生成器的结果相当难以理解，这也是我们预期的结果。[图 22-22](#figure22-22)展示了它们的样子。
- en: '![F22022](Images/F22022.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![F22022](Images/F22022.png)'
- en: 'Figure 22-22: The blotches from the generator after one epoch of training'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22-22：训练一个周期后生成器的斑点图
- en: After 100 epochs of training, the generator produced the results of [Figure
    22-23](#figure22-23). We could have trained longer since the discriminator was
    still sometimes identifying the generator’s output, but this seemed a good place
    to stop because it shows the generator’s progress.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 经过 100 个训练周期后，生成器产生了[图 22-23](#figure22-23)中的结果。我们本可以训练更久，因为判别器仍然有时能够识别出生成器的输出，但这里是一个很好的停止点，因为它展示了生成器的进展。
- en: When we step back to consider the process, this is a startling result. Remember
    that the generator has never seen the dataset. It has no idea what the MNIST data
    looks like. All it’s ever done is create 3D tensors of real numbers, and then
    receive feedback that told it how good or bad the values in those tensors were.
    Over time, it produced tensors that look like digits. Somehow, the generator managed
    to find a way to turn random numbers into recognizable digits. Amazing. There
    are some misfires, but most of the digits are easily recognizable.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们退后一步考虑这个过程时，这是一个令人吃惊的结果。请记住，生成器从未见过数据集。它完全不知道 MNIST 数据是什么样子。它所做的仅仅是生成 3D
    张量的实数，然后收到反馈，告诉它这些张量中的值有多好或多差。随着时间的推移，它生成了看起来像数字的张量。不知怎么的，生成器设法找到了将随机数转化为可识别数字的方法。真是太神奇了。虽然有些错误，但大多数数字都是容易辨认的。
- en: This wraps up our basic discussion of GANs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这就总结了我们对 GAN 的基础讨论。
- en: '![f22023](Images/f22023.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![f22023](Images/f22023.png)'
- en: 'Figure 22-23: The output of the deep convolutional GAN of [Figure 22-21](#figure22-21)
    after 100 epochs of training on the MNIST dataset'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22-23：经过 100 次迭代训练后，深度卷积 GAN 在 [图 22-21](#figure22-21) 上的输出结果，使用的是 MNIST 数据集
- en: Before we move on, it’s worth reviewing a bit of practical advice. We mentioned
    earlier that GANs are very sensitive to their specific architecture and training
    variables. A famous paper investigated DCGANs, and found a few rules of thumb
    that seem to lead to good results (Radford, Metz, and Chintala 2016). As always,
    experimentation is the key to success. Small changes often make the difference
    between a GAN that learns efficiently and one that learns slowly, or not at all.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，值得回顾一些实践建议。我们之前提到过，GAN 对其特定架构和训练变量非常敏感。一篇著名的论文研究了 DCGAN，发现了一些经验法则，似乎能带来不错的结果（Radford、Metz
    和 Chintala 2016）。像往常一样，实验是成功的关键。小的改变往往决定了一个 GAN 是学习高效，还是学习缓慢，甚至根本不学习。
- en: Challenges
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 挑战
- en: Perhaps the biggest challenge to using GANs in practice is their sensitivity
    to both structure and hyperparameters. Playing a game of cat and mouse requires
    both parties to be closely matched at all times. If either the discriminator or
    generator gets better than the other too quickly, the other will never be able
    to catch up. As we mentioned earlier, getting the right combination of all of
    these values is essential to getting good performance out of a GAN, but finding
    that combination can be challenging (Arjovsky and Bottou 2017; Achlioptas et al.
    2017). Following the rules of thumb given earlier is generally recommended for
    giving us a good starting point when training a new DCGAN.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 也许在实践中使用 GAN 的最大挑战是它们对结构和超参数的敏感性。进行一场猫捉老鼠的游戏要求双方始终保持密切匹配。如果判别器或生成器的性能比另一个提高得太快，另一个就永远追赶不上。如前所述，找到这些值的正确组合对于从
    GAN 中获得良好的表现至关重要，但找到这种组合可能具有挑战性（Arjovsky 和 Bottou 2017；Achlioptas 等 2017）。通常建议遵循前面给出的一些经验法则，作为训练新
    DCGAN 时的良好起点。
- en: A theoretical issue with GANs is that we currently have no proof that they will
    *converge*. Recall our lone perceptron of Chapter 13, which finds the dividing
    line between two linearly separable sets of data. We can *prove* that the perceptron
    will, given enough training time, always find that dividing line. But for GANs,
    such proofs are nowhere to be found. All we can say is that many people have found
    ways to make at least some of their GANs train properly, but there’s no guarantee
    beyond that.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 的一个理论问题是，我们目前没有证明它们会 *收敛*。回想一下我们在第 13 章提到的单层感知机，它找出了两个线性可分数据集之间的分割线。我们可以
    *证明*，只要有足够的训练时间，感知机总会找到这个分割线。但对于 GAN，这样的证明是不存在的。我们能说的只是，许多人已经找到了至少能让部分 GAN 正常训练的方法，但除此之外并没有保证。
- en: Using Big Samples
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用大样本
- en: The basic structure of a GAN can run into trouble when we try to train a generator
    to produce large images, such as 1,000 by 1,000 pixels. The computational problem
    is that with all that data, it’s easy for the discriminator to tell the generated
    fakes from the real images. Trying to fix all these pixels simultaneously can
    lead to error gradients that cause the generator’s output to move in almost random
    directions, rather than getting closer to matching the inputs (Karras et al. 2018).
    On top of that, there’s the practical problem of finding enough compute power,
    memory, and time to process large numbers of these big samples. Recall that every
    pixel is a feature, so every image that’s 1,000 pixels on a side has one million
    features (or three million if it’s a color photo).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们尝试训练生成器生成大图像（如 1000×1000 像素）时，GAN 的基本结构可能会遇到问题。计算问题在于，面对如此大量的数据，判别器很容易将生成的假图像与真实图像区分开。试图同时修复所有这些像素可能导致误差梯度，使得生成器的输出几乎随机地变化，而不是朝着与输入匹配的方向前进（Karras
    等，2018）。除此之外，还有一个实际问题，那就是找到足够的计算能力、内存和时间来处理大量的大样本。回想一下，每个像素都是一个特征，因此每张边长为 1000
    像素的图像有一百万个特征（如果是彩色照片则有三百万个）。
- en: Because we want our final, high-resolution images to stand up to scrutiny, we’re
    going to want to use a large training set. The time required to crunch through
    big collections of giant images is going to add up fast. Even fast hardware might
    not be able to do the job in the time we have available.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们希望最终的高分辨率图像能够经得起审查，所以我们需要使用一个大型的训练集。处理这些巨型图像的大量数据所需的时间会很快累积。即使是快速的硬件，也可能无法在我们有限的时间内完成任务。
- en: A practical approach to building big images is called the *Progressive GAN*
    or *ProGAN* (Karras et al. 2018). To start with this technique, resize the images
    in the training set into a variety of smaller sizes, for example 512 pixels on
    a side, then 128, then 64, and so on, down to 4 pixels on a side. Then build a
    small generator and discriminator, each with just a few layers of convolution.
    Train these small networks with the 4 by 4 images. When they are doing a great
    job, add a few more convolution layers to the end of each network, and gradually
    blend in their contribution until the networks are doing well with 8 by 8 images.
    Then add some more convolution layers to the end of each network and train them
    on 16 by 16 images, and so on.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 构建大图像的实用方法被称为*渐进式 GAN*（*ProGAN*）（Karras 等，2018）。要开始使用这种技术，首先将训练集中的图像调整为各种较小的尺寸，例如一边
    512 像素，然后是 128 像素，接着是 64 像素，依此类推，直到 4 像素一边。然后构建一个小型的生成器和判别器，每个网络只有几层卷积。使用 4×4
    像素的图像训练这些小型网络。当它们表现得很好时，向每个网络的末端添加几层卷积，并逐渐融入它们的贡献，直到网络能够很好地处理 8×8 像素的图像。然后再向每个网络的末端添加更多的卷积层，并用
    16×16 像素的图像训练它们，依此类推。
- en: In this way, the generator and discriminator are able to build on their training
    as they grow. This means that by the time we work our way up to full size images
    that are 1,024 pixels on a side, we already have a GAN that can do a great job
    at generating and discriminating images that are 512 pixels on a side. We won’t
    have to do too much additional training with the larger images until the system
    performs well with them, too. This process takes much less time to complete than
    if we’d trained with only the full-sized images from the start.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，生成器和判别器能够在它们的训练过程中不断进步。这意味着，当我们逐渐训练到 1024 像素一边的全尺寸图像时，我们已经有一个能够很好地生成和判别 512
    像素一边图像的 GAN。我们不需要在大图像上进行太多额外的训练，直到系统也能很好地处理它们。与从一开始就只使用全尺寸图像进行训练相比，这个过程所需的时间要少得多。
- en: Modal Collapse
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模式崩溃
- en: GANs have an interesting way to exploit a loophole in our training. Recall that
    we want the generator to learn to fool the discriminator. It can succeed at this
    task in a way that is almost useless to us.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 有一种有趣的方式，可以利用我们训练中的漏洞。记住，我们希望生成器能够学会欺骗判别器。它可能会以几乎对我们没有用的方式成功地完成这一任务。
- en: Let’s suppose that we’re trying to train our GAN to produce pictures of cats.
    Suppose that the generator manages to create one cat image that the discriminator
    accepts as real. A sneaky generator could then just produce that image every time.
    No matter what values we use for the noise inputs, we always get back that one
    image. The discriminator tells us that every image it gets is plausibly real,
    so the generator has accomplished its goal and stops learning.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们试图训练我们的GAN生成猫的图片。假设生成器设法创建一张被鉴别器接受为真实的猫图像。然后一个狡猾的生成器可以每次只是产生那张图像。无论我们使用什么样的噪声输入值，我们总是得到那张图片。鉴别器告诉我们，它收到的每张图片都可能是真实的，所以生成器已经完成了它的目标并停止学习。
- en: This is another example of neural networks finding sneaky solutions to doing
    what we ask for, but not necessarily what we want. The generator has accomplished
    exactly what we requested, since it is turning random numbers into brand-new samples
    that the discriminator cannot tell apart from real samples. The problem is that
    every sample made by the generator is identical. A very sneaky kind of success.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这是神经网络找到的另一个为我们提供我们要求的但不一定是我们想要的狡猾解决方案的例子。生成器确实完成了我们要求的事情，因为它将随机数转化为鉴别器无法区分的全新样本。问题在于生成器生成的每个样本都是相同的。这是一种非常狡猾的成功。
- en: This problem of producing just one successful output over and over is called
    *modal collapse* (note that the first word is *modal*, pronounced “mode′-ull,”
    referring to a mode, or a way of working, and not “model”). If the generator settles
    into just a single sample (in this case, a single picture of a cat), the situation
    is described as *full modal collapse*. Much more common is when the system produces
    the same few outputs, or minor variations of them. This situation is called *partial
    modal collapse*.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这种反复产生一个成功输出的问题称为*模态崩溃*（请注意，第一个词是*模态*，发音为“mode′-ull”，指的是一种模式或工作方式，并非“模型”）。如果生成器陷入只有一个样本（在这种情况下是一张猫的图片）的模式，这种情况被描述为*完全模态崩溃*。更常见的情况是系统产生相同的少数几个输出或它们的轻微变化。这种情况称为*部分模态崩溃*。
- en: '[Figure 22-24](#figure22-24) shows one run of our DCGAN after three epochs
    of training using some poorly chosen hyperparameters. It’s pretty clear that the
    system is collapsing toward a mode where it’s going to output some kind of 1 a
    lot more than anything else.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[图22-24](#figure22-24) 显示了我们的DCGAN经过三个训练周期使用一些选择不当的超参数后的运行情况。很明显，系统正在向一个模式崩溃的方向崩溃，输出一些类型1的情况比其他任何情况都多。'
- en: There are schemes for addressing this problem. Perhaps the best recommendation
    begins with using mini-batches of data, as we did earlier. Then we can extend
    the discriminator’s loss function with some additional terms to measure the diversity
    of the outputs produced in that mini-batch. If the outputs fall into a few groups
    where they’re all the same, or nearly the same, the discriminator can assign a
    larger error to the result. The generator then diversifies because that action
    reduces the error (Arjovsky, Chintala, and Bottou 2017).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些方案可以解决这个问题。也许最好的建议是从使用数据的小批次开始，就像我们之前做的那样。然后我们可以扩展鉴别器的损失函数，加入一些额外的项来衡量在该小批次中产生的输出的多样性。如果输出落入几个组，其中它们全部相同或几乎相同，鉴别器可以对结果分配较大的错误。生成器因此多样化，因为这个动作减少了错误（Arjovsky,
    Chintala和Bottou 2017年）。
- en: Training with Generated Data
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用生成数据进行训练
- en: The most common use of GANs is to train a generator that fools the discriminator.
    Then we discard the discriminator, leaving us with a generator capable of creating
    as much new data as we like, all of it seeming to come from the original dataset.
    Thus, we can make an unlimited number of new images of cats or sailboats, or spoken
    phrases, or puffs of smoke from a wood fire.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: GANs最常见的用途是训练一个欺骗鉴别器的生成器。然后我们丢弃鉴别器，留下一个能够创建尽可能多新数据的生成器，所有这些数据看起来都来自原始数据集。因此，我们可以创建无限数量的新猫图像、帆船图像、口头短语或木火的烟雾喷发。
- en: '![f22024](Images/f22024.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![f22024](Images/f22024.png)'
- en: 'Figure 22-24: After only three epochs of training, this DCGAN is showing clear
    signs of modal collapse.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图22-24：在仅经过三次训练周期后，这个DCGAN显示出明显的模态崩溃迹象。
- en: It may be tempting to use that generated, or synthetic, data to train another
    neural network. After all, huge datasets are just what we need to train neural
    networks. But this is a very risky practice, because our trained generators are
    rarely perfect. One problem is that it’s very hard to make a discriminator that
    is robust enough to notice every possible detail in the generator’s output. The
    output from the generator might always be slightly skewed in some way that the
    discriminator was unable to notice, or to which it assigned a very low penalty.
    Another problem is that the generator’s output can be incomplete. As we saw in
    our example of modal collapse, the generator’s results might not span the whole
    range of the inputs. For example, tasked with generating new paintings in a given
    artist’s style, a generator might always produce landscapes, or portraits, or
    still lifes, even when the artist’s body of work has a much wider range of subjects.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: It’s very difficult to completely catch every issue that can come up. As hard
    as we might try to build a perfect generator, it always seems to be able to find
    another sneaky way to satisfy our desired criteria (as expressed by the discriminator)
    while still producing data that isn’t quite as diverse or realistic as we were
    hoping for. Another problem is that our criteria themselves often aren’t as clear
    or as broad as we think they are.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, the generator’s output can contain errors and biases that get past
    the discriminator. If we train a new system with that data, it inherits those
    errors and biases, which we may be completely unaware of. The differences may
    be subtle, but they can still influence the results in practice. This can create
    a dangerous situation in which we believe we have trained a robust neural network
    capable of making important decisions, without realizing that it has blind spots
    and biases. When we use trained networks for critical safety or medical applications,
    or we use them in social situations like hiring interviews, school admissions,
    or granting bank loans, we may get back seriously flawed or unfair decisions due
    to perpetuated errors we’re not aware of. The biases, errors, prejudices, misjudgments,
    and other common problems with databases become the baked-in basis on which the
    generator creates new data. The result is a self-perpetuating, self-fulfilling,
    but erroneous system. We can summarize this with a simple credo: *bias in, bias
    out*.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: In short, training neural networks on excellent data can still produce flawed
    results. Training networks on flawed data can produce much more deeply flawed
    results. As a general rule, it’s usually a good idea to resist the temptation
    to train a network on synthetic, or generated data.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we saw how to build a generative adversarial network, or GAN,
    out of two smaller pieces. The generator learns how to create new data that is
    plausibly like data from a given data set, and the discriminator learns how to
    distinguish the generator’s output from real data in the given set. They both
    learn from the other as they train, improving their respective skills. When a
    successful training is complete, the discriminator is unable to reliably distinguish
    between the synthetic data and the real data. At that point, we usually throw
    away the discriminator and use the generator for any application where we want
    arbitrary amounts of new data.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: We saw that training takes place in alternating steps so that the generator
    and discriminator learn at roughly the same pace. We then looked at building a
    simple GAN with fully connected layers to learn how to make data points in 2D
    and then a convolutional GAN that learned to generate new image data from MNIST.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Because GANs are notoriously hard to train, we discussed some rules of thumb
    for convolutional GANs that usually give us a good start. We saw that we can generate
    large outputs by working our way up in size during training, and we saw that we
    can use mini-batches to avoid modal collapse, where the generator always produces
    the same output (or a small number of outputs).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: We closed with a brief consideration of the perils of training with synthetic
    data.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
