- en: '## **7'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
- en: COMPUTER HARDWARE**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: 'The preceding chapters covered the foundational elements of computing—binary,
    digital circuits, memory. Let’s now examine how these elements come together in
    a computer, a device that’s more than the sum of its parts. In this chapter, I
    first provide an overview of computer hardware. Then we dive deeper into three
    parts of a computer: main memory, the processor, and input/output.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: '**Computer Hardware Overview**'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s begin with an overview of what makes a computer different from other electronic
    devices. Previously, we’ve seen how we can use logic circuits and memory devices
    to build circuits that perform useful tasks. The circuits we’ve built with logic
    gates have a set of features hard-wired into their design. If we want to add or
    modify a feature, we have to change the physical design of our circuit. On a breadboard
    that’s possible, but for a device that has been manufactured and sent to customers,
    changing hardware isn’t usually an option. Defining the features of a device in
    hardware alone limits our ability to quickly innovate and improve a design.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'The circuits we’ve built so far give us a glimpse into how computers work,
    but we’re missing one critical element of computers: *programmability*. That is,
    a computer must be able to perform new tasks *without* changing hardware. To accomplish
    such a feat, a computer must be able to accept a set of instructions (a *program*)
    and perform the actions specified in those instructions. It must therefore have
    hardware that can perform a variety of operations in the order specified in a
    program. Programmability is a key differentiator between a device that is a computer
    and one that is not. In this chapter we cover computer *hardware*, the physical
    elements of a computer. This is in contrast to *software*, the instructions that
    tell a computer what to do, which we’ll cover in the next chapter.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: The ability to run software distinguishes a computer from a fixed-purpose device.
    That said, software still needs hardware, so what kind of hardware do we need
    to implement a general-purpose computer? First, we need memory. We’ve already
    covered single-bit memory devices such as latches and flip-flops; the type of
    memory used in a computer is a conceptual extension of those simple memory devices.
    The primary memory used in a computer is known as *main memory*, but often it’s
    referred to as just memory or *random access memory (RAM)*. It’s *volatile*, meaning
    it only retains data while powered. The “random access” part of RAM means that
    any arbitrary memory location can be accessed in roughly the same amount of time
    as any other location.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: The second key component we need is a *central processing unit*, or *CPU*. Often
    simply called a *processor*, this component carries out the instructions specified
    in software. The CPU can directly access main memory. Most processors today are
    *microprocessors*, CPUs on a single integrated circuit. A processor built on a
    single integrated circuit has the benefits of lower cost, improved reliability,
    and increased performance. A CPU is a conceptual extension of the digital logic
    circuits we covered previously.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Although main memory and a CPU are the minimum hardware requirements for a computer,
    in practice most computing devices need to interact with the outside world, and
    they do so through input/output (I/O) devices. In this chapter, we cover main
    memory, the CPU, and I/O in more detail. These three elements are illustrated
    in [Figure 7-1](ch07.xhtml#ch7fig1).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-1.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-1: The hardware elements of a computer*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '**Main Memory**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While executing a program, a computer needs a place to store the program’s instructions
    and related data. For example, when a computer runs a word processor for editing
    documents, the computer needs a place to hold the program itself, the contents
    of the document, and the state of editing—what part of the document is visible,
    the location of the cursor, and so forth. All of this data is ultimately a series
    of bits that the CPU needs to be able to access. Main memory handles the task
    of storing these 1s and 0s.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s explore how main memory works in a computer. There are two common types
    of computer memory: *static random access memory (SRAM)* and *dynamic random access
    memory (DRAM)*. In both types, the basic unit of memory storage is a *memory cell*,
    a circuit that can store a single bit. In SRAM, memory cells are a type of flip-flop.
    SRAM is static because its flip-flop memory cells retain their bit values while
    power is applied. On the other hand, DRAM memory cells are implemented using a
    transistor and a capacitor. The capacitor’s charge leaks over time, so data must
    be periodically rewritten to the cells. This refreshing of the memory cells is
    what makes DRAM dynamic. Today, DRAM is commonly used for main memory due to its
    relatively low price. SRAM is faster but more expensive, so it’s used in scenarios
    where speed is critical, such as in cache memory, which we’ll cover later. An
    example “stick” of RAM is shown in [Figure 7-2](ch07.xhtml#ch7fig2).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-2.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-2: Random access memory*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: As a generalization, you can think of the internals of RAM as grids of memory
    cells. Each single-bit cell in a grid can be identified using two-dimensional
    coordinates, the location of that cell in its grid. Accessing a single bit at
    a time isn’t very efficient, so RAM accesses multiple grids of 1-bit memory cells
    in parallel, allowing for reads or writes of multiple bits at once—a whole byte,
    for example. The location of a set of bits in memory is known as a *memory address*,
    a numeric value that identifies a memory location. It’s common for memory to be
    *byte-addressable*, meaning a single memory address refers to 8 bits of data.
    The internal details of the arrangement of memory or the implementation of the
    memory cells aren’t required knowledge for a CPU (or a programmer!). The main
    thing to understand is that computers assign numeric addresses to bytes of memory,
    and the CPU can read or write to those addresses, as illustrated in [Figure 7-3](ch07.xhtml#ch7fig3).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-3.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-3: A CPU reads a byte from a memory address.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider a fictitious computer system that can address up to 64KB of memory.
    By today’s standards, that’s a tiny amount of memory for a computer, but it’s
    still useful for us as an example. Let’s also imagine that our fictitious computer’s
    memory is byte-addressable; each memory address represents a single byte. That
    means that we need one unique address for each byte of memory, and since 64KB
    is 64 × 1024 = 65,536 bytes, we need 65,536 unique addresses. Each address is
    just a number, and memory addresses usually start with 0, so our range of addresses
    is 0 to 65,535 (or 0xFFFF).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Since our fictitious 64KB computer is a digital device, memory addresses are
    ultimately represented in binary. How many bits do we need to represent a memory
    address on this system? The number of unique values that can be represented by
    a binary number with *n* bits is equal to 2^(*n*). So we want to know the value
    of *n* for 2^(*n*) = 65,536\. The inverse of raising 2 to a certain power is the
    base-2 logarithm. Therefore log[2](2^(*n*)) = *n* and log[2](65,536) = 16\. Stated
    another way, 2^(16) = 65,536\. Therefore, a 16-bit memory address is needed to
    address 65,536 bytes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Or, more simply, since we already know that our highest numbered memory address
    is 0xFFFF, and we know that each hexadecimal symbol represents 4 bits, we can
    see that 16 bits are required (4 hex symbols × 4 bits per symbol). Again, our
    fictitious computer is able to address 65,536 bytes, and each byte is assigned
    a 16-bit memory address. [Table 7-1](ch07.xhtml#ch7tab1) shows a 16-bit memory
    layout with some example data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 7-1:** A 16-Bit Memory Address Layout, Skipping Middle Addresses, with
    Example Data'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '| **Memory address (as binary)** | **Memory address (as hex)** | **Example
    data** |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: '| `0000000000000000` | `0000` | `23` |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
- en: '| `0000000000000001` | `0001` | `51` |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: '| `0000000000000010` | `0002` | `4A` |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: '| `----------------` | `----` | `--` |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: '| `1111111111111101` | `FFFD` | `03` |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
- en: '| `1111111111111110` | `FFFE` | `94` |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
- en: '| `1111111111111111` | `FFFF` | `82` |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: Why does the number of bits matter? The number of bits used to represent a memory
    address is a key part of a computer system’s design. It limits the amount of memory
    that a computer can access, and it impacts how programs deal with memory at a
    low level.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now imagine that our fictitious computer has stored the ASCII string “Hello”
    starting at memory address 0x0002\. Since ASCII characters each require 1 byte,
    storing “Hello” requires 5 bytes. When examining memory, it’s common to use hexadecimal
    to represent both memory addresses and the contents of those memory addresses.
    [Table 7-2](ch07.xhtml#ch7tab2) provides a visual look at “Hello” stored in memory,
    starting at address 0x0002.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 7-2:** “Hello” Stored in Memory'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '| **Memory address** | **Data byte** | **Data as ASCII** |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
- en: '| `0000` | `00` |  |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
- en: '| `0001` | `00` |  |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '| `0002` | `48` | `H` |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
- en: '| `0003` | `65` | `e` |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| `0004` | `6C` | `l` |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| `0005` | `6C` | `l` |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: '| `0006` | `6F` | `o` |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: '| `0007` | `00` |  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
- en: '| `----` | `--` |  |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
- en: '| `FFFF` | `00` |  |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
- en: Using this format makes it clear that each address only stores 1 byte, so storing
    all 5 ASCII characters requires addresses 0x0002 through 0x0006\. Note that the
    table shows a value of 00 for other memory addresses, but in practice, it isn’t
    safe to assume that a random address will hold 0; it could be anything. That said,
    in some programming languages it’s standard practice to end a text string with
    a null terminator (a byte equal to 0), and in that case, we’d actually expect
    to see 00 at address 0x0007.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Applications that allow inspection of computer memory commonly represent the
    contents of memory in a format similar to what is shown in [Figure 7-4](ch07.xhtml#ch7fig4).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-4.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-4: A typical view of memory bytes*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: The leftmost column in [Figure 7-4](ch07.xhtml#ch7fig4) is a memory address
    in hexadecimal, and the following 16 values represent the bytes at that address
    and the 15 subsequent addresses. This approach is more compact than [Table 7-2](ch07.xhtml#ch7tab2),
    but it means that each address isn’t uniquely called out. In this figure, we again
    see the ASCII string “Hello” stored starting at address 0x0002.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Our hypothetical computer with 64KB of RAM is useful as an example, but modern
    computing devices tend to have a much larger amount of memory. As of 2020, smartphones
    commonly have at least 1GB of memory, and laptop computers usually have at least
    4GB.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '**EXERCISE 7-1: CALCULATE THE REQUIRED NUMBER OF BITS**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Using the techniques just described, determine the number of bits required for
    addressing 4GB of memory. You’ll want to look back at [Table 1-3](ch01.xhtml#ch1tab3)
    for a reference on SI prefixes. Remember that each byte is assigned a unique address,
    which is just a number. The answer is in [Appendix A](appa.xhtml).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '**Central Processing Unit (CPU)**'
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**中央处理单元（CPU）**'
- en: Memory gives the computer a place to store data and program instructions, but
    it’s the CPU, or processor, that carries out those instructions. It’s the processor
    that allows a computer to have the flexibility to run programs that weren’t even
    conceived of at the time the processor was designed. A processor implements a
    set of instructions that programmers can then use to construct meaningful software.
    Each instruction is simple, but these basic instructions are the building blocks
    for all software.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 内存为计算机提供了一个存储数据和程序指令的地方，但执行这些指令的是CPU或处理器。正是处理器使得计算机能够运行在设计处理器时尚未构想到的程序。处理器实现了一组指令，程序员可以利用这些指令来构建有意义的软件。每条指令都很简单，但这些基本指令是所有软件的构建块。
- en: 'Here are some examples of types of instructions that CPUs support:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是CPU支持的一些指令类型示例：
- en: '**Memory access**   read, write (to memory)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存访问**   读取、写入（到内存）'
- en: '**Arithmetic**   add, subtract, multiply, divide, increment'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**算术**   加法、减法、乘法、除法、自增'
- en: '**Logic**   AND, OR, NOT'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑**   与、或、非'
- en: '**Program flow**   jump (to a specific part of a program), call (a subroutine)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**程序流程**   跳转（到程序的特定部分）、调用（子程序）'
- en: We’ll go into specific CPU instructions in [Chapter 8](ch08.xhtml), but for
    now, it’s important to understand that CPU instructions are just operations that
    the processor can perform. They are fairly simple (add two numbers, read from
    a memory address, perform a logical AND, and so forth). Programs consist of ordered
    sets of these instructions. To use a cooking analogy, the CPU is the cook, a program
    is a recipe, and each instruction in the program is a step of the recipe that
    the cook knows how to perform.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第8章](ch08.xhtml)中详细介绍具体的CPU指令，但现在重要的是要理解，CPU指令只是处理器可以执行的操作。它们相对简单（加两个数字、从内存地址读取、执行逻辑与等）。程序由这些指令的有序集合组成。用做饭的类比，CPU就是厨师，程序是食谱，程序中的每条指令就是厨师知道如何执行的食谱步骤。
- en: Program instructions reside in memory. The CPU reads these instructions so it
    can run the program. [Figure 7-5](ch07.xhtml#ch7fig5) illustrates a simple program
    that’s read from memory by the CPU.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 程序指令驻留在内存中。CPU读取这些指令以便运行程序。[图7-5](ch07.xhtml#ch7fig5)展示了一个简单的程序，CPU从内存中读取该程序。
- en: '![image](../images/fig7-5.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/fig7-5.jpg)'
- en: '*Figure 7-5: An example program is read from memory and runs on the CPU.*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7-5：一个示例程序从内存中读取并在CPU上运行。*'
- en: The example program in [Figure 7-5](ch07.xhtml#ch7fig5) is written in *pseudocode*,
    a human-readable description of a program that’s not written in a real programming
    language. The steps in the program fall into the categories just described (memory
    access, arithmetic, logic, and program flow). In the first step, the program reads
    a number stored at a certain address in memory. The program then adds 3 to that
    number. It then performs a logical AND of two conditions. If the logical result
    is true, then the program does “this”; otherwise, it does “that.” Believe it or
    not, all programs are, in essence, simply various combinations of these types
    of fundamental operations.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7-5](ch07.xhtml#ch7fig5)中的示例程序是用*伪代码*编写的，这是一种人类可读的程序描述，但并不是用真实的编程语言编写的。程序中的步骤属于刚才描述的几类（内存访问、算术、逻辑和程序流程）。在第一步中，程序从内存中的某个地址读取一个数字。然后程序将3加到这个数字上。接着，它执行两个条件的逻辑与操作。如果逻辑结果为真，则程序执行“这个”；否则，执行“那个”。信不信由你，所有程序本质上只是这些基本操作的各种组合。'
- en: '***Instruction Set Architectures***'
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***指令集架构***'
- en: 'Although all CPUs implement these types of instructions, the specific instructions
    available on different processors vary. Some instructions that exist for one type
    of CPU simply don’t exist on other types of CPUs. Even instructions that do exist
    on nearly all CPUs aren’t implemented in the same way. For example, the specific
    binary sequence used to mean “add two numbers” is not the same across processor
    types. A family of CPUs that use the same instructions are said to share an *instruction
    set architecture (ISA)*, or just *architecture*, a model of how a CPU works. Software
    that’s built for a certain ISA works on any CPU that implements that ISA. It’s
    possible for multiple processor models, even those from different manufacturers,
    to implement the same architecture. Such processors may work very differently
    internally, but by adhering to the same ISA, they can run the same software. Today,
    there are two prevalent instruction set architectures: x86 and ARM.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管所有 CPU 都实现了这些类型的指令，不同处理器上可用的具体指令是不同的。有些指令在某一类型的 CPU 上存在，但在其他类型的 CPU 上根本不存在。即使是几乎所有
    CPU 都有的指令，也不是以相同的方式实现的。例如，用于表示“加两个数字”的特定二进制序列，在不同的处理器类型之间并不相同。使用相同指令的 CPU 家族被称为共享
    *指令集架构（ISA）*，或者简称 *架构*，它是描述 CPU 如何工作的模型。为某个特定 ISA 开发的软件可以在任何实现该 ISA 的 CPU 上运行。多个处理器型号，即使来自不同的制造商，也有可能实现相同的架构。这些处理器可能在内部工作方式上有很大不同，但通过遵循相同的
    ISA，它们可以运行相同的软件。如今，存在两种流行的指令集架构：x86 和 ARM。
- en: The majority of desktop computers, laptops, and servers use x86 CPUs. The name
    comes from Intel Corporation’s naming convention for its processors (each ending
    in 86), beginning with the 8086 released in 1978, and continuing with the 80186,
    80286, 80386, and 80486\. After the 80486 (or more simply the 486), Intel began
    branding its CPUs with names such as Pentium and Celeron; these processors are
    still x86 CPUs despite the name change. Other companies besides Intel also produce
    x86 processors, notably Advanced Micro Devices, Inc. (AMD).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数桌面计算机、笔记本电脑和服务器都使用 x86 CPU。这个名字源自英特尔公司为其处理器制定的命名惯例（每个处理器型号都以 86 结尾），从 1978
    年发布的 8086 开始，一直到 80186、80286、80386 和 80486。继 80486（或者更简单地说是 486）之后，英特尔开始使用 Pentium
    和 Celeron 等品牌命名其 CPU；这些处理器尽管更名，但仍然是 x86 CPU。除了英特尔，其他公司也生产 x86 处理器，尤其是超威半导体公司（AMD）。
- en: The term *x86* refers to a set of related architectures. Over time, new instructions
    have been added to the x86 architecture, but each generation has tried to retain
    backward compatibility. This generally means that software developed for an older
    x86 CPU runs on a newer x86 CPU, but software built for a newer x86 CPU that takes
    advantage of new x86 instructions won’t be able to run on older x86 CPUs that
    don’t understand the new instructions.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*x86* 这个术语指的是一组相关的架构。随着时间的推移，新的指令被加入到 x86 架构中，但每一代都试图保持向后兼容性。这通常意味着为较旧的 x86
    CPU 开发的软件可以在较新的 x86 CPU 上运行，但针对较新的 x86 CPU 开发的，利用新 x86 指令的软件将无法在不支持这些新指令的旧 x86
    CPU 上运行。'
- en: 'The x86 architecture includes three major generations of processors: 16-bit,
    32-bit, and 64-bit. Let’s pause to examine what we mean when we say that a CPU
    is a 16-bit, 32-bit, or 64-bit processor. The number of bits associated with a
    processor, also known as its *bitness* or *word size*, refers to the number of
    bits it can deal with at a time. So a 32-bit CPU can operate on values that are
    32 bits in length. More specifically, this means that the computer architecture
    has 32-bit registers, a 32-bit address bus, or a 32-bit data bus. Or all three
    may be 32-bit. We’ll cover more details on registers, data buses, and address
    buses later.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: x86 架构包括三代主要的处理器：16 位、32 位和 64 位。让我们停下来仔细分析一下，当我们说一个 CPU 是 16 位、32 位还是 64 位处理器时是什么意思。与处理器相关的位数，也称为
    *位宽* 或 *字长*，指的是处理器一次可以处理的位数。因此，一个 32 位的 CPU 可以处理 32 位长度的值。更具体地说，这意味着计算机架构有 32
    位寄存器、32 位地址总线或 32 位数据总线，或者这三者都是 32 位。我们稍后会详细讨论寄存器、数据总线和地址总线。
- en: Going back to x86 and its generations of processors, the original 8086 processor,
    released in 1978, was a 16-bit processor. Encouraged by the success of the 8086,
    Intel continued producing compatible processors. Intel’s subsequent x86 processors
    were also 16-bit until the 80386 processor was released in 1985, bringing with
    it a new 32-bit version of the x86 architecture. This 32-bit version of x86 is
    sometimes called IA-32\. Thanks to backward compatibility, modern x86 processors
    still fully support IA-32\. An example x86 processor is shown in [Figure 7-6](ch07.xhtml#ch7fig6).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, it was AMD, and not Intel, that brought x86 into the 64-bit era.
    In the late 1990s, Intel’s 64-bit focus was on a new CPU architecture called IA-64
    or Itanium, which was *not* an x86 ISA, and ended up as a niche product for servers.
    With Intel focused on Itanium, AMD seized the opportunity to extend the x86 architecture.
    In 2003, AMD released the Opteron processor, the first 64-bit x86 CPU. AMD’s architecture
    was originally known as *AMD64*, and later Intel adopted this architecture and
    called its implementation *Intel 64*. The two implementations are mostly functionally
    identical, and today 64-bit x86 is generally referred to as *x64* or *x86-64*.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-6.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-6: An Intel 486 SX, a 32-bit x86 processor*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Although x86 rules the personal computer and server world, ARM processors command
    the realm of mobile devices like smartphones and tablets. Multiple companies manufacture
    ARM processors. A company called ARM Holdings develops the ARM architecture and
    licenses their designs to other companies to implement. It’s common for ARM CPUs
    to be used in *system-on-chip (SoC)* designs, where a single integrated circuit
    contains not only a CPU, but also memory and other hardware. The ARM architecture
    originated in the 1980s as a 32-bit ISA. A 64-bit version of the ARM architecture
    was introduced in 2011\. ARM processors are favored in mobile devices due to their
    reduced power consumption and lower cost as compared to x86 processors. ARM processors
    can be used in PCs as well, but that market largely remains focused on x86, to
    retain backward compatibility with existing x86 PC software. However, in 2020,
    Apple announced their intention to move macOS computers from x86 to ARM CPUs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '***CPU Internals***'
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Internally, a CPU consists of multiple components that work together to execute
    instructions. We’ll focus on three fundamental components: the processor registers,
    the arithmetic logic unit, and the control unit. *Processor registers* are locations
    within the CPU that hold data during processing. The *arithmetic logic unit (ALU)*
    performs logical and mathematical operations. The processor *control unit* directs
    the CPU, communicating with the processor registers, the ALU, and main memory.
    [Figure 7-7](ch07.xhtml#ch7fig7) shows a simplified view of CPU architecture.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-7.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-7: A greatly simplified view of CPU architecture*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at processor registers. Main memory holds data for an executing program.
    However, when a program needs to operate on a piece of data, the CPU needs a temporary
    place to store the data within the processor hardware. To accomplish this, CPUs
    have small internal storage locations known as processor registers, or just registers.
    Compared to accessing main memory, accessing registers is a very fast operation
    for a CPU, but registers can only hold very small amounts of data. We measure
    the size of an individual register in bits, not bytes, because registers are so
    small. As an example, a 32-bit CPU usually has registers that are 32 bits “wide,”
    meaning each register can hold 32 bits of data. The registers are implemented
    in a component known as the *register file* (not to be confused with a data file,
    such as a document or photo). The memory cells used in the register file are typically
    a type of SRAM.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: The ALU handles logic and math operations within the CPU. We previously covered
    combinational logic circuits, circuits in which the output is a function of the
    input. A processor’s ALU is just a complex combinational logic circuit. The ALU’s
    inputs are values called *operands*, and a code indicating what operation to perform
    on those operands. The ALU outputs the result of the operation along with a status
    that provides more detail on execution of the operation.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'The control unit acts as the coordinator of the CPU. It works on a repeating
    cycle: fetch an instruction from memory, decode it, and execute it. Since a running
    program is stored in memory, the control unit needs to know which memory address
    to read in order to fetch the next instruction. The control unit determines this
    by looking at a register known as the *program counter (PC)*, also known as the
    *instruction pointer* on x86\. The program counter holds the memory address of
    the next instruction to execute. The control unit reads the instruction from the
    specified memory address, stores the instruction in a register called the *instruction
    register*, and updates the program counter to point to the next instruction. The
    control unit then decodes the current instruction, making sense of the 1s and
    0s that represent an instruction. Once decoded, the control unit executes the
    instruction, which may require coordinating with other components in the CPU.
    For example, execution of an addition operation requires the control unit to instruct
    the ALU to perform the needed math. Once an instruction has completed, the control
    unit repeats the cycle: fetch, decode, execute.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '***Clock, Cores, and Cache***'
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Since CPUs execute ordered sets of instructions, you may wonder what causes
    a CPU to progress from one instruction to the next. We previously demonstrated
    how a clock signal can be used to move a circuit from one state to another, such
    as in a counter circuit. The same principle applies here. A CPU takes an input
    clock signal, as illustrated in [Figure 7-8](ch07.xhtml#ch7fig8), and a clock
    pulse acts as a signal to the CPU to transition between states.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-8.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-8: A clock provides an oscillating signal to the CPU.*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: It’s an oversimplification to think that a CPU executes exactly one instruction
    per clock cycle. Some instructions take multiple cycles to complete. Also, modern
    CPUs use an approach called *pipelining* to divide instructions into smaller steps
    so that portions of multiple instructions can be run in parallel by a single processor.
    For example, one instruction can be fetched while another is decoded and yet another
    is executed. Still, it can be helpful to think of each pulse of the clock as a
    signal to the CPU to move forward with executing a program. Modern CPUs have clock
    speeds measured in *gigahertz (GHz)*. For example, a 2GHz CPU has a clock that
    oscillates at 2 *billion* cycles per second!
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Increasing the frequency of the clock allows a CPU to perform more instructions
    per second. Unfortunately, we can’t just run a CPU at an arbitrarily high clock
    rate. CPUs have a practical upper limit on their input clock frequency, and pushing
    a CPU beyond that limit leads to excessive heat generation. Also, the CPU’s logic
    gates may not be able to keep up, causing unexpected errors and crashes. For many
    years, the computer industry saw steady increases in the upper limit of clock
    rates for CPUs. This clock rate increase was largely due to regular improvements
    in manufacturing processes that led to increased transistor density, which allowed
    for CPUs with higher clock rates but roughly the same power consumption. In 1978,
    the Intel 8086 ran at 5MHz, and by 1999, the Intel Pentium III had a 500MHz clock,
    a 100x increase in only about 20 years! CPU clock rates continued to increase
    rapidly until the 3GHz threshold was crossed in the early 2000s. Since then, despite
    continued growth in transistor count, physical limitations associated with diminutive
    transistor sizes have made significant increases to clock rate impractical.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: With clock rates stagnant, the processor industry turned to a new approach for
    getting more work out of a CPU. Rather than focusing on increasing clock frequency,
    CPU design began to focus on execution of multiple instructions in parallel. The
    idea of a *multicore* CPU was introduced, a CPU with multiple processing units
    called *cores*. A *CPU core* is effectively an independent processor that resides
    alongside other independent processors in a single CPU package, as illustrated
    in [Figure 7-9](ch07.xhtml#ch7fig9).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-9.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-9: A four-core CPU—each core has its own registers, ALU, and control
    unit*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Note that multiple cores running in parallel is not the same as pipelining.
    The parallelism of multicore means that each core works on a different task, a
    separate set of instructions. In contrast, pipelining happens *within* each core,
    allowing portions of multiple instructions to be executed in parallel by a single
    core.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Each core added to a processor opens the door to a computer running additional
    instructions in parallel. That said, adding multiple cores to a computer’s CPU
    doesn’t mean all applications benefit immediately or equally. Software must be
    written to take advantage of parallel processing of instructions to get the maximum
    benefit of multicore hardware. However, even if individual programs aren’t designed
    with parallelism in mind, a computer system as a whole can benefit, since modern
    operating systems run multiple programs at once.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: I’ve previously described how CPUs load data from main memory into registers
    for processing and then store that data back from registers to memory for later
    use. It turns out that programs tend to access the same memory locations over
    and over. As you might expect, going back to main memory multiple times to access
    the same data is inefficient! To avoid this inefficiency, a small amount of memory
    resides within the CPU that holds a copy of data frequently accessed from main
    memory. This memory is known as a *CPU cache*.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: The processor checks the cache to see if data it wishes to access is there.
    If so, the processor can speed things up by reading or writing to the cache rather
    than to main memory. When needed data is not in the cache, the processor can move
    that data into cache once it has been read from main memory. It’s common for processors
    to have multiple cache levels, often three. We refer to these cache levels as
    L1 cache, L2 cache, and L3 cache. A CPU first checks L1 for the needed data, then
    L2, then L3, before finally going to main memory, as illustrated in [Figure 7-10](ch07.xhtml#ch7fig10).
    L1 cache is the fastest to access, but it’s also the smallest. L2 is slower and
    larger, and L3 is slower and larger still. Remember that even with these progressively
    slower levels of cache, it is still slower to access main memory than any level
    of cache.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-10.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-10: A single-core CPU with three levels of cache*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: In multicore CPUs, some caches are specific to each core, whereas others are
    shared among the cores. For example, each core may have its own L1 cache, whereas
    the L2 and L3 caches are shared, as shown in [Figure 7-11](ch07.xhtml#ch7fig11).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-11.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-11: A two-core CPU with cache. Each core has its own L1 cache, whereas
    L2 and L3 caches are shared.*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '**Beyond Memory and Processor**'
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'I have outlined the two fundamental components required for a computer: memory
    and a processor. However, a device that consists of only memory and a processor
    has a couple of gaps that need to be filled if we want a useful device. The first
    gap is that both memory and CPUs are volatile; they lose state when power is removed.
    The second gap is that a computer with only memory and a processor has no way
    of interacting with the outside world. Let’s now see how secondary storage and
    I/O devices fill these gaps.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '***Secondary Storage***'
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If a computer only included memory and a processor, then every time that device
    was powered down, it would lose all its data! To emphasize that point, *data*
    here means not only a user’s files and settings, but also any installed applications,
    and even the operating system itself. This rather inconvenient computer would
    require someone to load the OS and any applications every time it was powered
    on. That might discourage users from ever turning it off. Believe it or not, computers
    in previous generations did work this way, but fortunately that isn’t the case
    today.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: To address this problem, computers have secondary storage. *Secondary storage*
    is nonvolatile and therefore remembers data even when the system is powered down.
    Unlike RAM, secondary storage is not directly addressable by the CPU. Such storage
    is usually much cheaper per byte than RAM, allowing for a large capacity of storage
    as compared to main memory. However, secondary storage is also considerably slower
    than RAM; it isn’t a suitable replacement for main memory.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: In modern computing devices, hard disk drives and solid-state drives are the
    most common secondary storage devices. A *hard disk drive (HDD)* stores data using
    magnetism on a rapidly spinning platter, whereas a *solid-state drive (SSD)* stores
    data using electrical charges in nonvolatile memory cells. Compared to HDDs, SSDs
    are faster, quieter, and more resistant to mechanical failure, since SSDs have
    no moving parts. [Figure 7-12](ch07.xhtml#ch7fig12) is a photo of a couple of
    secondary storage devices.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: With a secondary storage device in place, a computer can load data on demand.
    When a computer is powered on, the operating system loads from secondary storage
    into main memory; any applications that are set to run at startup also load. After
    startup, when an application is launched, program code loads from secondary storage
    into main memory. The same goes for any user data (documents, music, settings,
    and so on) stored locally; it must load from secondary storage into main memory
    before it can be used. In common usage, secondary storage is often referred to
    simply as storage, while primary storage/main memory is just called memory or
    RAM.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-12.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-12: A 4GB hard disk drive from 1997 beside a modern 32GB microSD
    card, a type of solid-state storage*'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '***Input/Output***'
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Even with secondary storage in place, our hypothetical computer still has a
    problem. A computer consisting of a processor, memory, and storage doesn’t have
    any way of interacting with the outside world! This is where input/output devices
    come in. An *input/output (I/O) device* is a component that allows a computer
    to receive input from the outside world (keyboard, mouse), send data to the outside
    world (monitor, printer), or both (touchscreen). Human interaction with a computer
    requires going through I/O. Computer-to-computer interaction also requires going
    through I/O, often in the form of a computer network, such as the internet. Secondary
    storage devices are actually a type of I/O device. You may not think of accessing
    internal storage as I/O, but from the perspective of the CPU, reading or writing
    to storage is just another I/O operation. Reading from the storage device is input,
    while writing to the storage device is output. [Figure 7-13](ch07.xhtml#ch7fig13)
    provides some examples of input and output.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-13.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-13: Common types of input and output*'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: So how does a CPU go about communicating with I/O devices? A computer can have
    a wide variety of I/O devices attached to it, and the CPU needs a standard way
    to communicate with any such device. To understand this, we need to first discuss
    *physical address space*, the range of hardware memory addresses available to
    a computer. Earlier in this chapter, in the section entitled “Main Memory” on
    [page 119](ch07.xhtml#page_119), we covered how bytes of memory are assigned an
    address. All memory addresses on a given computer system will be represented with
    a certain number of bits. That number of bits determines not only the size of
    each memory address, but also the range of addresses available for the computer
    hardware to use—the physical address space. Address space is often larger than
    the amount of RAM installed on a computer, leaving some physical memory addresses
    unused.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: To give an example, in the case of a computer with a 32-bit physical address
    space, the physical address range is from 0x00000000 to 0xFFFFFFFF (the largest
    address that can be represented with a 32-bit number). That’s approximately 4
    billion addresses, each representing a single byte, or 4GB of address space. Let’s
    say that this computer has 3GB of RAM, so 75 percent of the available physical
    memory addresses are assigned to bytes of RAM.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s return to the question of how CPUs communicate with I/O devices. Addresses
    in physical address space don’t always refer to bytes of memory; they can also
    refer to an I/O device. When physical address space is mapped to an I/O device,
    the CPU can communicate with that device just by reading or writing to its assigned
    memory address(es); this is called *memory-mapped I/O (MMIO)* and is illustrated
    in [Figure 7-14](ch07.xhtml#ch7fig14). When a computer treats the memory of I/O
    devices just like main memory, its CPU does not need any special instructions
    for I/O operations.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: However, some CPU families, notably x86, do include special instructions for
    accessing I/O devices. When computers use this approach, rather than mapping I/O
    devices to a physical memory address, devices are assigned an *I/O port*. A port
    is like a memory address, but instead of referring to a location in memory, the
    port number refers to an I/O device. You can think of the set of I/O ports as
    just another address space, distinct from memory addresses. This means that port
    0x378 does not refer to the same thing as physical memory address 0x378\. Accessing
    I/O devices through a separate port address space is known as *port-mapped I/O
    (PMIO)*. Today’s x86 CPUs support both port-mapped and memory-mapped I/O.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: I/O ports and memory-mapped I/O addresses generally refer to a device controller
    rather than directly to data stored on the device. For example, in the case of
    a hard disk drive, the bytes of the disk aren’t directly mapped into address space.
    Instead, a hard drive controller presents an interface, accessible through I/O
    ports or memory-mapped I/O addresses, that allows the CPU to request read or write
    operations to locations on the disk.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-14.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-14: Memory-mapped I/O*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '**EXERCISE 7-2: GET TO KNOW THE HARDWARE DEVICES IN YOUR LIFE**'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Choose a couple of computing devices that you own or use—say a laptop, smartphone,
    or game console. Answer the following questions about each device. You may be
    able to find the answers by looking at the settings on the device itself, or you
    may have to do some research online.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: What kind of CPU does the device have?
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the CPU 32-bit or 64-bit (or something else)?
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What’s the CPU clock frequency?
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the CPU have L1, L2, or L3 cache? If so, how much?
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which instruction set architecture does the CPU use?
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many cores does the CPU have?
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much and what kind of main memory does the device have?
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much and what kind of secondary storage does the device have?
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What I/O devices does the device have?
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bus Communication**'
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At this point, we’ve covered the roles of memory, the CPU, and I/O devices in
    a computer. We’ve also touched on the CPU’s communication with both memory and
    I/O devices through memory address space. Let’s take a closer look at how the
    CPU communicates with memory and I/O devices.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: A *bus* is a hardware communication system used by computer components. There
    are multiple bus implementations, but in the early days of computers, a bus was
    simply a set of parallel wires, each carrying an electrical signal. This allowed
    multiple bits of data to be transferred in parallel; the voltage on each wire
    represented a single bit. Today’s bus designs aren’t always that simple, but the
    intent is similar.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: There are three common bus types used in communication between the CPU, memory,
    and I/O devices. An *address bus* acts as a selector for the memory address that
    the CPU wishes to access. For example, if a program wishes to write to address
    0x2FE, the CPU writes 0x2FE to the address bus. The *data bus* transmits a value
    read from memory or a value to be written to memory. So if the CPU wishes to write
    the value 25 to memory, then 25 is written to the data bus. Or if the CPU is reading
    data from memory, the CPU reads the value from the data bus. Finally, a *control
    bus* manages the operations happening over the other two buses. As examples, the
    CPU uses the control bus to indicate that a write operation is about to happen,
    or the control bus can carry a signal indicating the status of an operation. [Figure
    7-15](ch07.xhtml#ch7fig15) illustrates how a CPU uses the address bus, data bus,
    and control bus to read memory.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/fig7-15.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-15: The CPU requests a read of the value at address 3F4, and the
    value of 84 is returned.*'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: In the example shown in [Figure 7-15](ch07.xhtml#ch7fig15), the CPU needs to
    read the value stored at memory address 000003F4\. To do this, the CPU writes
    000003F4 to the address bus. The CPU also sets a certain value on the control
    bus, indicating that it wishes to perform a read operation. These bus updates
    act as inputs to the memory controller (the circuit that manages interactions
    with main memory), telling it that the CPU wishes to read the value stored at
    address 000003F4 in main memory. In response, the memory controller retrieves
    the value stored at address 000003F4 (84 in this example) and writes it to the
    data bus, which the CPU can then read.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this chapter, we covered computer hardware: a central processing unit (CPU)
    to execute instructions, random access memory (RAM) that stores instructions and
    data while powered, and input/output (I/O) devices that interact with the outside
    world. You learned that memory is composed of single-bit memory cells, implemented
    with a type of flip-flop in SRAM, and with a transistor and capacitor in DRAM.
    We covered how memory addressing works, where each address refers to a byte of
    memory. You learned about CPU architectures, including x86 and ARM. We explored
    how CPUs work internally, looking at registers, the ALU, and the control unit.
    We covered secondary storage and other types of I/O, and finally, we looked at
    bus communication.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll move beyond hardware to the thing that makes computers
    unique among devices—software. We’ll examine the low-level instructions that processors
    execute, and we’ll see how those instructions can be combined to perform useful
    operations. You’ll have the opportunity to write software in assembly language
    and use a debugger to explore machine code.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
