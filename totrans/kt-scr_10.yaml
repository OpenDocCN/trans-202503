- en: <hgroup>
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <hgroup>
- en: 7 SORTING AND SEARCHING
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 排序与搜索
- en: </hgroup>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: </hgroup>
- en: '![](../images/icon.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/icon.jpg)'
- en: One of the fundamental skills that any serious developer needs to learn is how
    to efficiently sort and search through a given dataset. This skill is invaluable
    for transforming raw data into actionable insights, whether you’re working with
    a simple array or with complex data structures spanning terabytes of multifield
    information extracted from the vast expanse of the internet.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 每个严肃的开发者都需要掌握的基本技能之一就是如何高效地对给定的数据集进行排序和搜索。这项技能对于将原始数据转化为可操作的洞察非常宝贵，无论你是在处理简单的数组，还是在处理跨越数TB、多字段信息的复杂数据结构，这些数据可能来自互联网的广阔天地。
- en: Sorting and searching are a dynamic duo that work hand in hand. *Sorting* organizes
    data into a specific order, which enables meaningful analysis of the dataset as
    a whole. Once the data is sorted, it becomes easier to identify patterns, trends,
    and outliers. Sorting also improves the speed and ease of *searching* for desired
    items within the dataset, especially when working with large volumes of data.
    Indeed, many search algorithms, such as binary search, interpolation search, and
    tree-based searches, rely on the organization achieved through sorting. Searching
    further complements sorting by enabling targeted analysis, allowing for the quick
    location of specific data points or subsets within the dataset. Together, sorting
    and searching streamline data exploration, optimize retrieval efficiency, and
    empower decision-making processes.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 排序和搜索是相辅相成的强大组合。*排序*将数据按特定顺序组织，从而使整个数据集能够进行有意义的分析。一旦数据被排序，就更容易识别模式、趋势和异常值。排序还提高了在数据集中*搜索*所需项的速度和便利性，尤其是在处理大量数据时。实际上，许多搜索算法，如二分搜索、插值搜索和基于树的搜索，都依赖于排序所实现的组织结构。搜索进一步补充了排序，通过启用有针对性的分析，使得快速定位数据集中的特定数据点或子集成为可能。排序和搜索共同简化了数据探索，优化了检索效率，并增强了决策过程的能力。
- en: A wide array of sorting and search algorithms are available. In this chapter’s
    projects, we’ll focus on a selected group of algorithms that have broad applications
    in fields that require working with large datasets. By mastering these algorithms,
    you’ll be better equipped to tackle complex data challenges and make the most
    of sorting and searching capabilities.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种排序和搜索算法可供选择。在本章的项目中，我们将专注于一组具有广泛应用的算法，特别是在需要处理大规模数据集的领域。通过掌握这些算法，你将更好地应对复杂的数据挑战，充分发挥排序和搜索的能力。
- en: Sorting Algorithms
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 排序算法
- en: Sorting algorithms allow us to rearrange a collection of data elements into
    a specific order, such as numerical or alphabetical or based on any other desired
    criteria. We can sort various types of data, including numbers, strings, records
    (lines of data in a database), and complex objects. Sorting is a fundamental building
    block for a variety of operations, such as merging, joining, and aggregating datasets.
    It paves the way for efficient data manipulation, which is crucial in domains
    like database management, algorithms, and programming. By organizing data structures,
    sorting provides a structured framework that promotes clarity, consistency, and
    ease of use. This streamlined approach enhances data management and maintenance,
    particularly in scenarios where data must be updated or modified frequently.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 排序算法允许我们将一组数据元素重新排列成特定的顺序，例如按数字、字母顺序或任何其他所需的标准进行排序。我们可以排序各种类型的数据，包括数字、字符串、记录（数据库中的数据行）以及复杂对象。排序是多种操作的基本构建块，如合并、连接和聚合数据集。它为高效的数据操作铺平道路，这在数据库管理、算法和编程等领域至关重要。通过组织数据结构，排序提供了一个有条理的框架，促进了清晰性、一致性和易用性。这种精简的方法提升了数据管理和维护，特别是在数据需要频繁更新或修改的场景中。
- en: Each sorting algorithm has its own advantages and disadvantages in terms of
    time complexity, space complexity, and stability. Before we get into specific
    algorithms, it’s important to review these concepts, as they’ll assist us in selecting
    the appropriate algorithm for a given problem.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 每种排序算法在时间复杂度、空间复杂度和稳定性方面都有各自的优缺点。在我们深入讨论具体算法之前，了解这些概念非常重要，因为它们将帮助我们为特定问题选择合适的算法。
- en: '*Time complexity* refers to the estimation of the algorithm’s running time
    based on the input size, which is denoted by *n*. It provides insight into how
    the algorithm’s performance scales with larger datasets. Common notations like
    *O*(1), *O*(log *n*), *O*(*n*), *O*(*n* log *n*), *O*(*n*²), and *O*(2*^n*) indicate
    different growth rates of time complexity in increasing order. The smaller the
    growth rate, the quicker the algorithm is in sorting a collection of data.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*时间复杂度*是指根据输入大小*n*来估计算法的运行时间。它提供了算法性能如何随数据集增大而变化的洞察。常见的表示法如 *O*(1)、*O*(log
    *n*)、*O*(*n*)、*O*(*n* log *n*)、*O*(*n*²) 和 *O*(2*^n*) 表示时间复杂度不同的增长速度，按递增顺序排列。增长率越小，算法在排序数据集合时的速度越快。'
- en: '*Space complexity*, on the other hand, describes the amount of additional memory
    an algorithm requires to perform the sorting operation, beyond the memory it needs
    to store the data being sorted. Some algorithms may operate with minimal extra
    space, where the swapping of data elements happens *in place*. Others may require
    significant auxiliary memory to perform sorting operations efficiently. This is
    also called *out-of-place* sorting, where full or partial copies of the original
    dataset are needed to carry out the sorting operation. The smaller the space complexity,
    the more efficient (and scalable) that algorithm is in terms of memory requirements.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*空间复杂度*则描述了算法在执行排序操作时所需的额外内存量，除了存储待排序数据的内存之外。有些算法可能只需最少的额外空间，数据元素的交换发生在*原地*。而另一些算法可能需要大量的辅助内存来有效地执行排序操作，这种方式也称为*非原地排序*，需要对原始数据集进行完整或部分复制来执行排序操作。空间复杂度越小，算法在内存需求方面就越高效（且更具可扩展性）。'
- en: '*Stability* is another important consideration. A sorting algorithm is stable
    if it maintains the relative order of elements with equal values. In certain situations,
    preserving the initial order of equal elements is required, and a stable algorithm
    becomes essential.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*稳定性*是另一个重要的考虑因素。一个排序算法是稳定的，如果它能保持具有相同值的元素的相对顺序。在某些情况下，保持相同元素的初始顺序是必要的，这时稳定的算法就变得至关重要。'
- en: '[Table 7-1](chapter7.xhtml#tab7-1) shows these properties for a selected group
    of sorting algorithms that we’ll discuss in this chapter.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 7-1](chapter7.xhtml#tab7-1) 展示了我们将在本章讨论的选定排序算法的这些特性。'
- en: 'Table 7-1: Key Features of Selected Sorting Algorithms'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7-1：选定排序算法的主要特性
- en: '| Algorithm | Time complexity |  | Space complexity | Stability |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | 时间复杂度 |  | 空间复杂度 | 稳定性 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Best | Average | Worst |  |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 最佳 | 平均 | 最坏 |  |'
- en: '| --- | --- | --- | --- |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Insertion sort | O(n) | O(n2) | O(n2) |  | O(1) | Stable |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 插入排序 | O(n) | O(n²) | O(n²) |  | O(1) | 稳定 |'
- en: '| Merge sort | O(n log n) | O(n log n) | O(n log n) |  | O(n) | Stable |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 归并排序 | O(n log n) | O(n log n) | O(n log n) |  | O(n) | 稳定 |'
- en: '| Quick sort | O(n log n) | O(n log n) | O(n2) |  | O(log n)* | Unstable |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 快速排序 | O(n log n) | O(n log n) | O(n²) |  | O(log n)* | 不稳定 |'
- en: '| Heap sort | O(n log n) | O(n log n) | O(n log n) |  | O(1) | Unstable |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 堆排序 | O(n log n) | O(n log n) | O(n log n) |  | O(1) | 不稳定 |'
- en: '| *The worst case can be O(n). |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| *最坏情况可以是 O(n)。 |'
- en: Of the sorting algorithms listed in [Table 7-1](chapter7.xhtml#tab7-1), insertion
    sort is the simplest and most intuitive, but it isn’t the most efficient in terms
    of average time complexity. It tends to be slower than the other algorithms for
    larger datasets. Due to this limitation, insertion sort generally isn’t used as
    a standalone algorithm, but rather as part of a hybrid sorting scheme that combines
    multiple methods, depending on the characteristics of the data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在[表 7-1](chapter7.xhtml#tab7-1)列出的排序算法中，插入排序是最简单且最直观的，但在平均时间复杂度方面并不是最有效的。对于较大的数据集，它通常比其他算法慢。由于这一限制，插入排序通常不是作为独立的算法使用，而是作为混合排序方案的一部分，根据数据的特征结合多种方法。
- en: Both merge sort and heap sort have similar time complexities, typically *O*(*n*
    log *n*). However, heap sort has an advantage in terms of space complexity because
    it’s an in-place algorithm, meaning it requires minimal additional memory beyond
    the input array. On the other hand, merge sort requires additional space proportional
    to the input size. If stability is a desired property, then merge sort becomes
    the preferred choice over heap sort. It’s a stable sorting algorithm, ensuring
    that elements with equal values maintain their original order.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 合并排序和堆排序具有相似的时间复杂度，通常为*O*(*n* log *n*)。然而，堆排序在空间复杂度方面具有优势，因为它是一种就地排序算法，这意味着它除了输入数组外几乎不需要额外的内存。另一方面，合并排序需要与输入大小成比例的额外空间。如果稳定性是一个期望的属性，那么合并排序就比堆排序更受欢迎。它是一种稳定的排序算法，确保具有相同值的元素保持其原始顺序。
- en: In practice, quick sort often performs better than other sorting algorithms,
    except when the data is already sorted or nearly sorted. Quick sort benefits from
    lower space complexity, and it has smaller overhead, or fewer hidden operations
    that don’t depend on the size of the input data. Many programming language libraries
    provide built-in functions for quick sort, making it easily accessible and widely
    used.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，快速排序通常比其他排序算法表现更好，除非数据已经排序或接近排序。快速排序具有较低的空间复杂度，并且它的开销较小，或者说没有依赖于输入数据大小的隐藏操作。许多编程语言的库都提供了内置的快速排序函数，使其易于访问和广泛使用。
- en: 'Project 27: Space-Efficient Sorting with Insertion Sort'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 项目27：使用插入排序实现空间高效排序
- en: Insertion sort is a simple and intuitive sorting algorithm that works by building
    a sorted array one element at a time. The algorithm maintains a sorted subarray
    within the given array and extends it by inserting elements from the unsorted
    part of the array into the correct position in the sorted part. At the beginning,
    the first element of the array is considered to be a sorted subarray of size 1\.
    The algorithm then iterates through the remaining elements, one at a time, and
    inserts each element into its appropriate position within the sorted subarray.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 插入排序是一种简单直观的排序算法，它通过一次插入一个元素来构建一个已排序的数组。该算法在给定数组中保持一个已排序的子数组，并通过将未排序部分的元素插入已排序部分的正确位置来扩展它。开始时，数组的第一个元素被视为大小为1的已排序子数组。然后，算法逐个遍历剩余的元素，并将每个元素插入到已排序子数组中的适当位置。
- en: To insert an element, the algorithm compares it with the elements in the sorted
    subarray from right to left. It shifts any larger elements one position to the
    right until it finds the correct position for the current element. Once the correct
    position is found, the element is inserted into that position. This process continues
    until all the elements in the array are processed, resulting in a fully sorted
    array.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要插入一个元素，算法将其与已排序子数组中的元素从右到左进行比较。它将任何较大的元素右移一个位置，直到找到当前元素的正确位置。一旦找到正确位置，元素就被插入到该位置。这个过程持续进行，直到数组中的所有元素都被处理，从而得到一个完全排序的数组。
- en: 'Say we have the unsorted array [8, 3, 4, 5, 1, 2]. Here’s how the insertion
    sort algorithm would process it:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个未排序的数组[8, 3, 4, 5, 1, 2]。下面是插入排序算法如何处理它的步骤：
- en: 1.  Imagine that the given array is made up of two subarrays—a sorted array,
    which initially holds only the first element (8), and an unsorted array made up
    of the remaining elements.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 1.  假设给定的数组由两个子数组组成——一个已排序的数组，最初只包含第一个元素（8），另一个未排序的数组由剩余元素构成。
- en: '2.  Compare the second element of the array (index 1) with its preceding element
    (index 0) as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 2.  将数组的第二个元素（索引1）与其前一个元素（索引0）进行比较，如下所示：
- en: a.  Compare 3 with 8\. Since 3 is smaller, swap the elements.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: a.  将3与8进行比较。由于3较小，交换元素。
- en: b.  The array after the first pass is [3, 8, 4, 5, 1, 2].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: b.  第一次遍历后的数组是[3, 8, 4, 5, 1, 2]。
- en: 3.  Move to the next element (index 2) and compare it with the previous elements.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 3.  移动到下一个元素（索引2），并将其与前一个元素进行比较。
- en: a.  Compare 4 with 8\. Since 4 is smaller, swap the elements.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: a.  将4与8进行比较。由于4较小，交换元素。
- en: b.  Compare 4 with 3\. Since 4 is greater, stop comparing.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: b.  将4与3进行比较。由于4较大，停止比较。
- en: c.  The array after the second pass is [3, 4, 8, 5, 1, 2].
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: c.  第二次遍历后的数组是[3, 4, 8, 5, 1, 2]。
- en: '4.  Repeat this process for the remaining elements of the array. In the end,
    the array will be sorted in ascending order: [1, 2, 3, 4, 5, 8].'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 4.  对数组中的剩余元素重复此过程。最后，数组将按升序排序：[1, 2, 3, 4, 5, 8]。
- en: As indicated in [Table 7-1](chapter7.xhtml#tab7-1), insertion sort has an average
    and worst-case time complexity of *O*(*n*²), where *n* is the number of elements
    in the array. However, it performs well for small lists or nearly sorted lists.
    It’s an in-place sorting algorithm with space complexity of *O*(1) for all cases,
    meaning it doesn’t require additional memory to perform the sorting.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如[表 7-1](chapter7.xhtml#tab7-1)所示，插入排序的平均和最坏情况时间复杂度为 *O*(*n*²)，其中 *n* 是数组中元素的个数。然而，它在处理小型列表或几乎已排序的列表时表现良好。它是一种就地排序算法，对于所有情况，空间复杂度为
    *O*(1)，这意味着它在执行排序时不需要额外的内存。
- en: The Code
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代码
- en: Implementing the insertion sort algorithm in Kotlin takes only a few lines of
    code. We’ll create a dedicated function called insertionSort() to handle all the
    necessary steps for sorting an array and call this function from main() to get
    the job done.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kotlin 中实现插入排序算法只需要几行代码。我们将创建一个名为 `insertionSort()` 的专用函数来处理排序数组所需的所有步骤，并从
    `main()` 函数中调用此函数来完成任务。
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code snippet implements the insertion sort algorithm to sort an array of
    numbers (in this case, integers) in ascending order. We create an array called
    arr that holds the initial unsorted array elements. The content of this array
    is printed to the console, allowing us to see the original order of the numbers.
    We then call the insertionSort() function to perform the sorting operation. It
    takes the array as input and modifies it in place, so you don’t have to return
    the sorted array to the calling function.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码实现了插入排序算法，用于按升序对一个数字数组（在此例中为整数）进行排序。我们创建了一个名为 `arr` 的数组，存储初始的未排序数组元素。该数组的内容将打印到控制台，使我们可以看到数字的原始顺序。然后，我们调用
    `insertionSort()` 函数来执行排序操作。它接受数组作为输入并就地修改它，因此您无需将排序后的数组返回给调用函数。
- en: 'Within the insertionSort() function, we iterate through the unsorted portion
    of the array by using a for loop ❶, starting from the second element (index 1)
    and continuing to the last element. For each element, we temporarily store the
    value in a variable called key. Next, we use a while loop ❷ to move from right
    to left through the sorted portion of the array, comparing key with each element.
    The while loop continues as long as two conditions are met: more elements remain
    to the left (checked using j > 0), and the current element is greater than key
    (checked using A[j-1] > key). Inside the while loop, if an element is greater
    than key, it’s shifted one position to the right. This makes space for key to
    be inserted at the correct sorted position.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `insertionSort()` 函数中，我们通过使用 `for` 循环 ❶ 遍历数组的未排序部分，从第二个元素（索引为 1）开始，一直到最后一个元素。对于每个元素，我们将其值临时存储在一个名为
    `key` 的变量中。接下来，我们使用 `while` 循环 ❷ 从右到左遍历数组的已排序部分，将 `key` 与每个元素进行比较。只要满足两个条件，`while`
    循环将继续：左边还有更多元素（使用 `j > 0` 检查），并且当前元素大于 `key`（使用 `A[j-1] > key` 检查）。在 `while` 循环内，如果某个元素大于
    `key`，它将向右移动一个位置。这样就为 `key` 的插入腾出了空间，使其能够插入到正确的排序位置。
- en: When the while loop ends, we assign the value of key to the current position
    in the array ❸, effectively inserting the element into the sorted portion of the
    array at the correct position. The for loop then moves to the next element, and
    the process repeats for all the elements in the array. Once the sorting is complete,
    the code prints the sorted array to the console, displaying the numbers in ascending
    order.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `while` 循环结束时，我们将 `key` 的值赋给数组中的当前位置 ❸，有效地将元素插入到数组已排序部分的正确位置。然后 `for` 循环移到下一个元素，并且这个过程会对数组中的所有元素重复进行。一旦排序完成，代码将排序后的数组打印到控制台，按升序显示数字。
- en: The Result
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果
- en: 'If you run the code without changing the given unsorted array, the output should
    look like this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在不更改给定的未排序数组的情况下运行代码，输出应如下所示：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The code can easily be tweaked to sort floating-point numbers by assembling
    an array of either Float or Double data types. I encourage you to modify the code
    to accept user input regarding the preferred sorting order—either ascending or
    descending. After that, you can implement a suitable function based on the user’s
    choice. Alternatively, you can use the same function with two subfunctions, which
    can be implemented using when(choice), one for sorting an array in ascending order
    and one for doing the opposite.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码可以很容易地调整以对浮点数进行排序，只需将数组改为 `Float` 或 `Double` 数据类型。我鼓励你修改代码以接受用户输入，选择首选的排序顺序——升序或降序。之后，您可以根据用户的选择实现适当的函数。或者，您可以使用相同的函数，并结合两个子函数来实现，通过
    `when(choice)` 来判断一个用于升序排序数组，另一个用于降序排序。
- en: 'Project 28: Faster Sorting with Merge Sort'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 项目28：使用归并排序提高排序速度
- en: '*Merge sort* is a popular sorting algorithm that follows a divide-and-conquer
    approach. It works by recursively dividing an array into smaller subarrays until
    each subarray contains only one element. The subarrays are then merged back into
    longer arrays, placing the elements in the correct order in the process, eventually
    resulting in a fully sorted array. [Figure 7-1](chapter7.xhtml#fig7-1) illustrates
    this process for the same [8, 3, 4, 5, 1, 2] array we used in [Project 27](chapter7.xhtml#pre-27).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*归并排序*是一种流行的排序算法，它采用分治法。它通过递归地将一个数组划分为更小的子数组，直到每个子数组只包含一个元素。然后，这些子数组会被合并成更长的数组，在合并过程中将元素按正确的顺序放置，最终生成一个完全排序的数组。[图
    7-1](chapter7.xhtml#fig7-1)展示了我们在[项目27](chapter7.xhtml#pre-27)中使用的同一个[8, 3, 4,
    5, 1, 2]数组的过程。'
- en: '![](../images/Figure7-1.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/Figure7-1.jpg)'
- en: 'Figure 7-1: Visualizing the merge sort algorithm'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-1：可视化归并排序算法
- en: Notice how the given array is initially divided into two subarrays, and then
    notice how each of those subarrays is further divided into two subarrays, and
    so on. The subarrays are then sorted and merged. When we implement the algorithm
    by using a recursive function, we’ll first process entirely the left subarray
    of the first pair of subarrays—in this example, [8, 3, 4]—before moving on to
    the right subarray, [5, 1, 2]. Within each branch, we’ll divide the subarrays
    into individual elements and then reassemble the sorted subarrays. Eventually,
    the final pair of sorted left and right subarrays will be merged to generate the
    final sorted array.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，给定的数组最初被划分为两个子数组，然后每个子数组会进一步被划分成两个子数组，以此类推。接着，子数组会被排序并合并。当我们通过递归函数实现该算法时，我们会首先完全处理第一对子数组中的左子数组——例如[8,
    3, 4]——然后再处理右子数组[5, 1, 2]。在每个分支内，我们会将子数组划分成单个元素，然后重新组合排序后的子数组。最终，最后一对已排序的左、右子数组将被合并，生成最终的排序数组。
- en: Merge sort guarantees a consistent time complexity of *O*(*n* log *n*) in all
    cases, making it efficient for large datasets. It’s also a stable sorting algorithm,
    preserving the relative order of equal elements. However, it needs additional
    space for the merging step, making its space complexity *O*(*n*). Nonetheless,
    merge sort’s efficiency and stability make it a popular choice for sorting in
    various applications.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 归并排序在所有情况下都能保证一致的时间复杂度 *O*(*n* log *n*)，使其在处理大数据集时非常高效。它还是一个稳定的排序算法，能够保持相等元素的相对顺序。然而，它在合并步骤中需要额外的空间，因此其空间复杂度为
    *O*(*n*)。尽管如此，归并排序的高效性和稳定性使它在各种应用中成为排序的热门选择。
- en: The Code
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代码
- en: 'We’ll follow a similar structure for the merge sort code as we did for the
    insertion sort: a main() function that kicks off the sorting process by passing
    an array to a mergeSort() function. This time, however, mergeSort() will recursively
    call itself until it reaches a stopping condition (when each subarray has only
    one element). To put everything back together, we’ll use a helper function called
    merge(), which handles the task of sorting and merging the subarrays.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将采用类似于插入排序代码结构的方式来编写归并排序代码：通过传递一个数组到mergeSort()函数来启动排序过程的main()函数。然而，这一次，mergeSort()将递归调用自身，直到达到停止条件（每个子数组只包含一个元素）。为了将所有内容重新组合起来，我们将使用一个名为merge()的辅助函数，该函数负责排序和合并子数组。
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the main() function, we begin by initializing an array called arr with a
    set of integer values. We also print the given array before proceeding so that
    we’ll be able to compare this with the sorted array once it’s generated. We then
    call the mergeSort() function ❶, which is responsible for carrying out the sorting
    process. This function takes an array arr as an argument.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在main()函数中，我们首先初始化一个名为arr的数组，包含一组整数值。在继续操作之前，我们还会打印出给定的数组，这样在生成排序后的数组时，便于我们进行对比。然后，我们调用mergeSort()函数
    ❶，该函数负责执行排序过程。这个函数将数组arr作为参数。
- en: 'Within mergeSort(), we first check the length of the incoming array. If it’s
    less than 2, the subarray has a length of 1, so the function simply returns, and
    the splitting process stops. This is the all-important stopping condition that
    any recursive function needs. Next, we calculate the middle index of the array
    ❷ and create two subarrays: leftArray and rightArray. The former contains elements
    from index 0 up to but not including middle, while the latter contains elements
    from middle to the end of the array. To continue the process, the mergeSort()
    function recursively calls itself on both leftArray and rightArray ❸. As mentioned,
    this recursive step continues until the base case is reached—that is, when the
    length of the subarrays becomes 1. Finally, we call merge() to reassemble leftArray
    and rightArray into a single, sorted array.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在 mergeSort() 中，我们首先检查传入数组的长度。如果长度小于 2，则子数组的长度为 1，函数直接返回，分割过程停止。这是任何递归函数所需的至关重要的停止条件。接下来，我们计算数组的中间索引
    ❷，并创建两个子数组：leftArray 和 rightArray。前者包含从索引 0 到但不包括中间的元素，后者包含从中间到数组末尾的元素。为了继续这个过程，mergeSort()
    函数会递归地调用自身处理 leftArray 和 rightArray ❸。如前所述，这个递归步骤会继续进行，直到达到基本情况——即子数组的长度变为 1。最后，我们调用
    merge() 将 leftArray 和 rightArray 重新组合成一个排序后的数组。
- en: The merge() function accepts three parameters, leftArray, rightArray, and arr,
    representing the two subarrays to be merged and the original array that will be
    modified during the merging process. We start the function by initializing variables
    to keep track of the indices within the arrays; i is for traversing the original
    arr, l for the leftArray, and r for the rightArray. The actual merging and sorting
    occur within a while loop ❹ that continues as long as elements remain in both
    leftArray and rightArray to compare. During each iteration, the function compares
    the values at indices l and r in leftArray and rightArray, respectively. If the
    value in leftArray is smaller, it’s assigned to arr at index i, and the l index
    is incremented. Conversely, if the value in rightArray is smaller, it’s assigned
    to arr at index i, and the r index is incremented. Following each assignment,
    the i index is also incremented ❺.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: merge() 函数接受三个参数：leftArray、rightArray 和 arr，分别表示要合并的两个子数组和在合并过程中会被修改的原始数组。我们通过初始化变量来跟踪数组中的索引；i
    用于遍历原始 arr，l 用于 leftArray，r 用于 rightArray。实际的合并和排序发生在一个 while 循环 ❹ 中，只要 leftArray
    和 rightArray 中仍然有元素可以比较，循环就会继续。在每次迭代中，函数会比较 leftArray 和 rightArray 中索引 l 和 r 处的值。如果
    leftArray 中的值更小，则将其赋值给 arr 中的索引 i，并且 l 索引递增。相反，如果 rightArray 中的值更小，则将其赋值给 arr
    中的索引 i，并且 r 索引递增。每次赋值后，i 索引也会递增 ❺。
- en: The while loop concludes when either leftArray or rightArray has been fully
    processed. The remaining elements from the nonempty array are then assigned to
    arr to complete the merging process. We use two separate while loops for this
    task—one for leftArray and one for rightArray. Only one of these loops will actually
    execute.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当左数组（leftArray）或右数组（rightArray）被完全处理时，while 循环结束。然后，将非空数组中的剩余元素分配到 arr 中，完成合并过程。我们为此任务使用了两个独立的
    while 循环——一个用于 leftArray，另一个用于 rightArray。只有其中一个循环会真正执行。
- en: The Result
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果
- en: 'When you run the merge sort code for the given input array, it should produce
    the following output:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行给定输入数组的归并排序代码时，它应该输出以下结果：
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: I encourage you to repeat the same exercise you did with insertion sort, allowing
    the user to choose the order of sorting (ascending or descending) and then modifying
    the code to sort accordingly. I also recommend that you think about arrays containing
    both positive and negative numbers. You might soon realize that by selectively
    multiplying the entire array by –1 before and after sorting, you can use the same
    code to sort an array in ascending or descending order instead of writing two
    separate functions!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你重复你在插入排序时做的练习，让用户选择排序的顺序（升序或降序），然后修改代码以相应地排序。我还建议你考虑包含正数和负数的数组。你可能很快会意识到，通过在排序前后有选择性地将整个数组乘以
    -1，你可以使用相同的代码对数组进行升序或降序排序，而无需编写两个独立的函数！
- en: 'Project 29: High-Efficiency Sorting with Quick Sort'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 项目 29：使用快速排序进行高效排序
- en: '*Quick sort* is a well-known and highly efficient in-place sorting algorithm
    that’s widely used in various real-world applications. It involves selecting a
    pivot element from the array and dividing the remaining elements into two subarrays,
    one for values less than the pivot and the other for values greater than the pivot.
    This mechanism places the pivot element itself in the correct position in the
    final sorted array, while the remaining elements end up on the appropriate side
    of the pivot. The process repeats recursively for the subarrays, selecting new
    pivot elements and further portioning the array, until everything is sorted.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*快速排序*是一种著名且高效的原地排序算法，广泛应用于各种现实世界的应用中。它涉及从数组中选择一个基准元素，并将剩余的元素划分为两个子数组，一个包含小于基准元素的值，另一个包含大于基准元素的值。这个机制将基准元素本身放置在最终排序数组的正确位置，而剩余的元素则落在基准元素的相应一侧。该过程会递归地应用于子数组，选择新的基准元素并进一步划分数组，直到所有元素排序完毕。'
- en: 'Here’s a step-by-step example of how quick sort works, using the array [8,
    3, 4, 5, 1, 2]:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是快速排序如何工作的逐步示例，使用数组[8, 3, 4, 5, 1, 2]：
- en: 1.  Choose a pivot element, which can be any element from the array. In this
    example, we’ll choose the last element, 2.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 1.  选择一个基准元素，可以是数组中的任何元素。在这个例子中，我们选择最后一个元素，2。
- en: 2.  Partition the array into two subarrays, the left subarray with elements
    less than the pivot and the right subarray with elements greater than the pivot.
    In this case, the left subarray becomes [1], and the right becomes [4, 5, 8, 3].
    I’ll explain where this order comes from later in the project.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 2.  将数组划分为两个子数组，左子数组包含小于基准元素的元素，右子数组包含大于基准元素的元素。在这个例子中，左子数组变为[1]，右子数组变为[4, 5,
    8, 3]。我将在项目后续部分解释这个顺序的来源。
- en: '3.  Recursively apply quick sort to the subarrays. For the left subarray, no
    further action is needed: it has only one element, so it’s already in its final
    position. For the right subarray, we now pick 3 as the pivot. This creates an
    empty left subarray as 3 is the smallest number. The right subarray now has [5,
    8, 4].'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 3.  递归地对子数组应用快速排序。对于左子数组，不需要进一步操作：它只有一个元素，因此已经处于最终位置。对于右子数组，我们现在选择3作为基准元素。这将产生一个空的左子数组，因为3是最小的数字。右子数组现在为[5,
    8, 4]。
- en: 4.  Repeat step 3 until all subarrays are sorted, meaning each subarray has
    only one element or is empty.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 4.  重复第3步，直到所有子数组都已排序，即每个子数组只有一个元素或为空。
- en: '5.  Combine the sorted subarrays to get the final sorted array: [1, 2, 3, 4,
    5, 8].'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 5.  将已排序的子数组合并，得到最终的排序数组：[1, 2, 3, 4, 5, 8]。
- en: 'In this example, we always chose the last element of the array or subarray
    as the pivot element. Another option could have been to choose the first element
    as the pivot. For a wide range of inputs, choosing the first or last element as
    the pivot will work well, especially if the input data is randomly or uniformly
    distributed. However, if the array is already sorted or nearly sorted, pivoting
    around the first or last element will yield the worst-case time complexity of
    *O*(*n*²). To avoid this, you can use one of the following alternative techniques
    for choosing a pivot:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们总是选择数组或子数组的最后一个元素作为基准元素。另一种选择是选择第一个元素作为基准元素。对于广泛的输入，选择第一个或最后一个元素作为基准通常表现良好，尤其是在输入数据是随机分布或均匀分布的情况下。然而，如果数组已经排序好或几乎排序好，基于第一个或最后一个元素的选择将导致最坏情况的时间复杂度为*O*(*n*²)。为了避免这种情况，你可以使用以下替代技术来选择基准元素：
- en: '**Choose a random element**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择一个随机元素**'
- en: Randomly selecting a pivot element helps mitigate the inefficiency of choosing
    the first or the last element when the array is already mostly sorted. This approach
    can provide a good average-case performance since the pivot’s position is less
    predictable. It reduces the likelihood of encountering worst-case scenarios, resulting
    in better overall efficiency.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 随机选择基准元素有助于减少选择第一个或最后一个元素时的低效，尤其是当数组已经大部分排序时。这种方法可以提供良好的平均情况性能，因为基准元素的位置较难预测。它减少了遇到最坏情况的可能性，从而提高了整体效率。
- en: '**Choose the median of three**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择三数中的中值**'
- en: This strategy involves using the median value among the first, middle, and last
    elements of the array as the pivot. This approach aims to balance the pivot selection
    by choosing a value closer to the true median of the dataset. It helps improve
    the algorithm’s performance on a wide range of inputs, reducing the chance of
    worst-case behavior.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 该策略通过使用数组中第一个、中央和最后一个元素的中位数作为枢轴。这种方法通过选择一个更接近数据集真正中位数的值来平衡枢轴选择。它有助于提高算法在各种输入上的性能，减少最坏情况的发生概率。
- en: Compared to other sorting algorithms, quick sort is highly efficient for large
    datasets, and its average and worst-case time complexity are *O*(*n* log *n*)
    and *O*(*n*²), respectively. Quick sort has an average space complexity of *O*(log
    *n*), which can degenerate to *O*(*n*) when the input array is already sorted
    or nearly sorted and the first or the last element is chosen as the pivot (worst
    case).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他排序算法相比，快速排序对于大数据集具有很高的效率，其平均时间复杂度和最坏情况下的时间复杂度分别为 *O*(*n* log *n*) 和 *O*(*n*²)。快速排序的平均空间复杂度为
    *O*(log *n*)，但当输入数组已经排序或接近排序，并且选择第一个或最后一个元素作为枢轴时（最坏情况），空间复杂度可能退化为 *O*(*n*)。
- en: The Code
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代码
- en: The code for quick sort is quite similar to that of merge sort in structure,
    as both algorithms rely on a divide-and-conquer approach. In the code, the main()
    function accepts an input array and passes it to the quickSort() function. Within
    quickSort(), we invoke a partition() helper function to determine the correct
    position for the pivot element. This allows us to divide the original array into
    a left array containing elements less than the pivot and a right array containing
    elements greater than or equal to the pivot. Finally, quickSort() is recursively
    called on these subarrays as long as start is less than end, which means at least
    two elements remain in the subarray.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 快速排序的代码在结构上与归并排序非常相似，因为这两种算法都依赖于分治法。在代码中，main() 函数接受一个输入数组，并将其传递给 quickSort()
    函数。在 quickSort() 中，我们调用 partition() 辅助函数来确定枢轴元素的正确位置。这使我们能够将原始数组分成一个包含小于枢轴的元素的左数组和一个包含大于或等于枢轴的元素的右数组。最后，只要
    start 小于 end，即子数组中至少还有两个元素，quickSort() 就会递归调用这些子数组。
- en: '[PRE4]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the main() function, we call the quickSort() function by passing three parameter
    values: the array to be sorted (arr) and the indices for its first and last elements
    (start and end) ❶. As before, we print the array before and after sorting.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在 main() 函数中，我们通过传递三个参数值调用 quickSort() 函数：要排序的数组 (arr) 以及其第一个和最后一个元素的索引 (start
    和 end) ❶。如前所述，我们在排序前后打印数组。
- en: In the quickSort() function, we start by checking whether the starting index
    of the incoming subarray is less than the ending index ❷. When this is no longer
    true, the subarray will have only one element, so the recursion of that branch
    will stop. Otherwise, we call the partition() helper function, which returns the
    final (sorted) position of the pivot element. We store this position as pivotIndex
    and use it to divide the original array into left and right subarrays. We then
    recursively call quicksort() on the left and right subarrays until the stopping
    condition is met.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在 quickSort() 函数中，我们首先检查传入子数组的起始索引是否小于结束索引 ❷。当这不再成立时，子数组将只包含一个元素，因此该分支的递归将停止。否则，我们调用
    partition() 辅助函数，它返回枢轴元素的最终（已排序）位置。我们将这个位置存储为 pivotIndex，并利用它将原始数组分成左子数组和右子数组。然后，我们递归地调用
    quicksort() 对左子数组和右子数组进行排序，直到满足停止条件。
- en: The real sorting work happens inside the partition() function. After setting
    pivot to the value of the last element in the subarray, we use two index variables,
    i and j, to swap the positions of the elements inside a for loop. Both start at
    the beginning of the subarray, and then j steps through the subarray looking for
    elements with values less than pivot ❸. Each time one is found, the values at
    i and j are swapped, and then i is incremented. In effect, this moves elements
    less than the pivot to earlier in the array, and elements greater than the pivot
    to later in the array. Once the for loop is done, the pivot itself is swapped
    with the element at i ❹, which puts the pivot element into its final sorted position.
    Then the final value of i is returned so that two new subarrays can be formed
    on both sides of the final position of the last pivot element. The swaps themselves
    are relegated to a swap() helper function, which uses the temp variable to avoid
    overwriting the value at i. Apart from this one extra variable, the sorting happens
    in place.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If you run the code with the example array, the output should look like this:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: I mentioned earlier that I would explain how the order of the subarray elements
    is determined. This has to do with the swapping algorithm in the partition() function.
    During the first round of processing the [8, 3, 4, 5, 1, 2] array, for example,
    2 is the pivot, and the first element in the array less than the pivot is 1\.
    This element gets swapped with the 8 at the start of the array (accessed using
    index variable i), yielding an array of [1, 3, 4, 5, 8, 2]. Then the pivot itself
    (2) is swapped with the next element of the array (3—again accessed via i), yielding
    [1, 2, 4, 5, 8, 3].
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: I encourage you to manually step through the entire process of sorting the array
    with quick sort. You can refer to [Figure 7-2](chapter7.xhtml#fig7-2), which shows
    the original input array, the intermediate subarrays after each round of processing,
    and the final sorted array. By going through the comparisons and swaps yourself,
    you can visualize the partitioning and sorting process in a more tangible way.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure7-2.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-2: The quick sort steps for [8, 3, 4, 5, 1, 2]'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: You can also autogenerate the subarrays at each stage by printing the left and
    right arrays from inside the quicksort() function, just after the position of
    the pivot is determined.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Search Algorithms
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Searching through a data structure is a fundamental operation in computer science.
    It helps us track down specific elements or retrieve information stored within
    a collection of data. While this task may seem trivial for a small amount of data,
    as the volume of data increases—up to large databases, filesystems, or even the
    whole internet—knowing how to choose the right search algorithm becomes paramount
    to keeping our digital life humming.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Search algorithms are intimately connected to the data structures they’re designed
    to search, since how the data is organized affects how efficiently a particular
    item can be found and accessed. For the purposes of the coming projects, we’ll
    focus on several algorithms that are used to search a graph, which is a type of
    data structure. Before we get to the algorithms themselves, however, it’s important
    to establish how graphs are structured.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: What Is a Graph?
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the field of graph theory, a graph is a mathematical structure consisting
    of a set of vertices (also known as *nodes*) and a set of edges (also known as
    *arcs* or *links*) that connect pairs of vertices. Vertices can represent any
    kind of objects, such as cities, people, or even more abstract concepts. Edges
    represent relationships or connections between the vertices. Mathematically, a
    graph is denoted by *G* and defined as *G* = (***V***, ***E***), where ***V***
    is a set of vertices or nodes, and ***E*** is a set of edges or links.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 7-3](chapter7.xhtml#fig7-3) depicts a simple graph consisting of five
    nodes and five edges. Each circle in the figure represents a vertex, and each
    line represents an edge. The nodes are named with sequential numbers for convenience.
    In real-world cases, most nodes would be names with strings, however. When node
    names are designated by whole numbers, we can treat them as either of type Int
    or of type String in the code.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure7-3.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-3: A simple graph with five nodes and five edges'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'Graphs can be categorized into two main groups: undirected and directed. In
    an *undirected graph*, the edges allow movement between vertices in both directions.
    This type of graph is often used to represent scenarios like a road network, where
    traffic can flow both ways. By contrast, each edge in a *directed graph* has a
    specific direction associated with it, restricting the way you can move between
    vertices. For example, a directed graph can represent a water or power distribution
    network, where the flow always moves from areas of high pressure to areas of low
    pressure or from high voltage to low voltage, respectively.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: When the edges of a graph have weights associated with them, the graph is called
    a *weighted graph*. The weight in this case could be a proxy for cost, distance,
    or any other edge-related property. Weighted graphs can be either directed or
    undirected.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: How to Search a Graph
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the coming projects, we’ll consider three different algorithms for searching
    a graph. The first, *depth-first search (DFS)*, is a technique that starts at
    a particular node and explores as far (or “as deep”) as possible along one branch
    before backtracking and exploring the next. In this way, it traverses the depth
    of a data structure before exploring its breadth. DFS is often implemented by
    using a *stack* data structure (we explored stacks in [Chapter 6](chapter6.xhtml)
    while developing the L-system simulator). This way, DFS can use the youngest node
    in the stack to extend the branch and explore each adjacent node at the end of
    a branch before backtracking and moving to the next branch. DFS is useful in many
    applications, including scheduling problems, detecting cycles in graphs, and solving
    puzzles with only one solution, such as a maze or a sudoku puzzle.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: The next algorithm, *breadth-first search (BFS)*, takes the opposite approach
    of DFS, exploring the data structure level by level. It starts at a given node
    and visits all its immediate neighbors. Then it moves on to the next level, visiting
    all the neighbors’ neighbors, and so on. In this way, BFS prioritizes exploring
    the breadth of the entire data structure over the depth of any individual branch.
    As we’ll discuss in [Project 31](chapter7.xhtml#pre-31), BFS typically uses a
    queue data structure, allowing it to visit each level in order. It’s useful for
    finding the shortest path, web crawling, analyzing social networks, and exploring
    all reachable nodes in a graph while using the smallest number of iterations.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: The choice between DFS and BFS depends on the specific problem and the characteristics
    of the data structure being searched. DFS is typically used when we want to conduct
    a deep exploration and potentially find a target item more quickly, while BFS
    is suitable for situations where we want to visit all nodes at a certain distance
    from the starting point or find the shortest path between nodes.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: The final algorithm we’ll explore is called *A* search* (pronounced “A-star
    search”). It excels in finding the shortest path in a graph or a maze by combining
    heuristic decision-making with real-time exploration to guide the search. The
    term *heuristic* refers to general decision-making strategies that rely on intuition,
    educated guesses, or common sense to arrive at a plausible solution or direction
    to explore. While heuristics can’t guarantee an optimal or perfect outcome, they
    often provide an advantage in situations where constraints such as limited information,
    time, or resources exist.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: The A* algorithm’s heuristic is to consider both the cost of reaching a specific
    node and an estimate of the remaining effort required to reach the destination.
    In this way, A* is able to intelligently prioritize the most promising paths.
    This strategic approach, similar to having a GPS in a labyrinth, helps save time
    and effort in the search process. Due to its versatility, A* is frequently applied
    in fields such as pathfinding in video games, robotics, navigation systems, and
    various optimization problems.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 30: Stack-Based Searching with Depth-First Search'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: In this project, we’ll explore the core steps of depth-first search and implement
    them in Kotlin. We’ll employ the stack data structure in the code, although it’s
    worth noting the existence of other viable methods for implementing the core DFS
    algorithm. Later on, I’ll share some hints on an alternative approach.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'For a given graph (a network of nodes and edges), here are the steps to perform
    a DFS by using a stack:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 1.  Start by selecting a node as the starting node (it can be any node).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 2.  Push the starting node onto the stack.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: 3.  While the stack is not empty, pop a node from the stack.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 4.  If the popped node is not yet visited, mark it as visited and push its neighbors
    to the stack; or else pop the next node from the stack.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 5.  Repeat steps 3 and 4 until the stack is empty.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Recall from [Chapter 6](chapter6.xhtml) that a stack follows the LIFO principle,
    whereby items are removed from the stack in the reverse order in which they were
    added. The LIFO principle allows the DFS algorithm to backtrack from the end of
    one branch before starting on a new, unvisited branch. This ensures an exhaustive
    search of the entire graph, although it would also be beneficial to include a
    stopping condition. When each node is visited, this condition would check if the
    desired goal of the search has been achieved, such as finding a specific object
    or completing a particular task. Once the goal is met, the search can be terminated
    early. For this project, we’ll use the graph shown in [Figure 7-3](chapter7.xhtml#fig7-3).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: The time complexity of the DFS algorithm is *O*(*V* + *E*), where *V* is the
    number of vertices and *E* is the number of edges in the graph. The space complexity
    of DFS depends on the implementation (a stack versus a recursive function); the
    worst-case space complexity is *O*(*V*).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s now examine the code that implements the core steps of DFS. We’ll use
    the code to traverse the entire example graph shown earlier in [Figure 7-3](chapter7.xhtml#fig7-3).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: First, we import the ArrayDeque class from java.util, which we’ll use to implement
    the stack. Next, we declare the main() function, which serves as the entry point
    of the program. It defines the graph as a map pairing each node ("0" through "4")
    with a set of all its neighboring nodes ❶. For example, node "2" is paired with
    the set ["0", "1", "4"], since it’s connected to those nodes. We print the graph
    to the console, then call the dfsStack() function to perform the search, passing
    the graph and a starting node as arguments ❷. Upon completion of the search, the
    list of visited nodes is returned, which is printed as the program’s final output.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Inside the dfsStack() function, we create a mutable set called visited to keep
    track of the visited nodes and an ArrayDeque named stack to store the nodes during
    traversal. We push the starting node to the stack, then enter a while loop that
    iterates for as long as the stack is not empty ❸. In each iteration, the last
    node from the stack is removed by using pop() and assigned to the variable node.
    If the node hasn’t been visited before, we could perform additional operations
    or processing specific to the application at this point—for example, checking
    if the node matches our search criteria and breaking from the loop if it does.
    The node is then added to the visited set by using the add() function.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Next, we add all neighboring nodes, retrieved from graph by using node as the
    key, to the stack via the push() function ❹. We use the nonnull assertion operator
    (!!) while adding graph[node] to the stack to avoid additional null safety checks
    that aren’t required for undirected graphs (every node will have at least one
    link or edge). The while loop terminates once the stack is empty, at which point
    the set of visited nodes is returned to main().
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Note that we could have used the ArrayDeque class from kotlin.collections (as
    we did in [Chapter 6](chapter6.xhtml)) instead of ArrayDeque from java.util to
    implement the stack. In that case, we would replace push() with addLast() and
    pop() with the removeLast() function. I’ve chosen to use the Java version in part
    to illustrate an alternative stack implementation and in part because the ArrayDeque
    method names like push() and pop() fit naturally with the stack architecture.
    Both techniques follow the LIFO principle, meaning that the last element added
    to the stack is the first one removed.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If you run the code with the given graph, you should get the following output:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The list of visited nodes [0, 3, 2, 4, 1] indicates the algorithm has traversed
    the entire graph. To see where this order comes from, and to better understand
    how the stack facilitates the DFS process, consider [Table 7-2](chapter7.xhtml#tab7-2),
    which shows the intermediate values at each step of the algorithm.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7-2: Anatomy of the Depth-First Search Using Stack'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '| Stage | Node | Node not visited? | Visited nodes | Neighbor nodes | Nodes
    on stack |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
- en: '| Initialization, with start of 0 | N/A | N/A | [] (empty) | N/A | [0] (start
    pushed to stack) |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
- en: '| Inside the while loop | 03024212001 | truetruefalsetruetruefalsetruefalsefalsefalsefalse
    | [0][0, 3]no change[0, 3, 2][0, 3, 2, 4]no change[0, 3, 2, 4, 1]no changeno changeno
    changeno change | [1, 2, 3][0]N/A[0, 1, 4][2]N/A[0, 2]N/AN/AN/AN/A | [1, 2, 3][1,
    2, 0][1, 2][1, 0, 1, 4][1, 0, 1, 2][1, 0, 1][1, 0, 0, 2][1, 0, 0][1, 0][1][] (empty;
    while loop terminates) |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
- en: Let’s take a look at a few rows from [Table 7-2](chapter7.xhtml#tab7-2) to understand
    how DFS works. In the first row, we see what happens during the initialization
    phase, before entering the while loop. We set the starting node to "0" and push
    it onto the stack. At this stage, node "0" hasn’t been marked as visited yet.
    Next, we move inside the while loop, where the rest of the processing happens.
    First, we pop the last node from the stack, which is "0" (this makes the stack
    momentarily empty). Since this node isn’t yet marked as visited, we add it to
    the list of visited nodes, which goes from [] to [0]. We then add all this node’s
    neighbors (accessed with graph["0"]) to the stack, which goes from [] to [1, 2,
    3].
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: The next time through the loop, "3" is popped from the stack, since it’s the
    last element. It hasn’t been visited yet, so it’s added to visited, and its only
    neighbor "0" is pushed to the stack. The process continues until the stack is
    found to be empty at the start of a while loop iteration. I strongly encourage
    you to go over the remaining rows of the table to get a hands-on feel for how
    the DFS algorithm works in practice.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 31: Queue-Based Searching with Breadth-First Search'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: In this project we’ll continue our exploration of search algorithms by implementing
    breadth-first search. BFS guarantees that all nodes at the same level are visited
    before moving on to the next level. This process continues until all nodes in
    the graph have been visited. As in [Project 30](chapter7.xhtml#pre-30), we’ll
    use the ArrayDeque class from java.util to implement the BFS algorithm. This time,
    however, we’ll use the class as a *queue*, a data structure that adheres to the
    *first in, first out (FIFO)* principle. Whereas items are always added (“pushed”)
    or removed (“popped”) from the end of a stack, items are added (“enqueued”) at
    the end of a queue and removed (“dequeued”) from the beginning of the queue. This
    ensures that items are processed in the order in which they were added to the
    queue.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform a BFS, we’ll follow these steps:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 1.  Select a node as the starting node (it can be any node).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 2.  Create a mutable list called visited and add the starting node to it.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 3.  Create an empty queue and enqueue (add) the starting node.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '4.  While the queue is not empty, perform the following steps:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: a.  Dequeue the front node from the queue.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: b.  Process the dequeued node as needed (perhaps printing its value or performing
    some operation).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: c.  Enqueue all the unvisited neighbors of the dequeued node and mark them as
    visited.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use the graph shown in [Figure 7-3](chapter7.xhtml#fig7-3) for this project
    as well.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: The time complexity of the BFS algorithm is *O*(*V* + *E*), where *V* is the
    number of vertices and *E* is the number of edges in the graph. The space complexity
    of the BFS algorithm is typically *O*(*V*). Both DFS and BFS therefore have the
    same time complexity, but their space complexity can vary depending on the implementation
    and the structure of the graph.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The code for BFS closely resembles that of DFS, but I’ll highlight a few important
    distinctions as we discuss the program.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The main() function is essentially the same as that of the previous project.
    We define the input graph by using a map data structure and print the graph, displaying
    each node and its neighbors. We then call the bfsQueue() search function, passing
    the graph and the starting node as arguments ❶. The function returns the visited
    nodes, which are printed as the final output of the program.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Inside the bfsQueue() function, we initialize a mutable list called visited
    to keep track of visited nodes as before, along with an ArrayDeque called queue
    to store the nodes to be visited. We then add the starting node to both the visited
    set and the queue, using the offer() method for the latter. Next, we initiate
    a while loop that continues until the queue becomes empty ❷. Within the loop,
    we dequeue a node from the front of the queue by using the poll() method, placing
    it in the node variable. We then iterate over each neighbor of the current node,
    obtained from the graph. If a neighbor hasn’t been visited (meaning it isn’t present
    in the visited set), it’s enqueued by using the offer() method and added to the
    visited set ❸. After processing all the neighbors, the loop continues until the
    queue becomes empty. The visited set is then returned, containing all the nodes
    visited during the search.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  id: totrans-157
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For the given graph, if you run the code without any changes, the code will
    produce the following output:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Again, the list of visited nodes [0, 1, 2, 3, 4] indicates the algorithm has
    successfully traversed the entire graph. This time, the nodes are marked as visited
    in numerical order, a function of the FIFO principle of the queue. [Table 7-3](chapter7.xhtml#tab7-3)
    shows the intermediate values of the key variables as the process unfolds and
    how the BFS algorithm works.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7-3: Anatomy of the Breadth-First Search Using a Queue'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '| Stage | Node | Neighbor nodes | next node | Node not visited? | Nodes on
    queue | Visited nodes |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
- en: '| Initialization, with start of 0 | N/A | N/A | N/A | N/A | [0] | [0] |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
- en: '| Inside the while loop | 0 | [1, 2, 3] | 123 | truetruetrue | [1][1, 2][1,
    2, 3] | [0, 1][0, 1, 2][0, 1, 2, 3] |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
- en: '| 1 | [0, 2] | 02 | falsefalse | [2, 3][2, 3] | no changeno change |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
- en: '| 2 | [0, 1, 4] | 014 | falsefalsetrue | [3][3][3, 4] | no changeno change[0,
    1, 2, 3, 4] |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
- en: '| 3 | [0] | 0 | false | [4] | no change |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
- en: '| 4 | [2] | 2 | false | [] (empty; while loop terminates) | no change |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
- en: Let’s go over a few of the rows in [Table 7-3](chapter7.xhtml#tab7-3) to gain
    a better understanding of how the BFS algorithm is implemented. At the initialization
    stage, we identify node "0" as the start node and add it to both the visited list
    and the queue. Both of these lists now contain "0" (see the first row).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Next, we move inside the while loop, which runs as long as queue is not empty.
    We start with the front node "0" and fetch its neighboring nodes, "1", "2", and
    "3". For each, we check that it hasn’t been visited before; when this is true,
    we add that node to both queue and visited. Since none of these nodes were visited,
    they’re all added to queue and visited when we’re done with node "0".
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: The process continues by pulling the next front node, "1". This time both its
    neighbors, "0" and "2", show up in the visited list, so nothing is added to queue
    or visited. Each time we remove a node from queue, the queue shrinks in size.
    In the final step, node "4" is pulled out, making queue empty, which breaks the
    while loop. The code returns the visited list as the final output.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Comparing [Tables 7-2](chapter7.xhtml#tab7-2) and [7-3](chapter7.xhtml#tab7-3)
    will help you gain a deeper understanding of the unique features of the DFS and
    BFS algorithms.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 32: Heuristic Searching with A*'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: In this project, we’ll explore the A* search algorithm, an informed search algorithm
    that uses a heuristic function to guide the search. Its primary objective is to
    find the optimal path between two nodes in a graph by considering the cost of
    each path. To that end, it’s best suited for working with weighted graphs, where
    each edge has an associated score. [Figure 7-4](chapter7.xhtml#fig7-4) shows the
    graph we’ll use for the project.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure7-4.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-4: An example graph for [Project 32](chapter7.xhtml#pre-32) (start
    node = A, target node = J)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: The graph in the figure has 13 nodes (A through M) and 20 edges, making it significantly
    more substantial than the example graph we used in the previous projects. The
    values along the edges represent the cost of traveling between the two nodes connected
    by that edge. We’re assuming that the graph is undirected, so travel along an
    edge can go in either direction, and that the cost for each edge is *symmetric*,
    meaning it’s the same no matter the direction of travel. For this project, we’re
    interested in determining the lowest-cost route from node A (the start) to node
    J (the target).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: 'As the A* algorithm traverses a graph, it uses two distinct functions to help
    make decisions. One calculates the *g-score*, the actual cost of traveling from
    the start node to the current node. The other calculates the *h-score*, the estimated
    or heuristic cost of traveling from the current node to the target node. Added
    together, these two scores give the *f-score*, the estimated total cost of the
    path:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '*  f-score* = *g-score* + *h-score*'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: One of the key strengths of the A* algorithm is its efficiency in finding the
    shortest path based on this informed approach. But for this to work, we need a
    good heuristic function.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '#### The Heuristic Function'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: In the context of the A* search algorithm, a heuristic function, denoted as
    *h*(*n*), is a function that estimates the cost from the current node to the target
    node in a graph. The purpose of the heuristic function is to guide the search
    algorithm by providing an informed estimate of how far a node is from the target,
    which helps A* make more efficient decisions about which nodes to explore next.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: An *admissible* heuristic function for the A* algorithm is a function that never
    overestimates the cost of reaching the goal from any node. With an admissible
    set of h-scores, A* is guaranteed to find the shortest or least costly path. However,
    not all sets of admissible h-scores are equally good. The algorithm’s performance
    depends on how close the h-scores are to the true costs. The more accurate the
    h-scores are, the faster the algorithm will find the optimal path.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'Another desirable property of the heuristic function is consistency. A *consistent*
    function satisfies this condition: the cost of reaching the goal from a node is
    always less than or equal to the cost of reaching the goal from any neighbor of
    that node, plus the cost of moving to that neighbor. Consistency implies admissibility
    but not vice versa. A consistent set of h-scores can make the A* algorithm more
    efficient, as it will expand fewer nodes and converge to the optimal solution
    very quickly.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: 'Consistent h-scores may be hard or impossible to obtain for large and complex
    real-world problems. However, we can still estimate admissible h-scores that are
    of high quality by using various techniques, depending on the problem type. Here
    are some common approaches for generating heuristic functions:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '**Ad hoc selection of h-scores**'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: This method will work when the graph is small and it’s possible to make conservative
    guesses about the h-scores depending on the depth of a node. For example, one
    can set all h-scores to some arbitrary small value that’s guaranteed to be both
    admissible and consistent.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '**Domain knowledge**'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, domain-specific knowledge can be used to craft heuristic functions.
    This requires an understanding of the problem and what makes a good heuristic
    based on expert insights. For example, in the case of solving an eight-piece sliding
    puzzle with a 3×3 grid, a practical heuristic is the Manhattan distance, determined
    by adding the horizontal and vertical distances between each tile’s current position
    and its target location.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '**Relaxation heuristics**'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: This method involves simplifying a problem by temporarily ignoring certain constraints.
    Relaxation frequently results in an admissible heuristic because it tends to underestimate
    the actual cost. Take, for example, pathfinding problems, where one can use the
    Euclidean distance between two points as a heuristic, ignoring any obstacles that
    may lengthen the path.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '**Abstraction**'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: This method involves simplifying the problem representation by grouping or abstracting
    specific elements within it. Abstraction can lead to admissible and consistent
    heuristics. Consider, for example, a navigation problem, where you could choose
    to abstract the map by representing cities as nodes and major highways as edges,
    while ignoring smaller streets.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '**Pattern databases**'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: In problems with large state spaces, where the graph includes numerous nodes
    and links (such as puzzle games), pattern databases can be employed to precompute
    heuristic values for subsets of the state space. These databases store the cost-to-goal
    for small subsets of the problem, and the heuristic for a given state is estimated
    as the sum of the costs associated with the relevant subsets.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: 'In the context of the graph shown in [Figure 7-4](chapter7.xhtml#fig7-4), we’ll
    employ a combination of abstraction and ad hoc heuristic approaches to estimate
    a set of h-scores that are both admissible and consistent. Since we lack additional
    information about the nodes, such as their coordinates, we’ll begin with a simplifying
    assumption (abstraction): all edges or links within the graph have the same weight
    or cost. Furthermore, we’ll assume this weight equals the smallest weight found
    within the graph (ad hoc). Our approach can be summarized as a three-step process:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '1.  Edge weight assumption: Assume that all edges within the graph have an
    identical weight, and set this value to the smallest weight found within the graph.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '2.  Minimum links count: For each node, determine the minimum number of edges
    or links needed to traverse from that node to the target node.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '3.  H-score estimation: The h-score for each node is estimated by multiplying
    the smallest weight determined in step 1 with the minimum number of links needed
    to reach the target node, as found in step 2.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Given the relatively modest size of the graph, using this process to calculate
    h-scores is straightforward and quick. A brief examination of the weights reveals
    that the smallest one within the graph is 2 (for the link connecting nodes B and
    C). Now let’s consider nodes I and K, immediate neighbors of the target node J.
    Their h-scores will be 2 × 1 = 2, since both I and K are only one link away from
    the target. Similarly, h-scores for nodes E, F, G, H, and L, which are two links
    away from the target, can be estimated as 2 × 2 = 4\. Following this logical progression,
    the h-score for the starting node A, located farthest from the target, is estimated
    to be 2 × 4 = 8 because at least four links must be traversed to reach the target.
    Once these heuristic values are computed, you can easily incorporate them into
    the application’s getHScore() function, a lookup function that retrieves the h-score
    for a given node. (We’ll discuss this function later, along with the rest of the
    code.)
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Given our approach of utilizing the minimum number of links necessary to traverse
    from a given node to the target, along with our use of the smallest weight present
    in the graph for h-score calculation, the resulting h-scores meet the criterion
    of admissibility. They never overestimate the cost of reaching the target. I invite
    you to verify that these h-scores also meet the criterion of consistency as defined
    earlier in the section. You can do this either manually or by writing a few lines
    of code.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: The Algorithm
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Given our heuristic function, here are the steps we’ll take to find the optimal
    path between two nodes by using the A* algorithm. This method assumes that at
    least one valid route exists between the starting node and the target:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: 1.  Initialize two mutable maps to keep track of the visited and the unvisited
    nodes, respectively. The visited map starts empty; the unvisited map starts with
    all nodes in the graph.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 2.  Initialize each unvisited node’s g-score and f-score to infinity (or the
    maximum possible value of the corresponding type) and its previous node property
    to “none.”
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: 3.  Set the starting node’s g-score to 0 (as the journey starts here, no previous
    node exists to come from), calculate or look up its h-score, and set its f-score
    equal to its h-score (since g-score = 0). Leave its previous node property set
    to “none.”
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '4.  While the unvisited map is not empty:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: a.  Select the node with the lowest f-score from the unvisited nodes and designate
    that as the current node. (The starting node will be the first current node.)
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: b.  If the current node is the target node, add the current node to the visited
    map and terminate the loop (the target has been reached).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: c.  Otherwise (when the current node is not the target node), retrieve the current
    node’s neighbors from the graph.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: d.  For each neighbor that has not already been visited, calculate a new g-score
    by adding the weight of the edge between the current node and the neighbor to
    the g-score of the current node. If this new g-score is lower than the neighbor’s
    existing g-score, update the neighbor’s attributes (g-score, f-score, previous
    node).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: e.  Add the current node to the visited map and remove it from the unvisited
    map.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 5.  Once the loop ends, the visited map is returned, which contains information
    about the nodes explored during the search, their directional relationship (as
    captured in the “previous node” property), and the associated costs (g-scores
    and f-scores).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 6.  Use the information contained in the visited map to reconstruct the entire
    optimal path.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: These steps outline the essence of the A* algorithm. They involve maintaining
    an open set of nodes to be explored and a closed set of nodes that have been visited,
    and calculating the cost of each node based on the actual cost from the starting
    node (g-score) and the estimated cost to the target node (h-score). By iteratively
    selecting the node with the lowest total cost (f-score), the algorithm efficiently
    finds the shortest path from the starting node to the target node.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: The time complexity of the A* search algorithm depends on the nature of the
    problem and the quality of the heuristic function used. In the worst case, the
    time complexity of A* is *O*(*b**^d*), where *b* is the branching factor (the
    average number of edges per node) and *d* is the depth of the shallowest target
    node (the minimum number of edges or steps needed to reach the target from the
    starting node). The space complexity of the standard A* algorithm depends on the
    data structure used for the open and closed lists (for example, this could be
    implemented by using priority queues). In the worst case, the space complexity
    can be very high, also up to *O*(*b**^d*), due to the storage of nodes in the
    open and closed lists.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: A well-chosen (admissible and consistent) heuristic can significantly improve
    the performance of A*, however, by efficiently guiding the algorithm to the target
    node, reducing the search space, and potentially making the actual time and space
    complexities much lower in practice. In the best-case scenario, when the heuristic
    function is perfect and the algorithm efficiently explores the most promising
    paths first, for example, A* can have a time complexity of *O*(*d*).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The code for A* search is more involved than the code for DFS and BFS. For this
    reason, I’ll break it down into a number of segments, starting with the global
    declarations and the main() function.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This application doesn’t require an import block, as the search algorithm can
    be implemented without relying on any specialized library functions. The sole
    global component is a data class that holds three key attributes of a node: its
    g-score, its f-score, and the previous node along the optimal path.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: In the main() function, we first define the graph shown in [Figure 7-4](chapter7.xhtml#fig7-4)
    as a Map ❶. Each node is specified in terms of its name ("A", "B", "C", and so
    on) along with an inner Map pairing each of the node’s neighbors with the weight
    of the edge leading to that neighbor. You can think of graph as a map of maps
    (similar to a list of lists) encapsulating all nodes in the network and their
    interconnections. Once the graph is defined, it’s printed by calling the displayGraph()
    function.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: We next define the start and target nodes ("A" and "J" in this example) and
    call the aStar() function by passing the start and target nodes and the graph
    to be searched as arguments ❷. A call to this function returns a list of visited
    nodes (visitedList) as a Map of type <String, List<Any>>. This list represents
    a subset of nodes that the algorithm explored while trying to locate the optimal
    path. Crucially, A* search doesn’t need to visit all nodes in the graph, as it
    relies on heuristic information to zoom in on the region that includes the optimal
    solution. We use the displayList() function to print this visited list and then
    call the displayShortestPath() function, which reconstructs and displays the optimal
    path.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '##### The Display Functions'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a closer look at the various display helper functions called from
    the main() function, starting with the displayGraph() function, which prints the
    whole graph.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This function takes in graph as its sole argument, which as we’ve seen is a
    Map of type <String, Map<String, Int>>. It uses two for loops to print the elements
    of graph. The outer loop cycles through the nodes, one at a time, printing each
    one. The inner loop extracts and prints each of the current node’s neighbors,
    along with the associated edge weights (labeled as Cost in the output). You’ll
    see how the output looks later when we examine the results.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Now we’ll consider the displayList() function, which prints the characteristics
    of each visited node after the A* search is complete.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This simple function uses a for loop to extract and print the collection of
    visited nodes and their attributes. Each element in this list, which is presented
    as a Map object, has two components: the name of the visited node and a Node object
    with three data points linked to the node—its g-score (Int), f-score (Int), and
    the previous node (String). The latter is the node from which we would have departed
    to reach the current node, ensuring the minimum f-score for the current node.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, here’s the displayShortestPath() function, which takes in the list
    of visited nodes, the start node, and the target node, and identifies the optimal
    path:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The function reconstructs the path in reverse, working backward from the target
    to the starting node. We start by initializing two variables to targetNode: currentNode,
    representing the current position in the path, and path, where the entire path
    is built up node by node. We then enter a while loop that iterates until currentNode
    becomes startNode. In the loop, we access currentNode from the list of visited
    nodes (supplied as a Map of type <String, Node>) and use its previousNode property
    to look up its previous node ❶. Next, we concatenate previousNode with the current
    value of path ❷ and update currentNode to previousNode for the next iteration.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: After the loop ends, we retrieve cost, the g-score of the target node, from
    the list of visited nodes, using targetNode as the key. We then print the reconstructed
    optimal path and its cost.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: The aStar() Function and Its Helpers
  id: totrans-236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s now dive into the core of the A* algorithm implemented in aStar() and
    its helper functions. This code very closely follows the steps outlined earlier
    for implementing the A* algorithm.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The algorithm begins by creating two mutable maps: visited and unvisited. At
    first, unvisited contains all the nodes in the graph, each initialized with the
    maximum possible g-score and f-score, and with a previous node of "none" ❶. The
    visited map, which is initially empty, keeps track of the nodes that have been
    visited. Next, the startNode in the unvisited map is updated to have a g-score
    of 0 and an f-score equivalent to its h-score ❷, which is retrieved with the getHScore()
    helper function. As shown here, this helper is implemented as a simple lookup
    function:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: These scores were estimated by using the hybrid three-step process explained
    earlier. Note that the h-score for the target node "J" is 0.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'Returning to the aStar() function, we next display the list of unvisited nodes
    and enter a while loop that continues until the unvisited map is empty or the
    target node is reached ❸. Within the loop, currentNode is set to the unvisited
    node with the minimum f-score by using the getCurrentNode() helper function ❹.
    Here’s how that helper function is implemented by using Kotlin’s built-in .minByOrNull
    method:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Back in aStar(), we check if currentNode is the same as targetNode ❺. If it
    is, we add the current node to the visited map and break the loop. Otherwise,
    for each neighbor of the current node not already in the visited map ❻, we calculate
    a new g-score by adding the edge weight to the current node’s g-score. If the
    new g-score is lower than the neighbor’s current g-score ❼, the neighbor’s attributes
    in the unvisited map are updated: its g-score is set to newGScore, its f-score
    is set to its new g-score, plus its h-score (again retrieved with the getHScore()
    function), and its previous node is set to currentNode.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: After processing all neighbors, the currentNode is added to the visited map
    and removed from the unvisited map. When the while loop terminates, the visited
    map is returned with all the information needed to reconstitute the optimal path.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  id: totrans-246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We’re now ready to run the code and have a look at its console output.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The output starts by printing the entire graph, node by node, along with each
    node’s neighbors and edge weights. Next, the initial state of the unvisited map
    is shown after updating the starting node’s attributes. Apart from node "A", each
    node should have the maximum possible g- and f-scores (2147483647) and a previous
    node of "none". Once the target node is reached, a message is printed before exiting
    the while loop. Then the final list of all visited nodes is printed. Looking over
    the list, we can see that not every node as been visited—nodes "L" and "M", representing
    a dead end, were skipped. Notice also that the target node’s g-score is the same
    as its f-score because its h-score is 0\. Also, as expected, all g-scores are
    less than or equal to their corresponding f-scores. This is because the f-score
    is the sum of the g-score and the h-score, and the latter is assumed to be greater
    than or equal to 0.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the terminal output shows the step-by-step process of reconstructing
    the optimal path, followed by the full path and its total associated cost.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this chapter, we explored some representative concepts and algorithms from
    two related domains: sorting and searching. These essential concepts and tools
    have extensive use in the realms of computer and data science, particularly in
    the context of information retrieval from databases, search engine performance
    optimization, data visualization, data mining, machine learning, and network routing.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: Within the domain of sorting, we implemented the insertion sort, merge sort,
    and quick sort algorithms and gained insight into their respective strengths,
    weaknesses, time and space complexities, and stability characteristics. In the
    searching domain, our projects revolved around navigating graph data structures.
    We implemented the depth-first search (DFS), breadth-first search (BFS), and A*
    algorithms.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Throughout these projects, we harnessed the power of various Kotlin features,
    including both stack and queue data structures, as well as lists, maps, and more
    intricate constructs like maps of maps. Last but not least, by tackling the exercises,
    you’ll not only solidify your grasp of these core concepts but also raise your
    sorting and searching skills to a professional level.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Bhargava, Aditya Y. *Grokking Algorithms*. 2nd ed. Shelter Island, NY: Manning,
    2024.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'Cormen, Thomas H., Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein.
    *Introduction to Algorithms*. 4th ed. Cambridge, MA: MIT Press, 2022.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'Even, Shimon. *Graph Algorithms*. 2nd ed., edited by Guy Even. New York: Cambridge
    University Press, 2012.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'Heineman, George, Gary Pollice, and Stanley Selkow. *Algorithms in a Nutshell*.
    2nd ed. Sebastopol, CA: O’Reilly, 2016.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'Kopec, David. *Classic Computer Science Problems in Python*. Shelter Island,
    NY: Manning, 2019.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: 'Skiena, Steven. *The Algorithm Design Manual*. 3rd ed. Cham, Switzerland: Springer
    Nature, 2020.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: 'Wengrow, Jay. *A Common-Sense Guide to Data Structures and Algorithms*. 2nd
    ed. Raleigh, NC: The Pragmatic Bookshelf, 2020.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
