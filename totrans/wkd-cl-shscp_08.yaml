- en: '**7**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**WEB AND INTERNET USERS**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/common4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: One area where Unix really shines is the internet. Whether you want to run a
    fast server from under your desk or simply surf the web intelligently and efficiently,
    there’s little you can’t embed in a shell script when it comes to internet interaction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Internet tools are scriptable, even though you might never have thought of
    them that way. For example, FTP, a program that is perpetually trapped in debug
    mode, can be scripted in some very interesting ways, as is explored in [Script
    #53](ch07.xhtml#ch07lev1sec01) on [page 174](ch07.xhtml#page_174). Shell scripting
    can often improve the performance and output of most command line utilities that
    work with some facet of the internet.'
  prefs: []
  type: TYPE_NORMAL
- en: The first edition of this book assured readers that the best tool in the internet
    scripter’s toolbox was `lynx`; now we recommend using `curl` instead. Both tools
    offer a text-only interface to the web, but while `lynx` tries to offer a browser-like
    experience, `curl` is designed specifically for scripts, dumping out the raw HTML
    source of any page you’d like to examine.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following shows the top seven lines of the source from the
    home page of *Dave on Film*, courtesy of `curl`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can accomplish the same result with `lynx` if `curl` isn’t available, but
    if you have both, we recommend `curl`. That’s what we’ll work with in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '**WARNING**'
  prefs: []
  type: TYPE_NORMAL
- en: '*One limitation to the website scraper scripts in this chapter is that if the
    script depends on a website that’s changed its layout or API in the time since
    this book was written, the script might be broken. But if you can read HTML or
    JSON (even if you don’t understand it all), you should be able to fix any of these
    scripts. The problem of tracking other sites is exactly why Extensible Markup
    Language (XML) was created: it allows site developers to provide the content of
    a web page separately from the rules for its layout.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**#53 Downloading Files via FTP**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the original killer apps of the internet was file transfer, and one of
    the simplest solutions is FTP, File Transfer Protocol. At a fundamental level,
    all internet interaction is based on file transfer, whether it’s a web browser
    requesting an HTML document and its accompanying image files, a chat server relaying
    lines of discussion back and forth, or an email message traveling from one end
    of the earth to the other.
  prefs: []
  type: TYPE_NORMAL
- en: The original FTP program still lingers on, and while its interface is crude,
    the program is powerful, capable, and well worth taking advantage of. There are
    plenty of newer FTP programs around, notably FileZilla (*[http://filezilla-project.org/](http://filezilla-project.org/)*)
    and NcFTP (*[http://www.ncftp.org/](http://www.ncftp.org/)*), plus lots of nice
    graphical interfaces you can add to FTP to make it more user-friendly. With the
    help of some shell script wrappers, however, FTP does just fine for uploading
    and downloading files.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a typical use case for FTP is to download files from the internet,
    which we’ll do with the script in [Listing 7-1](ch07.xhtml#ch7ex1). Quite often,
    the files will be located on anonymous FTP servers and will have URLs similar
    to *ftp://<someserver>/<path>/<filename>/*.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-1: The* `*ftpget*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***How It Works***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The heart of this script is the sequence of commands fed to the FTP program
    starting at ➊. This illustrates the essence of a batch file: a sequence of instructions
    that’s fed to a separate program so that the receiving program (in this case FTP)
    thinks the instructions are being entered by the user. Here we specify the server
    connection to open, specify the anonymous user (FTP) and whatever default password
    is specified in the script configuration (typically your email address), and then
    get the specified file from the FTP site and quit the transfer.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Running the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This script is straightforward to use: just fully specify an FTP URL, and it’ll
    download the file to the current working directory, as [Listing 7-2](ch07.xhtml#ch7ex2)
    details.'
  prefs: []
  type: TYPE_NORMAL
- en: '***The Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-2: Running the* `*ftpget*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: Some versions of FTP are more verbose than others, and because it’s not too
    uncommon to find a slight mismatch in the client and server protocol, those verbose
    versions of FTP can spit out scary-looking errors, like `Unimplemented command`.
    You can safely ignore these. For example, [Listing 7-3](ch07.xhtml#ch7ex3) shows
    the same script run on OS X.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-3: Running the* `*ftpget*` *script on OS X*'
  prefs: []
  type: TYPE_NORMAL
- en: If your FTP is excessively verbose and you’re on OS X, you can quiet it down
    by adding a `-V` flag to the FTP invocation in the script (that is, instead of
    FTP `-n`, use FTP `-nV`).
  prefs: []
  type: TYPE_NORMAL
- en: '***Hacking the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This script can be expanded to decompress the downloaded file automatically
    (see [Script #33](ch04.xhtml#ch04lev1sec07) on [page 109](ch04.xhtml#page_109)
    for an example of how to do this) if it has certain file extensions. Many compressed
    files such as *.tar.gz* and *.tar.bz2* can be decompressed by default with the
    system `tar` command.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also tweak this script to make it a simple tool for *uploading* a specified
    file to an FTP server. If the server supports anonymous connections (few do nowadays,
    thanks to script kiddies and other delinquents, but that’s another story), all
    you really have to do is specify a destination directory on the command line or
    in the script and change the `get` to a `put` in the main script, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To work with a password-protected account, you could have the script prompt
    for the password interactively by turning off echoing before a `read` statement
    and then turning it back on when you’re done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: A smarter way to prompt for a password, however, is to just let the FTP program
    do the work itself. This will happen as written in our script because if a password
    is required to gain access to the specified FTP account, the FTP program itself
    will prompt for it.
  prefs: []
  type: TYPE_NORMAL
- en: '**#54 Extracting URLs from a Web Page**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A straightforward shell script application of `lynx` is to extract a list of
    URLs on a given web page, which can be quite helpful when scraping the internet
    for links. We said we’d switched from `lynx` to `curl` for this edition of the
    book, but it turns out that `lynx` is about a hundred times easier to use for
    this script (see [Listing 7-4](ch07.xhtml#ch7ex4)) than `curl`, because `lynx`
    parses HTML automatically whereas `curl` forces you to parse the HTML yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t have `lynx` on your system? Most Unix systems today have package managers
    such as `yum` on Red Hat, `apt` on Debian, and `brew` on OS X (though `brew` is
    not installed by default) that you can use to install `lynx`. If you prefer to
    compile `lynx` yourself, or just want to download prebuilt binaries, you can download
    it from *[http://lynx.browser.org/](http://lynx.browser.org/)*.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-4: The* `*getlinks*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***How It Works***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When displaying a page, `lynx` shows the text of the page formatted as best
    it can followed by a list of all hypertext references, or links, found on that
    page. This script extracts just the links by using a `sed` invocation to print
    everything after the `"References"` string in the web page text ➎. Then the script
    processes the list of links as needed based on the user-specified flags.
  prefs: []
  type: TYPE_NORMAL
- en: One interesting technique demonstrated by this script is the way the variable
    `lastcmd` (➊, ➋, ➌, ➍) is set to filter the list of links that it extracts according
    to the flags specified by the user. Once `lastcmd` is set, the amazingly handy
    `eval` command ➏ is used to force the shell to interpret the content of the variable
    as if it were a command instead of a variable.
  prefs: []
  type: TYPE_NORMAL
- en: '***Running the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'By default, this script outputs a list of all links found on the specified
    web page, not just those that are prefaced with `http:`. There are three optional
    command flags that can be specified to change the results, however: `-d` produces
    just the domain names of all matching URLs, `-r` produces a list of just the *relative*
    references (that is, those references that are found on the same server as the
    current page), and `-a` produces just the *absolute* references (those URLs that
    point to a different server).'
  prefs: []
  type: TYPE_NORMAL
- en: '***The Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A simple request is a list of all links on a specified website home page, as
    [Listing 7-5](ch07.xhtml#ch7ex5) shows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-5: Running the* `*getlinks*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another possibility is to request a list of all domain names referenced at
    a specific site. This time, let’s first use the standard Unix tool `wc` to check
    how many links are found overall:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Amazon has 219 links on its home page. Impressive! How many different domains
    does that represent? Let’s generate a list with the `-d` flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Amazon doesn’t tend to point outside its own site, but there are some partner
    links that creep onto the home page. Other sites are different, of course.
  prefs: []
  type: TYPE_NORMAL
- en: What if we split the links on the Amazon page into relative and absolute links?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you might have expected, Amazon has four times more relative links pointing
    inside its own site than it has absolute links, which would lead to a different
    website. Gotta keep those customers on your own page!
  prefs: []
  type: TYPE_NORMAL
- en: '***Hacking the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You can see where `getlinks` could be quite useful as a site analysis tool.
    For a way to enhance the script, stay tuned: [Script #69](ch09.xhtml#ch09lev1sec01)
    on [page 217](ch09.xhtml#page_217) complements this script nicely, allowing us
    to quickly check that all hypertext references on a site are valid.'
  prefs: []
  type: TYPE_NORMAL
- en: '**#55 Getting GitHub User Information**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GitHub has grown to be a huge boon to the open source industry and open collaboration
    across the world. Many system administrators and developers have visited GitHub
    to pull down some source code or report an issue to an open source project. Because
    GitHub is essentially a social platform for developers, getting to know a user’s
    basic information quickly can be useful. The script in [Listing 7-6](ch07.xhtml#ch7ex6)
    prints some information about a given GitHub user, and it gives a good introduction
    to the very powerful GitHub API.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-6: The* `*githubuser*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***How It Works***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Admittedly, this is almost more of an `awk` script than a bash script, but sometimes
    you need the extra horsepower `awk` provides for parsing (the GitHub API returns
    JSON). We use `curl` to ask GitHub for the user ➊, given as the argument of the
    script, and pipe the JSON to `awk`. With `awk`, we specify a field separator of
    the double quotes character, as this will make parsing the JSON much simpler.
    Then we match the JSON with a handful of regular expressions in the `awk` script
    and print the results in a user-friendly way.
  prefs: []
  type: TYPE_NORMAL
- en: '***Running the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The script accepts a single argument: the user to look up on GitHub. If the
    username provided doesn’t exist, nothing will be printed.'
  prefs: []
  type: TYPE_NORMAL
- en: '***The Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When passed a valid username, the script should print a user-friendly summary
    of the GitHub user, as [Listing 7-7](ch07.xhtml#ch7ex7) shows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-7: Running the* `*githubuser*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Hacking the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This script has a lot of potential due to the information that can be retrieved
    from the GitHub API. In this script, we are only printing four values from the
    JSON returned. Generating a “résumé” for a given user based on the information
    provided by the API, like those provided by many web services, is just one possibility.
  prefs: []
  type: TYPE_NORMAL
- en: '**#56 ZIP Code Lookup**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To demonstrate a different technique for scraping the web, this time using `curl`,
    let’s create a simple ZIP code lookup tool. Give the script in [Listing 7-8](ch07.xhtml#ch7ex8)
    a ZIP code, and it’ll report the city and state the code belongs to. Easy enough.
  prefs: []
  type: TYPE_NORMAL
- en: Your first instinct might be to use the official US Postal Service website,
    but we’re going to tap into a different site, *[http://city-data.com/](http://city-data.com/)*,
    which configures each ZIP code as its own web page so information is far easier
    to extract.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-8: The* `*zipcode*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***How It Works***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The URLs for ZIP code information pages on *[http://city-data.com/](http://city-data.com/)*
    are structured consistently, with the ZIP code itself as the final part of the
    URL.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This consistency makes it quite easy to create an appropriate URL for a given
    ZIP code on the fly. The resultant page has the city name in the title, conveniently
    denoted by open and close parentheses, as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Long, but pretty easy to work with!
  prefs: []
  type: TYPE_NORMAL
- en: '***Running the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The standard way to invoke the script is to specify the desired ZIP code on
    the command line. If it’s valid, the city and state will be displayed, as shown
    in [Listing 7-9](ch07.xhtml#ch7ex9).
  prefs: []
  type: TYPE_NORMAL
- en: '***The Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-9: Running the* `*zipcode*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: Since 30001 isn’t a real ZIP code, the script generates a `Page not found` error.
    That’s a bit sloppy, and we can do better.
  prefs: []
  type: TYPE_NORMAL
- en: '***Hacking the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The most obvious hack to this script would be to do something in response to
    errors other than just spew out that ugly `<title>Page not found – City-Data.com</title>`
    sequence. More useful still would be to add a `-a` flag that tells the script
    to display more information about the specified region, since *[http://city-data.com/](http://city-data.com/)*
    offers quite a bit of information beyond city names—including land area, population
    demographics, and home prices.
  prefs: []
  type: TYPE_NORMAL
- en: '**#57 Area Code Lookup**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A variation on the theme of the ZIP code lookup in [Script #56](ch07.xhtml#ch07lev1sec04)
    is an area code lookup. This one turns out to be really simple, because there
    are some very easy-to-parse web pages with area codes. The page at *[http://www.bennetyee.org/ucsd-pages/area.html](http://www.bennetyee.org/ucsd-pages/area.html)*
    is particularly easy to parse, not only because it is in tabular form but also
    because the author has identified elements with HTML attributes. For example,
    the line that defines area code 207 reads like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We’ll use this site to look up area codes in the script in [Listing 7-10](ch07.xhtml#ch7ex10).
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-10: The* `*areacode*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***How It Works***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The code in this shell script is mainly input validation, ensuring the data
    provided by the user is a valid area code. The core of the script is a `curl`
    call ➊, whose output is piped to `sed` for cleaning up and then trimmed with `cut`
    to what we want to display to the user.
  prefs: []
  type: TYPE_NORMAL
- en: '***Running the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This script takes a single argument, the area code to look up information for.
    [Listing 7-11](ch07.xhtml#ch7ex11) gives examples of the script in use.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-11: Testing the* `*areacode*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Hacking the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A simple hack would be to invert the search so that you provide a state and
    city and the script prints all of the area codes for the given city.
  prefs: []
  type: TYPE_NORMAL
- en: '**#58 Keeping Track of the Weather**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Being inside an office or server room with your nose to a terminal all day sometimes
    makes you yearn to be outside, especially when the weather is really nice. Weather
    Underground (*[http://www.wunderground.com/](http://www.wunderground.com/)*) is
    a great website, and it actually offers a free API for developers if you sign
    up for an API key. With the API key, we can write a quick shell script (shown
    in [Listing 7-12](ch07.xhtml#ch7ex12)) to tell us just how nice (or poor) the
    weather is outside. Then we can decide whether taking a quick walk is really a
    good idea.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-12: The* `*weather*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***How It Works***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this script, we use `curl` to call the Wunderground API and save the HTTP
    response data in the `weather` variable ➊. We then use the `xmllint` (easily installable
    with your favorite package manager such as `apt`, `yum`, or `brew`) utility to
    perform an XPath query on the data returned ➋. We also use an interesting syntax
    in bash when calling `xmllint` with the `<(echo $weather)` at the end. This syntax
    takes the output of the inner command and passes it to the command as a file descriptor,
    so the program thinks it’s reading a real file. After gathering all the relevant
    information from the XML returned, we print a friendly message with general weather
    stats.
  prefs: []
  type: TYPE_NORMAL
- en: '***Running the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When you invoke the script, just specify the desired ZIP code, as [Listing 7-13](ch07.xhtml#ch7ex13)
    shows. Easy enough!
  prefs: []
  type: TYPE_NORMAL
- en: '***The Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-13: Testing the* `*weather*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Hacking the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We have a secret. This script can actually take more than just ZIP codes. You
    can also specify regions in the Wunderground API, such as `CA/San_Francisco` (try
    it as an argument to the weather script!). However, this format isn’t incredibly
    user-friendly: it requires underscores instead of spaces and the slash in the
    middle. Adding the ability to ask for the state abbreviation and the city and
    then replacing any spaces with underscores if no arguments are passed would be
    a useful addition. As usual, this script could do with more error-checking code.
    What happens if you enter a four-digit ZIP code? Or a ZIP code that’s not assigned?'
  prefs: []
  type: TYPE_NORMAL
- en: '**#59 Digging Up Movie Info from IMDb**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The script in [Listing 7-14](ch07.xhtml#ch7ex14) demonstrates a more sophisticated
    way to access the internet through `lynx`, by searching the Internet Movie Database
    (*[http://www.imdb.com/](http://www.imdb.com/)*) to find films that match a specified
    pattern. IMDb assigns every movie, TV series, and even TV episode a unique numeric
    code; if the user specifies that code, this script will return a synopsis of the
    film. Otherwise, it will return a list of matching films from a title or partial
    title.
  prefs: []
  type: TYPE_NORMAL
- en: The script accesses different URLs depending on the type of query (numeric ID
    or file title) and then caches the results so it can dig through the page multiple
    times to extract different pieces of information. And it uses a lot—a *lot*!—of
    calls to `sed` and `grep`, as you’ll see.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-14: The* `*moviedata*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***How It Works***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This script builds a different URL depending on whether the command argument
    specified is a film title or an IMDb ID number. If the user specifies a title
    by ID number, the script builds the appropriate URL, downloads it, saves the `lynx`
    output to the `$tempout` file ➋, and finally calls `summarize_film()` ➊. Not too
    difficult.
  prefs: []
  type: TYPE_NORMAL
- en: 'But if the user specifies a title, then the script builds a URL for a search
    query on IMDb and saves the results page to the temp file. If IMDb can’t find
    a match, then the `<h1>` tag with `class="findHeader"` value in the returned HTML
    will say `No results`. That’s what the invocation at ➌ checks. Then the test is
    easy: if `$fail` is not zero length, the script can report that no results were
    found.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the result *is* zero length, however, that means that `$tempfile` now contains
    one or more successful search results for the user’s pattern. These results can
    all be extracted by searching for `/title/tt` as a pattern within the source,
    but there’s a caveat: IMDb doesn’t make it easy to parse the results because there
    are multiple matches to any given title link. The rest of that gnarly `sed|grep|sed`
    sequence tries to identify and remove the duplicate matches, while still retaining
    the ones that matter.'
  prefs: []
  type: TYPE_NORMAL
- en: Further, when IMDb has a match like `"Lawrence of Arabia (1962)"`, it turns
    out that the title and year are two different HTML elements on two different lines
    in the result. Ugh. We need the year, however, to differentiate films with the
    same title that were released in different years. That’s what the `awk` statement
    at ➍ does, in a tricky sort of way.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re unfamiliar with `awk`, the general format for an `awk` script is `(*condition*)
    { *action* }`. This line saves odd-numbered lines in `$title` and then, on even-numbered
    lines (the year and match type data), it outputs both the previous and the current
    line’s data as one line of output.
  prefs: []
  type: TYPE_NORMAL
- en: '***Running the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Though short, this script is quite flexible with input formats, as can be seen
    in [Listing 7-15](ch07.xhtml#ch7ex15). You can specify a film title in quotes
    or as separate words, and you can then specify the eight-digit IMDb ID value to
    select a specific match.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-15: Running the* `*moviedata*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Hacking the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The most obvious hack to this script would be to get rid of the ugly IMDb movie
    ID numbers in the output. It would be straightforward to hide the movie IDs (because
    the IDs as shown are rather unfriendly and prone to mistyping) and have the shell
    script output a simple menu with unique index values that can then be typed in
    to select a particular film.
  prefs: []
  type: TYPE_NORMAL
- en: In situations where there’s exactly one film matched (try `moviedata monsoon
    wedding`), it would be great for the script to recognize that it’s the only match,
    grab the movie number for the film, and reinvoke itself to get that data. Give
    it a whirl!
  prefs: []
  type: TYPE_NORMAL
- en: A problem with this script, as with most scripts that scrape values from a third-party
    website, is that if IMDb changes its page layout, the script will break and you’ll
    need to rebuild the script sequence. It’s a lurking bug but, with a site like
    IMDb that hasn’t changed in years, probably not a dangerous one.
  prefs: []
  type: TYPE_NORMAL
- en: '**#60 Calculating Currency Values**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the first edition of this book, currency conversion was a remarkably difficult
    task requiring two scripts: one to pull conversion rates from a financial website
    and save them in a special format and another to use that data to actually do
    the conversion—say from US dollars to Euros. In the intervening years, however,
    the web has become quite a bit more sophisticated, and there’s no reason for us
    to go through tons of work when sites like Google offer simple, script-friendly
    calculators.'
  prefs: []
  type: TYPE_NORMAL
- en: For this version of the currency conversion script, shown in [Listing 7-16](ch07.xhtml#ch7ex16),
    we’re just going to tap into the currency calculator at *[http://www.google.com/finance/converter](http://www.google.com/finance/converter)*.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-16: The* `*convertcurrency*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***How It Works***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Google Currency Converter has three parameters that are passed via the
    URL itself: the amount, the original currency, and the currency you want to convert
    to. You can see this in action in the following request to convert 100 US dollars
    into Mexican pesos.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In the most basic use case, then, the script expects the user to specify each
    of those three fields as arguments, and then passes it all to Google in the URL.
  prefs: []
  type: TYPE_NORMAL
- en: The script also has some usage messages that make it a lot easier to use. To
    see those, let’s just jump to the demonstration portion, shall we?
  prefs: []
  type: TYPE_NORMAL
- en: '***Running the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This script is designed to be easy to use, as [Listing 7-17](ch07.xhtml#ch7ex17)
    details, though a basic knowledge of at least a few countries’ currencies is beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-17: Running the* `*convertcurrency*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Hacking the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: While this web-based calculator is austere and simple to work with, the output
    could do with some cleaning up. For example, the output in [Listing 7-17](ch07.xhtml#ch7ex17)
    doesn’t entirely make sense because it expresses US dollars with four digits after
    the decimal point, even though cents only go to two digits. The correct output
    should be 84.51, or if rounded up, 84.52\. That’s something fixable in the script.
  prefs: []
  type: TYPE_NORMAL
- en: While you’re at it, validating currency abbreviations would be beneficial. And
    in a similar vein, changing those abbreviated currency codes to proper currency
    names would be a nice feature, too, so you’d know that AWG is the Aruban florin
    or that BTC is Bitcoin.
  prefs: []
  type: TYPE_NORMAL
- en: '**#61 Retrieving Bitcoin Address Information**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Bitcoin has taken the world by storm, with whole businesses built around the
    technology of the *blockchain* (which is the core of how Bitcoin works). For anyone
    who works with Bitcoin at all, getting useful information about specific Bitcoin
    addresses can be a major hassle. However, we can easily automate data gathering
    using a quick shell script, like that in [Listing 7-18](ch07.xhtml#ch7ex18).
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-18: The* `*getbtcaddr*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***How It Works***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This script automates a handful of `curl` calls to retrieve a few key pieces
    of information about a given Bitcoin address. The API available on *[http://blockchain.info/](http://blockchain.info/)*
    gives us very easy access to all kinds of Bitcoin and block-chain information.
    In fact, we don’t even need to parse the responses coming back from the API, because
    it returns only single, simple values. After making calls to retrieve the given
    address’s balance, how many BTC have been sent and received by it, and when it
    was made, we print the information to the screen for the user.
  prefs: []
  type: TYPE_NORMAL
- en: '***Running the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The script accepts only a single argument, the Bitcoin address we want information
    about. However, we should mention that a string passed in that is not a real Bitcoin
    address will simply print all 0s for the sent, received, and current balance values,
    as well as a creation date in the year 1969\. Any nonzero values are in a unit
    called *satoshis*, which is the smallest denomination of a Bitcoin (like pennies,
    but to many more decimal places).
  prefs: []
  type: TYPE_NORMAL
- en: '***The Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Running the `getbtcaddr` shell script is simple as it only takes a single argument,
    the Bitcoin address to request data about, as [Listing 7-19](ch07.xhtml#ch7ex19)
    shows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-19: Running the* `*getbtcaddr*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Hacking the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The numbers printed to the screen by default are pretty large and a bit difficult
    for most people to comprehend. The `scriptbc` script ([Script #9](ch01.xhtml#ch01lev1sec10)
    on [page 34](ch01.xhtml#page_34)) can easily be used to report in more reasonable
    units, such as whole Bitcoins. Adding a scale argument to the script would be
    an easy way for the user to get a more readable printout.'
  prefs: []
  type: TYPE_NORMAL
- en: '**#62 Tracking Changes on Web Pages**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Sometimes great inspiration comes from seeing an existing business and saying
    to yourself, “That doesn’t seem too hard.” The task of tracking changes on a website
    is a surprisingly simple way of collecting such inspirational material. The script
    in [Listing 7-20](ch07.xhtml#ch7ex20), `changetrack`, automates that task. This
    script has one interesting nuance: when it detects changes to the site, it emails
    the new web page to the user, rather than just reporting the information on the
    command line.'
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-20: The* `*changetrack*` *script*'
  prefs: []
  type: TYPE_NORMAL
- en: '***How It Works***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Given a URL and a destination email address, this script grabs the web page
    content and compares it to the content of the site from the previous check. If
    the site has changed, the new web page is emailed to the specified recipient,
    with some simple rewrites to try to keep the graphics and `href` tags working.
    These HTML rewrites starting at ➋ are worth examining.
  prefs: []
  type: TYPE_NORMAL
- en: The call to `lynx` retrieves the source of the specified web page ➋, and then
    `sed` performs three different translations. First, `SRC="` is rewritten as `SRC="baseurl/`
    ➌ to ensure that any relative pathnames of the form `SRC="logo.gif"` are rewritten
    to work properly as full pathnames with the domain name. If the domain name of
    the site is *[http://www.intuitive.com/](http://www.intuitive.com/)*, the rewritten
    HTML would be `SRC="http://www.intuitive.com/logo.gif"`. Likewise, `href` attributes
    are rewritten ➍. Then, to ensure we haven’t broken anything, the third translation
    pulls the `baseurl` back *out* of the HTML source in situations where it’s been
    erroneously added ➎. For example, `HREF="http://www.intuitive.com/http://www.somewhereelse.com/link"`
    is clearly broken and must be fixed for the link to work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice also that the recipient address is specified in the `echo` statement
    ➊ (`echo "To: $2"`) rather than as an argument to `sendmail`. This is a simple
    security trick: by having the address within the `sendmail` input stream (which
    `sendmail` knows to parse for recipients because of the `-t` flag), there’s no
    worry about users playing games with addresses like `"joe;cat /etc/passwd|mail
    larry"`. This is a good technique to use whenever you invoke `sendmail` within
    shell scripts.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Running the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This script requires two parameters: the URL of the site being tracked (and
    you’ll need to use a fully qualified URL that begins with `http://` for it to
    work properly) and the email address of the person (or comma-separated group of
    people) who should receive the updated web page, as appropriate. Or, if you’d
    prefer, just use `-` (a hyphen) as the email address, and the `diff` output will
    instead be displayed on screen.'
  prefs: []
  type: TYPE_NORMAL
- en: '***The Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The first time the script sees a web page, the page is automatically mailed
    to the specified user, as [Listing 7-21](ch07.xhtml#ch7ex21) shows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 7-21: Running the* `*changetrack*` *script for the first time*'
  prefs: []
  type: TYPE_NORMAL
- en: 'All subsequent checks on *[http://www.intuitive.com/](http://www.intuitive.com/)*
    will produce an email copy of the site only if the page has changed since the
    last invocation of the script. This change can be as simple as a single typo fix
    or as complex as a complete redesign. While this script can be used for tracking
    any website, sites that don’t change frequently will probably work best: if the
    site is the BBC News home page, checking for changes is a waste of CPU cycles
    because this site is *constantly* updated.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If a site has not changed when the script is invoked the second time, the script
    has no output and sends no email to the specified recipient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '***Hacking the Script***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An obvious deficiency in the current script is that it’s hardcoded to look for
    *http://* links, which means it will reject any HTTP web pages served over HTTPS
    with SSL. Updating the script to work with both would require some fancier regular
    expressions, but is totally possible!
  prefs: []
  type: TYPE_NORMAL
- en: Another change to make the script more useful could be to have a granularity
    option that would allow users to specify that if only one line has changed, the
    script should not consider the website updated. You could implement this by piping
    the `diff` output to `wc -l` to count lines of output changed. (Keep in mind that
    `diff` generally produces *three* lines of output for each line changed.)
  prefs: []
  type: TYPE_NORMAL
- en: This script is also more useful when invoked from a `cron` job on a daily or
    weekly basis. We have similar scripts that run every night and send us updated
    web pages from various sites that we like to track.
  prefs: []
  type: TYPE_NORMAL
- en: A particularly interesting possibility is to modify this script to work off
    a data file of URLs and email addresses, rather than requiring those as input
    parameters. Drop that modified version of the script into a `cron` job, write
    a web-based front end to the utility (similar to the shell scripts in [Chapter
    8](ch08.xhtml#ch08)), and you’ve just duplicated a function that some companies
    charge people money to use. No kidding.
  prefs: []
  type: TYPE_NORMAL
