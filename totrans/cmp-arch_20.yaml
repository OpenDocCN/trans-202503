- en: '**APPENDIX**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**附录**'
- en: '**OPERATING SYSTEM SUPPORT**'
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**操作系统支持**'
- en: '![Image](../images/f0425-01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0425-01.jpg)'
- en: We’ve avoided discussing operating systems in this book in order to see “bare
    metal” architecture more clearly. Operating systems are a distinct area of study
    with their own books. It’s common to study architecture first, then operating
    systems. However, demand from operating systems has led to several features being
    added at the architectural level, and these *do* belong in an architecture book.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书避免讨论操作系统，以便更清楚地看到“裸机”架构。操作系统是一个独立的研究领域，有专门的书籍。通常是先学习架构，再学习操作系统。然而，操作系统的需求促使架构层面加入了若干特性，而这些*确实*属于架构书的范畴。
- en: This [appendix](bm01.xhtml) is designed for you to come back to later, during
    your study of operating systems, as it covers the areas in which the two fields
    overlap. We’ll review some basic features of operating systems, then look at how
    recent architectures have developed in order to support them at the hardware level.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这个[附录](bm01.xhtml)是为你在学习操作系统时回顾的，它涵盖了两个领域交集的部分内容。我们将回顾操作系统的一些基本特性，然后看看现代架构是如何在硬件层面上支持这些特性的。
- en: Concurrency
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并发
- en: The most basic function of an operating system is to create the illusion of
    multiple user programs running simultaneously on a single CPU. The operating system
    program that does this is usually called the *kernel*. The user programs being
    run by the kernel are called *processes*.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统最基本的功能是创建多个用户程序在单个CPU上同时运行的假象。执行这一功能的操作系统程序通常被称为*内核*。由内核运行的用户程序被称为*进程*。
- en: The kernel runs each process in turn for a short period of time, before switching
    to the next one; this is called a *cycle*, and this form of execution is called
    *concurrency*. This means that processes appear to be running in parallel, but
    are actually being time-sliced, with the slices run in series. Concurrency is
    roughly the opposite of parallel computing. Parallelism usually takes many CPUs
    and uses them to execute a single program at the same time. Concurrency takes
    a single CPU and uses it to execute multiple processes at the same time.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 内核轮流运行每个进程一小段时间，然后切换到下一个进程；这种方式叫做*周期*，这种执行方式被称为*并发*。这意味着进程看起来像是并行运行的，但实际上是通过时间切片方式按顺序执行的。并发大致上是与并行计算相对的概念。并行计算通常需要多个CPU，使用它们同时执行一个程序。而并发则使用单个CPU，在同一时间内执行多个进程。
- en: The kernel typically uses architectural timers, IRQ lines, and IRQ callbacks
    to control switching between processes and kernel code itself. At startup, the
    kernel sets up a hardware timer that creates a regular IRQ to the CPU. The kernel
    also has a subroutine, which we’ll call a *callback*, that’s set up to be called
    when this IRQ appears. The kernel is given a set of processes to run. It loads
    all of them into memory, at different locations. It then jumps to the first process’s
    main subroutine, passing control to it to run as normal.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 内核通常使用架构定时器、IRQ线和IRQ回调来控制进程之间以及内核代码本身的切换。在启动时，内核设置一个硬件定时器，定期向CPU发出IRQ。内核还设有一个子程序，我们称之为*回调*，它在IRQ到达时被调用。内核被分配了一组需要运行的进程。它将所有进程加载到内存中，分别放置在不同的位置。然后，它跳转到第一个进程的主子程序，交出控制权让它正常运行。
- en: The first process will run for a while, then the timer that was previously set
    will activate an IRQ. The IRQ hardware detects this, makes a copy of the program
    counter somewhere (such as in a dedicated internal register), and then sets the
    program counter to the address of the callback.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个进程会运行一段时间，然后之前设置的定时器将触发一个IRQ。IRQ硬件会检测到这个信号，并将程序计数器的副本存储在某个地方（例如在专用的内部寄存器中），然后将程序计数器设置为回调的地址。
- en: The callback is usually programmed to first save a copy of each of the registers
    and the previously copied program counter in an area of RAM reserved for use by
    the kernel (that is, not used by any of the processes). It then decides (schedules)
    which process to run next. The simplest way to do this is for the processes to
    take turns in a fixed order. The saved register and program counter states for
    the new process are loaded into the registers and program counter. The updated
    program counter thus transfers control to the new process until the timer triggers
    the next IRQ and calls the callback again.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 回调函数通常会先在一个为内核保留的 RAM 区域内保存每个寄存器的副本以及先前保存的程序计数器（即不被任何进程使用的区域）。然后，它决定（调度）下一个要运行的进程。最简单的方法是让进程按固定顺序轮流执行。新的进程的保存寄存器和程序计数器状态将被加载到寄存器和程序计数器中。更新后的程序计数器将控制权转交给新进程，直到定时器触发下一个
    IRQ 并再次调用回调函数。
- en: Kernel Mode and User Mode
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内核模式和用户模式
- en: The kernel will work well as long as the processes can be trusted to play nicely
    with one another—that is, as long as they access only separate individual areas
    of memory. It won’t work well if processes are malicious. The obvious security
    problem is that any process could read and write to memory intended for use by
    the other processes, and by the kernel itself. This could include stealing data,
    overwriting data, or overwriting code, including overwriting kernel code to take
    full control of the machine.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 内核可以正常工作，只要进程能够相互信任——即，只要它们只访问各自独立的内存区域。如果进程存在恶意行为，系统将无法正常工作。显而易见的安全问题是，任何进程都可能读写本应由其他进程或内核使用的内存，这可能包括窃取数据、覆盖数据或覆盖代码，包括覆盖内核代码以完全控制机器。
- en: Modern CPUs prevent this at the architectural level by providing two (or more)
    *CPU modes*, called *kernel mode* and *user mode*. In kernel mode, all of the
    CPU’s features are available for the kernel to use. This includes full access
    to RAM. In user mode, restrictions are enforced that prevent access to instructions
    and memory locations outside the region of memory allocated to the user process.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现代 CPU 通过提供两种（或更多）*CPU 模式*，即*内核模式*和*用户模式*，从架构层面防止了这一点。在内核模式下，CPU 的所有特性都可以供内核使用，这包括对
    RAM 的完全访问。在用户模式下，会强制执行限制，防止访问分配给用户进程的内存区域之外的指令和内存位置。
- en: Virtual Memory
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 虚拟内存
- en: A modern operating system doesn’t allow user processes to access each other’s
    data, or the kernel’s own data. Each user process is presented by the operating
    system with a *virtual memory* space, which appears to the process as if it were
    memory in a bare metal machine, isolated from the other processes. For example,
    all processes might think they’re using memory locations 0x00000000 to 0xffffffff.
    The physical addresses of memory are thus unavailable to the user program, and
    processes are separated from one another and can’t read and write each other’s
    memory. The load and store instructions in user programs work entirely using virtual
    memory addresses.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现代操作系统不允许用户进程访问彼此的数据或内核的数据。操作系统为每个用户进程提供一个*虚拟内存*空间，这对进程来说看起来就像是裸机上的内存，与其他进程隔离。例如，所有进程可能都认为它们在使用地址
    0x00000000 到 0xffffffff 之间的内存位置。物理内存地址对用户程序来说是不可见的，进程之间是相互隔离的，无法读写彼此的内存。用户程序中的加载和存储指令完全使用虚拟内存地址。
- en: Virtual memory can also be made substantially larger than physical RAM by making
    use of *swap space* with secondary and primary memory. Here, both primary and
    secondary memories are divided into standard-sized chunks called *pages*. Caching
    is used to move whole pages between primary and secondary memory according to
    how recently they were used.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用*交换空间*，虚拟内存的大小也可以比物理 RAM 大得多，这包括使用次级和主存储器。在这里，主存和次存被划分为标准大小的块，称为*页面*。缓存被用来根据最近的使用情况在主存和次存之间移动整个页面。
- en: Unlike the hardware CPU and RAM caches we saw previously, this is a slower process
    that’s usually managed at least partly in software by the operating system. A
    hardware *memory management unit (MMU)* may be added to the architectural level
    to perform translations between physical and virtual addresses as configured by
    the operating system.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前看到的硬件 CPU 和 RAM 缓存不同，这通常是一个较慢的过程，至少部分由操作系统软件管理。硬件*内存管理单元（MMU）*可能会被添加到架构层面，以执行操作系统配置的物理地址和虚拟地址之间的转换。
- en: Different CPU and operating system combinations will use virtual memory in different
    ways. For example, a key architecture design decision is whether to use physical
    or virtual addresses in the different CPU-RAM caches.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的 CPU 和操作系统组合将以不同的方式使用虚拟内存。例如，一个关键的架构设计决策是是否在不同的 CPU-RAM 缓存中使用物理地址还是虚拟地址。
- en: A *translation lookaside buffer (TLB)* cache is a dedicated cache designed at
    an architectural level for the operating system to use to implement its virtual
    memory. It can exist as a third specialist L1 cache along with the instruction
    and data L1 caches seen in [Figure 10-12](ch10.xhtml#ch10fig12). When a user program
    mentions a virtual address, the TLB cache looks up and converts it to a physical
    address, invisible to the user. If the virtual address is missing from the TLB
    cache, the TLB then calls back to the operating system code using an IRQ, asking
    it what to do. The operating system will either find the required virtual-physical
    mapping and add it to the TLB cache, or it will give an *access violation* error—often
    known as a *segmentation fault*—if it’s not available or allowed. If you’ve ever
    run into a segmentation fault in your C code before, it arises here, when you
    try to access memory that isn’t allocated to you.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*翻译查找缓冲区（TLB）* 缓存是一个专门的缓存，它在架构级别上为操作系统提供虚拟内存实现所用的缓存。它可以作为第三个专业的 L1 缓存，与[图 10-12](ch10.xhtml#ch10fig12)中看到的指令和数据
    L1 缓存一起存在。当用户程序提到一个虚拟地址时，TLB 缓存会查找并将其转换为物理地址，用户无法看到。如果虚拟地址在 TLB 缓存中不存在，TLB 会通过中断请求（IRQ）调用操作系统代码，询问该如何处理。操作系统要么找到所需的虚拟-物理映射并将其添加到
    TLB 缓存中，要么如果该映射不存在或不允许，就会给出*访问冲突*错误——通常称为*段错误*——如果它不可用或不被允许。如果你曾经在 C 代码中遇到段错误，它就是在这里出现的，当你试图访问未分配给你的内存时。'
- en: Device Drivers
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设备驱动程序
- en: A modern operating system also doesn’t allow user processes to access I/O addresses
    directly. Instead, they must call operating system subroutines called *device
    drivers* to politely request I/O functionality, via the operating system’s API.
    As with other processes’ memory, user mode prevents processes from loading or
    storing outside their designated address space, and it will raise an exception—such
    as a segmentation fault—if this is attempted.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现代操作系统也不允许用户进程直接访问 I/O 地址。相反，它们必须调用被称为*设备驱动程序*的操作系统子程序，通过操作系统的 API 礼貌地请求 I/O
    功能。与其他进程的内存一样，用户模式会阻止进程加载或存储到其指定地址空间之外的内存，如果尝试这样做，它会引发异常——例如段错误。
- en: I/O modules and device drivers are different concepts. I/O modules are hardware
    connected to the bus. A device driver is a higher-level concept, a piece of software
    that takes sole responsibility for all communications with the I/O module or with
    one (of the many) devices connected using it; it also provides higher-level interfaces
    (such as C or C++ libraries) that wrap the memory-mapped instructions. In the
    8-bit era, these were simple programs located in ROM or loaded into RAM that were
    accessible to user programs. Today, they’re usually implemented as kernel modules
    that are accessible only to the operating system, and user programs will request
    their use via the operating system.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: I/O 模块和设备驱动程序是不同的概念。I/O 模块是连接到总线的硬件。设备驱动程序是一个更高层次的概念，是一段软件，负责与 I/O 模块或通过它连接的设备（之一）进行所有通信；它还提供更高层次的接口（如
    C 或 C++ 库），将内存映射指令进行封装。在 8 位时代，这些程序通常位于 ROM 中或加载到 RAM 中，供用户程序访问。今天，它们通常作为内核模块实现，只能由操作系统访问，用户程序通过操作系统请求它们的使用。
- en: '**ARCHITECTURAL OPERATING SYSTEM SECURITY**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**架构操作系统安全**'
- en: Studying the architectural level opens up many interesting opportunities for
    operating system security. The operating system generally tries to restrict user
    program access to most parts of the computer, but if you have access to the architectural
    level, you may be able to circumvent this. What could you do, for example, if
    you could physically control the IRQ line used by the operating system timer callback,
    by opening up your computer, attaching a wire to the IRQ pin, and applying voltages
    to it at times of your choosing?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 学习架构级别为操作系统安全打开了许多有趣的机会。操作系统通常尝试限制用户程序访问计算机的大部分部分，但如果你能够访问架构级别，你可能能够绕过这一限制。例如，如果你能物理控制操作系统定时器回调使用的
    IRQ 线路，通过打开计算机、将电线连接到 IRQ 引脚，并在你选择的时间施加电压，你能做什么呢？
- en: An ongoing security question is whether device drivers should run in kernel
    or user mode. Often they’re made part of the operating system and given full access
    to the machine, but this may be dangerous, as it enables any of the writers of
    the drivers to access your entire machine. This was considered okay in the days
    when there were just a few reputable printer manufacturers asking to install their
    own drivers from a CD in the printer box, but it’s more worrying now that there
    are many more international and untrusted hardware manufacturers in operation,
    not to mention the unbranded websites claiming to host drivers for their products.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一个持续的安全问题是设备驱动程序是否应该在内核模式或用户模式下运行。通常，它们被作为操作系统的一部分并获得对机器的完全访问权限，但这可能是危险的，因为它使得驱动程序的编写者能够访问你整个机器。这在以前只涉及少数几个声誉良好的打印机制造商，要求从打印机盒子中的CD上安装他们的驱动程序时是可以接受的，但现在问题更加严重，因为有越来越多的国际和不受信任的硬件制造商在运营，更不用提那些声称托管其产品驱动程序的无品牌网站了。
- en: Loaders
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载器
- en: 'On an 8-bit machine with no operating system, running an executable file simply
    requires copying its contents to some location in memory, then setting the program
    counter of the CPU to point to its first line. This is done by a simple program
    known as a *loader* stored in ROM. On a modern machine with an operating system,
    loaders are more complicated: the executable will be running alongside other processes
    in an area of virtual rather than real memory. A loader thus has to do some work
    to set this up and alter the executable to use virtual addresses rather than the
    physical ones the program thinks it’s using. On Linux, the loader is invoked with
    a command such as `./myexecutable`, where the `./` is technically required for
    security reasons but in practice functions as the loader command.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有操作系统的8位机器上，运行可执行文件只需将其内容复制到内存中的某个位置，然后将CPU的程序计数器设置为指向文件的第一行。这是由一个简单的程序，称为*加载器*，存储在ROM中完成的。在现代机器上有操作系统的情况下，加载器则更复杂：可执行文件将与其他进程一起运行，在虚拟内存区域中而非真实内存中运行。因此，加载器需要做一些工作来设置这一切，并修改可执行文件，使其使用虚拟地址而非程序所认为使用的物理地址。在Linux上，加载器通过类似`./myexecutable`的命令来调用，其中`./`在技术上出于安全原因是必须的，但实际上它充当了加载器命令的角色。
- en: 'Let’s try writing, loading, and running a “Hello, world!” program from inside
    an operating system. (We previously did this on the BIOS.) In particular, the
    following program is able to run inside a window system such as the X Window System
    and arrange for the text to be displayed in a terminal rather than directly lighting
    up ASCII patterns of screen pixels. It does this by calling a kernel function—rather
    than a BIOS function—to request the text display. The operating system’s loader
    assumes there’s an externally visible (`global`) label called `_start`, to which
    it jumps after loading in the code:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试从操作系统内部编写、加载和运行一个“Hello, world!”程序。（我们之前在BIOS上做过这件事。）特别是，以下程序能够在像X Window系统这样的窗口系统中运行，并安排在终端中显示文本，而不是直接点亮ASCII模式的屏幕像素。它通过调用内核函数——而不是BIOS函数——来请求文本显示。操作系统的加载器假设有一个名为`_start`的外部可见（`global`）标签，加载器加载代码后会跳转到该标签：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This code runs on 64-bit Linux only. To assemble and run, use this command:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码仅在64位Linux上运行。要进行汇编和运行，请使用以下命令：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This should write `Hello, Kernel!` to the console using only system calls.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码应该仅通过系统调用将`Hello, Kernel!`写入控制台。
- en: Linkers
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 链接器
- en: When an operating system–hosted executable calls to subroutines in other libraries,
    virtual memory addresses need to be further relocated. This is to ensure the executable
    machine code for each library is loaded into memory at a suitable location, meaning
    one that doesn’t conflict with the others. Tweaking these addresses also ensures
    the libraries can find one another. If one program or library calls a function
    in another, the address of the target subroutine needs to be changed in its executable
    machine code to the correct location where the target has actually been loaded.
    Making these tweaks is called *linking* and is performed by a *linker* program,
    usually called invisibly by the loader.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当操作系统托管的可执行文件调用其他库中的子程序时，虚拟内存地址需要进一步重新定位。这是为了确保每个库的可执行机器代码被加载到内存中的合适位置，即不与其他库发生冲突的位置。调整这些地址还确保库之间可以互相找到。如果一个程序或库调用另一个程序中的函数，则需要将目标子程序的地址更改为目标实际加载的位置。进行这些调整的过程叫做*链接*，通常由一个*链接器*程序完成，加载器通常会隐式地调用它。
- en: 'As an example of linking, here’s another way to write to the terminal, this
    time by calling the standard C library’s `printf` subroutine:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 作为链接的一个例子，这里有另一种向终端写入的方式，这次是通过调用标准C库的`printf`子程序：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: With this style, you can call any C libraries from your assembly programs, as
    long as you respect their calling conventions. Because it’s part of a C compiler
    stack, the `gcc` compiler looks for an externally visible (`global`) subroutine
    named `main`, as in C. It will create its own lower-level `_start` subroutine
    and set it to call `main`; it will also set up any structures needed by the C
    libraries.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方式，你可以从汇编程序中调用任何C库，只要你遵守它们的调用约定。因为它是C编译器栈的一部分，`gcc`编译器会寻找一个名为`main`的外部可见（`global`）子程序，和C语言中的做法一样。它会创建自己的低级`_start`子程序，并设置为调用`main`；它还会设置C库所需的任何结构。
- en: Note that because `printf` can take a variable number of arguments, we have
    to tell it how many extra arguments are used and should be expected on the stack;
    we set this number in RAX. This is standard in most x86 calling conventions for
    variable arguments.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于`printf`可以接受可变数量的参数，我们必须告诉它在栈上使用了多少个额外的参数，并预期会出现多少个参数；我们在RAX中设置这个数字。这在大多数x86调用约定中是处理可变参数的标准做法。
- en: 'To assemble, link, and run on 64-bit Linux, use this command:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要在64位Linux上汇编、链接并运行，请使用以下命令：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can see what extra code the linker has added by *disassembling*—that is,
    converting the machine code back to human-readable assembly. You can do this with
    a tool like `objdump:`
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过*反汇编*来查看链接器添加了哪些额外的代码——也就是将机器代码转换回人类可读的汇编代码。你可以使用像`objdump`这样的工具来做到这一点：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Some operating systems make use of x86 segments—or, at least, their assembler
    directives—to enforce a read-only `.text` section in the code. They typically
    allow writes in the `.data` section.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一些操作系统利用x86段——或者至少是它们的汇编指令——来强制代码中的`.text`部分为只读。它们通常允许在`.data`部分进行写操作。
- en: Extra Boot Sequence Stages
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 额外的启动序列阶段
- en: Most systems can’t boot an operating system directly at power on. Operating
    systems are responsible for loading and configuring device drivers, which aren’t
    available when the operating system still needs to be loaded. Instead, they’re
    gradually brought into being during later stages of the boot process.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数系统在开机时无法直接启动操作系统。操作系统负责加载和配置设备驱动程序，而这些驱动程序在操作系统还没有加载时并不可用。相反，它们是在启动过程的后续阶段逐步加载的。
- en: 'We met BIOS and UEFI previously in [Chapter 13](ch13.xhtml). Usually only two
    programs ever get run on your BIOS: an operating system loader and an operating
    system loader selector program, such as GRUB2 (Grand Unified Bootloader version
    2). PCBIOS runs the first such program from a specific hard disk location called
    the master boot record. UEFI now has a higher-level view of the filesystem than
    this, and it includes a specific path on the hard disk to look for and run the
    first of these programs. GRUB2 provides a text-based user interface, displaying
    a list of operating systems available on a hard disk and allowing the user to
    input their selection using their cursor and other keys. GRUB2 checks what kind
    of BIOS is available, then calls the available subroutines from that BIOS to write
    the characters on the screen and read the keyboard. When the user makes a selection,
    it loads that operating system loader and passes control to it.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第13章](ch13.xhtml)中已经介绍过BIOS和UEFI。通常，只有两个程序会在BIOS中运行：操作系统加载程序和操作系统加载程序选择器程序，比如GRUB2（GRUB版本2）。PCBIOS会从一个特定的硬盘位置，即主引导记录，运行第一个这样的程序。UEFI现在对文件系统有比这更高层次的视图，它包括一个硬盘上的特定路径，用于寻找并运行这些程序中的第一个。GRUB2提供了一个基于文本的用户界面，显示硬盘上可用的操作系统列表，并允许用户使用光标和其他按键输入他们的选择。GRUB2会检查可用的BIOS类型，然后调用该BIOS中的可用子程序来在屏幕上显示字符并读取键盘。当用户做出选择时，它会加载相应的操作系统加载程序，并将控制权交给它。
- en: The operating system loader is thus the first program that’s part of the operating
    system. It will initially rely on the BIOS libraries to access the computer, especially
    the hard disk that contains the code for the rest of the operating system. An
    operating system may have its own drivers, hopefully better than those of the
    BIOS, and it will progressively load and switch over to them. For example, BIOS
    graphics are by design low resolution so that they work on any monitor, but once
    the operating system loads it can consider the precise make and model of the monitor
    and load a new custom driver that can make use of all its features.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统加载器因此成为操作系统的第一个程序。它最初将依赖BIOS库来访问计算机，特别是硬盘，这个硬盘包含了其余操作系统的代码。操作系统可能有自己的驱动程序，最好比BIOS的驱动程序更好，并且它将逐步加载并切换到这些驱动程序。例如，BIOS图形本身分辨率较低，以便在任何显示器上都能正常工作，但一旦操作系统加载，它可以考虑显示器的具体品牌和型号，并加载一个新的定制驱动程序，以便利用显示器的所有功能。
- en: Modern boot processes have been controversial for security reasons. The boot
    process occurs before the operating system kicks in, meaning it has access to
    the entirety of the computer. UEFI keeps running in the background once the operating
    system has started, allowing the operating system to call its subroutines. But
    this means that any malicious code built into UEFI firmware could potentially
    retain access to the whole machine during regular operating system operation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现代的启动过程因安全原因而备受争议。启动过程发生在操作系统启动之前，这意味着它可以访问整个计算机。UEFI在操作系统启动后继续在后台运行，允许操作系统调用它的子程序。但这也意味着，任何嵌入UEFI固件的恶意代码都可能在正常操作系统运行期间保持对整个机器的访问权限。
- en: UEFI was designed by a committee whose members included proprietary operating
    system vendors who successfully lobbied for the introduction of a “secure boot”
    part of its standard. This allows the boot process to be locked down so that buyers
    of preinstalled machines can’t install GRUB2 and other operating systems. It’s
    possible to fix this bug in the standard if you’re able to reset the secure boot
    system itself. This is usually done by soldering two wires to the UEFI chip and
    applying a voltage to factory-reset it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: UEFI是由一个委员会设计的，委员会成员包括成功游说将“安全启动”作为标准一部分的专有操作系统供应商。这使得启动过程可以被锁定，以至于预装机器的买家无法安装GRUB2和其他操作系统。如果你能够重置安全启动系统本身，就有可能修复这个标准中的漏洞。通常这是通过将两根电线焊接到UEFI芯片上，并施加电压进行出厂重置。
- en: Since around 2008, rumors have circulated that Intel motherboards have included
    an entire additional operating system, based on MINIX3, running somewhere in the
    boot process between UEFI and the main operating system, as the “Intel Management
    Engine.” If true, these rumors would suggest a major security loophole, as this
    operating system would have full access to the entire machine, including internet
    communications and automatic update systems, which would enable Intel or others
    to push code at any time over the network to run with full read and write access
    to your computer. These rumors would also suggest that MINIX is now the most widely
    run operating system in the world—this would be somewhat ironic, as MINIX was
    created as an educational operating system, with Linux considered to be the more
    “real world” evolution of it.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 自2008年左右以来，关于英特尔主板包含一个基于MINIX3的完整操作系统的传言开始流传，这个操作系统在UEFI和主操作系统之间的启动过程中运行，被称为“英特尔管理引擎”。如果这些传言属实，那么它们暗示了一个重大的安全漏洞，因为这个操作系统将拥有对整台机器的完全访问权限，包括互联网通信和自动更新系统，这将使得英特尔或其他方能够随时通过网络推送代码，并以完全的读写权限在你的计算机上运行。这些传言还暗示，MINIX现在可能是世界上使用最广泛的操作系统——这有点讽刺，因为MINIX最初是作为一款教育操作系统创建的，而Linux则被认为是它的“现实世界”进化。
- en: Hypervisor Mode, Virtualization, and Containers
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 虚拟机监控器模式、虚拟化和容器
- en: Kernel mode is sometimes known as *supervisor mode*, the supervisor being the
    kernel that controls the switching of the processes being run. *Hypervisor mode*
    is a related but higher-level concept in which—rather than switching between multiple
    processes within an operating system—the CPU switches between multiple operating
    systems running concurrently. This concept has become especially important in
    current cloud computing, in which the many machines in a computer center are shared
    in this way to provide each user with the experience of being on a scalable group
    of machines as their root user.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 内核模式有时被称为*监控模式*，其中“监控者”是内核，它控制着正在运行的进程之间的切换。*虚拟监控器模式*是一个相关但更高级的概念，在该模式下，CPU不是在操作系统内部切换多个进程，而是在多个操作系统之间切换，这些操作系统并行运行。这个概念在当前的云计算中尤为重要，因为计算机中心中的众多机器就是以这种方式共享的，旨在为每个用户提供类似于根用户操作可扩展机器组的体验。
- en: 'Similar operating system sharing can also be achieved using software only:
    there are programs that emulate or simulate virtual machines. However, these incur
    performance hits, while hypervisors don’t. With a hypervisor, each operating system
    really is running directly on the hardware. Dedicated hypervisor architecture
    is used to manage the swapping of state in and out of the hardware, in a similar
    style to how a software supervisor swaps processes in and out of execution. Some
    virtual machine programs, such as the VirtualBox program used in [Chapter 13](ch13.xhtml),
    can make use of the hypervisor to run their virtual machines on hypervised processors.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 相似的操作系统共享也可以仅通过软件实现：有些程序能够模拟或仿真虚拟机。然而，这样做会带来性能损失，而虚拟监控器则不会。有了虚拟监控器，每个操作系统实际上是直接运行在硬件上的。专用的虚拟监控器架构被用来管理硬件状态的进出交换，类似于软件监控器如何在执行中交换进程。一些虚拟机程序，比如[第13章](ch13.xhtml)中使用的VirtualBox程序，可以利用虚拟监控器在虚拟化处理器上运行其虚拟机。
- en: '*Containerization* is an alternative to virtualization. Rather than creating
    a set of completely isolated virtual machines, it works together with additional
    software to create the *appearance* of many such machines, while having them all
    actually share a single operating system and other components such as software
    libraries. (This is arguably what operating systems were intended to do in the
    first place. But unlike operating systems, containers enable different users to
    experience different installations and versions of the system, libraries, and
    installed software.) This is a lighter-weight solution than virtual machines,
    and it can enable thousands of containers to run together, for different users,
    on a single computer. Containerization is especially useful for cloud computing,
    in which thousands of users want to run isolated programs and providers want to
    minimize costs by having them share a single physical machine.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*容器化*是虚拟化的替代方案。它并不是创建一套完全隔离的虚拟机，而是与额外的软件一起工作，创建出许多虚拟机的*外观*，同时让它们实际共享一个操作系统和其他组件，例如软件库。（这可以说是操作系统最初的设计目的。但与操作系统不同的是，容器能够让不同用户体验系统、库和已安装软件的不同安装和版本。）这是比虚拟机更轻量的解决方案，它可以让成千上万的容器在一台计算机上为不同的用户一起运行。容器化在云计算中特别有用，因为在云计算中，成千上万的用户希望运行隔离的程序，而服务提供商则希望通过让这些程序共享一台物理机器来最小化成本。'
- en: Real-Time Operating Systems
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实时操作系统
- en: Most embedded systems run just a single small, simple program, so they have
    no need for an operating system. However, as the needs of some embedded systems
    grow in complexity, it’s becoming easier and more common to program them as multiple
    processes. At this stage it can make sense to start running a small operating
    system on the embedded system, to manage these multiple processes.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数嵌入式系统只运行一个小而简单的程序，因此不需要操作系统。然而，随着某些嵌入式系统需求的复杂化，将它们编程为多个进程变得更加容易和常见。在这个阶段，开始在嵌入式系统上运行一个小型操作系统来管理这些多个进程是有意义的。
- en: Embedded environments typically have special requirements for an operating system,
    most commonly the need for what’s called *hard real time*. Regular operating systems
    may switch between processes in a way that, from the programs’ point of view,
    seems random; their device drivers will often use buffering and interrupts to
    read and write data also at apparently random times. Such behaviors would be catastrophic
    for, say, a precision industrial robot controller, working in microseconds and
    micrometers, as they would interfere with its required level of precision motion
    in the real world. A hard real-time operating system (RTOS)—such as SMX, QNX,
    FreeRTOS, or Zephyr—is an operating system specifically designed from the ground
    up to absolutely guarantee the timing of such tasks. This requires different approaches
    to scheduling and I/O. Typically, an embedded microcontroller is a much lower-power
    machine than a desktop, so operating system design requirements must also include
    low computational overheads.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入式环境通常对操作系统有特殊要求，最常见的是对所谓的*硬实时*的需求。普通操作系统可能会以一种看似随机的方式在进程之间切换；它们的设备驱动程序通常也会使用缓冲和中断来读取和写入数据，这些操作看起来也像是随机的。这样的行为对于比如说精密工业机器人控制器来说是灾难性的，因为它们需要在微秒和微米级别的精度下工作，这些行为会干扰其在现实世界中的精确运动要求。硬实时操作系统（RTOS）——例如SMX、QNX、FreeRTOS或Zephyr——是专门从头开始设计的操作系统，旨在绝对保证此类任务的时间精度。这要求在调度和I/O方面采取不同的方法。通常，嵌入式微控制器的功耗远低于桌面计算机，因此操作系统设计要求还必须包括低计算开销。
- en: To be used in safety-critical environments, an RTOS, like the microcontroller
    it runs on, will typically go through an expensive and rigorous safety-assurance
    process based on either extensive testing or, in the most hardcore cases, formal
    specification and verification, using mathematics and logic to prove it will always
    work under various assumptions.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在安全关键的环境中使用，像微控制器一样运行的RTOS通常会经历一个昂贵且严格的安全保障过程，该过程要么依赖于广泛的测试，要么在最严格的情况下，依靠形式化规范和验证，使用数学和逻辑来证明其在各种假设下都能始终可靠运行。
- en: RTOSes are distinguished from *soft* real-time operating systems, such as variants
    of Linux modified for tasks like computer audio production. In these systems,
    real time is desirable but not strictly necessary—it won’t, say, explode a nuclear
    power station if it can’t be absolutely guaranteed every time—and so occasional
    slips are tolerated.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: RTOS与*软*实时操作系统有所区别，后者如为计算机音频制作任务修改过的Linux变种。在这些系统中，实时性是理想的，但并非绝对必要——如果不能每次都绝对保证，譬如说，它不会让核电站爆炸——因此偶尔的延迟是可以容忍的。
- en: Speculative Execution Vulnerabilities
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 投机执行漏洞
- en: In our study of architecture, we’ve seen that your computer takes your program
    and converts it to thousands of different instructions, messes with the order
    these instructions are run in, tries to execute parts of multiple instructions
    at once, passes incomplete results between instructions, and secretly updates
    its microcode to execute in new ways.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们对架构的研究中，我们发现计算机会将程序转换为成千上万条不同的指令，混乱地调整这些指令执行的顺序，尝试同时执行多个指令的部分内容，在指令之间传递不完整的结果，并秘密地更新其微代码以采用新的执行方式。
- en: Each of these behaviors, and the interactions between them, creates enormous
    complexity in chip design and function. The resulting chip designs are thus some
    of the most complex systems known to humanity, with no individual human able to
    fully understand everything taking place in a CPU. It’s natural to ask whether
    we can thus be confident that our CPU designs are safe and secure when there are
    so many parts that could go wrong.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这些行为及其相互作用在芯片设计和功能上产生了巨大的复杂性。由此产生的芯片设计是人类已知的最复杂系统之一，没有任何个人能够完全理解CPU中发生的所有事情。提出一个问题是很自然的——在如此多可能出错的部分下，我们能否确信我们的CPU设计是安全且可靠的？
- en: The answer to this question was recently found to be “no”—this is why we now
    have *speculative execution* vulnerabilities, architecture bugs that can enable
    a process to read the data belonging to another process, such as passwords and
    bank details. In most cases, this includes the ability for hyper-vised systems
    belonging to different users on physical cloud machines to spy on one another.
    This has been considered a catastrophic security threat to many manufacturers;
    some consider it the most serious hardware problem of all time. Software patches
    for the vulnerabilities cause a 5 to 30 percent slowdown in performance, while
    architects are currently working to redesign hardware to avoid them in their next-generation
    processors.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最近发现这个问题的答案是“否”——这就是为什么我们现在有了*推测执行*漏洞，架构错误可能允许一个进程读取属于另一个进程的数据，如密码和银行信息。在大多数情况下，这包括不同用户在物理云机器上运行的虚拟化系统相互间窃听的能力。这被许多制造商认为是灾难性的安全威胁；一些人认为它是有史以来最严重的硬件问题。针对这些漏洞的软件补丁会导致性能降低5%到30%，而架构师目前正在努力重新设计硬件，以避免在下一代处理器中出现这些问题。
- en: Speculative execution vulnerabilities were first discovered in 2018 as bugs
    called Spectre and Meltdown, and new variants continue to be found at the time
    of writing. To give a basic understanding of this large class of bugs, we’ll examine
    the Meltdown variant here.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 推测执行漏洞首次在2018年被发现，作为名为Spectre和Meltdown的错误，新的变种在撰写本文时仍在不断被发现。为了基本了解这一类大量的漏洞，我们将在这里讨论Meltdown变种。
- en: 'Meltdown is caused by a complex unintended interaction between multiple modern
    architectural features: speculative execution, virtual memory, CPU kernel mode
    switching, cache timing effects, and a race condition in indirect addressing.
    Suppose the target process is running alongside our own process under an operating
    system. The operating system defines separate areas of memory for the two processes
    and restricts each process’s access to only its own memory space. The memory spaces
    look like this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Meltdown是由多个现代架构特性之间复杂的意外交互引起的：推测执行、虚拟内存、CPU内核模式切换、缓存时间效应以及间接寻址中的竞态条件。假设目标进程与我们自己的进程在操作系统下同时运行。操作系统为两个进程定义了独立的内存区域，并限制每个进程只能访问自己的内存空间。内存空间如下所示：
- en: '| **Address** | **Data** |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| **地址** | **数据** |'
- en: '| --- | --- |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 |  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 1 |  |'
- en: '| 2 |  |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 2 |  |'
- en: '| 3=BASE |  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 3=基础 |  |'
- en: '| 4=TEST1 | FOO |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 4=测试1 | FOO |'
- en: '| 5=TEST2 | FOO |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 5=测试2 | FOO |'
- en: '| 6=TEST3 | FOO |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 6=测试3 | FOO |'
- en: '| **Address** | **Target’s Data** |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| **地址** | **目标数据** |'
- en: '| --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 7 |  |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 7 |  |'
- en: '| 8=TARGET | PASSWORD |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 8=目标 | 密码 |'
- en: '| 9 |  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 9 |  |'
- en: '| 10 |  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 10 |  |'
- en: '| 11 |  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 11 |  |'
- en: '| 6 |  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 6 |  |'
- en: Here, we assume we have access to the source code of the target program that
    tells us where the user password will be stored in its memory, so the contents
    of address `TARGET`, written as `*TARGET`, is `PASSWORD`, which we’ll assume is
    known in advance to be an integer from 1 to 3\. We want to read this password
    from our own process. Our own process’s address space contains a series of addresses
    marked `TEST1`, `TEST2`, and `TEST3`. We can store any dummy data at these locations,
    marked as `FOO`. We’ll be reading this data as part of our attack, but we don’t
    actually care what its values are. Let’s call the address just before these `BASE`,
    because it will act as a base address from which we can use offsets to refer to
    each of the `TEST` addresses.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们假设我们可以访问目标程序的源代码，这样我们就知道用户密码会存储在它的内存中的位置，因此`TARGET`地址的内容，即`*TARGET`，是`PASSWORD`，我们假设它已知并且是一个从1到3之间的整数。我们想从我们自己的进程中读取这个密码。我们自己进程的地址空间包含一系列标记为`TEST1`、`TEST2`和`TEST3`的地址。我们可以在这些位置存储任何虚拟数据，标记为`FOO`。我们将读取这些数据作为攻击的一部分，但我们其实并不关心它们的具体值。我们将把这些地址前面的地址称为`BASE`，因为它将作为基地址，我们可以使用偏移量来引用每个`TEST`地址。
- en: 'To attack, we first execute an indirect offset addressing instruction together
    with a conditional:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行攻击，我们首先执行一个间接偏移寻址指令，并带有一个条件：
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Although the semantics of `if (0)` mean that the condition will never be true—meaning
    the `LOAD BASE+(*TARGET)` won’t be completely performed in the program—eager execution
    (as in [Chapter 8](ch08.xhtml)) initially begins to run both branches at the same
    time. When it does this, `BASE+(*TARGET)` will be evaluated, giving an address
    that must be one of 4, 5, or 6\. The content of the data at this address (one
    of the three `FOO` items) will then be loaded into cache. (The `FOO` from address
    1 is also loaded to cache from the other side of the branch.) While this is happening,
    the condition is tested and found to be false. At this point the `LOAD BASE+(*TARGET)`
    instruction is aborted, but its value has already been loaded into cache even
    though it won’t be used any further.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管`if (0)`的语义意味着条件永远不会为真——这意味着`LOAD BASE+(*TARGET)`在程序中不会完全执行——但急切执行（如在[第8章](ch08.xhtml)中）最初会同时运行两个分支。当它这样做时，`BASE+(*TARGET)`将被评估，得到的地址必须是4、5或6之一。这个地址上的数据内容（其中之一为三个`FOO`项）将被加载到缓存中。（地址1的`FOO`也从分支的另一侧加载到缓存。）在此过程中，条件被测试并发现为假。此时，`LOAD
    BASE+(*TARGET)`指令被中止，但其值已经被加载到缓存中，尽管之后不会再被使用。
- en: Note that if the condition were true instead of false, the `LOAD BASE+(*TARGET)`
    would then attempt to complete and at that point, and only at that point, a security
    exception would occur as the `TARGET` address is tested for security and found
    to lie in another process’s address space. But because the condition is actually
    false, this test is never performed.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果条件为真而非假，那么`LOAD BASE+(*TARGET)`将尝试完成，此时且仅此时，会发生安全异常，因为`TARGET`地址会被测试安全性，并发现它位于另一个进程的地址空间中。但因为条件实际上是假的，所以这个测试从未执行。
- en: 'Once the value is loaded into the cache, we run a cache timing attack:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦值被加载到缓存中，我们就进行缓存计时攻击：
- en: '[PRE6]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: All three of the instructions in the loop succeed, loading the three `FOO` values
    into registers from their three memory locations. But if we time each of these
    three `LOAD`s, we’ll find that one of them is faster than the others because it
    was cached during the speculative execution. If `PASSWORD=i`, then `LOAD BASE+i`
    is fast, because (`BASE+i`) was cached. Measuring these times and finding the
    fast one reveals the value of `i`, which is equal to `PASSWORD`, as required.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 循环中的三个指令都成功执行，将三个`FOO`值从它们的三个内存位置加载到寄存器中。但是如果我们为这三个`LOAD`操作计时，会发现其中一个比其他的更快，因为它在猜测执行期间被缓存了。如果`PASSWORD=i`，那么`LOAD
    BASE+i`会很快，因为（`BASE+i`）已被缓存。通过测量这些时间并找出最快的一个，可以揭示出`i`的值，它等于`PASSWORD`，这是所需要的。
- en: The Meltdown vulnerability existed undetected in almost all major commercial
    CPUs for 20 years! It may have been known and exploited by secret state actors
    during this time, but it hasn’t yet been exploited by any other malware as far
    as we know.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Meltdown漏洞在几乎所有主要商业CPU中存在了20年而未被发现！在此期间，可能有秘密的国家行为者知道并利用了这一漏洞，但据我们所知，尚未被任何其他恶意软件利用。
- en: The public disclosure sequence of Meltdown in 2017 was a model of how ethical
    security bug disclosure can and should work. Following public discovery by security
    researchers, the manufacturers were first informed in secret. Researchers, CPU
    manufacturers, and operating system programmers then worked together to patch
    the bug at the operating system software level for all major operating systems.
    These operating systems were updated in the field by pushing automatic updates
    to users.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Meltdown的公开披露过程是2017年一个关于道德安全漏洞披露的典范。在安全研究人员公开发现之后，制造商首先被秘密通知。研究人员、CPU制造商和操作系统程序员随后合作，在操作系统软件层面为所有主要操作系统修补了该漏洞。这些操作系统通过向用户推送自动更新，在现场完成了更新。
- en: The operating system level software patch is called KAISER. Here, the operating
    system randomizes process memory locations to prevent a Meltdown attack from knowing
    which addresses to search for target data. This is still not completely secure
    but makes the bug much harder to exploit. After user machines had been patched
    with KAISER, the discoverers of Meltdown published their findings in 2018, first
    immediately on the pre-print arXiv server, then submitted for formal academic
    peer review, which completed and published in 2020.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统级别的软件补丁叫做KAISER。在这里，操作系统随机化进程的内存位置，以防止Meltdown攻击知道要搜索哪些地址来寻找目标数据。这仍然不是完全安全的，但使得该漏洞更难被利用。在用户计算机安装了KAISER补丁之后，Meltdown的发现者在2018年发布了他们的研究成果，首先是在arXiv服务器上的预印本发布，然后提交进行正式的学术同行评审，最终在2020年完成并发表。
- en: CISC processors are constructed using microcode that enables their hardware
    to be “rewired” to some extent by CPU firmware updates; this provides a stronger
    fix for CISC users. Pushing microcode updates is a more difficult and dangerous
    procedure than patching operating system software, and developing hardware patches
    also takes longer, in part because of the extensive testing required before allowing
    a patch to be pushed out. The cost of “bricking” millions of users’ processors
    is higher than damaging their operating system, which could be more easily reinstalled
    in the event of a bad update. Microcode patch development thus continued after
    publication of the Meltdown paper and was later pushed out as firmware updates
    for CISC users.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: The new microcode adds logic to clear cache following all speculative executions,
    removing the vulnerability. However, this has a cost of a significant performance
    hit, typically producing a 5 to 30 percent slowdown. Pushing such a performance
    hit onto users—usually automatically, without telling or asking them—led to some
    lively debate, especially between the operating system programmers whose work
    on software-level patches was being replaced by the microcode patches.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, CPU architects are working to redesign their basic architectures
    to fix Meltdown properly at the hardware level. In 2022, some of these fixes for
    Meltdown were reported by researchers to have introduced a new speculative execution
    bug, which they named Retbleed. This may become an ongoing game of whack-a-mole,
    providing employment for architects for many years to come.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**A 6502 Kernel**'
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Read the assembly code for Joachim Deboy’s minimal 6502 kernel at *[http://6502.org/source/kernels/minikernel.txt](http://6502.org/source/kernels/minikernel.txt)*.
    Explain where the IRQs, saves, and restores occur. Try to make an x86 or RISC-V
    version of the same idea.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '**Speculative Execution Vulnerability Audit**'
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Find out if and how your own computer has been patched for speculative execution
    vulnerabilities. For Linux, `lscpu` may show some relevant information.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The definitive textbook on operating systems is Andrew Tanenbaum and Herbert
    Bos, *Modern Operating Systems*, 4th ed. (Hoboken: Pearson, 2014).'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a list of all the subroutines Linux provides for you to call from your x86
    code, see R.A. Chapman, “Linux System Calls for x86,” *[https://blog.rchapman.org/posts/Linux_System_Call_Table_for_x86_64/](https://blog.rchapman.org/posts/Linux_System_Call_Table_for_x86_64/)*.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For more on the Meltdown vulnerability, see M. Lipp et al., “Meltdown: Reading
    Kernel Memory from User Space,” *Communications of the ACM* 63, no. 6 (2020):
    46–56.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
