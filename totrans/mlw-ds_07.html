<html><head></head><body>
<h2 class="h2" id="ch07"><span epub:type="pagebreak" id="page_119"/><strong><span class="big">7</span></strong><br/><strong>EVALUATING MALWARE DETECTION SYSTEMS</strong></h2>
<div class="image1"><img alt="image" src="../images/common01.jpg"/></div>
<p class="noindent">In the previous chapter, you learned how machine learning can help you build malware detectors. In this chapter, you learn the basic concepts necessary to predict how malware detection systems will perform. The ideas you learn here will prove crucial in improving any malware detection system you build, because without a way to measure your system’s performance, you will not know how to improve it. Please note that while this chapter is dedicated to introducing basic evaluation concepts, <a href="ch08.xhtml#ch08">Chapter 8</a> continues this thread, introducing essential evaluation concepts like cross-validation.</p>
<p class="indent">First, I introduce the basic ideas behind detection accuracy evaluation, and then I introduce more advanced ideas concerning the environment in which you deploy your system when evaluating its performance. To do this, I walk you through an evaluation of a hypothetical malware detection system.</p>
<h3 class="h3" id="lev114"><span epub:type="pagebreak" id="page_120"/><strong>Four Possible Detection Outcomes</strong></h3>
<p class="noindent">Suppose you run a malware detection system on a software binary and get the system’s “opinion” about whether the binary is malicious or benign. As illustrated in <a href="ch07.xhtml#ch07fig1">Figure 7-1</a>, four possible outcomes may occur.</p>
<div class="image"><a id="ch07fig1"/><img alt="image" src="../images/f0120-01.jpg"/></div>
<p class="figcap"><em>Figure 7-1: The four possible detection outcomes</em></p>
<p class="indent">These outcomes can be defined as follows:</p>
<p class="hang"><strong>True positive</strong> The binary is malware and the system says it is malware.</p>
<p class="hang"><strong>False negative</strong> The binary is malware and the system says it’s not malware.</p>
<p class="hang"><strong>False positive</strong> The binary is not malware and the system says it is malware.</p>
<p class="hang"><strong>True negative</strong> The binary is not malware and the system says it’s not malware.</p>
<p class="indentt">As you can see, there are two scenarios in which your malware detection system can produce inaccurate results: false negatives and false positives. In practice, true positive and true negative results are what we desire, but they are often difficult to obtain.</p>
<p class="indent">You’ll see these terms used throughout this chapter. In fact, most of detection evaluation theory is built on this simple vocabulary.</p>
<h4 class="h4" id="lev115"><strong><em>True and False Positive Rates</em></strong></h4>
<p class="noindent">Now suppose you want to test the detection system’s accuracy using a set of benignware and malware. You can run the detector on each binary and keep count of which of the four possible outcomes the detector gives you over the entire test set. At this point, you need some summary statistics to give you an overall sense of the system’s accuracy (that is, how likely it is that your system will generate false positives or false negatives).</p>
<p class="indent"><span epub:type="pagebreak" id="page_121"/>One such summary statistic is the <em>true positive rate</em> of the detection system, which you can calculate by dividing the number of true positives on your test set by the total number of malware samples in your test set. Because this calculates the percentage of malware samples your system is able to detect, it measures your system’s ability to recognize malware when it “sees” malware.</p>
<p class="indent">However, simply knowing that your detection system will raise alarms when it sees malware is insufficient to evaluate its accuracy. For example, if you only used the true positive rate as an evaluation criterion, a simple function that says “yes, this is malware” on all files would yield a perfect true positive rate. The real test of a detection system is whether or not it says “yes, this is malware” when it sees malware and “no, this is not malware” when it sees benignware.</p>
<p class="indent">To measure a system’s ability to discern whether something is not malware, you also need to measure the system’s <em>false positive rate</em>, which is the rate at which your system issues a malware alarm when it sees benignware. You can calculate your system’s false positive rate by dividing the number of benign samples the system flags as malware by the total number of benign samples tested.</p>
<h4 class="h4" id="lev116"><strong><em>Relationship Between True and False Positive Rates</em></strong></h4>
<p class="noindent">When designing a detection system, you want to keep the false positive rate as low as possible while keeping the true positive rate as high as possible. Unless you build a truly perfect malware detection system that is always right (which is really an impossibility given the evolving nature of malware), there will always be tension between the desire for a high true positive and the desire for a low false positive rate.</p>
<p class="indent">To see why this is the case, imagine a detection system that, before deciding whether or not a binary is malware, adds up all the evidence that the binary is malware to create a <em>suspiciousness score</em> for the binary. Let’s call this hypothetical suspiciousness-score-generating system MalDetect. <a href="ch07.xhtml#ch07fig2">Figure 7-2</a> shows an example of the values that MalDetect might output for 12 sample binaries, where the circles represent individual software binaries. The further to the right a binary, the higher the suspiciousness score given by MalDetect.</p>
<div class="image"><a id="ch07fig2"/><img alt="image" src="../images/f0121-01.jpg"/></div>
<p class="figcap"><em>Figure 7-2: Suspiciousness scores output by the hypothetical MalDetect system for individual software binaries</em></p>
<p class="indent">Suspiciousness scores are informative, but in order to calculate MalDetect’s true positive rate and false positive rate on our files, we <span epub:type="pagebreak" id="page_122"/>need to convert MalDetect’s suspiciousness scores to “yes” or “no” answers regarding whether or not a given software binary is malicious. To do this, we use a threshold rule. For example, we decide that if the suspiciousness score is greater or equal to some number, the binary in question raises a malware alarm. If the score is lower than the threshold, it doesn’t.</p>
<p class="indent">Such a threshold rule is the standard way to convert a suspiciousness score into a binary detection choice, but where should we set the threshold? The problem is that there is no right answer. <a href="ch07.xhtml#ch07fig3">Figure 7-3</a> shows the conundrum: the higher we set the threshold, the less likely we are to get false positives, but the more likely we are to get false negatives.</p>
<div class="image"><a id="ch07fig3"/><img alt="image" src="../images/f0122-01.jpg"/></div>
<p class="figcap"><em>Figure 7-3: An illustration of the relationship between false positive rate and true positive rate when deciding on a threshold value</em></p>
<p class="indent">For example, let’s consider the leftmost threshold shown in <a href="ch07.xhtml#ch07fig3">Figure 7-3</a>, where binaries to the left of the threshold are classified as benign and binaries to its right are classified as malware. Because this threshold is low, we get a great true positive rate (classifying 100 percent of the malware samples correctly) but a terrible false positive rate (falsely classifying 33 percent of the benign samples as malicious).</p>
<p class="indent">Our intuition might be to increase the threshold so that only samples with a higher suspiciousness score are deemed to be malware. Such a solution is given by the middle threshold in <a href="ch07.xhtml#ch07fig3">Figure 7-3</a>. Here, the false positive rate drops to 0.17, but unfortunately the true positive rate drops as well, to 0.83. If we continue to move the threshold to the right, as shown by the rightmost threshold, we eliminate any false positives, but detect only 50 percent of the malware.</p>
<p class="indent">As you can see, there is no such thing as a perfect threshold. A detection threshold that yields a low false positive rate (good) will tend to miss more malware, yielding a low true positive rate (bad). Conversely, using a detection threshold that has a high true positive rate (good) will also increase the false positive rate (bad).</p>
<h4 class="h4" id="lev117"><span epub:type="pagebreak" id="page_123"/><strong><em>ROC Curves</em></strong></h4>
<p class="noindent">The tradeoff between the true positive rate and false positive rate of detection systems is a universal problem for all detectors, not just malware detectors. Engineers and statisticians have thought long and hard about this phenomenon and come up with the <em>Receiver Operating Characteristic (ROC)</em> curve to describe and analyze it.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>If you’re confused by the phrase Receiver Operating Characteristic, don’t worry about it—this phrase</em> is <em>confusing and pertains to the context in which ROC curves were originally developed, which is radar-based detection of physical objects.</em></p>
</div>
<p class="indent">ROC curves characterize a detection system by plotting false positive rates against their associated true positive rates at various threshold settings. This helps us evaluate the tradeoff between lower false positive rates and higher true positive rates, and in doing so determine the “best” threshold for our situation.</p>
<p class="indent">For example, for our hypothetical MalDetect system from <a href="ch07.xhtml#ch07fig3">Figure 7-3</a>, the system’s true positive rate is 0.5 when its false positive rate is 0 (low threshold), and the system’s true positive rate is 1.00 when the false positive rate is 0.33 (high threshold).</p>
<p class="indent"><a href="ch07.xhtml#ch07fig4">Figure 7-4</a> shows how this works in more detail.</p>
<div class="image"><a id="ch07fig4"/><img alt="image" src="../images/f0123-01.jpg"/></div>
<p class="figcap"><em>Figure 7-4: An illustration of what ROC curves mean and how they are constructed</em></p>
<p class="indent">To build the ROC curve, we start with the three thresholds used in <a href="ch07.xhtml#ch07fig3">Figure 7-3</a> and plot their resulting false and true positive rates, shown in the left half of <a href="ch07.xhtml#ch07fig3">Figure 7-3</a>. The plot on the right of <a href="ch07.xhtml#ch07fig4">Figure 7-4</a> shows the same thing, but for all possible thresholds. As you can see, the higher the false positive rates, the higher the true positive rates. Similarly, the lower the false positive rates, the lower the true positive rates.</p>
<p class="indent"><span epub:type="pagebreak" id="page_124"/>The “curve” of the ROC curve is a line within the two-dimensional ROC plot that represents how we think our detection system will do on its true positive rate over all possible false positive values, and how we think our detection system will do on its false positive rate over all possible true positive values. There are multiple ways of generating such a curve, but that goes beyond the scope of this book.</p>
<p class="indent">One simple method, however, is to try many threshold values, observe the corresponding false and true positive rates, plot them, and connect the dots using a line. This connected line, shown in the right plot of <a href="ch07.xhtml#ch07fig4">Figure 7-4</a>, becomes our ROC curve.</p>
<h3 class="h3" id="lev118"><strong>Considering Base Rates in Your Evaluation</strong></h3>
<p class="noindent">As you’ve seen, ROC curves can tell you how your system will perform in terms of the rate at which it calls malicious binaries malicious (true positive rate) and the rate at which it calls benign binaries malicious (false positive rate). However, ROC curves will not tell you the <em>percentage</em> of your system’s alarms that will be true positives, which we call the <em>precision</em> of the system. The precision of a system is related to the percentage of binaries the system encounters that are actually malware, which we call the <em>base rate</em>. Here’s a breakdown of each term:</p>
<p class="hang"><strong>Precision</strong> The percentage of system detection alarms that are true positives (meaning that they are detections of actual malware). In other words, <em>precision</em> is the detection system’s number of <em>true positives / (true positives + false positives)</em> when tested against some set of binaries.</p>
<p class="hang"><strong>Base rate</strong> The percentage of the data fed to the system that has the quality we are looking for. In our case, <em>base rate</em> refers to the percentage of binaries that are <em>actually malware</em>.</p>
<p class="indent">We discuss how these two metrics are related in the next section.</p>
<h4 class="h4" id="lev119"><strong><em>How Base Rate Affects Precision</em></strong></h4>
<p class="noindent">Although a detection system’s true and false positive rates do not change when the base rate changes, the system’s precision is affected by changes in the malware base rate—often dramatically. To see why this is true, let’s consider the following two cases.</p>
<p class="indent">Suppose the false positive rate of MalDetect is 1 percent and the true positive rate is 100 percent. Now suppose we set MalDetect loose on a network that we know upfront has no malware on it (perhaps the network has just been created from scratch in a laboratory). Because we know in advance there is no malware on the network, every alarm the MalDetect throws will by definition be a false positive, because the only binaries that MalDetect encounters will be benignware. In other words, precision will be 0 percent.</p>
<p class="indent">In contrast, if we run MalDetect on a dataset composed of entirely malware, none of its alarms will ever be false positives: there simply will <span epub:type="pagebreak" id="page_125"/>never be an opportunity for MalDetect to generate a false positive since there is no benignware in the software dataset. Therefore, precision will be 100 percent.</p>
<p class="indent">In both of these extreme cases, the base rates have a huge impact on MalDetect’s precision, or the probability that its alarm is a false positive.</p>
<h4 class="h4" id="lev120"><strong><em>Estimating Precision in a Deployment Environment</em></strong></h4>
<p class="noindent">You now know that depending on the proportion of malware in a test dataset (base rate), your system will yield very different precision values. What if you want to estimate the precision your system will have based on an estimate of the base rate of the environment in which you deploy it? All you have to do is use your deployment environment’s estimated base rate to estimate the variables in the precision formula: <em>true positives / (true positives + false positives)</em>. You’ll need three numbers:</p>
<ul>
<li class="noindent"><strong>True positive rate (TPR)</strong> of the system, or the percentage of malware samples the system will correctly detect</li>
<li class="noindent"><strong>False positive rate (FPR)</strong> of the system, or the percentage of benign samples the system will incorrectly alarm on</li>
<li class="noindent"><strong>Base rate (BR)</strong> of the binaries against which you will use the system (for example, the percentage of binaries downloaded from piracy sites you expect will be malware, if this is what you’ll be using your system on)</li>
</ul>
<p class="indent">The numerator of the precision equation—the number of true positives—can be estimates by <em>true positive rate × base rate</em>, giving you the percentage of malware your system will correctly detect. Similarly, the denominator of the equation—that is, <em>(true positives + false positives)</em>—can be estimated by <em>true positive rate × base rate + false positive rate × (1 – base rate)</em>, giving you the percentage of <em>all</em> binaries the system will alarm on by calculating the number of malware binaries that will be detected correctly plus the fraction of benignware binaries for which false positives will be issued.</p>
<p class="indent">In sum, you calculate the expected precision of your system as follows:</p>
<div class="imagec"><img alt="image" src="../images/f0125-01.jpg"/></div>
<p class="indent">Let’s consider another example to see how base rate can have a profound impact on the performance of a detection system. For example, suppose we have a detection system that has an 80 percent true positive rate and a 10 percent false positive rate, and 50 percent of the software binaries we run it against are expected to be malware. This would lead to an expected precision of 89 percent. But when the base rate is 10 percent, our precision drops to 47 percent.</p>
<p class="indent">What happens if our base rate is very low? For example, in a modern enterprise network, very few software binaries are actually malware. Using our precision equation, if we assume a base rate of 1 percent (1 in 100 binaries are malware), we get a precision of about 7.5 percent, which <span epub:type="pagebreak" id="page_126"/>means that 92.5 percent of our system’s alarms would be false positives! And if we assume a base rate of 0.1 percent (1 in 1000 binaries are likely to be malware), we get a precision of 1 percent, meaning 99 percent of our system’s alarms would be false positives! Finally, at a base rate of 0.01 percent (1 in 10,000 binaries are likely to be malware—probably the most realistic assumption on an enterprise network), our expected precision drops to 0.1 percent, meaning the overwhelming majority of our system’s alerts will be false positives.</p>
<p class="indent">One takeaway from this analysis is that detection systems that have high false positive rates will almost never be useful in enterprise settings, because their precision will be far too low. Therefore, a key goal in building malware detection systems is to minimize the false positive rate such that the precision of the system is reasonable.</p>
<p class="indent">Another related takeaway is that when you do the ROC curve analysis introduced earlier in this chapter, you should effectively ignore false positive rates over, say, 1 percent, if you are developing your system to be deployed in an enterprise setting, because any higher false positive rate will likely result in a system that has such low precision that it is rendered useless.</p>
<h3 class="h3" id="lev121"><strong>Summary</strong></h3>
<p class="noindent">In this chapter, you learned basic detection evaluation concepts, including true positive rate, false positive rate, ROC curves, base rates, and precision. You saw how maximizing the true positive rate and minimizing the false positive rate are both important in building a malware detection system. Because of the way base rate affects precision, reducing the false positive rate is particularly important if you want to deploy your detection system within an enterprise.</p>
<p class="indent">If you don’t feel completely fluent in these concepts, don’t worry. You’ll get more practice with them in the next chapter, where you’ll build and evaluate a malware detection system from the ground up. In the process, you’ll learn additional machine learning–specific evaluation concepts that will help you improve your machine learning–based detectors.</p>
</body></html>