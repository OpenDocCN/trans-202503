<html><head></head><body>
<div id="sbo-rt-content" class="calibre1"><h2 class="h1" id="ch07"><span epub:type="pagebreak" id="page_111" class="calibre2"/><strong class="calibre3"><span class="big">7</span><br class="calibre18"/>FINDING A GOOD SET OF HYPERPARAMETERS</strong></h2>
<div class="imagec"><img alt="Image" src="../images/common.jpg" class="calibre14"/></div>
<p class="noindent">As discussed in earlier chapters, especially <a href="ch03.xhtml#ch03lev2sec1" class="calibre12">Section 3.2.1</a>, most analysts’ approach to the problem of determining good values of hyperparameters is to use cross-validation. In this chapter, we’ll learn to use a <code>qeML</code> function, <code>qeFT()</code>, that greatly facilitates the process.</p>
<h3 class="h2" id="ch07lev1">7.1 Combinations of Hyperparameters</h3>
<p class="noindent">Note that typically we are talking about <em class="calibre13">sets</em> of hyperparameters. Suppose, for instance, that we wish to use PCA in a k-NN setting. Then we have two hyperparameters: the number of neighbors <em class="calibre13">k</em> and the number of principal components <em class="calibre13">m</em>. Thus we are interested in finding a good <em class="calibre13">combination</em> of a <em class="calibre13">k</em> value and an <em class="calibre13">m</em> value.</p>
<p class="indent">In many cases, the combinations are larger than just pairs. With <code>qeDT()</code>, for instance, there are hyperparameters <code>alpha</code>, <code>minsplit</code>, <code>minbucket</code>, <code>maxdepth</code>, and <code>mtry</code>. We thus wish to find a good set of five hyperparameters.</p>
<p class="indent"><span epub:type="pagebreak" id="page_112"/>Many ML methods have even more hyperparameters. The more hyperparameters an ML method has, the more challenging it is to find a good combination of values. The <code>qeML</code> function <code>qeFT()</code> is aimed at facilitating this search.</p>
<div class="note">
<p class="notet"><strong class="calibre3"><span class="notes">NOTE</span></strong></p>
<p class="notep"><em class="calibre13">Before continuing, note that though ML discussions—as well as some software documentation—will often refer to finding the <strong class="calibre5">best</strong> hyperparameter combination, this is typically an illusion. Due to p-hacking (see <a href="ch01.xhtml#ch01lev13" class="calibre12">Section 1.13</a>), the best combination for a given training set may not be the best for predicting new data, which is what counts. Nevertheless, by the end of this chapter, you’ll have the tools to dependably determine <strong class="calibre5">good</strong> combinations.</em></p>
</div>
<h3 class="h2" id="ch07lev2">7.2 Grid Searching with qeFT()</h3>
<p class="noindent">Many ML packages include functions to do a <em class="calibre13">grid search</em>, which means evaluating all possible hyperparameter combinations. However, the number of combinations is typically so large that a full grid search would take a prohibitive amount of time to run.</p>
<p class="indent">Some grid search software libraries attempt to solve this problem by evaluating only combinations that seem promising, via an iterative search moving through narrow parts of the grid. At each iteration, the algorithm updates its guess as to what to try next. This saves time but can move in the wrong direction and, again, is vulnerable to p-hacking problems.</p>
<p class="indent">The <code>qeML</code> function <code>qeFT()</code> takes a more cautious approach. It generates a large number of random hyperparameter combinations, with the number being specified by the user, and evaluates them according to the relevant loss criterion (MAPE for numeric- <em class="calibre13">Y</em> settings or OME for classification settings). It tabulates and displays the results and includes a graphical display option. And, most importantly and uniquely, it guards against p-hacking, as will be explained shortly.</p>
<p class="indent">The <code>qeFT()</code> function is a <code>qe</code>-series wrapper for a <code>regtools</code> function, <code>fineTuning()</code>. Recall that another term for hyperparameters is <em class="calibre13">tuning parameters</em>. The function name is a pun on the old radio days, when tuning to the precise frequency of your favorite station was known as “fine-tuning.”</p>
<h4 class="h3" id="ch07lev2sec1"><em class="calibre22"><strong class="calibre3">7.2.1 How to Call qeFT()</strong></em></h4>
<p class="noindent">Here is the basic <code>qeFT()</code> call form:</p>
<pre class="calibre16">qeFT(data,yName,qeftn,pars,nCombs=NULL,nTst,nXval,showProgress=TRUE)</pre>
<p class="noindent">Let’s look at the roles of the arguments:</p>
<p class="block2"><span class="codestrong1">data</span>   As in all of the <code>qe*</code>-series, our input data.</p>
<p class="block1"><span class="codestrong1">yName</span>   As in all of the <code>qe*</code>-series, the name of our <em class="calibre13">Y</em> column.</p>
<p class="block1"><span class="codestrong1">qeftn</span>   ML function name, such as <code>qeKNN</code>.</p>
<p class="block1"><span class="codestrong1">pars</span>   R list specifying which <code>qeftn</code> hyperparameter values we wish to consider, such as <em class="calibre13">k</em> in k-NN.<span epub:type="pagebreak" id="page_113"/></p>
<p class="block1"><span class="codestrong1">nCombs</span>   Number of random combinations of the hyperparameters to evaluate. If <code>NULL</code>, then all possible combinations will be run.</p>
<p class="block1"><span class="codestrong1">nTst</span>   Size of the holdout sets.</p>
<p class="block1"><span class="codestrong1">nXval</span>   Number of holdout sets to run for each hyperparameter combination.</p>
<p class="block1"><span class="codestrong1">showProgress</span>   For the impatient; print results as they become available.</p>
<p class="noindent">In short, we run the specified ML function <code>qeftn</code> on <code>nCombs</code> combinations of hyperparameters using ranges shown in <code>pars</code>. For each combination, we generate <code>nXval</code> training/test partitions of the data, with the test portion being of size <code>nTst</code>. We then tabulate the resulting MAPE or OME values across all combinations of hyperparameters.</p>
<p class="indent">Note the difference between <code>qeFT()</code> and the <code>replicMeans()</code> function introduced in <a href="ch03.xhtml#ch03lev2sec2" class="calibre12">Section 3.2.2</a>. The latter deals with the problem that the analyst may feel that a single holdout set is not enough to accurately assess performance. The <code>qeFT()</code> function does this too, via the argument <code>nXval</code>, but it does much more, automating the search process.</p>
<h3 class="h2" id="ch07lev3">7.3 Example: Programmer and Engineer Data</h3>
<p class="noindent">Returning to the US census data on programmers’ and engineers’ salaries in the year 2000 (see <a href="ch03.xhtml#ch03lev2sec3" class="calibre12">Section 3.2.3</a>), let’s find good hyperparameters to predict wage income.</p>
<pre class="calibre16">&gt; <span class="codestrong">set.seed(9999)</span>
&gt; <span class="codestrong">ftout &lt;- qeFT(data=pef,yName='wageinc',qeftn='qeKNN',</span>
+    <span class="codestrong">pars=list(k=5:25),nTst=1000,nXval=5)</span>
&gt; <span class="codestrong">ftout</span>
$outdf
    k  meanAcc       CI   bonfCI
1   5 22991.82 23402.16 23693.80
2   7 23168.20 24038.72 24657.43
3   9 23302.83 23829.56 24203.92
4  14 23384.68 23857.61 24193.75
5  10 23471.30 24095.60 24539.30
6   6 23635.61 24538.43 25180.09
7  25 23767.42 24651.47 25279.81
8  15 23843.55 24633.13 25194.31
9   8 23921.75 24846.51 25503.77
10 22 23924.46 24271.38 24517.95
11 16 24036.80 24784.32 25315.61
12 20 24120.60 24996.35 25618.78
13 11 24168.83 25639.28 26684.37
14 13 24192.18 24693.87 25050.43
15 12 24256.22 24690.67 24999.46
16 17 24261.34 24934.30 25412.59
17 18 24375.20 24576.41 24719.41
18 23 24376.66 25109.56 25630.46
19 24 24619.82 25249.43 25696.91
20 21 24693.10 25456.93 25999.81
21 19 24842.66 25564.61 26077.72
<br class="calibre1"/>
$nTst
[1] 1000
...</pre>
<p class="indent"><span epub:type="pagebreak" id="page_114"/>The only hyperparameter argument here is <code>k</code>. We’ve specified its range as <code>5:25</code>—that is, we try <em class="calibre13">k</em> = 5, <em class="calibre13">k</em> = 6, and so on, up through <em class="calibre13">k</em> = 25. Since we’ve left out the <code>nCombs</code> argument, we investigated all 21 of these by default.</p>
<p class="indent">The <code>meanAcc</code> is the primary result, giving us the mean <code>testAcc</code> over all cross-validation runs. We will explain the <code>CI</code> and <code>bonfCI</code> columns in the next section.</p>
<h4 class="h3" id="ch07lev3sec1"><em class="calibre22"><strong class="calibre3">7.3.1 Confidence Intervals</strong></em></h4>
<p class="noindent">At first it would seem that <em class="calibre13">k</em> = 5 neighbors is best. Indeed, that is our guess as to the optimal <em class="calibre13">k</em> for our setting here (meaning this <em class="calibre13">n</em>, this feature set, this sampled population, and so on). But we should be careful. Here is why.</p>
<p class="indent">Any <code>testAcc</code> value output from a <code>qe*</code>-series function is random, due to the randomness of the holdout sets. With <code>qeFT()</code>, we look at many holdout sets and average the result to obtain <code>meanAcc</code>. Since all the holdout sets are random, then so is <code>meanAcc</code>. Of course, the larger the <code>nXval</code>, the better the accuracy.</p>
<p class="indent">Thus the <code>meanAcc</code> column is only approximate. The idea of the <code>CI</code> column is to get an idea as to the accuracy of that approximation. Specifically, the values in the <code>CI</code> column are the right endpoints of approximate 95 percent confidence intervals (CIs) for the true mean accuracy of any given combination. (For those who know statistics, these are <em class="calibre13">one-sided</em> CIs, of the form (− ∞, <em class="calibre13">a</em>).)</p>
<p class="indent">In our case here, the <code>meanAcc</code> value for 7 neighbors is well within that CI for 5 neighbors. It’s really a toss-up between using 5 or 7 neighbors, and their <code>meanAcc</code> numbers are not too far apart anyway. Thus we should not take the apparent superiority of <em class="calibre13">k</em> = 5 literally.</p>
<p class="indent">In other words, the <code>CI</code> column “keeps us honest,” serving to remind us that <code>meanAcc</code> is only approximate and giving us some idea whether the apparent top few performers are distinguishable from each other.</p>
<p class="indent">But there’s more. When we construct a large number of CIs, their overall validity declines due to p-hacking (see <a href="ch01.xhtml#ch01lev13" class="calibre12">Section 1.13</a>). CIs that are set individually at a nominal 95 percent level have a much lower overall confidence level. To see this, imagine tossing 10 coins. The individual probability of heads is 0.5 for each coin, but the probability that <em class="calibre13">all</em> of them come up heads is much lower. Similarly, if we have ten 95 percent CIs, the probability that they are <em class="calibre13">all</em> correct is much less than 95 percent.</p>
<p class="indent"><span epub:type="pagebreak" id="page_115"/>The <code>bonfCI</code> column adjusts for that, using something called <em class="calibre13">Bonferroni−Dunn</em> CIs. In other words, that column gives us CIs that take into account that we are looking at many random CIs. We thus really should look more at that column than the <code>CI</code> one.</p>
<p class="indent">In our case here, the adjusted CI bounds are only a little larger than the original ones. This means we are not in much danger of p-hacking in this simple example. But as discussed in <a href="ch01.xhtml#ch01lev13" class="calibre12">Section 1.13</a>, it could be an issue with an ML algorithm having many hyperparameters. In such a setting, it is quite possible that we will pounce on a seemingly “best” combination that actually is quite unrepresentative and thus much inferior to some other alternatives.</p>
<p class="indent">We have no way of knowing that is the case, of course, but a good rule of thumb is to consider taking the more moderate combination among several with similar <code>meanAcc</code> values rather than extremely large or small values of the hyperparameters.</p>
<p class="indent">For instance, consider neural networks (we will look at these further in <a href="ch11.xhtml" class="calibre12">Chapter 11</a>), which typically have a number of hyperparameters, including:</p>
<ul class="calibre15">
<li class="noindent3">number of layers</li>
<li class="noindent3">number of neurons per layer</li>
<li class="noindent3">dropout rate</li>
<li class="noindent3">learning rate</li>
<li class="noindent3">momentum</li>
<li class="noindent3">initial weights</li>
</ul>
<p class="noindent">In order to investigate a broad variety of hyperparameter combinations, we would need to set the <code>nCombs</code> argument in <code>qeFT()</code> to a very large number, putting us at significant risk of finding a combination that is not actually very effective but that accidentally looks great. The <code>bonfCI</code> column warns us of this; the higher the discrepancy between it and the <code>CI</code> column, the greater the risk.</p>
<p class="indent">On the other hand, we are merely seeking a <em class="calibre13">good</em> combination of hyperparameters, not the absolute best. For any particular combination, the <code>bonfCI</code> figure is giving us a reasonable indication as to whether this combination will work well in predicting future cases. As with many things in ML, there is no magic formula for how to deal with the CIs, but they can act as informal aids to our thinking.</p>
<div class="note">
<p class="notet"><strong class="calibre3"><span class="notes">NOTE</span></strong></p>
<p class="notep"><em class="calibre13">Here’s a bit of history on Bonferroni−Dunn intervals: Traditionally, only the name Bonferroni is used, in honor of the Italian mathematician who developed the probability inequality central to the CIs. However, as a former student of Professor Olive Jean Dunn, I have been pleased to find that her name is now often included, as she was the one who proposed using the inequality for constructing CIs.</em></p>
</div>
<h4 class="h3" id="ch07lev3sec2"><span epub:type="pagebreak" id="page_116" class="calibre2"/><em class="calibre22"><strong class="calibre3">7.3.2 The Takeaway on Grid Searching</strong></em></h4>
<p class="noindent">The takeaway here is that we cannot take the ordering of results in a grid search literally. The first few “best” results may actually be similar. Moreover, the apparent “best” may actually be unrepresentative. Settle on a “good” combination that is hopefully not too extreme rather than trying to optimize.</p>
<h3 class="h2" id="ch07lev4">7.4 Example: Programmer and Engineer Data</h3>
<p class="noindent">Let’s try predicting occupation instead of wage income.</p>
<pre class="calibre16">&gt; <span class="codestrong">ftout &lt;- qeFT(data=pef,yName='occ',qeftn='qeKNN',pars=list(k=1:25),</span>
   <span class="codestrong">nTst=1000,nXval=5)</span>
&gt; <span class="codestrong">ftout</span>
$outdf
    k meanAcc        CI    bonfCI
1   4  0.4656 0.4774134 0.4862065
2   7  0.4688 0.4756510 0.4807504
3   3  0.4726 0.4850419 0.4943029
4   2  0.4746 0.4846176 0.4920740
5   1  0.4766 0.4866176 0.4940740
6   5  0.4782 0.4827307 0.4861032
7   8  0.4990 0.5082016 0.5150508
8   6  0.5016 0.5179475 0.5301156
9  11  0.5150 0.5273033 0.5364611
10  9  0.5162 0.5239988 0.5298037
11 10  0.5292 0.5376199 0.5438871
12 14  0.5326 0.5425630 0.5499789
13 13  0.5332 0.5411714 0.5471048
14 15  0.5374 0.5522555 0.5633130
15 12  0.5402 0.5546542 0.5654131
16 17  0.5416 0.5499582 0.5561795
17 16  0.5422 0.5568134 0.5676908
18 24  0.5514 0.5632823 0.5721268
19 18  0.5570 0.5706960 0.5808905
20 20  0.5576 0.5682114 0.5761100
21 19  0.5600 0.5699275 0.5773169
22 21  0.5656 0.5766019 0.5847911
23 22  0.5674 0.5797099 0.5888727
24 25  0.5738 0.5844089 0.5923055
25 23  0.5758 0.5904321 0.6013233</pre>
<p class="noindent">The CIs, especially the Bonferroni−Dunn ones—which, as noted, are more reliable—suggest that any of the first <code>k</code> values have about the same predictive ability. The <code>bonfCI</code> value for 4 neighbors extends to include the <code>meanAcc</code> value for 5 neighbors.</p>
<p class="indent"><span epub:type="pagebreak" id="page_117"/>Note the role of <code>nXval</code> here. We simply used too few cross-validations. We should try more, but if not, the values of <code>k</code>, 1, 2, 3, 4, and 7, look about the same. Conservatively, we might choose to use 3 or 4 neighbors.</p>
<h3 class="h2" id="ch07lev5">7.5 Example: Phoneme Data</h3>
<p class="noindent">This dataset, which is included in the <code>regtools</code> package, seeks to predict one of two phoneme types from five sound measurements. Let’s take a look:</p>
<pre class="calibre16">&gt; <span class="codestrong">head(phoneme)</span>
         V1        V2        V3        V4        V5 lbl
0  0.489927 -0.451528 -1.047990 -0.598693 -0.020418   1
1 -0.641265  0.109245  0.292130 -0.916804  0.240223   1
2  0.870593 -0.459862  0.578159  0.806634  0.835248   1
3 -0.628439 -0.316284  1.934295 -1.427099 -0.136583   1
4 -0.596399  0.015938  2.043206 -1.688448 -0.948127   1
5  0.164735 -0.642728 -0.980619 -0.386415 -0.242046   1
&gt; <span class="codestrong">dim(phoneme)</span>
[1] 5404    6</pre>
<p class="noindent">The <em class="calibre13">Y</em> column here is <code>lbl</code>. As noted, it has two levels, so this is a two-class classification problem.</p>
<p class="indent">Let’s try <code>qeDT()</code> on this data. As noted, the various hyperparameters interact with each other, so at first, we might not try using all of them. We might just use, say, <code>alpha</code>, <code>minbucket</code>, and <code>maxdepth</code>.</p>
<p class="indent">We need to specify ranges that we want to investigate for each of these parameters. Once again, there is no formula for deciding this, and one must gain insight from experience. But as an example, let’s try 0.01, 0.05, 0.10, 0.25, 0.50, and 1 for <code>alpha</code>, and 1, 5, and 10 for <code>minbucket</code>, and so on, as seen in the call:</p>
<pre class="calibre16">&gt; <span class="codestrong">z &lt;- qeFT(phoneme,'lbl','qeDT',list(alpha=c(0.01,0.05,0.10,0.25,0.50,1),</span>
   <span class="codestrong">minbucket=c(1,5,10),maxdepth=c(3,8),minsplit=c(1,5,10),mtry=c(0,3)),</span>
   <span class="codestrong">50,1000,5,showProgress=T)</span>
&gt; <span class="codestrong">z</span>
$outdf
   alpha minbucket maxdepth minsplit mtry meanAcc        CI    bonfCI
1   1.00         1        8        5    0  0.1150 0.1284351 0.1401622
2   1.00         5        8       10    0  0.1176 0.1224275 0.1266412
3   1.00         5        8        1    0  0.1180 0.1238801 0.1290127
4   0.25         1        8        5    0  0.1218 0.1344352 0.1454640
5   1.00        10        8        1    3  0.1276 0.1403232 0.1514289
6   0.10         1        8        1    0  0.1310 0.1412380 0.1501744
7   1.00        10        8       10    3  0.1336 0.1380151 0.1418689
8   0.05         5        8       10    0  0.1338 0.1386500 0.1428834
9   0.05         5        8        1    0  0.1358 0.1429046 0.1491060
10  0.50         1        8        5    3  0.1362 0.1507200 0.1633940
11  0.01         1        8       10    0  0.1376 0.1416952 0.1452698
12  0.10        10        8       10    0  0.1408 0.1442374 0.1472378
13  0.50         5        8        5    3  0.1448 0.1543984 0.1627765
14  0.05         1        8        1    0  0.1466 0.1511066 0.1550404
15  0.25         5        8       10    3  0.1480 0.1609606 0.1722736
16  0.01         5        8       10    0  0.1486 0.1535665 0.1579015
17  0.10        10        8        1    3  0.1502 0.1631963 0.1745404
18  0.25        10        8        1    3  0.1536 0.1682711 0.1810770
19  0.25         5        8        5    3  0.1548 0.1731395 0.1891475
20  0.10         1        8        1    3  0.1552 0.1629286 0.1696747
...
46  0.50        10        3       10    3  0.2210 0.2279024 0.2339274
47  0.10        10        3       10    3  0.2216 0.2274476 0.2325518
48  0.50        10        3        1    3  0.2224 0.2302890 0.2371751
49  0.25         1        3       10    3  0.2228 0.2301494 0.2365645
50  0.01         5        3        5    3  0.2238 0.2333700 0.2417233</pre>
<p class="indent"><span epub:type="pagebreak" id="page_118"/>Recall the role of <code>nCombs</code>. If we set it to <code>NULL</code>, that means we want <code>qeFT()</code> to try all possible combinations of our specified hyperparameter ranges. It turns out that there are 216 combinations (not shown). But we had set <code>nCombs</code> to 50, so <code>qeFT()</code> ran 50 randomly chosen combinations among the 216, and thus we see only 50 rows in the output here.</p>
<p class="indent">The more hyperparameters an ML algorithm has, and the more values we try for each one, the more possible combinations we have. In some cases, there are just too many to try them all, hence the non- <code>NULL</code> use of <code>nCombs</code>.</p>
<p class="indent">Note, too, that the more hyperparameter combinations we run, the greater the risk of p-hacking. It is here that the <code>bonfCI</code> column is most useful. The fact that, in the output above, the <code>bonfCI</code> column is very close to the <code>CI</code> column in most cases tells us that p-hacking is probably not an issue for this data.</p>
<p class="indent">Now, what might we glean from this output?</p>
<ol class="calibre17">
<li class="noindent3">Hyperparameter tuning matters. The lowest OME values were about half of the largest ones.</li>
<li class="noindent3">Since the first three <code>CI</code> values are very close and within each other’s CIs, any of the first three hyperparameter combinations should be good.</li>
<li class="noindent3">The first 20 hyperparameter combinations all had a value of 8 for <code>maxdepth</code>. This suggests that we might do even better with a value larger than 8.</li>
<li class="noindent3">Larger values of <code>alpha</code> seemed to do better. This suggests that we try some additional large values. For instance, we didn’t try any values between 0.50 and 1, so 0.75 might be worth a try.</li>
<li class="noindent3"><span epub:type="pagebreak" id="page_119"/>The top three combinations all had <code>mtry = 0</code>, while the bottom ones had a value of 3 for that hyperparameter. We probably should do more detailed investigation here.</li>
<li class="noindent3">The hyperparameters do interact. Look at line 6, for instance. The value of <code>alpha</code> was smaller than in most top lines, putting a damper on the node-splitting process, but this was compensated for in part by small values of <code>minsplit</code> and <code>minbucket</code>, which encourage lots of node splitting. Such negative “correlations” are clear in the graphical display capability of <code>qeFT()</code> (not shown).</li>
</ol>
<h3 class="h2" id="ch07lev6">7.6 Conclusions</h3>
<p class="noindent">No doubt about it, finding a good set of hyperparameters is one of the major challenges in ML. But in this chapter we’ve seen tools that can be used for this purpose, and we can be reasonably confident that we’ve made a good choice.<span epub:type="pagebreak" id="page_120"/></p>
</div></body></html>