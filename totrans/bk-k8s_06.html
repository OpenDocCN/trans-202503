<html><head></head><body>
<h2 class="h2" id="ch05"><span epub:type="pagebreak" id="page_69"/><span class="big">5</span><br/>CONTAINER IMAGES AND RUNTIME LAYERS</h2>&#13;
<div class="image1"><img alt="image" src="../images/common01.jpg"/></div>&#13;
<p class="noindent">To run a process, we need storage. One of the great advantages of containerized software is the ability to bundle an application for delivery together with its dependencies. As a result, we need to store the executable for the program and any shared libraries it uses. We also need to store configuration files, logs, and any data managed by the program. All of this storage must be isolated so that a container can’t interfere with the host system or with other containers. Altogether, this represents a large need for storage, and it means container engines must provide some unique features to be efficient in the use of disk space and bandwidth. In this chapter, we’ll explore how the use of a layered filesystem makes container images efficient to download and containers efficient to start.</p>&#13;
<h3 class="h3" id="ch00lev1sec22"><span epub:type="pagebreak" id="page_70"/>Filesystem Isolation</h3>&#13;
<p class="noindent">In <a href="ch02.xhtml#ch02">Chapter 2</a>, we saw how we could use a <em>chroot</em> environment to create a separate, isolated part of the filesystem that contained only the binaries and libraries we needed to run a process. Even to run a simple <code>ls</code> command, we needed the binary and several libraries. A more fully featured container, such as one running the NGINX web server, needs quite a bit more—a complete set of files for a Linux distribution.</p>&#13;
<p class="indent">In the chroot example, we built the isolated filesystem from the host system when we were ready to use it. That approach would be impractical for containers. Instead, the isolated filesystem is packaged in a <em>container image</em>, which is a ready-to-use bundle that includes all files and metadata, such as environment variables and the default executable.</p>&#13;
<h4 class="h4" id="ch00lev2sec32">Container Image Contents</h4>&#13;
<p class="noindent">Let’s take a quick look inside an NGINX container image. For this chapter, we’ll be running commands using Docker because it’s still the most common tool for building container images.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>The example repository for this book is at</em> <a href="https://github.com/book-of-kubernetes/examples">https://github.com/book-of-kubernetes/examples</a>. <em>See “Running Examples” on <a href="ch00.xhtml#ch00lev1sec2">page xx</a> for details on getting set up.</em></p>&#13;
</div>&#13;
<p class="indent">Run the following command on <em>host01</em> from this chapter’s examples to download the image:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">docker pull nginx</span>&#13;
Using default tag: latest&#13;
latest: Pulling from library/nginx&#13;
...&#13;
Status: Downloaded newer image for nginx:latest&#13;
docker.io/library/nginx:latest</pre>&#13;
<p class="indent">The <code>docker pull</code> command downloads an image from an <em>image registry</em>. An image registry is a web server that implements an API for downloading and publishing container images. We can see the image we’ve downloaded by listing images with <code>docker images</code>:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">docker images</span>&#13;
REPOSITORY   TAG       IMAGE ID       CREATED       SIZE&#13;
nginx        latest    f0b8a9a54136   7 days ago    133MB</pre>&#13;
<p class="indent">This image is 133MB and has a unique identifier of <code>f0b8a9a54136</code>. (Your identifier will be different, as new NGINX container images are built every day.) This image includes not only the NGINX executables and required libraries but also a Linux distribution based on Debian. We saw this briefly <span epub:type="pagebreak" id="page_71"/>in <a href="ch01.xhtml#ch01">Chapter 1</a> when we demonstrated a Rocky Linux container on an Ubuntu host and kernel, but let’s look at it in a little more detail. Start by running an NGINX container:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">docker run --name nginx -d nginx</span>&#13;
516d13e912a55cfc6f73f0dd473661d6b7d3b868d5a07a2bc7253971015b6799</pre>&#13;
<p class="indent">The <code>--name</code> flag gives the container a friendly name that we can use for future commands, whereas the <code>-d</code> flag sends it to the background.</p>&#13;
<p class="indent">Now, let’s explore the filesystem of our running container:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">docker exec -ti nginx /bin/bash</span>&#13;
root@516d13e912a5:/#</pre>&#13;
<p class="indent">From here, we can see the various libraries needed for NGINX to work:</p>&#13;
<pre>root@516d13e912a5:/# <span class="codestrong1">ldd $(which nginx)</span>&#13;
        linux-vdso.so.1 (0x00007ffe2a1fa000)&#13;
...&#13;
        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fe0d6531000)&#13;
        /lib64/ld-linux-x86-64.so.2 (0x00007fe0d6ed4000)</pre>&#13;
<p class="indent">All of these libraries are part of the container image we downloaded, so our NGINX container does not need (and cannot see) any files from the host system.</p>&#13;
<p class="indent">Not only do we have a healthy number of libraries present, but we have typical configuration files in <em>/etc</em> that we would expect for a Debian system:</p>&#13;
<pre>root@516d13e912a5:/# <span class="codestrong1">ls -1 /etc</span>&#13;
...&#13;
debian_version&#13;
deluser.conf&#13;
dpkg&#13;
...&#13;
systemd/&#13;
...</pre>&#13;
<p class="indent">This listing shows that the filesystem even includes directories that aren’t really needed for a container, like the <em>/etc/systemd</em> directory. (Remember, a container is just a set of related processes run under isolation, so a container almost never runs a system service manager like systemd.) This full filesystem is included for a couple reasons. First, many processes were written to expect the usual set of files to be present. Second, it’s just easier to build container images starting from a typical Linux distribution.</p>&#13;
<p class="indent">The separate filesystem for our container is writable as well. While we have this shell open, let’s send some random data to a file in the container so that we can inspect that storage from the host. We can then exit the shell:</p>&#13;
<pre>root@516d13e912a5:/# <span class="codestrong1">dd if=/dev/urandom of=/tmp/data bs=1M count=10</span>&#13;
...&#13;
<span epub:type="pagebreak" id="page_72"/>10485760 bytes (10 MB, 10 MiB) copied, 0.0913977 s, 115 MB/s&#13;
root@516d13e912a5:/# <span class="codestrong1">exit</span></pre>&#13;
<p class="indent">The <code>dd</code> command wrote a 10MB file into the <em>/tmp</em> directory. Even though we exited the shell, the container is still running, so we can use <code>docker inspect</code> to see the amount of disk space this container is using:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">docker inspect -s nginx | jq '.[0].SizeRw'</span>&#13;
10487109</pre>&#13;
<p class="indent">The <code>-s</code> flag tells <code>docker inspect</code> to report the size of the container. Because <code>docker inspect</code> produces a huge JSON output, we use the JSON query tool <code>jq</code> to choose the field we want.</p>&#13;
<p class="indent">The reported size is just about 10MB, suggesting that the container is consuming only the amount of read-write storage required for the file we wrote, plus any files written by NGINX. We’ll explore this in more detail as we continue in this chapter.</p>&#13;
<h4 class="h4" id="ch00lev2sec33">Image Versions and Layers</h4>&#13;
<p class="noindent">The ability to quickly download a prepackaged filesystem to run a process is only one of the advantages of container images. Another is the ability to tag different versions of an image to allow for rapid upgrading. Let’s explore this by pulling and running two different versions of Redis, the popular in-memory key–value database:</p>&#13;
<pre>   root@host01:~# <span class="codestrong1">docker pull redis:6.0.13-alpine</span>&#13;
   6.0.13-alpine: Pulling from library/redis&#13;
<span class="ent">➊</span> 540db60ca938: Pull complete &#13;
   29712d301e8c: Pull complete &#13;
   8173c12df40f: Pull complete &#13;
   ...&#13;
   docker.io/library/redis:6.0.13-alpine&#13;
   root@host01:~# <span class="codestrong1">docker pull redis:6.2.3-alpine</span>&#13;
   6.2.3-alpine: Pulling from library/redis&#13;
<span class="ent">➋</span> 540db60ca938: Already exists &#13;
   29712d301e8c: Already exists &#13;
   8173c12df40f: Already exists &#13;
   ...&#13;
   docker.io/library/redis:6.2.3-alpine</pre>&#13;
<p class="indent">The data after the colon is the <em>image tag</em> and acts as a version identifier. Previously, when we left this off, Docker defaulted to <em>latest</em>, which is a tag like any other, but it is used by convention to refer to the latest published image. By specifying the version, we can ensure that even as newer versions of Redis are released, we will continue to run the same version until we are ready to upgrade. The tag can contain any characters, and it is common to add extra information after a hyphen. In this case, the <code>-alpine</code> at the end of the tag indicates that this image is based on Alpine Linux, a lightweight <span epub:type="pagebreak" id="page_73"/>Linux distribution that is popular for making container images because of its small size.</p>&#13;
<p class="indent">One other interesting item of note is the fact that when we downloaded the second version of Redis, some of the content <span class="ent">➋</span> was flagged as <code>Already exists</code>. Looking at the first Redis download, we see the same unique identifiers are present there <span class="ent">➊</span>. This is because a container image is made up of layers, and these identifiers uniquely describe a layer. If a layer we’ve already downloaded is used by another image, we don’t need to download it again, saving download time. Additionally, each layer needs to be stored only once on disk, saving disk space.</p>&#13;
<p class="indent">We now have two different versions of Redis downloaded:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">docker images | grep redis</span>&#13;
redis        6.0.13-alpine   a556c77d3dce   2 weeks ago   31.3MB&#13;
redis        6.2.3-alpine    efb4fa30f1cf   2 weeks ago   32.3MB</pre>&#13;
<p class="indent">Although Docker is reporting that each image has a size of about 30MB, that is the total size of all the layers and doesn’t account for the storage savings that come from shared layers. The actual storage on disk is less, as we can see by examining Docker’s use of disk space:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">docker system df -v</span>&#13;
Images space usage:&#13;
&#13;
REPOSITORY TAG           ... SIZE      SHARED SIZE   UNIQUE SIZE ...&#13;
redis      6.0.13-alpine ... 31.33MB   6.905MB       24.42MB     ...&#13;
redis      6.2.3-alpine  ... 32.31MB   6.905MB       25.4MB      ...</pre>&#13;
<p class="indent">The two Redis images are sharing almost 7MB of base layers.</p>&#13;
<p class="indent">These two versions of Redis can be run separately:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">docker run -d --name redis1 redis:6.0.13-alpine</span>&#13;
66dbf56ec0e8db24ca78afc07c68b7d0699d68b4749e0c03310857cfce926366&#13;
root@host01:~# <span class="codestrong1">docker run -d --name redis2 redis:6.2.3-alpine</span>&#13;
9dd3f86a1284171e5ca60f7f8a6a13dc517237826a92b3cb256f5ac64a5f5c31</pre>&#13;
<p class="indent">Now that both images are running, we can confirm that our containers have exactly the version of Redis we want, independent of what version might be the latest release and independent of the versions available for our host server:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">docker logs redis1 | grep version</span>&#13;
1:C 21 May 2021 14:18:24.952 # Redis version=6.0.13, ...&#13;
root@host01:~# <span class="codestrong1">docker logs redis2 | grep version</span>&#13;
1:C 21 May 2021 14:18:36.387 # Redis version=6.2.3, ...</pre>&#13;
<p class="indent">This is a big advantage for building reliable systems. We can test our application thoroughly with one version of the software and be sure that version will continue to be used until we choose to upgrade. We can also <span epub:type="pagebreak" id="page_74"/>easily test our software against a new version without having to upgrade a host system.</p>&#13;
<h3 class="h3" id="ch00lev1sec23">Building Container Images</h3>&#13;
<p class="noindent">In the preceding example, we saw how we could reduce the download and disk requirements for container images by sharing layers. This layer sharing can be used with any container image, not just two different versions of the same software.</p>&#13;
<p class="indent">The layers in a container image come from the way it is built. A container image build starts with a <em>base image</em>. For example, both of our two Redis versions started with the same exact Alpine Linux base image, which is why those layers were shared in that image. Starting from the base image, each step in the build process can produce a new layer. This new layer contains only the changes to the filesystem that came from that build step.</p>&#13;
<p class="indent">A base image must also come from somewhere, and, ultimately, there must be an initial layer, which is typically a minimal Linux filesystem created from some Linux distribution, transferred into an empty container image, and then expanded to become an initial layer.</p>&#13;
<h4 class="h4" id="ch00lev2sec34">Using a Dockerfile</h4>&#13;
<p class="noindent">There are many different ways to build container images, but the most popular is to create a file known as a <em>Dockerfile</em> or <em>Containerfile</em> that specifies the commands and configuration for the image. Here’s a simple <em>Dockerfile</em> that adds web content to an NGINX image:</p>&#13;
<p class="noindent6"><em>Dockerfile</em></p>&#13;
<pre>---&#13;
FROM nginx&#13;
&#13;
# Add index.html&#13;
RUN echo "&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello World!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;" \&#13;
    &gt;/usr/share/nginx/html/index.html</pre>&#13;
<p class="indent">Each line in a <em>Dockerfile</em> starts with a command that is followed by parameters. Blank lines and content after a <code>#</code> are ignored, and a backslash at the end of a line continues that command onto the next line. There are many possible commands; here are the most common:</p>&#13;
<div class="bqparan">&#13;
<p class="noindent5"><span class="codestrong">FROM</span> Specify the base image for this build.</p>&#13;
<p class="noindent5"><span class="codestrong">RUN</span> Run a command inside the container.</p>&#13;
<p class="noindent5"><span class="codestrong">COPY</span> Copy files into the container.</p>&#13;
<p class="noindent5"><span class="codestrong">ENV</span> Specify an environment variable.</p>&#13;
<p class="noindent5"><span class="codestrong">ENTRYPOINT</span> Configure the initial process for the container.</p>&#13;
<p class="noindent5"><span class="codestrong">CMD</span> Set default parameters for the initial process.</p>&#13;
</div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_75"/>Docker provides the <code>docker build</code> command to build an image from a <em>Dockerfile</em>. The <code>docker build</code> command creates a new image by running each command in the <em>Dockerfile</em>, one at a time. <a href="ch05.xhtml#ch05list1">Listing 5-1</a> illustrates how to run <code>docker build</code>.</p>&#13;
<pre>   root@host01:~# <span class="codestrong1">cd /opt/hello</span>&#13;
   root@host01:/opt/hello# <span class="codestrong1">docker build -t hello .</span>&#13;
<span class="ent">➊</span> Sending build context to Docker daemon  2.048kB&#13;
   Step 1/2 : FROM nginx&#13;
 <span class="ent">➋</span> ---&gt; f0b8a9a54136&#13;
   Step 2/2 : RUN echo "&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello World!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;" ...&#13;
 <span class="ent">➌</span> ---&gt; Running in 77ba9163d0a5&#13;
   Removing intermediate container 77ba9163d0a5&#13;
    ---&gt; e9ca31d590f9&#13;
   Successfully built e9ca31d590f9&#13;
<span class="ent">➍</span> Successfully tagged hello:latest</pre>&#13;
<p class="caption" id="ch05list1"><em>Listing 5-1: Docker build</em></p>&#13;
<p class="indent">The <code>-t</code> switch tells <code>docker build</code> to store the image from the build process under the name <code>hello</code>.</p>&#13;
<p class="indent">Examining the steps in this build process will help clarify how container images are made. First, Docker sends the <em>build context</em> to the Docker daemon <span class="ent">➊</span>. The build context is a directory and all of its files and subdirectories. In this case, we specified the build context as the current directory when we added <code>.</code> to the end of the <code>docker build</code> command. The actual container image build happens inside the daemon, so the only files that would be available for a <code>COPY</code> command are those that are in the build context.</p>&#13;
<p class="indent">Second, Docker identifies our base image, in this case <code>nginx</code>. The unique identifier it displays <span class="ent">➋</span> matches the one displayed earlier for our NGINX image when we ran <code>docker images</code>. Third, Docker executes the command we specified in the <code>RUN</code> step. This command is actually run inside a container based on our NGINX base image <span class="ent">➌</span>, which means that only the commands installed in the container image are available to run. If we need other commands to be available, we might need to create a <code>RUN</code> step that installs them before we can use them.</p>&#13;
<p class="indent">After all of the build steps are complete, Docker “tags” the new container image with the name we provided using the <code>-t</code> flag. As before, we didn’t specify a version, so <code>latest</code> is used as a default. We now can see this image in the list of available images:</p>&#13;
<pre>root@host01:/opt/hello# <span class="codestrong1">docker images | grep hello</span>&#13;
hello        latest          e9ca31d590f9   9 minutes ago   133MB</pre>&#13;
<p class="indent">The unique identifier for this image matches the output from the end of <a href="ch05.xhtml#ch05list1">Listing 5-1</a>. This image is shown as 133MB because it has all of the layers from the NGINX image in addition to the new small HTML file we added. As before, the shared layers are stored only once, so the extra storage required to build this image was very small.</p>&#13;
<div class="note">&#13;
<p class="notet"><span epub:type="pagebreak" id="page_76"/><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>When you try this example yourself, the unique identifier displayed for your “hello” image will be different, even though the Dockerfile has the same content for the HTML file. The identifier for each layer is based not only on the layer’s file content but also on the identifier for the layer above it. As a result, if two images have the same identifier, we can be confident that the contents are exactly the same, even if they were built separately.</em></p>&#13;
</div>&#13;
<p class="indent">We can run a container based on this new image just as we would any other image:</p>&#13;
<pre>root@host01:/opt/hello# <span class="codestrong1">docker run -d -p 8080:80 hello</span>&#13;
83a23cf2921bb37474bfcefb0da45f9953940febfefd01ebadf35405d88c4396&#13;
root@host01:/opt/hello# <span class="codestrong1">curl http://localhost:8080/</span>&#13;
&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello World!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</pre>&#13;
<p class="indent">As described in <a href="ch01.xhtml#ch01">Chapter 1</a>, the <code>-p</code> flag forwards a host port into the container, enabling us to access the NGINX server from the host even though it is running in a separate network namespace. We then can use <code>curl</code> to see that our container has the content we provided.</p>&#13;
<h4 class="h4" id="ch00lev2sec35">Tagging and Publishing Images</h4>&#13;
<p class="noindent">The image is ready to run locally, but we’re not ready yet to publish it to a registry. To publish to a registry, we need to give it a name that includes the full host and path for the registry location to ensure that when we refer to an image, we are getting exactly what we expect.</p>&#13;
<p class="indent">To demonstrate, let’s pull multiple BusyBox images from different registries. We’ll start with a BusyBox image from <em>quay.io</em>, an alternative container image registry:</p>&#13;
<pre>root@host01:/opt/hello# <span class="codestrong1">docker pull quay.io/quay/busybox</span>&#13;
...&#13;
quay.io/quay/busybox:latest</pre>&#13;
<p class="indent">This image name specifies both the host <code>quay.io</code> and the location of the image within that host, <code>quay/busybox</code>. As before, because we didn’t specify a version, <code>latest</code> is used as a default. We are able to pull a version called <code>latest</code> because someone has explicitly published a <code>latest</code> version of the image to this registry.</p>&#13;
<p class="indent">The BusyBox image we get using this command is different from the one we get if we just pull <code>busybox</code>:</p>&#13;
<pre>root@host01:/opt/hello# <span class="codestrong1">docker pull busybox</span>&#13;
...&#13;
docker.io/library/busybox:latest&#13;
root@host01:/opt/hello# <span class="codestrong1">docker images | grep busybox</span>&#13;
busybox                latest          d3cd072556c2   3 days ago       1.24MB&#13;
quay.io/quay/busybox   latest          e3121c769e39   8 months ago     1.22MB</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_77"/>When we use the plain name <code>busybox</code>, Docker defaults to pulling the image from <code>docker.io/library</code>. This registry is known as <em>Docker Hub</em>, which you can browse at <em><a href="https://hub.docker.com">https://hub.docker.com</a></em>.</p>&#13;
<p class="indent">Similarly, when we used the plain name <code>hello</code> to build our image, Docker sees it as belonging to <code>docker.io/library</code>. That path is for official Docker images, and, of course, we don’t have the right to publish images there.</p>&#13;
<p class="indent">The automated setup for this chapter includes running a local container registry, which means that we can publish this image to that local registry if we name it correctly:</p>&#13;
<pre>root@host01:/opt/hello# <span class="codestrong1">docker tag hello registry.local/hello</span>&#13;
root@host01:/opt/hello# <span class="codestrong1">docker images | grep hello</span>&#13;
hello                  latest          e9ca31d590f9   52 minutes ago   133MB&#13;
registry.local/hello   latest          e9ca31d590f9   52 minutes ago   133MB</pre>&#13;
<p class="indent">The same image now exists under two different names, providing an extra advantage of the way images are stored by layer. It’s cheap to add an extra name for an image. Of course, we could also have used the full name in the first place when we ran <code>docker build</code>, but it is convenient to use shorter names when building and using images locally.</p>&#13;
<p class="indent">Now that we have named the image correctly, we can publish it using <code>docker push</code>:</p>&#13;
<pre>root@host01:/opt/hello# <span class="codestrong1">docker push registry.local/hello</span>&#13;
Using default tag: latest&#13;
The push refers to repository [registry.local/hello]&#13;
...</pre>&#13;
<p class="indent">Our local registry starts out empty, so this command uploads all of the layers, but if we push any future images that include some of the same layers, they won’t be uploaded again. Similarly, if we were to delete an image tag from the registry, that would not remove the layer data.</p>&#13;
<p class="indent">This ability to publish images is not limited to images that we build ourselves. We can tag and push the BusyBox image we just downloaded from Docker Hub:</p>&#13;
<pre>root@host01:/opt/hello# <span class="codestrong1">docker tag busybox registry.local/busybox</span>&#13;
root@host01:/opt/hello# <span class="codestrong1">docker push registry.local/busybox</span>&#13;
Using default tag: latest&#13;
The push refers to repository [registry.local/busybox]&#13;
...&#13;
root@host01:/opt/hello# <span class="codestrong1">cd</span></pre>&#13;
<p class="indent">Retagging an image so that we can upload it to a private registry is a common practice that can help an application start faster and avoid being dependent on an internet registry.</p>&#13;
<p class="indent">The last command (<code>cd</code>) takes us back to our home directory, given that we’re finished in <em>/opt/hello</em>.</p>&#13;
<h3 class="h3" id="ch00lev1sec24"><span epub:type="pagebreak" id="page_78"/>Image and Container Storage</h3>&#13;
<p class="noindent">As mentioned previously, using individual layers to build up a container image has multiple advantages, including reduced download size, reduced disk space, and the ability to re-tag an image with a new name without using any additional space. The additional disk space needed by a running container is limited to just the files that we write while the container is running. Finally, all of the examples have shown how fast a new container starts up. All of these features together demonstrate why layers must be shared, not only for images but also for new containers. To make the best use of this layered approach in building efficient images, it helps to understand how this layered filesystem works.</p>&#13;
<h4 class="h4" id="ch00lev2sec36">Overlay Filesystems</h4>&#13;
<p class="noindent">When we run a container, we are presented with what looks like a single filesystem, with all the layers merged together and with the ability to make changes to any file. If we run multiple containers from the same image, we see an independent filesystem in each one, so that changes in one do not affect the other. How does this work without having to copy the entire filesystem every time we start a container? The answer is an <em>overlay filesystem</em>.</p>&#13;
<p class="indent">An overlay filesystem has three main parts. The <em>lower directory</em> is where the “base” layer exists. (There may be multiple lower directories.) The <em>upper</em> directory has the “overlay” layer, and the <em>mount</em> directory is where the unified filesystem is made available for use. A directory listing in the mount directory reflects all of the files from all of the layers, in priority order. Any changes made to the mount directory are really written to the upper directory by copying the changed file to the upper directory from a lower one, and then updating it—a process known as <em>copy on write</em>. Deletions are also written to the upper directory as metadata, so the lower directory can remain unmodified. This means that multiple users can share the lower directory without conflict because it is only read from, never written to.</p>&#13;
<p class="indent">An overlay filesystem is useful for more than just container images and containers. It is also useful for embedded systems, such as a network router, for which a read-only filesystem is written in firmware, making it possible for the device to be safely rebooted to a known state every time. It is also useful for virtual machines, enabling multiple virtual machines to be started from the same image.</p>&#13;
<p class="indent">Overlay filesystems are provided by a Linux kernel module, enabling very high performance. We can easily create an overlay filesystem. The first step is to create the necessary directories:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">mkdir /tmp/{lower,upper,work,mount}</span></pre>&#13;
<p class="indent">The <code>mkdir</code> command creates four separate directories in <em>/tmp</em>. We’ve already discussed the <em>lower</em> directory, <em>upper</em> directory, and <em>mount</em> directory. The <em>work</em> directory is an extra empty directory that the overlay filesystem uses as temporary space to ensure that changes in the mount directory appear atomic—that is, to ensure that they appear all at once.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_79"/>Let’s put some content into the lower and upper directories:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">echo "hello1" &gt; /tmp/lower/hello1</span>&#13;
root@host01:~# <span class="codestrong1">echo "hello2" &gt; /tmp/upper/hello2</span></pre>&#13;
<p class="indent">Next, we just mount the overlay filesystem:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">mount -t overlay \</span>&#13;
  <span class="codestrong1">-o rw,lowerdir=/tmp/lower,upperdir=/tmp/upper,workdir=/tmp/work \</span>&#13;
  <span class="codestrong1">overlay /tmp/mount</span></pre>&#13;
<p class="indent">The <em>/tmp/mount</em> directory now contains the merged content of both the upper and lower directories:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">ls -l /tmp/mount</span>&#13;
total 8&#13;
-rw-r--r-- 1 root root 7 May 24 23:05 hello1&#13;
-rw-r--r-- 1 root root 7 May 24 23:05 hello2&#13;
root@host01:/opt/hello# <span class="codestrong1">cat /tmp/mount/hello1</span>&#13;
hello1&#13;
root@host01:/opt/hello# <span class="codestrong1">cat /tmp/mount/hello2</span>&#13;
hello2</pre>&#13;
<p class="indent">Any changes that we make are shown in the mount location but are actually made in the upper directory:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">echo "hello3" &gt; /tmp/mount/hello3</span>&#13;
root@host01:~# <span class="codestrong1">ls -l /tmp/mount</span>&#13;
total 8&#13;
-rw-r--r-- 1 root root 7 May 24 23:05 hello1&#13;
-rw-r--r-- 1 root root 7 May 24 23:10 hello2&#13;
-rw-r--r-- 1 root root 7 May 24 23:09 hello3&#13;
root@host01:~# <span class="codestrong1">ls -l /tmp/lower</span>&#13;
total 4&#13;
-rw-r--r-- 1 root root 7 May 24 23:05 hello1&#13;
root@host01:~# <span class="codestrong1">ls -l /tmp/upper</span>&#13;
total 8&#13;
-rw-r--r-- 1 root root 7 May 24 23:10 hello2&#13;
-rw-r--r-- 1 root root 7 May 24 23:09 hello3</pre>&#13;
<p class="indent">Additionally, even deleting files does not affect the lower directory:</p>&#13;
<pre>   root@host01:~# <span class="codestrong1">rm /tmp/mount/hello1</span>&#13;
   root@host01:~# <span class="codestrong1">ls -l /tmp/mount</span>&#13;
   total 8&#13;
   -rw-r--r-- 1 root root 7 May 24 23:10 hello2&#13;
   -rw-r--r-- 1 root root 7 May 24 23:09 hello3&#13;
   root@host01:~# <span class="codestrong1">ls -l /tmp/lower</span>&#13;
   total 4&#13;
   <span epub:type="pagebreak" id="page_80"/>-rw-r--r-- 1 root root 7 May 24 23:05 hello1&#13;
   root@host01:~# <span class="codestrong1">ls -l /tmp/upper</span>&#13;
   total 8&#13;
<span class="ent">➊</span> c--------- 1 root root 0, 0 May 24 23:11 hello1&#13;
   -rw-r--r-- 1 root root    7 May 24 23:10 hello2&#13;
   -rw-r--r-- 1 root root    7 May 24 23:09 hello3</pre>&#13;
<p class="indent">The <code>c</code> next to the listing for <code>hello1</code> in the upper directory <span class="ent">➊</span> indicates that this is a <em>character special file</em>. Its purpose is to indicate that this file was deleted in the upper directory. As a result, it does not show up in the mounted filesystem, even though it still exists in the lower directory.</p>&#13;
<p class="indent">Thanks to this approach, we can reuse the lower directory with an independent overlay, similar to how we can run multiple independent containers from the same image:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">mkdir /tmp/{upper2,work2,mount2}</span>&#13;
root@host01:~# <span class="codestrong1">mount -t overlay \</span>&#13;
  <span class="codestrong1">-o rw,lowerdir=/tmp/lower,upperdir=/tmp/upper2,workdir=/tmp/work2 \</span>&#13;
  <span class="codestrong1">overlay /tmp/mount2</span>&#13;
root@host01:~# <span class="codestrong1">ls -l /tmp/mount2</span>&#13;
total 4&#13;
-rw-r--r-- 1 root root 7 May 24 23:05 hello1</pre>&#13;
<p class="indent">Not only does the “deleted” file from the lower directory appear, but none of the content from the first upper directory shows up because it’s not part of this new overlay.</p>&#13;
<h4 class="h4" id="ch00lev2sec37">Understanding Container Layers</h4>&#13;
<p class="noindent">Armed with this information about overlay filesystems, we can explore the filesystem of our running NGINX container:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">ROOT=$(docker inspect nginx \</span>&#13;
  <span class="codestrong1">| jq -r '.[0].GraphDriver.Data.MergedDir')</span>&#13;
root@host01:~# <span class="codestrong1">echo $ROOT</span>&#13;
/var/lib/docker/overlay2/433751e2378f9b11.../merged</pre>&#13;
<p class="indent">As before, we use <code>jq</code> to choose just the field we want; in this case, it’s the path to the <em>merged</em> directory for the container’s filesystem. This merged directory is the mount point for an overlay filesystem:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">mount | grep $ROOT | tr [:,] '\n'</span>&#13;
overlay on /var/lib/docker/overlay2/433751e2378f9b11.../merged ...&#13;
lowerdir=/var/lib/docker/overlay2/l/ERVEI5TCULK4PCNO2HSWB4MFDB&#13;
/var/lib/docker/overlay2/l/RQDO2PYQ3OKMKDY3DAYPAJTZHF&#13;
/var/lib/docker/overlay2/l/LFSBVPYPODQJXDL5WQTI7ISYNC&#13;
/var/lib/docker/overlay2/l/TLZUYV2BFQNPFGU3AZFUHOH27V&#13;
<span epub:type="pagebreak" id="page_81"/>/var/lib/docker/overlay2/l/4M66FKSHDBNUWE7UAF2REQHSB2&#13;
/var/lib/docker/overlay2/l/LCTKPRHP6LG7KC7JQHETKIL6TZ&#13;
/var/lib/docker/overlay2/l/JOECSCSAQ5CPNHGEURVRT4JRQQ&#13;
upperdir=/var/lib/docker/overlay2/433751e2378f9b11.../diff&#13;
workdir=/var/lib/docker/overlay2/433751e2378f9b11.../work,xino=off)</pre>&#13;
<p class="indent">The <code>tr</code> command transforms colons and commas to newlines to make the output more readable.</p>&#13;
<p class="indent">The <code>mount</code> command shows seven separate entries for <code>lowerdir</code>, one for each of the layers in the NGINX container image. All seven of these directories, plus the <code>upperdir</code>, are merged together in the overlay filesystem.</p>&#13;
<p class="indent">We can see the 10MB data file we created earlier in both the mount directory and the upper directory:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">ls -l $ROOT/tmp/data</span>&#13;
-rw-r--r-- 1 root root 10485760 May 25 00:27 /var/lib/.../merged/tmp/data&#13;
root@host01:~# <span class="codestrong1">ls -l $ROOT/../diff/tmp/data</span>&#13;
-rw-r--r-- 1 root root 10485760 May 25 00:27 /var/lib/.../diff/tmp/data</pre>&#13;
<p class="indent">The actual file is stored in the upper directory <em>diff</em>, whereas the mount directory <em>merged</em> is just a view generated by the overlay filesystem.</p>&#13;
<p class="indent">Usually, we don’t need to delve into the container filesystem from the host, because we can just run commands from within the container to explore its files. However, this technique can be useful for pulling files from a container for cases in which the container engine is not behaving correctly.</p>&#13;
<h4 class="h4" id="ch00lev2sec38">Practical Image Building Advice</h4>&#13;
<p class="noindent">Some important practical implications result from the way that overlay filesystems are used with container images. First, because an overlay filesystem can have multiple lower directories, and merging is performant, breaking our container image into multiple layers causes very little performance penalty. It allows us to be very modular when building container images, enabling reuse of layers. For example, we might start with a base image and then build an image on top that installs some common dependencies, and then another image that adds specialized dependencies for some of our application components, and finally yet another image that adds a specific application. Assembling application container images using a layered approach can result in very efficient image transfer and storage, as the base layers are shared between components where possible.</p>&#13;
<p class="indent">Second, because a deletion in an upper layer does not actually remove the file from a lower layer, we need to be careful with how we handle large temporary files and also in how we store secrets while building images. In both cases, if we finish a layer while the file is still present, it will be there forever, causing us to waste bandwidth and space, or worse, leak secret information to anyone who downloads the image. In general, you should assume that every line of a <em>Dockerfile</em> makes a new layer, and you should also make <span epub:type="pagebreak" id="page_82"/>the assumption that all of the information associated with each command is stored in the image metadata. As a result:</p>&#13;
<ul>&#13;
<li><p class="noindent">Perform multiple steps in a single <code>RUN</code> line, and make sure every <code>RUN</code> command cleans up after itself.</p></li>&#13;
<li><p class="noindent">Don’t use <code>COPY</code> to transfer large files or secrets into the image, even if you clean them up in a later <code>RUN</code> step.</p></li>&#13;
<li><p class="noindent">Don’t use <code>ENV</code> to store secrets, because the resulting values become part of the image metadata.</p></li>&#13;
</ul>&#13;
<h3 class="h3" id="ch00lev1sec25">Open Container Initiative</h3>&#13;
<p class="noindent">A container image is more than just the set of layers that make up the overlay filesystem. It also includes important metadata, such as the initial command for the container and any environment variables for that command. The Open Container Initiative (OCI) provides a standard format for storing image information. It ensures that container images built by one tool can be used by any other tool and provides a standard way to transfer images layer by layer or in a complete package.</p>&#13;
<p class="indent">To demonstrate the OCI format, let’s extract a BusyBox container image from Docker and store it in OCI format using Skopeo, a program designed to move container images around between repositories and formats. The first step is to extract the image:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">skopeo copy docker-daemon:busybox:latest oci:busybox:latest</span>&#13;
...</pre>&#13;
<p class="indent">This command tells Skopeo to fetch the image from the Docker engine’s storage and write it out in OCI format. We now have a <em>busybox</em> directory that contains the image:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">ls -l busybox</span>&#13;
total 12&#13;
drwxr-xr-x 3 root root 4096 May 24 23:59 blobs&#13;
-rw-r--r-- 1 root root  247 May 24 23:59 index.json&#13;
-rw-r--r-- 1 root root   31 May 24 23:59 oci-layout</pre>&#13;
<p class="indent">The <em>oci-layout</em> file specifies the OCI version used for this image:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">jq . busybox/oci-layout</span>&#13;
{&#13;
  "imageLayoutVersion": "1.0.0"&#13;
}</pre>&#13;
<p class="indent">The <em>index.json</em> file tells us about the image:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">jq . busybox/index.json</span>&#13;
{&#13;
  "schemaVersion": 2,&#13;
<span epub:type="pagebreak" id="page_83"/>  "manifests": [&#13;
    {&#13;
      "mediaType": "application/vnd.oci.image.manifest.v1+json",&#13;
      "digest": "sha256:9c3c5aeeaa7e1629871808339...",&#13;
      "size": 347,&#13;
      "annotations": {&#13;
        "org.opencontainers.image.ref.name": "latest"&#13;
      }&#13;
    }&#13;
  ]&#13;
}</pre>&#13;
<p class="indent">The <code>manifests</code> property is an array that allows us to store multiple images in a single OCI directory or package. The actual filesystem content is stored by layer in the <em>blobs</em> directory, with each layer as a separate <em>.tar</em> file, so any shared layers are stored only once.</p>&#13;
<p class="indent">This BusyBox image has only a single layer. To look at its contents, we’ll need to work through the <em>index.json</em> and image manifest to find the path to its <em>.tar</em> file:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">MANIFEST=$(jq -r \</span>&#13;
  <span class="codestrong1">.manifests[0].digest busybox/index.json | sed -e 's/sha256://')</span>&#13;
root@host01:~# <span class="codestrong1">LAYER=$(jq -r \</span>&#13;
  <span class="codestrong1">.layers[0].digest busybox/blobs/sha256/$MANIFEST | sed -e 's/sha256://')</span>&#13;
root@host01:~# <span class="codestrong1">echo $LAYER</span>&#13;
197dfd3345530fd558a64f2a550e8af75a9cb812df5623daf0392aa39e0ce767</pre>&#13;
<p class="indent">The files in the <em>blobs</em> directory are named using the SHA-256 digest calculated from the file contents. We start by using <code>jq</code> to get the digest for the BusyBox image’s manifest, stripping off the <code>sha256:</code> part at the front to get the name of the manifest file. We then read the manifest to find the first (and only) layer. We now can see the content of this layer:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">tar tvf busybox/blobs/sha256/$LAYER</span>&#13;
drwxr-xr-x 0/0               0 2021-05-17 19:07 bin/&#13;
-rwxr-xr-x 0/0         1149184 2021-05-17 19:07 bin/[&#13;
hrwxr-xr-x 0/0               0 2021-05-17 19:07 bin/[[ link to bin/[&#13;
...&#13;
drwxr-xr-x 0/0               0 2021-05-17 19:07 dev/&#13;
drwxr-xr-x 0/0               0 2021-05-17 19:07 etc/&#13;
...</pre>&#13;
<p class="indent">Passing <code>tvf</code> to the <code>tar</code> command tells it to list a table of contents from the file we specify, which is the BusyBox image layer in this case. This layer contains a complete Linux filesystem, with BusyBox acting as the single executable for most of the standard Linux commands.</p>&#13;
<p class="indent">Using this <em>busybox</em> directory, we can also package up the container image, move it to a separate system, and then pull it into another container engine.</p>&#13;
<h3 class="h3" id="ch00lev1sec26"><span epub:type="pagebreak" id="page_84"/>Final Thoughts</h3>&#13;
<p class="noindent">When we run a container, we get what appears to be a separate, isolated filesystem that we can modify as desired. Underneath, the container engine is using the overlay filesystem to merge together multiple container image layers and a writeable directory that stores all the changes we make. Not only does the use of an overlay filesystem make a new container fast to start, but it also means that we can run multiple containers from the same image without waiting for file copy to complete, and we can reduce the required disk space by sharing image layers.</p>&#13;
<p class="indent">Now that we’ve looked at process isolation, resource limits, network isolation, and container storage, we’ve covered the main features of containers that make them so valuable for packaging, distributing, updating, and running application components. It’s time to move on to the critical features that we can get only from a container orchestration environment like Kubernetes. We’ll do that in <a href="part02.xhtml#part02">Part II</a>.</p>&#13;
</body></html>