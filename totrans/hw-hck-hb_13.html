<html><head></head><body>
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="387" id="Page_387"/>13</span><br/>
<span class="ChapterTitle">No Kiddin’: Real-Life Examples</span></h1>
</header>
<figure class="opener">
<img src="image_fi/book_art/chapterart.png" alt=""/>
</figure>
<p class="ChapterIntro">You’ve learned about embedded systems, and you’ve learned about embedded attacks. You might still feel like the hands-on attack details for real systems is missing. This chapter will help bridge the gap between laboratory examples and real life, and we’ll provide examples of both fault injection and power analysis attacks.</p>
<h2 id="h1-278748c13-0001">Fault Injection Attacks</h2>
<p class="BodyFirst">Fault injection attacks have probably been used the most in (published) real-world attacks of products (compared to power analysis). Two high-profile examples you might have heard about are attacking the Sony PlayStation’s hypervisor and the Xbox 360 via the “reset glitch.” Gaming systems are interesting targets because they typically have some of the best security in consumer-level equipment. During the same timeframe that these PlayStation and Xbox 360 attacks were occurring, most other <span epub:type="pagebreak" title="388" id="Page_388"/>consumer electronics (such as routers and TVs) had no boot signing and required no advanced attacks to exploit. You can also explore details on attacks, such as the Nintendo Switch attack and beyond, if you want to see how device security has been improving.</p>
<h3 id="h2-278748c13-0001">PlayStation 3 Hypervisor</h3>
<p class="BodyFirst">Game consoles are always going to be a target, as there is a motivated population interested in attacking them. Gamers may be looking to run pirated versions of games, may be interested in modifying the games themselves (or cheating within the games), or they may want to run custom code on a fairly widely available and powerful platform. This last reason was especially the case with the Sony PlayStation 3, which had a unique Cell microprocessor that lent itself well to multiprocessing. Although now you would plan on just building an algorithm to put onto your graphics processing unit (GPU), the field of GPU computing was not as easily accessible; for example, CUDA was released in June 2007 and OpenCL in August 2008, but clusters of PlayStation 3 consoles were tested as early as January 2007.</p>
<p>The PlayStation release supported running Linux directly. Linux itself was running under control of the PlayStation hypervisor, which prevented the user from accessing anything unintended (such as secure key storage). Attacking the PlayStation effectively meant finding a way around the hypervisor, as only then could one probe into the rest of the system to recover critical secrets. After initial work on breaking the PlayStation 3 occurred, Sony announced it no longer would support running Linux on future PlayStation updates due to the security risks. This announcement had the side effect of giving hackers added incentive to fully break the PlayStation 3, since running Linux on an updated PlayStation 3 now required a successful attack.</p>
<p>What was this attack? We’re actually going to concentrate on the “initial work,” which occurred thanks to George Hotz (GeoHot) and wasn’t the final exploit on the PlayStation, but it remains a well-known attack, so it’s worth understanding as an example of a fault attack.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">note</span></h2>
<p>	In the following paragraphs, we’ll generally refer to the HTAB (which just means the hash table) as a reference to the hash table used for the virtual memory page index. For example, modifying the HTAB actually means modifying the page table (which is stored as a hash table). Elsewhere, you’ll see the HTAB referred to as such, so we are using the same notation to make things easy.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>To understand the attack, we first have to look at some details on how the Linux kernel gets access to memory. To do so, the Linux kernel requests that the hypervisor allocate a memory buffer. The hypervisor duly allocates the requested buffer. The kernel also requests that a number of references be made in the hash table (HTAB) page index, so there are a number of references to this same block of memory. You can see an abstract view of the memory at this point in <a href="#figure13-1" id="figureanchor13-1">Figure 13-1</a>, step 1.</p>
<span epub:type="pagebreak" title="389" id="Page_389"/><figure>
<img src="image_fi/278748c13/f13001.png" alt="f13001"/>
<figcaption><p><a id="figure13-1">Figure 13-1</a>: The five steps of PS3 pwnage</p></figcaption>
</figure>
<p><a href="#figure13-1">Figure 13-1</a> shows an abstract view of the memory contents throughout the attack. HTABs are “handles” that give the kernel access to a particular memory range, as indicated by the arrows. Gray cells are accessible only to the hypervisor, whereas white cells are accessible to the kernel.</p>
<p>Back to the attack. Everything until now is nice and safe. The kernel has read/write access to a block of memory, but the hypervisor is well aware of this memory and ensures that no out-of-bound reads or writes occur. The attack comes when we request that the hypervisor deallocate the memory by <span epub:type="pagebreak" title="390" id="Page_390"/>closing all those references made through the HTAB in step 1 of <a href="#figure13-1">Figure 13-1</a>. At this point in time, we insert a glitch onto the PS3 memory bus with the goal of failing one of the deallocations. We’ll explain in a second why this is important, but for now note that the attack works because the deallocation is never “verified.” If the pointer to what we were supposed to deallocate on the hardware is corrupted, the hypervisor won’t know about this.</p>
<p>The physical fault comes from a logic-level signal inserted onto the memory data bus (that is, DQx pins). The original demo used a field-programmable gate array (FPGA) board to generate a short (~40ns) pulse, but later people re-creating this also demonstrated it with microcontrollers to generate similar pulses (in the 40 to 300ns range). As many deallocations are forced, the fault can simply be manually triggered. Specific timing isn’t needed since only one of the deallocations needs to fail.</p>
<p>This brings us to step 2 in <a href="#figure13-1">Figure 13-1</a>: the kernel has access to a piece of memory that was not actually invalidated in the HTAB. The hypervisor isn’t aware of this, as it thinks it safely deallocated the memory and removed all references to it.</p>
<p>The final stage of the attack is to generate a new virtual memory space that overlaps with this chunk of memory the kernel can read/write to. This virtual memory space will also include an HTAB for the page map within this virtual space, but if we are lucky, that HTAB will be in a chunk of memory we can read/write from, as shown in step 3 in <a href="#figure13-1">Figure 13-1</a>. If we can write to the HTAB, this means we can map memory pages into our space, which normally only the hypervisor should be able to do. This would bypass most protections since the memory pages appear to be passing through the valid HTAB, and the kernel itself is reading/writing a memory address that it is allowed to access.</p>
<p>The final step in achieving full read/write access is to remap the original HTAB so we can read/write to this table directly, as shown in step 4 in <a href="#figure13-1">Figure 13-1</a>. By switching back to the original memory space (not the virtual memory space created for the attack), we can now write to the main HTAB to remap arbitrary memory pages into our buffer. Since we have read/write access to this buffer, we can get read/write access to any memory locations, including the hypervisor code itself, as shown in step 5 in <a href="#figure13-1">Figure 13-1</a>.</p>
<p>The vulnerability can occur because the hypervisor became decoupled from the HTAB status, so it isn’t aware the kernel still has read/write access to the newly created virtual memory space. It’s also helped by the hypervisor allowing the kernel to discover the actual memory address of that initial buffer by standard API calls (which helps when creating the virtual memory space in getting the HTAB overlap).</p>
<p>If you’re interested in more details, you may be able to find a mirror of the original code posted by Hotz. Due to a lawsuit, Hotz stopped any further work on Sony products. You may also find useful a series of blog posts by xorloser that include both the original details and some updated versions of the attack tools (called XorHack). These blog posts provide complete examples of the attack if you want the gory details.</p>
<p>The takeaway is that with fault attacks, one can use a variety of methods to apply the fault. The attack may not be limited to the voltage, clock, <span epub:type="pagebreak" title="391" id="Page_391"/>electromagnetic (EM), and optical fault injection methods, for example. In this case, the memory bus itself is faulted, which may be a more exposed target than attempting to insert a fault onto the power supply of a complex device. The fault injection device can be a simple microcontroller, and it even works with an Arduino used to pulse the appropriate memory bus pin.</p>
<p>The other takeaway is that clever target preparation makes life much easier. Although the attack would work with careful timing to fault a single HTAB entry, it’s much easier to force a massive number of entries to be modified at once. Doing so allows rather loose timing on the fault injection, as the attack is designed such that only a small number of successes would be needed.</p>
<h3 id="h2-278748c13-0002">Xbox 360</h3>
<p class="BodyFirst">The Xbox 360 is another game console that has been successfully attacked with fault injection. This work is primarily credited to GliGli and Tiros, with previous reverse engineering work done by various users (see <a href="https://github.com/Free60Project" class="LinkURL">https://github.com/Free60Project</a> for full credits for the Reset Glitch Hack, and see the detailed hardware on <a href="https://github.com/gligli/tools/tree/master/reset_glitch_hack" class="LinkURL">https://github.com/gligli/tools/tree/master/reset_glitch_hack</a>). <a href="#figure13-2" id="figureanchor13-2">Figure 13-2</a> shows a high-level overview of the attack steps.</p>
<p>The Xbox 360 has a ROM-based first-stage bootloader (1BL) that loads the second-stage bootloader (2BL, also referred to as CB on the Xbox) stored in NAND flash. The 1BL verifies the RSA signature of the 2BL before loading it. Finally, 2BL loads a block called CD that includes the hypervisor and kernel—basically meaning we would ideally prefer to load our own CD block, as then we don’t even need to exploit the hypervisor since we’d simply be running our own code entirely.</p>
<p>The 2BL block will verify the expected SHA-1 hash for the CD block before running this code. Because the 2BL block was checked with an RSA signature, we can’t modify the SHA-1 hash that the 2BL block expects for the CD block without being detected. If we had an SHA-1 hash collision, we could load our own (unexpected) code, but there is a much easier way forward.</p>
<p>The SHA-1 will be calculated on the CD code and then compared with something like <code>memcmp()</code>. We know such operations are susceptible to fault attacks, so we could look to insert a glitch at this point in time.</p>
<p>To simplify the timing, some hardware features of the Xbox 360 are used. In particular, the main central processing unit (CPU) has an exposed pin that can be used to bypass the phase-locked loop (PLL). The result is the CPU runs at a much slower 520 kHz. This pin has been labeled CPU_PLL_BYPASS in the examples, but keep in mind, these pin names are not based on public documentation such as a datasheet. It’s possible this pin is actually something like a feedback loop for the PLL, but grounding it has the same effect as if it were a bypass enabled for the PLL.</p>
<span epub:type="pagebreak" title="392" id="Page_392"/><figure>
<img src="image_fi/278748c13/f13002.png" alt="f13002"/>
<figcaption><p><a id="figure13-2">Figure 13-2</a>: Sequence of a successful fault attack on the Xbox 360 “fat” version</p></figcaption>
</figure>
<p>With the CPU now running at a slower speed, it is easier to fine-tune the fault injection timing. In this case, the fault injection method is a short spike on the reset line of the CPU. Rather than reset the system, this fault causes the SHA-1 comparison to report a successful comparison, even if the SHA-1 hash doesn’t match.</p>
<p>If the reset line fault isn’t successful, one might expect other avenues, such as voltage or electromagnetic fault injection, might be successful. But like the PlayStation attacks, the goal is to develop very simple tools such that the attack is easy to replicate. Sending simple logic-level signals onto the reset pin is something one can do with a complex programmable logic device (CPLD), a field-programmable gate array (FPGA), or a microcontroller.</p>
<p>And the modchips are doing exactly that. These chips “weaponize” the fault vulnerability. They use details of the power-on self-test (POST) system that reports the boot progress. By tying into the POST reporting, it’s possible to know almost exactly when to trigger the slow clock operation and <span epub:type="pagebreak" title="393" id="Page_393"/>then inject the reset glitch. Like any fault attack, the reset glitch will not have a perfect success rate. If the glitch is unsuccessful, the modchip detects it, resets the system properly, and simply tries again. This process allows loading of an unsecured binary in 30–60 seconds in most cases.</p>
<p>Again, clever preparation has turned a relatively complex target into one that can be attacked with basic electronics. In this case, rather than forcing a number of vulnerable operations to occur, the target is slowed down considerably. Later revisions of the hardware did not have the same test point but instead exposed the clock generator on the I2C bus. By tying into the I2C bus, an attacker could slow down the main CPU with similar results.</p>
<p>Having external control over the clock frequency may be possible, even for complex targets. For example, a target may use a PLL to multiply up a crystal frequency; replacing a 12 MHz crystal with a 1 MHz oscillator might make the main CPU run at 66.7 MHz instead of the targeted 800 MHz. Whether this is successful is far from a sure thing, however. The PLLs and oscillators themselves have limits (they may not operate that slowly), external parts such as DRAM will have upper and lower frequency limits (DRAM chips have minimum and maximum refresh times), and the CPU may detect frequency deviation and shut itself down to prevent attacks.</p>
<p>The Xbox 360 reset glitch shows that time spent “exploring” a target may be useful in finding vulnerabilities that are exploitable at scale. In this case, reaching a reliable fault attack combines several observations that alone might not have been an obvious attack vector: the boot stages are known to an observer in real time; a pin on the CPU allows running at a much slower speed, and short glitches on the reset pin (at least when running very slowly) do not correctly reset the chip, but instead insert faults.</p>
<h2 id="h1-278748c13-0002">Power Analysis Attacks</h2>
<p class="BodyFirst">The fault injection attacks demonstrated in the previous section were used to achieve temporary privileges beyond what the security architecture was supposed to permit (allowing loading of unsigned firmware, for example). Although fault injection can be about information disclosure through a memory dump or key disclosure through differential fault analysis, it is often about gaining privileges to then continue the attack. By comparison, power analysis is almost entirely concerned with revealing sensitive information, such as encryption keys. The difference is that a successful power analysis attack may provide you with the “keys to the kingdom.” These keys can make it impossible to discern an attacker from a legitimate owner or operator, and they may allow scaling without the further need of a hardware attack.</p>
<h3 id="h2-278748c13-0003">Philips Hue Attack</h3>
<p class="BodyFirst">The Philips Hue bulbs are smart lights that allow various settings to be controlled remotely by the owner. These lights communicate with the Zigbee Light Link (ZLL), which runs over a very constrained wireless network <span epub:type="pagebreak" title="394" id="Page_394"/>protocol (IEEE 802.15.4). Here we present part of “IoT Goes Nuclear: Creating a ZigBee Chain Reaction,” by Eyal Ronen et al. This work details recovering Philips Hue firmware encryption keys. After finding a bug, the authors also managed to bypass the “proximity test,” which these lightbulbs normally use to protect them from being disassociated from their network by an attacker more than about 1 meter away. This bug and proximity test bypass allow an attacker to create a worm that disassociates a victim bulb from the network within full Zigbee range (30–400 meters, depending on conditions) and remotely installs the wormed firmware, after which the now-infected bulb starts attacking other bulbs. Power analysis is used to compromise the (global) firmware encryption and signing key.</p>
<h4 id="h3-278748c13-0001">The Zigbee Light Link</h4>
<p class="BodyFirst">ZLL is a specific version of Zigbee (not the same as regular Zigbee or Zigbee Home Automation) that, like Zigbee, uses a low-power wireless protocol called IEEE 802.15.4. ZLL has a simple method of letting a new device, such as a bulb you just purchased, join the network.</p>
<p>This joining process relies on a fixed master key to transfer the unique network key to the new bulb, and the device will be connected to a network with the unique key. The shared master key is no longer in use in the network once the unique key is transferred, as the master key was always at risk of being leaked. The network owner would have to put the network in a mode that allows new devices to join, so new devices cannot be added without the owner’s knowledge. This explanation, however, doesn’t describe how we solve the problem of replacing a bridge that has died, or if a user needs to move a bulb from one network to another.</p>
<h4 id="h3-278748c13-0002">Bypassing Proximity Checking</h4>
<p class="BodyFirst">For scenarios where the unique network key needs to change, we come into the second portion, a special “Reset to Factory New” message, which allows someone to de-authenticate a bulb from an existing network such that it can now join a different network. To perform this step, you needed to be physically close (~1 meter range). The ZLL master key (as you might expect) was leaked, meaning anyone could send those messages.</p>
<p>The proximity check is normally done by rejecting messages less than a certain signal strength. Although it’s possible to use high-power radio transmitters to fake the radio distance and reset devices from a longer range, doing so isn’t “wormable,” as the Hue transmitter itself isn’t strong enough. A wormable solution presented itself via a firmware bug and some compatibility requirements. First, a crafted “Reset to Factory New” message is sent to the victim. It’s designed to exploit the firmware bug such that the proximity test is bypassed. After the factory reset, the victim actively starts searching for Zigbee networks. The details are in the paper; here we focus on the power analysis part of the attack.</p>
<h4 id="h3-278748c13-0003"><span epub:type="pagebreak" title="395" id="Page_395"/>Firmware Updates on Hue</h4>
<p class="BodyFirst">Now we have reached the stage where a device could be forced to join a new, attacker-controlled network, at which point you could send a firmware update request. The real question is, what is the actual format of the firmware update file and how can we send one ourselves? At this stage, we reset your vision of the attack setup and return to a legitimate Philips Hue lamp.</p>
<p>The Philips Hue lamps have the ability to perform a firmware update. By standard reverse engineering techniques, along with just looking at sample implementations of Zigbee over-the-air (OTA) update mechanisms posted as part of reference designs, we can learn how it works. When a bulb needs a firmware update, it downloads the file from the bridge device (which previously downloaded it from a remote server) into an external SPI flash memory chip. The actual OTA download can take some time (often at least an hour), as only small amounts are sent in each packet. If the network is in a busy wireless environment or the bulb is at the edge of radio range, this time can be extended considerably.</p>
<p>Rather than attempt to sniff an update from this slow OTA interface directly, we can look at what’s happening to the SPI chip, which provides us with an “update-ready” SPI flash image. If we want to trigger an update on a given bulb, we can just write this SPI image to the SPI flash chip, and the bulb will perform the actual reprogramming of itself. This programming is initiated by a byte in the SPI flash image that indicates the bulb is ready for an update. On boot, the bulb checks the value of this byte and triggers the programming, if indicated. This programming mechanism also means that if you interrupted the reprogramming phase by turning the bulb power off, on the next boot, the bulb would automatically restart the reprogramming step.</p>
<h4 id="h3-278748c13-0004">Getting Firmware Keys with Power Analysis </h4>
<p class="BodyFirst">AES-CCM is used for encrypting and authenticating the firmware file (the AES-CCM specification is available in IETF RFC 3610), so we cannot simply upload any forged image. We first need to extract the key. To do this, the SPI flash chip becomes our “input” to the encryption algorithm that we can break with power analysis. In this case, CCM makes things a little trickier than you might assume at first guess. We no longer have a direct input to each of the encryption modes, as AES-CCM uses AES-CTR mode along with AES-CBC. <a href="#figure13-3" id="figureanchor13-3">Figure 13-3</a> gives an incomplete overview of CCM, focused only on what we need for the attack.</p>
<p>The top row of AES blocks are AES in CTR mode: an increasing counter is encrypted to obtain 128-bit chunks of stream cipher (<em>CTR</em><sub><em>m</em></sub>, <span class="CodeAnnotation" aria-label="annotation8">8</span>). This is used to decrypt the ciphertext using a simple XOR operation (<span class="CodeAnnotation" aria-label="annotation9">9</span>). To create the authentication tag, the bottom row of AES blocks’ ciphertext is being XOR’d to the input of the next block (<span class="CodeAnnotation" aria-label="annotation3">3</span>, <span class="CodeAnnotation" aria-label="annotation5">5</span>), which constitutes the cipher block chaining (<em>CBC</em><sub><em>m</em></sub>, <span class="CodeAnnotation" aria-label="annotation2">2</span>, <span class="CodeAnnotation" aria-label="annotation4">4</span>). We left out some pieces of how the authentication tag is precisely calculated, but that’s irrelevant for the attack.</p>
<span epub:type="pagebreak" title="396" id="Page_396"/><figure>
<img src="image_fi/278748c13/f13003.png" alt="f13003"/>
<figcaption><p><a id="figure13-3">Figure 13-3</a>: All you need to know about AES-CCM for the attack</p></figcaption>
</figure>
<p>How do we attack CCM using power analysis? Going after AES-CTR is not an option, since we don’t know the input (<span class="CodeAnnotation" aria-label="annotation7">7</span>, because of the unknown IV), and we don’t know the output either, as that is the cipher stream, which is never accessible (<span class="CodeAnnotation" aria-label="annotation8">8</span>). On the AES-CBC, we also cannot perform a vanilla CPA; the input is the decrypted firmware (<span class="CodeAnnotation" aria-label="annotation9">9</span>, which we don’t know), and the output of the AES-CBC (<span class="CodeAnnotation" aria-label="annotation2">2</span>, <span class="CodeAnnotation" aria-label="annotation4">4</span>) is never accessible. However, Ronen et al. describe how to perform a clever key transformation (like we did in <span class="xref" itemid="xref_target_Chapter 12">Chapter 12</span>) that allows obtaining the key from the AES-CBC (<span class="CodeAnnotation" aria-label="annotation1">1</span>).</p>
<p>Let’s start at the top, with the ciphertext <em>CT</em>. We split that into 128-bit blocks, <em>CT</em><sub><em>m</em></sub>, where <em>m</em> is the block index. AES-CTR decryption is a stream cipher, and we’ll write the stream (<span class="CodeAnnotation" aria-label="annotation8">8</span>) as <em>CTR</em><sub><em>m</em></sub> = <code>AES</code>(<em>k</em>, <em>IV</em><sub><em>ctr</em></sub> || <em>m</em>), where || is concatenation of bits, so we can write the <em>PT</em> (<span class="CodeAnnotation" aria-label="annotation9">9</span>) coming out of it as <em>PT</em><sub><em>m</em></sub> = <em>CT</em><sub><em>m</em></sub> ⊕ <em>CTR</em><sub><em>m</em></sub>.</p>
<p>The <em>IV</em><sub><em>ctr</em></sub> in CCM consists of a few fields, but basically the nonce is the big unknown to us at this point. For simplicity, we’ll just say we don’t know <em>IV</em><sub><em>ctr</em></sub> (for now).</p>
<p>Next, AES-CBC is used to encrypt <em>PT</em><sub><em>m</em></sub>, generating the authentication tag. We can write output block <em>m</em> of CBC (<span class="CodeAnnotation" aria-label="annotation2">2</span>, <span class="CodeAnnotation" aria-label="annotation4">4</span>) as <em>CBC</em><sub><em>m</em></sub> = <code>AES</code>(<em>k</em>, <em>PT</em><sub><em>m</em></sub> ⊕ <em>CBC</em><sub><em>m–1</em></sub>), with block <em>m</em> = <em>0</em> defined using <em>CBC</em><sub><em>-1</em></sub> = <em>IV</em><sub><em>mac</em></sub>. We can substitute <em>PT</em><sub><em>m</em></sub><em> </em>to get <em>CBC</em><sub><em>m</em></sub> = <code>AES</code> (<em>k</em>, <em>CT</em><sub><em>m</em></sub> ⊕ <em>CTR</em><sub><em>m</em></sub> ⊕ <em>CBC</em><sub><em>m–1</em></sub>).</p>
<p>So far so good, although everything in that formula is unknown except for the <em>CT</em>. In a regular AES-ECB power analysis attack, we assume we at least know the plaintext or the ciphertext, and thus we can recover <em>k</em>. The problem with any of the preceding AES functions is that we don’t know the input and we don’t know the output.</p>
<p><span epub:type="pagebreak" title="397" id="Page_397"/>The cleverness comes in at this point. In AES, <code>AddRoundKey</code>(<em>k, p</em>) is just <em>k</em> ⊕ <em>p</em>, meaning we can rewrite <code>AddRoundKey</code>(<em>k</em>, <em>p</em> ⊕ <em>d</em>) = <code>AddRoundKey</code>(<em>k</em> ⊕ <em>p</em>, <em>d</em>). This means if <em>p</em> is unknown and fixed, we can just consider it to be part of a transformed key <em>k</em> ⊕ <em>p</em>. If we control <em>d</em>, we can do a CPA attack to recover <em>k</em> ⊕ <em>p</em>.</p>
<p>In our CCM case, we can’t attack <code>AddRoundKey</code>(<em>k</em>, <em>CT</em><sub><em>m</em></sub> ⊕ <em>CTR</em><sub><em>m</em></sub> ⊕ <em>CBC</em><sub><em>m–1</em></sub>), but we can attack <code>AddRoundKey</code>(<em>k</em> ⊕ <em>CTR</em><sub><em>m</em></sub> ⊕ <em>CBC</em><sub><em>m–1</em></sub>, <em>CT</em><sub><em>m</em></sub>), because we control <em>CT</em><sub><em>m</em></sub>! Assuming the target leaks, we can use <em>CPA</em><sub><em>a</em></sub> (see <a href="#figure13-4" id="figureanchor13-4">Figure 13-4</a>) to find the transformed key <em>k</em> ⊕ <em>CTR</em><sub><em>m</em></sub> ⊕ <em>CBC</em><sub><em>m-1</em></sub>, which in itself isn’t useful. This transformed key allows us to calculate all intermediate data until the second <code>AddRoundKey</code>(<em>k</em>, <em>p′</em>). This second <code>AddRoundKey</code> again uses <em>k</em>, which we don’t know. However, since we know the transformed round key and <em>CT</em>, we can calculate <em>p′</em>. We can now apply a vanilla <em>CPA</em><sub><em>b</em></sub> attack using <em>p′</em> to recover <em>k</em> from the second round of AES.</p>
<figure>
<img src="image_fi/278748c13/f13004.png" alt="f13004"/>
<figcaption><p><a id="figure13-4">Figure 13-4</a>: Two CPA attacks: one on the transformed key and one on the regular key</p></figcaption>
</figure>
<p>Once we have <em>k</em> (<span class="CodeAnnotation" aria-label="annotation1">1</span> in <a href="#figure13-3">Figure 13-3</a>), we have a few more steps to go. Note that we still don’t have <em>PT</em> or any of the IVs. However, <em>k</em> allows us to finish the “modified” AES calculation of <a href="#figure13-4">Figure 13-4</a> to obtain the <em>CBC</em><sub><em>m</em></sub> blocks <span class="CodeAnnotation" aria-label="annotation2">2</span>. This block we can now decrypt to get <em>CT</em><sub><em>m</em></sub> ⊕ <em>CTR</em><sub><em>m</em></sub> ⊕ <em>CBC</em><sub><em>m–1 </em></sub><span class="CodeAnnotation" aria-label="annotation3">3</span>, and because we know <em>CT</em><sub><em>m</em></sub>, we know <em>CTR</em><sub><em>m</em></sub> ⊕ <em>CBC</em><sub><em>m–1</em></sub>. </p>
<p>For the final blow, we can use the same attack on the subsequent block <em>m+1</em>. This allows us to find <em>CBC</em><sub><em>m+1</em></sub> <span class="CodeAnnotation" aria-label="annotation4">4</span> and <em>CT</em><sub><em>m+1</em></sub> ⊕ <em>CTR</em><sub><em>m+1</em></sub><sub> </sub>⊕ <em>CBC</em><sub><em>m</em></sub> <span class="CodeAnnotation" aria-label="annotation5">5</span>. Since we already knew <em>CT</em><sub><em>m+1</em></sub> and <em>CBC</em><sub><em>m</em></sub> from the previous attack, we can XOR it out and calculate <em>CTR</em><sub><em>m+1</em></sub> <span class="CodeAnnotation" aria-label="annotation6">6</span>, which is equal to <code>AES</code>(<em>k</em>, <em>IV</em><sub><em>ctr</em></sub> || <em>m+1</em>). Since we know <em>k</em>, we can decrypt this to find <em>IV</em><sub><em>ctr</em></sub> <span class="CodeAnnotation" aria-label="annotation7">7</span>, and we subsequently can calculate <em>CTR</em><sub><em>m</em></sub> for any <em>m</em> <span class="CodeAnnotation" aria-label="annotation8">8</span>, which finally allows us to decrypt <em>PT</em><sub><em>m</em></sub> = <em>CTR</em><sub><em>m</em></sub> ⊕ <em>CT</em><sub><em>m </em></sub><span class="CodeAnnotation" aria-label="annotation9">9</span>!</p>
<p>We now have the firmware key and plaintext; therefore, we have easy access to forge firmware. Using the attack that allows us to disassociate a Hue from its network and upload new firmware, we could create a worm that propagates throughout a city. In the paper, the authors calculate that <span epub:type="pagebreak" title="398" id="Page_398"/>for a city like Paris, about 15,000 Hue lights need to be present for the worm to take over all of the Hue lights in the city.</p>
<p>This attack combines a scalable/real-life attack, hardware reverse engineering, wireless communication, protocol abuse, exploiting a firmware bug, <em>and</em> a power analysis attack on CCM. Add whipped cream, and it would be the perfect dessert.</p>
<h2 id="h1-278748c13-0003">Summary</h2>
<p class="BodyFirst">In this chapter, we described how the PlayStation 3, Xbox 360, and Philips Hue lights were broken using hardware attacks. Especially in systems that have a small density of software flaws, hardware attacks can be a critical step leading to compromise.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="box">
<h2>References</h2>
<p class="BoxBodyFirst">To inspire you to use your newfound skills for good on any device you wish, we present a number of our favorite real-life attacks from both academia and hobby hackers, on SoCs, FPGAs, and microcontrollers, proprietary and standard crypto, and from contactless smart cards to hardware wallets, door openers, and gaming systems. All this material is available with a quick online search.</p>
<p class="BoxListHead"><b>Andrew “bunnie” Huang:<em> </em>Hacking the Xbox</b></p>
<ol class="none">
<li>A perfect example showing what is possible when the threat model of the designer vastly underestimates the capabilities of an attacker. See “bunnie’s adventures hacking the Xbox” blog and the website associated with the book.</li>
</ol>
<p class="BoxListHead"><b>GliGli and Tiros (primarily credited): Xbox 360 Hack</b></p>
<ol class="none">
<li>Fault injection attack on the reset line of the Xbox 360 SoC, creating a faulty <code>memcpy()</code> result that allows arbitrary firmware to be loaded and thereby run homebrewed and pirated games.</li>
</ol>
<p class="BoxListHead"><b>George Hotz (GeoHot): PS3 Glitching</b></p>
<ol class="none">
<li>Fault injection attack on the memory bus of the PS3, creating faulty page tables that allow a full dump of the hypervisor memory. This in turn was used to create a software exploit and run homebrewed and pirated games.</li>
</ol>
<p class="BoxListHead"><b>Yifan Lu: “Attacking Hardware AES with DFA”</b></p>
<ol class="none">
<li>The PlayStation Vita’s AES-256 is glitched, producing faulty results that allows a DFA attack; all 30 master keys are recovered.</li>
</ol>
<p class="BoxListHead"><b>Micah Scott: “Glitchy Descriptor Firmware Grab – scanlime:015”</b></p>
<ol class="none">
<li>Fault injection on Wacom CTE-450, glitching USB descriptor transfer that leads to full ROM dump.</li>
</ol>
<p class="BoxListHead"><b><span epub:type="pagebreak" title="399" id="Page_399"/>Josep Balasch, Benedikt Gierlichs, Roel Verdult, Lejla Batina, and Ingrid Verbauwhede: “Power Analysis of Atmel CryptoMemory—Recovering Keys from Secure EEPROMs”</b></p>
<ol class="none">
<li>Proprietary cipher with 64-bit key in Atmel CryptoMemory (AT88SCxxxxC) broken by using CPA and circumventing the attack counter update by resetting the chip at the right time. This allows full read/write access to the memory contents.</li>
</ol>
<p class="BoxListHead"><b>David Oswald and Christof Paar: “Breaking Mifare DESFire MF3ICD40: Power Analysis and Templates in the Real World”</b></p>
<ol class="none">
<li>The contactless Mifare DESFire MF3ICD40 is broken by using template attacks on 3DES, leading to full read/write access to the card’s memory.</li>
</ol>
<p class="BoxListHead"><b>David Oswald: “Side-Channel Attacks on SHA-1-based Product Authentication ICs”</b></p>
<ol class="none">
<li>The SHA-1-based authentication on the Maxim DS2432 and DS28E01 is broken using CPA, allowing for spoofing the authentication.</li>
</ol>
<p class="BoxListHead"><b>Thomas Eisenbarth, Timo Kasper, Amir Moradi, Christof Paar, Mahmoud Salmasizadeh, and Mohammad T. Manzuri Shalmani: “Physical Cryptanalysis of KeeLoq Code Hopping Applications”</b></p>
<ol class="none">
<li>CPA attack on Microchip HCSXXX KeeLoq crypto, allowing cloning of garage door remote controls with only 10 power traces.</li>
</ol>
<p class="BoxListHead"><b>David Oswald, Daehyun Strobel, Falk Schellenberg, Timo Kasper, and Christof Paar: “When Reverse-Engineering Meets Side-Channel Analysis—Digital Lockpicking in Practice”</b></p>
<ol class="none">
<li>A PIC microcontroller-based SimonsVoss door lock is reverse engineered, after which a CPA attack is performed on the proprietary crypto, yielding the system key. This allows cloning all transponders in a SimonsVoss installation.</li>
</ol>
<p class="BoxListHead"><b>Amir Moradi and Tobias Schneider: “Improved Side-Channel Analysis Attacks on Xilinx Bitstream Encryption of 5, 6, and 7 Series”</b></p>
<ol class="none">
<li>Recovery of the AES bitstream encryption key of various Xilinx FPGAs by using CPA, allowing decryption of the bitstreams.</li>
</ol>
<p class="BoxListHead"><b>David Oswald, Bastian Richter, and Christof Paar: “Side-Channel Attacks on the Yubikey 2 One-Time Password Generator”</b></p>
<ol class="none">
<li>One hour of access to a Yubikey 2 is sufficient to extract the 128-bit AES key and spoof one-time passwords (OTPs).</li>
</ol>
<p class="BoxListHead"><b>Amir Moradi and Gesine Hinterwälder: “Side-Channel Security Analysis of Ultra-Low-Power FRAM-based MCUs”</b></p>
<ol class="none">
<li>Low-power AES accelerator on the TI MSP430FR59xx is broken using CPA.</li>
</ol>
<p class="BoxListHead"><b><span epub:type="pagebreak" title="400" id="Page_400"/>Niek Timmers and Cristofaro Mune: “Escalating Privileges in Linux Using Voltage Fault Injection”</b></p>
<ol class="none">
<li>An ARM Cortex A9 Linux-based system is the target of fault injection, and several ways are shown that escalate normal user privileges to kernel/root privileges.</li>
</ol>
<p class="BoxListHead"><b>Niek Timmers, Albert Spruyt, and Marc Witteman: “Controlling PC on ARM Using Fault Injection”</b></p>
<ol class="none">
<li>A fault injection modified the opcode of an ARM memory load instruction, overwriting the program counter (PC) with attacker-controlled data and leading to arbitrary code execution.</li>
</ol>
<p class="BoxListHead"><b>Nils Wiersma and Ramiro Pareja: “Safety ≠ Security: A Security Assessment of the Resilience Against Fault Injection Attacks in ASIL-D Certified Microcontrollers”</b></p>
<ol class="none">
<li>ASIL-D is the highest safety rating in ISO 26262, which is used in automotive applications. Two ASIL-D-rated microcontrollers are successfully faulted, demonstrating lockstep is not a sufficient countermeasure against fault injection (FI).</li>
</ol>
<p class="BoxListHead"><b>Colin O’Flynn: “MINimum Failure: Stealing Bitcoins with Electromagnetic Fault Injection”</b></p>
<ol class="none">
<li>Colin uses EMFI to glitch the Trezor One hardware wallet and read out the recovery seed, allowing cloning of the wallet.</li>
</ol>
<p class="BoxListHead"><b>Lennert Wouters, Jan Van den Herrewegen, Flavio D. Garcia, David Oswald, Benedikt Gierlichs, and Bart Preneel: “Dismantling DST80-based Immobiliser Systems”</b></p>
<ol class="none">
<li>Part of a series of work looking at automotive security, this work shows how several different attacks (glitching, power analysis) can be used to fully reverse engineer and break system security.</li>
</ol>
<p class="BoxListHead"><b>Victor Lomne and Thomas Roche: “A Side Journey to Titan: Side-Channel Attack on the Google Titan Security Key”</b></p>
<ol class="none">
<li>The authors study an open JavaCard platform that has the same cryptographic ECDSA implementation as the Google Titan security key, find a side-channel leak, and use that to recover the long-term ECDSA private key linked to the key’s FIDO U2F account.</li>
</ol>
<p class="BoxListHead"><b>Thomas Roth (StackSmashing): “How the Apple AirTags Were Hacked” (video)</b></p>
<ol class="none">
<li>The author uses a fault injection weakness known in nRF52 series to re-enable debug access and then reprograms the firmware to Rickroll any user that uses NFC to connect to the AirTag.</li>
</ol>
<p class="BoxListHead"><b>LimitedResults: “Enter the EFM32 Gecko”</b></p>
<ol class="none">
<li>The author builds their own EMFI setup (called “Der Injektor”) to re-enable debug access on an EFM32WG.<em> </em></li>
</ol><div class="bottom hr"><hr/></div>
</section>
</aside>
</section>
</body></html>