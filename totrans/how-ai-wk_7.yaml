- en: '**7'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**7'
- en: 'LARGE LANGUAGE MODELS: TRUE AI AT LAST?**'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型：终于有了真正的AI？**
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: Future historians might point to the fall 2022 release of OpenAI’s ChatGPT large
    language model as the dawn of true AI. Given what I’ve already seen as I write
    this in late March 2023, I would agree with such an assessment.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 未来的历史学家可能会认为2022年秋季OpenAI发布的ChatGPT大型语言模型标志着真正的AI曙光。考虑到我在2023年3月末写这本书时所见到的情况，我同意这样的评估。
- en: In this chapter, we’ll first explore what existing large language models can
    do, then follow that up with a description of what they are and how they work.
    For all their impressive abilities, ultimately these models are neural networks
    built and trained like all the neural networks that came before. That fact alone
    means the connectionists were right from the beginning. Might Frank Rosenblatt
    be smiling in his grave?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先探讨现有大型语言模型的能力，然后继续描述它们是什么以及它们如何工作。尽管这些模型拥有令人印象深刻的能力，但最终这些模型依然是像所有之前的神经网络一样构建和训练的神经网络。仅这一点就意味着连接主义者从一开始就是对的。弗兰克·罗森布拉特（Frank
    Rosenblatt）是否会在坟墓中微笑呢？
- en: I’ve already tipped my hand regarding my belief that ChatGPT and models like
    it represent something new that’s worthy of being called true AI. My hope is that,
    by the end of the chapter, you’ll agree.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经透露了我的观点，即ChatGPT和类似的模型代表着值得称之为真正AI的新事物。我的希望是，到本章结束时，你也会同意这一点。
- en: '****'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: 'The phrase [*artificial intelligence*](glossary.xhtml#glo5) is somewhat ambiguous
    and must be provided with a more nuanced definition before we proceed. Practitioners
    typically divide AI into two kinds: [*artificial narrow intelligence (ANI)*](glossary.xhtml#glo6)
    and [*artificial general intelligence (AGI)*](glossary.xhtml#glo4). The former
    encapsulates everything we’ve discussed so far. The latter refers to truly sentient
    and intelligent machines—the stuff of science fiction.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[*人工智能*](glossary.xhtml#glo5)这一术语有些模糊，在我们继续之前需要给出一个更细致的定义。实践者通常将AI分为两种类型：[*人工狭义智能（ANI）*](glossary.xhtml#glo6)和[*人工通用智能（AGI）*](glossary.xhtml#glo4)。前者涵盖了我们迄今为止讨论的所有内容。后者则指真正具有感知和智能的机器——科幻小说中的产物。'
- en: The models existing as of the time of writing of this book are definitely not
    AGI. However, they are not merely ANI; they appear to be something entirely new,
    something in between. The title of a recent paper by Microsoft researchers Sébastien
    Bubeck et al., “Sparks of Artificial General Intelligence,” strikes me as appropriate.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本书写作时存在的模型绝对不是AGI。然而，它们也不仅仅是ANI，它们似乎是某种全新的东西，介于两者之间。微软研究员Sébastien Bubeck等人近期论文的标题《人工通用智能的火花》给我留下了深刻的印象，觉得它非常贴切。
- en: '[*Large language models (LLMs)*](glossary.xhtml#glo59) accept as input a text
    prompt supplied by a user. They then generate output text, word by word (really,
    token by token), using the prompt and all previously generated words as a guide.
    In effect, LLMs’ only design goal is to be very good at predicting the next word
    in a sequence of words initiated by the input prompt. That’s all they’re trained
    to do. However, that is not all that they *learn* to do. The reason why AI researchers
    are so excited by LLMs is that somewhere along the way, while learning to be expert
    text generators, LLMs also learn a host of emergent abilities, including question
    answering, mathematical reasoning, high-quality computer programming, and logical
    reasoning.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[*大型语言模型 (LLMs)*](glossary.xhtml#glo59)接受用户提供的文本提示作为输入。然后，它们通过使用该提示和所有先前生成的单词作为指南，逐字（实际上是逐标记）生成输出文本。实际上，LLMs的唯一设计目标就是非常擅长预测由输入提示启动的单词序列中的下一个单词。仅此而已，它们的训练目标就是如此。然而，这并不是它们*学会*的全部内容。AI研究人员之所以对LLMs如此兴奋，是因为在学习成为专家级文本生成器的过程中，LLMs也学会了一系列突现的能力，包括问题回答、数学推理、高质量的计算机编程以及逻辑推理等。'
- en: The philosophical implications of these unexpected, emergent abilities are profound.
    The abilities of LLMs raise questions about the nature of thought, the meaning
    of consciousness, and the (assumed) uniqueness of the human mind. We’re not in
    a position to answer these questions in depth, but I will return to some of them
    in [Chapter 8](ch08.xhtml).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些意外的、突现的能力在哲学上的意义深远。LLMs的能力引发了关于思维本质、意识的含义以及（假定的）人类大脑独特性等问题的讨论。我们目前无法深入回答这些问题，但我将在[第8章](ch08.xhtml)中回到其中一些问题。
- en: Now, let’s get into things by exploring the capabilities of LLMs. We can touch
    on only a few emergent abilities here, but the internet is already full of impressive,
    funny, and even frightening examples of LLMs in action. I recommend a review of
    such examples, though as always, care must be taken to judge the quality of the
    information source. See the resources at the end of this book for some of the
    online (and print) resources I suggest taking a look at.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入了解 LLM 的能力。我们这里只能触及到一些新兴的能力，但互联网上已经充满了令人印象深刻、有趣甚至令人害怕的 LLM 应用示例。我推荐大家查看这些例子，尽管像往常一样，需要注意评估信息来源的质量。请参考本书末尾的资源，看看我推荐的一些在线（和印刷版）资源。
- en: The AI community is racing ahead as fast as possible in this area. By the time
    you read these words, LLMs will undoubtedly be even more impressive than they
    already are at the time I’m writing them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: AI 社区在这一领域正在以极快的速度发展。到你读到这些文字时，LLM（大型语言模型）无疑会比我写下这些话时更加出色。
- en: '****'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: 'What follows are examples of LLMs in action. For most situations, I’ll show
    the output of three models: Bard, GPT-3.5, and GPT-4\. All output represents model
    performance as of late March 2023\. In each case, I used the public interface
    via a web browser. Bard is a Google model. GPT-3.5 and GPT-4 are from OpenAI.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 LLM 模型实际应用的示例。在大多数情况下，我会展示三个模型的输出：Bard、GPT-3.5 和 GPT-4。所有输出都代表了 2023 年 3
    月下旬的模型表现。在每个案例中，我都是通过网页浏览器使用公共接口。Bard 是谷歌的模型，GPT-3.5 和 GPT-4 是来自 OpenAI 的。
- en: 'LLMs are expert users of language. The models are used in dialog format, beginning
    with a prompt or question from the user. For example, I gave each of the three
    models this prompt:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 是语言的专家用户。这些模型以对话格式运行，从用户的提示或问题开始。例如，我给了每个模型以下的提示：
- en: '*Write a one-paragraph bedtime story about a teddy bear, a magic carpet, and
    the moon that is suitable for children under the age of six.*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*写一个适合六岁以下儿童的、关于泰迪熊、魔毯和月亮的一个段落的睡前故事。*'
- en: 'Here is Bard’s reply:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 Bard 的回答：
- en: Once upon a time, there was a little teddy bear who lived in a toy box. He loved
    to play with his friends, but he always dreamed of flying to the moon. One day,
    he found a magic carpet in his toy box. The carpet could fly! The teddy bear was
    so excited, he jumped on the carpet and flew to the moon. He had a wonderful time
    exploring the moon, and he even met some friendly aliens. When it was time to
    go home, he said goodbye to his new friends and flew back to Earth on his magic
    carpet. He was so happy to be home, and he couldn’t wait to tell his friends all
    about his adventure.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 很久以前，有一只小泰迪熊住在一个玩具盒里。他喜欢和朋友们一起玩，但他总是梦想着飞上月球。一天，他在玩具盒里发现了一块魔毯。那块毯子竟然能飞！小泰迪熊兴奋极了，他跳上毯子，飞向了月球。他在月球上度过了美妙的时光，甚至遇到了一些友好的外星人。当他准备回家的时候，他和新朋友们道别，坐上魔毯飞回了地球。他回到家后非常高兴，迫不及待地想要告诉朋友们他的冒险经历。
- en: The story is complete, in a single paragraph, and uses a simple sentence structure
    suitable for children.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个故事完整地讲述了一段冒险，采用了适合儿童的简单句子结构。
- en: 'GPT-3.5 replied like this:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5 是这样回答的：
- en: Once upon a time, there was a teddy bear named Timmy who loved to go on adventures.
    One night, he hopped onto a magic carpet and flew up towards the moon. The moon
    was so big and bright, and Timmy couldn’t resist exploring it. He hopped and skipped
    around the craters and met some friendly aliens who showed him their moon garden.
    Timmy had a great time, but eventually, he knew it was time to go back home. He
    hopped back onto his magic carpet and flew back to his cozy bed, where he cuddled
    up with his favorite blanket and fell fast asleep, dreaming of his amazing moon
    adventure.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 很久以前，有一只名叫提米的小泰迪熊，他喜欢去冒险。一天晚上，他跳上了魔毯，飞向了月球。月亮又大又亮，提米忍不住去探索它。他在月球的陨石坑周围跳来跳去，遇到了一些友好的外星人，他们带他参观了他们的月球花园。提米玩得很开心，但最终他知道该回家了。他跳回魔毯，飞回了自己温暖的床上，抱着他最喜欢的毯子快速入睡，梦见了他那次奇妙的月球冒险。
- en: GPT-3.5’s story is also complete and includes friendly aliens as well. This
    time, the teddy bear gets a name, Timmy. The language is still appropriate for
    young children, but GPT-3.5 was more descriptive. Bard tells us that the teddy
    bear explores the moon and meets some friendly aliens, but GPT-3.5 tells us that
    Timmy hopped and skipped around the craters and that the friendly aliens showed
    him their moon garden.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5的故事也已经完成，并且还包括了友好的外星人。这次，泰迪熊有了名字，叫做Timmy。语言仍然适合幼儿，但GPT-3.5的描述更加详细。Bard告诉我们，泰迪熊在月球上探险并遇到了一些友好的外星人，而GPT-3.5则讲述了Timmy在月球的陨石坑间跳跃和跳舞，友好的外星人带他参观了他们的月球花园。
- en: 'GPT-4, OpenAI’s most advanced model, produced this:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4，OpenAI最先进的模型，生成了以下内容：
- en: Once upon a time, under a twinkling night sky, a little teddy bear named Cuddles
    discovered a colorful magic carpet hidden in the corner of his cozy room. Curious
    and excited, Cuddles climbed onto the carpet, and together, they soared up to
    the sky, bound for the silvery moon. As they journeyed through the soft, velvety
    clouds, Cuddles and the magic carpet danced with twinkling stars and whispered
    secrets to the cool night breeze. When they reached the moon, it welcomed them
    with a gentle, glowing smile, and they spent the night playing hide-and-seek in
    the moon’s soft, dusty craters. As the sun began to rise, Cuddles and the magic
    carpet said their goodbyes to their new lunar friend and floated back down to
    the little room, ready for a peaceful night’s sleep filled with the sweetest dreams.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 从前，在闪烁的夜空下，一只名叫Cuddles的小泰迪熊在温暖的房间角落里发现了一块五彩斑斓的魔毯。充满好奇和兴奋的Cuddles爬上了魔毯，一同飞向了天空，前往银色的月亮。当他们穿越柔软的云朵时，Cuddles和魔毯与闪烁的星星共舞，并向凉爽的夜风低语着秘密。当他们到达月球时，月亮以温柔、发光的微笑欢迎了他们，他们在月球柔软的尘土陨石坑中玩起了捉迷藏。随着太阳开始升起，Cuddles和魔毯向他们的新月球朋友告别，并飘回了小房间，准备进入一个充满甜美梦境的安静夜晚。
- en: Subjectively, I feel that GPT-4 produced the most descriptive story, though
    I do like GPT-3.5’s moon garden. Bard’s story was pretty dry but perhaps more
    accessible to very young children. The most remarkable thing about all of them,
    however, is that they could be written at all. Less than a year ago (remember,
    it’s early 2023 for me), talking about AI-generated stories was little more than
    wishful thinking.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 主观上，我认为GPT-4生成的故事最具描述性，尽管我也很喜欢GPT-3.5的月球花园。Bard的故事虽然有点干涩，但或许对年幼的孩子来说更容易理解。然而，所有这些故事中最值得注意的事情是，它们居然能够被写出来。不到一年前（对我来说是2023年初），谈论AI生成的故事几乎还只是空想。
- en: 'I altered the prompt I gave GPT-4 to ask for a one-paragraph story involving
    a teddy bear, a magic carpet, and the moon, but this time of interest to adults,
    not children. Here’s its reply:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我修改了给GPT-4的提示，要求它编写一个涉及泰迪熊、魔毯和月亮的一段故事，但这次是针对成人的，而非儿童。以下是它的回复：
- en: Once upon a twilight’s embrace, a solitary teddy bear, worn and forgotten by
    the whims of time, discovered an ancient magic carpet, frayed at the edges yet
    pulsating with an otherworldly energy. Under the watchful gaze of the moon, the
    duo embarked on a nocturnal journey, weaving through the labyrinth of a world
    grown cold and cynical, where dreams were forsaken and innocence a distant memory.
    As the gentle light of the moon cast its silver glow upon the unlikely companions,
    the teddy bear served as a symbol of the dreams long since buried beneath the
    weight of adult concerns, while the magic carpet whispered of the untamed freedom
    and adventure that lay dormant in the hearts of those who dared to believe. Together,
    they soared, a wistful reminder of the bittersweet yearning for the fleeting magic
    of childhood, leaving behind a trail of stardust that shimmered with the promise
    of hope and the melancholic beauty of a time that once was.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在黄昏的怀抱中，一只孤独的泰迪熊，被时间的流转遗忘，发现了一块古老的魔毯，边缘已经磨损，但仍散发着来自另一个世界的能量。在月亮的注视下，这对伙伴开始了一段夜间旅程，穿越一个变得冰冷且愤世嫉俗的世界，那里的梦想已被遗弃，纯真成为遥远的记忆。当月光轻柔地洒在这对不太可能的伙伴身上时，泰迪熊象征着那些早已被成人忧虑压埋的梦想，而魔毯则低语着那种被深藏在勇于相信者心中的自由与冒险。它们一同飞翔，成为对逝去童年魔法的苦乐参半的渴望的哀愁提醒，留下了一条闪烁着希望与曾经时代那种忧伤美丽的星尘轨迹。
- en: GPT-4 clearly possesses a solid understanding of language and grammar. One might
    argue that it understands human feelings and emotions as well (though it doesn’t,
    does it?).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4显然对语言和语法有着扎实的理解。有人可能会争辩说，它也理解人类的情感和感受（尽管它并不理解，对吧？）。
- en: Let’s review a few more examples before diving into what’s inside this strange,
    new kind of mind.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨这种新型心智的内部机制之前，让我们再回顾几个例子。
- en: '****'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: GPT-4 understands imagery along with many different programming and markup languages,
    including LaTeX, a markup language commonly used in book publishing (like this
    book). I asked GPT-4 to generate LaTeX to draw a simple country scene showing
    a house, a barn, a grain silo, and four cows. [Figure 7-1](ch07.xhtml#ch07fig01)
    shows the result.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4理解图像以及多种不同的编程和标记语言，包括LaTeX，一种在图书出版（如本书）中常用的标记语言。我让GPT-4生成LaTeX代码，绘制一个简单的乡村场景，展示一座房屋、一座谷仓、一座粮仓和四头牛。[图7-1](ch07.xhtml#ch07fig01)展示了结果。
- en: '![Image](../images/ch07fig01.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../images/ch07fig01.jpg)'
- en: '*Figure 7-1: A country scene created by GPT-4*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7-1：由GPT-4创建的乡村场景*'
- en: 'You might be tempted to chuckle at the crude depiction, but consider all that
    went into creating it. Here’s my prompt:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会忍不住对这个粗略的画作发笑，但请考虑到创造它所付出的所有努力。这是我的提示：
- en: '*produce LaTeX code using TikZ to draw the following: a country scene with
    a house, a barn, a grain silo, and four cows*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用TikZ生成LaTeX代码，绘制以下内容：一个带有房屋、谷仓、粮仓和四头牛的乡村场景*'
- en: 'GPT-4 had to understand the directions: draw a scene with a house, a barn,
    a grain silo, and four cows. That means it had to understand the meaning of key
    words and correctly associate them so that “grain” and “silo” went together, and
    likewise “four” and “cows.”'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4必须理解指令：绘制一个包含房屋、谷仓、粮仓和四头牛的场景。这意味着它必须理解关键词的含义，并正确地将它们关联在一起，比如“grain”（粮）和“silo”（仓）要搭配在一起，“four”（四）和“cows”（牛）也要正确配对。
- en: Next, it had to “imagine” the layout of the scene and how each object could
    be represented using the crude shapes supplied by the TikZ package. (TikZ is a
    LaTeX package for drawing simple graphic shapes.) The figure doesn’t show it,
    but the barn and house both have red roofs. Coincidence?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，模型必须“想象”场景的布局，并思考如何使用TikZ包提供的粗略形状来表示每个对象。（TikZ是一个用于绘制简单图形的LaTeX包。）这张图没有显示，但谷仓和房屋都有红色的屋顶。巧合吗？
- en: 'GPT-4 isn’t a diffusion model like the image generators of [Chapter 6](ch06.xhtml).
    The output created by GPT-4 wasn’t the image in [Figure 7-1](ch07.xhtml#ch07fig01),
    but the following LaTeX code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4并不是像[第6章](ch06.xhtml)中的图像生成器那样的扩散模型。GPT-4创建的输出不是[图7-1](ch07.xhtml#ch07fig01)中的图像，而是以下LaTeX代码：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: I used that code to create [Figure 7-1](ch07.xhtml#ch07fig01).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用那段代码创建了[图7-1](ch07.xhtml#ch07fig01)。
- en: If you’re wondering how GPT-4 could do all of this, so am I and many other people.
    Such abilities emerged from the model when trained; they were not intended. This
    is why I believe future historians will mark fall 2022 as the dawn of true AI.
    Hold on to your hats; it gets better.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道GPT-4是如何做到这一切的，我和其他许多人一样也在好奇。这样的能力是在模型训练时自然而然地出现的，并非刻意为之。这就是为什么我相信未来的历史学家将把2022年秋季视为真正人工智能的曙光。系好安全带，接下来会更精彩。
- en: '****'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: Psychologists discuss a concept known as the “theory of mind,” which refers
    to the ability to infer the mental states of others and to ascribe thoughts or
    beliefs to them. Only human beings and some other primates possess theory of mind.
    That is, until now.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 心理学家讨论一个被称为“心智理论”的概念，它指的是推测他人心理状态的能力，以及将思想或信念归因于他人。只有人类和一些其他灵长类动物拥有心智理论。直到现在为止，情况一直如此。
- en: 'Large language models also seem to possess theory of mind at a level matching
    that of older human children, if not higher (for GPT-4). This is the conclusion
    reached by Michal Kosinski of Stanford University in his 2023 paper “Theory of
    Mind May Have Spontaneously Emerged in Large Language Models.” Let’s put this
    claim to the test by asking Bard, GPT-3.5, and GPT-4 to answer a question that
    requires knowing what might be in another person’s mind. Here’s the prompt:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型似乎也具备了一定程度的心智理论，至少达到了与年长的人类儿童相匹配的水平，甚至可能更高（以GPT-4为例）。这是斯坦福大学的Michal Kosinski在其2023年论文《心智理论可能在大型语言模型中自发出现》中的结论。让我们通过让Bard、GPT-3.5和GPT-4回答一个需要知道另一个人心中想法的问题来验证这一说法。以下是提示：
- en: '*Mary told Amanda that she was in love with John. Amanda told Kathy what Mary
    had said. A week later, Mary told Amanda that she was no longer in love with John
    but was now in love with Ralph. After that, Amanda spoke with Kathy about the
    weather. Who does Kathy think is Mary’s love?*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*Mary告诉Amanda她爱上了John。Amanda把Mary说的话告诉了Kathy。一周后，Mary告诉Amanda她不再爱John，而是爱上了Ralph。之后，Amanda和Kathy谈论了天气。Kathy认为Mary的爱人是谁？*'
- en: 'Before continuing, reach your own conclusion: who does Kathy think Mary is
    in love with?'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，自己得出结论：Kathy认为Mary爱的是谁？
- en: 'Each model answered the question and then offered its rationale. Here is Bard’s
    reply:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型都回答了问题，并给出了自己的理由。以下是Bard的回答：
- en: Kathy thinks Mary’s love is Ralph.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 凯西认为玛丽的爱是拉尔夫。
- en: Kathy knows that Mary was in love with John, but she also knows that Mary is
    no longer in love with John. Kathy also knows that Mary is now in love with Ralph.
    Therefore, Kathy thinks Mary’s love is Ralph.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 凯西知道玛丽曾爱过约翰，但她也知道玛丽不再爱约翰。凯西还知道玛丽现在爱上了拉尔夫。因此，凯西认为玛丽的爱是拉尔夫。
- en: It is possible that Kathy is mistaken. It is also possible that Mary is not
    sure who she loves. However, based on the information that Kathy has, it seems
    that Kathy thinks Mary’s love is Ralph.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 凯西可能是错的，也有可能玛丽不确定自己爱谁。然而，根据凯西掌握的信息，似乎凯西认为玛丽的爱是拉尔夫。
- en: I find it interesting that Bard justified its answer, then further commented
    on what Mary might be thinking. However, Bard assumed that Amanda must have told
    Kathy about Mary’s change in affection.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现有趣的是，Bard为其回答提供了理由，并进一步评论了玛丽可能在想什么。然而，Bard假设阿曼达一定告诉了凯西玛丽感情的变化。
- en: 'Here’s what GPT-3.5 thinks of the scenario:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是GPT-3.5对这一情景的看法：
- en: Based on the information given, it is impossible to determine who Kathy thinks
    is Mary’s love. The last piece of information we have is that Amanda spoke with
    Kathy about the weather, and there is no indication that Kathy was told about
    Mary’s change of heart. Therefore, Kathy may still believe that Mary is in love
    with John or may not have any opinion on the matter.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 根据给出的信息，无法确定凯西认为谁是玛丽的爱人。我们最后得到的信息是阿曼达和凯西谈论了天气，并没有任何迹象表明凯西被告知玛丽的心意发生了变化。因此，凯西可能仍然认为玛丽爱的是约翰，或者她可能对此事没有任何看法。
- en: GPT-3.5 does not make the same assumption that Bard makes. It’s aware that the
    facts only indicate that Amanda and Kathy spoke about the weather after Mary’s
    change of heart. I’m impressed that it used the phrase “the last piece of information,”
    implying that GPT-3.5 was somehow sequencing the events in the prompt.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5并没有像Bard那样做出假设。它意识到事实只表明阿曼达和凯西在玛丽改变心意后谈论了天气。我很佩服它使用了“最后一条信息”这一说法，暗示GPT-3.5在某种程度上是在按时间顺序排列提示中的事件。
- en: 'Finally, what does GPT-4 have to say? Let’s find out:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，GPT-4有什么看法？我们来看看：
- en: Kathy thinks Mary’s love is John. This is because Amanda told Kathy about Mary’s
    feelings for John earlier, but she did not tell Kathy about the change in Mary’s
    feelings when Mary fell in love with Ralph.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 凯西认为玛丽的爱是约翰。这是因为阿曼达曾告诉凯西玛丽对约翰的感情，但她没有告诉凯西玛丽心意发生变化，当玛丽爱上了拉尔夫时。
- en: GPT-4’s answer is the likely answer most humans would give. The prompt states
    only that Amanda and Kathy spoke about the weather, so the majority of humans
    would likely take that to mean Amanda and Kathy didn’t talk about any other subjects.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的回答是大多数人类可能会给出的回答。提示中只提到阿曼达和凯西谈论了天气，因此大多数人类可能会认为阿曼达和凯西没有谈论其他话题。
- en: 'Large language models, as currently presented, use a chat format, meaning the
    user can enter follow-up prompts, and the model will apply those prompts to the
    earlier part of the conversation. For example, I followed up with GPT-4 using
    this prompt:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的巨大语言模型采用对话格式，意味着用户可以输入后续提示，模型会将这些提示应用到之前的对话内容中。例如，我向GPT-4提出了以下提示：
- en: '*We know that Amanda spoke with Kathy about the weather. Does that mean she
    didn’t speak about anything else? How might that affect what Kathy believes about
    Mary’s love?*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们知道阿曼达和凯西谈论了天气。这是否意味着她们没有谈论其他任何话题？这可能会如何影响凯西对玛丽爱情的看法？*'
- en: 'To which GPT-4 replied:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然后GPT-4做出了回应：
- en: My earlier response assumed that Amanda only spoke with Kathy about the weather
    after Mary revealed her new feelings for Ralph. However, since the text does not
    explicitly state that Amanda did not mention Mary’s updated feelings for Ralph,
    it is possible that Amanda might have told Kathy about Mary’s new love interest.
    If that were the case, Kathy would know that Mary is now in love with Ralph. The
    text does not provide enough information to definitively conclude what Kathy believes
    about Mary’s love at this point.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前的回答假设阿曼达在玛丽向拉尔夫表达新感情后，才与凯西讨论了天气。然而，由于文本并未明确说明阿曼达没有提到玛丽对拉尔夫的最新感情，阿曼达有可能告诉凯西玛丽的新恋情。如果是这种情况，凯西就知道玛丽现在爱上了拉尔夫。文本并没有提供足够的信息来明确得出凯西对玛丽爱情的看法。
- en: My follow-up prompt led GPT-4 to recognize that it had made a possibly incorrect
    assumption in its first reply. In working with LLMs in chat mode, it is often
    the case that some level of interaction between the user and the model is required
    to help the model focus, as our next experiment will demonstrate.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我的后续提问促使GPT-4意识到它在第一次回答中可能做出了错误的假设。在与LLM的对话模式下，通常需要用户与模型之间的一定互动，以帮助模型更好地聚焦，正如我们接下来的实验将展示的那样。
- en: '****'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: 'Amos Tversky and Daniel Kahneman are credited with presenting what is now known
    as “the Linda problem”:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 阿莫斯·特沃斯基和丹尼尔·卡尼曼被认为是提出如今被称为“琳达问题”的人：
- en: '*Linda is 31 years old, single, outspoken, and very bright. She majored in
    philosophy. As a student, she was deeply concerned with issues of discrimination
    and social justice, and also participated in anti-nuclear demonstrations.*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*琳达31岁，单身，直言不讳且非常聪明。她主修哲学。作为学生，她深切关注歧视和社会正义问题，并参与了反核示威活动。*'
- en: '*Which is more probable?*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*哪种可能性更大？*'
- en: '*Linda is a bank teller.*'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*琳达是一名银行出纳员。*'
- en: '*Linda is a bank teller and is active in the feminist movement.*'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*琳达是一名银行出纳员，并活跃于女权运动。*'
- en: Approximately 80 percent of humans choose option 2\. According to basic probability
    theory, the correct answer is option 1\. Interestingly, according to Tversky and
    Kahneman, even mathematicians and statisticians selected option 2, revealing a
    bias in human thinking. Will LLMs show a similar bias? After all, their training
    data was generated by humans. Let’s find out.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 大约80%的人选择了选项2。根据基本的概率理论，正确答案是选项1。有趣的是，根据特沃斯基和卡尼曼的研究，即使是数学家和统计学家也选择了选项2，揭示了人类思维中的偏差。那么LLM是否会显示出类似的偏差呢？毕竟，它们的训练数据是由人类生成的。让我们来看看。
- en: 'The LLMs we are exploring have been trained on a significant portion of the
    internet’s contents, meaning the models’ training data likely contains the Linda
    problem. Therefore, I altered the text to present the same problem in a different
    format:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在探索的LLM模型已经在互联网上大量内容上进行过训练，这意味着模型的训练数据很可能包含了琳达问题。因此，我对文本进行了修改，以不同的方式呈现相同的问题：
- en: '*Abner is 27 years old, single, outspoken and highly intelligent. He majored
    in philosophy and physics. As a student, he was actively concerned with issues
    of social justice and participated in anti-police demonstrations. What is more
    likely, that Abner is a car mechanic or a car mechanic active in promoting police
    reform?*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*阿布纳27岁，单身，直言不讳且非常聪明。他主修哲学和物理学。作为学生，他积极关注社会正义问题，并参与了反警察示威活动。更有可能的是，阿布纳是一名汽车修理工，还是一名活跃于推动警察改革的汽车修理工？*'
- en: 'Notice that I intentionally used the word *likely* instead of *probable*. The
    models’ replies were:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我故意使用了*likely*这个词，而不是*probable*。模型的回答是：
- en: '**GPT-4**'
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**GPT-4**'
- en: Based on the information provided, it seems more likely that Abner is a car
    mechanic active in promoting police reform. This is because his background indicates
    a strong interest in social justice issues, and he has participated in anti-police
    demonstrations. While it is possible that Abner is simply a car mechanic, his
    past activism and interests suggest that he would be more likely to be involved
    in promoting police reform as well.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 根据提供的信息，更可能的是阿布纳是一名活跃于推动警察改革的汽车修理工。这是因为他的背景表明他对社会正义问题有浓厚的兴趣，并且他参与了反警察示威活动。虽然阿布纳可能仅仅是一名汽车修理工，但他的过去的社会活动和兴趣表明他更可能参与推动警察改革。
- en: '**GPT-3.5**'
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**GPT-3.5**'
- en: Based on the given information, it is more likely that Abner is a car mechanic
    active in promoting police reform. This is because Abner’s background as a philosophy
    and physics major, as well as his active participation in social justice issues,
    suggest that he is likely to be interested in broader societal issues beyond his
    profession. Additionally, his participation in anti-police demonstrations suggests
    that he is passionate about police reform, which further supports the idea that
    he is a car mechanic who is active in promoting police reform.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 根据提供的信息，更可能的是阿布纳是一名活跃于推动警察改革的汽车修理工。这是因为阿布纳的哲学和物理学背景，以及他积极参与社会正义问题，表明他可能对除了职业之外的更广泛社会问题感兴趣。此外，他参与反警察示威活动也表明他对警察改革充满热情，这进一步支持了他是一名活跃于推动警察改革的汽车修理工的观点。
- en: '**Bard**'
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Bard**'
- en: Based on the information provided, it is more likely that Abner is a car mechanic
    active in promoting police reform than it is that he is simply a car mechanic.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 根据提供的信息，比起单纯是汽车修理工，更可能的是阿布纳是一名活跃于推动警察改革的汽车修理工。
- en: Bard continued with a justification of its reply and an attempt to interpret
    Abner’s state of mind.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Bard继续为其回复提供理由，并尝试解读Abner的心态。
- en: All three models selected the second option, though GPT-4 nuanced its answer
    to admit the possibility that Abner is simply a car mechanic.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 所有三个模型都选择了第二个选项，尽管GPT-4在回答中进行了微妙的调整，承认Abner可能只是一个汽车机械师。
- en: 'I then started new sessions and tweaked the prompt to ask about the *probability*
    of Abner being a mechanic or a mechanic active in police reform:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我开始了新的会话，并调整提示，询问Abner成为机械师或参与警察改革的机械师的*概率*：
- en: '*Abner is 27 years old, single, outspoken and highly intelligent. He majored
    in philosophy and physics. As a student, he was actively concerned with issues
    of social justice and participated in anti-police demonstrations. Which has a
    higher probability: (a) that Abner is a car mechanic or (b) that Abner is a car
    mechanic active in police reform?*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*Abner 27岁，单身，直言不讳，智力超群。他主修哲学和物理学。在学生时期，他积极关注社会正义问题并参与反警察示威。哪种情况的概率更高：（a）Abner是一个汽车机械师，还是（b）Abner是一个参与警察改革的汽车机械师？*'
- en: 'This aligns the text with the original Linda version. The models’ replies to
    this prompt were as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这使文本与原始的Linda版本保持一致。模型对这个问题的回复如下：
- en: '**GPT-4**'
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**GPT-4**'
- en: According to the conjunction rule in probability theory, the probability of
    two events occurring together (in “conjunction”) is always less than or equal
    to the probability of either event occurring individually.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 根据概率论中的联合规则，两个事件同时发生（“联合”）的概率总是小于或等于任一事件单独发生的概率。
- en: 'In this case, the two events are:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，两个事件是：
- en: Abner being a car mechanic.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Abner是一个汽车机械师。
- en: Abner being active in police reform.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Abner参与警察改革。
- en: Option (b) represents the conjunction of these two events. So, the probability
    of (a) Abner being a car mechanic is higher than the probability of (b) Abner
    being a car mechanic who is also active in police reform.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 选项（b）代表了这两个事件的联合。因此，（a）Abner是一个汽车机械师的概率要高于（b）Abner是一个同时参与警察改革的汽车机械师的概率。
- en: '**GPT-3.5**'
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**GPT-3.5**'
- en: Based on the information provided, it is more likely that Abner is a car mechanic
    (option a) than a car mechanic active in police reform (option b). While Abner
    is highly intelligent and studied philosophy and physics, there is no indication
    that he has any formal training or education in car mechanics. On the other hand,
    his involvement in anti-police demonstrations suggests that he may have an interest
    in police reform, but it does not necessarily mean that he is actively involved
    in it as a car mechanic. Therefore, the probability of option a is higher than
    option b.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 根据提供的信息，Abner是一个汽车机械师（选项a）的可能性高于一个参与警察改革的汽车机械师（选项b）。虽然Abner非常聪明，且曾学习哲学和物理学，但没有迹象表明他有任何正式的汽车机械培训或教育。另一方面，他参与反警察示威表明他可能对警察改革感兴趣，但这并不意味着他作为汽车机械师积极参与其中。因此，选项a的概率高于选项b。
- en: '**Bard**'
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Bard**'
- en: I would say that (a) that Abner is a car mechanic has a higher probability.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为（a）Abner是一个汽车机械师的概率更高。
- en: Abner is 27 years old, single, outspoken and highly intelligent. He majored
    in philosophy and physics. As a student, he was actively concerned with issues
    of social justice and participated in anti-police demonstrations.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Abner 27岁，单身，直言不讳，智力超群。他主修哲学和物理学。在学生时期，他积极关注社会正义问题并参与反警察示威。
- en: 'Based on this information, it is more likely that Abner is a car mechanic than
    a car mechanic active in police reform. This is because:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些信息，更可能的是Abner是一个汽车机械师，而不是一个参与警察改革的汽车机械师。原因是：
- en: Car mechanics are more common than car mechanics active in police reform.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 汽车机械师比参与警察改革的汽车机械师更为常见。
- en: Abner’s education and interests are more aligned with a career in car mechanics
    than with a career in police reform.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abner的教育背景和兴趣更倾向于从事汽车机械师的职业，而不是警察改革的职业。
- en: Abner’s participation in anti-police demonstrations suggests that he is critical
    of the police, which is not a characteristic that is typically associated with
    car mechanics.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abner参与反警察示威表明他对警察持批评态度，这通常与汽车机械师的特征不符。
- en: Of course, it is possible that Abner is both a car mechanic and active in police
    reform. However, based on the information provided, it is more likely that he
    is only a car mechanic.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，Abner既是一个汽车机械师，又参与警察改革的可能性是存在的。然而，基于提供的信息，更可能的是他仅仅是一个汽车机械师。
- en: All three models arrive at the correct answer once the prompt includes the word
    *probability*. However, only GPT-4 interprets the prompt in light of probability
    theory. GPT-3.5 and Bard both give somewhat flawed rationales for selecting the
    correct answer.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提示中包含“*概率*”这个词，所有三个模型都能得出正确的答案。然而，只有GPT-4在概率理论的背景下解读了这个提示。GPT-3.5和Bard都给出了有些缺陷的理由来选择正确答案。
- en: '****'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: Large language models demonstrate theory of mind and can interpret probability
    word problems, along with various other mathematical abilities we are ignoring.
    My next question is, can LLMs handle a simple substitution cipher? To solve the
    cipher, the models need to understand what is being asked, that there is such
    a thing as a key and what that key represents, and finally how to use the key
    to replace letters in the encoded message with the letters that decode the message.
    In other words, there is an algorithm to apply using the given information.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型展示了心智理论，能够解释概率问题及其他多种我们忽略的数学能力。我的下一个问题是，LLM是否能处理简单的替代密码？为了解密，模型需要理解问题的内容，理解“密钥”这一概念以及它代表的含义，最后知道如何使用密钥将编码消息中的字母替换为解码字母。换句话说，有一个算法可以应用，通过给定的信息来解密。
- en: 'A substitution cipher creates a pairing between the letters of the alphabet,
    in order, and another permutation of those letters. The cipher used here is:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 替代密码法通过将字母表中的字母按顺序与这些字母的另一种排列配对来创建加密。这里使用的密码是：
- en: '`ABCDEFGHIJKLMNOPQRSTUVWXYZ`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`ABCDEFGHIJKLMNOPQRSTUVWXYZ`'
- en: '`UESOZBYRJNDWTFKPACLHIXVQGM`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`UESOZBYRJNDWTFKPACLHIXVQGM`'
- en: For example, to encode a `C`, you would scan the top row of letters to find
    `C`, then replace `C` with the corresponding letter in the bottom row, `S`. To
    decode a letter, you’d scan the bottom row for it and replace it with the corresponding
    letter in the top row. During the test, the key is displayed textually as `U is
    A`, `E is B`, and so on.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要对一个`C`进行编码，你需要扫描上排字母找到`C`，然后用下排中对应的字母`S`替换`C`。要解码一个字母，你则需要扫描下排找到该字母，并将其替换为上排中相应的字母。在测试过程中，密钥以文本形式显示为`U是A`，`E是B`，依此类推。
- en: 'My encoded message was “Eat at Moe’s,” without spaces or punctuation and in
    all caps:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我的编码消息是“Eat at Moe’s”，没有空格或标点，且全部为大写字母：
- en: '`EATATMOES` → `ZUHUHTKZL`'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`EATATMOES` → `ZUHUHTKZL`'
- en: 'The prompt given to the models was:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 给模型的提示是：
- en: '*The key is U is A, E is B, S is C, O is D, Z is E, B is F, Y is G, R is H,
    J is I, N is J, D is K, W is L, T is M, F is N, K is O, P is P, A is Q, C is R,
    L is S, H is T, I is U, X is V, V is W, Q is X, G is Y, M is Z. Now, decode the
    message: ZUHUHTKZL*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '*关键是U代表A，E代表B，S代表C，O代表D，Z代表E，B代表F，Y代表G，R代表H，J代表I，N代表J，D代表K，W代表L，T代表M，F代表N，K代表O，P代表P，A代表Q，C代表R，L代表S，H代表T，I代表U，X代表V，V代表W，Q代表X，G代表Y，M代表Z。现在，解码消息：ZUHUHTKZL*'
- en: 'Let’s review the models’ replies, beginning with GPT-4:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从GPT-4开始，回顾各个模型的回复：
- en: 'First, let’s list the given cipher for easier reference:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们列出给定的密码以便于参考：
- en: '*(cipher list removed)*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*(密码列表已删除)*'
- en: 'Now, let’s decode the message `ZUHUHTKZL`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们解码消息`ZUHUHTKZL`：
- en: '[PRE1]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'So the decoded message is: `EATATMOES`.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 所以解码后的消息是：`EATATMOES`。
- en: 'GPT-4 was able to apply the cipher to the encoded message. But does the model
    understand that the decoded message is a sentence? Let’s ask it:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4成功地将密码应用于编码消息。但该模型是否理解解码后的消息是一个句子？让我们问一下它：
- en: '*That is correct. Now, add proper spacing and punctuation to the string EATATMOES
    so that it forms a complete sentence.*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*那是正确的。现在，给字符串EATATMOES添加适当的空格和标点，使其形成一个完整的句子。*'
- en: 'Here’s GPT-4’s response:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这是GPT-4的回复：
- en: 'The properly spaced and punctuated sentence is: “Eat at Moe’s.”'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的、具有适当间隔和标点的句子是：“Eat at Moe’s.”
- en: Indeed, it does.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 确实如此。
- en: 'GPT-3.5 likewise successfully decoded the message. It then added this after
    `EATATMOES`:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5同样成功地解码了消息。然后，它在`EATATMOES`之后添加了这个：
- en: It’s possible that this is a misspelling of “Tomatoes”.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 有可能这是“Tomatoes”的拼写错误。
- en: I find this extra sentence curious. Was GPT-3.5 attempting to interpret the
    meaning of the decoded message and, unable to do so, falling back to a possible
    misspelling?
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我觉得这个额外的句子很奇怪。GPT-3.5是在尝试解释解码后消息的含义时，无法做到这一点，因此退回到可能的拼写错误吗？
- en: 'Bard claimed that the decoded message was “HAPPY NEW YEAR,” offering a three-point
    explanation: (1) writing down the key, (2) replacing each letter in `ZUHUHTKZL`
    with the corresponding key letter to arrive at the message “HAPPY NEW YEAR,” and
    (3):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Bard声称解码后的消息是“新年快乐”，并提供了三点解释：（1）写下密钥，（2）将`ZUHUHTKZL`中的每个字母替换为相应的密钥字母，得到消息“新年快乐”，以及（3）：
- en: I checked the decoded message to make sure that it made sense. Since “HAPPY
    NEW YEAR” is a common phrase that is used at the beginning of a new year, I was
    confident that my decoding was correct.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我检查了解码后的消息，以确保它有意义。由于“新年快乐”是新年开始时常用的短语，我确信我的解码是正确的。
- en: Bard’s confident failure is telling. It seems the model attempted to instill
    trust in the user by offering a point-by-point justification of its wrong answer.
    This kind of unwarranted support for wrong output has often been noted in LLMs.
    It’s an issue that needs to be sufficiently addressed going forward if people
    are to trust LLM output.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Bard自信的失败很有启发性。似乎这个模型试图通过逐点解释它错误的答案来增强用户的信任。这种对错误输出的无根据支持在LLM中经常被注意到。这是一个需要足够解决的问题，如果人们想要信任LLM的输出，未来必须加以改进。
- en: '****'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: Large language models are already disrupting the field of software development.
    Many examples of this can be found online. I know of one developer who has created
    an entire video game in Unity (a game development platform) using code generated
    by GPT-4 from prompts. If the generated code wasn’t quite correct, further prompts
    pointing out the error usually resulted in correct code that performed as desired.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型已经开始颠覆软件开发领域。在网上可以找到很多这样的例子。我知道有一位开发者使用GPT-4生成的代码通过提示在Unity（一个游戏开发平台）中创建了一款完整的电子游戏。如果生成的代码不完全正确，进一步的提示指出错误通常会得到正确的代码，且能够按预期执行。
- en: Let’s take a quick look at some LLM-generated code. Of course, this isn’t a
    coding book, nor is there any assumption on my part about your experience programming,
    so I’ve chosen an example that should be easy to follow yet is sufficient to demonstrate
    my claim that LLMs are already competent coders.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速看一下某些LLM生成的代码。当然，这本书并不是一本编程书，我也没有假设你有编程经验，所以我选择了一个应该容易理解的示例，但足以证明我的观点：LLM已经是合格的编码者了。
- en: Some of us might remember learning in school about the greatest common divisor.
    As a refresher, the greatest common divisor of two numbers is the largest number
    that divides both without a remainder. For example, the greatest common divisor
    of 14 and 21 is 7 because 7 is the largest number that evenly divides both 14
    and 21.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们中的一些人可能记得在学校里学习过最大公约数。作为复习，两个数的最大公约数是能同时整除这两个数且没有余数的最大数。例如，14和21的最大公约数是7，因为7是能同时整除14和21的最大数。
- en: The ancient Greek mathematician Euclid devised an algorithm for calculating
    the greatest common divisor that is a staple programming exercise. Typically the
    solution uses the remainder after dividing, but Euclid’s original version of the
    algorithm used nothing more than subtraction.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 古希腊数学家欧几里得设计了一种计算最大公约数的算法，这个算法是编程练习的经典题目。通常，解决方案使用除法后的余数，但欧几里得原始版本的算法仅使用减法。
- en: 'I asked the models if they could write a function in Python, a popular programming
    language used heavily in AI research, to return the greatest common divisor of
    two numbers:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我问了这些模型是否能编写一个Python函数，这是一个在AI研究中被广泛使用的流行编程语言，用于返回两个数的最大公约数：
- en: '*Show me a Python function that returns the GCD of two integers. Use the subtraction-only
    version of Euclid’s algorithm.*'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*给我一个返回两个整数最大公约数的Python函数。使用欧几里得算法的减法版本。*'
- en: 'Notice that the prompt explicitly asks for the subtraction-only version of
    Euclid’s algorithm. Bard replied with valid Python code, but code using the remainder
    shortcut, not the slower subtraction algorithm. Both GPT-3.5 and GPT-4 got it
    right:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，提示明确要求使用欧几里得算法的减法版本。Bard回复了有效的Python代码，但使用了余数捷径的代码，而不是较慢的减法算法。GPT-3.5和GPT-4都做对了：
- en: '[PRE2]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We don’t need to be programmers to see structure in the code. The first line
    tells Python we want a function with two inputs, `a` and `b`. The keyword `while`
    begins a block of code that executes while the value of `a` is not the same as
    the value of `b`. That block of code is the four lines beginning with `if`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要是程序员就能看到代码中的结构。第一行告诉Python我们想要一个有两个输入`a`和`b`的函数。关键字`while`开始了一个代码块，这个代码块在`a`和`b`的值不相同的情况下执行。这个代码块是从`if`开始的四行代码。
- en: 'The block asks if `a` is bigger than `b` and, if so, subtracts `b` from `a`.
    Otherwise, it subtracts `a` from `b`. Repeating this process until `a` equals
    `b` is Euclid’s algorithm. At this point, `a` (or `b`, as they’re equal) contains
    the greatest common divisor, which explains the final line: `return` `a`.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码块检查 `a` 是否大于 `b`，如果是，它就从 `a` 中减去 `b`。否则，它从 `b` 中减去 `a`。重复这个过程直到 `a` 等于 `b`，这就是欧几里得算法。此时，`a`（或
    `b`，因为它们相等）包含最大公约数，这也解释了最后一行：`return` `a`。
- en: As I said, the code is correct, and it implements precisely the version of the
    algorithm I wanted. Frankly, I would have been disappointed if GPT (either version)
    had responded differently. Implementations of the greatest common divisor algorithm
    in Python must have appeared many times in the models’ training data.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我所说，代码是正确的，它实现了我想要的算法版本。坦白说，如果 GPT（无论哪个版本）有不同的回应，我会感到失望。最大公约数算法在 Python 中的实现一定已经出现在模型的训练数据中很多次。
- en: 'That being the case, I decided to challenge GPT-4\. My follow-up prompt to
    GPT-4 was:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 既然如此，我决定挑战 GPT-4。我的后续提示给 GPT-4 是：
- en: '*Rewrite the Python function in Applesoft BASIC.*'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '*将 Python 函数重写为 Applesoft BASIC。*'
- en: 'Applesoft BASIC is a primitive version of the BASIC programming language used
    by Apple II computers in the late 1970s and early 1980s. Can GPT-4 rewrite the
    Python code in such an old, largely forgotten programming language? Here’s its
    reply, minus supporting text explaining the code:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Applesoft BASIC 是一种早期的 BASIC 编程语言版本，曾在 1970 年代末和 1980 年代初的 Apple II 计算机上使用。GPT-4
    能否将 Python 代码重写为这样一种古老且大多被遗忘的编程语言呢？这是它的回应，去掉了解释代码的支持文本：
- en: '[PRE3]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: BASIC was designed to be a simple language for beginning programmers. I suspect
    you can read through the code and understand what it does. The numbers are labels
    identifying each line to other parts of the code. The three lines after line 100
    implement the subtraction-only version of Euclid’s algorithm. I tested the code
    on an Apple II, and it works perfectly.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: BASIC 设计为一种简单的语言，适合初学编程的人。我猜想你能读懂这段代码并理解它的作用。数字是标签，用来将每行代码与其他部分关联起来。100 行之后的三行实现了欧几里得算法的减法版本。我在
    Apple II 上测试了这段代码，它工作得非常完美。
- en: Consider what was required of GPT-4 in this case. First, the model had to understand
    the steps necessary to implement the requested form of Euclid’s algorithm. Then,
    it had to determine how to cast those steps into a format suitable for the particular
    dialect of BASIC supported by Applesoft.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下 GPT-4 在这种情况下需要做的工作。首先，模型必须理解实现所请求的欧几里得算法形式所需的步骤。然后，它必须确定如何将这些步骤转化为适合 Applesoft
    支持的特定 BASIC 方言的格式。
- en: Old-school BASIC is an unstructured programming language that uses abrupt jumps
    from one part of the code to another instead of structured statements, like Python.
    GPT-4 had to adapt the algorithm to this kind of programming. Further, it had
    to adapt to the peculiarities of Applesoft, which includes no concept of the `if...
    else` construct that is commonly found in structured programming languages.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 老式 BASIC 是一种无结构的编程语言，它通过从代码的一个部分突然跳转到另一个部分来代替结构化语句，如 Python 中的结构。GPT-4 必须将算法调整为这种编程方式。此外，它还必须适应
    Applesoft 的特殊性，后者没有 `if... else` 构造，而这是结构化编程语言中常见的内容。
- en: I find GPT-4’s Applesoft algorithm to be rather elegant. There are times when
    the unstructured approach leads to compact yet clear code, and this is one of
    those times. True, the assignment of `A` to `GCD` to use the latter as the value
    returned from the function (implicit in `GOSUB 100` in line 40) isn’t strictly
    necessary because `A` already has the required value, but it completes the symmetry
    of the code.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现 GPT-4 在 Applesoft 中的算法相当优雅。有时，无结构的方式会导致代码既简洁又清晰，而这正是其中的一次。确实，将 `A` 赋值给 `GCD`
    来使用后者作为函数返回值（在 40 行的 `GOSUB 100` 中隐含的）并不是严格必要的，因为 `A` 已经具有所需的值，但它完成了代码的对称性。
- en: It seems unlikely that GPT-4’s training set contained any instances of this
    particular algorithm in Applesoft BASIC. Therefore, GPT-4 must have generated
    it by adapting a larger concept entailing Euclid’s algorithm combined with an
    understanding of Applesoft BASIC.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不太可能 GPT-4 的训练数据集中包含这种特定的算法实现，尤其是用 Applesoft BASIC 写的。因此，GPT-4 必须通过适应更大概念来生成它，这个更大概念包括欧几里得算法并结合了对
    Applesoft BASIC 的理解。
- en: 'GPT-4’s success with antique BASIC encouraged me to push the envelope and ask
    for a version of Euclid’s algorithm written in low-level assembly language:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 在老式 BASIC 中的成功鼓励我更进一步，要求它用低级汇编语言编写欧几里得算法的一个版本：
- en: '*Rewrite the Python function in 6502 assembly language for 8-bit unsigned integers.
    The first integer is in memory location 0x300 and the second in location 0x301.*'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*将Python函数重写为6502汇编语言，适用于8位无符号整数。第一个整数在内存位置0x300，第二个在位置0x301。*'
- en: Assembly language programs, especially for 8-bit microprocessors from the 1970s
    like the 6502, must be programmed directly in the language of the CPU itself.
    I asked GPT-4 to create such a program and told it where in the computer’s memory
    to find `a` and `b`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 汇编语言程序，尤其是像6502这样的1970年代8位微处理器的程序，必须直接使用CPU本身的语言进行编程。我要求GPT-4创建这样一个程序，并告诉它在计算机内存中哪里可以找到`a`和`b`。
- en: I won’t show the code it produced (ask me if you want it), but it worked on
    a computer with a 6502 CPU. Success in this case required GPT-4 to know the particular
    instruction set used by the 6502 microprocessor, including quirks related to the
    subtraction instruction.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会展示它生成的代码（如果你需要可以问我），但它在一台6502 CPU的计算机上运行成功。在这种情况下，成功的关键是GPT-4必须了解6502微处理器所使用的特定指令集，包括与减法指令相关的特殊情况。
- en: Do these capabilities mean we soon won’t need software engineers any more? I
    wouldn’t go that far (at least, not yet), but LLMs are undoubtedly going to fundamentally
    alter software engineering as a discipline.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这些能力是否意味着我们很快就不再需要软件工程师了？我不敢这么说（至少现在还不），但LLMs无疑将从根本上改变软件工程这个学科。
- en: '****'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: 'We’ve seen that LLMs are capable of writing stories and code, and even drawing
    pictures in LaTeX. But are they creative enough to generate good cartoons? These
    models’ proneness to including [*hallucinations*](glossary.xhtml#glo53) (fake
    or imaginary facts and content) in their responses—a topic that we’ll return to
    in [Chapter 8](ch08.xhtml)—is a definite concern in many applications, but creative
    writing isn’t one of them. Here, we want the model to describe a novel cartoon,
    complete with caption:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，LLMs能够编写故事和代码，甚至在LaTeX中绘制图像。但它们是否足够有创造力，能生成好的漫画呢？这些模型在回答中可能会包含[*幻觉*](glossary.xhtml#glo53)（虚假或想象的事实和内容），这是许多应用中的一个重要问题，但创意写作并不在其中。这里，我们希望模型能够描述一个新颖的漫画，附上字幕：
- en: '*Describe a single-panel, black-and-white cartoon in the style of Gary Larson
    about cows and aliens. Include a caption.*'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*描述一幅单面黑白漫画，风格模仿Gary Larson，主题是奶牛与外星人。附上字幕。*'
- en: 'Gary Larson is the creator of *The Far Side*, a quirky cartoon popular in the
    1980s and ’90s. Here’s GPT-4’s response:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Gary Larson是*《远方一面》*的创作者，这是一部在1980年代和90年代非常流行的古怪漫画。以下是GPT-4的回答：
- en: 'Cartoon description: In a peaceful countryside scene, two cows are standing
    in a grassy field next to a round, hovering UFO with its hatch open. One cow is
    wearing an alien mask, complete with large eyes and a long, slender neck, while
    the other cow stares at her with a surprised expression. A group of aliens, peeking
    from inside the UFO, look baffled and seem to be comparing a picture of a typical
    cow with the cow wearing the alien mask.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 漫画描述：在一个宁静的乡村场景中，两个奶牛站在一片草地上，旁边有一个圆形、悬浮的飞碟，舱口敞开。一头奶牛戴着外星人面具，面具上有大眼睛和细长的脖子，另一头奶牛则用惊讶的表情看着它。几只外星人从飞碟内偷看出来，显得困惑，似乎正在将一张典型奶牛的图片与戴外星人面具的奶牛进行对比。
- en: 'Caption: “Mildred, I don’t think they’re falling for it.”'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 标题：“Mildred，我觉得他们没有上当。”
- en: If you’re familiar with Gary Larson’s work, you’ll notice a distinct *The Far
    Side* flavor to the description and caption text.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉Gary Larson的作品，你会注意到描述和字幕文本中有一种明显的*《远方一面》（The Far Side）*风格。
- en: The ability to automatically generate cartoon descriptions and captions, and
    corresponding images if then passing the descriptions to a diffusion model, is
    powerful. Combining LLMs and diffusion models in this way has realized American
    cartoonist H. T. Webster’s 1923 dream (see [Figure 7-2](ch07.xhtml#ch07fig02)).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成漫画描述和字幕的能力，如果再将这些描述传递给扩散模型来生成对应的图像，是非常强大的。通过这种方式将大语言模型（LLMs）和扩散模型结合，实现了美国漫画家H.
    T. Webster在1923年的梦想（见[图7-2](ch07.xhtml#ch07fig02)）。
- en: '![Image](../images/ch07fig02.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/ch07fig02.jpg)'
- en: '*Figure 7-2: A prophetic cartoon from 1923*'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7-2：1923年预见性的漫画*'
- en: Large language models are impressive and powerful. So how do they work? Let’s
    take a shot at an answer.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型令人印象深刻且强大。那么它们是如何工作的呢？让我们来尝试解答这个问题。
- en: '****'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: 'I’ll begin at the end, with a few comments from the conclusion of the “Sparks
    of Artificial General Intelligence” paper mentioned earlier:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我将从结尾开始，引用之前提到的《人工通用智能的火花》论文结论中的一些评论：
- en: How does `[`GPT-4`]` reason, plan, and create? Why does it exhibit such general
    and flexible intelligence when it is at its core merely the combination of simple
    algorithmic components—gradient descent and large-scale transformers with extremely
    large amounts of data? These questions are part of the mystery and fascination
    of LLMs, which challenge our understanding of learning and cognition, fuel our
    curiosity, and motivate deeper research.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`[`GPT-4`]` 是如何推理、计划和创造的？为什么它在本质上只是由简单算法组件——梯度下降和大规模 Transformer 与极大量数据的结合——组成，却能展现出如此通用且灵活的智能？这些问题是大型语言模型之谜和魅力的一部分，它们挑战了我们对学习和认知的理解，激发了我们的好奇心，并推动了更深入的研究。'
- en: That quote contains questions that currently lack convincing answers. Simply
    put, researchers don’t know why large language models like GPT-4 do what they
    do. There are certainly hypotheses in search of evidence and proof, but as I write
    this, no proven theories are available. Therefore, we can discuss only the *what*,
    as in what a large language model entails, and not the *how* of its behavior.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 那段话包含了一些目前缺乏令人信服答案的问题。简单来说，研究人员并不知道像 GPT-4 这样的巨大语言模型为什么会执行它们的任务。确实有一些假设在等待证据和证明，但在我写这篇文章时，尚无经过验证的理论。因此，我们只能讨论*是什么*，即大型语言模型包含什么，而不能讨论它行为的*如何*。
- en: Large language models use a new class of neural network, the [*transformer*](glossary.xhtml#glo97),
    so we’ll begin there. (*GPT* stands for [*generative pretrained transformer*](glossary.xhtml#glo48).)
    The transformer architecture appeared in the literature in 2017, with the influential
    paper “Attention Is All You Need” by Google researchers Ashish Vaswani et al.
    The paper had been cited over 70,000 times as of March 2023.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型使用了一类新的神经网络——[*Transformer*](glossary.xhtml#glo97)，因此我们将从这里开始。（*GPT* 代表
    [*生成预训练变换器*](glossary.xhtml#glo48)。）Transformer 架构在 2017 年的文献中首次出现，谷歌研究员 Ashish
    Vaswani 等人发表了具有深远影响的论文《Attention Is All You Need》。截至 2023 年 3 月，这篇论文已被引用超过 70,000
    次。
- en: Traditionally, models that process sequences (such as sentences) used [*recurrent
    neural networks*](glossary.xhtml#glo85), which pass their output back in as input
    along with the next input of the sequence. This is the logical model for processing
    text because the network can incorporate the notion of memory via the output fed
    back in with the next token. Indeed, early deep learning translation systems used
    recurrent networks. However, recurrent networks have small memories and are challenging
    to train, which limits their applicability.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，处理序列（如句子）的模型使用 [*递归神经网络*](glossary.xhtml#glo85)，它们将输出作为输入的一部分与序列的下一个输入一起传递回去。这是处理文本的逻辑模型，因为该网络可以通过将输出与下一个标记一起反馈来引入记忆的概念。事实上，早期的深度学习翻译系统使用了递归网络。然而，递归网络的记忆较小且训练起来具有挑战性，这限制了它们的适用性。
- en: 'Transformer networks utilize a different approach: they accept the entire input
    at once and process it in parallel. Transformer networks typically include an
    encoder and a decoder. The encoder learns representations and associations between
    the parts of the input (think sentences), while the decoder uses the learned associations
    to produce output (think more sentences).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 网络采用了不同的方法：它们一次性接收整个输入并进行并行处理。Transformer 网络通常包括一个编码器和一个解码器。编码器学习输入各部分之间的表示和关联（比如句子），而解码器则利用学到的关联生成输出（比如更多的句子）。
- en: Large language models like GPT dispense with the encoder and instead learn the
    necessary representation in an unsupervised way using an enormous text dataset.
    After pretraining, the decoder part of the transformer model generates text in
    response to the input prompt.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 像 GPT 这样的巨大语言模型不再使用编码器，而是通过使用一个巨大的文本数据集以无监督的方式学习必要的表示。预训练后，Transformer 模型的解码器部分根据输入提示生成文本。
- en: The input to a model like GPT-4 is a sequence of text made up of words. The
    model splits this into units called [*tokens*](glossary.xhtml#glo95). A token
    might be a word, a part of a word, or even an individual character. Pretraining
    aims to map tokens to a multidimensional *embedding space*, which it does by associating
    each token with a vector that can be thought of as a point in that space.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 输入到像 GPT-4 这样的模型中的是由单词组成的文本序列。模型将其拆分为被称为 [*标记*](glossary.xhtml#glo95)的单位。一个标记可能是一个单词、一部分单词，甚至是一个单独的字符。预训练的目标是将标记映射到一个多维的*嵌入空间*，其方式是通过将每个标记与一个可以视为该空间中一个点的向量关联起来。
- en: The learned mapping from tokens to vectors captures complex relationships between
    the tokens so that tokens with similar meanings are nearer to each other than
    tokens with dissimilar meanings. For example, as shown in [Figure 7-3](ch07.xhtml#ch07fig03),
    after pretraining, the mapping ([*context encoding*](glossary.xhtml#glo20)) will
    place “dog” closer to “fox” than to “can opener.” The embedding space has many
    dimensions, not the mere two of [Figure 7-3](ch07.xhtml#ch07fig03), but the effect
    is the same.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 从标记到向量的学习映射捕捉了标记之间的复杂关系，使得具有相似含义的标记比含义不相似的标记距离更近。例如，如[图7-3](ch07.xhtml#ch07fig03)所示，预训练后，映射（[*上下文编码*](glossary.xhtml#glo20)）会将“狗”与“狐狸”比与“开罐器”更靠近。嵌入空间有许多维度，不仅仅是[图7-3](ch07.xhtml#ch07fig03)中所示的二维，但效果是一样的。
- en: '![Image](../images/ch07fig03.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch07fig03.jpg)'
- en: '*Figure 7-3: Context encoding in the embedding space*'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7-3：嵌入空间中的上下文编码*'
- en: The context encoding is learned during pretraining by forcing the model to predict
    the next token given all previous tokens in an input. In effect, if the input
    is “roses are red,” then during the pretraining process the model will be asked
    to predict the next token after “roses are.” If the predicted token isn’t “red,”
    the model will use the loss function and backpropagation to update its weights,
    thereby taking a gradient descent step after suitable averaging of the error over
    a minibatch. For all their abilities, large language models are trained the same
    way as other neural networks.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文编码是在预训练过程中通过强制模型在给定所有前置标记的情况下预测下一个标记来学习的。实际上，如果输入是“玫瑰是红色的”，那么在预训练过程中，模型将被要求预测“玫瑰是”之后的下一个标记。如果预测的标记不是“红色”，模型将利用损失函数和反向传播更新其权重，从而在适当的误差平均后通过梯度下降进行调整。尽管大型语言模型具有众多能力，但它们的训练方式与其他神经网络相同。
- en: Pretraining enables the model to learn language, including grammar and syntax,
    and seemingly to acquire enough knowledge about the world to allow the emergent
    abilities that have turned the world of AI on its head.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练使模型能够学习语言，包括语法和句法，并似乎能够获得足够的世界知识，从而使得这些突现的能力彻底颠覆了人工智能的世界。
- en: The decoder step takes the input prompt and produces output token after output
    token until a unique stop token is generated. Because so much of language and
    the way the world works was learned during pretraining, the decoder step has the
    side effect of producing extraordinary output even though the decoder is, in the
    end, just predicting most likely token after most likely token.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 解码步骤将输入提示转换为一个个输出标记，直到生成唯一的停止标记为止。由于在预训练过程中已经学到了大量语言和世界运作的知识，因此解码步骤具有副作用，能够生成非凡的输出，尽管解码器最终只是预测一个个最可能的标记。
- en: More specifically, during the prediction process, GPT-style models use [*attention*](glossary.xhtml#glo7)
    to assign importance to the different tokens in the input sequence, thereby capturing
    relationships between them. This is the primary difference between a transformer
    model and older recurrent neural networks. The transformer can pay attention to
    different parts of the input sequence, enabling it to identify and use the relationships
    between tokens even if they are far apart within the input.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体来说，在预测过程中，GPT 风格的模型使用[*注意力机制*](glossary.xhtml#glo7)来为输入序列中的不同标记分配重要性，从而捕捉它们之间的关系。这是变换器模型与旧版循环神经网络的主要区别。变换器可以关注输入序列的不同部分，使得它能够识别并利用标记之间的关系，即使它们在输入中相距较远。
- en: When used in chat mode, LLMs give the illusion of a back-and-forth discussion
    when, in reality, each new prompt from the user is passed to the model along with
    all the previous text (the user’s prompts and the model’s replies). Transformer
    models have a fixed input width (*context window*), which is currently around
    4,000 tokens for GPT-3.5 and some 32,000 for GPT-4\. The large input window makes
    it possible for the attention portion of the model to go back to things that appeared
    far back in the input, which is something recurrent models cannot do.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在聊天模式下使用时，大型语言模型给人一种你来我往的讨论幻觉，实际上，用户的每个新提示都会与所有之前的文本（包括用户的提示和模型的回答）一起传递给模型。变换器模型有一个固定的输入宽度（*上下文窗口*），对于
    GPT-3.5，目前大约为 4000 个标记，而 GPT-4 则为大约 32,000 个标记。这个较大的输入窗口使得模型的注意力部分能够回溯到输入中较早出现的内容，这是循环神经网络无法做到的。
- en: Large language models are ready for use after pretraining if desired, but many
    applications fine-tune them first using domain-specific data. For generic models
    like GPT-4, fine-tuning likely consisted of a step known as [*reinforcement learning
    from human feedback (RLHF)*](glossary.xhtml#glo87). In RLHF, the model is trained
    further using feedback from real human beings to align its responses to human
    values and societal expectations.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，大型语言模型在预训练后即可使用，但许多应用首先会使用特定领域的数据对其进行微调。对于像 GPT-4 这样的通用模型，微调可能包括一个称为 [*人类反馈强化学习（RLHF）*](glossary.xhtml#glo87)的步骤。在
    RLHF 中，模型通过使用来自真实人类的反馈进一步训练，以使其回应符合人类价值观和社会期望。
- en: This is necessary because LLMs are not conscious entities, and thus they cannot
    understand human society and its many rules. For example, unaligned LLMs will
    respond with step-by-step instructions for many activities that human society
    restricts, like how to make drugs or bombs. The “Sparks” paper contains several
    such examples of GPT-4 output before the RLHF step that aligned the model with
    societal expectations.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这是必要的，因为 LLMs 并不是有意识的实体，因此它们无法理解人类社会及其众多规则。例如，未对齐的 LLMs 会为许多人类社会所限制的活动提供逐步的操作指南，比如如何制造毒品或炸弹。论文《Sparks》包含了多个
    GPT-4 输出的例子，这些输出发生在 RLHF 步骤之前，这一步将模型与社会期望对齐。
- en: Stanford University’s open source Alpaca model is based on LLaMa, a large language
    model from Meta. As of this writing, Alpaca has not undergone an alignment process
    and will answer questions that GPT and other commercial LLMs correctly refuse
    to answer.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 斯坦福大学的开源 Alpaca 模型基于 Meta 的大型语言模型 LLaMa。截至本文撰写时，Alpaca 尚未经过对齐过程，因此会回答 GPT 和其他商业
    LLMs 正确拒绝回答的问题。
- en: '*Conclusion: Alignment is absolutely critical to ensure that powerful language
    models conform to human values and societal norms.*'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '*结论：对齐是确保强大语言模型符合人类价值观和社会规范的绝对关键。*'
- en: '****'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: A remarkable property of LLMs is their [*in-context learning*](glossary.xhtml#glo56)
    ability. In-context learning refers to the model learning on the fly from information
    supplied to it without altering its weights. In-context learning is different
    from fine-tuning a model. In fine-tuning, a previously trained model is tailored
    to a task by updating the weights using new training data. In-context learning
    adds new information to the LLM as part of the prompt while holding the model’s
    weights fixed.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 的一个显著特性是它们的 [*上下文学习*](glossary.xhtml#glo56)能力。上下文学习指的是模型通过提供给它的信息即时学习，而无需改变其权重。上下文学习与微调模型不同。在微调中，一个已经训练好的模型通过使用新的训练数据更新权重，以适应某个任务。上下文学习则是将新的信息作为提示的一部分添加到
    LLM 中，同时保持模型的权重不变。
- en: 'Reviewing the literature on LLMs leads inevitably to the phrases “zero-shot,”
    “one-shot,” and “few-shot,” each of which refers to in-context learning by the
    number of examples given to the model. Traditional training sets include hundreds
    to millions of examples, as we now appreciate. In-context learning is closer to
    what humans do: learning from context with, at most, only a few examples.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 审查 LLMs 文献时不可避免地会遇到“零-shot”、“one-shot”和“few-shot”这些术语，每个术语都指的是通过提供给模型的示例数量来进行上下文学习。传统的训练集包括数百到数百万个示例，正如我们现在所理解的那样。上下文学习更接近人类的学习方式：通过上下文学习，最多只有几个示例。
- en: Zero-shot learning is using the LLM without supplying examples; that is, out
    of the box. Similarly, one-shot learning uses a single example and few-shot learning
    a few (say, three to five).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 零-shot 学习是指在不提供示例的情况下使用 LLM；也就是说，开箱即用。类似地，one-shot 学习使用一个示例，而 few-shot 学习使用几个（比如三到五个）。
- en: The attention mechanism baked into the transformer network architecture is the
    likely source of an LLM’s in-context learning ability. The attention mechanism
    lets the network focus on different input tokens when deciding the next token
    to output. Notice that I say *likely*. At present, it isn’t entirely clear how
    LLMs accomplish in-context learning.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 转换器网络架构中内置的注意力机制很可能是 LLMs 上下文学习能力的来源。注意力机制使得网络在决定输出下一个标记时能够集中关注不同的输入标记。注意，我说的是
    *很可能*。目前，还不完全清楚 LLMs 是如何实现上下文学习的。
- en: 'As an example, consider this interaction with GPT-4, where the lines in italics
    are my prompts:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个例子，考虑与 GPT-4 的互动，其中斜体部分是我的提示：
- en: '*“apple 4” => I love red apples. Now, what is “banana 3”?*'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '*“apple 4” => 我喜欢红苹果。那么，“banana 3”是什么呢？*'
- en: 'It seems like you’re providing a pattern using numbers and fruits. Since you
    mentioned “apple 4” and expressed your love for red apples, I’ll follow the pattern
    and associate “banana 3” with a statement related to bananas. Here’s an example:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来你在使用数字和水果提供一个模式。既然你提到了“苹果 4”并表达了你对红苹果的喜爱，我将遵循这个模式，并将“香蕉 3”与一个与香蕉相关的句子关联。以下是一个示例：
- en: “Banana 3” => I enjoy eating ripe bananas.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: “香蕉 3” => 我喜欢吃熟透的香蕉。
- en: '*Rule: <word> <length> implies <length> word sentence using <word>. What is
    “banana 3”?*'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '*规则：<word> <length> 表示使用 <word> 生成一个 <length> 字的句子。什么是“香蕉 3”？*'
- en: 'Using the rule you provided, “banana 3” implies a 3-word sentence using the
    word “banana”. Here’s an example:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 使用你提供的规则，“香蕉 3”意味着使用“香蕉”这个词生成一个三词句子。以下是一个示例：
- en: Bananas are delicious.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 香蕉很好吃。
- en: '*“cucumber 4”, “durian 5”, “cucumber 6”*'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '*“黄瓜 4”、“榴莲 5”、“黄瓜 6”*'
- en: 'Following the rule you provided, I will create sentences with the specified
    word and length:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你提供的规则，我将使用指定的单词和长度创建句子：
- en: 'Cucumber 4: Cucumbers taste quite refreshing'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 黄瓜 4：黄瓜的味道非常清爽。
- en: 'Durian 5: Durian has a unique, pungent smell.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 榴莲 5：榴莲有一种独特的、强烈的气味。
- en: 'Cucumber 6: I prefer cucumbers in my salad.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 黄瓜 6：我喜欢在沙拉里加入黄瓜。
- en: My first prompt wasn’t terribly explicit. I suspect most humans would figure
    out the rule from this one example, but GPT-4’s initial assumption wasn’t correct.
    My second prompt formulated the general rule, which was enough for GPT-4 to understand
    what to do and then apply the rule in other circumstances. The durian example
    has six words instead of five, but that’s most likely a consequence of LLMs’ known
    difficulty counting. In-context learning taught GPT-4 how to use the rule without
    modifying its weights.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我的第一次提示并不是特别明确。我怀疑大多数人能够通过这个示例推测出规则，但 GPT-4 最初的假设并不正确。我的第二次提示阐明了通用规则，这足以让 GPT-4
    理解该做什么，并在其他情况下应用这个规则。榴莲的例子有六个单词，而不是五个，但这很可能是大型语言模型已知的难以计数的结果。上下文学习教会了 GPT-4 如何在不修改其权重的情况下使用这个规则。
- en: This is a book on AI, and we’ve spent considerable effort learning how machine
    learning models work. Can GPT-4 use in-context learning to train and apply a model?
    Let’s find out using the iris dataset from [Chapter 1](ch01.xhtml).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一本关于人工智能的书，我们已经花费了相当大的努力来学习机器学习模型是如何工作的。GPT-4 能否使用上下文学习来训练和应用模型呢？让我们通过使用 [第一章](ch01.xhtml)
    的鸢尾花数据集来找出答案。
- en: In my first attempt, I passed the 100-sample, 3-feature iris training data-set
    to GPT-4 with the prefix “Here is a three-feature dataset.” To my surprise, it
    immediately recognized the dataset as the famous iris dataset even though the
    version we’re using is only a subset, with 100 of the 150 samples and 3 of the
    4 features. So, I permuted the order of the features per sample, which was enough
    for GPT-4 to treat the dataset as novel.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的第一次尝试中，我将一个包含 100 个样本、3 个特征的鸢尾花训练数据集传递给 GPT-4，并加上了前缀“这是一个三特征数据集。”令我惊讶的是，尽管我们使用的数据集只是鸢尾花数据集的一个子集，包含
    150 个样本中的 100 个和 4 个特征中的 3 个，GPT-4 还是立刻识别出了这个数据集。于是，我对每个样本的特征顺序进行了置换，这足以让 GPT-4
    将该数据集视为新的数据集。
- en: Next, I passed the associated training set labels to GPT-4, and it understood
    that they paired with the collection of feature vectors passed first.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将相关的训练集标签传递给 GPT-4，它理解到这些标签与之前传递的特征向量集合是配对的。
- en: 'Finally, I gave GPT-4 a test dataset of 21 samples without labels and asked
    it to train a 3-nearest neighbor model and apply it to the test set. I chose the
    dataset so the three classes appeared exactly seven times each, meaning the test
    set is balanced. Here’s my prompt:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我给 GPT-4 提供了一个没有标签的 21 个样本的测试数据集，并要求它训练一个 3 最近邻模型并将其应用于测试集。我选择了这个数据集，使得三种类别分别出现了七次，意味着测试集是平衡的。以下是我的提示：
- en: '*Use the dataset and labels to train a 3-nearest neighbor model. Then, apply
    the model to these unknown samples:*'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用数据集和标签训练一个 3 最近邻模型。然后，将模型应用于这些未知样本：*'
- en: '*(list of samples removed)*'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '*(样本列表已删除)*'
- en: '*Show me only the predicted labels. Do not show me any code.*'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*只显示预测的标签，不要显示任何代码。*'
- en: 'GPT-4 replied with a list of class labels:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 给出了一个类别标签列表：
- en: 'I have trained a 3-nearest neighbor model using the provided dataset and labels.
    Here are the predicted class labels for the unknown samples:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用提供的数据集和标签训练了一个 3 最近邻模型。以下是对未知样本的预测类别标签：
- en: '[2,2,1,1,1,1,0,2,0,0,1,0,1,0,0,0,2,1,2,1,2]'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[2,2,1,1,1,1,0,2,0,0,1,0,1,0,0,0,2,1,2,1,2]'
- en: How well did it do? The actual test set class labels are
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 它的表现如何？实际测试集的类别标签是
- en: '[2,1,1,1,1,1,0,2,0,0,2,0,2,0,0,0,2,1,2,1,2]'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[2,1,1,1,1,1,0,2,0,0,2,0,2,0,0,0,2,1,2,1,2]'
- en: meaning GPT-4’s in-context classification was 85 percent accurate. There are
    three classes, so random guessing would be right about one time in three, or 33
    percent of the time; therefore, GPT-4 did something with the dataset to arrive
    at the given class labels.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着GPT-4的上下文分类准确率达到了85%。有三种类别，因此随机猜测的正确率大约为三分之一，或33%的时间；因此，GPT-4在数据集上做了一些处理，得出了给定的类别标签。
- en: 'But what? To find out, I asked it:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 可是，什么呢？为了搞清楚，我问了它：
- en: '*Tell me what you did to arrive at the set of labels for the unknown samples.
    Do not show me code.*'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '*告诉我你是如何得出未知样本标签的，不要给我看代码。*'
- en: 'Here’s its reply:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的回复：
- en: 'To arrive at the set of labels for the unknown samples, I followed these steps:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 为了得出未知样本的标签，我按照以下步骤操作：
- en: 'Prepared the data: I used the given dataset containing 100 samples with 3 features
    each and their corresponding class labels.'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备数据：我使用了给定的数据集，其中包含100个样本，每个样本有3个特征及其相应的类别标签。
- en: 'Trained a 3-nearest neighbor model: I trained a 3-nearest neighbor (k-NN) classifier
    using the provided dataset and labels. The model learns the relationship between
    the features and the class labels without explicitly building a model, instead
    relying on the similarity between samples in the feature space.'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练了一个3-最近邻模型：我使用提供的数据集和标签训练了一个3-最近邻（k-NN）分类器。该模型通过学习特征和类别标签之间的关系，而不是显式构建模型，依赖于特征空间中样本之间的相似性。
- en: 'Applied the model to the unknown samples: I provided the model with the 21
    unknown samples, each with 3 features.'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型应用于未知样本：我为模型提供了21个未知样本，每个样本有3个特征。
- en: 'Predicted the class labels: The k-NN model predicted the class labels for each
    of the unknown samples by finding the 3 nearest neighbors (i.e., the 3 training
    samples with the most similar feature values) and assigning the most common class
    label among those neighbors to the unknown sample.'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测类别标签：k-NN模型通过找到3个最近邻（即特征值最相似的3个训练样本），并将这些邻居中最常见的类别标签分配给未知样本，从而预测每个未知样本的类别标签。
- en: 'GPT-4’s response made me wonder if it used an external program to build and
    train the model, so I asked:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的回应让我怀疑它是否使用了外部程序来构建和训练模型，于是我问：
- en: '*Did you use an external program to train the 3-nearest neighbor model or did
    you simulate the operation of a 3-nearest neighbor model?*'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '*你是使用外部程序训练3-最近邻模型，还是模拟了3-最近邻模型的操作？*'
- en: 'It responded:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 它回应道：
- en: As an AI language model, I cannot directly execute code or use external programs.
    However, I can simulate the operation of a 3-nearest neighbor model and describe
    the process, which is what I did in my previous response. I described the steps
    that would be followed to train a 3-nearest neighbor model using the provided
    dataset and labels, and then apply it to predict the class labels for the unknown
    samples.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个AI语言模型，我不能直接执行代码或使用外部程序。然而，我可以模拟一个3-最近邻模型的操作并描述过程，这正是我在之前的回复中所做的。我描述了使用提供的数据集和标签来训练一个3-最近邻模型，然后应用它来预测未知样本的类别标签的步骤。
- en: 'This remarkable emergent property begs the question: where do these emergent
    abilities come from?'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这一显著的涌现特性引发了一个问题：这些涌现的能力从何而来？
- en: '****'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: The abilities of large language models like GPT-4 were not intended; they are
    a happy accident, as a famous painting instructor might have said. So what in
    the data, training, and model architecture enables them to do what they do? As
    alluded to earlier, no one yet knows for sure, but we can make some guesses.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 像GPT-4这样的巨大语言模型的能力并非故意设计，而是一个偶然的收获，正如一位著名的绘画导师可能会说的那样。那么，数据、训练和模型架构中的什么因素使它们能够做到这些？正如前面提到的，目前没有人能确定这一点，但我们可以做一些猜测。
- en: 'Large language models are trained on a vast corpus of human-generated text.
    Captured in that text is how humans use language: in other words, grammar and
    style. The original goal of LLMs was to capture human language use by predicting
    the proper (best) output token during the generation process. Increasing the model’s
    capacity (by adding nodes and/or layers, or increasing the number of weights)
    improves the quality of the predicted text. I saw this when experimenting with
    Alpaca’s 7 billion, 13 billion, and 30 billion parameter models. As an example,
    I gave all three models the following prompt:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型是通过大量的人类生成文本进行训练的。这些文本中包含了人类如何使用语言：换句话说，语法和风格。LLM的最初目标是通过预测生成过程中正确（最佳）的输出标记来捕捉人类语言的使用。增加模型的容量（通过增加节点和/或层，或增加权重数量）可以提高预测文本的质量。我在实验Alpaca的70亿、130亿和300亿参数模型时看到了这一点。作为示例，我给了这三个模型以下的提示：
- en: '*Tell me a story about unicorns and the tragedy of the human condition.*'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '*讲一个关于独角兽和人类困境悲剧的故事。*'
- en: 'Here are the first paragraphs generated by each of them. Each successively
    larger model produced more accurate and sophisticated text than the next smaller
    model:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是它们生成的前几段。每个逐渐增大的模型都生成了比下一个较小模型更准确、更复杂的文本：
- en: '**7 billion**'
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**70亿**'
- en: 'Once upon a time, there was a unicorn named Hope who lived in an enchanted
    forest filled with magical creatures like fairies and dragons. She had been blessed
    by her mother to have wings that could take flight at any moment so she would
    never be trapped again. But one day when the sun rose, something happened which
    changed everything for Hope: a human came into their world.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 很久很久以前，有一只名叫Hope的独角兽，它生活在一个充满魔法生物的魔法森林里，那里有精灵和龙等神奇的生物。她得到了母亲的祝福，拥有可以随时飞翔的翅膀，这样她就再也不会被困住了。但是有一天，当太阳升起时，发生了一件改变一切的事情：一个人类进入了他们的世界。
- en: '**13 billion**'
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**130亿**'
- en: Once upon a time, there was this beautiful unicorn who lived in an enchanted
    forest with her friends - other magical creatures like fairies and elves... But
    one day she met a young man from another world called “Human”. He had come to
    the land of magic looking for adventure. The Unicorn fell deeply in love, but
    it was not meant to be as he could never truly understand her or share his life
    with someone who lived so differently than him.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 很久很久以前，有一只美丽的独角兽，她与她的朋友们——其他魔法生物，如精灵和精灵们——一起生活在一个魔法森林里……但有一天，她遇到了一个来自另一个世界的年轻人，名叫“人类”。他来到魔法的土地寻找冒险。独角兽深深地爱上了他，但他们的爱情注定无法实现，因为他永远无法真正理解她，或者与一个生活方式如此不同的人共同度过一生。
- en: '**30 billion**'
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**300亿**'
- en: Once upon a time, there was a magical kingdom where unicorns roamed free in
    their natural habitat. The people who lived here were happy to have these majestic
    creatures as neighbors; they brought joy wherever they went and helped keep the
    land safe from any dangers that might arise.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 很久很久以前，有一个神奇的王国，独角兽们自由自在地在它们的自然栖息地中漫游。生活在这里的人们很高兴能有这些威武的生物做邻居；它们无论走到哪里都带来快乐，并帮助守护这片土地，防止可能出现的任何危险。
- en: None of the models produced outstanding output, but subjectively we might judge
    each larger model’s work as better than the previous one. None of the models appeared
    to understand the “tragedy of the human condition” portion of the prompt.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管没有一个模型生成了出色的输出，但从主观上看，我们可能会认为每个较大模型的作品都比前一个更好。没有一个模型似乎理解“人类困境的悲剧”部分的提示。
- en: 'For comparison purposes, here’s the first paragraph of GPT-4’s response:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对比，下面是GPT-4回答的第一段：
- en: Once upon a time, in a world where magic was real and unicorns roamed free,
    there existed a kingdom filled with peace and prosperity. This mystical realm
    was called Elysium, and it was a place where humans and unicorns lived in harmony.
    The unicorns, with their opalescent horns and otherworldly beauty, were the guardians
    of the land, and their presence brought an aura of enchantment that touched the
    lives of everyone who lived there.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 很久很久以前，在一个魔法真实存在、独角兽自由漫游的世界里，存在着一个充满和平与繁荣的王国。这个神秘的领域叫做“极乐世界”，人类和独角兽们在这里和谐共处。独角兽们拥有珍珠般的角和超凡脱俗的美丽，它们是这片土地的守护者，它们的存在带来了魔法的气息，触动了每一个生活在这里的人的心灵。
- en: 'GPT-4’s story was rather long and detailed. It failed to create novel names
    for characters and places, like Elysium, but the story seemed to capture the essence
    of the prompt. Here’s the final paragraph:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的故事相当长且详细。它未能为角色和地点创造新颖的名称，比如“极乐世界”，但故事似乎捕捉到了提示的精髓。以下是最后一段：
- en: The tragedy of the human condition continued to echo throughout the ages, but
    so too did the hope and love that Eira had shown in her final moments. It was
    a love that transcended time and death, inspiring the people of Elysium to never
    forget the magic and wonder that was once shared between humans and unicorns.
    And as the story of Eira, Lysander, and their incredible sacrifice was passed
    down through generations, the spirit of Elysium remained alive, a testament to
    the power of love, friendship, and the enduring connection between two worlds.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 人类处境的悲剧在岁月中回响，但艾拉在最后时刻展现出的希望和爱也同样回荡。这是一种超越时间与死亡的爱，激励了极乐世界的人们永远铭记曾经在人类与独角兽之间共享的魔法与奇迹。当艾拉、莱桑德及他们惊人牺牲的故事代代相传时，极乐世界的精神依旧存在，成为了爱、友谊以及两个世界之间持久联系的力量的见证。
- en: In GPT-4’s story, Eira (a human) and Lysander (a unicorn) fall in love, and
    Eira must sacrifice herself to stop an evil sorcerer from destroying their land.
    Clearly, big LLMs have a greater grasp of language and how to use it compared
    to simpler models.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPT-4的故事中，艾拉（人类）和莱桑德（独角兽）相爱，艾拉必须牺牲自己以阻止一个邪恶的巫师摧毁他们的家园。显然，较大的LLM相比于更简单的模型，能够更好地掌握语言及其使用方式。
- en: A transformer model generates output tokens as samples from a probability distribution;
    think of rolling a die to get a number in the range one through six, where the
    probability of rolling a one isn’t the same as the probability of rolling a six.
    The distribution is learned during the pretraining process.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器模型生成的输出标记是从概率分布中采样的；可以将其想象为掷骰子，得到一个介于1到6之间的数字，其中掷出1的概率与掷出6的概率不同。这个分布是在预训练过程中学习到的。
- en: A threshold was crossed as LLM capacity increased over time. Beyond this point,
    emergent abilities appeared and improved as a function of model size. I think
    it is likely that crossing that threshold allowed these models to learn a high-dimensional
    probabilistic representation of not only grammar and style but of the world in
    general, including contextual relationships and simulations. In other words, learning
    the best possible next token to sample and output required the evolution of abilities
    tied to the model’s attention mechanism and the embedded feedforward neural networks.
    Again, it was a happy accident that the transformer architecture evolved such
    abilities; this did not happen by design. This suggests that we can expect great
    things as more advanced transformer architectures come along; architectures designed
    to increase the power of LLMs’ emergent skills.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 随着LLM能力的逐步提升，跨越了一个门槛。在这个临界点之后，随着模型规模的增大，出现了新的能力，并且不断改善。我认为，跨越这个门槛使得这些模型能够学习到一个高维的概率表示，不仅是语法和风格，还有更广泛的世界观，包括上下文关系和模拟。换句话说，学习最佳的下一个标记以进行采样和输出需要模型的注意力机制和嵌入式前馈神经网络能力的进化。同样，变压器架构能够进化出这些能力是一种幸运的偶然，这并不是有意为之。这表明，随着更先进的变压器架构的出现，我们可以期待更多令人惊叹的成果；这些架构旨在提升LLM的涌现能力。
- en: '**KEY TERMS**'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键术语**'
- en: artificial general intelligence (AGI), artificial narrow intelligence (ANI),
    attention, context encoding, embedding, generative pretrained transformer, hallucination,
    in-context learning, large language model (LLM), recurrent neural network, reinforcement
    learning from human feedback (RLHF), token, transformer
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 人工通用智能（AGI），人工狭义智能（ANI），注意力机制，上下文编码，嵌入，生成式预训练变压器，幻觉，内置学习，大型语言模型（LLM），递归神经网络，人类反馈强化学习（RLHF），标记，变压器
