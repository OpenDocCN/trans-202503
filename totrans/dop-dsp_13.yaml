- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Troubleshooting Hosts
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 主机故障排除
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: Engineers spend a lot of time trying to figure out why something isn’t working
    as intended. Instrumentation, tracing, and monitoring play big roles in determining
    the health of a host or application, but sometimes, observability is not enough.
    There will be times when you’ll need to roll up your sleeves and figure out why
    something is broken and how to fix it. In other words, you’ll be troubleshooting
    and debugging. *Troubleshooting* is the process of analyzing the system and rooting
    out potential causes of trouble. *Debugging*, on the other hand, is the process
    of discovering the cause of trouble and possibly implementing steps to remedy
    it. The differences are subtle, and in fact, you can think of debugging as a subset
    of troubleshooting. Most of what you’ll do in this chapter is considered troubleshooting.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 工程师们花费大量时间试图弄清楚为什么某些事情不能按预期运行。仪器设备、跟踪和监控在确定主机或应用程序的健康状态方面起着重要作用，但有时仅靠可观察性还不够。有时候，你需要挽起袖子找出为什么某些事情出了问题以及如何修复它。换句话说，你将进行故障排除和调试。*故障排除*
    是分析系统并排除潜在问题原因的过程。而*调试* 则是发现问题原因并可能实施修复步骤的过程。两者之间的区别微妙，实际上，你可以把调试看作是故障排除的一个子集。本章中的大部分内容都可视为故障排除。
- en: In this chapter, you’ll explore common performance problems and issues you may
    encounter on a Linux host. You’ll look at symptoms, commands you can use to diagnose
    various potential problems, and the next steps to take after troubleshooting.
    By the end of this chapter, you’ll have expanded your command line arsenal and
    sleuthing skills to troubleshoot common issues.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将探讨Linux主机上常见的性能问题和可能遇到的问题。你将查看症状、可以用来诊断各种潜在问题的命令，以及故障排除后要采取的下一步措施。通过本章的学习，你将扩展你的命令行工具库和侦察技能，以解决常见问题。
- en: 'Troubleshooting and Debugging: A Primer'
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故障排除与调试：入门指南
- en: Troubleshooting and debugging is an art, not an exact science. Rarely will you
    see a big neon sign with an arrow pointing to the exact issue. Most of the time,
    you’ll find a trail of breadcrumbs that leads you from clue to clue. You may have
    to crawl through the weeds to find those crumbs, and you may want to pull out
    your hair before you find what you’re looking for. But diagnosing a broken system
    can be very rewarding, and figuring out an issue that’s plaguing your customers
    or haunting a coworker can feel amazing.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 故障排除和调试是一门艺术，而非一门精确的科学。很少会看到一个大型霓虹灯牌上有一个指向确切问题的箭头。大多数时候，你会找到一串串面包屑，从线索到线索引导你。你可能需要在草丛中爬行，可能会在找到所需内容之前抓狂。但诊断一个破损系统可能会带来极大的满足感，找到困扰你的客户或同事的问题会让你感到惊喜。
- en: 'But even an artist needs a method, and having a standard set of steps and techniques
    to follow whenever you are investigating an issue is a great way to start. So
    here are some tips to keep in mind when venturing forth to confront those fickle
    beasts we call hosts:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 但即使是一位艺术家也需要方法，拥有一套标准的步骤和技术，每当你调查问题时都跟随，是开始的好方法。因此，以下是在面对我们称之为主机的这些善变的野兽时要记住的一些技巧：
- en: Start simple. When troubleshooting a problem, it can be tempting to jump to
    conclusions and assume it’s the worst-case scenario. Instead, be methodical and
    build upon the knowledge you have gained. The problem is usually human error.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从简单开始。在解决问题时，很容易贸然下结论并假设是最坏的情况。相反，要有方法论，建立在你所获取的知识基础之上。问题通常出在人为错误。
- en: Build a mental model. Understanding what the system’s role is and how it interacts
    with other systems will help you troubleshoot faster. You will find yourself spending
    less time worrying about architecture and more time working on the issue.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 建立心理模型。理解系统的角色及其与其他系统的交互方式将有助于你更快地进行故障排除。你会发现自己花费更少的时间担心架构问题，更多时间解决实际问题。
- en: Take your time developing a theory. You may want to latch on to the first clue
    you find, but it’s always worth checking to see if the breadcrumb trail leads
    any farther. Come up with a test to validate your theory.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给自己时间构建理论。你可能会想抓住找到的第一个线索，但检查一下面包屑能否引领你更远总是值得的。制定一个测试来验证你的理论。
- en: Have consistent tools across hosts. Make sure your hosts were built with the
    same tooling. There is nothing worse than logging in to a host and finding out
    it is not like the others. Tool consistency is one of the benefits of building
    your hosts with automation.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保主机之间使用一致的工具。确保你的主机是使用相同的工具构建的。没有什么比登录到一台主机时发现它与其他主机不同更糟糕的了。工具的一致性是通过自动化构建主机的好处之一。
- en: Keep a journal. Keep a high-level account of problems, symptoms, and fixes so
    you don’t forget important details about an issue. Your future self will thank
    you.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持记录。保持一个高层次的问题、症状和修复的记录，这样你就不会忘记关于某个问题的重要细节。你的未来的自己会感谢你的。
- en: Know when to ask for help. If your business depends on solving an issue but
    you are struggling to find the cause, it is best to send up a flare. Someone with
    more experience can usually help, and someday, you will pay that knowledge forward
    or maybe even return the favor.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 知道什么时候寻求帮助。如果你的业务依赖于解决一个问题，但你在找不到原因时感到困惑，最好发出求救信号。经验丰富的人通常能够提供帮助，某一天，你也会将这些知识传递下去，甚至回报这份帮助。
- en: 'Scenario: High Load Average'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 情景：高负载平均值
- en: Linux has a metric called *load average* that provides an idea of how busy a
    host is. The load average takes into account data like CPU and I/O when calculating
    this number. The load of a system is displayed in 1-minute, 5-minute, and 15-minute
    averages. At first glance, any high number in an average might seem like a problem.
    But troubleshooting a high load average can be tricky because a high load doesn’t
    always indicate that your host is in a degraded state. A busy host can have a
    high load but still respond to requests and commands without issue. It’s like
    when two people have the same temperature, but one person is awake and functioning
    in a normal capacity and the other is bedridden and lethargic. Each host and workload
    is different, so you first need to identify what a normal range for your host
    looks like. A good rule of thumb is if the load average is larger than the CPU
    core count, you may have processes waiting and causing latency or performance
    degradation. When investigating this scenario, a good first step is to identify
    the high load and try to locate any process that could be causing it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Linux 有一个名为*负载平均值*的度量，它可以反映主机的忙碌程度。负载平均值在计算时会考虑 CPU 和 I/O 等数据。系统的负载会以 1 分钟、5
    分钟和 15 分钟的平均值显示。乍一看，任何一个高值可能都会被认为是问题。但排查高负载平均值时可能会比较棘手，因为高负载并不总是意味着主机处于降级状态。一台忙碌的主机可能会有较高的负载，但仍然能够正常响应请求和命令。就像两个人体温相同，但一个人保持清醒，正常运作，另一个人则躺在床上，行动迟缓。每台主机和每种工作负载都是不同的，因此你需要首先确定你主机的正常负载范围。一个简单的经验法则是，如果负载平均值大于
    CPU 核心数，那么可能有进程在等待，导致延迟或性能下降。在调查这种情况时，第一步是确定高负载，并尽量找到可能导致负载增加的进程。
- en: uptime
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: uptime
- en: 'Enter the `uptime` command to display how long a host has been running, the
    number of logged-in users, and the system load. It reports the load in 1-minute,
    5-minute, and 15-minute averages:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 输入 `uptime` 命令以显示主机的运行时间、已登录用户的数量以及系统负载。它以 1 分钟、5 分钟和 15 分钟的平均值报告负载：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This four-core CPU host has been `up` for `47 days` and `31 minutes`, and `2
    users` are currently logged in. The 1-minute `load average` is `8.05`. The 5-minute
    `load average` is `1.01`, which means the pressure on the system has been increasing
    during somewhere between 1 and 5 minutes of runtime. You know this because the
    15-minute `load average` is `0.00` (no load at that time). If the numbers were
    reversed, with the 15-minute load showing the higher number and the 1-minute load
    at zero, you could infer that the spike in load is not ongoing and happened around
    15 minutes ago. Since this load seems to be increasing and has been climbing for
    more than 5 minutes, and since it is greater than the CPU core count, it may be
    worth investigating why.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这台四核 CPU 主机已经`运行`了 `47天` `31分钟`，当前有 `2个用户` 登录。1分钟`负载平均值`是`8.05`。5分钟`负载平均值`是`1.01`，这意味着在
    1 到 5 分钟的运行期间，系统的负载正在增加。你之所以知道这一点，是因为 15 分钟的`负载平均值`是 `0.00`（那个时间没有负载）。如果这些数字相反，即
    15 分钟的负载值较高，而 1 分钟的负载为零，那么你可以推断出负载的激增并不是持续发生的，而是发生在大约 15 分钟前。由于这个负载似乎在不断增加，并且已经持续攀升超过
    5 分钟，同时它大于 CPU 核心数，因此可能值得调查其原因。
- en: top
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: top
- en: The `top` command displays information about a system and the processes running
    on that host. It provides details like CPU percentage, load average, memory, and
    process information. Execute the `top` command to launch an interactive real-time
    dashboard showing system information, as shown in [Figure 10-1](#figure10-1).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`top`命令显示有关系统和在该主机上运行的进程的信息。它提供了诸如CPU占用百分比、负载平均值、内存和进程信息等详细内容。执行`top`命令可以启动一个交互式实时仪表板，显示系统信息，如[图
    10-1](#figure10-1)所示。'
- en: '![Screenshot of running the top command, showing all the system information
    in several columns with a summary at the top](image_fi/502482c10/f10001.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![运行`top`命令的截图，显示多个列的系统信息和顶部的摘要](image_fi/502482c10/f10001.png)'
- en: 'Figure 10-1: The `top` command output on a mostly idle host'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10-1：在大部分空闲的主机上执行`top`命令的输出
- en: By default, `top` sorts all the processes by `CPU` percentage. The first row
    contains the process using the most `CPU` percentage at that given poll cycle.
    The display refreshes (polls) every 3.0 seconds, so you’ll want to view `top`
    for a few cycles before settling on a process or any data that might be or indicate
    the cause of the high load.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`top`会根据`CPU`百分比对所有进程进行排序。第一行显示的是在给定轮询周期内使用最多`CPU`百分比的进程。显示会每3.0秒刷新（轮询一次），因此你需要观察`top`几轮，才能决定哪个进程或数据可能是导致高负载的原因。
- en: 'The following snippet is from a `top` report where a process is using 120 percent
    CPU:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`top`报告中的一段，其中一个进程使用了120%的CPU：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The key columns are `PID`, `RES`, `%CPU`, `%MEM`, and `COMMAND`. (Others are
    omitted here for readability.) The `fail2ban-server` command (in the `COMMAND`
    column) is using 120.3 percent CPU and is consuming around `177,740`KB of memory,
    as shown in the `RES` column. This process is using around `1.8` percent of the
    total memory (`%MEM`) available on the host. Taking everything into account, it
    would be a good idea for you to investigate process `3048` to determine why it
    is using so much CPU.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 关键列是`PID`、`RES`、`%CPU`、`%MEM`和`COMMAND`。（为了可读性，其他列在此省略。）`fail2ban-server`命令（在`COMMAND`列中）使用了120.3%的CPU，并且消耗了大约`177,740`KB的内存，如`RES`列所示。该进程使用了主机总内存的`1.8`%（`%MEM`）。综合来看，调查进程`3048`，查明其为何消耗如此多的CPU资源，是个不错的主意。
- en: Next Steps
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 后续步骤
- en: In a scenario with a high load average, you’ll want to dig down further into
    the offending process. Perhaps this application is misconfigured, hung, or busy
    waiting on external resources (like a disk or an HTTP call). Maybe the host is
    undersized for its use case. If it’s a cloud-based instance, perhaps there aren’t
    enough CPU cores or disk IOPS. Also, check whether the host is experiencing increased
    traffic during this time, as that could indicate an intermittent spike. You can
    also use tools like `vmstat`, `strace`, and `lsof` to discover more about a process’s
    interaction with the system. (You’ll learn more details about those tools in later
    sections.)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在负载平均值较高的情况下，你需要更深入地分析问题进程。也许这个应用程序配置不当、卡住了，或者在等待外部资源（如磁盘或HTTP请求）。也有可能是主机的规格不足以应对其使用场景。如果是云实例，也许CPU核心数或磁盘IOPS不够。另外，也要检查在此期间主机是否流量增加，这可能表示出现了间歇性的流量激增。你还可以使用`vmstat`、`strace`和`lsof`等工具，进一步了解进程与系统的交互。（你将在后续章节中详细了解这些工具。）
- en: 'Scenario: High Memory Usage'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景：高内存使用
- en: Temporary spikes in traffic, performance-related issues, or an application with
    a memory leak can cause memory to be consumed at a high rate. The first step in
    investigating high memory usage is to make sure the host is really running low
    on memory. Linux likes to use all the memory for caches and buffers, so it can
    appear that free memory is low. But the Linux kernel can reallocate that cached
    memory elsewhere if needed. The `free`, `vmstat`, and `ps` commands can help identify
    how much memory is being used and what process may be the culprit.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 临时的流量激增、性能问题或内存泄漏的应用程序，都可能导致内存以较高的速度被消耗。调查高内存使用的第一步是确保主机确实存在内存不足的情况。Linux倾向于将所有内存用于缓存和缓冲区，因此可能看起来空闲内存较少。但实际上，Linux内核可以在需要时将这些缓存内存重新分配到其他地方。`free`、`vmstat`和`ps`命令可以帮助识别使用了多少内存，以及是哪个进程可能是罪魁祸首。
- en: free
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: free
- en: 'The `free` command provides a quick sanity check on system memory by displaying
    used and available memory at the time it is run. Pass the `-h` and `-m` flags
    to instruct the `free` command to show all output fields in human-readable (`-h`)
    format using the *mebibyte* unit (`-m`) of measure. In *human-readable format*,
    data appears in familiar units like *mebibyte* or *gibibyte* instead of bytes.
    The following example shows a host that’s low on available memory. Enter the following
    command to display memory:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`free` 命令通过显示运行时的已用和可用内存，提供了一个快速的系统内存检查。传递 `-h` 和 `-m` 标志，指示 `free` 命令以人类可读的（`-h`）格式，使用
    *兆二进制字节*（`-m`）为单位显示所有输出字段。在 *人类可读格式* 中，数据以类似 *兆二进制字节* 或 *吉比字节* 的单位出现，而不是字节。以下示例显示了一个内存不足的主机。输入以下命令以显示内存：'
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The system contains `981Mi` of `total` memory, and `838Mi` of memory is being
    `used`, with `95Mi` `free`. The `buff/cache` column contains information from
    data that has been read off disk and the metadata associated with it. This is
    used for fast retrieval if you need to access it again, which is why Linux tries
    to use all the system memory it can instead of letting it sit idle. A Linux host
    will swap data out of memory and write it to disk if a system is running low on
    memory. As you can imagine, using disk as memory is much slower than using actual
    RAM. If the `free` column for `Swap` is ever low, your system may be performing
    slower than it normally can. In this example, the system is swapping to disk only
    a little (`141Mi`), which can be normal.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 系统总内存为 `981Mi`，其中 `838Mi` 被 `used`，`95Mi` 为 `free`。`buff/cache` 列包含从磁盘读取的数据和相关元数据的信息。这些数据被用来加速检索，如果你需要再次访问它。正因为如此，Linux
    尝试使用所有的系统内存，而不是让它空闲。若系统内存不足，Linux 主机会将数据交换到磁盘中。正如你能想象的那样，使用磁盘作为内存比使用实际的 RAM 要慢得多。如果
    `Swap` 的 `free` 列数值过低，系统可能会比平时更慢。在这个例子中，系统仅略微交换到磁盘（`141Mi`），这可以是正常现象。
- en: The `used` and `free` columns can be misleading on a Linux host. Linux likes
    to use every bit of RAM on a system, so it may appear at a quick glance that a
    host is low on memory. Or, as in this case, it can appear that there is more memory
    than actually is available. Here, the `free` column shows `95Mi`, but according
    to the `available` column, only `43Mi` is left. When using the `free` command
    to display system memory, pay attention to the `available` column as a barometer
    of actual memory available to the system and new processes.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`used` 和 `free` 列在 Linux 主机上可能会让人误解。Linux 喜欢利用系统的每一份 RAM，因此快速查看时可能看起来主机内存不足。或者，就像这个例子一样，它可能显示比实际可用的内存更多。这里，`free`
    列显示 `95Mi`，但根据 `available` 列，实际上只剩下 `43Mi`。当使用 `free` 命令显示系统内存时，注意 `available`
    列，它是判断系统和新进程实际可用内存的一个晴雨表。'
- en: Looking at how little memory is available in this example, it’s safe to say
    this host has a memory shortage. Having roughly `43Mi` out of 1Gi left on a system
    can cause stability issues and stop new processes from being created. It can also
    force the Linux kernel to invoke the out of memory manager (OOM) and select a
    process to kill, which can and will cause unexpected behavior.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个示例中看出可用内存非常少，可以安全地说，这个主机存在内存短缺。系统剩余大约 `43Mi`（从 1Gi 中）可能会导致稳定性问题，并且阻止新进程的创建。它还可能迫使
    Linux 内核调用内存不足管理器（OOM），并选择一个进程进行终止，这可能会导致不可预期的行为。
- en: vmstat
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: vmstat
- en: 'The `vmstat` command provides useful information about processes, memory, IO,
    disks, and CPU activity. It can report this data over a period of time, which
    is an upgrade over the `free` command and makes trends much easier to spot. You’ll
    pass two parameters to the `vmstat` command: `delay`, which specifies the time
    delay between each of the polling counts, and `count`, which specifies the number
    of times `vmstat` will fetch data until it quits. For this example, you will poll
    the data five times with a one-second delay between each poll. Enter the following
    command to poll the data:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`vmstat` 命令提供了关于进程、内存、IO、磁盘和 CPU 活动的有用信息。它可以在一段时间内报告这些数据，这是对 `free` 命令的升级，使得趋势更加容易识别。你将向
    `vmstat` 命令传递两个参数：`delay`，指定每次轮询之间的时间延迟，以及 `count`，指定 `vmstat` 获取数据的次数，直到停止。对于这个示例，你将以一秒的延迟轮询五次数据。输入以下命令来轮询数据：'
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `vmstat` report is divided into multiple categories: `procs`, `memory`,
    `swap`, `io`, `system`, and `cpu`. Each category contains like columns. The first
    row of data is an average of each statistic since the last boot time. Since you
    are hunting for high memory usage, you’ll focus only on the `memory` and `swap`
    sections from the `vmstat` output.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`vmstat`报告分为多个类别：`procs`、`memory`、`swap`、`io`、`system`和`cpu`。每个类别包含类似的列。数据的第一行是自上次启动以来每个统计量的平均值。由于你正在寻找内存使用高的情况，你只会关注`vmstat`输出中的`memory`和`swap`部分。'
- en: The `swpd` column of the `memory` section shows the total swap space used; in
    this case, it’s around 54Mi (`54,392`Ki). Next comes the `free` column. According
    to `vmstat`, the free memory has fluctuated between 71,000Ki and 74,000Ki in the
    polling snapshot. This does not mean you have only 71,000Ki of memory available;
    it’s an estimate because of the free-able cache and buffers.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`memory`部分的`swpd`列显示使用的总交换空间；在本例中约为54Mi（`54,392`Ki）。接下来是`free`列。根据`vmstat`，空闲内存在轮询快照中波动在71,000Ki到74,000Ki之间。这并不意味着你只有71,000Ki可用的内存；这是一个估算，因为可释放的缓存和缓冲区。'
- en: 'Under the `swap` section are two columns: `si` (swapped in) and `so` (swapped
    out). The `si` and `so` columns indicate you are paging memory to and from the
    disk. At one point, you were swapping memory from the disk at about `104`KiB per
    second. As mentioned previously, a little swapping can be okay, but being low
    on free memory plus swapping usually indicates a memory bottleneck.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在`swap`部分下面有两列：`si`（交换入）和`so`（交换出）。`si`和`so`列表示你正在将内存页到磁盘和从磁盘交换内存。曾经有一段时间，你正在以约`104`KiB每秒的速度从磁盘交换内存。如前所述，少量交换是可以接受的，但是如果空闲内存不足并且还在交换，则通常表示存在内存瓶颈。
- en: The `r` and `b` columns under `procs` can provide good indications of possible
    bottlenecks. The `r` column is the number of running (or waiting-to-run) processes.
    A high number here can indicate a CPU bottleneck. The `b` column is the number
    of processes in an uninterruptable sleep. If the number in the `b` column is high,
    it can be a good signal that there are processes waiting on resources like disk
    or network IO.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在`procs`下的`r`和`b`列可以提供可能存在瓶颈的良好指示。`r`列是运行中（或等待运行）进程的数量。这里的高数值可能表示存在CPU瓶颈。`b`列是处于不可中断睡眠状态的进程数。如果`b`列中的数值较高，这可能是一个信号，表明有进程在等待资源，比如磁盘或网络IO。
- en: ps
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ps
- en: 'If memory usage is high on the host, you’ll want to check all the running processes
    to find where the memory is being used. The `ps` command provides a snapshot of
    the current processes on a host. You’ll use some flags to narrow down the results
    and show only the top-10 hosts sorted by most memory. Enter the following command:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果主机的内存使用量很高，你将要检查所有运行中的进程，找出内存使用情况。`ps`命令提供了主机上当前进程的快照。你将使用一些标志来缩小结果范围，并仅显示按最大内存排序的前10个主机。输入以下命令：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `-efly` and `--sort=-rss` flags are used to show all the processes in a
    long format. The `RSS` (resident set size) column shows the amount of non-swappable
    physical memory a process uses (in kilobytes), in descending numerical order.
    You pipe those results to the `head` command, which displays only 10 by default.
    The `CMD` column shows the command that belongs to each process. In this example,
    the `memory-hog` command is using around 890MB (`890,652`KB) of physical memory,
    according to the `RSS` column. Considering that this host has only 1Gi of total
    memory, that application is hogging all the memory.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`-efly`和`--sort=-rss`标志显示所有进程的长格式。`RSS`（常驻集大小）列显示进程使用的非可交换物理内存量（以千字节为单位），按降序排列。你将这些结果传输到`head`命令，默认显示前10行。`CMD`列显示每个进程所属的命令。在这个示例中，`memory-hog`命令根据`RSS`列使用了约890MB（`890,652`KB）的物理内存。考虑到这台主机只有1Gi的总内存，该应用程序正在占用所有内存。
- en: Next Steps
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下一步
- en: The steps you’ll take to resolve a high-memory-usage issue like this will depend
    on risk factors for your system and/or users. If you’re dealing with a production
    system, you’ll want to tread lightly and check the logs, traces, and metrics to
    determine when and where the problem started. If this were a new behavior on a
    production system, rolling back `memory-hog` to a previous version would be a
    great first step. (Any time you can recover quickly in production is a win.) Once
    you have remediated the issue in production, do a performance profile in a different
    environment and dig through the clues to figure out why and where the memory is
    being used.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你解决高内存使用问题的步骤将取决于系统和/或用户的风险因素。如果你在处理生产系统，你需要小心行事，查看日志、跟踪记录和度量数据，以确定问题何时何地开始。如果这是生产系统上的新行为，回滚`memory-hog`到先前版本是一个很好的第一步。（任何时候你能快速恢复生产环境，都是一次胜利。）一旦在生产环境中修复了问题，可以在不同环境中进行性能分析，深入挖掘线索，找出内存使用的原因和位置。
- en: 'Scenario: High iowait'
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景：高 iowait
- en: A host that is spending too much time waiting for disk I/O is said to have a
    condition called *high iowait*. The way to measure iowait is to check the percentage
    of time that CPUs are idle because the system has unfinished disk I/O requests
    that are blocking processes from doing other work. Significant iowait usually
    results in a host having an increased load and possibly higher reported CPU usage
    than it normally would. To put it another way, if your CPU is waiting for the
    disk to respond, it has less time to service other requests from other parts of
    the system. One cause of high iowait might be an aging, slow, or failing disk.
    Another culprit could be an application that is performing heavy disk reads and
    writes. If you are in a virtualized environment, slow network-attached storage
    is most likely where your congestion lies.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个主机花费过多时间等待磁盘 I/O，我们称其为*高 iowait*。衡量 iowait 的方法是检查 CPU 空闲的时间百分比，因为系统存在未完成的磁盘
    I/O 请求，这些请求阻塞了进程的其他工作。显著的 iowait 通常会导致主机负载增加，可能还会导致报告的 CPU 使用率高于正常水平。换句话说，如果 CPU
    在等待磁盘响应，它就没有足够的时间处理系统其他部分的请求。高 iowait 的原因可能是磁盘老化、慢速或故障。另一个原因可能是应用程序正在执行大量的磁盘读写。如果你处于虚拟化环境中，慢速的网络附加存储很可能是瓶颈所在。
- en: All systems will have some iowait, and modern CPUs are faster than storage.
    High iowait by itself, however, is not enough to signal a problem. Some systems
    with high iowait can perform without issues, while others will show significant
    signs of a bottleneck. The goal is to identify issues that are accompanied by
    high iowait. There’s no bright line with normal iowait on one side and high iowait
    on the other, so I have set the threshold for high iowait at anything over 30
    percent that is sustained over a significant period.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 所有系统都会有一定的 iowait，现代 CPU 的速度通常快于存储。然而，单独的高 iowait 并不足以表明问题。一些系统即使出现高 iowait
    也能正常运行，而另一些系统则会出现明显的瓶颈迹象。目标是找出伴随高 iowait 出现的问题。正常 iowait 和高 iowait 之间没有明确的界限，因此我将高
    iowait 的阈值设定为持续超过 30% 的情况。
- en: Two command line tools, `iostat` and `iotop`, will help you troubleshoot a host
    with high iowait.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 两个命令行工具，`iostat`和`iotop`，将帮助你排查高 iowait 的主机问题。
- en: iostat
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: iostat
- en: The `iostat` command line tool reports CPU and I/O stats for devices, so it’s
    a great tool to help you determine whether your system is experiencing any iowait.
    If `iostat` is not installed by default, use your package manager to install the
    sysstat package.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`iostat`命令行工具报告设备的 CPU 和 I/O 状态，因此它是帮助你确定系统是否出现 iowait 的绝佳工具。如果系统默认未安装`iostat`，可以使用包管理器安装
    sysstat 包。'
- en: 'As I mentioned previously, having some iowait is normal. You are looking for
    abnormal behavior, so you’ll want to poll the system over a period of time to
    get a better view of the problem, like you did with the `vmstat` command. For
    this example, enter the command below to poll for statistics every second for
    a total of 20 times. The command and output should look like the following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，拥有一定的 iowait 是正常的。你需要关注的是异常行为，因此你需要在一段时间内轮询系统，以便更好地了解问题，就像你使用`vmstat`命令时一样。在这个例子中，输入下面的命令，每秒轮询一次，持续
    20 次。命令和输出应如下所示：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The first report `iostat` prints is from the last time the host was booted.
    Since that data is not relevant to your current troubleshooting scenario, I’ve
    omitted it here, along with multiple columns from the `Device` output. The `-xz`
    flag shows only active devices using an extended stat format. The `w/s` column
    shows that the `vda` device is executing a lot of write requests per second (`1179.00`).
    The `CPU` is waiting on outstanding disk requests around `66.67%` of the time
    (`%iowait`). Finally, as further proof that this disk is quite busy, the `%util`
    (percent utilization) column shows `100%`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个报告 `iostat` 打印的是主机上次启动时的数据。由于这些数据与当前的故障排除场景无关，因此我在此省略了它，以及 `Device` 输出中的多个列。`-xz`
    标志只显示使用扩展统计格式的活动设备。`w/s` 列显示 `vda` 设备每秒执行大量写请求（`1179.00`）。`CPU` 大约 `66.67%` 的时间都在等待未完成的磁盘请求（`%iowait`）。最后，作为该磁盘非常繁忙的进一步证据，`%util`（百分比利用率）列显示为
    `100%`。
- en: You can conclude that the host is suffering from high iowait that is sustained
    and not just intermittent. More importantly, you know that the iowait is occurring
    on the device named `vda`. From here, it is worth trying to find a process that
    could be the cause of the increased iowait. You can do that with the `iotop` command,
    which you’ll explore next.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以得出结论，主机正遭遇持续的高 iowait，而不仅仅是间歇性的。更重要的是，你知道 iowait 发生在名为 `vda` 的设备上。从这里开始，值得尝试找到可能导致
    iowait 增加的进程。你可以使用 `iotop` 命令来实现，接下来你将探索这个命令。
- en: iotop
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: iotop
- en: The `iotop` command displays I/O usage in a `top`-like format. Not only does
    it provide an overview of I/O on the host, but it lets you drill down to the process
    level to locate any processes that might be causing a lot of disk I/O. Most distributions
    don’t include `iotop` by default, so use your package manager to install it.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`iotop` 命令以类似 `top` 的格式显示 I/O 使用情况。它不仅提供主机 I/O 的概述，还允许你深入到进程级别，定位任何可能导致大量磁盘
    I/O 的进程。大多数发行版默认不包括 `iotop`，因此你需要使用包管理器来安装它。'
- en: 'When running `iotop`, you’ll want to limit the output to show only active processes
    that are performing I/O, using a batch mode that polls constantly to keep the
    output concise and reveal any possible I/O patterns. This command requires elevated
    permissions, so you’ll need to run it with `sudo` or as a privileged user. Enter
    the command below:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行 `iotop` 时，你可能只希望限制输出显示执行 I/O 的活跃进程，使用不断轮询的批处理模式，以保持输出简洁并揭示可能的 I/O 模式。此命令需要提升的权限，因此你需要使用
    `sudo` 或以特权用户身份运行它。请输入以下命令：
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `-oPab` flags make `iotop` show only processes performing I/O with accumulative
    stats in a batch mode. In this example, the `heavy-io` command is at `83.26%`,
    according to the `IO` column. The `PID` column reports the process ID, which in
    this case is `88576`. No other processes in your report are using a lot of I/O,
    so it’s safe to assume that the `heavy-io` process is part of the reason for the
    high iowait.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`-oPab` 标志使得 `iotop` 仅显示执行 I/O 的进程，并以批处理模式显示累积统计信息。在这个示例中，`heavy-io` 命令的 `IO`
    列显示为 `83.26%`。`PID` 列报告了进程 ID，在此情况下为 `88576`。在报告中没有其他进程使用大量 I/O，因此可以推测 `heavy-io`
    进程是导致高 iowait 的原因之一。'
- en: Next Steps
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下一步
- en: After checking the stats and finding the process ID that is causing high iowait,
    you might want to explore what this application is used for. If you have the source
    code or configuration files, look for more clues by checking any disk operations
    or files the process has access to. Another cause for high iowait could be that
    your VM is in a cloud provider and you do not have enough provisioned I/O operations
    for your disk. Check the disk metrics to confirm and adjust the number to compensate
    the load. If all else fails, use tools like `lsof`to examine what files are open,
    `strace` to trace any system calls the process is making, or `dmesg` for any hardware
    kernel errors. (We’ll discuss `lsof`, `strace`, and `dmesg` later in this chapter.)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查统计信息并找到导致高 iowait 的进程 ID 后，你可能想要探索一下这个应用程序的用途。如果你有源代码或配置文件，可以通过检查进程访问的磁盘操作或文件来寻找更多线索。另一个导致高
    iowait 的原因可能是你的虚拟机托管在云服务提供商上，而你为磁盘预配置的 I/O 操作数量不足。检查磁盘指标以确认并调整数字，以补偿负载。如果一切都失败了，可以使用像
    `lsof` 这样的工具检查哪些文件是打开的，使用 `strace` 跟踪进程正在进行的系统调用，或者使用 `dmesg` 查找任何硬件内核错误。（我们将在本章后面讨论
    `lsof`、`strace` 和 `dmesg`。）
- en: 'Scenario: Hostname Resolution Failure'
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景：主机名解析失败
- en: Traditionally, when a service needs to connect to another service, it uses Domain
    Name System (DNS) to look up the IP address to send it a request. *DNS is a directory
    for host IP address mappings. It allows us to use names like google.com or nostarch.com
    without needing to know those hosts’ exact IP addresses. Humans are far better
    at remembering names than IP addresses like 142.250.72.78 or 104.20.208.3\. Imagine
    if you had to find a store by trying to remember its latitude and longitude coordinates
    without using GPS instead of just remembering it’s at 123 Main Street. You would
    get lost . . . a lot.*
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，当一个服务需要连接到另一个服务时，它会使用域名系统（DNS）查找IP地址并发送请求。*DNS是主机IP地址映射的目录。它允许我们使用像google.com或nostarch.com这样的名称，而无需知道这些主机的确切IP地址。人类比起像142.250.72.78或104.20.208.3这样的IP地址，更容易记住名字。想象一下，如果你不得不通过尝试记住一个商店的经纬度坐标来找到它，而不能使用GPS，而只是记住它在123
    Main Street，你会迷路…很多次。*
- en: '*For this scenario, say you have an application that is trying to connect to
    a Postgres database in your local environment. The application starts emitting
    errors in the logs that look like this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设在这种情况下，你有一个应用程序尝试连接到本地环境中的Postgres数据库。应用程序开始在日志中输出类似这样的错误：'
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It appears that the application can’t resolve the DNS record for *db.smith.lab*.
    There can be multiple reasons for the failure in name resolution. We’ll explore
    a few tools to help troubleshoot this error. Before that, though, you really need
    to understand how your host uses DNS.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来应用程序无法解析*db.smith.lab*的DNS记录。名称解析失败可能有多种原因。我们将探索一些工具来帮助排除这个错误。在此之前，你需要真正理解主机如何使用DNS。
- en: resolv.conf
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: resolv.conf
- en: 'The first place to start investigating DNS issues on any Linux host is the
    */etc/resolv.conf* file that provides information on what DNS servers to query
    and any special options needed (like timeout or security). The following is a
    *resolv.conf* file from a typical Ubuntu host:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何Linux主机上，调查DNS问题的第一步是查看*/etc/resolv.conf*文件，该文件提供了要查询的DNS服务器信息以及任何特殊选项（例如超时或安全性）。以下是典型Ubuntu主机的*resolv.conf*文件：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The file contains several comments describing `systemd-resolved`, and most importantly,
    it notes that you shouldn’t edit it. This file is controlled by the `systemd-resolved`
    service provided by *systemd*, and it will overwrite the file next time the host
    or service restarts. After the comments, the second line from the bottom contains
    the `nameserver` keyword and the IP address of the DNS server to query. On this
    Ubuntu host, the `nameserver` is set to `127.0.0.53`, which means any DNS requests
    will be sent to this address. If the local `resolver` does not know the answer
    to the query, the `resolver` will forward the request to an upstream `DNS server`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件包含了多个描述`systemd-resolved`的注释，最重要的是，它指出你不应编辑此文件。此文件由*systemd*提供的`systemd-resolved`服务控制，并且在主机或服务重新启动时，服务会覆盖该文件。在注释之后，从底部倒数第二行包含了`nameserver`关键字和查询DNS服务器的IP地址。在这台Ubuntu主机上，`nameserver`设置为`127.0.0.53`，意味着任何DNS请求都会发送到这个地址。如果本地`resolver`不知道查询的答案，`resolver`将把请求转发到上游的`DNS服务器`。
- en: The DNS upstream servers are usually set when you receive an IP address lease
    from a DHCP server. These upstream DNS servers can be internal servers that handle
    all your requests, or they can be any of the many public servers that the internet
    uses. For example, Cloudflare hosts public DNS servers at 1.1.1.1\. There are
    quite a few public DNS servers around the globe.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当你从DHCP服务器获取IP地址租约时，上游的DNS服务器会被设置。这些上游的DNS服务器可以是处理所有请求的内部服务器，也可以是互联网上使用的众多公共服务器之一。例如，Cloudflare在1.1.1.1提供公共DNS服务器。全球范围内有许多公共DNS服务器可供使用。
- en: The last line in the file modifies some specific resolver attributes using the
    `options` keyword. In this example, the `edns0` and `trust-ad` options are set.
    The `edns0` option enables expanded features to the DNS protocol. See RFC 2671
    ([https://tools.ietf.org/html/rfc2671/](https://tools.ietf.org/html/rfc2671/))
    for more details. The `trust-ad`, or authenticated data (AD) bit, option will
    include the authenticated data on all outbound DNS queries and preserve the authenticated
    data in the response. This will allow the client and server to validate the exchange
    between each other. This option is a part of a larger set of extensions that add
    security to DNS. See [https://www.dnssec.net/](https://www.dnssec.net/) for more
    information.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: resolvectl
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this example host’s *resolv.conf*, the DNS server is set to `127.0.0.53`,
    which is a local resolver that proxies any DNS request it does not know about.
    Each DNS server typically will have an upstream server that it forwards unknown
    requests to. Since you are using `systemd-resolver`, you can use a tool called
    `resolvectl` to interact with your local resolver. If this command line application
    is missing, you can install it via your package manager.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll want to know where your local DNS resolver (`127.0.0.53`) sends unknown
    requests. This might help you figure out why *db.smith.lab* resolution is failing.
    To see what DNS servers the resolver points to upstream, enter the following command:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The results show the downstream DNS server is set to `10.0.2.3` for interface
    `enp0s3`, which is the default interface and route on this host. Your setup and
    interface might be different. When any application on this host tries to connect
    to *db.smith.lab*, it first sends a DNS request to `127.0.0.53`, asking what IP
    address the hostname resolves to. The local resolver first looks for the answer
    locally. If the mapping is there, the results are returned immediately. However,
    if the answer is unknown, the resolver forwards the request to the upstream DNS
    server at IP `10.0.2.3`. Now, if the DNS server at `10.0.2.3` knows the answer
    for *db.smith.lab*, it will return a response to the local resolver, which in
    turn will respond to the user. If it doesn’t know the answer, the upstream server
    will forward that request to its upstream server until it reaches the authoritative
    server for the domain it’s looking for.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know the IP address of your local resolver and upstream DNS server,
    you can query both to look for clues.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: dig
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `dig` command line tool queries DNS servers and displays the results. This
    is extremely handy when you are troubleshooting DNS issues or need to fetch an
    IP address for a host. All you need to do is pass `dig` the hostname, and the
    response will provide information about the query and server that is responding.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'Try querying the local resolver for the IP address of *db.smith.lab*. Enter
    the following command:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `status` field 1 lets us know whether the query was successful. A successful
    query would have a status of `NOERROR`. In this example, the status is set to
    `SERVFAIL`, showing that no answer could be given. This makes sense, as the local
    DNS does not know where to find *db.smith.lab*. The `QUESTION SECTION` displays
    the query that was sent to the DNS server. In this case, the query is for the
    A record for *db.smith.lab* 2. (An *A record* is a type of DNS record that maps
    a domain to an IP address.) The `SERVER` section tells us which DNS server was
    contacted to make the query. In this example, it’s the local resolver (`127.0.0.53`)
    3, as expected.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'To test your upstream server, you can instruct `dig` to talk to a specific
    DNS server instead of the local one. This will let you verify whether DNS resolution
    is failing locally or upstream. To do this, enter the following command:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `@10.0.2.3` parameter makes `dig` skip the local DNS and query the upstream
    host directly. The results, however, are the same, and you received a `SERVFAIL`
    for the status. This means the upstream server couldn’t provide an answer for
    the hostname. You know you queried the correct server, because the `SERVER` section
    now states `10.0.2.3` instead of `127.0.0.53`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'To be safe, you should try one more query to make sure the local and upstream
    DNS servers are working correctly. First, you’ll query for a DNS record that you
    are positive will return a response. This will let you verify whether DNS is broken
    for any domains, not just *db.smith.lab*. Enter the following command to query
    the A record for google.com:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The status is `NOERROR`, and you received the A record of `142.250.72.78` in
    the `ANSWER SECTION`. This means the DNS server can resolve another hostname without
    error, but for some reason, it doesn’t know about the *db.smith.lab* A record.
    Note that when there is an error or no answer to be given, the `ANSWER SECTION`
    is omitted from the results.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Next Steps
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If there are resolution issues with a given hostname and DNS is functioning
    correctly and can resolve other hostnames, then the issues might stem from a DNS
    resolver that is missing the information that maps the hostname to an IP address.
    If your DNS is hosted on a service like Amazon Route53, make sure the record has
    not been removed by configuration management software or due to human error. If
    you manage the DNS server locally, you can look to see if the A record is present.
    If it is not, perhaps the configuration contains some syntax error preventing
    the record from being served, or perhaps the DNS server needs to be restarted
    to read in its new records.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'Scenario: Out of Disk Space'
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You will run out of disk space eventually. When this happens, you need to find
    out what is using all the space. The culprit could be anything from a misbehaving
    application to uncapped logfiles to a buildup of Docker images. To find the source
    of the problem, you’ll first need to figure out which drive and filesystem are
    low on space. Once you locate those pieces, you will be able to search for files
    on the disk that may be using a lot of space.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: df
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `df` command displays the free disk space on all the mounted filesystems
    on a host. It has multiple options, but the `-h` flag (for human-readable) is
    probably all you’ll need. To see the free space on the mounted filesystems, enter
    the following command in a terminal:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this example, device */dev/vda1* is using `100%` of its `25G` of disk space.
    The filesystem is mounted at */*, which is the root directory. If your host has
    multiple mounted disks, they’ll be visible in the output as well.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: find
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `find` command searches the filesystem for directories and files, and you
    can filter it to narrow down the search by looking for files that match only certain
    criteria or a specific directory. You can also locate files by their sizes on
    disk.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'In your example, since you know the *root* filesystem is out of space after
    running the `df` command, you should direct `find` to search there. You’ll execute
    the `find` command and search the *root* filesystem, looking for any files over
    `100M`. You’ll sort them by size and display the top 10 with the `head` command.
    This could take a while, depending on the number of files on your drive. Enter
    the following command:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: For each file located that is more than 100M, you’ll execute (`-exec` flag)
    the `du -ah` command to fetch the file size on disk in human-readable format.
    The results, with file size, are sorted with largest files first. Then, the first
    10 results are displayed.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: This output shows a file named *php7.2-fpm.log* that is located under */var/log*
    and is `10G` in size. Also, a Docker container log located in */var/lib/docker/containers*
    is using `5G` of space. Together, these files are taking up 15GB of space on your
    disk. Usually, application logs like these should rotate and not become so large.
    The fact that both files are so big should trip your Spidey sense that something
    is not right here.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: With more breadcrumbs to follow, check to see what process, if any, is using
    the *php7.2-fpm.log* file before you form a hypothesis.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: lsof
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Use the `lsof` command to list open files on a host. Files on a Linux host can
    be regular files, directories, or sockets, to name just a few. You can search
    for files owned by a particular process or by a specific user.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll use `lsof`, which requires elevated privileges, to find the process
    writing to the */var/log/php7.2-fpm.log* file. Enter the following command:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: You must pass the full path to the file you are interested in. In this case,
    it’s the logfile. The `php-fpm7` command with the `PID 23496` owns the logfile
    in question. The file descriptor is `2w`, which means the file’s descriptor is
    `2` and the file is opened for write access (`w`). The `TYPE` of file is `REG`
    (regular), representing a typical ASCII text file.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Next Steps
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When your free disk space is low and you have tracked down a file that is contributing
    to the lack of space, you have a couple of options to remedy the situation. Since
    this logfile is currently being used, truncating or deleting it out from under
    the `php-fpm7` process isn’t wise. Doing so could cause the process to die or
    stop writing logs completely. Instead, you can start by looking at the log output
    to see whether there are any telling errors or the application log level is perhaps
    stuck on `debug`. Also, there might be some correlation between this logfile and
    the fact that a Docker container log is large. Perhaps this process is running
    inside that container. Check the contents of the container log as well for any
    visible errors. On a housecleaning note, you should always make sure the host
    is set up to use the `logrotate` command to compress and rotate logfiles on a
    schedule. This can keep your logfiles from growing unbound and eating up your
    disk space. The `logrotate` configuration files are located in the */etc/logrotate.d**/*
    directory on Ubuntu systems.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'Scenario: Connection Refused'
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sometimes, services refuse connections and do not leave an obvious reason why.
    For example, say you have an internal API that is reporting a high error rate,
    and say other services that use this API are throwing a lot of errors as well.
    The errors in the application logs would look something like this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: It appears users are receiving a `Connection refused` error when trying to connect
    to the API server. You know the Docker container is up and running, or you would
    have gotten an alert that it was down. To troubleshoot this, you’ll use a few
    commands that will help you identify any network- or configuration-related issues.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: curl
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Anytime you need to check whether a web server is responding to requests or
    just want to fetch some data or a file, turn to the `curl` command. For this example,
    you’ll want to verify that an endpoint is down for everyone and that there is
    not just a routing issue on other hosts. The API server should respond with an
    `HTTP 200` status if it is functioning properly. To double-check that the API
    server is refusing connections, you could use `curl` by entering the following
    command:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The output shows you are getting a `Connection refused` error as well. This
    usually means the host is not listening on your port or a firewall is rejecting
    packets. Regardless of the reason, something is breaking your API requests.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: ss
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ss` (socket statistics) command is used to dump socket information on
    a host. For your troubleshooting scenario, you’ll use it to see whether any application
    on the host is bound (or listening) to requests on `port 8080`. Enter the following
    command:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `-l` flag shows all the listening sockets on the host. The `-n` flag instructs
    `ss` not to resolve any service names like HTTP or SSH, and the `-p` flag shows
    the process that’s using the socket. For `ss` to determine which process owns
    the socket, `sudo` or elevated permissions are required. I truncated the beginning
    of the output line for readability, but the important part shows that the `docker-proxy`
    process is listening on all interfaces for port 8080 (`0.0.0.0:8080`). Next, you
    can verify that the requests destined for *api.smith.lab* are making it all the
    way to the host, where it lives.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: tcpdump
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One way to verify network traffic on a host is with the `tcpdump` command, which
    has many options and can capture traffic on one or all interfaces. It can even
    write out the network capture into a file for later analysis. Not only is `tcpdump`
    great for troubleshooting network issues, but you can use it for security auditing
    as well. For your example, you’ll use it to capture network traffic intended for
    the *api.smith.lab* host on port 8080\. This will let you know whether traffic
    being sent to that host is reaching its target, and it will hopefully shed some
    light on why you are getting the `Connection refused` error message.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'On the host where the API application is running, enter the following command
    in a terminal. This will start the network packet capture on all interfaces for
    any TCP packet headed for port 8080 (note that elevated privileges are needed
    to listen on a network interface):'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `-n` flag makes sure you do not try to resolve any host or port names. The
    `-i` flag tells `tcpdump` the network interface on which to listen. In this case,
    the term `any` is specified and means “Listen on all interfaces.” You want to
    capture all packets destined for port 8080 since there might be numerous network
    interfaces on this host. The final `tcp port 8080` parameter states that you want
    only TCP packets that have port 8080 in them. These will include packets from
    both the client and the server.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Let’s focus on the parts of the output that help with the `Connection refused`
    error problem. On the first line, the `IP` section shows that something from source
    `IP` `192.168.50.26` is trying to connect to `192.168.50.4` on port `8080`. The
    `>` (greater-than) sign tells us the direction of the communication from one IP
    to another. The `Flags` being set show the types of network packets being sent.
    The first packet has an `S` (synchronize) flag. Anytime a client wants to establish
    a connection to another host, it sends the synchronize packet. In the next packet,
    host `192.168.50.4` responds to `192.168.50.26` with a reset (`R`) packet. A reset
    packet is usually sent when there is an unrecoverable error and the server wants
    the client to terminate the connection immediately. Undeterred by the “Get off
    my lawn!” reset packet, the client tries again with another synchronize packet,
    which in turn causes server `192.168.50.4` to send another reset packet back to
    `192.168.50.26`. The client at `192.168.50.26` finally takes a hint, and the connection
    is closed.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: The flags show this connection isn’t normal. A normal TCP connection starts
    off with a `SYN` packet from the client, followed by a `SYN-ACK` packet from the
    server. Once that packet is received, the client sends back an `ACK` packet to
    the server, acknowledging the last packet. This is referred to as a *three-way
    handshake*. See [Figure 10-2](#figure10-2) for details.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram showing one client server on the left with the IP 192.168.50.26 passing
    packets back and forth with the server at 192.168.50.4 on the right](image_fi/502482c10/f10002.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10-2: TCP three-way handshake'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: You clearly do not see any other packets (except resets) being sent from the
    server. The reset packets will cause the connecting clients to report that the
    connection is being refused. The good news is you verified that connections are
    making it all the way to server. The bad news is you still do not know why you
    are being refused.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Next Steps
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At this point, you know the service is listening on port 8080\. You verified
    this with the `ss` command. You also know traffic is making it all the way to
    the server, according to your network capture with `tcpdump`.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: The next places to look are the Docker container and the application configuration.
    It is possible `docker-proxy` is having issues and not forwarding the traffic
    to the container running the API. Another possibility is that the container was
    started with incorrect internal port mappings. You know the external port, 8080,
    is mapped correctly, since it is listening for connections. But it’s possible
    the mapped internal port is misconfigured. You can check both of these scenarios
    by looking at Docker’s system logs for proxy errors, or by running `docker ps`
    `<container id>` or `docker inspect` `<container_id>` to check the port mappings.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Searching Logs
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In almost every troubleshooting scenario, you’ll most likely need to check logs.
    System and application logs hold a wealth of information you can view from the
    command line. Modern Linux distributions use `systemd`, which has a log-collection
    mechanism called the *journal* that pulls in log events from multiple sources
    like *syslog*, *auth.log*, and *kern.log*. This lets you view and search logs
    in a single stream. As a troubleshooting archaeologist, you should know where
    logs are located and how to view and parse them.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Common Logs
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most system and application logs on a Linux host are stored in the */var/log*
    directory. The most common logs on a host that will aid in troubleshooting are
    *syslog*, *auth.log*, *kern.log*, and *dmesg*. Depending on your Linux distribution,
    the names of the logfiles may be different.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: /var/log/syslog
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The *syslog* file contains general global system messages for the Linux OS.
    Here is an example of a log line for `systemd`, stating that the logs are finished
    rotating:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The line begins with a timestamp, followed by the host it is on (`box`) and
    the process (`systemd[1]`) that is reporting the log event. The last part of the
    line is the text message. This structured line format, also called *syslog*, is
    the default protocol for logging on a Linux host.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: /var/log/auth.log
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The *auth.log* file contains information regarding authorization and authentication
    events. This makes it a great place to investigate user logins and brute-force
    attacks, or to track a user’s `sudo` commands. Here is an example of an *auth.log*
    message:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This message shows a failed login attempt over SSH for the user *aiden*, from
    the IP address `192.168.1.133`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: /var/log/kern.log
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The *kern.log* is a good place to look for Linux kernel messages, such as hardware
    issues or general information related to the Linux kernel. The following log line
    shows the Linux out of memory manager (OOM) in action:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Process `20371` was killed by the `Out of memory` manager because the system
    was running low on memory.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: /var/log/dmesg
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The *dmesg* log contains bootup messages from the host since last boot time.
    These messages can be anything from a USB device being recognized to a possible
    SYN packet flood attack. This sample log line from *dmesg* shows a `Network driver`
    being loaded into the kernel:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The *dmesg* log has its own command line application, `dmesg`, to view the kernel
    ring buffer in real time. The `dmesg` command prints information, just like the
    *dmesg* log, but it can show information after bootup as well. You can also use
    it to troubleshoot multiple scenarios, such as port exhaustion, hardware failures,
    and OOM.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Common journalctl Commands
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: On a host that is using `systemd`, all of these common logs are stored in a
    single binary stream called a journal, which is orchestrated by the `journald`
    daemon. You can access the journal with the `journalctl` command line application.
    The journal is a handy troubleshooting tool because you can use it to view and
    search multiple logs at the same time. The `journalctl` command mimics many other
    logging commands you’ve discussed in this book, such as `tail`, minikube `minikube
    kubectl -- logs` and `docker logs`.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'Say you want to review the logs, with the newest lines first. Enter the `sudo`
    command and pass the `-r` flag (reverse) to `journalctl` to view all logs in that
    order:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This output shows log lines for all services, with newest lines first.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, view logs during a certain time frame with the `--since` flag. Enter
    the following command:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This output shows the logs that have a timestamp starting `2 hours ago` up till
    the current time, when the command is run. With the `-r` flag, the newest logs
    are displayed first.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'You can filter logs based on a `systemd` service name. For example, to view
    all the logs that were written by the SSH service, enter the following command
    to pass the `-u` (unit) flag to `journalctl`:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The output shows log lines for SSH pertaining to a login `session`, in reverse
    order.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also display log lines that match a specific log level, like info or
    error. Choose the priority level (`-p`) by using keywords like `info`, `err`,
    `debug`, or `crit`. The following is the same command as above but with the `-p
    err` flag to show only error logs from the SSH daemon:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The output shows an `error` log line where the *root* user reached the maximum
    failed login attempts.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'Narrowing down logs to a specific time frame or showing log lines that match
    a given log level is great, but what if you want to find a specific message in
    the journal stream? The pattern-matching flag (`-g`) in `journalctl` can match
    any message using a regular expression. The following example searches the SSH
    logs for the `session opened` message. Enter the following command:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here, SSH sessions for two different users (*vagrant* and *x7b7*) are filtered
    out.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: The `journalctl` tool is helpful when you want to view many logs at once, but
    you’ll also encounter logs that are not captured in the journal system.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Parsing Logs
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Parsing logs is a key troubleshooting skill. In addition to `journalctl`, you
    can parse and traverse logs with the `grep` and `awk` commands. The `grep` command
    is used to search for patterns in text or a file. The `awk` command is a scripting
    language tool that can filter text, but it also has more advanced features like
    built-in functions for math and time.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: grep
  id: totrans-183
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The `grep` command allows you to search for a pattern quickly. For example,
    to use `grep` to find any occurrences of the IP address 10.0.2.33 in */var/log/syslog*,
    pass `grep` the search pattern and the file to search by entering this command:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This command returned two log lines for the postfix daemon containing the `10.0.2.33`
    IP address.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: 'To find users trying to execute the `sudo` command who don’t have permission,
    search */var/log/auth.log* using `grep` by entering the following command:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The search pattern `"user NOT in sudoers``"` indicates an unauthorized `sudo`
    attempt violation. This search returns one match showing that the user *akira*
    tried to read the contents of the */etc/passwd* file but was denied.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Taking it one step further, it would be helpful to check the *auth.log* to see
    what else this user was doing around the same time. To get extra log lines with
    `grep`, use the `-A` flag to grab a given number of lines after the matched lines
    or use the `-B` flag to fetch a given number of lines before the matched results.
    You can also use the `-C` flag to fetch before and after the match, simultaneously.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you should grab the five log lines before the log line alerting to the
    `sudo` violation for the user *akira*. This will help you get an idea of what
    else might have been going on around that time in the log. Enter the following
    command:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The first five lines show the user *akira* logging in over SSH 1. Within five
    seconds of logging in (`17:37:35` to `17:37:40`), the user *akira* tried to read
    the contents of the */etc/passwd* file 2. Without the extra context, it might
    be tempting to overlook this action, but after seeing the user’s behavior upon
    logging in, grabbing additional lines around a match can provide more insight.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: awk
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The `awk` command can search for specific patterns like `grep` does, but it
    can also filter out information from any column. For this example, you should
    grab all the source IP addresses from the requests in */var/log/nginx/access.log*.
    This log contains all the requests to a website proxied by Nginx. The source IP
    address is usually the first column in the log line, unless you have modified
    Nginx’s default logging format. You’ll use `awk`’s `print` function and pass the
    `$1` argument so it prints only the first column. By default, `awk` splits columns
    on whitespace. Enter the following command:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output shows only two IP addresses. Clearly, it’s not a busy web server,
    but the output doesn’t show the whole log line as do the previous `grep` examples.
    You can parse the text and display the column of your choosing with the `awk`
    command. Each column in the log line is given a unique column number. For example,
    to see only the date timestamps (fourth column) in the *access.log*, pass `$4`
    to the `print` function. If you want to return more than the one column, pass
    multiple column numbers to the `print` function, separating each from the next
    with a comma, like this: `''{print $1,$4}''`.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll use `awk` to search for all the HTTP 500 response code, which is usually
    in the ninth column (`$9`) in the Nginx *access.log* file. Enter the following
    command:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Inside the parentheses, the tilde (`~`) is a field number that tells `awk` to
    apply the search pattern only to a specific column. In this case, you want to
    search in the ninth column for anything matching 500\. The command returned a
    single result for a `GET` request that responded with an HTTP `500`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: 'You can change the search pattern to suit your needs. For instance, if you
    want to search the logs for any unauthorized HTTP requests, change the pattern
    of `/500/` to `/401/`. To expand on this even further, you can change the search
    pattern from `/500/` to `/404/` and add a requirement that any 404 responses must
    be from an HTTP POST method. You do this by adding an `if` conditional block to
    `awk`. To search for any lines that match those criteria, enter the following
    in a terminal:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The search pattern is like the previous one. Match the value at column `$9`
    to the number `404`. Then pass an `if` block that states, “If the line from the
    column `$9` match contains the word `POST` anywhere in it, print that whole log
    line.” The result shows an HTTP `POST` to the */login* path that returned an HTTP
    `404`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Probing Processes
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, you won’t encounter many symptoms when investigating issues on a
    host. The health stats may look okay, the logs may show nothing interesting .
    . . but something will still not be right. Maybe a scheduled job didn’t execute
    cleanly, or an application appears to be hung. One way to dig deeper is to investigate
    the running process on the host.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: strace
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `strace` command traces system calls and signals, allowing you to attach
    to a process and gain valuable knowledge in real time. Your application uses system
    calls to ask the Linux kernel to perform tasks like opening a network socket,
    reading and writing a file, or creating a child process. You should use the `strace`
    command to troubleshoot a process that looks for issues in these calls, or when
    you need an overview of what a process is doing. Note that the `strace` command
    needs *root* privileges since it is attaching to another process.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'Many system calls are available, but here are a few for reference:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '`open()` Create or open files.'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`read()` Read from a file descriptor.'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`write()` Write to a file.'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`connect()` Open a connection.'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`futex()` Wait or wake up threads when a condition becomes true (blocking lock).'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, you should trace a process. The following command attaches to the running
    process `19419`, which is the Greeting web server from Chapter 4 and prints out
    any system calls that are happening when the trace begins:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The `-s` flag sets the message output size of `128` bytes. The `-p` flag tells
    `strace` which PID to attach to (in this case, it’s `19419`). I cherry-picked
    some system calls from the output to make it easier to follow. The `accept4` system
    call creates a new connection from IP address `172.28.128.1` and returns file
    descriptor `9`. The `recvfrom` system call receives an HTTP `GET` request from
    a socket with file descriptor `9`. The first `sendto` system call sends an HTTP
    header response from the web server back over the socket. The following `sendto`
    system call transmits the body of the HTTP `GET` response back to the socket as
    well. The `write` system call writes what appears to be a *syslog* line to file
    descriptor `1`. Finally, the `close` system call is executed, closing the previous
    socket file descriptor `9`, which closes the network connection. You have captured
    the transaction between an HTTP client and an HTTP server for a `GET` request.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Now, imagine you’re trying to investigate an issue but are lacking context on
    a process. You have exhausted other means, like log spelunking and metric watching.
    Everything seems in order, but your application is still not behaving correctly.
    You can use the summary flag (`-c`) for `strace` to get an overview of what system
    calls the process is using. It will output a running count of what system calls
    are being executed, how long each one is taking, and any errors that those calls
    return. Once you run the command, it will pause in the foreground while it collects
    data, and it won’t display the results until you press CTRL-C. The longer you
    let it run, the more data you will accumulate.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: The `strace` command has numerous flags and options to use for tracing. You
    can use the follow (`-f`) flag to follow any new processes created (forked) from
    the parent. You can use the syscall (`-e`) flag when you want to track only specific
    system calls. You can use the summarize (`-c`) flag when you want an overall view
    of the system calls, timings, and errors. Finally, the output (`-o`) flag can
    be extremely useful for storing the trace output to a file so you can review and
    parse it later.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, enter the following command to fetch a summary for process ID
    `28485`:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The `% time` column shows the percentage of time each call made up during the
    trace capture. In this example, the process spent most of its trace time 1 (before
    the trace was stopped) in the `sendto` system call. The `calls` column shows how
    many times the system call was executed. In this case, `getpeername` 3 was executed
    the most (50 times). The `getpeername` call returns the IP address of the peer
    connected over the socket. During the trace, process `28485` counted six errors
    2 when calling the `openat` system call. You can use this call to open a file
    by its specified path name.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'You should run `strace` again to focus on the errors for the `openat` system
    call. Enter the following command:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The output shows that process `28485` is trying to open the */var/log/telnet-server.log*
    file. The call is returning `-1`, which means the file does not exist. This matches
    the error output from the earlier summary. As you can see, being able to peer
    down into a running process and understand what it is doing at the system call
    level can be invaluable.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most of the scenarios described here reflect issues you will encounter throughout
    your career. Experience and repetition will help you build muscle memory for making
    quick work of these issues. My goal in describing these scenarios has been to
    show you how to use deductive reasoning to follow clues to find causes.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you learned about helpful forensic tools like `top`, `lsof`,
    `tcpdump`, `iostat`, and `vmstat`, which will help you diagnose symptoms. You
    also learned how to parse common logfiles using tools like `journalctl`, `grep`,
    and `awk`. All the tools and tactics discussed here should aid you the next time
    you find yourself trying to investigate problems.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: This concludes Part III, which has been on monitoring and troubleshooting. You
    now can monitor and alert on any application you deploy to Kubernetes. You have
    also gotten a troubleshooting primer to help you investigate common problems that
    arise when managing hosts and software.*
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
