- en: '**5'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SWARM OPTIMIZATION**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Swarm techniques do more than optimize mathematical functions. In this chapter,
    we’ll use randomness to pack circles in a square, place cell towers, enhance images,
    and organize product placement at the grocery store. We’ll apply the same collection
    of swarm intelligence and evolutionary algorithms as in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '**Packing Circles in a Square**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A classic math problem involves packing equal diameter circles in a square.
    An equivalent formulation is to locate, for a given number of points, positions
    in the unit square ([0, 1]) where the smallest distance between any pair of points
    is as large as possible. The point locations correspond to the centers of the
    best-packed circles. For example, where in the unit square do we put two points
    to maximize the distance between them? In opposite corners. In that case, the
    distance between the points is ![Image](../images/f0137-01.jpg), and it can’t
    be any larger.
  prefs: []
  type: TYPE_NORMAL
- en: 'What about three points? Four points? Seventeen points? Now the answer isn’t
    so obvious. We might approach this problem by using the elaborate algorithm detailed
    in Locatelli and Raber’s 2002 paper, “Packing Equal Circles in a Square: A Deterministic
    Global Optimization Approach,” but that’s not how we’ll do it here. Instead, we’ll
    use randomness in the form of a swarm search. We need to map positions in some
    multidimensional space to candidate solutions and then search this space for the
    best possible solution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we have *n* points and want to know the coordinates of *n* circle centers
    that are, for each pair, as far apart as possible while still within [0, 1], we
    need to find *n* points. At first, we might believe we have an *n*-dimensional
    problem. However, the dimensionality is actually 2*n*: we need both the *x*- and
    *y*-coordinates to specify a point. We know the search’s bounds are [0, 1] for
    each dimension. Therefore, we’ll use swarms that are 2*n*-dimensional vectors
    bounded by [0, 1] where each pair of components is a point, (*x*, *y*). In other
    words, if we want to find five points, each particle is a 10-element vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '***p*** = (*x*[0], *y*[0]; *x*[1], *y*[1]; *x*[2], *y*[2]; *x*[3], *y*[3];
    *x*[4], *y*[4])'
  prefs: []
  type: TYPE_NORMAL
- en: 'To run a search, we need the dimensionality of the problem and the bounds,
    both of which we now have. The only remaining issue is the objective function,
    which tells us how good a solution each particle position represents. The problem
    specification lights the way: we need to maximize the smallest distance between
    any pair of points. If there are five points, we calculate the distance between
    each possible pair, find which distance is the smallest, and return the opposite.
    Our framework only minimizes, so to maximize, we return the negative. The largest
    smallest distance between pairs, when made negative, becomes the most negative
    number.'
  prefs: []
  type: TYPE_NORMAL
- en: '***The Swarm Search***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The code we want is in *circles.py*. Consider putting the book down and reading
    through the file to understand the flow. Once you’ve done that, we can begin with
    the objective function class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The constructor does nothing more than initialize `fcount`, which counts the
    number of times `Evaluate` is called. The `Evaluate` method is given a position
    vector (`p`) that is immediately reshaped into a set of (*x*, *y*) pairs (`xy`).
  prefs: []
  type: TYPE_NORMAL
- en: The second code paragraph in `Evaluate` runs through each pairing of points
    in `xy` and calculates the Euclidean distance between them. If that distance is
    the smallest found so far, we keep it in `dmin`. We want to maximize the smallest
    distance between any pair of points, so we first find the smallest distance between
    any two points represented by the particle position.
  prefs: []
  type: TYPE_NORMAL
- en: The final line returns the negative of `dmin`. Because the framework minimizes,
    returning the negative of the smallest pairwise distance forces the framework
    to *maximize* this smallest distance—exactly what we want.
  prefs: []
  type: TYPE_NORMAL
- en: We now have everything we need to implement the search. The main body of *circles.py*
    follows the standard approach of pulling values off the command line and setting
    up the framework objects before calling `Optimize` to execute the search.
  prefs: []
  type: TYPE_NORMAL
- en: 'In code, the essential steps are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We create the desired randomness engine, followed by the bounds, initializer,
    and objective function instance. Notice that the objective function requires no
    ancillary information.
  prefs: []
  type: TYPE_NORMAL
- en: The `swarm` object, `PSO` configured for bare-bones searching, is followed by
    `Optimize` and `Results`. Not shown is code to report the best set of points and
    the distance between them before dumping all search results, including a simple
    plot of the point locations, into the supplied output directory.
  prefs: []
  type: TYPE_NORMAL
- en: Try running *circles.py* with no command line options to see what it expects.
    Now that we have it, let’s use it.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s pack some circles. I created two shell scripts, *go_circle_results* and
    *go_plots*. The former runs *circles.py* for 2 through 20 circles and 7 algorithms:
    bare-bones PSO, canonical PSO, DE, GWO, Jaya, RO, and GA. The output is stored
    in the *results* directory. I recommend starting it in the evening and coming
    back the next morning, as the framework is designed for clarity, not speed. Run
    it with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: When *go_circle_results* finishes, execute *go_plots* to produce a series of
    plots showing the circle configuration each algorithm located. My results from
    this exercise are in [Table 5-1](ch05.xhtml#ch05tab01), though yours will be somewhat
    different due to the stochastic nature of the swarm searches.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 5-1:** Largest Center Distance, Known and as Found by Each Algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: '| ***n*** | **Known** | **Bare** | **DE** | **PSO** | **GWO** | **Jaya** |
    **RO** | **GA** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 1.4142 | 1.4142 | 1.4142 | 1.4142 | 1.4142 | 1.4142 | 1.4142 | 1.4134
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 1.0353 | 1.0353 | 1.0353 | 1.0353 | 1.0353 | 1.0353 | 1.0301 | 1.0264
    |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 0.9998 | 0.9969
    |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 0.7071 | 0.7071 | 0.7070 | 0.6250 | 0.7025 | 0.7071 | 0.6796 | 0.6052
    |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 0.6009 | 0.5951 | 0.5953 | 0.5995 | 0.5988 | 0.5858 | 0.5723 | 0.5884
    |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 0.5359 | 0.5359 | 0.5223 | 0.5000 | 0.5072 | 0.5176 | 0.5000 | 0.4843
    |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 0.5176 | 0.5090 | 0.5045 | 0.5000 | 0.5002 | 0.4801 | 0.4661 | 0.4355
    |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 0.5000 | 0.5000 | 0.4202 | 0.5000 | 0.4798 | 0.5000 | 0.4421 | 0.4470
    |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 0.4213 | 0.4147 | 0.3697 | 0.4195 | 0.4187 | 0.3517 | 0.3788 | 0.3819
    |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | 0.3980 | 0.3978 | 0.3296 | 0.3694 | 0.3895 | 0.3918 | 0.3588 | 0.3787
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 0.3887 | 0.3726 | 0.2989 | 0.3717 | 0.3289 | 0.3819 | 0.3496 | 0.3542
    |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | 0.3660 | 0.3595 | 0.2752 | 0.3333 | 0.3277 | 0.2832 | 0.3212 | 0.3230
    |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | 0.3451 | 0.3354 | 0.2537 | 0.3333 | 0.3116 | 0.3435 | 0.3037 | 0.3204
    |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 0.3372 | 0.3256 | 0.2303 | 0.3333 | 0.3278 | 0.2437 | 0.2949 | 0.2995
    |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 0.3333 | 0.2996 | 0.2269 | 0.2500 | 0.3011 | 0.2220 | 0.2760 | 0.2761
    |'
  prefs: []
  type: TYPE_TB
- en: '| 17 | 0.3060 | 0.2985 | 0.2062 | 0.2913 | 0.2952 | 0.1992 | 0.2658 | 0.2721
    |'
  prefs: []
  type: TYPE_TB
- en: '| 18 | 0.3005 | 0.2782 | 0.1927 | 0.2808 | 0.2703 | 0.2126 | 0.2516 | 0.2493
    |'
  prefs: []
  type: TYPE_TB
- en: '| 19 | 0.2900 | 0.2697 | 0.1852 | 0.2500 | 0.1905 | 0.1731 | 0.2384 | 0.2559
    |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | 0.2866 | 0.2632 | 0.1789 | 0.2500 | 0.2419 | 0.1659 | 0.2200 | 0.2342
    |'
  prefs: []
  type: TYPE_TB
- en: '[Table 5-1](ch05.xhtml#ch05tab01) shows the best-known distance between the
    points and the distance found by the swarm searches, by algorithm. These numbers
    will be our gold standard.'
  prefs: []
  type: TYPE_NORMAL
- en: For *n* < 10, many of the distances are known from geometric arguments, as [Table
    5-2](ch05.xhtml#ch05tab02) shows.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 5-2:** Known Circle Center Distances'
  prefs: []
  type: TYPE_NORMAL
- en: '| ***n*** | **Distance** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | ![Image](../images/f0140-01.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | ![Image](../images/f0140-02.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | ![Image](../images/f0140-03.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | ![Image](../images/f0140-04.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | ![Image](../images/f0140-05.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | ![Image](../images/f0140-06.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 0.42127954 |'
  prefs: []
  type: TYPE_TB
- en: The expressions come from Table D1 in *Unsolved Problems in Geometry* by Croft,
    Falconer, and Guy (Springer, 1991). The *plot_results.py* file, called by *go_plots*,
    uses this table to generate plots showing the packed circles. If the packing is
    optimal, the circles barely touch. Otherwise, the circles are separated from each
    other or overlap.
  prefs: []
  type: TYPE_NORMAL
- en: Examining [Table 5-1](ch05.xhtml#ch05tab01) reveals 2 through 4 circles to be
    straightforward; every algorithm located the best arrangement. For 5 circles,
    bare-bones PSO, DE, and Jaya converged on the solution. We won’t quibble about
    the one-ten-thousandth difference between the known distance and differential
    evolution’s solution.
  prefs: []
  type: TYPE_NORMAL
- en: The swarms begin to struggle after 5 circles. For 6 circles, no swarm nails
    the distance, at least to four decimals, but several come pretty close. [Figure
    5-1](ch05.xhtml#ch05fig01) shows the output plots for each algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-1: Packing 6 circles. From top left to right: PSO, GWO, DE, bare-bones
    PSO, GA, RO, and Jaya.*'
  prefs: []
  type: TYPE_NORMAL
- en: While solutions are unique regarding the distance between the circle centers,
    they aren’t in terms of rotations. The canonical PSO, DE, and GWO results are
    essentially the same, only rotated by 90 degrees in some cases.
  prefs: []
  type: TYPE_NORMAL
- en: View all graphs generated by *go_plots* by the number of circles. As *n* increases,
    the swarms struggle more and more, but there are nice *n* values, like *n* = 9,
    where the swarms are more likely to arrive at the highly symmetric solution. Since
    we’re packing a square, it makes sense that *n* values that are perfect squares—like
    4, 9, and 16—lead to nicely aligned packings. However, only a few algorithms located
    the ideal *n* = 9 output, and none found the best *n* = 16 outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move on to a more practical problem.
  prefs: []
  type: TYPE_NORMAL
- en: '**Placing Cell Towers**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Placing a cell phone tower is not an academic exercise; real utility and cost
    are involved. In this section we’ll experiment with a (simplified) cell tower
    placement problem.
  prefs: []
  type: TYPE_NORMAL
- en: Our inputs are a collection of cell towers, each with a different effective
    range, and a mask showing where cell towers can be placed. The output is a collection
    of locations where the specified towers should be placed to maximize coverage.
  prefs: []
  type: TYPE_NORMAL
- en: The code we’ll work with is in *cell.py*. It has the same general structure
    as the other swarm experiments, but is slightly more advanced because evaluating
    a particle position involves checking for illegal tower positions and building
    an image. The `Evaluate` method of the objective function class is more complex,
    but still accepts a particle position and returns a score where lower implies
    a better solution.
  prefs: []
  type: TYPE_NORMAL
- en: I’ll lay out the plan of attack; then we’ll walk through the essential parts
    of the code before running some experiments.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Swarm Search***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We need to translate vectors of numbers within some bounds into possible solutions.
    We’ll work with cell towers and maps telling us where we can place them. Let’s
    begin with representing towers and maps.
  prefs: []
  type: TYPE_NORMAL
- en: The cell towers radiate in all directions, so we’ll represent them as circles
    where the diameter of the circle indicates the tower’s strength and the center
    of the circle the tower’s location. Not all towers are of equal strength. We specify
    a tower with a single floating-point number in (0, 1]; exactly how will become
    clear momentarily.
  prefs: []
  type: TYPE_NORMAL
- en: The maps are grayscale images. If a pixel’s value is 0, that pixel is a possible
    tower location; if the pixel is 255, it’s off-limits. I placed a collection of
    maps in the *maps* directory. You can make your own in any graphics program; use
    255 to mark regions off-limits to towers and 0 for everything else. The maps need
    not be square. Note that the larger the map, the slower the search, which is why
    the supplied maps are rather small.
  prefs: []
  type: TYPE_NORMAL
- en: Tower sizes are fractions of half the map’s largest dimension. For example,
    the supplied maps are 80 pixels on a side. Therefore, a tower given as 0.1 has
    a diameter of 0.1 × 40 = 4 pixels, while a 0.6 tower’s diameter is 0.6 × 40 =
    24 pixels. Towers are stored in a text file, one number per line, with the number
    of lines indicating the number of towers. Examine the files in the *towers* directory
    to see what I mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'Particle positions represent tower locations. If there are *n* towers, we need
    2*n*-dimensional particles, as we did for packing circles. Every two elements
    of a particle position are the center location for a tower. The order in which
    towers are specified maps, one-to-one, to pairs of particle elements. For example,
    *towers0* has six lines for six towers: 0.1, 0.2, 0.3, 0.4, 0.5, 0.6\. Therefore,
    a search using *towers0* involves 12-dimensional particles'
  prefs: []
  type: TYPE_NORMAL
- en: (*x*[0], *y*[0]; *x*[1], *y*[1]; *x*[2], *y*[2]; *x*[3], *y*[3]; *x*[4], *y*[4];
    *x*[5], *y*[5])
  prefs: []
  type: TYPE_NORMAL
- en: where (*x*[0], *y*[0]) is the location of the 0.1 tower, (*x*[1], *y*[1]) is
    the location of the 0.2 tower, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 5-2](ch05.xhtml#ch05fig02) shows the default maps.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-2: The default maps*'
  prefs: []
  type: TYPE_NORMAL
- en: The first map is blank, with no forbidden regions. Any marked area on the other
    maps is off-limits to a tower. Think of these as roads, parking lots, lakes, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: We have towers and maps. We know how to represent tower locations and sizes.
    How do we put towers, maps, and locations together to get a score? We want to
    cover the map as much as possible by placing towers in allowed locations. Therefore,
    we want to minimize the number of allowed map pixels that aren’t covered by a
    tower; we want the number of zero pixels after placing towers to be as small as
    possible. This sounds like a job for the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: For a given particle position, the objective function needs to determine whether
    any proposed cell tower centers are in an illegal location. If even one tower
    is, the objective function rejects the entire configuration by immediately returning
    a score of 1.0, the largest possible, implying that none of the map is covered.
  prefs: []
  type: TYPE_NORMAL
- en: If all proposed tower locations are allowed, it’s time to calculate the coverage.
    The number of uncovered pixels divided by the number of pixels in the map is a
    value in [0, 1], where 0 means all pixels are covered. The lower this value, the
    better the coverage.
  prefs: []
  type: TYPE_NORMAL
- en: The approach I chose begins with an empty image the same size as the map image.
    We add towers to the image by adding each pixel covered by the tower to any current
    pixel value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding pixels in this way accomplishes two things: first, any pixel of the
    initially empty image that is still 0 after adding all the pixels covered by towers
    is uncovered; second, adding pixels tower by tower builds a comprehensible image.
    We’ll be able to see each tower and its covered region clearly, including areas
    where towers overlap.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To recap, for a given particle position, we:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert the tower coordinates to a set of points as we did earlier for packing
    circles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Return 1.0 as the score if any tower centers land on illegal regions of the
    map.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add each tower to an initially empty image array, including all covered pixels,
    if all tower centers are allowed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Return the count of uncovered pixels divided by the total number of pixels as
    the score.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These steps map particle positions to solutions, thereby generating a single
    number representing the quality of the solution.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 5-3](ch05.xhtml#ch05fig03) shows an input map on the left and output
    generated after a canonical particle swarm search using the six towers in *towers0*
    on the right.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-3: An input mask (left) and resulting tower placement (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: The towers overlap only slightly, and no centers are in masked areas. Examine
    the files in the *example* directory to view these images in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s review the essential parts of *cell.py* to understand how the steps were
    translated into code.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The code in *cell.py* is relatively complex. Spend some quality time with the
    file before continuing.
  prefs: []
  type: TYPE_NORMAL
- en: The most important piece of code is the objective function class and friends;
    see [Listing 5-1](ch05.xhtml#ch05list01).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-1: The objective function class*'
  prefs: []
  type: TYPE_NORMAL
- en: The constructor stores the map (`image`), towers vector (`towers`), and `radius`,
    which is one-half the largest dimension of the map image. This sets the largest
    possible cell tower range; for example, if the tower’s range is 1, then the circle
    representing the tower has a radius of `radius` pixels, which is half the height
    or width of the map image, whichever is larger. Internally, `radii` is a vector
    of tower radii in pixels ➊.
  prefs: []
  type: TYPE_NORMAL
- en: The `Evaluate` method first reshapes the particle position vector into (*x*,
    *y*) points, as we did for *circles.py*. In this case, we want pixel coordinates,
    so `floor` ensures that points are integer valued ➋.
  prefs: []
  type: TYPE_NORMAL
- en: The `Collisions` method first checks whether any proposed cell tower centers
    are in a forbidden region. This is a simple query against the map image. If the
    center pixel isn’t 0, count it as a collision. If any collisions happen, return
    a score of 1.0, implying all pixels are uncovered.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming no collisions, it’s time to place the towers and calculate the score.
    An `empty` image the same size as the map image is created and passed to `CoverageMap`
    along with the tower centers (`xy`) and `radii` ➌. The return value, `cover`,
    is an image similar to the right side of [Figure 5-3](ch05.xhtml#ch05fig03), but
    without proper scaling to [0, 255]—it is a floating-point array. If an element
    of `cover` is 0, that element isn’t in the range of any tower, so we count it
    with NumPy’s `where` function and divide that count by the number of pixels in
    the map to calculate the score.
  prefs: []
  type: TYPE_NORMAL
- en: The `CoverageMap` method is not of the `Objective` class because it’s used elsewhere
    in *cell.py*. It is, however, critical to the success of the code, so let’s walk
    through it in some detail ([Listing 5-2](ch05.xhtml#ch05list02)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-2: Generating the coverage map for a set of tower positions*'
  prefs: []
  type: TYPE_NORMAL
- en: The `CoverageMap` method accepts the map image, tower center locations, and
    tower radii as input. Its goal is to fill in `im`. Passing an empty image to `CoverageMap`
    seems odd at present, but later calls to the function pass the map image itself.
  prefs: []
  type: TYPE_NORMAL
- en: Towers are applied in turn with center at (*x*, *y*) ➊. The (inefficient) double
    loop ➋ examines every pixel in the map that could be inside the range of the current
    tower. The body of the inner loop asks whether the current pixel, (*i*, *j*),
    is within the disk of the current tower (the `if` statement). If so, and the (*i*,
    *j*) pixel is within the space of the image, the current pixel value is incremented
    according to
  prefs: []
  type: TYPE_NORMAL
- en: 0.5(*k* + 1)/*n*
  prefs: []
  type: TYPE_NORMAL
- en: where *n* is the number of towers. This equation increments the pixel value
    (`im` is a floating-point array) by an amount specific to each tower. The result
    leads to the right side of [Figure 5-3](ch05.xhtml#ch05fig03), where each disk
    is a different intensity and overlaps are visible.
  prefs: []
  type: TYPE_NORMAL
- en: After all towers are added, a final loop over adds each tower’s center point
    ➌. The value of the center point is always 1.4 times the intensity of the maximum
    pixel value to make the center points visible (best viewed on a computer screen).
    Since `im` is a floating-point array, it isn’t restricted to [0, 255]. Scaling
    comes later in the code when writing output images to disk.
  prefs: []
  type: TYPE_NORMAL
- en: The `CoverageMap` method returns a two-dimensional array where any remaining
    zero values are pixels not covered by any tower. The number of zero values scaled
    by the number of pixels is the final score for the given tower locations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main body of *cell.py* follows *circles.py* in form: parse the command
    line, create framework objects, and do the search. However, instead of calling
    `Optimize`, the search is performed by repeated calls to `Step` so the current
    best score can be displayed per iteration.'
  prefs: []
  type: TYPE_NORMAL
- en: The search is configured as in [Listing 5-3](ch05.xhtml#ch05list03).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-3: Configuring the search*'
  prefs: []
  type: TYPE_NORMAL
- en: Here `radius` sets the maximum radius for any tower.
  prefs: []
  type: TYPE_NORMAL
- en: The search itself is a loop ([Listing 5-4](ch05.xhtml#ch05list04)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-4: Running the search*'
  prefs: []
  type: TYPE_NORMAL
- en: The `Initialize` method configures the swarm, `Done` returns `True` when the
    search is complete (all iterations done or tolerance met), and `Step` performs
    one update of the swarm (it acts like headquarters).
  prefs: []
  type: TYPE_NORMAL
- en: Every iteration calls the `Results` method to report on the current best value—the
    fraction of image pixels not covered by a tower. After the loop exits, the final
    call to `Results` returns the best set of tower locations. Additional code captures
    the per-iteration output and generates the output map for the swarm’s best configuration.
    See the `frames` option on the command line.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the coverage map is generated and stored in the output directory, as
    shown in [Listing 5-5](ch05.xhtml#ch05list05).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-5: Generating the coverage map*'
  prefs: []
  type: TYPE_NORMAL
- en: The swarm best position (`p`) is converted to a set of (*x*, *y*) points, which,
    along with the corresponding radii for the towers, are passed to `CoverageMap`
    along with the input map itself (`map_image`). Unlike the `Evaluate` method in
    the objective function, the map with masked regions is passed rather than an empty
    image.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting coverage map (`cover`) is passed through a square root function
    to squash intensities before converting to a grayscale image (`img`) and writing
    to the output directory.
  prefs: []
  type: TYPE_NORMAL
- en: By necessity, we skipped code in *cell.py*, but a careful reading of the file
    will make those sections clear. Now let’s see what *cell.py* can do.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running *cell.py* without arguments shows us how to use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s run the code using *map_01* and *towers0*. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We’re using the GA with 20 particles for 100 iterations and dumping the output
    to a directory called *test*. The `frames` keyword outputs the current best tower
    placement per iteration so we can trace the evolution of the swarm visually.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that 100 iterations is not many compared to the 10,000 or more we used
    with *circles.py*. All the manipulation to generate the coverage map takes time,
    so running for 10,000 iterations is out of the question. Fortunately, we don’t
    usually need more than a few hundred iterations.
  prefs: []
  type: TYPE_NORMAL
- en: As *cell.py* runs, it dumps the current swarm best score along with a summary
    when the search ends. The output directory contains this text in *README.txt*
    along with the original map image (*map.png*) and the final coverage map (*coverage.png*).
    The Python `pickle` file (*.pkl*) contains the swarm objects, should you wish
    to explore the evolution in more detail. The output directory also contains a
    *frames* directory holding images representing the swarm’s best configuration
    by iteration. Page through these files to watch the swarm evolve.
  prefs: []
  type: TYPE_NORMAL
- en: My run produced a final coverage value of 0.358, meaning about 36 percent of
    the map wasn’t covered by a tower, as seen in [Figure 5-4](ch05.xhtml#ch05fig04).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-4: Placing towers*'
  prefs: []
  type: TYPE_NORMAL
- en: All six towers in *towers0* are visible in the output. The towers overlap only
    slightly, which is a good sign. Each tower center avoids masked regions.
  prefs: []
  type: TYPE_NORMAL
- en: To experiment with *cell.py*, run the shell scripts *go_tower_results*, *go_towers*,
    and *go_towers0*. The first applies *towers0* to all sample maps using all algorithms.
    The second applies all tower files and algorithms to *map_02*. Finally, the last
    one applies each tower file to *map_00* using only bare-bones PSO to illustrate
    how the swarm places towers when there are no obstacles.
  prefs: []
  type: TYPE_NORMAL
- en: Run *go_results* and *go_towers*, then run *make_results_plot.py* and *make
    _towers_plot.py* to produce an image file containing all the results with each
    row showing the output of a different swarm algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The final script, *go_towers0*, produces the output seen in [Figure 5-5](ch05.xhtml#ch05fig05).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-5: Placing towers on the default maps*'
  prefs: []
  type: TYPE_NORMAL
- en: It runs bare-bones PSO over the blank map for each tower file. Note that *towers0*
    isn’t able to completely cover the map, but the resulting positions do not overlap,
    meaning bare-bones PSO found an optimal configuration (one of many). The output
    for *towers3* is much the same with the small towers not overlapping the larger
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: Contrast these results with those for *towers1* and *towers2*. It’s not immediately
    clear whether *towers1* is capable of completely covering the map, but *towers2*
    certainly is—yet tiny parts of the map remained uncovered. I suspect running for
    more than 300 iterations would take care of this. Does it? Is there a difference
    in runtime between using any map with masked regions and the blank map? If so,
    why might that be?
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to experiment with different custom maps and numbers and sizes of
    towers to find whether there’s an optimal or more utilitarian mix of tower sizes.
    What works best, many small towers or a few larger ones?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use randomness to implement a “make it pretty” image filter.
  prefs: []
  type: TYPE_NORMAL
- en: '**Enhancing Images**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When I view images I’ve taken with my phone in its gallery, I’m offered the
    option to remaster the picture; I call it the “make it pretty” filter. In this
    section, we’ll use a swarm search to implement a “make it pretty” filter for grayscale
    images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our filter is based on one that has consistently appeared in academic literature.
    It’s a good example of the tendency to take an existing paper, slightly alter
    the technique, and publish it as new. A quick review of the literature turned
    up eight papers all implementing this approach with only a tweak of the optimization
    algorithm: PSO, Firefly, Cuckoo search, DE, PSO, Cuckoo, Cuckoo, and DE, respectively.
    While our implementation is yet another in this illustrious line of research,
    I’m claiming the excuse of pedagogy and do not appeal to novelty or applicability.'
  prefs: []
  type: TYPE_NORMAL
- en: Disclaimers aside, the “make it pretty” filter applies a local image enhancement
    function to an input grayscale image to make it look nicer. If that sentence is
    as clear as mud, have no worries—I’ll explain.
  prefs: []
  type: TYPE_NORMAL
- en: We intend to apply a function to each pixel of the input image to produce a
    new output pixel. Let’s apply the function
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0151-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: to the pixel at row *i* and column *j*; that is, *g[ij]*. We need to find *a*,
    *b*, *m*, and *k* to make the image look as nice as possible.
  prefs: []
  type: TYPE_NORMAL
- en: '*G* is the original image’s *mean intensity*, or the value found by adding
    all the pixel intensities and dividing by the number of pixels. The *µ* and *σ*
    variables are the mean (*µ*) and standard deviation (*σ*) of a 3×3 region around
    the current pixel, *g[ij]*. Imagine a tic-tac-toe (naughts and crosses) board
    as in [Figure 5-6](ch05.xhtml#ch05fig06).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-6: Pixel offsets*'
  prefs: []
  type: TYPE_NORMAL
- en: The 3×3 region slides over the image visiting each pixel, calculates *µ* and
    *σ*, and then uses [Equation 5.1](ch05.xhtml#ch05equ1) to create a new pixel value,
    ![Image](../images/f0151-02.jpg). Note that ![Image](../images/f0151-03.jpg) is
    the value of the *ij* pixel in the output image; it does not update the original
    image pixel, *g[ij]*.
  prefs: []
  type: TYPE_NORMAL
- en: The function for updating image pixels has four parameters we need to find,
    along with other values that depend on the original image and how we apply the
    function. However, the function only tells us how to update the image for a given
    *a*, *b*, *m*, and *k*; it doesn’t say anything about how nice the output image
    will appear to a human observer. For that, we need an objective function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Researchers claim that the following function captures something of what makes
    an image look pleasant to humans:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0152-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We’ll use *F* as our objective function. The higher *F* is, the better the
    image will look to a human observer—at least, that’s the theory. *I* is the sum
    of the pixel intensities of an edge-detected version of the input image. The “edgels”
    variable is the number of edges in the edge-detected version of the image above
    a threshold, here 20\. Finally, *r* and *c* are the image dimensions (rows and
    columns) and *h* is the entropy of the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0152-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here *p[i]* is the probability of pixel intensity in bin *i* of a 64-bin histogram.
    Entropy, in this sense, refers to the information content of the image.
  prefs: []
  type: TYPE_NORMAL
- en: This exercise seems superficially similar to curve fitting. We have a function
    with parameters to be optimized, but the algorithm behind the application of the
    function has many more steps. However, as we’ll soon learn, the extra effort means
    little to our swarm algorithms. They still provide floating-point vectors to the
    objective function and expect a scalar quality measure in return. The swarm is
    blissfully unaware of what it’s optimizing.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Enhancement Function***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We have a four-parameter optimization problem: for a given image, we want to
    find the best *a*, *b*, *m*, and *k* values, all of which are floating-point numbers.
    From a framework perspective, the setup is straightforward once we decide on bounds
    for the parameters. All the cool code will be in the objective function class.
    The full program is in *enhance.py*.'
  prefs: []
  type: TYPE_NORMAL
- en: We start with [Listing 5-6](ch05.xhtml#ch05list06), the objective function class,
    which implements both the elaborate image enhancement and *F* functions given
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-6: The image enhancement objective function class*'
  prefs: []
  type: TYPE_NORMAL
- en: The class constructor stores a copy of the original image. The `Evaluate` method
    extracts *a*, *b*, *m*, and *k* from the supplied particle position, passing them
    and the original image to `ApplyEnhancement` to return a new image, `dst`. We
    pass the new image to the `F` method to calculate the score. Since we want to
    maximize *F*, we return the negative.
  prefs: []
  type: TYPE_NORMAL
- en: I’ll explain `ApplyEnhancement` momentarily; let’s focus on `F` for now. The
    method is linear and makes heavy use of powerful functions supplied by NumPy and
    PIL (`Image` and `ImageFilter`). Walking through, line by line, makes sense in
    this case.
  prefs: []
  type: TYPE_NORMAL
- en: First, we extract the image dimensions (`r`, `c`). In the next line, we apply
    an edge detection filter to the image producing `Is` from `dst`. The output of
    an edge detector looks like [Figure 5-7](ch05.xhtml#ch05fig07).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-7: An edge detector in action*'
  prefs: []
  type: TYPE_NORMAL
- en: We recast the PIL image, `Is`, as a NumPy array before using `where` to count
    the number of edge pixels greater than 20\. We chose 20 because it’s an empirically
    selected threshold that works well. The count is stored in `edgels`.
  prefs: []
  type: TYPE_NORMAL
- en: The only part of *F* yet to determine is the entropy, *h*, here given as `ent`.
    To get this, we first need the histogram of the image using 64 bins, conveniently
    acquired in a single line of code courtesy of NumPy’s `histogram` function. Scaling
    the histogram by the sum of all bins converts from counts per bin to an estimate
    of the probability per bin, `p`.
  prefs: []
  type: TYPE_NORMAL
- en: With `p` in hand, we calculate the entropy by summing the probabilities multiplied
    by the log, base 2, of the probabilities (`ent`). The penultimate line in `F`
    is a direct analog of the equation for *F*, the value of which is returned.
  prefs: []
  type: TYPE_NORMAL
- en: Now for `ApplyEnhancement` in [Listing 5-7](ch05.xhtml#ch05list07).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-7: Applying a set of parameters to an image*'
  prefs: []
  type: TYPE_NORMAL
- en: We enhance the original image by applying [Equation 5.1](ch05.xhtml#ch05equ1).
    The output image (`dst`) is constructed, pixel by pixel, using the local 3×3 region
    mean (`m`) and standard deviation (`s`) in conjunction with the arguments `a`,
    `b`, `c`, and `k`. Note that `c` is *m* in [Equation 5.1](ch05.xhtml#ch05equ1).
  prefs: []
  type: TYPE_NORMAL
- en: The helper function, `stats`, defines the 3×3 region around (*i*, *j*), accounting
    for the image index limits. It then returns the mean and standard deviation. The
    `if` catches the edge case where too few pixels exist for a meaningful standard
    deviation calculation. Notice the `ddof` keyword in the call to `std`. By default,
    NumPy calculates the biased estimator of the variance by dividing by the number
    of values instead of the unbiased estimate found by dividing by one less than
    the number of values. Many statistics packages use the unbiased estimator by default.
    In most cases, especially if there are < 20 values in the dataset, we want the
    unbiased estimator, so we set `ddof=1`. Recall that the standard deviation is
    the square root of the variance.
  prefs: []
  type: TYPE_NORMAL
- en: All that remains is to configure the search, as shown in [Listing 5-8](ch05.xhtml#ch05list08).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-8: Configuring the search*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration follows our framework: randomness source (`rng`), bounds
    (`b`), initializer (`i`), objective function (`obj`), and a `swarm` object, here
    `GWO`. We force the input image (`orig`) to grayscale (`convert`) and scale it
    by 256 to be in the range [0, 1) (`img`). It’s not uncommon to manipulate images
    in this range instead of [0, 255]. After manipulation, the image is scaled to
    [0, 255] and converted to an integer type before writing it to disk.'
  prefs: []
  type: TYPE_NORMAL
- en: The search is four dimensional (`ndim`), so there are four bounds. The bounds
    vary by dimension. The limits *a ∈* [0, 1.5], *b ∈* [1.0, 22], *m ∈* [0, 1], and
    *k ∈* [0.5, 1.5] are based on values used in the literature. As we’ll see, they
    appear to work well, but try experimenting with them, especially if you notice
    output values near the limits. We’ll soon learn how to find these values after
    a search.
  prefs: []
  type: TYPE_NORMAL
- en: Running the search is as simple as calling `Optimize` on the `swarm` object,
    but we want to track the *F* score as we go, so we’ll loop manually instead ([Listing
    5-9](ch05.xhtml#ch05list09)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-9: Running the search*'
  prefs: []
  type: TYPE_NORMAL
- en: The search ends after all specified iterations. We then dump the final results
    (`res`) to the output directory via `pickle`. Use the `gpos` key to return the
    final set of parameters. To conclude, the image is enhanced with the best set
    and written to the output directory along with the original image for comparison
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Does *enhance.py* work? Let’s find out.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Run *enhance.py* without arguments to learn what it expects on the command
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We need to supply the original image, swarm size, iterations, algorithm type,
    randomness source, and output directory name.
  prefs: []
  type: TYPE_NORMAL
- en: The *images* directory contains a set of 128×128-pixel grayscale images that
    we’ll use for our experiments. The search isn’t particularly fast, given the sequential
    nature of the framework and the extensive image manipulations each call to the
    objective function entails, so smaller images work best. The program will work
    with larger images, which need not be square; all that’s required is patience.
  prefs: []
  type: TYPE_NORMAL
- en: 'Give this command line a try:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The output shows the current swarm best *F* score by iteration. The value is
    negative because we want to maximize *F*. The command line specified GWO with
    a swarm of 10 particles, 60 iterations, and an output directory named *babs*.
  prefs: []
  type: TYPE_NORMAL
- en: 'On my system, the search finishes with this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Therefore, the best set of parameters led to *F* = 6.09797 after 14 swarm best
    updates. The *babs* output directory contains
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: giving us the enhanced image, the original image, the pickled results, and a
    README file containing all output generated during the search.
  prefs: []
  type: TYPE_NORMAL
- en: The enhanced image should look sharper with better contrast than the original.
    Unfortunately, a printed version will likely not show the differences clearly.
    Nonetheless, [Figure 5-8](ch05.xhtml#ch05fig08) shows both images, with the original
    on the left and the enhanced version on the right.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-8: The original and enhanced images*'
  prefs: []
  type: TYPE_NORMAL
- en: Look, in particular, at the books in the bookcase. They are better defined and
    show improved contrast.
  prefs: []
  type: TYPE_NORMAL
- en: To extract the enhancement parameters, load the *results.pkl* file
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: which tells us that *a* = 0.01867, *b* = 1.0078, *m* = 0.45469, and *k* = 1.17311\.
    We haven’t used `pickle` before; it requires a file object (the output of `open`)
    and must use binary mode (`"rb"`).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are nine images in the *images* directory. We’ll run various swarm and
    evolutionary algorithms against these images, and then collect the resulting output
    to produce composite images showing the original and the enhanced versions so
    we might rate each algorithm’s performance. To that end, I created two Python
    scripts: *process_images.py* and *merge_images.py*.'
  prefs: []
  type: TYPE_NORMAL
- en: Run *process_images.py* first. I recommend starting it in the evening and returning
    in the morning. The script processes every image in *images* using each swarm
    algorithm. The swarm consists of 10 particles and runs for 75 iterations in all
    cases.
  prefs: []
  type: TYPE_NORMAL
- en: When *process_images.py* finishes, use *merge_images.py* to produce composite
    images showing the results, which are in the *output* directory. For example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: creates *zelda_results.png*, as in [Figure 5-9](ch05.xhtml#ch05fig09). Canonical
    PSO looks like the winner here.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-9: A composite image. From top left: original, bare-bones PSO, DE,
    GA, GWO, Jaya, canonical PSO, RO.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 5-3](ch05.xhtml#ch05tab03) lists the *F* scores and parameters for each
    algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 5-3:** *F* Scores and Parameters for Each Algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ***F*** | ***a*** | ***b*** | ***m*** | ***k*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **GWO** | 4.59328 | 0.00030 | 2.21893 | 0.71926 | 0.99232 |'
  prefs: []
  type: TYPE_TB
- en: '| **Canonical PSO** | 5.07767 | 0.00585 | 1.50612 | 0.39545 | 1.46734 |'
  prefs: []
  type: TYPE_TB
- en: '| **Jaya** | 4.31448 | 1.21667 | 1.00493 | 0.76448 | 1.47750 |'
  prefs: []
  type: TYPE_TB
- en: '| **DE** | 4.29245 | 1.24982 | 1.00076 | 0.76535 | 1.46355 |'
  prefs: []
  type: TYPE_TB
- en: '| **Bare-bones PSO** | 4.27962 | 1.09779 | 1.01205 | 0.89588 | 1.49625 |'
  prefs: []
  type: TYPE_TB
- en: '| **GA** | 4.10057 | 1.14040 | 1.64773 | 0.12196 | 1.19704 |'
  prefs: []
  type: TYPE_TB
- en: '| **RO** | 4.01708 | 1.08478 | 5.07904 | 0.53249 | 0.97552 |'
  prefs: []
  type: TYPE_TB
- en: The subjectively best-looking image is also the image with the largest *F* score—a
    good sign. The GWO image, which has low contrast but is quite sharp, has the second-highest
    *F* score. The GWO parameters are also quite different from the others. It’s possible
    that the enhancement function parameter space has a fairly complex structure,
    and there are multiple local minima. For the Zelda image, the GWO algorithm seems
    to have landed apart from the others. Does this happen with the other images?
    Which algorithm seems to work best overall?
  prefs: []
  type: TYPE_NORMAL
- en: The program *F.py* applies a specific set of parameters to an image. What happens
    if we apply *a* from the GWO result and *b*, *m*, and *k* from the canonical PSO
    result?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The new *F* score is higher still, and the output file, *zelda2.png*, looks
    even better than the canonical PSO result.
  prefs: []
  type: TYPE_NORMAL
- en: There is much more to explore here. I’ll provide a few suggestions in “Exercises”
    on [page 169](ch05.xhtml#ch00lev1_33), including a way to (possibly) enhance color
    images. For the time being, let’s move on to another experiment, which combines
    optimization with simulation to maximize profit by figuring out how to best arrange
    the products in a grocery store.
  prefs: []
  type: TYPE_NORMAL
- en: '**Arranging a Grocery Store**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Have you noticed that grocery stores usually put milk in the back, as far from
    the entrance as possible? Or that candy is located right at the front, near the
    checkouts? The placement of products in a grocery store is not an accident; it’s
    intentional to maximize profit. Many people stop by the store to pick up necessities,
    like milk, and often pick up something else if they run across it, like candy.
    Grocery stores arrange the products to maximize such occurrences and increase
    revenue.
  prefs: []
  type: TYPE_NORMAL
- en: This section attempts to replicate such an arrangement of products to validate
    or refute common store practice. This experiment combines optimization with simulation.
    We’ll optimize product placement in the store using a set of simulated shoppers
    to evaluate the arrangement. Our goal is an arrangement of products, our objective
    function score is revenue over a day, and the function itself is a simulation
    of several hundred shoppers. Randomness is everywhere, from swarm initialization
    and position updates to the collection of shoppers and their habits. To jump in,
    read through *store.py*.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Environment***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s define our operating environment. Actual stores are essentially two dimensional;
    there is a layout over some floor space. Our framework uses position vectors,
    one-dimensional entities. We’ll make the store one-dimensional as well, so a position
    vector can be a store layout with each element a product. Shoppers will enter
    the store on the left (index 0) and progress through the store to the right, like
    in [Figure 5-10](ch05.xhtml#ch05fig10).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-10: Shopping at a one-dimensional grocery store (Illustration by
    Joseph Kneusel)*'
  prefs: []
  type: TYPE_NORMAL
- en: People typically go to the store to pick up a specific product; we’ll call this
    the *target product*. The shoppers will also have impulse products that they’ll
    buy if they encounter them before the target product.
  prefs: []
  type: TYPE_NORMAL
- en: For example, [Figure 5-10](ch05.xhtml#ch05fig10) shows two shoppers who are
    thinking of a target product (signified by the question mark) and an impulse product
    (the exclamation point).
  prefs: []
  type: TYPE_NORMAL
- en: The shopper on the left is searching for the diamond product, but will purchase
    the circle product if they see it. Since they encounter the diamond before the
    circle, they buy only the diamond product and leave the store.
  prefs: []
  type: TYPE_NORMAL
- en: The shopper on the right is searching for the triangle product, but they’ll
    buy the square product if they come across it. They find the square while searching
    for the triangle and purchase both.
  prefs: []
  type: TYPE_NORMAL
- en: 'The shopping simulation requires products, located in the *products.pkl* file.
    The file contains three lists, each of 24 elements: counts, names, and prices,
    in that order. The data comes from an actual collection of products purchased
    over some period. The products are stored in decreasing purchase frequency, so
    the item most often purchased is first, and the least often purchased is last.'
  prefs: []
  type: TYPE_NORMAL
- en: We convert the counts to a purchase probability by dividing each by the sum
    of all the counts. We’ll use the purchase probability in our objective function.
  prefs: []
  type: TYPE_NORMAL
- en: If there are 24 products in the store, we have 24-dimensional position vectors.
    We’re searching for the best ordering of products to maximize daily revenue. We’ll
    visit the simulation part in more detail later, but for the moment, let’s focus
    on the product order and how we’ll represent it in a swarm.
  prefs: []
  type: TYPE_NORMAL
- en: At first, we might think to make the position vectors discrete values in [0,
    23], where each number is a product, an index into the list of products read from
    *products.pkl*. However, I implemented an alternate approach using position vectors
    in [0, 1).
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, we want a vector that places products in a particular order, some
    permutation of the vector {0, 1, 2, 3, . . . , 23}. The trick is to abstract this
    permutation so we can still use continuous floating-point values in [0, 1). Instead
    of using the product numbers directly, we pass each position vector to NumPy’s
    `argsort` function, which returns the order of indices that would sort the vector.
    For a vector of 24 elements, the output of `argsort` is a permutation of the numbers
    0 through 23.
  prefs: []
  type: TYPE_NORMAL
- en: That this approach works—and we’ll see that it does—is impressive. We’re asking
    the swarms to generate a collection of floating-point numbers, [0, 1), that are
    useful only when the additional operation of determining their sort order has
    happened. The reason it works likely has to do with the fact that using integer
    values requires some kind of truncation or rounding of a floating-point number
    where the implemented approach uses the numbers as they are. If changing a particular
    element of the particle position from 0.304 to 0.288 alters the sort order of
    the entire vector to a more profitable configuration, the swarm makes use of that
    change, whereas truncation might call both numbers 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps we need to implement:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the swarm with 24-element position vectors in [0, 1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize a collection of randomly generated shoppers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run our usual swarm search where each position vector is evaluated by passing
    shoppers through the store using the sort order of the current vector as the arrangement
    of products. Then, tally the amount of money each shopper spends. They’ll always
    find their target product, but may not find their impulse products. Finally, return
    the negative of the total spent by the shoppers, as we want to maximize daily
    revenue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let the swarm algorithm update positions as usual until all iterations have
    run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Report the sort order of the best position found as the “ideal” ordering of
    the products.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The following two sections detail how to implement shoppers and how the objective
    function works. With those in mind, we’ll be ready to go shopping and see if our
    simulation agrees with grocery industry experts.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Shoppers***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A shopper is an instance of the Shopper class, as shown in [Listing 5-10](ch05.xhtml#ch05list010).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-10: The* Shopper *class*'
  prefs: []
  type: TYPE_NORMAL
- en: The constructor configures the shopper by selecting the target (`target`) and
    impulse (`impulse`) products. It also keeps a copy of the product prices (`item_values`)
    for when it’s time to go shopping.
  prefs: []
  type: TYPE_NORMAL
- en: A call to `Select` returns the target product, which is an index into the product
    list ➊. The `Select` method takes advantage of the fact that `fi` is the probability
    of a product being purchased in decreasing order ([Listing 5-11](ch05.xhtml#ch05list011)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-11: Selecting a product according to its purchase frequency*'
  prefs: []
  type: TYPE_NORMAL
- en: We select a random value, [0, 1) (`t`). We then add successive probabilities
    for each product to `c` until equaling or exceeding `t`. When that happens, as
    it must because *t* < 1 and the sum of all product probabilities is 1.0, the current
    product index is returned (`i`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see an example to clarify how `Select` works. Imagine there are five
    products, each selected with probability:'
  prefs: []
  type: TYPE_NORMAL
- en: 0.5, 0.3, 0.1, 0.07, 0.03
  prefs: []
  type: TYPE_NORMAL
- en: 'This means product 0 is purchased about 50 percent of the time while product
    4 is purchased only 3 percent of the time. The sum is 1.0, or 100 percent. Now,
    pick a random value in *t ∈* [0, 1). This will be less than 0.5 half of the time,
    meaning `Select` will return index 0\. The sum of the first two product probabilities
    is 0.5 + 0.3 = 0.8\. But half the time *t* < 0.5, so the difference between 0.5
    and 0.8 is the fraction of the time 0.5 > *t ≤* 0.8: 30 percent of the time. Similarly,
    10 percent of the time 0.8 > *t ≤* 0.9, 7 percent of the time 0.9 > *t ≤* 0.97,
    and 3 percent of the time 0.97 > *t ≤* 1.0\. Therefore, the index returned by
    `Select` reflects the true purchase probability for the item.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 5-10](ch05.xhtml#ch05fig10) shows a single impulse purchase product.
    In reality, the simulation selects three unique impulse products that aren’t the
    target product ➋. The call to `argsort` returns a permutation of the product indices,
    so keeping the first three ensures unique products. The `while` loop repeats the
    process, if necessary, to ensure that the target isn’t one of the impulse purchases.'
  prefs: []
  type: TYPE_NORMAL
- en: When evaluating a particle position, we call the `GoShopping` method. It’s passed
    a list of `products`, the sort order for the current particle. It then walks through
    the list, checking if the current product is the target or one of the impulse
    buys. If it is either, the method adds the price to `spent` to indicate that the
    shopper purchased the item. If the item is the target, the loop exits, and any
    unencountered impulse products are ignored ➌. The method then returns the total
    spent.
  prefs: []
  type: TYPE_NORMAL
- en: The `Shopper` class represents a single shopper. The `Objective` class manages
    a collection of shoppers.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Objective Function***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The `Objective` class evaluates a single particle position, or a configuration
    of products, as shown in [Listing 5-12](ch05.xhtml#ch05list012).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 5-12: The* Objective *function class*'
  prefs: []
  type: TYPE_NORMAL
- en: The constructor builds a list of randomly initialized shoppers, meaning we use
    the same collection of shoppers for the entire simulation. Here, `pci` is the
    probability of each product being selected, most probable first, and `pv` is the
    associated price.
  prefs: []
  type: TYPE_NORMAL
- en: The `Evaluate` method receives a single particle position; however, we aren’t
    interested in `p`’s values, only the `order` in which they need to be moved to
    sort them ➊. This is the product order `GoShopping` uses to determine how much
    money the shopper spends. To get the total revenue, then, each shopper is asked
    to go shopping while tallying the amount of money spent (`revenue`). The objective
    function value is the negative of this amount (to maximize).
  prefs: []
  type: TYPE_NORMAL
- en: 'The remainder of *store.py* loads the products and then parses the command
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The code then creates the list of purchase probabilities (`pci`)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'before initializing the swarm and running the search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The remainder of the file generates a report showing how successful the search
    was.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Shopping Simulation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Enough prep; let’s run and see what output we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The code expects the number of shoppers to simulate (`250`), the number of particles
    (`20`) and iterations (`200`), the algorithm (`pso`), and a randomness source
    (`mt19937`). The output prints to the screen.
  prefs: []
  type: TYPE_NORMAL
- en: First, we’re told this run generated $1,114.28 as the maximum daily revenue.
    The product order is as given, where the first product is at the front of the
    store, here cream cheese (strangely). The order provides the product name, the
    probability of purchasing it, and the price.
  prefs: []
  type: TYPE_NORMAL
- en: Conventional wisdom says to put the milk at the back of the store and the candy
    at the front. In this case, milk ended up as product 23, which is at the back
    of the store, while candy was product 3, very close to the front. This run followed
    conventional wisdom—a good sign.
  prefs: []
  type: TYPE_NORMAL
- en: 'The remainder of the output gives the median purchase probability for products
    in the first half of the store along with the median price for those products,
    and then again for products in the second half of the store. If the swarm is ordering
    the store along the lines we expect it to, then lower probability items that cost
    more will appear in the front part of the store (the top half of the product list).
    At the same time, higher probability items that generally cost less will appear
    toward the back of the store. This is precisely what we see in the output: items
    toward the back are more likely to be purchased and, in general, cost less.'
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the search produced reasonable output validating conventional wisdom.
  prefs: []
  type: TYPE_NORMAL
- en: The script *go_store* runs 10 searches for each algorithm capturing the results
    in the *output* directory. Run it with
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'then follow with *process_results.py*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This should produce a *results* directory that contains NumPy files (*.npy*)
    holding the milk and candy rankings for each algorithm and run, along with the
    best revenue for each run by algorithm. Also included is a plot tracking the milk
    and candy rankings across runs for each algorithm; see [Figure 5-11](ch05.xhtml#ch05fig11).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-11: Product rankings by algorithm across 10 runs, in which solid
    circles are milk and open circles are candy*'
  prefs: []
  type: TYPE_NORMAL
- en: In the figure, solid circles represent where milk ended up in the rankings,
    and open circles are for candy. Almost all algorithms were able to put milk near
    the very back of the store, with both PSO variants and Jaya perhaps the most consistent
    (for this single run of *go_store*). An obvious exception is RO. While it managed
    to put milk behind candy on every run, at times the placement wasn’t particularly
    great. For example, in run 9, milk and candy were almost next to each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *process_results.py* code also outputs a summary. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The first part shows the mean revenue across the 10 runs by algorithm. The standard
    error of the mean (standard deviation divided by the square root of the number
    of samples, here 10) is in parentheses. Bare-bones PSO is the winner, averaging
    a daily revenue of $1,148.59 compared with RO’s meager performance of $1,023.75.
  prefs: []
  type: TYPE_NORMAL
- en: The right-hand part of the output requires some explanation. I wanted to compare
    the revenue across runs by algorithm. The code locates the highest performing
    algorithm, bare-bones PSO in this case, and runs a t-test with it against the
    others. A *t-test* is a hypothesis test that asks whether two datasets are plausibly
    from the same data generating process. The value shown is the p-value, the probability
    of the observed difference in the means and standard deviations of the two datasets
    (or greater), given they are from the same data generating process. If the p-value
    is high, then the two data-sets are likely from the same data generating process,
    meaning the test’s null hypothesis is likely valid. In this case, the bare-bones
    PSO result is not meaningfully different from the GWO result, because the p-value
    is 0.36.
  prefs: []
  type: TYPE_NORMAL
- en: The smaller the p-value, the more likely that the results aren’t from the same
    data generating process. For RO and GA, the p-values are very low, giving us confidence
    that the bare-bones PSO result is better. However, the other p-values are also
    low. So, is bare-bones PSO head and shoulders above all the others for this task,
    or was it just lucky this time around?
  prefs: []
  type: TYPE_NORMAL
- en: To find out, I ran *go_store* five more times and accumulated the output of
    *process_results.py* in the *results_per_run.txt* file. The best-performing algorithm
    varied across runs, but there were trends. For three of the six runs, Jaya was
    the top performer; for two, it was bare-bones PSO; and for one, GWO. The GA and
    RO results were always the worst. Looking at the p-values from the t-tests, Jaya,
    bare-bones PSO, and GWO are good algorithms to use for this task, with likely
    no meaningful difference between Jaya and bare-bones PSO.
  prefs: []
  type: TYPE_NORMAL
- en: The products in *products.pkl* are arranged in decreasing order of purchase
    probability but increasing order of price, meaning the least likely product to
    be purchased is the most expensive and vice versa. Therefore, we might expect
    to maximize profit by arranging the products so the least likely but most expensive
    is first and the most likely, least costly is last, at the back of the store.
    The order generated by a run of *store.py* is the swarm’s attempt to meet this
    ideal.
  prefs: []
  type: TYPE_NORMAL
- en: Run *product_order.py*, passing it an output directory (*output* created by
    *go_store*) followed by another directory name, like *orders*. You’ll generate
    a collection of plots, one for each algorithm, showing the mean value of each
    product slot, from 0 through 23, for all 10 runs of each algorithm. Also plotted
    is the curve reflecting the ideal product ordering, the reverse of the product
    order in *products.pkl*.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 5-12](ch05.xhtml#ch05fig12) shows the mean product cost by position
    in the store over 10 runs of each algorithm compared to the ideal ordering (smooth
    curve).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/05fig12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-12: Comparing the mean swarm value by product order to the ideal.
    From top left to right: bare-bones PSO, DE, GA, GWO, Jaya, canonical PSO, RO.*'
  prefs: []
  type: TYPE_NORMAL
- en: First, note that in no way did the swarm search seek to match the ideal sequence.
    Instead, any match is an emergent effect of the swarms’ attempts to maximize daily
    profit.
  prefs: []
  type: TYPE_NORMAL
- en: Second, all algorithms except RO were effective at matching the order of the
    cheapest products. We also see this in [Figure 5-11](ch05.xhtml#ch05fig11) by
    the consistency of milk placement compared to candy. Most of the variation between
    algorithms is in the order of the first few products. We also see this in the
    larger error bars for products near the front of the store compared to those at
    the back.
  prefs: []
  type: TYPE_NORMAL
- en: The placement of products near the front of the store might be more difficult
    because those products are the least often purchased. Both bare-bones PSO and
    Jaya did reasonably well with more expensive products, but one could argue that
    GWO more closely matched the ideal curve. This tells us that the differences between
    algorithms are subtle, at least when viewed in this fashion, though GA was nearly
    as poor at matching the early product order as RO.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Had enough of swarm algorithms? Me neither. Here’s more to explore and contemplate:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Circles.py* used `enforce="clip"` to pack circles. Change this to `enforce=
    "resample"`. If the results are suddenly different, why?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Packing circles in a square is a similar problem to packing spheres in a cube.
    Modify a copy of *circles.py* to pack spheres in a cube, making a 2D problem a
    3D problem. Run your code and compare it to the numbers in *sphere_dmin.png*.
    If you get stuck, take a peek at *spheres.py*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Placing cell towers on an empty map returns (primarily) non-overlapping towers.
    What sort of output do you get from *cell.py* if the map is particularly busy
    with relatively few allowed locations? You can make your own map or give *map_busy.png*
    in the *maps* directory a try. Can the swarm algorithms find places for the towers?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *enhance.py* file manipulates grayscale images. Modify it to enhance RGB
    images instead. A crude approach is in the file *process_rgb_images.py* in the
    *rgb* directory. This directory also contains some RGB images (*original*). Does
    *process_rgb_images.py* consistently produce good results? Why? Implement a new
    version that doesn’t enhance channels independently, but instead seeks a set of
    parameters that work best across all channels, perhaps by summing *F* per channel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modify *enhance.py* to use `ddof=0` instead of `ddof=1`—to use the biased variance
    and not the unbiased. Do you notice any difference in the results?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The grocery store simulation used the same collection of shoppers for each iteration
    of the swarm. What happens to the results if the collection of shoppers is regenerated
    before each iteration? Do you expect this to make a difference?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The simulation results presented in the grocery store simulation used 250 shoppers.
    What happens to my claim that Jaya and bare-bones PSO are well suited to the task
    if there are only five shoppers? Ten? Fifty?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This chapter continued our exploration of swarm optimization algorithms. We
    learned how to pack circles in squares, place cell towers while avoiding restricted
    locations, implement a “make it pretty” filter, and mix optimization and simulation
    to develop a product placement plan for a grocery store.
  prefs: []
  type: TYPE_NORMAL
- en: We did all this using the same collection of algorithms. We didn’t change a
    single swarm intelligence or evolutionary algorithm to adapt it to the problem.
    Instead, casting the problem in the proper form enabled the direct application
    of the algorithms. This is a powerful ability that’s widely applicable. Many processes
    in the real world are, in the end, optimization problems, meaning swarm algorithms
    likely have a role to play. They are general-purpose algorithms, as are many machine
    learning algorithms to which we now turn.
  prefs: []
  type: TYPE_NORMAL
- en: The experiments in this chapter and the previous one introduced a powerful approach
    to general optimization problems. If we can cast the problem as finding the best
    position in a multidimensional space where each point represents a possible solution,
    then swarm intelligence and evolutionary algorithms are likely applicable. I can’t
    emphasize enough the usefulness of this concept.
  prefs: []
  type: TYPE_NORMAL
- en: 'We used a simple framework supporting a handful of standard swarm algorithms,
    of which there are hundreds to choose from—though not all are created equal. We
    designed the framework to be easy to use and pedagogical instead of performant.
    The framework acts as a stepping stone to more sophisticated tools, should you
    often return to swarm algorithms. If that’s the case, then consider exploring
    more advanced toolkits like these:'
  prefs: []
  type: TYPE_NORMAL
- en: '**inspyred**   *[https://pythonhosted.org/inspyred](https://pythonhosted.org/inspyred)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**pyswarms**   *[https://github.com/ljvmiranda921/pyswarms](https://github.com/ljvmiranda921/pyswarms)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**DEAP**   *[https://github.com/DEAP/deap](https://github.com/DEAP/deap)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'These toolkits support multiple swarm algorithms, both swarm intelligence and
    evolutionary, and are designed for performance. Toolkits for other languages include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Java**   *[https://cs.gmu.edu/~clab/projects/ecj](https://cs.gmu.edu/~clab/projects/ecj)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**C++**   *[https://eodev.sourceforge.net](https://eodev.sourceforge.net)*'
  prefs: []
  type: TYPE_NORMAL
- en: Swarm algorithms will make another appearance in [Chapter 7](ch07.xhtml), but
    for now, we’ll explore randomness in the world of artificial intelligence.
  prefs: []
  type: TYPE_NORMAL
