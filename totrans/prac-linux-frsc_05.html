<html><head></head><body><div id="sbo-rt-content"><h2 class="h2" id="ch05"><span epub:type="pagebreak" id="page_115"/><strong><span class="big">5</span><br/>INVESTIGATING EVIDENCE FROM LINUX LOGS</strong></h2>&#13;
<div class="image1"><img src="Images/common01.jpg" alt="Image" width="190" height="189"/></div>&#13;
<p class="noindent">The computer term <em>log</em> originates from an ancient sailor’s technique for measuring the speed of a moving ship. A wooden log attached to a long rope was thrown overboard behind the ship. The rope had regularly spaced knots that sailors would count as the moving ship distanced itself from the floating log. They could calculate the speed of the ship from the number of knots counted over a period of time. Regular measurements of the ship’s speed were recorded in the ship’s “log book” or log.</p>&#13;
<p class="indent">Over time, the word <em>log</em> came to represent a variety of recorded periodic measurements or events. Log books are still used by organizations to document visitors entering buildings, the delivery of goods, and other activities that need a written historical record. The concept of a computer login and logout was created to control and record user activity. Early time-sharing computer systems were expensive and needed to keep track of computing resources consumed by different users. As the cost of storage capacity and <span epub:type="pagebreak" id="page_116"/>processing power dropped, the use of logging expanded to nearly all parts of a modern computer system. This wealth of logged activity is a valuable source of digital evidence and helps forensic investigators reconstruct past events and activity.</p>&#13;
<h3 class="h3" id="ch00lev1_22"><strong>Traditional Syslog</strong></h3>&#13;
<p class="noindent">The traditional logging system on Unix and Unix-like operating systems such as Linux is <em>syslog</em>. Syslog was originally written for the sendmail software package in the early 1980s and has since become the de facto logging standard for IT infrastructure.</p>&#13;
<p class="indent">Syslog is typically implemented as a daemon (also known as a collector) that listens for log messages from multiple sources, such as packets arriving over network sockets (UDP port 514), local named pipes, or syslog library calls (see <a href="ch05.xhtml#ch05fig01">Figure 5-1</a>).</p>&#13;
<div class="image"><img id="ch05fig01" src="Images/ch05fig01.jpg" alt="Image" width="693" height="505"/></div>&#13;
<p class="figcap"><em>Figure 5-1: Traditional syslog architecture (rsyslog)</em></p>&#13;
<p class="indent">The syslog architecture and network protocol is defined in RFC 5424. Linux distributions have historically included one of several implementations of syslog for local system logging, the most common being <em>rsyslog</em>.</p>&#13;
<h4 class="h4" id="ch00lev2_61"><strong><em>Syslog Facility, Severity, and Priority</em></strong></h4>&#13;
<p class="noindent">The syslog standard defines the format of messages and several characteristics of log entries. These characteristics are <em>facility</em>, <em>severity</em>, and <em>priority</em>.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_117"/>The message facility allows the categorization of logs depending on a subsystem. RFC 5424 documents 24 syslog message facilities. The rsyslog .conf(5) man page and the Linux <em>syslog.h</em> header file define them as follows:</p>&#13;
<pre>0  kern: kernel messages&#13;
1  user: random user-level messages&#13;
2  mail: mail system&#13;
3  daemon: system daemons&#13;
4  auth: security/authorization messages&#13;
5  syslog: messages generated internally by syslogd&#13;
6  lpr: line printer subsystem&#13;
7  news: network news subsystem (obsolete)&#13;
8  uucp: UUCP subsystem (obsolete)&#13;
9  cron: clock daemon&#13;
10 authpriv (auth-priv): security/authorization messages&#13;
11 ftp: FTP daemon&#13;
12 reserved&#13;
13 reserved&#13;
14 reserved&#13;
15 reserved&#13;
16 local0: reserved for local use&#13;
17 local1: reserved for local use&#13;
18 local2: reserved for local use&#13;
19 local3: reserved for local use&#13;
20 local4: reserved for local use&#13;
21 local5: reserved for local use&#13;
22 local6: reserved for local use&#13;
23 local7: reserved for local use</pre>&#13;
<p class="noindent">Some of these facility codes, like <span class="literal">news</span> (Usenet) or <span class="literal">uucp</span> (Unix-to-Unix copy) are obsolete and might be explicitly redefined by a system administrator at a local site. The last eight “local” facilities are reserved specifically for local sites to use as needed.</p>&#13;
<p class="indent">One internal facility called <span class="literal">mark</span> is often implemented separately from the syslog standard. If used, the syslog daemon generates <span class="literal">mark</span> log entries, together with a timestamp, at regularly defined intervals. These markers indicate that the logging subsystem was still functional during periods of time when no logs were received. In a forensic examination, the marks are interesting as potential indicators of the absence of certain activity, which can be useful information in an investigation.</p>&#13;
<p class="indent">There are eight severity levels, with zero being the most severe. The highest numbers generate the most volume of information and are often enabled on demand for troubleshooting or debugging. The severity level can be represented as either a numeric value or a text label. The levels are listed here together with the short or alternate names and description:</p>&#13;
<pre>0 emergency (emerg or panic): system is unusable&#13;
1 alert (alert): action must be taken immediately&#13;
<span epub:type="pagebreak" id="page_118"/>2 critical (crit): critical conditions&#13;
3 error (err): error conditions&#13;
4 warning (warn): warning conditions&#13;
5 notice (notice): normal but significant condition&#13;
6 informational (info): informational messages&#13;
7 debug (debug): debug-level messages</pre>&#13;
<p class="noindent">These severity levels are interesting from a forensic readiness perspective. If a particular syslog-generating component is at heightened risk or suspicion, or if there is an ongoing incident, the logging severity can be changed temporarily to increase the verbosity of the logs. Some tools and documentation may use the word priority when referring to severity.</p>&#13;
<p class="indent">The priority, or <em>PRI</em> value, of a syslog message is calculated from the facility and severity (by multiplying the facility by eight and then adding the severity). The syslog daemon can use the priority number to decide how to handle the message. These decisions include the location and file to save, filtering, which host(s) to forward messages to, and so on.</p>&#13;
<h4 class="h4" id="ch00lev2_62"><strong><em>Syslog Configuration</em></strong></h4>&#13;
<p class="noindent">The configuration of the local syslog daemon is important to know in a forensic investigation. The configuration file entries (both defaults and administrator customization) direct the investigator to where logs are located, which severity levels have been logged, and what other logging hosts are involved. Common syslog daemon configuration file locations are:</p>&#13;
<ul>&#13;
<li class="noindent"><em>/etc/syslog.conf</em></li>&#13;
<li class="noindent"><em>/etc/rsyslog.conf</em></li>&#13;
<li class="noindent"><em>/etc/rsyslog.d/*.conf</em></li>&#13;
<li class="noindent"><em>/etc/syslog-ng.conf</em></li>&#13;
<li class="noindent"><em>/etc/syslog-ng/*</em></li>&#13;
</ul>&#13;
<p class="noindent">These are plaintext files that any text editor can read. The examples here include BSD syslog, rsyslog, and syslog-ng implementations.</p>&#13;
<p class="indent">The configuration files define the location and contents of the logs managed by the daemon. A typical syslog configuration line has two fields: the selector and the action. The <em>selector</em> field is composed of the facility and severity (separated by a dot). The <em>action</em> field defines the destination or other action taken when logs match the selector. The following is an example rsyslog configuration file:</p>&#13;
<pre>#*.debug    /var/log/debug&#13;
kern.*      /var/log/kern.log&#13;
mail.err    /var/log/mail.err&#13;
*.info      @loghost</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_119"/>The first line is commented out and intended for debugging when needed. The second line sends all kernel logs to <em>/var/log/kern.log</em>, regardless of severity. In the third line, mail logs with a severity of <em>error</em> or more are sent to the <em>/var/log/mail.err</em> logfile. These files are stored locally and can be easily located and examined. The last line sends all log messages (any facility) with a severity of <em>info</em> or more to another host on the network. The <span class="literal">@</span> indicates a network destination and <span class="literal">loghost</span> is a central logging infrastructure.</p>&#13;
<p class="indent">The network destinations are especially interesting for an investigation because they indicate a separate non-local source of log data that can be collected and examined. If identical logs are stored both locally and on a remote log host, the correlation can be interesting if the data doesn’t match. A mismatch may indicate malicious modification of one of the logs.</p>&#13;
<p class="indent">On Linux systems, the <em>/var/log/</em> directory is the most common place to save logs. However, these flat text files have scalability, performance, and reliability challenges when high volumes of log data are ingested. Enterprise IT environments still use the syslog protocol over the network, but messages are often saved to high-performance databases or systems designed specifically for managing logs (Splunk is a popular example). These databases can be a valuable source of information for investigators and enable a quick iterative investigative process. Very large text-based logfiles can take a long time to query (<span class="literal">grep</span>) for keywords compared to database log systems.</p>&#13;
<h4 class="h4" id="ch00lev2_63"><strong><em>Analyzing Syslog Messages</em></strong></h4>&#13;
<p class="noindent">A syslog message transmitted across a network is not necessarily identical to the corresponding message that is saved to a file. For example, some fields may not be saved (depending on the syslog configuration).</p>&#13;
<p class="indent">A program with built-in syslog support, also known as an <em>originator</em>, uses programming libraries or external programs to generate syslog messages on a local system. Programs implementing syslog are free to choose any facility and severity they wish for each message.<sup><a id="ch05foot01" href="footnotes.xhtml#ch05foot_01">1</a></sup></p>&#13;
<p class="indent">To illustrate, let’s take a look at the <span class="literal">logger</span><sup><a id="ch05foot02" href="footnotes.xhtml#ch05foot_02">2</a></sup> tool for generating syslog messages:</p>&#13;
<pre>$ <span class="codestrong1">logger -p auth.emerg "OMG we</span>'<span class="codestrong1">ve been hacked!"</span></pre>&#13;
<p class="noindent">The syslog message from this example can be observed traversing a network. When captured and decoded by <span class="literal">tcpdump</span>, it looks like this:</p>&#13;
<pre>21:56:32.635903 IP (tos 0x0, ttl 64, id 12483, offset 0, flags [DF],&#13;
proto UDP (17), length 80)&#13;
    pc1.42661 &gt; loghost.syslog: SYSLOG, length: 52&#13;
        Facility auth (4), Severity emergency (0)&#13;
        Msg: Nov 2 21:56:32 pc1 sam: OMG we've been hacked!</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_120"/>Some information (like severity or facility) in the original syslog messages might not be stored in the destination logfiles depending on how the syslog daemon is configured. For example, a typical rsyslog configuration will log the syslog message from the preceding example as follows:</p>&#13;
<pre>Nov 2 21:56:32 pc1 sam: OMG we've been hacked!</pre>&#13;
<p class="noindent">Here, the severity and facility are not logged locally; however, the syslog daemon is aware of them when the message arrives and may use this information to choose the log destination. On the <span class="literal">loghost</span>, the UDP port numbers (the source port in particular) are also not logged unless the site is logging firewall traffic or using netflow logging.</p>&#13;
<p class="indent">Most syslog systems log a few standard items by default. Here is an example of a typical log entry generated by rsyslog:</p>&#13;
<pre>Nov 2 10:19:11 pc1 dhclient[18842]: DHCPACK of 10.0.11.227 from 10.0.11.1</pre>&#13;
<p class="noindent">This log line contains a timestamp, the local hostname, and the program that generated the message together with its process ID (in square brackets), followed by the message produced by the program. In this example, the <span class="literal">dhclient</span> program (PID 18842) is logging a DHCP acknowledgement containing the machine’s local IP address (10.0.11.227) and the IP address of the DHCP server (10.0.11.1).</p>&#13;
<p class="indent">Most Linux systems use log rotation to manage retention as logs grow over time. Older logs might be renamed, compressed, or even deleted. A common software package for this is logrotate, which manages log retention and rotation based on a set of configuration files. The default configuration file is <em>/etc/logrotate.conf</em>, but packages may supply their own logrotate configuration and save it in <em>/etc/logrotate.d/*</em> during package installation. During a forensic examination, it is useful to check whether and how logfiles are rotated and retained over time. The logrotate package can manage any logfile, not only those generated by syslog.</p>&#13;
<p class="indent">Forensic examiners should be aware that syslog messages have some security issues that may affect the evidential value of the resulting logs. Thus, all logs should be analyzed with some degree of caution:</p>&#13;
<ul>&#13;
<li class="noindent">Programs can generate messages with any facility and severity they want.</li>&#13;
<li class="noindent">Syslog messages sent over a network are stateless, unencrypted, and based on UDP, which means they can be spoofed or modified in transit.</li>&#13;
<li class="noindent">Syslog does not detect or manage dropped packets. If too many messages are sent or the network is unstable, some messages may go missing, and logs can be incomplete.</li>&#13;
<li class="noindent">Text-based logfiles can be maliciously manipulated or deleted.</li>&#13;
</ul>&#13;
<p class="noindent">In the end, trusting logs and syslog messages involves assessing and accepting the risks of integrity and completeness.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_121"/>Some Linux distributions are starting to switch over to the systemd journal for logging and aren’t installing a syslog daemon. It is likely that locally installed syslog daemons on desktop Linux systems will decline in popularity, but in server environments, syslog will remain a de facto standard for network-based logging.</p>&#13;
<h3 class="h3" id="ch00lev1_23"><strong>Systemd Journal</strong></h3>&#13;
<p class="noindent">The shortcomings of the aging syslog system have resulted in a number of security and availability enhancements. Many of these enhancements have been added to existing syslog daemons as non-standard features and never gained widespread use among Linux distributions. The systemd journal was developed from scratch as an alternative logging system with additional features missing from syslog.</p>&#13;
<h4 class="h4" id="ch00lev2_64"><strong><em>Systemd Journal Features and Components</em></strong></h4>&#13;
<p class="noindent">The design goals and decisions of the systemd journal were to add new features to those already found in traditional logging systems and integrate various components that had previously functioned as separate daemons or programs. Systemd journal features include:</p>&#13;
<ul>&#13;
<li class="noindent">Tight integration with systemd</li>&#13;
<li class="noindent"><span class="literal">stderr</span> and <span class="literal">stdout</span> from daemons is captured and logged</li>&#13;
<li class="noindent">Log entries are compressed and stored in a database format</li>&#13;
<li class="noindent">Built-in integrity using forward secure sealing (FSS)</li>&#13;
<li class="noindent">Additional trusted metadata fields for each entry</li>&#13;
<li class="noindent">Logfile compression and rotation</li>&#13;
<li class="noindent">Log message rate limiting</li>&#13;
</ul>&#13;
<p class="indent">With the introduction of FSS and trusted fields, the developers created a greater focus on log integrity and trustworthiness. From a digital forensics perspective, this is interesting and useful because it strengthens the reliability of the evidence.</p>&#13;
<p class="indent">The journal offers network transfer of messages to another log host (central logging infrastructure) in a similar way to traditional logging, but with a few enhancements:</p>&#13;
<ul>&#13;
<li class="noindent">TCP-based for stateful established sessions (solves dropped packet issue with UDP)</li>&#13;
<li class="noindent">Encrypted transmission (HTTPS) for confidentiality and privacy</li>&#13;
<li class="noindent">Authenticated connections to prevent spoofing and unauthorized messages</li>&#13;
<li class="noindent">Message queuing when <span class="literal">loghost</span> is unavailable (no lost messages)</li>&#13;
<li class="noindent"><span epub:type="pagebreak" id="page_122"/>Signed data with FSS for message integrity</li>&#13;
<li class="noindent">Active or passive message delivery modes</li>&#13;
</ul>&#13;
<p class="noindent">These networking features allow a more secure logging infrastructure to be built, with a focus on integrity and completeness. A significant problem with syslog was the UDP-based stateless packet transmission. With the systemd journal, reliability and completeness of log transmission is addressed.</p>&#13;
<p class="indent">If the journal networking features are used, check the <em>/etc/systemd/ journal-upload.conf</em> file for the <span class="literal">"URL="</span> parameter containing the hostname of a central log host. This is a forensic artifact that may point to the existence of logs in a different location and may be important on systems for which logging is not persistent.</p>&#13;
<p class="indent"><a href="ch05.xhtml#ch05fig02">Figure 5-2</a> shows the architectural component diagram of systemd journal networking.</p>&#13;
<div class="image"><img id="ch05fig02" src="Images/ch05fig02.jpg" alt="Image" width="679" height="457"/></div>&#13;
<p class="figcap"><em>Figure 5-2: Systemd journal networking</em></p>&#13;
<p class="indent">See the systemd-journal-remote(8), systemd-journal-gatewayd(8), and systemd-journal-upload(8) man pages for more information about the journal networking features. Although those features are innovative and greatly improve traditional logging, they are systemd specific and not compatible or well known outside the Linux community.</p>&#13;
<h4 class="h4" id="ch00lev2_65"><strong><em>Systemd Journal Configuration</em></strong></h4>&#13;
<p class="noindent">Understanding the configuration of the systemd journal helps us assess the potential for finding forensic evidence on a system. The journal functions as a normal Linux daemon (see <a href="ch05.xhtml#ch05fig03">Figure 5-3</a>) called systemd-journald and is well</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_123"/>documented in the systemd-journald(8) man page. You can find the <em>enable</em> status of the journal daemon at boot time by examining the systemd unit files (<em>systemd-journald.service</em>).</p>&#13;
<div class="image"><img id="ch05fig03" src="Images/ch05fig03.jpg" alt="Image" width="693" height="401"/></div>&#13;
<p class="figcap"><em>Figure 5-3: Systemd journal daemon</em></p>&#13;
<p class="indent">The systemd journal has several configuration parameters that define aspects of its operation (described in the journald.conf(5) man page). Common configuration file locations for the journal are as follows:</p>&#13;
<ul>&#13;
<li class="noindent"><em>/etc/systemd/journald.conf</em></li>&#13;
<li class="noindent"><em>/etc/systemd/journald.conf.d/*.conf</em></li>&#13;
<li class="noindent"><em>/usr/lib/systemd/journald.conf.d/*.conf</em></li>&#13;
</ul>&#13;
<p class="indent">The configuration file specifies whether logs are volatile or persistent with the <span class="literal">"Storage="</span> parameter. Persistent logs, if configured, are stored in a binary format in <em>/var/log/journal/</em>. If logs are configured to be volatile, they will be stored in <em>/run/log/journal/</em> and exist only when the system is running; they are not available for postmortem forensic analysis. If <span class="literal">"ForwardToSyslog=</span> <span class="literal">yes"</span> is set, journal logs are sent to the traditional syslog system on the local machine and stored in local logfiles (<em>/var/log/</em>) or possibly forwarded to a central log host.</p>&#13;
<p class="indent">On systems with a persistent journal, the <em>/var/log/journal/</em> directory contains a subdirectory named after the machine-id (as found in <em>/etc/machine-id</em>) that contains the local journal logfiles. The magic number identifying a journal file is the initial byte sequence 0x4C504B5348485248 or LPKSHHRH.</p>&#13;
<p class="indent">The journal files contain both system and user logs. System logs are generated by system services and the kernel. User logs are generated by user login sessions (shell or desktop) and various programs that a user executes. Users may read their own logs, but they are not permitted to modify or write to them directly.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_124"/>Here is an example of a system with a machine-id of <span class="literal">506578466b474f6e88ec</span> <span class="literal">fbd783475780</span> and the corresponding directory with journal logfiles:</p>&#13;
<pre>$ <span class="codestrong1">ls /var/log/journal/506578466b474f6e88ecfbd783475780</span>&#13;
user-1001@0005aa24f4aa649b-46435710c1877997.journal~&#13;
user-1001@dd54beccfb52461d894b914a4114a8f2-00000000000006a8-0005a1d176b61cce.journal&#13;
system@e29c14a0a5fc46929ec601deeabd2204-0000000000000001-00059e3713757a5a.journal&#13;
user-1001@dd54beccfb52461d894b914a4114a8f2-0000000000000966-0005a1d17821abe4.journal&#13;
system@e29c14a0a5fc46929ec601deeabd2204-000000000000189c-00059e37774baedd.journal&#13;
user-1001.journal&#13;
system.journal</pre>&#13;
<p class="indent">Normal journal logs have a file extension of <em>*.journal</em>. If the system crashed or had an unclean shutdown, or if the logs were corrupted, the filename will end in a tilde (<em>*.journal~</em>). Filenames of logs that are in current use, or “online,” are <em>system.journal</em> and <em>user-UID.journal</em> (where UID is the numeric ID of a user). Logs that have been rotated to an “offline” or “archived” state have the original filename followed by <em>@</em> and a unique string. The unique string between the <em>@</em> and <em>.journal</em> is broken into three parts that describe the content of the logfile.</p>&#13;
<p class="indent">Let’s analyze the composition of a long journal filename, as shown in this example:</p>&#13;
<pre>/var/log/journal/506578466b474f6e88ecfbd783475780/system@e29c14a0a&#13;
5fc46929ec601deeabd2204-000000000000189c-00059e37774baedd.journal</pre>&#13;
<p class="indent">The deconstructed parts are as follows:</p>&#13;
<div class="bqparan">&#13;
<p class="noindentin"><span class="codestrong">/var/log/journal/</span> The location (path) of persistent journal files</p>&#13;
<p class="noindentin"><span class="codestrong">506578466b474f6e88ecfbd783475780/</span> The machine-id directory</p>&#13;
<p class="noindentin"><span class="codestrong">system@</span> Indicates a system logfile that has been archived</p>&#13;
<p class="noindentin"><span class="codestrong">e29c14a0a5fc46929ec601deeabd2204</span> A sequence ID</p>&#13;
<p class="noindentin"><span class="codestrong">-000000000000189c</span> The first sequence number in the file</p>&#13;
<p class="noindentin"><span class="codestrong">-00059e37774baedd</span> Hexadecimal timestamp of the first log entry</p>&#13;
<p class="noindentin"><span class="codestrong">.journal</span> Indicates a systemd journal logfile</p>&#13;
</div>&#13;
<p class="noindent">The hexadecimal timestamp refers to when the first entry was added to the journal. For the familiar epoch in seconds, convert this timestamp to decimal and then strip off the last six digits.</p>&#13;
<p class="indent">If the system is receiving journal logs over the network from other hosts (by <span class="literal">systemd-journal-upload</span> or <span class="literal">systemd-journal-gatewayd</span>), a <em>remote/</em> directory may exist that contains logs for each remote host. These logs will have filenames like <em>remote-</em>HOSTNAME<em>.journal</em>.</p>&#13;
<p class="indent">The journal logs the systemd boot process and follows the starting and stopping of unit files until the system is shut down. Linux systems maintain a unique 128-bit boot-id that can be found (on a running system) in <em>/proc/sys/kernel/random/boot_id</em>. The boot-id is randomly generated by the <span epub:type="pagebreak" id="page_125"/>kernel at every boot, and it acts as a unique identifier for a particular duration of uptime (from boot to shutdown/reboot). The boot-id is recorded in the journal logs and used to distinguish time periods between boots (for example, <span class="literal">journalctl --list-boots</span>) and to show logs since the last boot (for example, <span class="literal">journalctl -b</span>). These journalctl options can also be applied to a file or directory for offline analysis. The boot-id may be of interest during a forensic examination if any malicious activity was known to have occurred during a specific boot period.</p>&#13;
<h4 class="h4" id="ch00lev2_66"><strong><em>Analysis of Journal File Contents</em></strong></h4>&#13;
<p class="noindent">If commercial forensic tool support for journal files is unavailable, you can copy and analyze the journal files on a separate Linux analysis machine using the <span class="literal">journalctl</span> command. This command allows you to list the journal contents, search the journal, list individual boot periods, view additional log metadata (journald specific), view <span class="literal">stderr</span> and <span class="literal">stdout</span> from programs, export to other formats, and more.</p>&#13;
<p class="indent">After copying the desired journal files or the entire journal directory to your analysis machine, you can use <span class="literal">journalctl</span> file and directory flags to specify the location of the journal files to be analyzed:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --file</span> &lt;<span class="codeitalic1">filename</span>&gt;&#13;
$ <span class="codestrong1">journalctl --directory</span> &lt;<span class="codeitalic1">directory</span>&gt;</pre>&#13;
<p class="noindent">Specifying a file will operate only on that single file. Specifying a directory will operate on all the valid journal files in that directory.</p>&#13;
<p class="indent">Each journal file contains a header with metadata about itself, which you can view by using the <span class="literal">--header</span> flag of <span class="literal">journalctl</span>; for example:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --file system.journal --header</span>&#13;
File path: system.journal&#13;
File ID: f2c1cd76540c42c09ef789278dfe28a8&#13;
Machine ID: 974c6ed5a3364c2ab862300387aa3402&#13;
Boot ID: e08a206411044788aff51a5c6a631c8f&#13;
Sequential number ID: f2c1cd76540c42c09ef789278dfe28a8&#13;
State: ONLINE&#13;
Compatible flags:&#13;
Incompatible flags: COMPRESSED-ZSTD KEYED-HASH&#13;
Header size: 256&#13;
Arena size: 8388352&#13;
Data hash table size: 233016&#13;
Field hash table size: 333&#13;
Rotate suggested: no&#13;
Head sequential number: 1 (1)&#13;
Tail sequential number: 1716 (6b4)&#13;
Head realtime timestamp: Thu 2020-11-05 08:42:14 CET (5b3573c04ac60)&#13;
Tail realtime timestamp: Thu 2020-11-05 10:12:05 CET (5b3587d636f56)&#13;
Tail monotonic timestamp: 1h 29min 53.805s (1417ef08e)&#13;
<span epub:type="pagebreak" id="page_126"/>Objects: 6631&#13;
Entry objects: 1501&#13;
Data objects: 3786&#13;
Data hash table fill: 1.6%&#13;
Field objects: 85&#13;
Field hash table fill: 25.5%&#13;
Tag objects: 0&#13;
Entry array objects: 1257&#13;
Deepest field hash chain: 2&#13;
Deepest data hash chain: 1&#13;
Disk usage: 8.0M</pre>&#13;
<p class="noindent">The output provides a technical description of the journal file, the time- stamps of the period covered (head and tail), the number of logs (<span class="literal">Entry</span> <span class="literal">objects</span>), and other statistics. You can find more information about the journal file format here:<sup><a id="ch05foot03" href="footnotes.xhtml#ch05foot_03">3</a></sup> <em><a href="https://systemd.io/JOURNAL_FILE_FORMAT/">https://systemd.io/JOURNAL_FILE_FORMAT/</a></em>.</p>&#13;
<p class="indent">The following example is a basic listing of a specific journal file’s contents using the <span class="literal">journalctl</span> command:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --file system.journal</span>&#13;
-- Logs begin at Thu 2020-11-05 08:42:14 CET, end at Thu 2020-11-05 10:12:05 CET. --&#13;
Nov 05 08:42:14 pc1 kernel: microcode: microcode updated early to revision 0xd6,&#13;
date = 2020-04-27&#13;
Nov 05 08:42:14 pc1 kernel: Linux version 5.9.3-arch1-1 (linux@archlinux) (gcc (GCC)&#13;
10.2.0, GNU ld (GNU Binutils) 2.35.1) #1 SMP PREEMPT Sun, 01 Nov 2020 12:58:59 +0000&#13;
Nov 05 08:42:14 pc1 kernel: Command line: BOOT_IMAGE=/boot/vmlinuz-linux root=&#13;
UID=efbfc8dd-8107-4833-9b95-5b11a1b96875 rw loglevel=3 quiet pcie_aspm=off&#13;
i915.enable_dpcd_backlight=1&#13;
...&#13;
Nov 05 10:11:53 pc1 kernel: usb 2-1: Product: USB Flash Drive&#13;
Nov 05 10:11:53 pc1 kernel: usb 2-1: Manufacturer: Philips&#13;
Nov 05 10:11:53 pc1 kernel: usb 2-1: SerialNumber: 070852A521943F19&#13;
Nov 05 10:11:53 pc1 kernel: usb-storage 2-1:1.0: USB Mass Storage device detected&#13;
...&#13;
Nov 05 10:12:05 pc1 sudo[10400]:   sam : TTY=pts/5 ; PWD=/home/sam/test ; USER=root ;&#13;
COMMAND=/usr/bin/cp /etc/shadow .&#13;
Nov 05 10:12:05 pc1 sudo[10400]: pam_unix(sudo:session): session opened for user&#13;
root(uid=0) by (uid=0)&#13;
...</pre>&#13;
<p class="indent">In this example, system.journal is the name of the file being analyzed. The first line is informational, indicating the time period contained in the output. Some of the output is from the kernel, similar to the output from the dmesg command. Other lines are similar to syslog, starting with a timestamp, hostname, daemon name, and the process ID in square brackets, and <span epub:type="pagebreak" id="page_127"/>ending with the log message. The journalctl command may also add other informational lines like -- Reboot -- to indicate the end of a boot period (and the start of a new boot-id).</p>&#13;
<p class="indent">Each log entry has journal-specific metadata stored together with the log message. A full extraction of a journal entry can be done with a verbose output (<span class="literal">-o verbose</span>) parameter. The following is a verbose journal entry from the OpenSSH daemon:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --file system.journal -o verbose</span>&#13;
...&#13;
Thu 2020-11-05 08:42:16.224466 CET [s=f2c1cd76540c42c09ef789278dfe28a8;i=4a9;&#13;
b=e08a206411044788aff51a5c6a631c8f;m=41d525;t=5b3573c2653ed;x=a1434bf47ce8597d]&#13;
    PRIORITY=6&#13;
    _BOOT_ID=e08a206411044788aff51a5c6a631c8f&#13;
    _MACHINE_ID=974c6ed5a3364c2ab862300387aa3402&#13;
    _HOSTNAME=pc1&#13;
    _UID=0&#13;
    _GID=0&#13;
    _SYSTEMD_SLICE=system.slice&#13;
    SYSLOG_FACILITY=4&#13;
    _CAP_EFFECTIVE=1ffffffffff&#13;
    _TRANSPORT=syslog&#13;
    SYSLOG_TIMESTAMP=Nov 5 08:42:16&#13;
    SYSLOG_IDENTIFIER=sshd&#13;
    SYSLOG_PID=397&#13;
    _PID=397&#13;
    _COMM=sshd&#13;
    _EXE=/usr/bin/sshd&#13;
    _CMDLINE=sshd: /usr/bin/sshd -D [listener] 0 of 10-100 startups&#13;
    _SYSTEMD_CGROUP=/system.slice/sshd.service&#13;
    _SYSTEMD_UNIT=sshd.service&#13;
    _SYSTEMD_INVOCATION_ID=7a91ff16d2af40298a9573ca544eb594&#13;
    MESSAGE=Server listening on :: port 22.&#13;
    _SOURCE_REALTIME_TIMESTAMP=1604562136224466&#13;
...</pre>&#13;
<p class="noindent">This output provides structured information with unique identifiers, systemd information, syslog <span class="literal">FACILITY</span> and <span class="literal">PRIORITY</span> (severity), the process that produced the log message, and more. The systemd.journal-fields(7) man page describes the fields of a journal log entry.</p>&#13;
<p class="indent">Journal files are saved in a binary format that’s open and documented. The <span class="literal">journalctl</span> tool can be used to perform various examination tasks on journal files, but some forensic investigators may prefer to export the journal contents into another format for analysis. Two useful output formats are <em>export</em> and <em>json</em>. The export format is similar to the verbose format, with each entry separated by a blank line (this is technically a binary format, but it contains mostly readable text). The <em>json</em> output generates the journal entries in JSON for easy scripting or ingesting into other analysis tools. Here are two <span epub:type="pagebreak" id="page_128"/>command line examples of creating <em>.json</em> and <em>.export</em> files with the full contents of a journal file:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --file system.journal -o json &gt; system.journal.json</span>&#13;
$ <span class="codestrong1">journalctl --file system.journal -o export &gt; system.journal.export</span></pre>&#13;
<p class="noindent">The new files created are <em>system.journal.json</em> and <em>system.journal.export</em>, which other (non-Linux) tools can easily read. Another output format is <em>.json-pretty</em>, which produces JSON in a more human-readable format.</p>&#13;
<p class="indent">Searching journal files is done by including match arguments in the form <em>FIELD</em><span class="literal">=</span><em>VALUE</em>, but the exact value you’re searching for needs to be specified. This type of search can be useful for extracting logs from a particular service. For example, to extract all logs from the <span class="literal">sshd.service</span> unit:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --file system.journal _SYSTEMD_UNIT=sshd.service</span>&#13;
-- Logs begin at Thu 2020-11-05 08:42:14 CET, end at Thu 2020-11-05 10:12:05 CET. --&#13;
Nov 05 08:42:16 pc1 sshd[397]: Server listening on 0.0.0.0 port 22.&#13;
Nov 05 08:42:16 pc1 sshd[397]: Server listening on :: port 22.&#13;
...</pre>&#13;
<p class="indent">Regular expressions (regex) can be used with the --grep= parameter, but they can search only the message fields, not the journal metadata. The search syntax is not very flexible for forensic investigators, and it may be easier to export the journal to another format and use familiar tools like grep or other text search tools.</p>&#13;
<p class="indent">It is worth mentioning that the systemd journal can log <span class="literal">stdout</span> and <span class="literal">sdterr</span> of daemons and other unit files. With traditional syslog, that information was typically lost because the daemon would detach from the controlling terminal when it started. Systemd preserves this output and saves it to the journal. You can list this output by specifying the <span class="literal">stdout</span> transport:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --file user-1000.journal _TRANSPORT=stdout</span></pre>&#13;
<p class="indent">Transports specify how the journal received the log entry. There are other transports like syslog, kernel, audit, and so on. These transports are documented in the systemd.journal-fields(7) man page.</p>&#13;
<p class="indent">If a journal file contains FSS information, the integrity can be checked using the <span class="literal">--verify</span> flag. In the following example, a journal file is checked, and <span class="literal">PASS</span> indicates that the file integrity is verified:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --file system.journal --verify</span>&#13;
PASS: system.journal</pre>&#13;
<p class="indent">If a journal file has been tampered with, it will fail the verification:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --file user-1002.journal --verify</span>&#13;
38fcc0: Invalid hash (afd71703ce7ebaf8 vs.49235fef33e0854e&#13;
38fcc0: Invalid object contents: Bad message&#13;
File corruption detected at user-1002.journal:38fcc0 (of 8388608 bytes, 44%).&#13;
FAIL: user-1002.journal (Bad message)</pre>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_129"/>In this example, the FSS integrity failed at byte offset 0x38fcc0 of the journal file, with a log entry that was maliciously modified. If a logfile has been tampered with in multiple places, the verification will fail at the first instance of tampering.</p>&#13;
<p class="indent">When investigating incidents that happened during a known window of time, extracting logs from an explicit time frame is useful. The <span class="literal">journalctl</span> command can extract logs with a specified time range using two flags: <span class="literal">-S</span> (since) and <span class="literal">-U</span> (until). Any logs existing since the time of <span class="literal">-S</span> until (but not including) the time of <span class="literal">-U</span> are extracted.</p>&#13;
<p class="indent">The following two examples are from a Linux forensic analysis machine where journal files have been copied to an evidence directory for examination using the <span class="literal">journalctl</span> command:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --directory ./evidence -S 2020-11-01 -U 2020-11-03</span>&#13;
$ <span class="codestrong1">journalctl --file ./evidence/system.journal -S "2020-11-05 08:00:00" -U "2020-11-05 09:00:00"</span></pre>&#13;
<p class="noindent">In the first example, the directory containing the journal files is specified and logs from November 1 and November 2 are extracted. The second example specifies a more exact time range and extracts logs from 8 AM to 9 AM on November 5. See the journalctl(1) man page for other variations of the time and date string.</p>&#13;
<p class="indent">The new features of systemd’s journal mechanism are very much aligned with forensic-readiness expectations. The systemd journal offers log completeness and integrity, which are fundamental concepts in digital forensics.</p>&#13;
<h3 class="h3" id="ch00lev1_24"><strong>Other Application and Daemon Logs</strong></h3>&#13;
<p class="noindent">Programs are not required to use syslog or the systemd journal. A daemon or application may have a separate logging mechanism that completely ignores system-provided logging. Daemons or applications may also use syslog or the journal, but with non-standard facilities or severities and their own message formats.</p>&#13;
<h4 class="h4" id="ch00lev2_67"><strong><em>Custom Logging to Syslog or Systemd Journal</em></strong></h4>&#13;
<p class="noindent">Syslog provides a C library function for programs to generate syslog messages. Systemd provides an API for programs to submit log entries to the journal. Developers are free to use those instead of developing their own logging subsystems. However, the facilities, severities, and format of the message, are all decided by the developer. This freedom can lead to a variety of logging configurations among programs.</p>&#13;
<p class="indent">In the following examples, each program uses a different syslog facility and severity for logging similar actions:</p>&#13;
<pre>mail.warning: postfix/smtps/smtpd[14605]: <span class="ent">➊</span> warning: unknown[10.0.6.4]: SASL LOGIN&#13;
 authentication failed: UGFzc3dvcmQ6&#13;
...&#13;
auth.info sshd[16323]: <span class="ent">➋</span> Failed password for invalid user fred from 10.0.2.5 port 48932 ssh2&#13;
<span epub:type="pagebreak" id="page_130"/>...&#13;
authpriv.notice: auth: pam_unix(dovecot:auth): <span class="ent">➌</span> authentication failure; logname= uid=0&#13;
 euid=0 tty=dovecot ruser=sam rhost=10.0.3.8&#13;
...&#13;
daemon.info: danted[30614]: <span class="ent">➍</span> info: block(1): tcp/accept ]: 10.0.2.5.56130 10.0.2.6.1080:&#13;
 error after reading 3 bytes in 0 seconds: client offered no acceptable authentication method</pre>&#13;
<p class="noindent">These logs describe failed logins from a mail server (<span class="literal">postfix</span>) <span class="ent">➊</span>, secure shell (<span class="literal">sshd</span>) <span class="ent">➋</span>, an imap server (<span class="literal">dovecot</span> using <span class="literal">pam</span>) <span class="ent">➌</span>, and a SOCKS proxy (<span class="literal">danted</span>) <span class="ent">➍</span> .They all use different facilities (<span class="literal">mail</span>, <span class="literal">auth</span>, <span class="literal">authpriv</span>, <span class="literal">daemon</span>), and they all use different severities (<span class="literal">warning</span>, <span class="literal">info</span>, <span class="literal">notice</span>). In some cases, additional logs may contain more information about the same event at different facilities or severities. Forensic examiners should not assume all similar log events will use the same facility or severity, but rather should expect some variation.</p>&#13;
<p class="indent">Daemons may choose to log to a custom or user-defined facility. This is usually defined in the daemon’s configuration or from compiled-in defaults. For example:</p>&#13;
<pre>local2.notice: pppd[645]: CHAP authentication succeeded&#13;
local5.info: TCSD[1848]: TrouSerS trousers 0.3.13: TCSD up and running.&#13;
local7.info: apache2[16455]: ssl: 'AH01991: SSL input filter read failed.'</pre>&#13;
<p class="noindent">Here a <span class="literal">pppd</span> daemon is using <span class="literal">local2</span> as the facility, the <span class="literal">tcsd</span> daemon that manages the TPM uses <span class="literal">local5</span>, and an Apache web server (<span class="literal">apache2</span>) is configured to use <span class="literal">local7</span>. Daemons can log to whatever facility they want, and system administrators may choose to configure logging to a desired facility.</p>&#13;
<p class="indent">When an investigation is ongoing or an attack is underway, additional logging may be needed (possibly only temporarily). If there are heightened risks involving potential suspects or victims, logging can be selectively increased to support the collection of digital forensic evidence. For example, consider these potential entities for which selective increased logging could be used:</p>&#13;
<ul>&#13;
<li class="noindent">A particular user or group</li>&#13;
<li class="noindent">A geographical region or specific location</li>&#13;
<li class="noindent">A particular server or group of servers</li>&#13;
<li class="noindent">An IP address or range of IPs</li>&#13;
<li class="noindent">Specific software components running on a system (daemons)</li>&#13;
</ul>&#13;
<p class="indent">Most daemons provide configuration options to increase the verbosity of logging. Some daemons offer very granular possibilities of selective logging. For example, Postfix configuration directives allow increased logging for a specific list of IP addresses or domain names:</p>&#13;
<pre>debug_peer_level = 3&#13;
debug_peer_list = 10.0.1.99</pre>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_131"/>In this example, a single IP address is selected for increased logging, using Postfix’s internal debug levels (3 instead of the default 2). The configuration documentation for each daemon will describe possibilities for verbose, debug, or other selective logging adjustments.</p>&#13;
<p class="indent">As described in the previous section, the <span class="literal">stdout</span> and <span class="literal">stderr</span> of a daemon started with systemd will be captured and logged to the journal, which is also useful from a forensic readiness perspective. If a daemon allows for verbose or debugging output to the console, it can be temporarily enabled for the duration of an incident or investigation.</p>&#13;
<h4 class="h4" id="ch00lev2_68"><strong><em>Independent Server Application Logs</em></strong></h4>&#13;
<p class="noindent">Often applications will manage their own logfiles without the use of local logging systems like syslog or the systemd journal. In those situations, logs are typically stored in a separate logfile or log directory, usually in the <em>/var/ log/</em> directory.</p>&#13;
<p class="indent">Larger applications may be complex enough to warrant multiple separate logfiles for different subsystems and components. This may include separate logfiles for the following:</p>&#13;
<ul>&#13;
<li class="noindent">Application technical errors</li>&#13;
<li class="noindent">User authentication (logins, logouts, and so on)</li>&#13;
<li class="noindent">Application user transactions (web access, sessions, purchases, and so on)</li>&#13;
<li class="noindent">Security violations and alerts</li>&#13;
<li class="noindent">Rotated or archived logs</li>&#13;
</ul>&#13;
<p class="indent">The Apache web server is a good example. It typically has a separate directory like <em>/var/log/apache2/</em> or <em>/var/log/httpd/</em>. The contents of the directory may include logs for the following:</p>&#13;
<ul>&#13;
<li class="noindent">General web access (<em>access.log</em>)</li>&#13;
<li class="noindent">Web access for individual virtual hosts</li>&#13;
<li class="noindent">Web access for individual web applications</li>&#13;
<li class="noindent">Daemon errors (<em>error.log</em>)</li>&#13;
<li class="noindent">SSL error logging</li>&#13;
</ul>&#13;
<p class="noindent">Applications will typically specify the log location, content, and verbosity in their configuration files. A forensic examiner should check for those log locations if it is not otherwise obvious.</p>&#13;
<p class="indent">Some application installations may be fully contained in a specific directory on the filesystem, and the application may use this directory to store logs together with other application files. This setup is typical of web applications that may be self-contained within a directory. For example, the</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_132"/>Nextcloud hosting platform and Roundcube webmail application have such application logs:</p>&#13;
<ul>&#13;
<li class="noindent"><em>nextcloud/data/nextcloud.log</em></li>&#13;
<li class="noindent"><em>nextcloud/data/updater.log</em></li>&#13;
<li class="noindent"><em>nextcloud/data/audit.log</em></li>&#13;
<li class="noindent"><em>roundcube/logs/sendmail.log</em></li>&#13;
<li class="noindent"><em>roundcube/logs/errors.log</em></li>&#13;
</ul>&#13;
<p class="noindent">Keep in mind that these logs are generated in addition to the web server access and error logs (apache, nginx, and so on). With web applications, a forensic examiner may find logs in multiple places related to a particular application, event, or incident.</p>&#13;
<p class="indent">Some applications may store logs in databases instead of text files. These are either full database services like MySQL or Postgres, or local database files like SQLite.</p>&#13;
<p class="indent">Another interesting log related to programs installed on a system is the <em>alternatives</em> log. The alternatives system was originally developed for Debian to allow installation of several concurrent versions of similar programs. Multiple distributions have adopted the alternatives mechanism. The <span class="literal">update-alternatives</span> script manages the symbolic links to generic or alternative application names located in the <em>/etc/alternatives/</em> directory. For example, several symlinks are created to provide a <span class="literal">vi</span> program alternative:</p>&#13;
<pre>$ <span class="codestrong1">ls -gfo /usr/bin/vi /etc/alternatives/vi /usr/bin/vim.basic</span>&#13;
lrwxrwxrwx 1      20 Aug 3 14:27 /usr/bin/vi -&gt; /etc/alternatives/vi&#13;
lrwxrwxrwx 1      18 Nov 8 11:19 /etc/alternatives/vi -&gt; /usr/bin/vim.basic&#13;
-rwxr-xr-x 1 2675336 Oct 13 17:49 /usr/bin/vim.basic</pre>&#13;
<p class="noindent">The timestamp of the <em>/etc/alternatives/</em> symlink indicates when the last change was made. This information is also recorded in the <em>alternatives.log</em> file:</p>&#13;
<pre>$ <span class="codestrong1">cat /var/log/alternatives.log</span>&#13;
...&#13;
update-alternatives 2020-11-08 11:19:06: link group vi updated to point to /usr/bin/vim.basic&#13;
...</pre>&#13;
<p class="noindent">This is a system-wide method of assigning default applications (analogous to XDG defaults for desktop users) and helps build a picture of which programs were used on a system. See the update-alternatives(1) man page<sup><a id="ch05foot04" href="footnotes.xhtml#ch05foot_04">4</a></sup> for more information.</p>&#13;
<p class="indent">During a forensic examination, pay close attention to error logs. Error messages reveal unusual and suspicious activity, and help to reconstruct past events. When investigating intrusions, error messages appearing before an incident can indicate pre-attack reconnaissance or prior failed attempts.</p>&#13;
<h4 class="h4" id="ch00lev2_69"><span epub:type="pagebreak" id="page_133"/><strong><em>Independent User Application Logs</em></strong></h4>&#13;
<p class="noindent">When a user logs in to a Linux system, standard logs are created by the various components of the system (login, pam, display manager, and so on). After a user has logged in to their desktop or shell, further logging may also be saved in locations specific to that user.</p>&#13;
<p class="indent">The systemd journal saves persistent logs specific to a user’s login session in <em>/var/log/journal/</em>MACHINE-ID<em>/</em>user-UID<em>.journal</em>, where <em>UID</em> is a user’s numeric ID. This log (and the rotated instances) contains traces of a person’s login session activity, which may include information like the following:</p>&#13;
<ul>&#13;
<li class="noindent">Systemd targets reached and user services started</li>&#13;
<li class="noindent">Dbus-daemon activated services and other activity</li>&#13;
<li class="noindent">Agents like gnupg, polkit, and so on</li>&#13;
<li class="noindent">Messages from subsystems like pulseaudio and Bluetooth</li>&#13;
<li class="noindent">Logs from desktop environments like GNOME</li>&#13;
<li class="noindent">Privilege escalation like <span class="literal">sudo</span> or <span class="literal">pkexec</span></li>&#13;
</ul>&#13;
<p class="noindent">The format of user journal files is the same as system journal files, and you can use the <span class="literal">journalctl</span> tool to analyze them (described earlier in the chapter).</p>&#13;
<p class="indent">Other logs may be saved by programs as they are run by a user. The location of such program logs must be in a directory writable by the user, which generally means they are somewhere in the user’s home directory. The most common places for persistent logs are the XDG base directory standards such as <em>~/.local/share/</em>APP<em>/*</em> or <em>~/.config/</em>APP<em>/*</em> (where <em>APP</em> is the application generating user logs).</p>&#13;
<p class="indent">The following example shows a Jitsi video chat application log stored in <em>~/.config/</em>, which contains error messages:</p>&#13;
<pre>$ <span class="codestrong1">cat ~/.config/Jitsi\ Meet/logs/main.log</span>&#13;
[2020-10-17 15:20:16.679] [warn] APPIMAGE env is not defined, current&#13;
 application is not an AppImage&#13;
...&#13;
[2020-10-17 16:03:19.045] [warn] APPIMAGE env is not defined, current&#13;
 application is not an AppImage&#13;
...&#13;
[2020-10-21 20:52:19.348] [warn] APPIMAGE env is not defined, current&#13;
 application is not an AppImage</pre>&#13;
<p class="noindent">The benign warning messages shown here were generated whenever the Jitsi application started. For a forensic investigator, the content of these messages may not be interesting, but the timestamps indicate every time the video chat program was started. Trivial errors like this are potentially interesting for reconstructing past events.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_134"/>Some programs ignore the XDG standard and create hidden files and directories at the root of the user’s home directory. For example, the Zoom video chat application creates a <em>~/.zoom/log/</em> directory with a logfile:</p>&#13;
<pre>$ <span class="codestrong1">cat ~/.zoom/logs/zoom_stdout_stderr.log</span>&#13;
ZoomLauncher started.&#13;
cmd line: zoommtg://zoom.us/join?action=join&amp;confno=...&#13;
...</pre>&#13;
<p class="noindent">This Zoom log contains a wealth of information, including traces of past conference IDs that were used.</p>&#13;
<p class="indent">Temporary or non-persistent logs may also be found in <em>~/.local/cache/</em> APP<em>/*</em>, as this cache directory is intended for data that can be deleted.</p>&#13;
<p class="indent">In this example, the <span class="literal">libvirt</span> system for managing the user’s KVM/QEMU virtual machines has a log directory with a file for each machine:</p>&#13;
<pre>$ <span class="codestrong1">cat ~/.cache/libvirt/qemu/log/pc1.log</span>&#13;
2020-09-24 06:57:35.099+0000: starting up libvirt version: 6.5.0, qemu version: 5.1.0,&#13;
kernel: 5.8.10-arch1-1, hostname: pc1.localdomain&#13;
LC_ALL=C \&#13;
PATH=:/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/home/sam/script \&#13;
HOME=/home/sam \&#13;
USER=sam \&#13;
LOGNAME=sam \&#13;
XDG_CACHE_HOME=/home/sam/.config/libvirt/qemu/lib/domain-1-linux/.cache \&#13;
QEMU_AUDIO_DRV=spice \&#13;
/bin/qemu-system-x86_64 \&#13;
...</pre>&#13;
<p class="indent">Performing a search for <em>*.log</em> files or directories called “log” across a user’s home directory will produce an initial list of files to analyze. Linux applications can produce a significant amount of logs and persistent data that’s saved whenever the user runs various programs.</p>&#13;
<p class="indent">The analysis of individual application logs is outside the scope of this book, but it is worth mentioning that many popular apps store significant amounts of information about past use in a user’s home directory. This information often contains a history of files opened, remote host connections, communication with other people, timestamps of usage, devices accessed, and more.</p>&#13;
<h4 class="h4" id="ch00lev2_70"><strong><em>Plymouth Splash Startup Logs</em></strong></h4>&#13;
<p class="noindent">During startup, most desktop distros use the Plymouth system to produce a graphical splash screen while the system is booting. The ESC key can be pressed while waiting to switch to console output. Non-graphical servers can also use Plymouth to provide visible output while a system is booting. The output provides color status indicators with green <span class="literal">[ OK ]</span> or red <span class="literal">[FAILED]</span> messages for each component.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_135"/>This Plymouth console output is typically saved to the <em>/var/log/boot.log</em> file; for example:</p>&#13;
<pre>$ <span class="codestrong1">cat /var/log/boot.log</span>&#13;
...&#13;
[ OK ] Started Update UTMP about System Boot/Shutdown.&#13;
[ OK ] Started Raise network interfaces.&#13;
[ OK ] Started Network Time Synchronization.&#13;
[ OK ] Reached target System Time Synchronized.&#13;
[ OK ] Reached target System Initialization.&#13;
[ OK ] Started Daily Cleanup of Temporary Directories.&#13;
[ OK ] Listening on D-Bus System Message Bus Socket.&#13;
[ OK ] Listening on Avahi mDNS/DNS-SD Stack Activation Socket.&#13;
[ OK ] Started Daily apt download activities.&#13;
[ OK ] Started Daily rotation of log files.&#13;
[ OK ] Started Daily apt upgrade and clean activities.&#13;
[ OK ] Started Daily man-db regeneration.&#13;
[ OK ] Reached target Timers.&#13;
[ OK ] Listening on triggerhappy.socket.&#13;
[ OK ] Reached target Sockets.&#13;
[ OK ] Reached target Basic System.&#13;
...</pre>&#13;
<p class="noindent">This file contains escape codes needed to produce the color indicators. It is safe to view, even if your analysis tool warns that it is a binary file.</p>&#13;
<p class="indent">Failed components during boot will also appear in the boot log:</p>&#13;
<pre>$ <span class="codestrong1">cat /var/log/boot.log</span>&#13;
...&#13;
[FAILED] Failed to start dnss daemon.&#13;
See 'systemctl status dnss.service' for details.&#13;
[ OK ] Started Simple Network Management Protocol (SNMP) Daemon..&#13;
[FAILED] Failed to start nftables.&#13;
See 'systemctl status nftables.service' for details.&#13;
...</pre>&#13;
<p class="noindent">Rotated versions of the boot log may also exist in the <em>/var/log/</em> directory.</p>&#13;
<p class="indent">This boot log can be interesting to analyze in a forensic investigation. It shows the sequence of events during previous boots and may provide useful error messages. For example, the preceding error message indicates that the Linux firewall rules (<span class="literal">nftables</span>) failed to start. If this were an investigation of a system intrusion, that could be a critical piece of information.</p>&#13;
<h3 class="h3" id="ch00lev1_25"><strong>Kernel and Audit Logs</strong></h3>&#13;
<p class="noindent">The logging described so far has been generated by userspace programs, daemons, and applications. The Linux kernel also generates log information from kernel space, which can be useful in a forensic investigation. This <span epub:type="pagebreak" id="page_136"/>section explains the purpose of kernel-generated messages, where they are located, and how to analyze them.</p>&#13;
<p class="indent">The Linux audit system is composed of many userspace tools and daemons to configure auditing, but the auditing and logging activity is performed from within the running kernel. This is the reason for including it here together with the kernel logging mechanism. Firewall logs are also produced by the kernel and would fit nicely in this section, but that topic is covered in <a href="ch08.xhtml">Chapter 8</a> on the forensic analysis of Linux networking.</p>&#13;
<h4 class="h4" id="ch00lev2_71"><strong><em>The Kernel Ring Buffer</em></strong></h4>&#13;
<p class="noindent">The Linux kernel has a cyclic buffer that contains messages generated by the kernel and kernel modules. This buffer is a fixed size, and once it’s full, it stays full and starts overwriting the oldest entries with any new entries, which means kernel logs are continuously lost as new messages are written. Userspace daemons are needed to capture and process events as they are produced. The kernel provides <em>/dev/kmsg</em> and <em>/proc/kmsg</em> for daemons like systemd-journald and rsyslogd to read new kernel messages as they are generated. These messages are then saved or forwarded depending on the log daemon’s configuration.</p>&#13;
<p class="indent">The <span class="literal">dmesg</span> command is used on a running system to display the current contents of the ring buffer, but that isn’t useful in a postmortem forensic examination. The ring buffer exists only in memory, but we can find traces of it in the logs written to the filesystem. During boot, the kernel begins saving messages to the ring buffer before any logging daemons are started. Once these daemons (systemd-journald, rsyslogd, and so on) start, they can read all the current kernel logs and begin to monitor for new ones.</p>&#13;
<p class="indent">It is common for syslog daemons to log kernel events to the <em>/var/log/ kern.log</em> file. Rotated versions of this log may include <em>kern.log.1</em>, <em>kern.log.2.gz</em>, and so on. The format is similar to other syslog files. For example, the saved kernel logs from a compressed rotated log from rsyslogd on a Raspberry Pi look like this:</p>&#13;
<pre>$ <span class="codestrong1">zless /var/log/kern.log.2.gz</span>&#13;
Aug 12 06:17:04 raspberrypi kernel: [  0.000000] Booting Linux on physical CPU 0x0&#13;
Aug 12 06:17:04 raspberrypi kernel: [  0.000000] Linux version 4.19.97-v7l+ (dom@buildbot) ...&#13;
Aug 12 06:17:04 raspberrypi kernel: [  0.000000] CPU: ARMv7 Processor [410fd083] revision 3&#13;
(ARMv7), cr=30c5383d&#13;
Aug 12 06:17:04 raspberrypi kernel: [  0.000000] CPU: div instructions available: patching&#13;
division code&#13;
Aug 12 06:17:04 raspberrypi kernel: [  0.000000] CPU: PIPT / VIPT nonaliasing data cache,&#13;
PIPT instruction cache&#13;
Aug 12 06:17:04 raspberrypi kernel: [  0.000000] OF: fdt: Machine model: Raspberry Pi 4&#13;
Model B Rev 1.1&#13;
...</pre>&#13;
<p class="noindent">The rsyslogd daemon has a module called <span class="literal">imklog</span> that manages the logging of kernel events and is typically configured in the <em>/etc/rsyslog.conf</em> file.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_137"/>Systemd stores kernel logs in the journal with everything else. To view the kernel logs from a journal file, add the <span class="codestrong">-k</span> flag, as follows:</p>&#13;
<pre>$ <span class="codestrong1">journalctl --file system.journal -k</span>&#13;
-- Logs begin at Thu 2020-11-05 08:42:14 CET, end at Thu 2020-11-05 10:12:05 CET. --&#13;
Nov 05 08:42:14 pc1 kernel: microcode: microcode updated early to revision 0xd6, date =&#13;
 2020-04-27&#13;
Nov 05 08:42:14 pc1 kernel: Linux version 5.9.3-arch1-1 (linux@archlinux) (gcc (GCC)&#13;
 10.2.0, GNU ld (GNU Binutils) 2.35.1) #1 SMP PREEMPT Sun, 01 Nov 2020 12:58:59 +0000&#13;
Nov 05 08:42:14 pc1 kernel: Command line: BOOT_IMAGE=/boot/vmlinuz-linux root=UUID=efbfc8dd&#13;
-8107-4833-9b95-5b11a1b96875 rw loglevel=3 quiet pcie_aspm=off i915.enable_dpcd_backlight=1&#13;
...</pre>&#13;
<p class="noindent">The <em>/etc/systemd/journald.conf</em> has a parameter (<span class="literal">ReadKMsg=</span>) that enables processing of kernel messages from <em>/dev/kmsg</em> (which is the default).</p>&#13;
<p class="indent">For a forensic examiner, kernel messages are important to help reconstruct the hardware components of a system at boot time and during system operation (until shutdown). During this period (identified by the boot-id), a record of attached, detached, and modified hardware devices (including manufacturer details) can be seen. In addition, information about various kernel subsystems such as networking, filesystems, virtual devices, and more can be found. Some examples of information that you can find in the kernel logs include:</p>&#13;
<ul>&#13;
<li class="noindent">CPU features and microcode</li>&#13;
<li class="noindent">Kernel version and kernel command line</li>&#13;
<li class="noindent">Physical RAM and memory maps</li>&#13;
<li class="noindent">BIOS and mainboard details</li>&#13;
<li class="noindent">ACPI information</li>&#13;
<li class="noindent">Secure boot and TPM</li>&#13;
<li class="noindent">PCI bus and devices</li>&#13;
<li class="noindent">USB hubs and devices</li>&#13;
<li class="noindent">Ethernet interfaces and network protocols</li>&#13;
<li class="noindent">Storage devices (SATA, NVMe, and so on)</li>&#13;
<li class="noindent">Firewall logging (blocked or accepted packets)</li>&#13;
<li class="noindent">Audit logs</li>&#13;
<li class="noindent">Errors and security alerts</li>&#13;
</ul>&#13;
<p class="indent">Let’s look at some examples of kernel messages that are interesting in a forensic investigation or that may raise questions regarding the existence of the message.</p>&#13;
<p class="indent">In this example, information about a particular mainboard is provided:</p>&#13;
<pre>Aug 16 12:19:20 localhost kernel: DMI: System manufacturer System Product&#13;
 Name/RAMPAGE IV BLACK EDITION, BIOS 0602 02/26/2014</pre>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_138"/>Here, we can determine the mainboard is an ASUS Republic of Gamers model, and the current firmware (BIOS) version is shown. The mainboard model may provide some indication of system use (gamer rig, server, office PC, and so on). The firmware version may be of interest when examining security relevant vulnerabilities.</p>&#13;
<p class="indent">Newly attached hardware will generate kernel logs like the following:</p>&#13;
<pre>Nov 08 15:16:07 pc1 kernel: usb 1-1: new full-speed USB device number 19 using xhci_hcd&#13;
Nov 08 15:16:08 pc1 kernel: usb 1-1: New USB device found, idVendor=1f6f, idProduct=0023,&#13;
 bcdDevice=67.59&#13;
Nov 08 15:16:08 pc1 kernel: usb 1-1: New USB device strings: Mfr=1, Product=2, SerialNumber=3&#13;
Nov 08 15:16:08 pc1 kernel: usb 1-1: Product: Jawbone&#13;
Nov 08 15:16:08 pc1 kernel: usb 1-1: Manufacturer: Aliph&#13;
Nov 08 15:16:08 pc1 kernel: usb 1-1: SerialNumber: Jawbone_00213C67C898</pre>&#13;
<p class="noindent">Here, an external speaker was plugged in to the system. This log information associates a specific piece of hardware with a machine at a specific point in time, and indicates that a person was in physical proximity to plug in the USB cable.</p>&#13;
<p class="indent">The following is an example kernel message about a network interface’s mode:</p>&#13;
<pre>Nov 2 22:29:57 pc1 kernel: [431744.148772] device enp8s0 entered promiscuous mode&#13;
Nov 2 22:33:27 pc1 kernel: [431953.449321] device enp8s0 left promiscuous mode</pre>&#13;
<p class="noindent">A network interface in <em>promiscuous mode</em> indicates that a packet sniffer is being used to capture traffic on a network subnet. An interface may enter promiscuous mode when a network administrator is troubleshooting problems or if a machine has been compromised and is sniffing for passwords or other information.</p>&#13;
<p class="indent">A kernel message about a network interface’s online/offline status may look like this:</p>&#13;
<pre>Jul 28 12:32:42 pc1 kernel: e1000e: enp0s31f6 NIC Link is Up 1000 Mbps Full Duplex,&#13;
 Flow Control: Rx/TX&#13;
Jul 28 13:12:01 pc1 kernel: e1000e: enp0s31f6 NIC Link is Down</pre>&#13;
<p class="noindent">Here, the kernel logs indicate that a network interface came online for nearly 50 minutes before going offline. If this were an intrusion or data theft investigation, observing an interface suddenly appearing could indicate an unused network port was involved. And if an unused physical Ethernet port was involved, it could mean that there was physical access to the server (which then means that you should check CCTV footage or server room access logs).</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_139"/>When analyzing the kernel logs, try to separate the boot logs from the operational logs. During boot, there will be hundreds of log lines in a short period that are all associated with the boot process. The kernel logs generated after booting is finished will indicate changes during the operational state of the machine until shutdown.</p>&#13;
<p class="indent">You can temporarily increase the verbosity of kernel logs during an ongoing investigation or attack to generate additional information. The kernel accepts parameters to specify increased (or reduced) logging in several areas. See <em><a href="https://github.com/torvalds/linux/blob/master/Documentation/admin-guide/kernel-parameters.txt">https://github.com/torvalds/linux/blob/master/Documentation/admin-guide/kernel-parameters.txt</a></em> for more information about the kernel parameters (search for “log”). These parameters can be added to GRUB during system startup (see <a href="ch06.xhtml">Chapter 6</a> for more information).</p>&#13;
<p class="indent">Individual kernel modules may also have verbose flags to increase logging. Use <span class="codestrong">modinfo</span> with the kernel module name to find possible debug options. Here is an example:</p>&#13;
<pre>$ <span class="codestrong1">modinfo e1000e</span>&#13;
filename:       /lib/modules/5.9.3-arch1-1/kernel/drivers/net/ethernet/intel/e1000e/e1000e.ko.xz&#13;
license:        GPL v2&#13;
description:    Intel(R) PRO/1000 Network Driver&#13;
...&#13;
parm:           debug:Debug level (0=none,...,16=all) (int)&#13;
...</pre>&#13;
<p class="noindent">In this example, Ethernet module e1000e has a <span class="literal">debug</span> option that can be set. The options for individual modules can be specified by placing a <em>*.conf</em> file in the <em>/etc/modprobe.d/</em> directory. See the modprobe.d(5) man page for more information.</p>&#13;
<h4 class="h4" id="ch00lev2_72"><strong><em>The Linux Auditing System</em></strong></h4>&#13;
<p class="noindent">The Linux Auditing System is described in the README file of the source code: “The Linux Audit subsystem provides a secure logging framework that is used to capture and record security relevant events.” Linux auditing is a kernel feature that generates an audit trail based on a set of rules. It has similarities to other logging mechanisms, but it is more flexible, granular, and able to log file access and system calls. The <span class="literal">auditctl</span> program loads rules into the kernel, and the <span class="literal">auditd</span> daemon writes the audit records to disk. See the auditctl(8) and auditd(8) man pages for more information. <a href="ch05.xhtml#ch05fig04">Figure 5-4</a> shows the interaction between the various components.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_140"/><img id="ch05fig04" src="Images/ch05fig04.jpg" alt="Image" width="590" height="686"/></div>&#13;
<p class="figcap"><em>Figure 5-4: Linux Auditing System</em></p>&#13;
<p class="indent">There are three kinds of audit rules:</p>&#13;
<div class="bqparan">&#13;
<p class="noindentin"><strong>Control rules</strong> Overall control of the audit system</p>&#13;
<p class="noindentin"><strong>File or “watch” rules</strong> Audit access to files and directories</p>&#13;
<p class="noindentin"><strong>Syscall</strong> Audit system calls</p>&#13;
</div>&#13;
<p class="noindent">Audit rules are loaded into the kernel at boot time or by a system administrator using the <span class="literal">auditctl</span> tool on a running system.<sup><a id="ch05foot05" href="footnotes.xhtml#ch05foot_05">5</a></sup> The audit rules are located in the <em>/etc/audit/audit.rules</em> file. See the audit.rules(7) man page for more information about audit rules.</p>&#13;
<p class="indent">A collection of separate rule files located in <em>/etc/audit/rules.d/*.rules</em> can be merged with the <em>/etc/audit/audit.rules</em> file using the <em>augenrules</em> file. The audit rules file is simply a list of arguments that would be provided to <span class="literal">auditctl</span> commands.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_141"/>Here are several examples of audit rule lines as seen in a rule file:</p>&#13;
<pre>-D&#13;
-w /etc/ssl/private -p rwa&#13;
-a always,exit -S openat -F auid=1001</pre>&#13;
<p class="noindent">The first rule deletes all current rules, effectively creating a new rule set. The second rule watches all the files in the <em>/etc/ssl/private/</em> directory (recursively). If any user or process reads, writes, or changes the attributes on any files (like SSL private keys), an audit record will be generated. The third rule monitors a specific user (UID 1001 specified with <span class="literal">auid=</span>) for all files opened. Presumably this user is at heightened risk of attack or under suspicion.</p>&#13;
<p class="indent">The default location of the audit log is <em>/var/log/audit/audit.log</em> where <span class="literal">auditd</span> writes new audit records. This is a plaintext file with <em>FIELD = VALUE</em> pairs separated by spaces. The current list of field names can be found at <em><a href="https://github.com/linux-audit/audit-documentation/blob/master/specs/fields/field-dictionary.csv">https://github.com/linux-audit/audit-documentation/blob/master/specs/fields/field-dictionary.csv</a></em>. This file can be examined in its raw format, but the <span class="literal">ausearch</span> and <span class="literal">aureport</span> tools provide normalization, post-processing, and more readable output.</p>&#13;
<p class="indent">The <em>audit.log</em> file can be copied to a Linux analysis machine on which <span class="literal">ausearch</span> and <span class="literal">aureport</span> can be used with the <span class="literal">--input</span> flag to specify the file.</p>&#13;
<p class="indent">An audit record format can be raw or enriched. Enriched records additionally resolve numbers to names and append them to the log line. An example enriched audit record from a <em>/var/log/audit/audit.log</em> file looks like this:</p>&#13;
<pre>type=USER_CMD msg=audit(1596484721.023:459): pid=12518 uid=1000 auid=1000 ses=3&#13;
subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 msg='cwd="/home/sam"&#13;
cmd=73797374656D63746C20656E61626C652073736864 exe="/usr/bin/sudo" terminal=pts/0&#13;
res=success{'}^]UID="sam" AUID="sam"</pre>&#13;
<p class="indent">The same audit record produced with the ausearch tool looks like:</p>&#13;
<pre>$ <span class="codestrong1">ausearch --input audit.log</span>&#13;
...&#13;
time-&gt;Mon Aug 3 21:58:41 2020&#13;
type=USER_CMD msg=audit(1596484721.023:459): pid=12518 uid=1000 auid=1000 ses=3&#13;
subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 msg='cwd="/home/sam"&#13;
cmd=73797374656D63746C20656E61626C652073736864 exe="/usr/bin/sudo" terminal=pts/0&#13;
res=success'&#13;
...</pre>&#13;
<p class="noindent">This command produces a formatted output of the entire <em>audit.log</em> file. Here the date is converted from epoch format, and some control character formatting corrections are made.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_142"/>You can specify <span class="literal">csv</span> or <span class="literal">text</span> for the output format. The <span class="literal">csv</span> format is useful for importing into other tools. The <span class="literal">text</span> format produces a single readable line for each audit record:</p>&#13;
<pre>$ <span class="codestrong1">ausearch --input audit.log --format text</span>&#13;
...&#13;
At 20:05:53 2020-11-08 system, acting as root, successfully started-service&#13;
man-db-cache-update using /usr/lib/systemd/systemd&#13;
At 20:05:53 2020-11-08 system, acting as root, successfully stopped-service&#13;
man-db-cache-update using /usr/lib/systemd/systemd&#13;
At 20:05:53 2020-11-08 system, acting as root, successfully stopped-service&#13;
run-r629edb1aa999451f942cef564a82319b using /usr/lib/systemd/systemd&#13;
At 20:07:02 2020-11-08 sam successfully was-authorized sam using /usr/bin/sudo&#13;
At 20:07:02 2020-11-08 sam successfully ran-command nmap 10.0.0.1 using /usr/bin/sudo&#13;
At 20:07:02 2020-11-08 sam, acting as root, successfully refreshed-credentials root&#13;
using /usr/bin/sudo&#13;
At 20:07:02 2020-11-08 sam, acting as root, successfully started-session /dev/pts/1&#13;
using /usr/bin/sudo&#13;
At 20:07:06 2020-11-08 sam, acting as root, successfully ended-session /dev/pts/1</pre>&#13;
<p class="noindent">See the ausearch(8) man page for other specific queries of the audit log.</p>&#13;
<p class="indent">To generate a report of statistics from an audit logfile, the <span class="literal">aureport</span> command can be used:</p>&#13;
<pre>$ <span class="codestrong1">aureport --input audit.log</span>&#13;
&#13;
Summary Report&#13;
======================&#13;
Range of time in logs: 2020-08-03 13:08:48.433 - 2020-11-08 20:07:09.973&#13;
Selected time for report: 2020-08-03 13:08:48 - 2020-11-08 20:07:09.973&#13;
Number of changes in configuration: 306&#13;
Number of changes to accounts, groups, or roles: 4&#13;
Number of logins: 25&#13;
Number of failed logins: 2&#13;
Number of authentications: 48&#13;
Number of failed authentications: 52&#13;
Number of users: 5&#13;
Number of terminals: 11&#13;
Number of host names: 5&#13;
Number of executables: 11&#13;
Number of commands: 5&#13;
Number of files: 0&#13;
Number of AVC's: 0&#13;
Number of MAC events: 32&#13;
Number of failed syscalls: 0&#13;
Number of anomaly events: 5&#13;
Number of responses to anomaly events: 0&#13;
Number of crypto events: 211&#13;
<span epub:type="pagebreak" id="page_143"/>Number of integrity events: 0&#13;
Number of virt events: 0&#13;
Number of keys: 0&#13;
Number of process IDs: 136&#13;
Number of events: 22056</pre>&#13;
<p class="noindent">This summary may be useful for inclusion in a forensic report or to help guide where to look next in a forensic examination.</p>&#13;
<p class="indent">You can generate individual reports for each of these statistics. For example, the following generates a report on logins:</p>&#13;
<pre>$ <span class="codestrong1">aureport --input audit.log --login</span>&#13;
&#13;
Login Report&#13;
============================================&#13;
# date time auid host term exe success event&#13;
============================================&#13;
1. 2020-08-03 14:08:59 1000 ? ? /usr/libexec/gdm-session-worker yes 294&#13;
2. 2020-08-03 21:55:21 1000 ? ? /usr/libexec/gdm-session-worker no 444&#13;
3. 2020-08-03 21:58:52 1000 10.0.11.1 /dev/pts/1 /usr/sbin/sshd yes 529&#13;
4. 2020-08-05 07:11:42 1000 10.0.11.1 /dev/pts/1 /usr/sbin/sshd yes 919&#13;
5. 2020-08-05 07:12:38 1000 10.0.11.1 /dev/pts/1 /usr/sbin/sshd yes 950</pre>&#13;
<p class="noindent">See the aureport(9) man page for the flags needed to generate other detailed reports about the other statistics.</p>&#13;
<p class="indent">The <span class="literal">aureport</span> and <span class="literal">ausearch</span> commands can also specify a time period. For example, this report is generated for the time period between 9 AM and 10 AM (but not including 10 AM) on November 8:</p>&#13;
<pre>$ <span class="codestrong1">aureport --input audit.log --start 2020-11-08 09:00:00 --end 2020-11-08 09:59:59</span></pre>&#13;
<p class="noindent">Both <span class="literal">aureport</span> and <span class="literal">ausearch</span> use the same flags for the time range.</p>&#13;
<p class="indent">The <span class="literal">aureport</span> and <span class="literal">ausearch</span> commands have flags to interpret numeric entities and convert them to names. Do not do this. It will replace the numeric user IDs and group IDs with the matching names found on your own analysis machine, not from the suspect disk under analysis. The <span class="literal">ausearch</span> command also has a flag to resolve hostnames, which is not recommended when performing a forensic examination. This will potentially trigger a DNS network request, which could produce inaccurate results or otherwise compromise an investigation.</p>&#13;
<h3 class="h3" id="ch00lev1_26"><strong>Summary</strong></h3>&#13;
<p class="noindent">In this chapter, we have identified the locations of typical logs found on a Linux system. You have learned how to view these logs and the information they may contain. You have also seen examples of tools used to analyze logs in a forensic context. This chapter has provided the background on Linux logs that are referenced throughout the rest of the book.<span epub:type="pagebreak" id="page_144"/></p>&#13;
</div></body></html>