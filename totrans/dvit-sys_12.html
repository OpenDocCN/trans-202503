<html><head></head><body>
<h2 class="h2" id="ch12"><span epub:type="pagebreak" id="page_589"/><span class="big">12</span><br/>CODE OPTIMIZATION</h2>&#13;
<div class="imagec"><img alt="image" src="../images/common.jpg"/></div>&#13;
<p class="noindents"><em>Code optimization</em> is the process by which a program is improved by reducing its code size, complexity, memory use, or runtime (or some combination thereof) without changing the program’s inherent function. Many compilation systems include a code optimizer as an intermediate step. Specifically, an <em>optimizing compiler</em> applies code-improving transformations as part of the compilation process. Virtually all modern compilers (including GCC) are optimizing compilers. The GCC C compiler implements a wide variety of <em>optimization flags</em> that give programmers direct access to a subset of the implemented optimizations. Compiler optimization flags optimize code at the expense of compile time and ease of debugging. For simplicity, GCC wraps up a subset of these optimization flags into different <em>optimization levels</em> that the programmer can directly <span epub:type="pagebreak" id="page_590"/>invoke. For example, the following command compiles a sample program with level 1 optimizations:</p>&#13;
<pre>$ <span class="codestrong1">gcc -O1 -o program program.c</span></pre>&#13;
<p class="indent">The level 1 (<code>-O1</code> or <code>-O</code>) optimizations in GCC perform basic optimizations to reduce code size and execution time while attempting to keep compile time to a minimum. Level 2 (<code>-O2</code>) optimizations include most of GCC’s implemented optimizations that do not involve a space–performance trade-off. Lastly, level 3 (<code>-O3</code>) performs additional optimizations (such as function inlining, discussed later in this chapter), and may cause the program to take significantly longer to compile. The GCC documentation<sup><a href="ch12.xhtml#fn12_1" id="rfn12_1">1</a></sup> describes the implemented optimization flags in detail.</p>&#13;
<p class="indent">A detailed discussion of optimizing compilers and their construction and operation is beyond the scope of this textbook; we encourage interested readers to check out the seminal text, <em>Compilers: Principles, Techniques, and Tools</em>, by Aho, Sethi, and Ulman. Rather, the purpose of the chapter is to highlight some things that most compilers can (and cannot) do, and how programmers can partner with their compilers and profiling tools to help improve their code.</p>&#13;
<h4 class="h4" id="lev2_202">What Compilers Already Do</h4>&#13;
<p class="noindent">Several of the common optimizations performed by virtually every compiler are described briefly in the upcoming sections. Students should <em>never</em> manually implement these optimizations, because they are already implemented by the compiler.</p>&#13;
<h5 class="h5" id="lev3_92">Constant Folding</h5>&#13;
<p class="noindent">Constants in the code are evaluated at compile time to reduce the number of resulting instructions. For example, in the code snippet that follows, <em>macro expansion</em> replaces the statement <code>int debug = N-5</code> with <code>int debug = 5-5</code>. <em>Constant folding</em> then updates this statement to <code>int debug = 0</code>.</p>&#13;
<pre>#define N 5<br/>&#13;
int debug = N - 5; //constant folding changes this statement to debug = 0;</pre>&#13;
<h5 class="h5" id="lev3_93">Constant Propagation</h5>&#13;
<p class="noindent"><em>Constant propagation</em> replaces variables with a constant value if such a value is known at compile time. Consider the following code segment:</p>&#13;
<pre>int debug = 0;<br/>&#13;
<br/>&#13;
//sums up all the elements in an array<br/>&#13;
int doubleSum(int *array, int length){<br/>&#13;
    int i, total = 0;<br/>&#13;
    for (i = 0; i &lt; length; i++){<br/>&#13;
        total += array[i];<br/>&#13;
        if (debug) {<br/>&#13;
            printf("array[%d] is: %d\n", i, array[i]);<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
    return 2 * total;<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_591"/>A compiler employing constant propagation will change <code>if (debug)</code> to <code>if (0)</code>.</p>&#13;
<h5 class="h5" id="lev3_94">Dead Code Elimination</h5>&#13;
<p class="noindent">It is not uncommon for a program to be littered with unused variables, assignments, or statements. Even though these unneeded statements are rarely introduced intentionally, they are often a natural by-product of the constant iteration and refinement of the software development cycle. If left undetected, these so-called <em>dead code</em> sequences can cause compilers to output unnecessary assembly instructions that in turn waste processing time. Most compilers employ techniques such as dataflow analysis to identify unreachable code segments and thereby remove them. <em>Dead code elimination</em> often makes a program faster by shrinking code size and the associated set of instructions. As an <span epub:type="pagebreak" id="page_592"/>example, let’s revisit the <code>doubleSum</code> function in which the compiler employed constant propagation to replace <code>debug</code> with <code>0</code> in the <code>if</code> statement:</p>&#13;
<pre>int debug = 0;<br/>&#13;
<br/>&#13;
//sums up all the elements in an array<br/>&#13;
int doubleSum(int *array, int length){<br/>&#13;
    int i, total = 0;<br/>&#13;
    for (i = 0; i &lt; length; i++){<br/>&#13;
        total += array[i];<br/>&#13;
        if (0) { //debug replaced by constant propagation by compiler<br/>&#13;
            printf("array[%d] is: %d\n", i, array[i]);<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
    return 2 * total;<br/>&#13;
}</pre>&#13;
<p class="indent">A compiler employing dataflow analysis recognizes that the <code>if</code> statement always evaluates to false and that the <code>printf</code> statement never executes. The compiler therefore eliminates the <code>if</code> statement and the call to <code>printf</code> in the compiled executable. Another pass also eliminates the statement <code>debug = 0</code>.</p>&#13;
<h5 class="h5" id="lev3_95">Simplifying expressions</h5>&#13;
<p class="noindent">Some instructions are more expensive than others. For example, the <code>imul</code> and <code>idiv</code> arithmetic instructions in assembly take a long time to execute. Compilers commonly attempt to reduce the number of expensive instructions by simplifying mathematical operations whenever possible. For example, in the <code>doubleSum</code> function, the compiler may replace the expression <code>2 * total</code> with <code>total + total</code> because the addition instruction is less expensive than multiplication:</p>&#13;
<pre>//declaration of debug removed through dead-code elimination<br/>&#13;
<br/>&#13;
//sums up all the elements in an array<br/>&#13;
int doubleSum(int *array, int length){<br/>&#13;
    int i, total = 0;<br/>&#13;
    for (i = 0; i &lt; length; i++){<br/>&#13;
        total += array[i];<br/>&#13;
        //if statement removed through data-flow analysis<br/>&#13;
    }<br/>&#13;
    return total + total; //simplifying expression<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent">Likewise, the compiler will transform code sequences with bit-shifting and other bitwise operators to simplify expressions. For example, the compiler may replace the expression <code>total * 8</code> with <code>total &lt;&lt; 3</code>, or the expression <code>total % 8</code> with <code>total &amp; 7</code> given that bitwise operations are performed with a single fast instruction.</p>&#13;
<h4 class="h4" id="lev2_203">What Compilers Cannot Always Do: Benefits of Learning Code Optimization</h4>&#13;
<p class="noindent">Given the benefits of optimizing compilers, it may not be immediately obvious why learning code optimization is useful. It may be tempting to think of the compiler as a magical black box that is “smart.” At the end of the day, the compiler is a piece of software that performs a series of code transformations in an effort to speed up code. Compilers are also limited in the types of optimizations they can perform.</p>&#13;
<h5 class="h5" id="lev3_96">Algorithmic Strength Reduction Is Impossible</h5>&#13;
<p class="noindent">The top reason for poor code performance is bad choices of data structures and algorithms. Compilers cannot magically fix these bad decisions. For example, a compiler will never optimize a program implementing bubble sort into one that implements quick sort. While the sophistication of compilers and their optimizations continues to improve, the <em>quality</em> of any individual compiler’s optimizations varies between platforms. The onus is therefore on the programmer to ensure that their code leverages the best algorithms and data structures.</p>&#13;
<h5 class="h5" id="lev3_97">Compiler Optimization Flags Are Not Guaranteed to Make Code “Optimal” (or Consistent)</h5>&#13;
<p class="noindent">Increasing the level of compiler optimizations (e.g., from <code>-O2</code> to <code>-O3</code>) may not always decrease the runtime of a program. Sometimes, the programmer may discover that updating the optimization flags from <code>-O2</code> to <code>-O3</code> <em>slows down</em> a program or yields no performance increase at all. In other cases, a programmer may discover that a program compiled without the optimization flags seemingly yields no errors, whereas compiling it with <code>-O2</code> or <code>-O3</code> results <span epub:type="pagebreak" id="page_593"/>in segmentation faults or other errors. These types of programming errors are especially difficult to debug, because gcc’s debug (<code>-g</code>) flag is incompatible with its optimization (<code>-O</code>) flags, as the transformations performed by compiler optimizations at the <code>-O</code> levels interfere with the debugger’s ability to analyze the underlying code. The <code>-g</code> flag is required by many common profiling tools, such as GDB and Valgrind.</p>&#13;
<p class="indent">One large reason for inconsistent behavior is that the C/C++ standard does not provide clear guidance for resolving undefined behavior. As a result, it is often up to the compiler to decide how to resolve ambiguity. Inconsistencies on how different optimization levels handle undefined behavior can cause answers to <em>change</em>. Consider the following example from John Regehr:<sup><a href="ch12.xhtml#fn12_2" id="rfn12_2">2</a></sup></p>&#13;
<pre>int silly(int a) {<br/>&#13;
  return (a + 1) &gt; a;<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent">Suppose that <code>silly</code> was run with <code>a = INT_MAX</code>. In this case, the computation <code>a + 1</code> results in integer overflow. However, the C/C++ standard does not define <em>how</em> integer overflow should be handled by the compiler. In fact, compiling the program with no optimizations causes the function to return 0, while compiling it with <code>-O3</code> optimizations results in the function returning 1.</p>&#13;
<p class="indent">In short, optimization flags should be used with caution, thoughtfully, and when necessary. Learning which optimization flags to employ can also help the programmer work with their compiler instead of against it.</p>&#13;
<p class="note"><strong><span class="black">Note</span> THE COMPILER IS NOT REQUIRED TO HANDLE UNDEFINED BEHAVIOR</strong></p>&#13;
<p class="note1">The <code>silly</code> function when run with <code>a = INT_MAX</code> is an example of undefined behavior. Note that the inconsistent output produced by the compiler is not a flaw in the compiler’s design or a consequence of using optimization flags. Compilers are specifically designed to follow a language’s specification. The C Language standard does not specify what a compiler should do when it encounters undefined behavior; the program may crash, fail to compile, or generate inconsistent or incorrect results. Ultimately, the programmer is responsible for identifying and eliminating undefined behavior in code. Whether <code>silly</code> should return 0, 1, or some other value is ultimately a decision the programmer must make. To learn more about undefined behavior and related issues in C programs, visit the C FAQ<sup><a href="ch12.xhtml#fn12_3" id="rfn12_3">3</a></sup> or John Regehr’s Guide to Undefined Behavior.<sup><a href="ch12.xhtml#fn12_4" id="rfn12_4">4</a></sup></p>&#13;
<h5 class="h5" id="lev3_98">Pointers Can Prove Problematic</h5>&#13;
<p class="noindent">Recall that the compiler makes transformations that leave the fundamental behavior of the source program unchanged. If a transformation risks changing the behavior of the program, the compiler will not make the transformation. This is especially true in the case of <em>memory aliasing</em> where two different pointers point to the same address in memory. As an example, consider the function <code>shiftAdd</code>, which takes two integer pointers as its two parameters. <span epub:type="pagebreak" id="page_594"/>The function multiplies the first number by 10 and adds the second number to it. So, if the <code>shiftAdd</code> function were passed the integers 5 and 6, the result will be 56.</p>&#13;
<p class="margnote">Unoptimized version</p>&#13;
<pre>void shiftAdd(int *a, int *b){<br/>&#13;
    *a = *a * 10; //multiply by 10<br/>&#13;
    *a += *b; //add b<br/>&#13;
}&#13;
</pre>&#13;
<p class="margnote">Optimized version</p>&#13;
<pre>void shiftAddOpt(int *a, int *b){<br/>&#13;
    *a = (*a * 10) + *b;<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent">The <code>shiftAddOpt</code> function optimizes the <code>shiftAdd</code> function by removing an additional memory reference to <code>a</code>, resulting in a smaller set of instructions in the compiled assembly. However, the compiler will never make this optimization due to the risk of memory aliasing. To understand why, consider the following <code>main</code> function:</p>&#13;
<pre>int main(void){<br/>&#13;
    int x = 5;<br/>&#13;
    int y = 6;<br/>&#13;
    shiftAdd(&amp;x, &amp;y); //should produce 56<br/>&#13;
    printf("shiftAdd produces: %d\n", x);<br/>&#13;
<br/>&#13;
    x = 5; //reset x<br/>&#13;
    shiftAddOpt(&amp;x, &amp;y); //should produce 56<br/>&#13;
    printf("shiftAddOpt produces: %d\n", x);<br/>&#13;
<br/>&#13;
    return 0;<br/>&#13;
<br/>&#13;
}</pre>&#13;
<p class="indent">Compiling and running this program gives the expected output:</p>&#13;
<pre>$ <span class="codestrong1">gcc -o shiftadd shiftadd.c</span><br/>&#13;
$ <span class="codestrong1">./shiftadd</span><br/>&#13;
shiftAdd produces: 56<br/>&#13;
shiftAddOpt produces: 56<br/>&#13;
</pre>&#13;
<p class="indent">Suppose, instead, that the program were modified so that <code>shiftAdd</code> now takes a pointer to <code>x</code> as its two parameters:</p>&#13;
<pre>int main(void){<br/>&#13;
    int x = 5;<br/>&#13;
    shiftAdd(&amp;x, &amp;x); //should produce 55<br/>&#13;
    printf("shiftAdd produces: %d\n", x);<br/>&#13;
<br/>&#13;
    x = 5; //reset x<br/>&#13;
    shiftAddOpt(&amp;x, &amp;x); //should produce 55<br/>&#13;
    printf("shiftAddOpt produces: %d\n", x);<br/>&#13;
<br/>&#13;
    return 0;<br/>&#13;
<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_595"/>The expected output is 55. However, recompiling and rerunning the updated code gives two different outputs:</p>&#13;
<pre>$ <span class="codestrong1">gcc -o shiftadd shiftadd.c</span><br/>&#13;
$ <span class="codestrong1">./shiftadd</span><br/>&#13;
shiftAdd produces: 100<br/>&#13;
shiftAddOpt produces: 55<br/>&#13;
</pre>&#13;
<p class="indent">Retracing through the <code>shiftAdd</code> functions with the assumption that <code>a</code> and <code>b</code> are pointing to the same memory location reveals the issue. The multiplication of <code>a</code> by 10 in <code>shiftAdd</code> updates <code>x</code> to 50. Next, adding <code>a</code> to <code>b</code> in <code>shiftAdd</code> results in <code>x</code> doubling to 100. The risk of memory aliasing reveals that <code>shiftAdd</code> and <code>shiftAddOpt</code> are not in fact equivalent, though the programmer may have intended them to be. To fix this issue, recognize that the second parameter of <code>shiftAdd</code> does not need to be passed in as a pointer. Replacing the second parameter with an integer eliminates the risk of aliasing and allows the compiler to optimize one function into the other:</p>&#13;
<p class="margnote">Unoptimized version (fixed)</p>&#13;
<pre>void shiftAdd(int *a, int b){<br/>&#13;
    *a = *a * 10; //multiply by 10<br/>&#13;
    *a += b; //add b<br/>&#13;
}&#13;
</pre>&#13;
<p class="margnote">Optimized version (fixed)</p>&#13;
<pre>void shiftAddOpt(int *a, int b){<br/>&#13;
    *a = (*a * 10) + b;<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent">Removing the unneeded memory reference allows the programmer to maintain the readability of the original <code>shiftAdd</code> function while enabling the compiler to optimize the function.</p>&#13;
<h4 class="h4" id="lev2_204">Partnering with Your Compiler: A Sample Program</h4>&#13;
<p class="noindent">In the following sections, we concentrate on learning more about popular types of optimizations and discuss programming and profiling strategies to help make it easier for compilers to optimize our code. To illustrate our discussion, we will work to optimize the following (suboptimally written) program that attempts to find all the prime numbers between 2 and <em>n</em>:<sup><a href="ch12.xhtml#fn12_5" id="rfn12_5">5</a></sup></p>&#13;
<p class="margnote">optExample.c</p>&#13;
<pre>//helper function: checks to see if a number is prime<br/>&#13;
int isPrime(int x) {<br/>&#13;
    int i;<br/>&#13;
    for (i = 2; i &lt; sqrt(x) + 1; i++) { //no prime number is less than 2<br/>&#13;
        if (x % i == 0) { //if the number is divisible by i<br/>&#13;
            return 0; //it is not prime<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
    return 1; //otherwise it is prime<br/>&#13;
}<br/>&#13;
<br/>&#13;
// finds the next prime<br/>&#13;
int getNextPrime(int prev) {<br/>&#13;
    int next = prev + 1;<br/>&#13;
    while (!isPrime(next)) { //while the number is not prime<br/>&#13;
        next++; //increment and check again<br/>&#13;
    }<br/>&#13;
    return next;<br/>&#13;
}<br/>&#13;
<br/>&#13;
// generates a sequence of primes<br/>&#13;
int genPrimeSequence(int *array, int limit) {<br/>&#13;
    int i;<br/>&#13;
    int len = limit;<br/>&#13;
    if (len == 0) return 0;<br/>&#13;
    array[0] = 2; //initialize the first number to 2<br/>&#13;
    for (i = 1; i &lt; len; i++) {<br/>&#13;
        array[i] = getNextPrime(array[i-1]); //fill in the array<br/>&#13;
        if (array[i] &gt; limit) {<br/>&#13;
            len = i;<br/>&#13;
            return len;<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
    return len;<br/>&#13;
}<br/>&#13;
<br/>&#13;
int main(int argc, char **argv) {<br/>&#13;
<br/>&#13;
  //error-handling and timing code omitted for brevity<br/>&#13;
  <br/>&#13;
  int *array = allocateArray(limit);<br/>&#13;
  int length = genPrimeSequence(array, limit);<br/>&#13;
<br/>&#13;
  return 0;<br/>&#13;
}</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_596"/><a href="ch12.xhtml#ch12tab1">Table 12-1</a> shows the timing results for producing the primes between 2 and 5,000,000 with the different optimization level flags using the following basic compilation command:</p>&#13;
<pre>$ <span class="codestrong1">gcc -o optExample optExample.c -lm</span></pre>&#13;
<p class="tabcap" id="ch12tab1"><span epub:type="pagebreak" id="page_597"/><strong>Table 12-1:</strong> Time in Seconds to Produce Prime Numbers Between 2 and 5,000,000</p>&#13;
<table class="line">&#13;
<colgroup>&#13;
<col style="width:40%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
</colgroup>&#13;
<tr class="borderb">&#13;
<td style="vertical-align: top"><p class="tab"><strong>Unoptimized</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">-O1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">-O2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">-O3</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab-c">3.86</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.32</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.14</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.15</p></td>&#13;
</tr>&#13;
</table>&#13;
<p class="indent">The fastest observed time with optimization flags is approximately 2.14 seconds. Although using optimization flags does shave off more than a second from the runtime of this program, upping the optimization flags provides minimal improvement. In the next sections, we will discuss how we can modify our program to make it easier for the compiler to optimize.</p>&#13;
<h3 class="h3" id="lev1_94">12.1 Code Optimization First Steps: Code Profiling</h3>&#13;
<p class="right"><em>The real problem is that programmers have spent far too much time worrying about efficiency in the wrong places and at the wrong times; premature optimization is the root of all evil (or at least most of it) in programming.</em></p>&#13;
<p class="right">—Don Knuth, <em>The Art of Computer Programming</em></p>&#13;
<p class="indenta">One of the biggest dangers in code optimization is the concept of <em>premature optimization</em>. Premature optimization occurs when a programmer attempts to optimize based on “gut feelings” of where performance inefficiencies occur, and not on data. Whenever possible, it is important to measure the runtime of different portions of code on different inputs <em>prior</em> to starting optimization to identify <em>hot spots</em> or areas in the program in which the most instructions occur.</p>&#13;
<p class="indent">To figure out how to optimize <code>optExample.c</code>, let’s start by taking a closer look at the <code>main</code> function:</p>&#13;
<pre>int main(int argc, char **argv) {<br/>&#13;
<br/>&#13;
    //error-handling and timing code omitted for brevity<br/>&#13;
<br/>&#13;
    int limit = strtol(argv[1], NULL, 10);<br/>&#13;
    int length = limit;<br/>&#13;
    int *array = allocateArray(length); //allocates array of specified length<br/>&#13;
<br/>&#13;
    genPrimeSequence(array, limit, &amp;length); //generates sequence of primes<br/>&#13;
<br/>&#13;
    return 0;<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent">The <code>main</code> function contains calls to two functions: <code>allocateArray</code>, which initializes an array of a user-specified length (or limit), and <code>genPrimeSequence</code>, which generates a sequence of primes within the specified limit (note that for any sequence between 2 and <em>n</em>, there cannot be more than <em>n</em> primes, and frequently there are significantly less). The <code>main</code> function contains code that <span epub:type="pagebreak" id="page_598"/>times each of the two functions in the preceding example. Compiling and running the code with <code>limit</code> set to 5,000,000 reveals the following:</p>&#13;
<pre>$ <span class="codestrong1">gcc -o optExample optExample.c -lm</span><br/>&#13;
$ <span class="codestrong1">time -p ./optExample 5000000</span><br/>&#13;
Time to allocate: 5.5e-05<br/>&#13;
Time to generate primes: 3.85525<br/>&#13;
348513 primes found.<br/>&#13;
real 3.85<br/>&#13;
user 3.86<br/>&#13;
sys 0.00</pre>&#13;
<p class="indent">The <code>optExample</code> program takes approximately 3.86 seconds to complete, with nearly all of the time in the <code>genPrimeSequence</code> function. There is no point in spending time optimizing <code>allocateArray</code>, because any improvements will be negligible to the runtime of the overall program. In the examples that follow, we focus more closely on the <code>genPrimeSequence</code> function and its associated functions. The functions are reproduced here for convenience:</p>&#13;
<pre>// helper function: checks to see if a number is prime<br/>&#13;
int isPrime(int x) {<br/>&#13;
    int i;<br/>&#13;
    for (i = 2; i &lt; sqrt(x) + 1; i++) { //no prime number is less than 2<br/>&#13;
        if (x % i == 0) { //if the number is divisible by i<br/>&#13;
            return 0; //it is not prime<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
    return 1; //otherwise it is prime<br/>&#13;
}<br/>&#13;
<br/>&#13;
// finds the next prime<br/>&#13;
int getNextPrime(int prev) {<br/>&#13;
    int next = prev + 1;<br/>&#13;
    while (!isPrime(next)) { //while the number is not prime<br/>&#13;
        next++; //increment and check again<br/>&#13;
    }<br/>&#13;
    return next;<br/>&#13;
}<br/>&#13;
<br/>&#13;
// generates a sequence of primes<br/>&#13;
int genPrimeSequence(int *array, int limit) {<br/>&#13;
    int i;<br/>&#13;
    int len = limit;<br/>&#13;
    if (len == 0) return 0;<br/>&#13;
    array[0] = 2; //initialize the first number to 2<br/>&#13;
    for (i = 1; i &lt; len; i++) {<br/>&#13;
        array[i] = getNextPrime(array[i-1]); //fill in the array<br/>&#13;
        if (array[i] &gt; limit) {<br/>&#13;
            len = i;<br/>&#13;
            return len;<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
    return len;<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_599"/>To find hot spots in a program, focus on the areas with the most loops. Manual inspection of code can assist in locating hot spots, though it should always be verified with benchmarking tools prior to attempting optimization. A manual inspection of the <code>optExample</code> program yields the following observations.</p>&#13;
<p class="indent">The <code>genPrimeSequence</code> function attempts to generate all the prime numbers between 2 and some integer <em>n</em>. Since the number of primes between 2 and <em>n</em> cannot exceed <em>n</em>, the <code>for</code> loop in <code>genPrimeSequence</code> runs no more than <em>n</em> times. Every iteration of the <code>for</code> loop calls the <code>getNextPrime</code> function once. Thus, <code>getNextPrime</code> runs no more than <em>n</em> times.</p>&#13;
<p class="indent">The <code>while</code> loop in the <code>getNextPrime</code> function will continue running until a prime is discovered. Although it is difficult to determine the number of times the <code>while</code> loop in the <code>getNextPrime</code> function will execute ahead of time as a function of <em>n</em> (the gap between consecutive prime numbers can be arbitrarily large), it is certain that <code>isPrime</code> executes on every iteration of the <code>while</code> loop.</p>&#13;
<p class="indent">The <code>isPrime</code> function contains exactly one <code>for</code> loop. Suppose that the loop runs for a total of <em>k</em> iterations. Then, the code in the loop body runs <em>k</em> times in total. Recall from “Loops in C” on <a href="ch01.xhtml#lev2_7">page 33</a> that the structure of a <code>for</code> loop consists of an <em>initialization statement</em> (which initializes the loop variable to a particular value), a <em>Boolean expression</em> (that determines when to terminate the loop), and a <em>step expression</em> (that updates the loop variable every iteration). <a href="ch12.xhtml#ch12tab2">Table 12-2</a> depicts the number of times each loop component executes in a <code>for</code> loop that runs for <em>k</em> iterations. In every <code>for</code> loop, initialization happens exactly once. The Boolean expression executes <em>k</em> + 1 times for <em>k</em> iterations, since it must perform one final check to terminate the loop. The loop body and the step expression execute <em>k</em> times each.</p>&#13;
<p class="tabcap" id="ch12tab2"><strong>Table 12-2:</strong> Loop Execution Components (Assuming k Iterations)</p>&#13;
<table class="line">&#13;
<colgroup>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
</colgroup>&#13;
<tr class="borderb">&#13;
<td style="vertical-align: top"><p class="tab"><strong>Initialization statement</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>Boolean expression</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>Step expression</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>Loop body</strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><em>k</em> + 1</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><em>k</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><em>k</em></p></td>&#13;
</tr>&#13;
</table>&#13;
<p class="indent">Our manual inspection of the code suggests that the program spends most of its time in the <code>isPrime</code> function, and that the <code>sqrt</code> function executes the most often. Let’s next use code profiling to verify this hypothesis.</p>&#13;
<h4 class="h4" id="lev2_205"><span epub:type="pagebreak" id="page_600"/>12.1.1 Using Callgrind to Profile</h4>&#13;
<p class="noindent">In our small program, it was relatively straightforward to use manual inspection to form the hypothesis that the <code>sqrt</code> function occurs in a “hot spot” in the code. However, identifying hot spots can become more complex in larger programs. Regardless, it is a good idea to use profiling to verify our hypothesis. Code profiling tools like Valgrind<sup><a href="ch12.xhtml#fn12_6" id="rfn12_6">6</a></sup> provide a lot of information about program execution. In this section, we use the <code>callgrind</code> tool to inspect the <code>OptExample</code> program’s call graph.</p>&#13;
<p class="indent">To use <code>callgrind</code>, let’s start by recompiling the <code>optExample</code> program with the <code>-g</code> flag and running <code>callgrind</code> on a smaller range (2 to 100,000). Like other Valgrind applications, <code>callgrind</code> runs as a wrapper around a program, adding annotations such as the number of times functions execute and the total number of instructions that are executed as a result. Consequently, the <code>optExample</code> program will take longer to execute when run in conjunction with <code>callgrind</code>.</p>&#13;
<pre>$ <span class="codestrong1">gcc -g -o optExample optExample.c -lm</span><br/>&#13;
$ <span class="codestrong1">valgrind --tool=callgrind ./optExample 100000</span><br/>&#13;
==32590== Callgrind, a call-graph generating cache profiler<br/>&#13;
==32590== Copyright (C) 2002-2015, and GNU GPL'd, by Josef Weidendorfer et al.<br/>&#13;
==32590== Using Valgrind-3.11.0 and LibVEX; rerun with -h for copyright info<br/>&#13;
==32590== Command: ./optExample 100000<br/>&#13;
==32590==<br/>&#13;
==32590== For interactive control, run 'callgrind_control -h'.<br/>&#13;
Time to allocate: 0.003869<br/>&#13;
Time to generate primes: 0.644743<br/>&#13;
9592 primes found.<br/>&#13;
==32590==<br/>&#13;
==32590== Events    : Ir<br/>&#13;
==32590== Collected : 68338759<br/>&#13;
==32590==<br/>&#13;
==32590== I   refs:      68,338,759<br/>&#13;
</pre>&#13;
<p class="indent">Typing <code>ls</code> at the terminal reveals a new file called <code>callgrind.out.xxxxx</code>, where <code>xxxxx</code> is a unique id. In this case, the file is <code>callgrind.out.32590</code> (i.e., the number shown along the left-hand column in the preceding output). Running <code>callgrind_annotate</code> on this file yields additional information on the three functions of interest:</p>&#13;
<pre>$ <span class="codestrong1">callgrind_annotate --auto=yes callgrind.out.32590</span><br/>&#13;
 ----------------------------------------------------------------<br/>&#13;
Profile data file 'callgrind.out.32393' (creator: callgrind-3.11.0)<br/>&#13;
 ----------------------------------------------------------------<br/>&#13;
...<br/>&#13;
  .  //helper function: checks to see if a number is prime<br/>&#13;
   400,004  int isPrime(int x) {<br/>&#13;
         .      int i;<br/>&#13;
36,047,657      for (i = 2; i &lt; sqrt(x)+1; i++) { //no prime is less than 2<br/>&#13;
13,826,015  =&gt; ???:sqrt (2765204x)<br/>&#13;
16,533,672          if (x % i == 0) { //if the number is divisible by i<br/>&#13;
   180,818              return 0; //it is not prime<br/>&#13;
         .          }<br/>&#13;
         .      }<br/>&#13;
     9,592      return 1; //otherwise it is prime<br/>&#13;
   200,002  }<br/>&#13;
         .<br/>&#13;
         .  // finds the next prime<br/>&#13;
    38,368  int getNextPrime(int prev) {<br/>&#13;
    28,776      int next = prev + 1;<br/>&#13;
   509,597      while (!isPrime(next)) { //while the number is not prime<br/>&#13;
67,198,556  =&gt; optExample.c:isPrime (100001x)<br/>&#13;
    90,409          next++; //increment and check again<br/>&#13;
         .      }<br/>&#13;
     9,592      return next;<br/>&#13;
    19,184  }<br/>&#13;
         .<br/>&#13;
         .  // generates a sequence of primes<br/>&#13;
         6  int genPrimeSequence(int * array, int limit) {<br/>&#13;
         .      int i;<br/>&#13;
         2      int len = limit;<br/>&#13;
         2      if (len == 0) return 0;<br/>&#13;
         2      array[0]=2; //initialize the first number to 2<br/>&#13;
    38,369      for (i = 1; i &lt; len; i++) {<br/>&#13;
   143,880          array[i] = getNextPrime(array[i-1]); //fill in the array<br/>&#13;
67,894,482  =&gt; optExample.c:getNextPrime (9592x)<br/>&#13;
    76,736          if (array[i] &gt; limit){<br/>&#13;
         2              len = i;<br/>&#13;
         2              return len;<br/>&#13;
         .          }<br/>&#13;
         .      }<br/>&#13;
         .      return len;<br/>&#13;
         4  }&#13;
</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_601"/>The numbers along the left-hand column represent the number of total executed instructions associated with each line. The numbers in parentheses indicate the number of times a particular function was run. Using the numbers along the left-hand column, we are able to verify the results of our manual inspection. In the <code>genPrimeSequence</code> function, the <code>getNextPrime</code> function resulted in the most number of executed instructions at 67.8 million instructions, corresponding to 9,592 function calls (to generate the primes between 2 and 100,000). Inspecting <code>getNextPrime</code> reveals that the majority of those instructions (67.1 million, or 99%) result from the call to <code>isPrime</code>, which is called a total of 100,001 times. Lastly, inspecting <code>isPrime</code> reveals that 13 million of the total instructions (20.5%) result from the <code>sqrt</code> function, which executes a total of 2.7 million times.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_602"/>These results verify our original hypothesis that the program spends most of its time in the <code>isPrime</code> function, with the <code>sqrt</code> function executing the most frequently of all the functions. Reducing the total number of executed instructions results in a faster program; the above analysis suggests that our initial efforts should concentrate on improving the <code>isPrime</code> function, and potentially reducing the number of times <code>sqrt</code> executes.</p>&#13;
<h4 class="h4" id="lev2_206">12.1.2 Loop-Invariant Code Motion</h4>&#13;
<p class="noindent">Loop-invariant code motion is an optimization technique that moves static computations that occur inside a loop to outside the loop without affecting the loop’s behavior. Optimizing compilers are capable of making most loop-invariant code optimizations automatically. Specifically, the <code>-fmove-loop -invariants</code> compiler flag in GCC (enabled at level <code>-O1</code>) attempts to identify examples of loop-invariant code motion and move them outside their respective loops.</p>&#13;
<p class="indent">However, the compiler cannot always identify cases of loop-invariant code motion, especially in the case of function calls. Since function calls can inadvertently cause <em>side effects</em> (unintended behavior), most compilers will avoid trying to determine whether a function call consistently returns the same result. Thus, even though the programmer knows that <code>sqrt(x)</code> always returns the square root of some input <code>x</code>, GCC will not always make that assumption. Consider the case where the <code>sqrt</code> function updates a secret global variable, <code>g</code>. In that case, calling <code>sqrt</code> once outside of the function (<em>one</em> update to <code>g</code>) is not the same as calling it every iteration of the loop (<em>n</em> updates to <code>g</code>). If a compiler cannot determine that a function always returns the same result, it will not automatically move the <code>sqrt</code> function outside the loop.</p>&#13;
<p class="indent">However, the programmer knows that moving the computation <code>sqrt(x) + 1</code> outside the <code>for</code> loop does not effect the loop’s behavior. The updated function is shown here and is available online:<sup><a href="ch12.xhtml#fn12_7" id="rfn12_7">7</a></sup></p>&#13;
<pre>//helper function: checks to see if a number is prime<br/>&#13;
int isPrime(int x) {<br/>&#13;
    int i;<br/>&#13;
    int max = sqrt(x)+1;<br/>&#13;
    for (i = 2; i &lt; max; i++) { //no prime number is less than 2<br/>&#13;
        if (x % i == 0) { //if the number is divisible by i<br/>&#13;
            return 0; //it is not prime<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
    return 1; //otherwise it is prime<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent"><a href="ch12.xhtml#ch12tab3">Table 12-3</a> shows that this simple change shaves off a full two seconds (47%) of the runtime of <code>optExample2</code>, even before using compiler flags. Furthermore, the compiler seems to have a slightly easier time optimizing <code>optExample2</code>.</p>&#13;
<p class="tabcap" id="ch12tab3"><span epub:type="pagebreak" id="page_603"/><strong>Table 12-3:</strong> Time in Seconds to Produce the Prime Numbers Between 2 and 5,000,000</p>&#13;
<table class="line">&#13;
<colgroup>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
</colgroup>&#13;
<tr class="borderb">&#13;
<td style="vertical-align: top"><p class="tab"><strong>Version</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c"><strong>Unoptimized</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">-O1</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">-O2</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">-O3</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">Original</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">3.86</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">2.32</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">2.14</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">2.15</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">With loop-invariant code motion</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.83</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.63</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.71</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.63</p></td>&#13;
</tr>&#13;
</table>&#13;
<p class="indent">Rerunning <code>callgrind</code> on the <code>optExample2</code> executable reveals why such a large improvement in runtime was observed. The following code snippet assumes that the file <code>callgrind.out.30086</code> contains the annotations of running <code>callgrind</code> on the <code>optExample2</code> executable:</p>&#13;
<pre>$ <span class="codestrong1">gcc -g -o optExample2 optExample2.c -lm</span><br/>&#13;
$ <span class="codestrong1">valgrind --tool=callgrind ./optExample2 100000</span><br/>&#13;
$ <span class="codestrong1">callgrind_annotate --auto=yes callgrind.out.30086</span><br/>&#13;
 ------------------------------------------------------------------<br/>&#13;
Profile data file 'callgrind.out.30086' (creator: callgrind-3.11.0)<br/>&#13;
 ------------------------------------------------------------------<br/>&#13;
 ...<br/>&#13;
   400,004  int isPrime(int x) {<br/>&#13;
         .      int i;<br/>&#13;
   900,013      int max = sqrt(x)+1;<br/>&#13;
   500,000  =&gt; ???:sqrt (100001x)<br/>&#13;
11,122,449      for (i = 2; i &lt; max; i++) { //no prime number is less than 2<br/>&#13;
16,476,120          if (x % i == 0) { //if the number is divisible by i<br/>&#13;
   180,818              return 0; //it is not prime<br/>&#13;
         .          }<br/>&#13;
         .      }<br/>&#13;
     9,592      return 1; //otherwise it is prime<br/>&#13;
   200,002  }<br/>&#13;
         .<br/>&#13;
         .  // finds the next prime<br/>&#13;
    38,368  int getNextPrime(int prev) {<br/>&#13;
    28,776      int next = prev + 1;<br/>&#13;
   509,597      while (!isPrime(next)) { //while the number is not prime<br/>&#13;
29,789,794  =&gt; optExample2.c:isPrime (100001x)<br/>&#13;
    90,409          next++; //increment and check again<br/>&#13;
         .      }<br/>&#13;
     9,592      return next;<br/>&#13;
    19,184  }&#13;
</pre>&#13;
<p class="indent">Moving the call to <code>sqrt</code> outside of the <code>for</code> loop reduces the number of times the <code>sqrt</code> function is called in the program from 2.7 million to 100,000 (96% reduction). This number corresponds to the number of times the <code>isPrime</code> function is called, confirming that the <code>sqrt</code> function executes only once with every invocation of the <code>isPrime</code> function.</p>&#13;
<p class="indent">Note that the compiler was able to perform significant levels of optimization when optimization flags were specified, even if the programmer <span epub:type="pagebreak" id="page_604"/>does not manually perform code motion. In this case, the reason is due to a special instruction called <code>fsqrt</code> that is specified by the x86 ISA. When optimization flags are turned on, the compiler replaces all instances of the <code>sqrt</code> function with the <code>fsqrt</code> instruction. This process is known as <em>inlining</em>, and we cover it greater detail in the following section. Since <code>fsqrt</code> is no longer a function, it is easier for the compiler to identify its loop-invariant nature and move it outside the body of the loop.</p>&#13;
<h3 class="h3" id="lev1_95">12.2 Other Compiler Optimizations: Loop Unrolling and Function Inlining</h3>&#13;
<p class="noindent">The loop-invariant code motion optimization described in the previous section was a simple change that resulted in a massive reduction in execution time. However, such optimizations are situationally dependent, and may not always result in improvements to performance. In most cases, loop-invariant code motion is taken care of by the compiler.</p>&#13;
<p class="indent">Code today is more often read than it is written. In most cases, fractional performance gains are not worth the hit to code readability. In general, a programmer should let the compiler optimize whenever possible. In this section, we cover some optimization techniques that were previously manually implemented by programmers but are today commonly implemented by compilers.</p>&#13;
<p class="indent">There are several sources online that advocate for the manual implementation of the techniques we describe in the following sections. However, we encourage readers to check whether their compilers support the following optimizations before attempting to manually implement them in their code. All the optimizations described in this section are implemented in GCC, but may not be available in older compilers.</p>&#13;
<h4 class="h4" id="lev2_207">12.2.1 Function Inlining</h4>&#13;
<p class="noindent">One optimization step that compilers attempt to perform is <em>function inlining</em>, which replaces calls to a function with the body of the function. For example, in the <code>main</code> function, a compiler inlining the <code>allocateArray</code> function will replace the call to <code>allocateArray</code> with a direct call to <code>malloc</code>:</p>&#13;
<p class="margnote">Original version</p>&#13;
<pre>int main(int argc, char **argv) {<br/>&#13;
    // omitted for brevity<br/>&#13;
    // some variables shortened for space considerations<br/>&#13;
    int lim = strtol(argv[1], NULL, 10);<br/>&#13;
<br/>&#13;
    // allocation of array<br/>&#13;
    int *a = allocateArray(lim);<br/>&#13;
<br/>&#13;
    // generates sequence of primes<br/>&#13;
    int len = genPrimeSequence(a, lim);<br/>&#13;
    return 0;<br/>&#13;
}&#13;
</pre>&#13;
<p class="margnote">allocateArray inlined</p>&#13;
<pre>int main(int argc, char **argv) {<br/>&#13;
    // omitted for brevity<br/>&#13;
    // some variables shortened for space considerations<br/>&#13;
    int lim = strtol(argv[1], NULL, 10);<br/>&#13;
<br/>&#13;
    // allocation of array (in-lined)<br/>&#13;
    int *a = malloc(lim * sizeof(int));<br/>&#13;
<br/>&#13;
    // generates sequence of primes<br/>&#13;
    int len = genPrimeSequence(a, lim);<br/>&#13;
<br/>&#13;
    return 0;<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_605"/>Inlining functions can result in some runtime savings for a program. Recall that every time a program calls a function, many instructions associated with function creation and destruction are necessarily generated. Inlining functions enables the compiler to eliminate these excessive calls, and makes it easier for the compiler to identify other potential improvements, including constant propagation, constant folding, and dead code elimination. In the case of the <code>optExample</code> program, inlining likely allows the compiler to replace the call to <code>sqrt</code> with the <code>fsqrt</code> instruction and subsequently move it outside the loop.</p>&#13;
<p class="indent">The <code>-finline-functions</code> flag suggests to GCC that functions should be inlined. This optimization is turned on at level 3. Even though <code>-finline-functions</code> can be used independently of the <code>-O3</code> flag, it is a <em>suggestion</em> to the compiler to look for functions to inline. Likewise, the <code>static inline</code> keyword can be used to suggest to the compiler that a particular function should be inlined. Keep in mind that the compiler will not inline all functions, and that function inlining is not guaranteed to make code faster.</p>&#13;
<p class="indent">Programmers should generally avoid inlining functions manually. Inlining functions carries a high risk of significantly reducing the readability of code, increasing the likelihood of errors, and making it harder to update and maintain functions. For example, trying to inline the <code>isPrime</code> function in the <code>getNextPrime</code> function will greatly reduce the readability of <code>getNextPrime</code>.</p>&#13;
<h4 class="h4" id="lev2_208">12.2.2 Loop Unrolling</h4>&#13;
<p class="noindent">The last compiler optimization strategy we discuss in this section is loop unrolling. Let’s revisit the <code>isPrime</code> function:</p>&#13;
<pre>// helper function: checks to see if a number is prime<br/>&#13;
int isPrime(int x) {<br/>&#13;
    int i;<br/>&#13;
    int max = sqrt(x) + 1;<br/>&#13;
<br/>&#13;
    // no prime number is less than 2<br/>&#13;
    for (i = 2; i &lt; max; i++) {<br/>&#13;
        // if the number is divisible by i<br/>&#13;
        if (x % i == 0) {<br/>&#13;
            return 0; // it's not prime<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
    return 1; // otherwise it is<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_606"/>The <code>for</code> loop executes a total of <code>max</code> times, where <code>max</code> is one more than the square root of integer <code>x</code>. At the assembly level, every execution of the loop checks to see whether <code>i</code> is less than <code>max</code>. If so, the instruction pointer jumps to the body of the loop, which computes the modulo operation. If the modulo operation results in 0, the program immediately exits the loop and returns 0. Otherwise, the loop continues execution. While branch predictors are fairly good at predicting what a conditional expression evaluates to (especially inside loops), wrong guesses can result in a hit to performance, due to disruptions in the instruction pipeline.</p>&#13;
<p class="indent"><em>Loop unrolling</em> is an optimization that compilers perform to reduce the impact of wrong guesses. In loop unrolling, the goal is to reduce the number of iterations of a loop by a factor of <em>n</em> by increasing the workload that each iteration performs by a factor of <em>n</em>. When a loop is unrolled by a factor of 2, the number of iterations in the loop is cut by <em>half</em> , whereas the amount work performed per iteration is <em>doubled</em>.</p>&#13;
<p class="indent">Let’s manually apply 2-factor loop unrolling to our <code>isPrime</code> function:<sup><a href="ch12.xhtml#fn12_8" id="rfn12_8">8</a></sup></p>&#13;
<pre>// helper function: checks to see if a number is prime<br/>&#13;
int isPrime(int x) {<br/>&#13;
    int i;<br/>&#13;
    int max = sqrt(x)+1;<br/>&#13;
<br/>&#13;
    // no prime number is less than 2<br/>&#13;
    for (i = 2; i &lt; max; i+=2) {<br/>&#13;
        // if the number is divisible by i or i+1<br/>&#13;
        if ( (x % i == 0) || (x % (i+1) == 0) ) {<br/>&#13;
            return 0; // it's not prime<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
    return 1; // otherwise it is<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent">Notice that even though we have halved the number of iterations that the <code>for</code> loop takes, each iteration of the loop now performs two modulo checks, doubling the amount of work per iteration. Recompiling and rerunning the program results in marginally improved times (see <a href="ch12.xhtml#ch12tab4">Table 12-4</a>).</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_607"/>The readability of the code is also reduced. A better way to utilize loop unrolling is to invoke the <code>-funroll-loops</code> compiler optimization flag, which tells the compiler to unroll loops whose iterations can be determined at compile time. The <code>-funroll-all-loops</code> compiler flag is a more aggressive option that unrolls all loops regardless of whether the compiler is certain of the number of iterations. <a href="ch12.xhtml#ch12tab4">Table 12-4</a> shows the runtimes of the manual 2-factor loop unrolling<sup><a href="ch12.xhtml#fn12_9" id="rfn12_9">9</a></sup> compared to adding the <code>-funroll-loops</code> and <code>-funroll -all-loops</code> compiler optimization flags to the previous program.<sup>7</sup></p>&#13;
<p class="tabcap" id="ch12tab4"><strong>Table 12-4:</strong> Time in Seconds to Produce 5,000,000 Prime Numbers</p>&#13;
<table class="line">&#13;
<colgroup>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
</colgroup>&#13;
<tr class="borderb">&#13;
<td style="vertical-align: top"><p class="tab"><strong>Version</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>File</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c"><strong>Unoptimized</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">-O1</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">-O2</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">-O3</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">Original</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><code>optExample.c</code></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">3.86</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">2.32</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">2.14</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">2.15</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">Loop-invariant code motion</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><code>optExample2.c</code></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.83</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.63</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.71</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.63</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">Manual factor-of-two loop</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><code>optExample3.c</code></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.65</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.53</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.45</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.45</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">unrolling</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><code>-funroll-loops</code></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><code>optExample2.c</code></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.82</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.48</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.46</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.46</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><code>-funroll-all-loops</code></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><code>optExample2.c</code></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.81</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.47</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.47</p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">1.46</p></td>&#13;
</tr>&#13;
</table>&#13;
<p class="indent">Manual loop unrolling does result in some performance improvement; however the compiler’s built-in loop unrolling flags when combined with the other optimization flags yield comparable performance. If a programmer wants to incorporate loop unrolling optimizations into their code, they should default to using the appropriate compiler flags, and <em>not</em> manually unroll loops themselves.</p>&#13;
<h3 class="h3" id="lev1_96">12.3 Memory Considerations</h3>&#13;
<p class="noindent">Programmers should pay special attention to memory use, especially when employing memory-intensive data structures such as matrices and arrays. Although compilers offer powerful optimization features, the compiler cannot always make optimizations that improve a program’s memory use. In this section, we use an implementation of a matrix-vector program <code>matrixVector.c</code><sup><a href="ch12.xhtml#fn12_10" id="rfn12_10">10</a></sup> to guide discussion of techniques and tools for improving memory use.</p>&#13;
<p class="indent">The <code>main</code> function of the program performs two steps. First, it allocates and initializes the input matrix, the input vector, and the output matrix. Next, it performs matrix-vector multiplication. Running the code on matrix-vector dimensions of 10,000 × 10,000 reveals that the <code>matrixVectorMultiply</code> function takes up the majority of the time:</p>&#13;
<pre>$ <span class="codestrong1">gcc -o matrixVector matrixVector.c</span><br/>&#13;
$ <span class="codestrong1">./matrixVector 10000 10000</span><br/>&#13;
Time to allocate and fill matrices: 1.2827<br/>&#13;
Time to allocate vector: 9.6e-05<br/>&#13;
Time to matrix-vector multiply: 1.98402</pre>&#13;
<p class="indent">Our discussion will thus focus on the <code>matrixVectorMultiply</code> function.</p>&#13;
<h4 class="h4" id="lev2_209"><span epub:type="pagebreak" id="page_608"/>12.3.1 Loop Interchange</h4>&#13;
<p class="noindent">Loop interchange optimizations switch the order of inner and outer loops in nested loops in order to maximize cache locality. Automatically performing this task is difficult for compilers to do. In GCC, the <code>-floop-interchange</code> compiler flag exists but is currently not available by default. Therefore, it is a good idea for programmers to pay attention to how their code is accessing memory-composite data structures like arrays and matrices. As an example, let’s take a closer look at the <code>matrixVectorMultiply</code> function in <code>matrixVector.c</code>:</p>&#13;
<p class="margnote">Original version</p>&#13;
<pre>void matrixVectorMultiply(int **m,<br/>&#13;
                          int *v,<br/>&#13;
                          int **res,<br/>&#13;
                          int row,<br/>&#13;
                          int col) {<br/>&#13;
    int i, j;<br/>&#13;
    //cycles through every matrix column<br/>&#13;
    //in inner-most loop (inefficient)<br/>&#13;
    for (j = 0; j &lt; col; j++){<br/>&#13;
        for (i = 0; i &lt; row; i++){<br/>&#13;
            res[i][j] = m[i][j] * v[j];<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
}&#13;
</pre>&#13;
<p class="margnote">Loop interchange version</p>&#13;
<pre>void matrixVectorMultiply(int **m,<br/>&#13;
                          int *v,<br/>&#13;
                          int **res,<br/>&#13;
                          int row,<br/>&#13;
                          int col) {<br/>&#13;
    int i, j;<br/>&#13;
    //cycles through every row of matrix<br/>&#13;
    //in inner-most loop<br/>&#13;
    for (i = 0; i &lt; row; i++){<br/>&#13;
        for (j = 0; j &lt; col; j++){<br/>&#13;
            res[i][j] = m[i][j] * v[j];<br/>&#13;
        }<br/>&#13;
    }<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent">The input and output matrices are dynamically allocated (see “Method 2: The Programmer-Friendly Way” on <a href="ch02.xhtml#lev3_17">page 90</a>). As a result, the rows in the matrices are not contiguous to one another, whereas the elements in each row are contiguous. The current ordering of the loops causes the program to cycle through each column instead of every row. Recall that data is loaded into cache in blocks, not elements (see “Direct-Mapped Caches” on <a href="ch11.xhtml#lev2_193">page 558</a>). As a result, when an element <em>x</em> in an array in either <code>res</code> or <code>m</code> is accessed, the <em>elements adjacent to</em> <span class="codeitalic">x</span> are also loaded into cache. Cycling through every “column” <span epub:type="pagebreak" id="page_609"/>of the matrix causes more cache misses, as the cache is forced to load new blocks with every access. <a href="ch12.xhtml#ch12tab5">Table 12-5</a> shows that adding optimization flags does not decrease the runtime of the function. However, simply switching the order of the loops (as shown in the previous code examples) makes the function nearly eight times faster and allows the compiler to perform additional optimizations.</p>&#13;
<p class="tabcap" id="ch12tab5"><strong>Table 12-5:</strong> Time in Seconds to Perform Matrix Multiplication on 10,000 × 10,000 Elements</p>&#13;
<table class="line">&#13;
<colgroup>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
</colgroup>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><strong>Version</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>Program</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>Unoptimized</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">-O1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">-O2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">-O3</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">Original</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><code>matrixVector</code></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">2.01</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.05</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.07</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.08</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">Loop interchange</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><code>matrixVector2</code></p></td>&#13;
<td style="vertical-align: top"><p class="tab-c">0.27</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.08</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.06</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.06</p></td>&#13;
</tr>&#13;
</table>&#13;
<p class="indent">The Valgrind tool <code>cachegrind</code> (discussed in “Cache Analysis and Valgrind” on <a href="ch11.xhtml#lev1_90">page 575</a>) is a great way to identify data locality issues, and reveals the cache access differences in the two versions of the <code>matrixVectorMultiply</code> function shown in the previous example.</p>&#13;
<h4 class="h4" id="lev2_210">12.3.2 Some Other Compiler Optimizations for Improving Locality: Fission and Fusion</h4>&#13;
<p class="noindent">Rerunning the improved program on 10,000 × 10,000 elements yields the following runtime numbers:</p>&#13;
<pre>$ <span class="codestrong1">gcc -o matrixVector2 matrixVector2.c</span><br/>&#13;
$ <span class="codestrong1">./matrixVector2 10000 10000</span><br/>&#13;
Time to allocate and fill matrices: 1.29203<br/>&#13;
Time to allocate vector: 0.000107<br/>&#13;
Time to matrix-vector multiply: 0.271369</pre>&#13;
<p class="indent">Now, matrix allocation and filling takes the most time. Additional timing reveals that it is the filling of the matrices that in fact takes the most time. Let’s take a closer look at that code:</p>&#13;
<pre>//fill matrices<br/>&#13;
for (i = 0; i &lt; rows; i++){<br/>&#13;
    fillArrayRandom(matrix[i], cols);<br/>&#13;
    fillArrayZeros(result[i], cols);<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent">To fill the input and output matrices, a <code>for</code> loop cycles through all the rows, and calls the <code>fillArrayRandom</code> and <code>fillArrayZeros</code> functions on each matrix. In some scenarios, it may be advantageous for the compiler to split the single loop into two separate loops (known as <em>loop fission</em>), as shown here:</p>&#13;
<p class="margnote">Original version</p>&#13;
<pre>for (i = 0; i &lt; rows; i++) {<br/>&#13;
    fillArrayRandom(matrix[i], cols);<br/>&#13;
    fillArrayZeros(result[i], cols);<br/>&#13;
<span epub:type="pagebreak" id="page_610"/>&#13;
}&#13;
</pre>&#13;
<p class="margnote">With loop fission</p>&#13;
<pre>for (i = 0; i &lt; rows; i++) {<br/>&#13;
    fillArrayRandom(matrix[i], cols);<br/>&#13;
}<br/>&#13;
<br/>&#13;
for (i = 0; i &lt; rows; i++) {<br/>&#13;
    fillArrayZeros(result[i], cols);<br/>&#13;
}&#13;
</pre>&#13;
<p class="indent">The process of taking two loops that operate over the same range and combining their contents into a single loop (i.e., the opposite of loop fission) is called <em>loop fusion</em>. Loop fission and fusion are examples of optimizations a compiler might perform to try to improve data locality. Compilers for multicore processors may also use loop fission or fusion to enable loops to execute efficiently on multiple cores. For example, a compiler may use loop fission to assign two loops to different cores. Likewise, a compiler may use loop fusion to combine together dependent operations into the body of the loop and distribute to each core a subset of the loop iterations (assuming data between iterations are independent).</p>&#13;
<p class="indent">In our case, applying loop fission manually does not directly improve program performance; there is virtually no change in the amount of time required to fill the array. However, it may reveal a more subtle optimization: the loop containing <code>fillArrayZeros</code> is not necessary. The <code>matrixVectorMultiply</code> function assigns values to each element in the <code>result</code> array; a prior initialization to all zeros is unnecessary.</p>&#13;
<p class="margnote">Previous version matrixVector2.c</p>&#13;
<pre>for (i = 0; i &lt; rows; i++) {<br/>&#13;
    matrix[i] = allocateArray(cols);<br/>&#13;
    result[i] = allocateArray(cols);<br/>&#13;
}<br/>&#13;
<br/>&#13;
for (i = 0; i &lt; rows; i++) {<br/>&#13;
    fillArrayRandom(matrix[i], cols);<br/>&#13;
    fillArrayZeros(result[i], cols);<br/>&#13;
}&#13;
</pre>&#13;
<p class="margnote">Updated version matrixVector3.c</p>&#13;
<pre>for (i = 0; i &lt; rows; i++) {<br/>&#13;
    matrix[i] = allocateArray(cols);<br/>&#13;
    result[i] = allocateArray(cols);<br/>&#13;
}<br/>&#13;
<br/>&#13;
for (i = 0; i &lt; rows; i++) {<br/>&#13;
    fillArrayRandom(matrix[i], cols);<br/>&#13;
    //fillArrayZeros(result[i], cols); //no longer needed<br/>&#13;
}&#13;
</pre>&#13;
<h4 class="h4" id="lev2_211"><span epub:type="pagebreak" id="page_611"/>12.3.3 Memory Profiling with Massif</h4>&#13;
<p class="noindent">Making the previous change results in only a slight decrease in runtime. Although it eliminates the step of filling in all elements in the result matrix with zeros, a significant amount of time is still required to fill the input matrix with random numbers:</p>&#13;
<pre>$ <span class="codestrong1">gcc -o matrixVector3 matrixVector3.c</span><br/>&#13;
$ <span class="codestrong1">./matrixVector3 10000 10000</span><br/>&#13;
Time to allocate matrices: 0.049073<br/>&#13;
Time to fill matrices: 0.946801<br/>&#13;
Time to allocate vector: 9.3e-05<br/>&#13;
Time to matrix-vector multiply: 0.359525</pre>&#13;
<p class="indent">Even though each array is stored noncontiguously in memory, each one takes up 10,000 × <code>sizeof(int)</code> bytes, or 40,000 bytes. Since there is a total of 20,000 (10,000 each for the initial matrix and the result matrix) arrays allocated, this corresponds to 800 million bytes, or roughly 762 MB of space. Filling 762 MB with random numbers understandably takes a lot of time. With matrices, memory use increases quadratically with the input size, and can play a large role in performance.</p>&#13;
<p class="indent">Valgrind’s <code>massif</code> tool can help you profile memory use. Like the other Valgrind tools we covered in this book (see “Debugging Memory with Valgrind” on <a href="ch03.xhtml#lev1_22">page 168</a>, “Cache Analysis and Valgrind” on <a href="ch11.xhtml#lev1_90">page 575</a>, and “Using Callgrind to Profile” on <a href="ch12.xhtml#lev2_205">page 600</a>), <code>massif</code> runs as a wrapper around a program’s executable. Specifically, <code>massif</code> takes snapshots of program memory use throughout the program, and profiles how memory usage fluctuates. Programmers may find the <code>massif</code> tool useful for tracking how their programs use heap memory, and for identifying opportunities to improve memory use. Let’s run the <code>massif</code> tool on the <code>matrixVector3</code> executable:</p>&#13;
<pre>$ <span class="codestrong1">valgrind --tool=massif ./matrixVector3 10000 10000</span><br/>&#13;
==7030== Massif, a heap profiler<br/>&#13;
==7030== Copyright (C) 2003-2015, and GNU GPL'd, by Nicholas Nethercote<br/>&#13;
==7030== Using Valgrind-3.11.0 and LibVEX; rerun with -h for copyright info<br/>&#13;
==7030== Command: ./matrixVector3 10000 10000<br/>&#13;
==7030==<br/>&#13;
Time to allocate matrices: 0.049511<br/>&#13;
Time to fill matrices: 4.31627<br/>&#13;
Time to allocate vector: 0.001015<br/>&#13;
Time to matrix-vector multiply: 0.62672<br/>&#13;
==7030==</pre>&#13;
<p class="indent">Running <code>massif</code> produces a <code>massif.out.xxxx</code> file, where <code>xxxx</code> is a unique id number. If you are typing along, type <span class="codestrong">ls</span> to reveal your corresponding massif file. In the example that follows, the corresponding file is <code>massif.out.7030</code>. Use the <span class="codestrong">ms_print</span> command to view the <code>massif</code> output:</p>&#13;
<pre>$ <span class="codestrong1">ms_print massif.out.7030</span><br/>&#13;
-----------------------------------------------------------------------------<br/>&#13;
Command:            ./matrixVector3 10000 10000<br/>&#13;
Massif arguments:   (none)<br/>&#13;
ms_print arguments: massif.out.7030<br/>&#13;
-----------------------------------------------------------------------------<br/>&#13;
<br/>&#13;
    MB<br/>&#13;
763.3^                                                ::::::::::::::::::::::#<br/>&#13;
     |:::::::::::::::::::::::::::::::::::::::::::::::::                     #<br/>&#13;
     |:                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
     |@                                               :                     #<br/>&#13;
   0 +--------------------------------------------------------------------&gt;Gi<br/>&#13;
     0                                                                  9.778<br/>&#13;
<br/>&#13;
Number of snapshots: 80<br/>&#13;
 Detailed snapshots: [3, 12, 17, 22, 49, 59, 69, 79 (peak)]<br/>&#13;
</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_612"/>At the top of the output is the memory use graph. The <em>x</em>-axis shows the number of instructions executed. The <em>y</em>-axis shows memory use. The graph above indicates that a total of 9.778 billion (Gi) instructions executed during our run of <code>matrixVector3</code>. During execution, <code>massif</code> took a total of 80 snapshots to measure use on the heap. Memory use peaked in the last snapshot (79). Peak memory use for the program was 763.3 MB, and stayed relatively constant throughout the program.</p>&#13;
<p class="indent">Summaries of all the snapshots occur after the graph. For example, the following table corresponds to the snapshots around snapshot 79:</p>&#13;
<pre>····<br/>&#13;
<br/>&#13;
------------------------------------------------------------------------------<br/>&#13;
  n        time(i)         total(B)   useful-heap(B) extra-heap(B)   stacks(B)<br/>&#13;
------------------------------------------------------------------------------<br/>&#13;
 70      1,081,926      727,225,400      727,080,000       145,400          0<br/>&#13;
 71      1,095,494      737,467,448      737,320,000       147,448          0<br/>&#13;
 72      1,109,062      747,709,496      747,560,000       149,496          0<br/>&#13;
 73      1,122,630      757,951,544      757,800,000       151,544          0<br/>&#13;
 74      1,136,198      768,193,592      768,040,000       153,592          0<br/>&#13;
 75      1,149,766      778,435,640      778,280,000       155,640          0<br/>&#13;
 76      1,163,334      788,677,688      788,520,000       157,688          0<br/>&#13;
 77      1,176,902      798,919,736      798,760,000       159,736          0<br/>&#13;
 78  7,198,260,935      800,361,056      800,201,024       160,032          0<br/>&#13;
 79 10,499,078,349      800,361,056      800,201,024       160,032          0<br/>&#13;
99.98% (800,201,024B) (heap allocations) malloc/new/new[], --alloc-fns, etc.<br/>&#13;
-&gt;99.96% (800,040,000B) 0x40089D: allocateArray (in matrixVector3)<br/>&#13;
</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_613"/>Each row corresponds to a particular snapshot, the time it was taken, the total heap memory consumption (in bytes) at that point, the number of bytes requested by the program ("useful-heap") at that point, the number of bytes allocated in excess of what the program asked for, and the size of the stack. By default, stack profiling is off (it slows <code>massif</code> down significantly). To enable stack profiling, use the <code>--stacks=yes</code> option when running <code>massif</code>.</p>&#13;
<p class="indent">The <code>massif</code> tool reveals that 99.96% of the program’s heap memory use occurred in the <code>allocateArray</code> function and that a total of 800 million bytes were allocated, consistent with the back-of-the-envelope calculation we performed earlier. Readers will likely find <code>massif</code> a useful tool for identifying areas of high heap memory use in their programs, which often slows a program down. For example, <em>memory leaks</em> can occur in programs when programmers frequently call <code>malloc</code> without calling <code>free</code> at the first correct opportunity. The <code>massif</code> tool is incredibly useful for detecting such leaks.</p>&#13;
<h3 class="h3" id="lev1_97">12.4 Key Takeaways and Summary</h3>&#13;
<p class="noindent">Our short (and perhaps frustrating) journey into code optimization should convey one very important message to the reader: if you are thinking about manually optimizing your code, think carefully about what is worth spending your time on and what should be left to the compiler. Next are some important tips to consider when looking to improve code performance.</p>&#13;
<h4 class="h4" id="lev2_212">Choose Good Data Structures and Algorithms</h4>&#13;
<p class="noindent">There is no substitute for using proper algorithms and data structures; failure to do so is often the top reason for poor performance in code. For example, the famous Sieve of Eratosthenes algorithm is a much more efficient way to generate prime numbers than our custom algorithm in <code>optExample</code>, and yields a significant improvement in performance. The following listing shows the time needed to generate all prime numbers between 2 and 5 million using an implementation of the sieve:</p>&#13;
<pre>$ <span class="codestrong1">gcc -o genPrimes genPrimes.c</span><br/>&#13;
$ <span class="codestrong1">./genPrimes 5000000</span><br/>&#13;
Found 348513 primes (0.122245 s)<br/>&#13;
</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_614"/>The sieve algorithm requires only 0.12 seconds to find all the prime numbers between 2 and 5 million, compared to the 1.46 seconds it takes <code>optExample2</code> to generate the same set of primes with the <code>-O3</code> optimization flags turned on (12× improvement). The implementation of the sieve algorithm is left as an exercise for the reader; however, it should be clear that choosing a better algorithm up front would have saved hours of tedious optimization effort. Our example demonstrates why a knowledge of data structures and algorithms is foundational for computer scientists.</p>&#13;
<h4 class="h4" id="lev2_213">Use Standard Library Functions Whenever Possible</h4>&#13;
<p class="noindent">Don’t reinvent the wheel. If in the course of programming you need a function that should do something very standard (e.g., find the absolute value, or find the maximum or minimum of a list of numbers), stop and check to see whether the function already exists as part of the higher-level language’s standard library. Functions in the standard libraries are well tested and tend to be optimized for performance. For example, if a reader manually implements their own version of the <code>sqrt</code> function, the compiler may not know to automatically replace the function call with the <code>fsqrt</code> instruction.</p>&#13;
<h4 class="h4" id="lev2_214">Optimize Based on Data and Not on Feelings</h4>&#13;
<p class="noindent">If after choosing the best data structures and algorithms <em>and</em> employing standard library functions, additional improvements in performance are required, enlist the help of a good code profiler like Valgrind. Optimization should <em>never</em> be based on gut feelings. Concentrating too much on what one <em>feels</em> should be optimized (without the data to back up the thought) often leads to wasted time.</p>&#13;
<h4 class="h4" id="lev2_215">Split Complex Code into Multiple Functions</h4>&#13;
<p class="noindent">Manually inlining code usually does not result in a sizable performance gain over what modern compilers can achieve. Instead, make it easier for your compiler to help optimize for you. Compilers have an easier time optimizing shorter code segments. Splitting complex operations into multiple functions simultaneously increases code readability and makes it easier for a compiler to optimize. Check to see whether your compiler attempts inlining by default or has a separate flag to attempt inlining code. It is better to let your compiler perform inlining rather than manually doing it yourself.</p>&#13;
<h4 class="h4" id="lev2_216">Prioritize Code Readability</h4>&#13;
<p class="noindent">In many applications today, readability is king. The truth is that code is read more often than it is written. Many companies spend considerable time training their software engineers to write code in a very particular way to maximize readability. If optimizing your code results in a noticeable hit to code readability, it is important to check if the performance improvement obtained is worth the hit. For example, many compilers today have optimization <span epub:type="pagebreak" id="page_615"/>flags that enable loop unrolling. Programmers should always use available optimization flags for loop unrolling instead of trying to manually unroll loops, which can lead to a significant hit in code readability. Reducing code readability often increases the likelihood that bugs are inadvertently introduced into code, which can lead to security vulnerabilities.</p>&#13;
<h4 class="h4" id="lev2_217">Pay Attention to Memory Use</h4>&#13;
<p class="noindent">A program’s memory usage often has a bigger impact on the program’s execution time than the number of instructions that it executes. The loop interchange example exemplifies this point. In both cases, the loop executes the same number of instructions. However, the ordering of the loops has a significant impact on memory access and locality. Remember to also explore memory profiling tools like <code>massif</code> and <code>cachegrind</code> when attempting to optimize a program.</p>&#13;
<h4 class="h4" id="lev2_218">Compilers Are Constantly Improving</h4>&#13;
<p class="noindent">Compiler writers continually update compilers to perform more sophisticated optimizations safely. For example, GCC switched to the static single assignment (SSA) form<sup><a href="ch12.xhtml#fn12_11" id="rfn12_11">11</a></sup> starting in version 4.0, which significantly improved the effects of some of its optimizations. The <code>GRAPHITE</code> branch of the GCC code base implements the polyhedral model,<sup><a href="ch12.xhtml#fn12_12" id="rfn12_12">12</a></sup> which allows the compiler to perform more complex types of loop transformations. As compilers become more sophisticated, the benefits of manual optimization significantly decrease.</p>&#13;
<h3 class="h3" id="lev1_98">Notes</h3>&#13;
<p class="fnote"><a href="ch12.xhtml#rfn12_1" id="fn12_1">1.</a> <em><a href="https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html">https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html</a></em></p>&#13;
<p class="fnote"><a href="ch12.xhtml#rfn12_2" id="fn12_2">2.</a> John Regehr, “A Guide to Undefined Behavior in C and C++, Part 1,” <em><a href="https://blog.regehr.org/archives/213">https://blog.regehr.org/archives/213</a></em>, 2010.</p>&#13;
<p class="fnote"><a href="ch12.xhtml#rfn12_3" id="fn12_3">3.</a> C FAQ, “comp.lang.c FAQ list: Question 11.33,” <em><a href="http://c-faq.com/ansi/undef.html">http://c-faq.com/ansi/undef.html</a></em></p>&#13;
<p class="fnote"><a href="ch12.xhtml#rfn12_4" id="fn12_4">4.</a> John Regehr, “A Guide to Undefined Behavior in C and C++, Part 1,” <em><a href="https://blog.regehr.org/archives/213">https://blog.regehr.org/archives/213</a></em>, 2010.</p>&#13;
<p class="fnote"><a href="ch12.xhtml#rfn12_5" id="fn12_5">5.</a> Source code available at <em><a href="https://diveintosystems.org/book/C12-CodeOpt/_attachments/optExample.c">https://diveintosystems.org/book/C12-CodeOpt/_attachments/optExample.c</a></em></p>&#13;
<p class="fnote"><a href="ch12.xhtml#rfn12_6" id="fn12_6">6.</a> <em><a href="http://valgrind.org/">http://valgrind.org/</a></em></p>&#13;
<p class="fnote"><a href="ch12.xhtml#rfn12_7" id="fn12_7">7.</a> <em><a href="https://diveintosystems.org/book/C12-CodeOpt/_attachments/optExample2.c">https://diveintosystems.org/book/C12-CodeOpt/_attachments/optExample2.c</a></em></p>&#13;
<p class="fnote"><a href="ch12.xhtml#rfn12_8" id="fn12_8">8.</a> <em><a href="https://diveintosystems.org/book/C12-CodeOpt/_attachments/optExample3.c">https://diveintosystems.org/book/C12-CodeOpt/_attachments/optExample3.c</a></em></p>&#13;
<p class="fnote"><a href="ch12.xhtml#rfn12_9" id="fn12_9">9.</a> <em><a href="https://diveintosystems.org/book/C12-CodeOpt/_attachments/optExample3.c">https://diveintosystems.org/book/C12-CodeOpt/_attachments/optExample3.c</a></em></p>&#13;
<p class="fnote1"><a href="ch12.xhtml#rfn12_10" id="fn12_10">10.</a> <em><a href="https://diveintosystems.org/book/C12-CodeOpt/_attachments/matrixVector.c">https://diveintosystems.org/book/C12-CodeOpt/_attachments/matrixVector.c</a></em></p>&#13;
<p class="fnote1"><a href="ch12.xhtml#rfn12_11" id="fn12_11">11.</a> <em><a href="https://gcc.gnu.org/onlinedocs/gccint/SSA.html">https://gcc.gnu.org/onlinedocs/gccint/SSA.html</a></em></p>&#13;
<p class="fnote1"><a href="ch12.xhtml#rfn12_12" id="fn12_12">12.</a> <em><a href="https://polyhedral.info/">https://polyhedral.info/</a></em><span epub:type="pagebreak" id="page_616"/></p>&#13;
</body></html>