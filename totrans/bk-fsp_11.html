<html><head></head><body><section class="chapter" title="Chapter&#xA0;11.&#xA0;Asynchronous and Parallel Programming" epub:type="chapter" id="asynchronous_and_parallel_programming"><div class="titlepage"><div><div><h2 class="title">Chapter 11. Asynchronous and Parallel Programming</h2></div></div></div><p>For most of computing’s history, software developers have been spoiled by processor manufacturers that were constantly pushing the limits of their chips’ clock speeds. If you needed your software to run faster (to process larger data sets, or because users were complaining about the system freezing when it was really just busy), often all you had to do was upgrade to the latest chip. Over the past decade or so something changed: Processor manufacturers began improving processor performance not by increasing clock speeds but by adding processing cores.</p><p>Although processor architecture has changed, software architecture has largely remained static. Multicore processors have become the norm, yet many applications are still written as though only one core is available to them and thus are not taking full advantage of the underlying hardware. Long-running tasks are still being executed on the UI thread, and large data sets are often processed synchronously. A big reason for this is <a id="iddle1176" class="indexterm"/><a id="iddle1275" class="indexterm"/><a id="iddle1732" class="indexterm"/><a id="iddle1998" class="indexterm"/><a id="iddle2000" class="indexterm"/><a id="iddle2019" class="indexterm"/>that, traditionally, asynchronous and parallel programming have been sufficiently complex and error prone that they were typically the domain of expert developers working on highly specialized software.</p><p>Fortunately, software is starting to catch up. Programmers are learning that the days of solving performance issues by throwing faster hardware at the problem have passed and that it’s increasingly important to consider concurrent processing needs at an architectural level.</p><p>Although they’re closely related, asynchronous and parallel programming have different goals. Asynchronous programming aims to separate processing and reduce blocking so that longer-running tasks don’t prevent the system from completing other tasks within the same process. By contrast, parallel processing aims to improve performance by partitioning work into chunks that can be distributed across processors and operated against independently.</p><p>Since its inception, the .NET Framework has supported both asynchronous and parallel programming through threads and a multitude of synchronization mechanisms such as monitors, mutexes, semaphores, and so on. The <span class="emphasis"><em>Asynchronous Programming Model (APM)</em></span>, where classes define <code class="literal">BeginX</code> and <code class="literal">EndX</code> methods for operations that should be run asynchronously (such as the <code class="literal">BeginRead</code> and <code class="literal">EndRead</code> methods on the <code class="literal">System.IO.FileStream</code> class) has long been the preferred approach to asynchronous programming in .NET.</p><p>In this chapter, we’ll explore several ways that F# makes asynchronous and parallel programming more accessible, thereby freeing you to focus on creating correct solutions. We’ll begin with a brief introduction to the Task Parallel Library. Next, we’ll discuss another F# construct: asynchronous workflows. Finally, we’ll conclude with an introduction to the <code class="literal">MailboxProcessor</code>, F#’s agent-based model for asynchronous programming.</p><div class="sect1" title="Task Parallel Library"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="task_parallel_library">Task Parallel Library</h2></div></div></div><p>As its name implies, the <span class="emphasis"><em>Task Parallel Library (TPL)</em></span> excels at handling parallel programming scenarios and is the preferred mechanism for CPU-bound operations. It abstracts much of the complexity of managing threads, locks, callbacks, cancellations, and exception handling behind a uniform interface. Although the TPL is not specific to F#, a basic understanding of it is helpful especially if you need to interact with code from libraries that use it.</p><p>The TPL enables two types of parallelism: data parallelism and task parallelism.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: none"><p title="Data parallelism"><span class="title"><strong><span class="strong"><strong>Data parallelism</strong></span></strong></span>. Involves performing a specific action against each value in a sequence by distributing the work effectively across available processing resources. Under the data parallelism model, you specify a sequence along with an action and the TPL determines how to partition the data and distributes the work accordingly.</p></li><li class="listitem" style="list-style-type: none"><p title="Task parallelism"><span class="title"><strong><span class="strong"><strong>Task parallelism</strong></span></strong></span>. Focuses on executing independent tasks concurrently. With task parallelism, you are responsible for manually creating and managing tasks, but this model offers you more control. Through <a id="iddle1276" class="indexterm"/><a id="iddle1721" class="indexterm"/><a id="iddle1722" class="indexterm"/><a id="iddle1725" class="indexterm"/><a id="iddle1774" class="indexterm"/><a id="iddle1775" class="indexterm"/>the various <code class="literal">Task</code> classes, you can easily initiate asynchronous processing, wait for tasks to complete, return values, set up continuations, or spawn additional tasks.</p></li></ul></div><div class="note" title="Note"><h3 class="title"><a id="ch11note01"/>Note</h3><p><span class="emphasis"><em>This section is not intended to be a comprehensive guide to the TPL. Thus, it won’t get into many of the intricacies of task creation, scheduling, management, or other associated topics. The intention here is to establish a baseline, providing you with enough information to make you immediately productive when writing code using the TPL.</em></span></p></div><div class="sect2" title="Potential Parallelism"><div class="titlepage"><div><div><h3 class="title" id="potential_parallelism">Potential Parallelism</h3></div></div></div><p>One of the key differences between working directly with threads and using the TPL is that the TPL is task based rather than thread based. This difference is quite important in that the TPL tries to run tasks concurrently by pulling threads from the thread pool, but it does not guarantee parallelism. This is known as <span class="emphasis"><em>potential parallelism</em></span>.</p><p>Whenever you create a thread directly, you incur the overhead of allocating and scheduling it. This overhead can be detrimental to overall system performance if there aren’t enough system resources available to support it. The basic concurrency mechanisms, like thread pooling, help reduce the impact by reusing existing threads, but the TPL goes a step further by taking available system resources into account. If there aren’t sufficient resources available or the TPL otherwise determines that running a task in parallel will be detrimental to performance, it will run the task synchronously. As resources fluctuate over time, the TPL’s task scheduling and work partitioning algorithms help rebalance work to use the available resources effectively.</p></div><div class="sect2" title="Data Parallelism"><div class="titlepage"><div><div><h3 class="title" id="data_parallelism">Data Parallelism</h3></div></div></div><p>Data parallelism is achieved primarily through the use of the static <code class="literal">For</code> and <code class="literal">ForEach</code> methods of the <code class="literal">Parallel</code> class located in the <code class="literal">System.Threading.Tasks</code> namespace. As their names imply, these methods are essentially parallel versions of the simple and enumerable <code class="literal">for</code> loops, respectively.</p><div class="note" title="Note"><h3 class="title"><a id="ch11note02"/>Note</h3><p><span class="emphasis"><em>Data parallelism can also be achieved through PLINQ’s (Parallel LINQ) AsParallel extension method. To simplify working with parallel sequences in F#, the PSeq module in the F# PowerPack exposes many of the ParallelEnumerable methods using the same nomenclature as the Seq module.</em></span></p></div><p>For normal usage, <code class="literal">Parallel.For</code> and <code class="literal">Parallel.ForEach</code> differ only by their input; <code class="literal">Parallel.For</code> accepts range boundaries, whereas <code class="literal">Parallel.ForEach</code> accepts a sequence. Both methods also accept a function that serves as the loop body, and they implicitly wait for all iterations to complete before returning control to the caller. Since the methods are so similar, the examples in this section will use <code class="literal">Parallel.For</code> for consistency.</p><p><a id="iddle1598" class="indexterm"/><a id="iddle1975" class="indexterm"/>The simplest form, the parallel <code class="literal">for</code> loop, simply invokes an action for each value in the range. Here, we use a parallel <code class="literal">for</code> loop to write the numbers 0 through 99.</p><a id="pro_id00565"/><pre class="programlisting">open System
open System.Threading.Tasks

Parallel.For(0, 100, printfn "%i")</pre><p>This snippet is pretty self-explanatory. The first argument passed to <code class="literal">Parallel.For</code> identifies the inclusive beginning of the range, while the second identifies the exclusive end of the range. The third argument is a function that writes a number to the console.</p><div class="sect3" title="Locking and Lock Avoidance"><div class="titlepage"><div><div><h4 class="title" id="locking_and_lock_avoidance">Locking and Lock Avoidance</h4></div></div></div><p>Now that we’re dealing with concurrency, there’s a subtle bug in the previous example. Internally, <code class="literal">printfn</code> incrementally sends its text to <code class="literal">System.Console.Out</code> as it parses the pattern. Hence, it’s possible that as each parallel iteration executes, multiple calls to <code class="literal">printfn</code> will be invoked simultaneously, resulting in some items being interlaced.</p><div class="note" title="Note"><h3 class="title"><a id="ch11note03"/>Note</h3><p><span class="emphasis"><em>The example used for this discussion is less of an issue in F# 3.1, where printf and its related functions have been improved such that they run up to 40 times faster than in previous releases.</em></span></p></div><p>We can address this problem a few ways. One approach is to control access to <code class="literal">System.Console.Out</code> with the <code class="literal">lock</code> operator. The <code class="literal">lock</code> operator serves the same purpose as the <code class="literal">lock</code> statement in C# (<code class="literal">SyncLock</code> in Visual Basic) in that it prevents additional threads from executing a block of code until the locked resource is freed. Here is the previous example reworked to use locking:</p><a id="pro_id00566"/><pre class="programlisting">Parallel.For(0, 100, fun n -&gt; lock Console.Out (fun () -&gt; printfn "%i" n))</pre><p>There are times when locking is appropriate, but using it like this is a horrible idea. By locking, we negate most of the benefits of parallelizing the loop because only one item can be written at a time! Instead, we want to try another approach that avoids locking and doesn’t interlace the results.</p><p>One of the easiest ways to achieve a satisfactory result is with function composition. Here, we use the <code class="literal">sprint</code> function to format the number and send that result to <code class="literal">Console.WriteLine</code>:</p><a id="pro_id00567"/><pre class="programlisting">Parallel.For(0, 100, (sprintf "%i") &gt;&gt; Console.WriteLine)</pre><p>This approach works because each call to <code class="literal">sprintf</code> writes to an isolated <code class="literal">StringBuilder</code> rather than a shared <code class="literal">TextWriter</code>. This eliminates the need to lock, thereby eliminating a potential bottleneck in your application.</p></div><div class="sect3" title="Short-Circuiting Parallel Loops"><div class="titlepage"><div><div><h4 class="title" id="short-circuiting_parallel_loops">Short-Circuiting Parallel Loops</h4></div></div></div><p><a id="iddle1689" class="indexterm"/><a id="iddle1723" class="indexterm"/><a id="iddle1726" class="indexterm"/><a id="iddle1727" class="indexterm"/><a id="iddle1728" class="indexterm"/><a id="iddle1729" class="indexterm"/><a id="iddle1730" class="indexterm"/>Unlike F#’s built-in <code class="literal">for</code> loops, parallel loops provide some short-circuiting mechanisms by means of the <code class="literal">ParallelLoopState</code> class’s <code class="literal">Break</code> and <code class="literal">Stop</code> methods. The TPL handles creating and managing the loop state, so all you need to do to access either of these methods is use one of the overloads that exposes it. Consider the following <code class="literal">shortCircuitExample</code> function:</p><a id="pro_id00568"/><pre class="programlisting">open System.Collections.Concurrent
open System.Threading.Tasks

let shortCircuitExample shortCircuit =
  let bag = ConcurrentBag&lt;_&gt;()
  Parallel.For(
    0,
    999999,
  ① fun i s -&gt; if i &lt; 10000 then bag.Add i else shortCircuit s) |&gt; ignore
  (bag, bag.Count)</pre><p>Like the previous examples, the <code class="literal">shortCircuitExample</code> function uses <code class="literal">Parallel.For</code>, but notice at ① that the supplied function accepts two parameters instead of one. The second parameter, <code class="literal">s</code>, is the loop state.</p><p>With <code class="literal">shortCircuitExample</code> in place we can now invoke it, passing a function that accepts a <code class="literal">ParallelLoopState</code> instance and calls either <code class="literal">Stop</code> or <code class="literal">Break</code>, like this:</p><a id="pro_id00569"/><pre class="programlisting">shortCircuitExample (fun s -&gt; s.Stop()) |&gt; printfn "%A"
shortCircuitExample (fun s -&gt; s.Break()) |&gt; printfn "%A"</pre><p>Both of the preceding lines will force the parallel loop to terminate before all iterations complete, but they have very different effects. <code class="literal">Stop</code> causes the loop to terminate at its earliest convenience but allows any iterations that are executing to continue. <code class="literal">Break</code>, on the other hand, causes the loop to terminate at its earliest convenience after the current iteration. You also need to take care that you do not call <code class="literal">Stop</code> and <code class="literal">Break</code> in succession to avoid an <code class="literal">InvalidOperationException</code>.</p><p>The difference between these two methods can be drastic. For example, in one run on my desktop, the <code class="literal">Break</code> version processed 10,000 items, whereas the <code class="literal">Stop</code> version processed only 975.</p></div><div class="sect3" title="Cancelling Parallel Loops"><div class="titlepage"><div><div><h4 class="title" id="cancelling_parallel_loops">Cancelling Parallel Loops</h4></div></div></div><p>Cancelling a parallel <code class="literal">for</code> loop is similar to short-circuiting, except that instead of using the <code class="literal">Stop</code> or <code class="literal">Break</code> methods to terminate the loop from within, you identify an external <span class="emphasis"><em>cancellation token</em></span> that the loop monitors and responds to. Unlike the short-circuiting mechanism, cancellation forces all tasks configured with the same token to stop. Cancelling does raise an <code class="literal">OperationCanceledException</code>, so you’ll want to handle that accordingly.</p><p><a id="iddle1225" class="indexterm"/><a id="iddle1724" class="indexterm"/><a id="iddle1731" class="indexterm"/><a id="iddle1999" class="indexterm"/><a id="iddle2004" class="indexterm"/>The following function demonstrates cancelling a parallel <code class="literal">for</code> loop:</p><a id="pro_id00570"/><pre class="programlisting">open System
open System.Threading.Tasks

let parallelForWithCancellation (wait : int) =
  use tokenSource = new ① System.Threading.CancellationTokenSource(wait)

  try
    Parallel.For(
      0,
      Int32.MaxValue,
    ② ParallelOptions(③ CancellationToken = ④ tokenSource.Token),
      fun (i : int) -&gt; Console.WriteLine i
    ) |&gt; ignore
  with
  | :? ⑤ OperationCanceledException -&gt; printfn "Cancelled!"
  | ex -&gt; printfn "%O" ex</pre><p>In the preceding code, we create a <code class="literal">CancellationTokenSource</code> at ①. This object is initialized to automatically cancel after a provided number of milliseconds. Inside the <code class="literal">try</code> block, we use an overload of <code class="literal">Parallel.For</code> that accepts a <code class="literal">ParallelOptions</code> instance as shown at ②. Through this <code class="literal">ParallelOptions</code> instance, we initialize the <code class="literal">CancellationToken</code> property ③ to the token exposed by the <code class="literal">CancellationTokenSource</code> ④. When the token source’s internal timer expires, the parallel loop raises an exception, which is then caught and handled at ⑤.Although we relied on a <code class="literal">CancellationTokenSource</code> that automatically cancelled, you can manually force cancellation by calling the <code class="literal">Cancel</code> method, typically from another task or thread.</p></div></div><div class="sect2" title="Task Parallelism"><div class="titlepage"><div><div><h3 class="title" id="task_parallelism">Task Parallelism</h3></div></div></div><p>Task parallelism gives you the most control over executing code in parallel while still abstracting many of the implementation details from you.</p><div class="sect3" title="Creating and Starting Tasks"><div class="titlepage"><div><div><h4 class="title" id="creating_and_starting_tasks">Creating and Starting Tasks</h4></div></div></div><p>Tasks can be created and started in several ways. The easiest, but least flexible, way is the <code class="literal">Parallel.Invoke</code> method, which accepts one or more functions to execute concurrently and implicitly waits for them to finish, like this:</p><a id="pro_id00571"/><pre class="programlisting">open System
open System.Threading.Tasks

Parallel.Invoke(
  (fun () -&gt; printfn "Task 1"),
  (fun () -&gt; Task.Delay(100).Wait()
             printfn "Task 2"),
  (fun () -&gt; printfn "Task 3")
)

printfn "Done"</pre><p><a id="iddle1981" class="indexterm"/><a id="iddle1984" class="indexterm"/><a id="iddle1985" class="indexterm"/><a id="iddle1988" class="indexterm"/><a id="iddle1995" class="indexterm"/><a id="iddle2006" class="indexterm"/><a id="iddle2008" class="indexterm"/>Here, <code class="literal">Parallel.Invoke</code> creates and starts three independent tasks. The first and third tasks simply print a message, while the second task waits 100 milliseconds before printing its message.</p><p><code class="literal">Parallel.Invoke</code> limits what you can do because it doesn’t expose any information about the individual tasks, nor does it provide any feedback about whether the tasks succeeded or failed. You can catch and handle exceptions raised by the tasks and cancel them by providing a cancellation token (similar to the approach used in <a class="xref" href="ch11.html#cancelling_parallel_loops" title="Cancelling Parallel Loops">Cancelling Parallel Loops</a>), but that’s about it. When you want to do anything more advanced with tasks, you’ll need to create them manually.</p><p>There are two ways to create tasks manually: directly via a constructor, or through a <code class="literal">TaskFactory</code>. For our purposes, the primary difference between the two approaches is that when creating tasks with the constructor you must manually start them. Microsoft recommends favoring the <code class="literal">TaskFactory</code> when task creation and scheduling don’t need to be separated.</p><p>To create a new task with the <code class="literal">Task</code> constructor, you need only provide a function that serves as the task’s body, like this:</p><a id="pro_id00572"/><pre class="programlisting">open System.Threading.Tasks

let t = new Task(fun () -&gt; printfn "Manual Task")</pre><p>This creates a new task that prints a string. To start the task, call its <code class="literal">Start</code> method.</p><a id="pro_id00573"/><pre class="programlisting">t.Start()</pre><p>Alternatively, you can combine the two steps into one with a <code class="literal">TaskFactory</code>. Conveniently, the <code class="literal">Task</code> class has a static <code class="literal">Factory</code> property that is preset to a default <code class="literal">TaskFactory</code>, so you don’t need to create one on your own. Here, we create and start a task using the default factory’s <code class="literal">StartNew</code> method:</p><a id="pro_id00574"/><pre class="programlisting">open System.Threading.Tasks

let t = Task.Factory.StartNew(fun () -&gt; printfn "Factory Task")</pre></div><div class="sect3" title="Returning Values from Tasks"><div class="titlepage"><div><div><h4 class="title" id="returning_values_from_tasks">Returning Values from Tasks</h4></div></div></div><p>The tasks we’ve looked at so far simply invoke an action, but you also need to know how to return a value—a commonly needed but cumbersome process under traditional asynchronous models. The TPL makes returning values trivial through a generic <code class="literal">Task&lt;'T&gt;</code> class, where <code class="literal">'T</code> represents the task’s return type.</p><div class="warning" title="Warning" epub:type="warning"><h3 class="title"><a id="ch11note04"/>Warning</h3><p><span class="emphasis"><em>The random-number generation used in the following examples is sufficient for demonstration purposes, but be aware that the <code class="literal">System.Random</code> class is not thread-safe and even creating a new instance per task may not be sufficient. Should your solution require a more robust approach to concurrently generating random numbers, I recommend reading Stephen Toub’s article on the subject at</em></span> <a class="ulink" href="http://blogs.msdn.com/b/pfxteam/archive/2009/02/19/9434171.aspx" target="_top">http://blogs.msdn.com/b/pfxteam/archive/2009/02/19/9434171.aspx</a>.</p></div><p><a id="iddle1989" class="indexterm"/><a id="iddle1996" class="indexterm"/><a id="iddle1997" class="indexterm"/><a id="iddle2007" class="indexterm"/><a id="iddle2009" class="indexterm"/><a id="iddle2011" class="indexterm"/>Creating tasks that return values is almost identical to the basic tasks we’ve already looked at. The <code class="literal">Task&lt;'T&gt;</code> class provides a set of constructor overloads that are comparable to that of the non-generic <code class="literal">Task</code> class, and the <code class="literal">TaskFactory</code> includes a generic overload of <code class="literal">StartNew</code>. To demonstrate, let’s use <code class="literal">StartNew&lt;'T&gt;</code> to create and run a task that returns a random number.</p><a id="pro_id00575"/><pre class="programlisting">let t = Task.Factory.StartNew(fun () -&gt; System.Random().Next())</pre><p>The only truly notable thing about this example is that the function passed to <code class="literal">StartNew</code> returns an integer and the generic overload is inferred. Of course, returning a value doesn’t do much good without a way to access that value, and that’s why <code class="literal">Task&lt;'T&gt;</code> provides the <code class="literal">Result</code> property, which will contain the return value when the task completes. Here, we see how to access the return value:</p><a id="pro_id00576"/><pre class="programlisting"><span class="strong"><strong>t.Result</strong></span> |&gt; printfn "Result: %i"</pre><p>Because this is an asynchronous operation, there’s no guarantee that the task has completed executing before the <code class="literal">Result</code> property is accessed. For this reason, <code class="literal">Result</code>’s <code class="literal">get</code> accessor checks whether the task has completed and waits for it to complete if necessary before returning its result. It’s more typical to access the result as part of a continuation (as shown a bit later in this chapter) than immediately after the task starts.</p></div><div class="sect3" title="Waiting for Task Completion"><div class="titlepage"><div><div><h4 class="title" id="waiting_for_task_completion">Waiting for Task Completion</h4></div></div></div><p>When your program depends on one or more tasks completing before it can continue processing, you can wait for those tasks using one of the wait mechanisms. For convenience, the examples in this section will use the following function, which returns a new function that sleeps for a random amount of time (simulating a long-running operation lasting up to <code class="literal">delayMs</code>) before printing a message:</p><a id="pro_id00577"/><pre class="programlisting">let randomWait (delayMs : int) (msg : string) =
  fun () -&gt; (System.Random().Next delayMs |&gt; Task.Delay).Wait()
            Console.WriteLine msg</pre><p>We can use the <code class="literal">TaskFactory</code> to create a task and wait for it to complete with the task’s <code class="literal">Wait</code> method like this:</p><a id="pro_id00578"/><pre class="programlisting">let waitTask = Task.Factory.StartNew(randomWait 1000 "Task Finished")
<span class="strong"><strong>waitTask.Wait()</strong></span>
printfn "Done Waiting"</pre><p>In this code, a new task is created and started, but the message “Done Waiting” won’t be written to the console until it completes due to the explicit wait. This can be helpful when subsequent code is dependent upon the task’s completion.</p><p><a id="iddle1124" class="indexterm"/><a id="iddle1224" class="indexterm"/><a id="iddle1270" class="indexterm"/><a id="iddle1982" class="indexterm"/><a id="iddle1986" class="indexterm"/><a id="iddle1987" class="indexterm"/><a id="iddle2003" class="indexterm"/>You’ll often want to run a number of tasks in parallel and block until one completes. To do so, you can use the static <code class="literal">WaitAny</code> method from the <code class="literal">Task</code> class. The most basic <code class="literal">WaitAny</code> overload accepts a <code class="literal">params</code> array of tasks and will stop blocking as soon as one of the tasks in the array completes. Here, we pass three started tasks to <code class="literal">WaitAny</code>:</p><a id="pro_id00579"/><pre class="programlisting">Task.WaitAny(
    Task.Factory.StartNew(randomWait 2000 "Task 0 Finished"),
    Task.Factory.StartNew(randomWait 2000 "Task 1 Finished"),
    Task.Factory.StartNew(randomWait 2000 "Task 2 Finished"))
Console.WriteLine "Done Waiting"</pre><p>When any of the three tasks complete, <code class="literal">WaitAny</code> will stop blocking, thus allowing execution to continue to the <code class="literal">Console.WriteLine</code> call. Note that <code class="literal">WaitAny</code> doesn’t kill the remaining tasks when it unblocks, so they’ll continue executing in parallel with the source thread.</p><p>Similar to <code class="literal">WaitAny</code>, the <code class="literal">Task</code> class provides a static <code class="literal">WaitAll</code> method. <code class="literal">WaitAll</code> also accepts a <code class="literal">params</code> array of tasks, but instead of allowing execution to continue when one task completes, <code class="literal">WaitAll</code> unblocks only when <span class="emphasis"><em>all</em></span> of the tasks have completed. Because the code differs only by which method is called, I haven’t included a sample, but I encourage you to experiment with each. As you do so, run each form several times and observe the differences.</p></div><div class="sect3" title="Continuations"><div class="titlepage"><div><div><h4 class="title" id="continuations">Continuations</h4></div></div></div><p>Traditionally, whenever you wanted to execute some code as soon as some parallel or asynchronous code completed, you needed to pass a function, called a <span class="emphasis"><em>callback</em></span>, to the asynchronous code. In .NET, callbacks have typically been implemented through the built-in <code class="literal">AsyncCallback</code> delegate type.</p><p>Using callbacks is effective, but they can complicate the code and be tricky to maintain. The TPL greatly simplifies this process with <span class="emphasis"><em>continuations</em></span>, which are tasks configured to start when one or more tasks, called <span class="emphasis"><em>antecedents</em></span>, complete.</p><p>The simplest continuations are created from individual tasks. Let’s start by creating a task that will serve as an antecedent:</p><a id="pro_id00580"/><pre class="programlisting">let antecedent =
  new Task&lt;string&gt;(
    fun () -&gt;
      Console.WriteLine("Started antecedent")
      System.Threading.Thread.Sleep(1000)
      Console.WriteLine("Completed antecedent")
      "Job's done")</pre><p>Now that we have a task, we can set up a continuation by passing a function to the task’s <code class="literal">ContinueWith</code> method, like so:</p><a id="pro_id00581"/><pre class="programlisting">let continuation =
  antecedent.ContinueWith(
    fun ① (a : Task&lt;string&gt;) -&gt;
      Console.WriteLine("Started continuation")
      Console.WriteLine("Antecedent status: {0}", a.Status)
      Console.WriteLine("Antecedent result: {0}", a.Result)
      Console.WriteLine("Completed continuation"))</pre><p><a id="iddle1983" class="indexterm"/><a id="iddle1990" class="indexterm"/><a id="iddle1991" class="indexterm"/><a id="iddle1993" class="indexterm"/><a id="iddle2010" class="indexterm"/>As you can see, creating a continuation is very similar to creating a regular task, but notice at ① how the function passed to the <code class="literal">ContinueWith</code> method accepts a parameter of type <code class="literal">Task&lt;string&gt;</code>. This parameter represents the antecedent so that the continuation can branch according to the antecedent’s status (for example, <code class="literal">RanToCompletion</code>, <code class="literal">Faulted</code>, <code class="literal">Canceled</code>, and so on) or its result if it has one.</p><p>At this point, neither task has been started, so we’ll start <code class="literal">antecedent</code>. When it completes, the TPL will automatically start <code class="literal">continuation</code>. We can observe this behavior as follows:</p><a id="pro_id00582"/><pre class="programlisting">antecedent.Start()
Console.WriteLine("Waiting for continuation")
continuation.Wait()
Console.WriteLine("Done")</pre><p>which should print the following messages:</p><a id="pro_id00583"/><pre class="programlisting">Waiting for continuation
Started antecedent
Completed antecedent
Started continuation
Antecedent status: RanToCompletion
Completed continuation
Done</pre><p>The <code class="literal">ContinueWith</code> method is useful when you’re dealing with only a single task. When you have multiple tasks, you can turn to the <code class="literal">TaskFactory</code>’s <code class="literal">ContinueWhenAny</code> or <code class="literal">ContinueWhenAll</code> methods. Like their <code class="literal">WaitAny</code> and <code class="literal">WaitAll</code> counterparts, the <code class="literal">ContinueWhenAny</code> and <code class="literal">ContinueWhenAll</code> methods will start the continuation task when any or all of the tasks in an array complete, respectively. For brevity we’ll focus on the <code class="literal">ContinueWhenAll</code> method.</p><a id="pro_id00584"/><pre class="programlisting">let antecedents =
  [|
    new Task(
        fun () -&gt;
          Console.WriteLine("Started first antecedent")
          System.Threading.Thread.Sleep(1000)
          Console.WriteLine("Completed first antecedent"))
    new Task(
        fun () -&gt;
          Console.WriteLine("Started second antecedent")
          System.Threading.Thread.Sleep(1250)
          Console.WriteLine("Completed second antecedent"))
    new Task(
        fun () -&gt;
          Console.WriteLine("Started third antecedent")
          System.Threading.Thread.Sleep(1000)
          Console.WriteLine("Completed third antecedent"))
  |]

let continuation =
  ① Task.Factory.ContinueWhenAll(
    antecedents,
    fun ② (a : Task array) -&gt;
      Console.WriteLine("Started continuation")
      for x in a do Console.WriteLine("Antecedent status: {0}", x.Status)
      Console.WriteLine("Completed continuation"))

for a in antecedents do a.Start()

Console.WriteLine("Waiting for continuation")
continuation.Wait()
Console.WriteLine("Done")</pre><p><a id="iddle1226" class="indexterm"/><a id="iddle1992" class="indexterm"/><a id="iddle1994" class="indexterm"/><a id="iddle2002" class="indexterm"/><code class="literal">ContinueWhenAny</code> follows the same pattern as <code class="literal">WaitAny</code>. Here we’ve defined three tasks, which we manually start after creating the continuation at ①.Notice the continuation task’s parameter at ②. Instead of receiving a single antecedent task as you would with <code class="literal">ContinueWith</code> or <code class="literal">ContinueWhenAny</code>, continuations created with <code class="literal">ContinueWhenAll</code> accept an array of tasks. This array contains all of the tasks supplied to <code class="literal">ContinueWhenAll</code> instead of the individual task that caused the continuation to start. This allows you to inspect each antecedent and handle success and failure scenarios as granularly as you need.</p></div><div class="sect3" title="Cancelling Tasks"><div class="titlepage"><div><div><h4 class="title" id="cancelling_tasks">Cancelling Tasks</h4></div></div></div><p>Cancelling a task is fundamentally the same as cancelling a parallel <code class="literal">for</code> loop, but it requires a bit more work because the parallel <code class="literal">for</code> loops handle the cancellation details for you. The following function demonstrates cancelling a task and follows the typical pattern for handling the cancellation:</p><a id="pro_id00585"/><pre class="programlisting">let taskWithCancellation (cancelDelay : int) (taskDelay : int) =
① use tokenSource = new System.Threading.CancellationTokenSource(cancelDelay)
② let token = tokenSource.Token

  try
    let t =
      Task.Factory.StartNew(
        (fun () -&gt;
         ③ token.ThrowIfCancellationRequested()
          printfn "passed cancellation check; waiting"
          System.Threading.Thread.Sleep taskDelay
         ④ token.ThrowIfCancellationRequested()),
         token)
      ⑤ t.Wait()
  with
  | ex -&gt; printfn "%O" ex
  printfn "Done"</pre><p><a id="iddle1110" class="indexterm"/><a id="iddle1113" class="indexterm"/><a id="iddle1115" class="indexterm"/><a id="iddle1690" class="indexterm"/><a id="iddle2005" class="indexterm"/>As with cancelling parallel <code class="literal">for</code> loops, we start by creating a <code class="literal">CancellationTokenSource</code> at ①. For convenience, we then bind the token to a name at ② so we can reference it within the function the task is based upon. Within the task body, the first thing we do at ③ is call the token’s <code class="literal">ThrowIfCancellationRequested</code> method, which interrogates the token’s <code class="literal">Is CancellationRequested</code> property and throws an <code class="literal">OperationCanceledException</code> if that property returns <code class="literal">true</code>. We do this to ensure that no unnecessary work is performed if cancellation was requested when the task was started. When no exception is thrown, execution continues. At ④ we again check for cancellation to avoid a successful task completion. Finally, at ⑤ we wait for the task to complete so we can handle any exceptions thrown by the task.</p></div><div class="sect3" title="Exception Handling"><div class="titlepage"><div><div><h4 class="title" id="exception_handling">Exception Handling</h4></div></div></div><p>Exceptions can be raised by any number of executing tasks at any time. When this happens, we need a way to capture and handle them. In the previous section, we handled the exception in a general manner—by matching any exception and writing it to the console. If you executed the <code class="literal">taskWithCancellation</code> function, you may have noticed that the exception we caught wasn’t an <code class="literal">OperationCanceledException</code> but rather an <code class="literal">AggregateException</code> that included an <code class="literal">OperationCanceledException</code>. The base exception classes aren’t well suited for parallel scenarios because they represent only a single failure. To compensate, a new exception type, <code class="literal">AggregateException</code>, was introduced to allow us to report one or more failures within a single construct.</p><p>Although you certainly could handle an <code class="literal">AggregateException</code> directly, you’ll typically want to find a specific exception within it. For this, the <code class="literal">AggregateException</code> class provides the <code class="literal">Handle</code> method, which iterates over the exceptions contained within its <code class="literal">InnerExceptions</code> collection so you can find the exception you really care about and handle it accordingly.</p><a id="pro_id00586"/><pre class="programlisting">try
  raise (AggregateException(
          NotSupportedException(),
          ArgumentException(),
          AggregateException(
            ArgumentNullException(),
            NotImplementedException())))
with
| :? AggregateException as ex -&gt;
      ex.Handle(
        ① Func&lt;_, _&gt;(
          function
          ② | :? AggregateException as ex1 -&gt;
               ③ ex1.Handle(
                 Func&lt;_, _&gt;(
                   function
                   | :? NotImplementedException as ex2 -&gt; printfn "%O" ex2; true
                   | _ -&gt; true))
               true
           | _ -&gt; true))</pre><p><a id="iddle1111" class="indexterm"/><a id="iddle1112" class="indexterm"/><a id="iddle1114" class="indexterm"/><a id="iddle1116" class="indexterm"/><a id="iddle1177" class="indexterm"/><a id="iddle1179" class="indexterm"/><a id="iddle2123" class="indexterm"/>Handling an <code class="literal">AggregateException</code> follows the familiar exception-handling pattern: We match against the <code class="literal">AggregateException</code> and bind it to the name <code class="literal">ex</code> as you might expect. Inside the handler, we invoke the <code class="literal">Handle</code> method ①, which accepts a <code class="literal">Func&lt;exn, bool&gt;</code> indicating that the supplied function accepts an exception, and return a Boolean value. (To use pattern-matching functions as we’ve done here, we explicitly construct <code class="literal">Func&lt;_, _&gt;</code> instances and allow the compiler to infer the proper type arguments.) Inside the pattern-matching function ②, we detect whether we have a nested <code class="literal">AggregateException</code> and handle it at ③. At each level, we need to return a Boolean value indicating whether the particular exception was handled. If we return <code class="literal">false</code> for any exception, a new <code class="literal">AggregateException</code> which contains the unhandled exception will be raised.</p><p>Handling <code class="literal">AggregateException</code>s like this can get quite cumbersome, complex, and tedious. Fortunately, <code class="literal">AggregateException</code> provides another method, <code class="literal">Flatten</code>, which simplifies error handling by iterating over the <code class="literal">InnerExceptions</code> collection and recursing over each nested <code class="literal">AggregateException</code> to construct a new <code class="literal">AggregateException</code> instance that directly contains all of the exceptions within the source exception’s hierarchy. For example, we can revise the previous example to use <code class="literal">Flatten</code> to simplify the handler, like this:</p><a id="pro_id00587"/><pre class="programlisting">try
  raise (AggregateException(
          NotSupportedException(),
          ArgumentException(),
          AggregateException(
            ArgumentNullException(),
            NotImplementedException())))
with
| :? AggregateException as ex -&gt;
      ex.<span class="strong"><strong>Flatten()</strong></span>.Handle(
        Func&lt;_, _&gt;(
          function
          | :? NotImplementedException as ex2 -&gt; printfn "%O" ex2; true
          | _ -&gt; true))</pre><p>In this revised example, we call <code class="literal">Handle</code> against the flattened <code class="literal">AggregateException</code>. With only one level to process, we can omit the checks for nested <code class="literal">AggregateExceptions</code> and handle the <code class="literal">NotImplementedException</code> directly.</p></div></div></div><div class="sect1" title="Asynchronous workflows"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="asynchronous_workflows">Asynchronous workflows</h2></div></div></div><p>Despite the many improvements that the TPL brings to asynchronous and parallel programming, F# offers its own model, which better matches the functional paradigm emphasized by the language. While it’s sometimes desirable to use the TPL in F# (particularly when working across language boundaries) you’ll often turn to F#’s asynchronous workflows, which are best suited for I/O-based operations.</p><p><a id="iddle1181" class="indexterm"/><a id="iddle1184" class="indexterm"/><a id="iddle1187" class="indexterm"/><a id="iddle1190" class="indexterm"/><a id="iddle1561" class="indexterm"/><a id="iddle1854" class="indexterm"/><a id="iddle2085" class="indexterm"/><span class="emphasis"><em>Asynchronous workflows</em></span> provide a uniform and idiomatic way to compose and execute asynchronous code against the thread pool. Furthermore, their very nature often makes it difficult (if not impossible) to fall into some of the asynchronous traps present even in the TPL.</p><div class="note" title="Note"><h3 class="title"><a id="ch11note05"/>Note</h3><p><span class="emphasis"><em>Like our TPL discussion, this section is intended to give you a basic working knowledge of asynchronous workflows rather than serving as a comprehensive guide.</em></span></p></div><div class="sect2" title="Creating and Starting Asynchronous Workflows"><div class="titlepage"><div><div><h3 class="title" id="creating_and_starting_asynchronous_workf">Creating and Starting Asynchronous Workflows</h3></div></div></div><p>Asynchronous workflows are based on the <code class="literal">Async&lt;'T&gt;</code> class that resides in the <code class="literal">Microsoft.FSharp.Control</code> namespace. This type represents a bit of code you want to run asynchronously, ultimately returning some value. Instead of creating <code class="literal">Async&lt;'T&gt;</code> instances directly, though, we compose them through async expressions much like we compose sequences or queries.</p><p>Async expressions take the following form:</p><p><code class="literal">async {</code> <span class="emphasis"><em>async-expressions</em></span> <code class="literal">}</code></p><p>Here, <span class="emphasis"><em>async-expressions</em></span> represents one or more expressions that will participate in the asynchronous operation. In addition to the standard expressions we’ve seen throughout this book, asynchronous workflows allow you to easily invoke additional workflows and wait for results without blocking through specialized variants of some familiar keywords such as <code class="literal">let</code> and <code class="literal">use</code>. For instance, the <code class="literal">let!</code> keyword invokes an asynchronous workflow and binds the result to a name. Similarly, the <code class="literal">use!</code> keyword invokes an asynchronous workflow that returns a disposable object, binds the result to a name, and disposes of the object when it goes out of scope. It’s also possible to invoke an asynchronous workflow and immediately return the result with the <code class="literal">return!</code> keyword.</p><p>To demonstrate, we’ll turn to the “hello world” example of asynchronous workflows: requesting multiple web pages. To begin, let’s define some functions that encapsulate the logic needed to create an asynchronous page request (note that a similar function, <code class="literal">Http.AsyncRequestString</code>, is available in the <code class="literal">FSharp.Data</code> framework):</p><a id="pro_id00588"/><pre class="programlisting">open System
open System.IO
open System.Net

type StreamReader with
  member x.AsyncReadToEnd () =
    async { do! Async.SwitchToNewThread()
            let content = x.ReadToEnd()
            do! Async.SwitchToThreadPool()
            return content }

let getPage (uri : Uri) =
  async {

  let req = WebRequest.Create uri
  use! response = req.AsyncGetResponse()
  use stream = response.GetResponseStream()
  use reader = new StreamReader(stream)
  return! reader.AsyncReadToEnd()
}</pre><p><a id="iddle1166" class="indexterm"/><a id="iddle1169" class="indexterm"/><a id="iddle1170" class="indexterm"/><a id="iddle1173" class="indexterm"/>After opening the relevant namespaces, we extend the <code class="literal">StreamReader</code> class with a single <code class="literal">AsyncReadToEnd</code> method. This method, adapted from the F# PowerPack, is similar to the existing <code class="literal">ReadToEndAsync</code> method except that instead of using the TPL, it returns an asynchronous workflow that we can evaluate as the final step of the larger workflow in the <code class="literal">getPage</code> function where we describe how to make the page request. The overall flow of the expression is pretty standard: Create a <code class="literal">WebRequest</code>, wait for the response, and then explicitly return the response stream’s contents.</p><div class="note" title="Note"><h3 class="title"><a id="ch11note06"/>Note</h3><p><span class="emphasis"><em>The <code class="literal">AsyncGetResponseMethod</code> is an extension method defined in the F# core library. It conveniently wraps the standard .NET code within another asynchronous workflow, which makes it possible to employ use! and greatly simplifies the code.</em></span></p></div><p>It’s important to recognize that <code class="literal">getPage</code> doesn’t actually execute the request; it merely creates an instance of <code class="literal">Async&lt;string&gt;</code> that represents the request. This allows us to define multiple requests or pass them around to other functions. We can even execute the request multiple times. To execute the request we need to turn to the static <code class="literal">Async</code> class, which you can think of as a controller for asynchronous workflows.</p><p>There are a number of methods for starting an asynchronous workflow. Some common methods are listed in <a class="xref" href="ch11.html#common_async_start_methods" title="Table 11-1. Common Async Start Methods">Table 11-1</a>.</p><div class="table"><a id="common_async_start_methods"/><div class="table-title">Table 11-1. Common Async Start Methods</div><div class="table-contents"><table style="border-collapse: collapse; border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col class="c1"/><col class="c2"/></colgroup><thead><tr><td style="vertical-align: top; border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>Method</p></td><td style="vertical-align: top; border-bottom: 0.5pt solid ; "><p>Description</p></td></tr></thead><tbody><tr><td style="vertical-align: top; border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><code class="literal">RunSynchronously</code></p></td><td style="vertical-align: top; border-bottom: 0.5pt solid ; "><p>Starts an asynchronous workflow and waits for its result.</p></td></tr><tr><td style="vertical-align: top; border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><code class="literal">Start</code></p></td><td style="vertical-align: top; border-bottom: 0.5pt solid ; "><p>Starts an asynchronous workflow but does not wait for a result.</p></td></tr><tr><td style="vertical-align: top; border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><code class="literal">StartImmediate</code></p></td><td style="vertical-align: top; border-bottom: 0.5pt solid ; "><p>Starts an asynchronous workflow immediately using the current thread. Useful for UI updates.</p></td></tr><tr><td style="vertical-align: top; border-right: 0.5pt solid ; "><p><code class="literal">StartWithContinuations</code></p></td><td style="vertical-align: top; "><p>Immediately starts an asynchronous workflow using the current thread, invoking a success, exception, or cancellation continuation depending on how the operation completed.</p></td></tr></tbody></table></div></div><p>The method you choose is largely dependent upon what the workflow does, but you’ll typically use <code class="literal">Start</code> unless your application requires one of the others. The workflow created by the <code class="literal">getPage</code> function returns the result of a web request. Since we’re making the request, we probably don’t want to ignore the result, so we’ll need to wire up a continuation to do something with it. The easiest way to do that is to wrap the call to <code class="literal">getPage</code> inside <a id="iddle1174" class="indexterm"/>another asynchronous expression, passing the result to another function when it completes, and starting the entire workflow with <code class="literal">Start</code>. Here, we call <code class="literal">getPage</code> and print the result:</p><a id="pro_id00589"/><pre class="programlisting">async {
  let! content = Uri "http://nostarch.com" |&gt; getPage
  content.Substring(0, 50) |&gt; printfn "%s" }
|&gt; Async.Start</pre><div class="sidebar"><a id="using_async"/><div class="sidebar-title">Using Async</div><p>The fact that <code class="literal">Async</code> is a static class rather than a module has ramifications for how you interact with it. Rather than providing <code class="literal">let</code>-bound functions as a module would, <code class="literal">Async</code> provides methods, many of which are overloaded primarily to aid in cancellation. Furthermore, <code class="literal">Async</code>’s methods are typically designed with a more object-oriented approach than is typical in the core F# libraries. Accordingly, their parameters are often tupled, making it difficult to use them with pipelining.</p></div><p>Alternatively, we can use the <code class="literal">StartWithContinuations</code> method, which accepts an asynchronous workflow and three functions to invoke when the workflow finishes successfully, raises an exception, or is cancelled, respectively. The following code shows such an approach:</p><a id="pro_id00590"/><pre class="programlisting">Async.StartWithContinuations(
  ① getPage(Uri "http://nostarch.com"),
  ② (fun c -&gt; c.Substring(0, 50) |&gt; printfn "%s..."),
  ③ (printfn "Exception: %O"),
  ④ (fun _ -&gt; printfn "Cancelled")
)</pre><p>When the asynchronous operation ① completes successfully, the success continuation ② is invoked and the first 50 characters from the page source will be printed. Should the operation throw an exception, the exception continuation ③ will execute and print the exception. Finally, if the operation is cancelled, as described in <a class="xref" href="ch11.html#cancelling_asynchronous_workflows" title="Cancelling Asynchronous Workflows">Cancelling Asynchronous Workflows</a>, the cancellation continuation ④ will execute and display a note informing the user of the cancellation.</p><p>Instead of relying on continuations, we can use the <code class="literal">RunSynchronously</code> method and get the result directly, like this:</p><a id="pro_id00591"/><pre class="programlisting">let html =
  Uri "http://nostarch.com"
  |&gt; getPage
  |&gt; Async.RunSynchronously</pre><p><a id="iddle1163" class="indexterm"/><a id="iddle1165" class="indexterm"/><a id="iddle1178" class="indexterm"/>Of course, running a single asynchronous workflow like this defeats the purpose of running it asynchronously because <code class="literal">RunSynchronously</code> waits for the result. Instead, <code class="literal">RunSynchronously</code> is often used in conjunction with <code class="literal">Async.Parallel</code> to run multiple workflows in parallel and wait for all of them to complete. For instance, we can make multiple requests, starting with an array of asynchronous workflows, as follows:</p><a id="pro_id00592"/><pre class="programlisting">open System.Text.RegularExpressions

[| getPage(Uri "http://nostarch.com")
   getPage(Uri "http://microsoft.com")
   getPage(Uri "http://fsharp.org") |]
|&gt; Async.Parallel
|&gt; Async.RunSynchronously
|&gt; Seq.iter (fun c -&gt; let sample = c.Substring(0, 50)
                      Regex.Replace(sample, @"[\r\n]| {2,}", "")
                      |&gt; printfn "%s...")</pre><p>Here, we employ the <code class="literal">Parallel</code> method to combine each of the asynchronous workflows into a single workflow that is then piped to the <code class="literal">RunSynchronously</code> method. When each of the requests has completed, we iterate over the resulting array, stripping a few characters from the content for readability and printing the result.</p></div><div class="sect2" title="Cancelling Asynchronous Workflows"><div class="titlepage"><div><div><h3 class="title" id="cancelling_asynchronous_workflows">Cancelling Asynchronous Workflows</h3></div></div></div><p>In the previous section I indicated that asynchronous workflows can be cancelled. Just as in the TPL, asynchronous workflows use cancellation tokens to control cancellation. It’s possible, and sometimes even necessary, to manage tokens on your own, but in many cases you can rely on the <code class="literal">Async</code> class’s default token.</p><p>For simple scenarios, such as when you’re starting a single work-flow via the <code class="literal">Start</code> or <code class="literal">StartWithContinuations</code> methods, you can use the <code class="literal">CancelDefaultToken</code> method to cancel the workflow, like this:</p><a id="pro_id00593"/><pre class="programlisting">① Async.StartWithContinuations(
    getPage(Uri "http://nostarch.com"),
    (fun c -&gt; c.Substring(0, 50) |&gt; printfn "%s..."),
    (printfn "Exception: %O"),
    (fun _ -&gt; printfn "Cancelled")
  )

② Async.CancelDefaultToken()</pre><p>The <code class="literal">StartWithContinuations</code> method ① monitors the default token and cancels the workflow when the token is marked as cancelled via the <code class="literal">CancelDefaultToken</code> method ②. In this example, because the workflow is cancelled before it completes, the cancellation callback is invoked instead of the success callback, resulting in the cancellation message being displayed.</p><p><a id="iddle1171" class="indexterm"/><a id="iddle1175" class="indexterm"/><a id="iddle1227" class="indexterm"/>The <code class="literal">TryCancelled</code> method, which accepts a workflow and a function that will be invoked when cancellation is requested, is a nice alternative for work-flows that don’t return a value. Here, the <code class="literal">displayPartialPage</code> function wraps a call to <code class="literal">getPage</code> within another asynchronous workflow. The outer workflow waits for the response and writes out the first 50 characters when the message is received. Because <code class="literal">TryCancelled</code> returns yet another workflow and doesn’t automatically start it, we need to explicitly do so with a call to <code class="literal">Start</code>.</p><a id="pro_id00594"/><pre class="programlisting">let displayPartialPage uri =
  Async.TryCancelled(
    async {
      let! c = getPage uri
      Regex.Replace(c.Substring(0, 50), @"[\r\n]| {2,}", "")
      |&gt; sprintf "[%O] %s..." uri
      |&gt; Console.WriteLine },
    (sprintf "[%O] Cancelled: %O" uri &gt;&gt; Console.WriteLine))

Async.Start(displayPartialPage (Uri "http://nostarch.com"))

Async.CancelDefaultToken()</pre><p>The default token is often sufficient for cancelling workflows. When you’re executing multiple workflows and want to coordinate cancellation or if you want more control over cancellation, you can supply your own. Consider what happens when you request three pages but request cancellation with the default token.</p><a id="pro_id00595"/><pre class="programlisting">[| Uri "http://nostarch.com"
   Uri "http://microsoft.com"
   Uri "http://fsharp.org" |]
|&gt; Array.iter (fun u -&gt; Async.Start(displayPartialPage u))

Async.CancelDefaultToken()</pre><p>Executing the preceding code usually results in all three workflows being cancelled. (Usually, but not always, because there’s a chance that one or more workflows complete before the cancellation is handled.) To isolate each workflow’s cancellation, we can use an overload of the <code class="literal">Start</code> method that accepts a user-specified token, like this:</p><a id="pro_id00596"/><pre class="programlisting">  open System.Threading

  let tokens =
    [| Uri "http://nostarch.com"
       Uri "http://didacticcode.com"
       Uri "http://fsharp.org" |]
    |&gt; Array.map (fun u -&gt; ① let ts = new CancellationTokenSource()
                           Async.Start(displayPartialPage u, ② ts.Token)
                           ts)
③ tokens.[0].Cancel()
④ tokens.[1].Cancel()</pre><p><a id="iddle1164" class="indexterm"/><a id="iddle1180" class="indexterm"/>In this revised version, we use <code class="literal">Array.map</code> to map each <code class="literal">Uri</code> to a workflow with its own <code class="literal">CancellationTokenSource</code> created at ①. We then pass the associated token to <code class="literal">Async.Start</code> as the second argument ② before returning the <code class="literal">CancellationTokenSource</code>. Finally, at ③ and ④, respectively, we request cancellation of the first and second requests, allowing the third to proceed as normal.</p><p>What’s especially nice about cancelling asynchronous workflows is that, unlike the TPL, cancellation tokens are propagated through the entire workflow automatically. This means that you don’t have to manually ensure that each new workflow is given a token, leaving you with cleaner code.</p></div><div class="sect2" title="Exception Handling"><div class="titlepage"><div><div><h3 class="title" id="exception_handling-id00017">Exception Handling</h3></div></div></div><p>Because exceptions can and do occur within asynchronous workflows, it’s important to know how to handle them properly. There are a few exception-handling options available, but their utility may vary depending on what you’re doing.</p><p>The most uniform way to handle exceptions in an asynchronous work-flow is to wrap the potentially offending code inside a <code class="literal">try...with</code> block within the async expression. For instance, we can provide a version of our <code class="literal">getPage</code> function that handles exceptions raised during the page request and read, like this:</p><a id="pro_id00597"/><pre class="programlisting">let getPageSafe uri =
  async {
    try
      let! content = getPage uri
      return Some content
    with
    | :? NotSupportedException as ex -&gt;
      Console.WriteLine "Caught NotSupportedException"
      return None
    | :? OutOfMemoryException as ex -&gt;
      Console.WriteLine "Caught OutOfMemoryException"
      return None
    | ex -&gt;
      ex |&gt; sprintf "Caught general exception: %O" |&gt; Console.WriteLine
      return None }</pre><p>There’s nothing unusual about the <code class="literal">try...with</code> block in the preceding code—we simply wrap the asynchronous call to <code class="literal">getPage</code> in the <code class="literal">try...with</code> block and return a successful read as an option. Should the operation raise an exception, we match the exception type, print a message, and return <code class="literal">None</code>.</p><p>Another way to handle exceptions from asynchronous workflows is the <code class="literal">Async.Catch</code> method. <code class="literal">Async.Catch</code> takes a more functional approach than <code class="literal">StartWithContinuations</code> in that rather than accepting an exception-handling function, it returns <code class="literal">Choice&lt;'T, exn&gt;</code>, where <code class="literal">'T</code> is the asynchronous workflow’s return type and <code class="literal">exn</code> is the exception thrown by the workflow.</p><p><a id="iddle1162" class="indexterm"/><a id="iddle1167" class="indexterm"/><a id="iddle1168" class="indexterm"/><a id="iddle1186" class="indexterm"/><a id="iddle1230" class="indexterm"/>The <code class="literal">Choice</code> type is a discriminated union with two union cases: <code class="literal">Choice1Of2</code> and <code class="literal">Choice2Of2</code>. For <code class="literal">Async.Catch</code>, <code class="literal">Choice1Of2</code> represents successful completion of the workflow and contains the result, whereas <code class="literal">Choice2Of2</code> represents failure and contains the first raised exception.</p><p>Handling exceptions with <code class="literal">Async.Catch</code> lets you structure your asynchronous code to create an idiomatic, pipelined data flow. For example, the following code shows how we can model an asynchronous operation as a series of function applications, beginning with a <code class="literal">Uri</code>.</p><a id="pro_id00598"/><pre class="programlisting">Uri "http://nostarch.com"
|&gt; getPage
|&gt; Async.Catch
|&gt; Async.RunSynchronously
|&gt; function
   | Choice1Of2 result -&gt; Some result
   | Choice2Of2 ex -&gt;
      match ex with
      | :? NotSupportedException -&gt;
        Console.WriteLine "Caught NotSupportedException"
      | :? OutOfMemoryException -&gt;
        Console.WriteLine "Caught OutOfMemoryException"
      | ex -&gt;
        ex.Message |&gt; sprintf "Exception: %s" |&gt; Console.WriteLine
      None</pre><p>Here, a <code class="literal">Uri</code> is piped into the <code class="literal">getPage</code> function to create an asynchronous workflow. The resulting workflow is piped into <code class="literal">Async.Catch</code> to set up another workflow, which we then pipe to <code class="literal">Async.RunSynchronously</code> so we can wait for the result. Finally, we pipe the <code class="literal">Choice</code> into a pattern-matching function where we either return <code class="literal">Some result</code> or handle the exception before returning <code class="literal">None</code>.</p></div><div class="sect2" title="Asynchronous Workflows and the Task Parallel Library"><div class="titlepage"><div><div><h3 class="title" id="asynchronous_workflows_and_the_task_para">Asynchronous Workflows and the Task Parallel Library</h3></div></div></div><p>In addition to the <code class="literal">ThreadPool</code>-based asynchronous operations we’ve seen so far, the <code class="literal">Async</code> class provides a few methods for working with TPL tasks. Most notable among them are <code class="literal">StartAsTask</code> and <code class="literal">AwaitTask</code>.</p><p>The <code class="literal">StartAsTask</code> method invokes an asynchronous workflow as a TPL task. You would typically use this for CPU-bound operations or to expose an asynchronous workflow to code using the TPL in C# or Visual Basic. For instance, we can treat the result of our <code class="literal">getPage</code> function as a TPL task like this:</p><a id="pro_id00599"/><pre class="programlisting">Uri "http://nostarch.com"
|&gt; getPage
|&gt; Async.StartAsTask
|&gt; (fun t -&gt; ① t.Result.Substring(0, 50))
|&gt; printfn "%s"</pre><p>The presence of the <code class="literal">Result</code> property at ① indicates that the result of <code class="literal">StartAsTask</code> is indeed a <code class="literal">Task</code>. In a more real-world scenario, you likely wouldn’t fire off a task and immediately block by waiting for the result, <a id="iddle1172" class="indexterm"/><a id="iddle1182" class="indexterm"/><a id="iddle1185" class="indexterm"/><a id="iddle1188" class="indexterm"/><a id="iddle1196" class="indexterm"/><a id="iddle2001" class="indexterm"/><a id="iddle2020" class="indexterm"/>but this example is intended only to show how to start an asynchronous workflow as a TPL <code class="literal">Task</code>.</p><p>The <code class="literal">StartAsTask</code> method is handy when you need to create a new task, but what about when you need to handle an existing task? Consider the <code class="literal">DownloadStringTaskAsync</code> method added to the <code class="literal">System.Net.WebClient</code> class in .NET 4.5. This method serves the same purpose as our <code class="literal">getPage</code> function except that it encapsulates downloading a resource within a TPL task.</p><p>In C#, you can easily handle such methods with the <code class="literal">async</code> modifier and <code class="literal">await</code> operator, as shown here:</p><a id="pro_id00600"/><pre class="programlisting">// C#
// using System.Threading.Tasks

private static ① async Task&lt;string&gt; GetPageAsync(string uri)
{
    using (var client = new System.Net.WebClient())
    {
      return ② await client.DownloadStringTaskAsync(uri);
    }
}

static void Main()
{
    var result = GetPageAsync("http://nostarch.com").Result;
    Console.WriteLine("{0}", result.Substring(0, 50));
    Console.ReadLine();
}</pre><p>From a greatly simplified perspective, what happens in the preceding C# code is this: The <code class="literal">async</code> modifier ① is applied to the <code class="literal">GetPageAsync</code> method to signify that part of the method will run asynchronously. The <code class="literal">await</code> operator ② then signifies that execution should return to the caller and the remainder of the method should be treated as a continuation to be executed when the task completes.</p><p>Asynchronous workflows allow us to follow a similar pattern in F# using the <code class="literal">AwaitTask</code> method in combination with a TPL task and <code class="literal">let!</code>, <code class="literal">use!</code>, or <code class="literal">return!</code>. Here is the corresponding code in F#:</p><a id="pro_id00601"/><pre class="programlisting">// F#
open System.Threading.Tasks

let getPageAsync (uri : string) =
  async {
    use client = new System.Net.WebClient()
  ① return! Async.AwaitTask (client.DownloadStringTaskAsync uri)
  }

async {
② let! result = getPageAsync "http://nostarch.com"
  result.Substring(0, 50) |&gt; printfn "%s"
} |&gt; Async.Start</pre><p><a id="iddle1102" class="indexterm"/><a id="iddle1109" class="indexterm"/><a id="iddle1183" class="indexterm"/><a id="iddle1603" class="indexterm"/><a id="iddle1612" class="indexterm"/>Although they’re not quite functionally equivalent (the C# version waits for the result in <code class="literal">Main</code> while the F# version passes the result to a continuation), the F# approach is similar to that of C#. In the F# version, the asynchronous workflow created by the <code class="literal">getPageAsync</code> function uses <code class="literal">return!</code> and <code class="literal">Async.AwaitTask</code> ① to wait for the task to complete before returning the result. Then, in the second asynchronous workflow, <code class="literal">let!</code> ② is used to evaluate <code class="literal">getPageAsync</code>, while printing the result is treated as a continuation.</p></div></div><div class="sect1" title="Agent-Based Programming"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="agent-based_programming">Agent-Based Programming</h2></div></div></div><p>As if the TPL and asynchronous workflows didn’t make parallel and asynchronous programming accessible enough, F# has borrowed a message-processing mechanism from Erlang. The <code class="literal">MailboxProcessor&lt;'T&gt;</code> class implements a queue-based system for asynchronously routing messages (data items) to handlers using shared memory. This is especially useful in scenarios where multiple sources (clients) need to request something from a single target (server), the canonical example being a web server. Furthermore, because <code class="literal">MailboxProcessor</code> instances are extremely lightweight, an application can manage thousands of them without breaking a sweat. This fact enables mailbox processors to work independently or together by passing messages between instances.</p><p><code class="literal">MailboxProcessor</code> instances are usually referred to as <span class="emphasis"><em>agents</em></span>, and I’ll follow this convention throughout this section. In that regard, a common practice in agent-based programming is to alias <code class="literal">MailboxProcessor&lt;'T&gt;</code> as <code class="literal">Agent&lt;'T&gt;</code>as follows:</p><a id="pro_id00602"/><pre class="programlisting">type Agent&lt;'T&gt; = MailboxProcessor&lt;'T&gt;</pre><p>With the type aliased, we can create agents using the more convenient name.</p><div class="sect2" title="Getting Started"><div class="titlepage"><div><div><h3 class="title" id="getting_started">Getting Started</h3></div></div></div><p>I think the best way to understand agent-based programming is with an example. We’ll start with a simple agent that simply prints whatever is sent into it.</p><a id="pro_id00603"/><pre class="programlisting">type Message = | Message of obj

let echoAgent =
① Agent&lt;Message&gt;.Start(
    fun inbox -&gt;
    ② let rec loop () =
        async {
          let! (Message(content)) =  ③ inbox.Receive()
          printfn "%O" content
        ④ return! loop()}
    ⑤ loop())</pre><p><a id="iddle1104" class="indexterm"/><a id="iddle1106" class="indexterm"/><a id="iddle1107" class="indexterm"/><a id="iddle1108" class="indexterm"/><a id="iddle1606" class="indexterm"/><a id="iddle1608" class="indexterm"/><a id="iddle1611" class="indexterm"/>In the preceding code, we create an agent called <code class="literal">echoAgent</code> by passing a function to the <code class="literal">Start</code> method as shown at ①. By convention, the function’s parameter is called <code class="literal">inbox</code> because it’s the <span class="emphasis"><em>mailbox</em></span> from which we’ll receive new messages. At ② we define the recursive <code class="literal">loop</code> function, which we’ll call continually to receive new messages.</p><div class="note" title="Note"><h3 class="title"><a id="ch11note07"/>Note</h3><p><span class="emphasis"><em>It’s certainly possible to loop imperatively using a while loop, but the recursive function is the more typical approach. Functional loops provide the additional benefit of easily allowing you to provide different looping logic when you need to manage multiple states. For instance, if your agent needs to behave differently in a paused state than a running state, you could define a pair of mutually recursive functions that both return a workflow that handles the corresponding state accordingly.</em></span></p></div><p>Inside the loop, we create an asynchronous workflow that first asynchronously receives a message from <code class="literal">inbox</code> using the <code class="literal">Receive</code> method as shown at ③.Next, the received message is printed before making an asynchronous recursive call to <code class="literal">loop</code> at ④. Finally, at ⑤ we initiate recursion by making a standard, synchronous call to <code class="literal">loop</code>.</p><p>With <code class="literal">echoAgent</code> actively listening, we can send it some messages via the <code class="literal">Post</code> method, like this:</p><a id="pro_id00604"/><pre class="programlisting">&gt; <span class="strong"><strong>Message "nuqneH" |&gt; echoAgent.Post;;</strong></span>
nuqneH
&gt; <span class="strong"><strong>Message 123 |&gt; echoAgent.Post;;</strong></span>
123
&gt; <span class="strong"><strong>Message [ 1; 2; 3 ] |&gt; echoAgent.Post;;</strong></span>
[1; 2; 3]</pre><p>As you can see, when <code class="literal">echoAgent</code> receives a message, it is written to the console and then <code class="literal">echoAgent</code> waits for another message, and the process repeats ad infinitum.</p></div><div class="sect2" title="Scanning for Messages"><div class="titlepage"><div><div><h3 class="title" id="scanning_for_messages">Scanning for Messages</h3></div></div></div><p>In the <code class="literal">echoAgent</code> example, we used the <code class="literal">Receive</code> method to get messages from the underlying queue. In many cases, <code class="literal">Receive</code> is appropriate, but it makes it difficult to filter messages because it removes them from the queue. To selectively process messages, you might consider using the <code class="literal">Scan</code> method instead.</p><p>Scanning for messages follows a different pattern than receiving them directly. Rather than processing the messages inline and always returning an asynchronous workflow, the <code class="literal">Scan</code> method accepts a filtering function that accepts a message and returns an <code class="literal">Async&lt;'T&gt;</code> option. In other words, when the message is something you want to process, you return <code class="literal">Some&lt;Async&lt;'T&gt;</code>; otherwise, you return <code class="literal">None</code>. To demonstrate, let’s revise the <code class="literal">echoAgent</code> to process only strings and integers.</p><a id="pro_id00605"/><pre class="programlisting">let echoAgent2 =
  Agent&lt;Message&gt;.Start(fun inbox -&gt;
    let rec loop () =
      inbox.Scan(fun (Message(x)) -&gt;
       match x with
       | ① :? string
       | ② :? int -&gt;
         Some (async { printfn "%O" x
                       return! loop() })
       | _ -&gt; printfn "&lt;not handled&gt;"; None)
   loop())</pre><p><a id="iddle1103" class="indexterm"/><a id="iddle1105" class="indexterm"/><a id="iddle1189" class="indexterm"/><a id="iddle1604" class="indexterm"/><a id="iddle1607" class="indexterm"/><a id="iddle1609" class="indexterm"/>At ① and ② you can see standard dynamic type-test patterns used to filter incoming messages to strings and integers, respectively. When the message is one of those two types, we associate an asynchronous workflow with <code class="literal">Some</code> and return it. For all other messages, we return <code class="literal">None</code>. <code class="literal">Scan</code> the nexamines the returned value, and when it is <code class="literal">Some</code>, the message is consumed(removed from the queue) and the workflow is invoked. When the returned value is <code class="literal">None</code>, <code class="literal">Scan</code> immediately waits for another message.</p><p>Passing messages to <code class="literal">echoAgent2</code> is the same as before—just pass the messages via the <code class="literal">Post</code> method:</p><a id="pro_id00606"/><pre class="programlisting">&gt; <span class="strong"><strong>Message "nuqneH" |&gt; echoAgent2.Post;;</strong></span>
nuqneH
&gt; <span class="strong"><strong>Message 123 |&gt; echoAgent2.Post;;</strong></span>
123
&gt; <span class="strong"><strong>Message [ 1; 2; 3 ] |&gt; echoAgent2.Post;;</strong></span>
&lt;not handled&gt;</pre><p>Scanning for messages does offer some flexibility with how you process messages, but you need to be mindful of what you’re posting to the agent because messages not processed by <code class="literal">Scan</code> remain in the queue. As the queue size increases, scans will take longer to complete, so you can quickly run into performance issues using this approach if you’re not careful. You can see how many messages are in the queue at any time by inspecting the <code class="literal">CurrentQueueLength</code> property. If you need to remove messages from the queue, you can do so by invoking <code class="literal">Receive</code> for each message in the queue, but needing to do so is probably indicative of a larger design problem that should be addressed.</p></div><div class="sect2" title="Replying to Messages"><div class="titlepage"><div><div><h3 class="title" id="replying_to_messages">Replying to Messages</h3></div></div></div><p>The agents we’ve created so far have been self-contained: They receive a message, do something with it, and wait for another message. Agents don’t have to work in isolation, though. One way you can make agents more interactive is by having them reply via an <code class="literal">AsyncReplyChannel</code>. To demonstrate, let’s revise <code class="literal">echoAgent</code> again, but this time, instead of printing a message within the agent, we’ll have it reply.</p><a id="pro_id00607"/><pre class="programlisting">① type ReplyMessage = | ReplyMessage of obj * AsyncReplyChannel&lt;obj&gt;

  let echoAgent3 =
    Agent.Start(fun inbox -&gt;
      let rec loop () =
        async {
          let! ② (ReplyMessage(m, c)) = inbox.Receive()
          ③ c.Reply m
          return! loop()
      }
    loop())</pre><p><a id="iddle1605" class="indexterm"/><a id="iddle1610" class="indexterm"/>The overall structure of <code class="literal">echoAgent3</code> doesn’t differ much from the previous versions. For convenience, we’re using a discriminated union ① for our message type as is typical in agent-based programming. In this case, the <code class="literal">ReplyMessage</code> union type has a single case with two associated values, an object and the reply channel.</p><p>Inside the loop body, we use pattern matching ② to identify the union case and extract the message and channel. We then pass the message to the channel’s <code class="literal">Reply</code> method ③ before repeating. Now all that’s left is to send a message to the agent.</p><p><code class="literal">ReplyMessage</code>’s second value is an <code class="literal">AsyncReplyChannel&lt;obj&gt;</code>, as you’ve already seen. In theory we could manually construct a reply channel and send the <code class="literal">ReplyMessage</code> to the agent with the <code class="literal">Post</code> method, but then we’d have to handle waiting for the result manually. There are much better ways to get the reply channel—namely, the <code class="literal">PostAndReply</code> method and its variants.</p><p>The <code class="literal">PostAndReply</code> methods differ a bit from <code class="literal">Post</code> in that, instead of accepting the message directly, they are higher-order functions that accept a function that takes in a preconstructed reply channel and returns the fully constructed method. For our purposes, we’ll simply create a <code class="literal">ReplyMessage</code> like this:</p><a id="pro_id00608"/><pre class="programlisting">echoAgent3.PostAndReply(fun c -&gt; ReplyMessage("hello", c))
|&gt; printfn "Response: %O"</pre><p>Internally, <code class="literal">PostAndReply</code> (and its variants) construct reply channels that they pass on to the supplied function, which then creates the message that is ultimately posted to the agent.</p></div><div class="sect2" title="Example: Agent-Based Calculator"><div class="titlepage"><div><div><h3 class="title" id="example_agent-based_calculator">Example: Agent-Based Calculator</h3></div></div></div><p>Now that you’ve seen a variety of ways to create and interact with agents, let’s look at a more interesting example that ties together several of the concepts for something a bit more useful than simply regurgitating its input: an agent-based calculator. We’ll begin by defining a discriminated union that represents the messages the calculator will support.</p><a id="pro_id00609"/><pre class="programlisting">type Operation =
| Add of float
| Subtract of float
| Multiply of float
| Divide of float
| Clear
| Current of AsyncReplyChannel&lt;float&gt;</pre><p>The <code class="literal">Operation</code> union type defines six cases. Of those, four represent basic mathematical operations and have an associated <code class="literal">float</code> that is used in the calculation. The <code class="literal">Clear</code> case allows us to clear the stored value. Finally, the <code class="literal">Current</code> case lets us interrogate the agent for its current value using its associated reply channel. From this definition, we can create a new agent that handles each case as follows:</p><a id="pro_id00610"/><pre class="programlisting">let calcAgent =
  Agent.Start(fun inbox -&gt;
   let rec loop total =
     async {
       let! msg = inbox.Receive()
       let newValue =
         match msg with
         | Add x -&gt; total + x
         | Subtract x -&gt; total - x
         | Multiply x -&gt; total * x
         | Divide x -&gt; total / x
         | Clear -&gt; 0.0
         | Current channel -&gt;
           channel.Reply total
           total
       return! loop newValue }
   loop 0.0)</pre><p>Even though <code class="literal">calcAgent</code> appears to keep a running total, it is a bit of an illusion in that we keep state only by passing a value (<code class="literal">total</code>) to the recursive <code class="literal">loop</code> function. When <code class="literal">calcAgent</code> receives a message, it uses pattern matching to determine the appropriate action, binding the result to <code class="literal">newValue</code>. For instance, when it receives an <code class="literal">Add</code>, <code class="literal">Subtract</code>, <code class="literal">Multiply</code>, or <code class="literal">Divide</code> operation, it applies the corresponding mathematical operation to <code class="literal">total</code>. Similarly, when it receives a <code class="literal">Clear</code> operation, it simply returns <code class="literal">0.0</code> and <code class="literal">Current</code> returns <code class="literal">total</code> after replying.</p><p>To see <code class="literal">calcAgent</code> in action, we just need to send it some messages:</p><a id="pro_id00611"/><pre class="programlisting">[ Add 10.0
  Subtract 5.0
  Multiply 10.0
  Divide 2.0 ]
|&gt; List.iter (calcAgent.Post)

calcAgent.PostAndReply(Current) |&gt; printfn "Result: %f"
calcAgent.Post(Clear)
calcAgent.PostAndReply(Current) |&gt; printfn "Result: %f"</pre><p>In the preceding snippet, we simply pass a list of <code class="literal">Operations</code> to <code class="literal">List.iter</code>, posting each message to <code class="literal">calcAgent</code>. When those have been processed, we query for the current value, clear, and then query again to ensure that the total has been zeroed out. Invoking the preceding snippet results in the following:</p><a id="pro_id00612"/><pre class="programlisting">Result: 25.000000
Result: 0.000000</pre></div></div><div class="sect1" title="Summary"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="summary-id00018">Summary</h2></div></div></div><p>Asynchronous and parallel programming have long been viewed as tools for specialized software and reserved for experienced developers. With processor manufacturers improving processor performance by adding cores instead of increasing clock speed, software developers can no longer solve performance issues solely by upgrading hardware, nor can they continue expecting users to wait for long-running operations to complete before returning control.</p><p>Languages such as F# make asynchronous and parallel programming more accessible by providing multiple, robust mechanisms. The TPL makes it easy for developers to efficiently handle CPU-bound operations such as processing large data sets while effectively using available system resources. Language features such as asynchronous workflows excel at keeping applications responsive during IO-based operations such as web requests or file accesses. Finally, agent-based programming lets you easily coordinate complex systems by firing off individual asynchronous processes without having to directly manage the complexity of traditional thread-based models. Together, these approaches help you build scalable, responsive applications that meet the demands of modern computing while keeping you focused on the actual problems your software is trying to solve.</p></div></section></body></html>