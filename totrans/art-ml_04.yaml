- en: '**3'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3'
- en: BIAS, VARIANCE, OVERFITTING, AND CROSS-VALIDATION**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差、方差、过拟合与交叉验证**
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: We now look in detail at a vital topic touched on in [Sections 1.7](ch01.xhtml#ch01lev7),
    [1.12.4](ch01.xhtml#ch01lev12sec4), and [2.2.5](ch02.xhtml#ch02lev2sec5)—overfitting.
    In this chapter, we’ll explain what bias and variance really mean in ML contexts
    and how they affect overfitting. We’ll then cover a popular approach to avoiding
    overfitting known as *cross-validation*.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们详细探讨在[第1.7节](ch01.xhtml#ch01lev7)、[第1.12.4节](ch01.xhtml#ch01lev12sec4)和[第2.2.5节](ch02.xhtml#ch02lev2sec5)中提到的一个重要话题——过拟合。在本章中，我们将解释偏差和方差在机器学习中的真正含义，以及它们如何影响过拟合。接着，我们将介绍一种常用的避免过拟合的方法，称为
    *交叉验证*。
- en: 'The problem of overfitting exemplifies the point made in the title of this
    book: ML is an art, not a science. There is no formulaic solution to various problems,
    especially overfitting. Professor Yaser Abu-Mostafa of Caltech, a prominent ML
    figure, once summed it up: “The ability to avoid overfitting is what separates
    professionals from amateurs in ML.”^([1](footnote.xhtml#ch3fn1)) And my Google
    query on “overfitting” yielded 6,560,000 results!'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合的问题恰好阐明了本书标题中提到的观点：机器学习是一门艺术，而非科学。对于各种问题，尤其是过拟合，没有固定的公式解法。加州理工大学的著名机器学习专家
    Yaser Abu-Mostafa 教授曾总结道：“避免过拟合的能力是区分专业人士与业余爱好者的关键。”^([1](footnote.xhtml#ch3fn1))
    而我在谷歌上查询“过拟合”时，得到了 6,560,000 个结果！
- en: Don’t be intimidated. The professor is correct, but avoiding overfitting is
    not difficult, provided one has a good understanding of bias and variance. One
    uses this understanding and gains skill through experience.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 不要被吓到。教授是对的，但只要对偏差和方差有充分的理解，避免过拟合并不困难。掌握这一点，并通过实践积累经验，就能做到。
- en: 3.1 Overfitting and Underfitting
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 过拟合与欠拟合
- en: So, what is all the fuss about overfitting? We’ve given a hint here and there
    in earlier chapters. Now let’s go into the topic in depth.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，过拟合究竟是怎么一回事呢？我们在之前的章节中已经稍微提到了这个话题。现在，让我们深入探讨这个问题。
- en: Recall our discussion in [Section 1.7](ch01.xhtml#ch01lev7) of the Bias-Variance
    Trade-off involved in choosing hyperparameter values, specifically the value *k*
    in k-NN. Once again, let’s take the bike sharing data ([Section 1.1](ch01.xhtml#ch01lev1))
    as our motivating example. As before, say we wish to predict ridership, such as
    for a day in which the temperature is 28 degrees. We will look at the days in
    our data with temperatures nearest to 28\. Our predicted value will be the average
    ridership among those days.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 回想我们在[第1.7节](ch01.xhtml#ch01lev7)中关于偏差-方差权衡的讨论，尤其是选择超参数值时的讨论，具体来说，就是在 k-NN 中选择
    *k* 的值。我们再次以共享单车数据（[第1.1节](ch01.xhtml#ch01lev1)）为例来说明。假设我们想预测骑行量，例如某一天的温度为 28
    度。我们将查看数据中温度最接近 28 的几天。这些天的平均骑行量将作为我们的预测值。
- en: 'Say we take *k* = 5\. Even those outside the technology world might intuitively
    feel that a value of 5 for *k* is “too small a sample.” There is too much variability
    in ridership from one set of 5 days to another, even if their temperatures are
    near 28\. If we had a sample from a different set of 731 days than the one we
    have, we’d have a different set of 5 closest days to 28, with a different average
    ridership. With *k* = 50, a lot of high and low ridership values would largely
    cancel out during the averaging process, but not so with just *k* = 5\. This argues
    for choosing a larger value than 5 for *k*. This is a *variance* issue: choosing
    too small a value for *k* brings us too much sampling variability.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们取 *k* = 5\. 即使是那些不在科技领域的人，也可能直观地感觉到 *k* 为 5 的值是“样本量太小”。即便它们的温度接近 28，5 天的骑行量也会有太多变动。如果我们从一个不同的731天数据集中获取样本，而不是我们当前拥有的数据集，我们将得到一组不同的
    5 天，温度接近 28，且对应的平均骑行量也会不同。使用 *k* = 50 时，高骑行量和低骑行量的数据在平均过程中会大致相互抵消，但如果仅使用 *k* =
    5，则不会出现这种情况。这表明我们应选择一个大于 5 的 *k* 值。这是一个 *方差* 问题：选择过小的 *k* 值会导致过多的抽样变异性。
- en: 'On the other hand, if we use, say, the *k* = 25 days with temperatures closest
    to 28, we risk getting some days whose temperatures are rather far from 28\. Say,
    for instance, the 25th-closest day had a temperature of 35\. People do not want
    to ride bikes in such hot weather. If we include too many hot days in our prediction
    for the 28-degree day, we will have a tendency to underpredict the true ridership.
    In such a situation, *k* = 25 may be too large. That’s a *bias* issue: choosing
    too large a value of *k* may induce a systemic tendency to underpredict or overpredict.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们使用例如 *k* = 25 天，并选择温度最接近 28 度的日子，我们就有可能得到一些温度远离 28 度的日子。例如，第 25 个最接近的日子可能温度是
    35 度。在如此炎热的天气下，人们不愿骑车。如果我们在预测 28 度那天的骑行人数时包含了过多的高温天气，可能会倾向于低估真正的骑行人数。在这种情况下，*k*
    = 25 可能太大了。这是一个 *偏差* 问题：选择过大的 *k* 值可能会引入系统性低估或高估的倾向。
- en: '**NOTE**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*We’ll repeatedly mention variance and bias in this chapter and in later ones.
    It’s important to keep in mind what quantity’s variance and bias is under discussion:
    predicted values. Say we are predicting ridership for a 28-degree day. The larger
    the value of* k *we use, the lesser the variability in our predicted value, but
    the greater the bias of that value.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们将在本章及后续章节中反复提到方差和偏差。需要记住的是，讨论的是哪种量的方差和偏差：预测值。假设我们在预测 28 度那天的骑行人数。我们使用的 *k*
    值越大，预测值的变异性就越小，但该值的偏差却越大。*'
- en: Variance and bias are at odds with each other. For a given dataset, we can reduce
    one only at the expense of the other. This trade-off is central to choosing the
    values of hyperparameters, as well as choosing which features to use. Using too
    small a *k*—trying to reduce bias below what is possible on this data—is called
    *overfitting*. Using too large a *k*—an overly conservative one—is called *underfitting*.
    We hope to choose our hyperparameter values in the “sweet spot,” neither overfitting
    nor underfitting.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 方差和偏差是相互对立的。对于给定的数据集，我们只能通过牺牲其中一个来减少另一个。这种权衡对于选择超参数的值以及选择哪些特征使用至关重要。使用过小的 *k*
    值——试图将偏差减少到该数据上无法实现的程度——叫做 *过拟合*。使用过大的 *k* 值——过于保守的值——叫做 *欠拟合*。我们希望在“甜点区”选择超参数值，既不发生过拟合也不发生欠拟合。
- en: '***3.1.1 Intuition Regarding the Number of Features and Overfitting***'
  id: totrans-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***3.1.1 特征数量与过拟合的直觉解释***'
- en: 'A similar statement holds for features: using too large a value for *p* (that
    is, the number of features) results in overfitting, while using too small a value
    gives us underfitting. Here is the intuition behind this.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特征也有类似的情况：使用过大的 *p* 值（即特征的数量）会导致过拟合，而使用过小的值则会导致欠拟合。这里是这一现象的直觉解释。
- en: Recall `mlb`, the dataset on Major League Baseball players (in [Section 1.8](ch01.xhtml#ch01lev8)).
    We might predict weight from height and age. But what if we were to omit height
    from our feature set? That would induce a bias. Roughly speaking, we’d be tacitly
    assuming everyone is of middling height, which would result in our tending to
    overpredict the weight of shorter players while underpredicting that of the taller
    ones.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下 `mlb` 数据集，关于美国职业棒球大联盟球员的数据（见 [第 1.8 节](ch01.xhtml#ch01lev8)）。我们可能根据身高和年龄预测体重。但如果我们从特征集中省略身高呢？那就会引入偏差。大致来说，我们会默许每个人的身高都是中等的，这样会导致我们倾向于高估较矮球员的体重，同时低估较高球员的体重。
- en: On the other hand, it turns out that the more predictors we use (in general,
    not just for this data), the higher the variance of our predicted values. To see
    this, say we are conducting a marketing study, predicting purchases of winter
    parkas, and wish to account for geography of customers. There are about 42,000
    ZIP codes (US postal codes). Say we use ZIP code as one of our features in predicting
    purchases. We would then have 42,000 dummy variables and would have other features
    such as age, gender, and income, or *p* > 42000\. If our data consists of, say,
    100,000 customers, we would have on average only 2 or 3 data points per ZIP code.
    Again, even nontechies would point out that this is far too small a sample, causing
    variance to rise. In other words, having too large a value of *p* increases variance.
    Once again, we see a tension between variance and bias.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，事实证明，我们使用的预测变量越多（通常来说，不仅仅是针对这个数据集），预测值的方差就越高。为了说明这一点，假设我们正在进行一项营销研究，预测冬季羽绒服的购买情况，并希望考虑客户的地理位置。美国大约有42,000个邮政编码。假设我们将邮政编码作为特征之一来预测购买情况。那样的话，我们将有42,000个虚拟变量，并且还会有其他特征，如年龄、性别和收入，即*p*
    > 42000。如果我们的数据包含100,000个客户，我们每个邮政编码的平均数据点只有2或3个。再次强调，甚至非技术人员也会指出，这是一个过小的样本，导致方差增加。换句话说，过大的*p*值会增加方差。我们再次看到了方差和偏差之间的矛盾。
- en: '***3.1.2 Relation to Overall Dataset Size***'
  id: totrans-18
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***3.1.2 与整体数据集大小的关系***'
- en: But there’s more. In choosing a “good” value of *k* or *p*, we need to take
    into consideration *n*, the number of data points we have. Recall that in the
    bike sharing example, we had *n* = 731 (that is, only 731 days’ worth of data).
    Is that large enough to make good predictions? Why should that number matter?
    Actually, it relates directly to the Bias-Variance Trade-off. Here’s why.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 但还有更多内容。在选择一个“好的”*k*或*p*值时，我们需要考虑*n*，即我们拥有的数据点数量。回想一下，在共享单车示例中，我们有*n* = 731（也就是只有731天的数据）。这个数量是否足够大，能够做出好的预测呢？为什么这个数字很重要？实际上，这与偏差-方差权衡直接相关。原因如下。
- en: 'In our bike sharing example above, we worried that with *k* = 25 nearest neighbors,
    we might have some days among those 25 whose temperatures are rather far from
    28\. But if we had, say, 2,000 days instead of 731, the 25th-closest might still
    be pretty close to 28\. In other words:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们上面的共享单车示例中，我们担心当*k* = 25时，可能会有一些天的温度与28度相差较远。但如果我们有，比如说，2,000天的数据，而不是731天，那么第25个最接近的温度可能仍然会非常接近28度。换句话说：
- en: The larger *n* is, the larger we can make *k* while still avoiding overly large
    bias.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*n*越大，我们可以选择的*k*值越大，同时仍能避免过大的偏差。'
- en: Similarly, consider the ZIP code issue mentioned above. With 100,000 customers,
    we would have on average only 2 or 3 data points per ZIP code. But what if our
    dataset consisted of 50 million customers? Then it may be useful to include the
    dummies for ZIP codes, as we may have a sufficient number of customers from most
    ZIP codes. Remember, *p* denotes the number of features, and this counts each
    dummy variable separately. Thus, inclusion of ZIP codes in our feature set would
    increase *p* by about 42,000.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，考虑上面提到的邮政编码问题。如果我们有100,000个客户，那么每个邮政编码的平均数据点只有2到3个。但如果我们的数据集由5000万客户组成呢？那时包括邮政编码虚拟变量可能是有用的，因为我们可能从大多数邮政编码中获得足够数量的客户。记住，*p*表示特征的数量，这里每个虚拟变量都会单独计算。因此，将邮政编码包含在我们的特征集中会使*p*增加大约42,000。
- en: 'In other words:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说：
- en: The larger *n* is, the larger the value we can use for *p*—that is, the more
    features we can use while still avoiding overly large variance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*n*越大，我们可以使用的*p*值越大——也就是说，我们可以使用更多的特征，同时仍然避免过大的方差。'
- en: '***3.1.3 Well Then, What Are the Best Values of k and p?***'
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***3.1.3 那么，*k*和*p*的最佳值是什么？***'
- en: Mind you, this still doesn’t tell us how to set a good “Goldilocks” value of
    *k*—not too small and not too large. The same holds for choosing *p* (that is,
    choosing the number of features to use); in fact, it’s an even more challenging
    problem, as it is a question of not only *how many* features to use but also *which
    ones*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这仍然没有告诉我们如何设置一个好的“金发女孩”*k*值——既不太小也不太大。对于选择*p*（也就是选择使用多少个特征），同样的情况也适用；事实上，这是一个更具挑战性的问题，因为它不仅是一个关于*使用多少个*特征的问题，还涉及*选择哪些*特征。
- en: 'As we have stated so many times:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经多次提到的：
- en: This is a fact of life in machine learning. For most issues, there are no neat,
    magic-formula answers. Again, ML is an art, not a science. However, holdout methods
    are used in practice, and they generally work pretty well, especially as the analyst
    gains experience.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是机器学习中的一个现实问题。对于大多数问题，没有简洁的“魔法公式”答案。再说一遍，机器学习是一门艺术，而不是科学。然而，验证方法在实践中是常用的，并且它们通常效果不错，尤其是在分析师积累经验之后。
- en: We’ll present holdout methods in full detail later in this chapter.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章稍后详细介绍验证方法。
- en: 'Also, a rough rule of thumb, suggested by some mathematical theory, is to follow
    this limitation:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些数学理论建议的一个大致经验法则是遵循以下限制：
- en: '![Image](../images/ch03equ01.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch03equ01.jpg)'
- en: That is, the number of nearest neighbors should be less than the square root
    of the number of data points.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，最近邻的数量应少于数据点数量的平方根。
- en: 'What about choosing *p*? As noted, a feature set is not “large” or “small”
    on its own. Instead, its size *p* must be viewed relative to the number of data
    points *n*. Overfitting can arise by using too many features for a given dataset
    size. In classical statistics, a rough—though in my experience, conservative—
    rule of thumb has been to follow another “square root of *n*” limitation:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如何选择*p*呢？如前所述，一个特征集本身并不是“大”或“小”的，而是其大小*p*必须相对于数据点数量*n*来考虑。对于给定的数据集大小，使用过多特征可能会导致过拟合。在经典统计学中，一个粗略的——尽管在我看来是保守的——经验法则是遵循另一个“平方根*n*”的限制：
- en: '![Image](../images/ch03equ02.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch03equ02.jpg)'
- en: That is, the number of features should be less than the square root of the number
    of data points. Under this criterion, if our data frame has, say, 1,000 rows,
    it can support about 30 features. This is not a bad rough guide and is supported
    by theoretical results for parametric models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，特征的数量应少于数据点数量的平方根。在此标准下，如果我们的数据框架有1,000行数据，那么它可以支持大约30个特征。这不是一个坏的粗略指导，并且得到了参数模型理论结果的支持。
- en: However, in modern statistics and ML, it is now common to have—or at least start
    with—a value of *p* much larger than *n*. We will see this with certain methods
    used later in the book. We’ll stick with ![Image](../images/prootn.jpg) as a reasonable
    starting point. If our data satisfies that rule, we can feel safe. But if *p*
    is larger, we should not automatically consider it to be overly large.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在现代统计学和机器学习中，现在常见的是拥有——或至少从——一个比*n*大的*p*值。我们将在本书后面看到某些方法时会遇到这一点。我们将保持![Image](../images/prootn.jpg)作为一个合理的起始点。如果我们的数据满足该规则，我们可以放心。但如果*p*较大，我们不应自动认为它过大。
- en: 3.2 Cross-Validation
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 交叉验证
- en: The most common approach to choosing the value of hyperparameters or choosing
    feature sets is to minimize MAPE (numeric- *Y* case) or the overall misclassification
    error (OME, classification case). For k-NN and a numeric- *Y* setting, we may
    find MAPE for each of a range of candidate values of *k* and then choose the one
    producing minimal MAPE.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 选择超参数值或选择特征集的最常见方法是最小化MAPE（数值型*Y*情况）或总体误分类错误（OME，分类情况）。对于k-NN和数值型*Y*设置，我们可能会为一系列候选*k*值计算MAPE，然后选择生成最小MAPE的那个。
- en: 'In deciding what value of *k* to use, we need to assess the predictive ability
    of various values of that hyperparameter. But in doing so, we need to make sure
    we are using a “fresh” dataset to predict. This motivates splitting the data into
    two sets: a training set and a holdout, or test, set.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定使用哪个*k*值时，我们需要评估不同超参数值的预测能力。但在此过程中，我们需要确保使用的是一个“新的”数据集来进行预测。这促使我们将数据分为两组：一个训练集和一个验证集或测试集。
- en: However, holdout sets are chosen randomly. This induces additional randomness,
    on top of the sampling variation we already have. We saw an example of this in
    [Section 1.12.3](ch01.xhtml#ch01lev12sec3). So, in choosing *k* in k-NN, for instance,
    one holdout set may indicate *k* = 5 as best, while another would favor *k* =
    12\. To be thorough, we should not rely on a single holdout set. This leads to
    the method of *K-fold cross-validation*, where we generate many holdout sets,
    averaging MAPE, OME, or other criterion over all those sets. Note that *k*, the
    number of neighbors, is different from *K*, the number of *folds*, or possible
    holdout sets.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，验证集是随机选择的。这在我们已有的采样变异基础上引入了额外的随机性。我们在[第1.12.3节](ch01.xhtml#ch01lev12sec3)中看到了这个例子。因此，在选择k-NN中的*k*时，某一验证集可能指示*k*
    = 5为最佳，而另一个则可能倾向于*k* = 12。为了全面起见，我们不应该仅依赖单一的验证集。这导致了*K折交叉验证*方法，在这种方法中，我们生成多个验证集，并对所有这些集的MAPE、OME或其他标准进行平均。请注意，*k*是邻居的数量，而*K*是折叠数，或者说是可能的验证集数量。
- en: '***3.2.1 K-Fold Cross-Validation***'
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To see how K-fold cross-validation works, consider the “leaving one out” method,
    in which we set a holdout set size of 1\. Say we wish to evaluate the predictive
    ability of *k* = 5\. For each of our *n* data points, we would take the holdout
    set to be that point and take the remaining *n* − 1 points as our training set;
    we then predict the holdout point. This gives us *n* predictions, and we calculate
    MAPE as the average absolute prediction error among those *n* predictions. In
    other words, we would proceed as in the following pseudocode for data frame `d`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We’d call this *n*-fold cross-validation. Alternatively, we could take our holdout
    sets to have size 2, say, by partitioning the set 1,2, . . . ,*n* into non-overlapping
    adjacent pairs. Now there are *n*/2 possible holdout sets (folds). For each fold,
    we apply k-NN to the remaining data and then predict the data in that fold. MAPE
    is then the average over the *n*/2 folds.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: One might expect that *K* = *n* is best, since then MAPE will be based on the
    most trials. On the other hand, each trial will be based on predicting just 1
    data point, which is presumably less accurate. There also may be computational
    and theoretical issues that we won’t go into here. How should we then choose *K*?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Note that *K* is not a hyperparameter, as it is not a trait of k-NN. It is simply
    a matter of how to estimate MAPE reliably. But yes, it’s one more thing to think
    about. Many analysts recommend using a value of 5 or 10.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'Another approach is as follows, say, for holdout sets of size 2\. We simply
    choose many random holdout sets, as many as we have time for, as in the following
    pseudocode:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, *r* is the number of holdout sets. The larger value we choose for *r*,
    the more accurate MAPE will be. It just depends on how much computation time we
    wish to expend. (The plurals, such as `predicted Ys`, allude to the fact that
    any holdout set has two Y values to predict.)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '***3.2.2 Using the replicMeans() Function***'
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We can use the `regtools` function `replicMeans()` to implement K-means cross-validation.
    The function name is short for “replicate an action and then take the mean of
    the results.”
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, say we have some data frame `d` in which we are predicting a
    column `y`. Consider the effect of the following call:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This says to run `cmd` 10 times and return the mean of the result. Since the
    command is to run `qeKNN()`, 10 runs will use 10 different holdout sets, yielding
    10 different values of `testAcc`. The end result will be that the function returns
    the average of those 10 values, which is exactly what we want.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '***3.2.3 Example: Programmer and Engineer Data***'
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Here we will introduce a new dataset, `pef`, to be used at several points in
    the book, and illustrate cross-validation on this data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 'The `pef` dataset is included in the `regtools` package, which in turn is included
    in `qeML`. It is drawn from the 2000 US census, showing data on programmers and
    engineers. Here is a glimpse:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: So, data on a bit more than 20,000 workers is stored here.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'The education variable here needs some explanation. The census has codes for
    education of various levels, down to even none at all. But for this dataset, there
    won’t be many (if any) workers with, say, just a sixth-grade education. For that
    reason, the `educ` column here has been simplified to just three levels: master’s
    (code 14), PhD (16), and “other” (coded as `zzzOther` by the software, `regtools::toSubFactor()`).
    Most of the “other” workers have a bachelor’s degree, but even those with less
    have been lumped into this level.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Why do this? The `qe*`-series functions convert any feature that is an R factor
    to dummy variables, and for some such functions, the output is displayed in terms
    of the dummies. So, consolidation as above compactifies output. Even running `head()`
    would give very wide output if all education levels were included and dummy variables
    were displayed.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Second, simplification of this nature may, in general, be needed to avoid overfitting—remember,
    each dummy variable counts separately in the feature count *p*—even though in
    this dataset we are well within the “![Images](../images/prootn.jpg)” rule of
    thumb.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: For detailed information on this dataset, such as the various occupation codes,
    type ?pef at the R prompt.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.3.1 Improved Estimation of MAPE
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Suppose we wish to predict `wageinc`, wage income, in this `pef` dataset. Let’s
    take a first cut at it:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'On average, our predictions are off by about $25,300\. This is a rather large
    number, but as emphasized in [Section 2.4](ch02.xhtml#ch02lev4), we must always
    gauge prediction accuracy of a feature set compared to predicting *without* the
    features:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: So, just predicting everyone to have the overall mean income would give us a
    much larger MAPE.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: At any rate, our point here concerns not this particular dataset but the general
    accuracy of MAPE if the latter is based on just a single holdout set. We really
    need to look at multiple holdout sets using cross-validation. Let’s do that using
    `replicMeans()`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: So, the indicated `qeKNN()` call was run 10 times, yielding 10 holdout sets,
    having an average value of about $25,633 for accuracy on the test set. This is
    somewhat larger than the $25,296 figure we had obtained earlier based on just
    one holdout set. Thus, we should treat this new figure as more reliable.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: That $412 number is the *standard error*. Multiplying it by 1.96 gives us the
    margin of error. If we feel that is too large, we can call `replicMeans()` with,
    say, 100 replications (that is, 100 holdout sets).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: We could then try other values of *k*, running `replicMeans()` for each one
    as above and then finally choosing the value that gives the best MAPE or OME.
    If we have more than a few such values, it would be easier to use the `qeML` function
    `qeFT()`, which will be presented in [Chapter 7](ch07.xhtml).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '***3.2.4 Triple Cross-Validation***'
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Suppose we split our data into training and test sets, and then fit many different
    combinations of hyperparameters, choosing the combination that does best on the
    test set. Again we run into the problem of potential p-hacking, meaning that the
    accuracy rates reported in the test set may be overly optimistic.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们将数据分为训练集和测试集，然后拟合许多不同的超参数组合，选择在测试集上表现最好的组合。我们再次遇到潜在的p-hacking问题，这意味着测试集报告的准确率可能过于乐观。
- en: One common solution is to partition the data into three subsets rather than
    two, with the intermediate one being termed the *validation set*. We fit the various
    combinations of hyperparameters to the training set and evaluate them on the validation
    set. After choosing the best combination, we then evaluate (only) that combination
    on the test set to obtain an accuracy estimate untainted by p-hacking.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的解决方案是将数据分为三个子集，而不是两个，其中间的子集称为*验证集*。我们将不同的超参数组合拟合到训练集上，并在验证集上评估它们。选择最佳组合后，我们再在测试集上评估（仅）该组合，以获得未受p-hacking影响的准确性估计。
- en: 3.3 Conclusions
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 结论
- en: 'In summary, the main concepts in this brief but vital chapter are:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，本章虽然简短，但关键的概念有：
- en: In choosing a hyperparameter such as k-NN’s *k*, and in choosing a feature set,
    variance and bias are at odds with each other. For a fixed dataset, a small *k*
    or large *p* increases variance while reducing bias, and vice versa.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在选择超参数，例如k-NN的*k*，以及选择特征集时，方差和偏差是相互对立的。对于固定数据集，较小的*k*或较大的*p*会增加方差而减少偏差，反之亦然。
- en: With a larger *n*, we can afford to take a larger value of *k* or *p*.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在更大的*n*情况下，我们可以选择更大的*k*或*p*。
- en: Unfortunately, there is no hard-and-fast formula for the “Goldilocks” values
    of *k* and *p*. But there are some very rough rules of thumb, and careful use
    of holdout sets and cross-validation will serve us pretty well. As one gains experience,
    one also becomes more skilled at this.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不幸的是，对于*k*和*p*的“金发女孩”值，没有固定不变的公式。但有一些非常粗略的经验法则，合理使用保留集和交叉验证会给我们带来很大帮助。随着经验的积累，技能也会随之提升。
- en: Again, use of holdout sets is the main remedy, including using multiple holdout
    sets if there is concern about accuracy of MAPE or OME on a single set.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，使用保留集是主要的解决办法，包括如果担心单一数据集上的MAPE或OME的准确性，可以使用多个保留集。
