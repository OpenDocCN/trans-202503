- en: B
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BECAUSE I CAN’T RESIST
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this appendix, I include additional material related to some of the problems
    studied in this book. I consider this appendix as optional: it doesn’t concern
    material that I think is core to the goal of learning about data structures and
    algorithms. However, if you’re keen to learn more about a problem, this appendix
    is for you.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unique Snowflakes: Implicit Linked Lists'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It’s often the case that at compile time we don’t know how much memory our
    program will need. If you’ve ever asked, “How big should I make this array?” or
    “Will this array be big enough?” then you’ve experienced firsthand the inflexibility
    of C arrays: we have to choose an array size, but we might not know the size we
    need until the array starts filling up. In many such cases, linked lists neatly
    solve the problem. Whenever we require new memory to store some data, we just
    call `malloc` at runtime to add a node to a linked list.'
  prefs: []
  type: TYPE_NORMAL
- en: In the first problem in [Chapter 1](ch01.xhtml), Unique Snowflakes, we used
    linked lists to chain together the snowflakes that reside in the same bucket.
    For every snowflake that we read in, we used `malloc` to allocate memory for exactly
    one snowflake. If we read 5,000 snowflakes, we’ll have made 5,000 `malloc` calls.
    The time taken by these `malloc` calls can add up.
  prefs: []
  type: TYPE_NORMAL
- en: 'Wait! We just said that linked lists are useful when we don’t know how much
    memory we might need. In Unique Snowflakes, we *do* know! Or, at least, we know
    the *maximum* that we’ll need: it’s whatever is required to store at most 100,000
    snowflakes.'
  prefs: []
  type: TYPE_NORMAL
- en: That raises questions. Why are we using `malloc`, anyway? Is there a way to
    avoid using `malloc` and linked lists? Indeed, we can solve Unique Snowflakes
    in a way that doesn’t use `malloc` and leads to a doubling of speed. How?
  prefs: []
  type: TYPE_NORMAL
- en: 'The key idea is to preallocate an array of the maximum number of nodes (100,000)
    that we might use. The array is called `nodes`, and it stores the nodes from all
    of the (now-implicit) linked lists. Each element of `nodes` is an integer giving
    the index of the next node in its list of nodes. Let’s get a handle on this by
    deciphering a sample `nodes` array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Suppose we know that one of the lists starts at index `6`. The value of index
    `6`, `5`, tells us that index `5` is the next node in the list. Similarly, index
    `5` tells us that index `4` is the next node in the list. Index `4` tells us that
    index `2` is the next node in the list. What about index `2`, with the value of
    `-1`? We’ll use `-1` as our `NULL` value: it indicates that there’s no “next”
    element. We have discovered the list of indices `6`, `5`, `4`, and `2`.'
  prefs: []
  type: TYPE_NORMAL
- en: There’s one more nonempty list in that array. Suppose we know this list starts
    at index `3`. Index `3` tells us that index `1` is the next node in the list.
    Index `1` tells us that index `0` is the next node in the list. That’s all then—index
    `0` is a `-1`, so the list is over. We have discovered the list of indices `3`,
    `1`, and `0`.
  prefs: []
  type: TYPE_NORMAL
- en: That’s the `nodes` array. If some index has a value of `-1`, then it’s the end
    of a list. Otherwise, it gives the index of the next element in the list.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that `nodes` doesn’t tell us anything about where the lists start. We
    had to assume that we somehow knew that the list heads were at indices `6` and
    `3`. How could we have known that? By using another array, `heads`, that gives
    the index of the first node in a list. `heads` uses `-1` for the value of any
    element that does not start a list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our `malloc`-less solution uses a total of three arrays in the `main` function:
    `snowflakes`, `nodes`, and `heads`. The `snowflakes` array stores the actual snowflakes
    so that we can look up a snowflake according to the indices in `nodes` and `heads`.
    Here are the three arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Only two of our functions must be adjusted to move from linked lists to the
    implicit lists that we use here: `identify_identical` and `main`. These adjustments
    are about syntax, not substance: `identify_identical` still performs pairwise
    comparisons of all snowflakes in a list, and `main` still reads in the snowflakes
    and builds the lists.'
  prefs: []
  type: TYPE_NORMAL
- en: The new `identify_identical` is in [Listing B-1](app02.xhtml#app02ex01)—compare
    this to what we had before in [Listing 1-12](ch01.xhtml#ch01ex012)!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing B-1: Identifying identical snowflakes in implicit linked lists*'
  prefs: []
  type: TYPE_NORMAL
- en: Inside the `for` loop, `node1` is set to the head of the current list. If this
    list is empty, then the outer `while` loop won’t run at all for this node. If
    it isn’t empty, then, by using the `nodes` array, `node2` is set to the node after
    `node1` ➊. Rather than linked-list code like `node2 = node2->next`, we again use
    the `nodes` array to find the next node ➋ ➌.
  prefs: []
  type: TYPE_NORMAL
- en: The new `main` function is given in [Listing B-2](app02.xhtml#app02ex02).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing B-2: The* main *function for implicit linked lists*'
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we have just read a snowflake and we have stored it in row `i` of `snowflakes`.
    We want this snowflake to become the head of its list. To accomplish this, we
    store the old list head at `nodes[i]` ➊, and then we set the head of the list
    to be snowflake `i` ➋.
  prefs: []
  type: TYPE_NORMAL
- en: Take some time to compare this solution to our linked-list solution. Which do
    you prefer? Is the `malloc`-less solution harder or easier for you to understand?
    Submit both to the judge; is the speedup worth it?
  prefs: []
  type: TYPE_NORMAL
- en: 'Burger Fervor: Reconstructing a Solution'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In [Chapter 3](ch03.xhtml), we solved three problems—Burger Fervor, Moneygrubbers,
    and Hockey Rivalry—that involved minimizing or maximizing the value of a solution.
    In Burger Fervor, we maximized Homer’s time spent eating burgers; we gave an answer
    such as `2 2`, meaning two burgers and two minutes drinking beer. In Moneygrubbers,
    we minimized the amount of money required to purchase apples; we gave an answer
    such as `Buy 3 for $3.00`. In Hockey Rivalry, we maximized the number of goals
    in rivalry games; we gave an answer such as `20`.
  prefs: []
  type: TYPE_NORMAL
- en: Notice, though, that what we are doing here is giving the *value* of an optimal
    solution. We are not giving the optimal solution itself. We are not indicating
    which burgers to eat, or how to purchase the apples, or which games are the rivalry
    games.
  prefs: []
  type: TYPE_NORMAL
- en: The vast majority of optimization problems in competitive programming ask for
    the value of an optimal solution, which was the focus in [Chapters 3](ch03.xhtml)
    and [4](ch04.xhtml). However, we can, if we like, use memoization and dynamic
    programming to return an optimal solution itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see how this is done using Burger Fervor as an example. Given the following
    test case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'let’s output not only the value of an optimal solution, but an optimal solution
    itself, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The first line is what we had before; the other lines constitute an optimal
    solution itself, proof that the `2 2` is indeed achievable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Outputting an optimal solution like this is known as *reconstructing* or *recovering*
    a solution. Both of these words suggest that we already have the pieces that can
    be put together to produce the optimal solution. And that’s true: what we need
    is sitting right there in the `memo` or `dp` array. Here, let’s use the `dp` array;
    the `memo` array could be used in precisely the same way.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re going to write the body for this function signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Recall that we have *m*-minute and *n*-minute burgers. The `m` and `n` parameters
    are these values and come from the current test case. The `dp` parameter is the
    array that is produced by the dynamic-programming algorithm in [Listing 3-8](ch03.xhtml#ch03ex08).
    Finally, the `minutes` parameter is the number of minutes spent eating burgers.
    The function will print, one per line, the number of burgers that should be eaten
    in an optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: What is the last burger that Homer should eat in an optimal solution? If we
    were solving this problem from scratch, then we wouldn’t know this answer. We’d
    have to see what happens if we choose an *m*-minute burger to be last and also
    see what happens if we choose an *n*-minute burger to be last. Indeed, that’s
    what we did when solving this problem in [Chapter 3](ch03.xhtml). Remember, though,
    that we now have the `dp` array at our disposal. That array is going to tell us
    which of the two options is the best.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the key idea: take a look at `dp[minutes - m]` and `dp[minutes - n]`.
    Both of those values are available to us, because the `dp` array has already been
    constructed. Whichever of these values is larger tells us what we should use as
    the last burger. That is, if `dp[minutes - m]` is larger, then an *m*-minute burger
    is last; if `dp[minutes - n]` is larger, then an *n*-minute burger is last. (If
    `dp[minutes - m]` and `dp[minutes - n]` are equal, then you can choose arbitrarily
    whether to make the last burger an *m*-minute or *n*-minute burger.)'
  prefs: []
  type: TYPE_NORMAL
- en: This reasoning parallels that used in [Listing 3-8](ch03.xhtml#ch03ex08) to
    build the `dp` array. There, we chose the maximum of `first` and `second`; here,
    we reverse engineer which of those choices the dynamic-programming algorithm made.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have deduced the final burger, we remove the time taken to eat that
    burger and then repeat the process. We keep going until we get down to zero minutes,
    at which point our reconstruction is complete. [Listing B-3](app02.xhtml#app02ex03)
    gives the code for the function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing B-3: Reconstructing the solution*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This function should be called in two places in [Listing 3-8](ch03.xhtml#ch03ex08),
    once after each `printf` call. The first is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The second is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: I encourage you to reconstruct optimal solutions for the Moneygrubbers and Hockey
    Rivalry problems, following this same style.
  prefs: []
  type: TYPE_NORMAL
- en: 'Knight Chase: Encoding Moves'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the Knight Chase problem of [Chapter 5](ch05.xhtml), we designed a BFS algorithm
    to find the number of moves needed for a knight to reach each square from its
    starting point. The knight has eight possible moves, and we wrote each of them
    out in our code (see [Listing 5-1](ch05.xhtml#ch05ex01)). For example, here’s
    what we did to have the knight explore moving up one and right two:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s what we did for up one and left two:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'There is gross code duplication there: the only change is a plus sign to a
    minus sign! In fact, all eight moves are encoded in a very similar way, just messing
    around with some pluses and minuses and 1s and 2s. That kind of thing is quite
    error-prone.'
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, there is a neat technique to dodge this kind of code duplication.
    It applies to many problems where you’re asked to explore an implicit graph of
    multiple dimensions (such as rows and columns).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the knight’s eight possible moves, as presented in the problem description
    in [Chapter 5](ch05.xhtml):'
  prefs: []
  type: TYPE_NORMAL
- en: Up 1, right 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Up 1, left 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Down 1, right 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Down 1, left 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Up 2, right 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Up 2, left 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Down 2, right 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Down 2, left 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s first focus on the rows and write down how each move changes the row
    number. The first move increases the row number by one, as does the second move.
    The third and fourth moves, by contrast, reduce the row number by one. The fifth
    and sixth moves increase the row number by two, and the seventh and eighth moves
    reduce the row number by two. Here’s an array of those numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: It’s called `row_dif` because it gives the difference in row numbers between
    the current row and the row after making a move.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s do the same thing for the columns. The first move increases the column
    number by two, the second move decreases the column number by two, and so on.
    As an array, the column differences are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: What’s useful about these two parallel arrays is that they characterize the
    effect that each move has on the current row and column. The numbers in `row_dif[0]`
    and `col_dif[0]` tell you that the first move increases the row by one and increases
    the column by two, those in `row_dif[1]` and `col_dif[1]` tell you that the second
    move increases the row by one and decreases the column by two, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, instead of typing out eight near-identical calls to `add_position`, we
    can use a loop of eight iterations, typing out just one call to `add_position`
    in there. Here’s how it’s done, using a new integer variable `m` to loop through
    the moves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: That’s better! Update your Knight Chase code from [Chapter 5](ch05.xhtml) and
    give it a go with the judge. You should still pass all of the test cases and your
    code shouldn’t be noticeably faster or slower, but you’ve shaved off quite a bit
    of repetitive code, and that’s a win.
  prefs: []
  type: TYPE_NORMAL
- en: We had only eight moves here, so we managed to survive Knight Chase in [Chapter
    5](ch05.xhtml) without using this encoding trick. However, if we had many more
    moves than this, then pasting the call to `add_position` over and over simply
    wouldn’t be feasible. What we’ve seen here scales much more nicely.
  prefs: []
  type: TYPE_NORMAL
- en: 'Dijkstra’s Algorithm: Using a Heap'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In [Chapter 6](ch06.xhtml), we learned Dijkstra’s algorithm for finding shortest
    paths in weighted graphs. The runtime of our Dijkstra implementation was *O*(*n*²),
    where *n* is the number of nodes in the graph. Dijkstra’s algorithm spends a lot
    of its time searching for minimums: on each iteration, it has to find the node
    whose distance is minimum of all nodes that are not done.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, in [Chapter 8](ch08.xhtml), we learned about max-heaps and min-heaps.
    A max-heap won’t help here—but a min-heap will, because its job is to quickly
    find the minimum. We can therefore use a min-heap to speed up Dijkstra’s algorithm.
    This is a match made in computer-science heaven.
  prefs: []
  type: TYPE_NORMAL
- en: 'The min-heap will hold all of the nodes that have been discovered and that
    are not done. It might also hold some discovered nodes that *are* done. That’s
    okay, though: as we did when solving the Supermarket Promotion problem with heaps
    in [Chapter 8](ch08.xhtml), we’ll just ignore any done node that happens to come
    off the min-heap.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Mice Maze: Tracing with Heaps*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s enhance our solution to the Mice Maze problem from [Chapter 6](ch06.xhtml)
    to use a min-heap. Here’s the graph that we used there ([Figure 6-1](ch06.xhtml#ch06fig01)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/unapp02fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In [Chapter 6](ch06.xhtml), we traced Dijkstra’s algorithm starting from Node
    1\. Let’s do that again, this time using a min-heap. Each heap element will consist
    of a node and a time necessary to reach that node. We’ll see that there can be
    multiple occurrences of the same node on the heap. However, because it’s a min-heap,
    we’ll be able to process each node using only its minimum time.
  prefs: []
  type: TYPE_NORMAL
- en: In each min-heap snapshot that follows, I’ve arranged the rows in the same order
    as they’d be stored in the heap array.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with only Node 1 in the heap, with a time of 0\. We have no time information
    for other nodes. We therefore have this snapshot:'
  prefs: []
  type: TYPE_NORMAL
- en: Min-heap
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: Rest of State
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***done*** | ***min_time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | false | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | false |  |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | false |  |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | false |  |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | false |  |'
  prefs: []
  type: TYPE_TB
- en: 'Extracting from the min-heap gives us its sole element, Node 1\. We then process
    Node 1 to update the shortest paths to Nodes 2, 3, 4, and 5 and place these nodes
    on the min-heap. Here’s our state now:'
  prefs: []
  type: TYPE_NORMAL
- en: Min-heap
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 12 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 45 |'
  prefs: []
  type: TYPE_TB
- en: Rest of State
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***done*** | ***min_time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | true | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | false | 12 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | false | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | false | 45 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | false | 7 |'
  prefs: []
  type: TYPE_TB
- en: 'Node 3 is next out of the min-heap and gives us a shorter path to Node 2\.
    We therefore add another occurrence of Node 2 to the heap, this one with a shorter
    path than before. Here’s what we’ve got now:'
  prefs: []
  type: TYPE_NORMAL
- en: Min-heap
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 45 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 12 |'
  prefs: []
  type: TYPE_TB
- en: Rest of State
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***done*** | ***min_time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | true | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | false | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | true | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | false | 45 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | false | 7 |'
  prefs: []
  type: TYPE_TB
- en: 'Next out is Node 5\. It doesn’t lead to any shortest-path updates, so nothing
    new gets added to the heap. Here’s where we are:'
  prefs: []
  type: TYPE_NORMAL
- en: Min-heap
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 12 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 45 |'
  prefs: []
  type: TYPE_TB
- en: Rest of State
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***done*** | ***min_time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | true | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | false | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | true | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | false | 45 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | true | 7 |'
  prefs: []
  type: TYPE_TB
- en: 'Node 2 is next out of the min-heap—specifically the one with 8 time, not the
    one with 12 time! It leads to an update of Node 4’s shortest path, and consequently
    a new occurrence of Node 4 on the min-heap. Here’s the result:'
  prefs: []
  type: TYPE_NORMAL
- en: Min-heap
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 12 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 45 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 17 |'
  prefs: []
  type: TYPE_TB
- en: Rest of State
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***done*** | ***min_time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | true | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | true | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | true | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | false | 17 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | true | 7 |'
  prefs: []
  type: TYPE_TB
- en: 'The next node to come out of the min-heap is Node 2\. Again! Node 2 is already
    done, so we simply extract it from the heap and do nothing else. We certainly
    don’t process this node again. Here’s what’s left:'
  prefs: []
  type: TYPE_NORMAL
- en: Min-heap
  prefs: []
  type: TYPE_NORMAL
- en: '| ***cell*** | ***time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 17 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 45 |'
  prefs: []
  type: TYPE_TB
- en: Rest of State
  prefs: []
  type: TYPE_NORMAL
- en: '| ***node*** | ***done*** | ***min_time*** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | true | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | true | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | true | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | false | 17 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | true | 7 |'
  prefs: []
  type: TYPE_TB
- en: The two occurrences of Node 4 will be extracted from the min-heap in turn. The
    first Node 4 won’t lead to any shortest-path updates—all other nodes are done—but
    will set Node 4 to done. The second Node 4 will therefore be skipped.
  prefs: []
  type: TYPE_NORMAL
- en: In most textbook heap-based implementations of Dijkstra’s algorithm, it is assumed
    that there’s a way to decrease the shortest-path distance of a node in a heap.
    That way, a node can be updated in the heap, and there’s no need to have multiple
    occurrences of a node hanging around. The heaps that we developed in [Chapter
    8](ch08.xhtml), though, don’t support such a “decrease” operation. Rest assured
    that what we’re doing here, with the insertions instead of updates, has the same
    worst-case time complexity. Which is what, exactly?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use *n* to represent the number of nodes in the graph and *m* the number
    of edges. We process each edge *u* *→* *v* at most once, when *u* is extracted
    from the heap. Each edge can lead to at most one insertion into the heap, so we
    insert at most *m* elements. The biggest the heap could ever get, then, is size
    *m*. We can only extract what’s been inserted, so there are at most *m* extractions.
    That’s 2*m* heap operations in all, each of which takes at most log *m* time.
    Therefore, we have an *O*(*m* log *m*) algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Compare this to the *O*(*n*²) implementation from [Chapter 6](ch06.xhtml).
    The heap-based implementation is a clear win when the number of edges is small
    in relation to *n*². For example, if there are *n* edges, then the heap-based
    implementation is *O*(*n* log *n*), which blows away the *O*(*n*²) runtime in
    [Chapter 6](ch06.xhtml). If the number of edges is large, then it matters less
    which implementation we use. For example, if there are *n*² edges, then the heap-based
    implementation is *O*(*n*² log *n*), which is competitive with, but a little slower
    than, *O*(*n*²). If you don’t know in advance whether your graph will have few
    or many edges, using a heap is a safe bet: the only cost is the extra log *n*
    factor on graphs with many edges, but that’s a small price to pay in exchange
    for much better performance on graphs with few edges.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Mice Maze: Implementation with Heaps*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Now let’s solve Mice Maze using heaps. We use this struct for the heap elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: I won’t replicate the min-heap insertion code ([Listing 8-5](ch08.xhtml#ch08ex05))
    or extraction code ([Listing 8-6](ch08.xhtml#ch08ex06)) here. The only change
    is to compare `time` rather than `cost`; I’ll leave that to you.
  prefs: []
  type: TYPE_NORMAL
- en: The `main` function is the same as it was in [Chapter 6](ch06.xhtml) ([Listing
    6-1](ch06.xhtml#ch06ex01)). All we need is a replacement of `find_time` ([Listing
    6-2](ch06.xhtml#ch06ex02)) to use a min-heap instead of linear searches. That
    code is given in [Listing B-4](app02.xhtml#app02ex04).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing B-4: Shortest path to exit using Dijkstra’s algorithm and heaps*'
  prefs: []
  type: TYPE_NORMAL
- en: Each cell can result in at most `MAX_CELLS` elements added to the min-heap,
    and there are at most `MAX_CELLS`. We’re safe from overflowing the min-heap, then,
    if we allocate space for `MAX_CELLS * MAX_CELLS` elements plus one, since we index
    starting at `1` rather than `0` ➊.
  prefs: []
  type: TYPE_NORMAL
- en: The main `while` loop continues as long as there’s something in the min-heap
    ➋. If the node that we extract from the min-heap is already done, then we don’t
    do anything on its iteration ➌. Otherwise, we process the outgoing edges as usual
    ➍, adding nodes to the min-heap when shorter paths are found ➎.
  prefs: []
  type: TYPE_NORMAL
- en: Compressing Path Compression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In [Chapter 9](ch09.xhtml), you learned about path compression, an optimization
    to the tree-based union-find data structure. We saw its code in the context of
    the Social Network problem in [Listing 9-8](ch09.xhtml#ch09ex08). Written like
    that, with the two `while` loops, is not how you’ll see the code in practice.
  prefs: []
  type: TYPE_NORMAL
- en: I generally don’t like to dwell on opaque code—and I hope I haven’t presented
    you with any such code in the book—but I’ll make an exception here, because you
    may at some point run into a particularly dense, one-line implementation of path
    compression. It’s presented in [Listing B-5](app02.xhtml#app02ex05).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing B-5: Path compression in practice*'
  prefs: []
  type: TYPE_NORMAL
- en: I changed `person` to `p` to get the code on one line (since readability is
    already shot, why not?).
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s a lot going on here: the `? :` ternary if operator, using the result
    of the `=` assignment operator, and even recursion. We’re going to unravel this
    in three steps.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 1: No More Ternary If*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The `? :` operator is a form of if–else that returns a value. Programmers use
    it when they want to save space and jam an entire if statement on one line. A
    quick example looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: If `x` is greater than or equal to 10, `"big"` is returned; otherwise, `"small"`
    is returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `? :` operator is called a *ternary* operator because it takes three operands:
    the first expression is the boolean expression whose truth we are testing, the
    second expression is the result when the first expression is true, and the third
    is the result when the first expression is false.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s rewrite [Listing B-5](app02.xhtml#app02ex05) to use a standard `if...else`
    statement rather than the ternary `if`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'That’s a little better. Now we explicitly see that the code has two paths:
    one if `p` is already the root and the other if `p` is not the root.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 2: Cleaner Assignment Operator*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: What do you think this code snippet does?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The answer is that it prints `5`! You know that `x = 5` assigns `5` to `x`,
    but it’s also an expression whose value is `5`. That’s right: `=` assigns a value,
    but it also returns the value that it stored in the variable. It’s also why we
    can do'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: to assign the same value to multiple variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the path-compression code, we have a return statement and an assignment
    statement on the same line. That line both assigns a value to `parent[p]` and
    returns that value. Let’s split those two actions out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We’re explicitly finding the representative for `p`, assigning `parent[p]` to
    that representative, and then returning the representative.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 3: Understand the Recursion*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Now we have the recursion isolated on its own line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The `find` function performs path compression from its argument to the root
    of the tree, and it returns the root of the tree. Therefore, this recursive call
    performs path compression from `p`’s parent to the root of the tree, and it returns
    the root of the tree. That handles all of the path compression except for `p`
    itself. We need to set `p`’s parent to the root of the tree as well, which we
    do with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'There we have it: proof that the one-line path-compression code really does
    work!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Caps and Bottles: In-Place Sorting'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In [Chapter 10](ch10.xhtml), we solved the Caps and Bottles problem using a
    famous “splitting” idea from Quicksort. If you look back at [Listing 10-9](ch10.xhtml#ch010ex09),
    you’ll notice that we’re allocating a lot of additional memory as our algorithm
    runs. Specifically, on each invocation of `solve`, we use `malloc` to allocate
    memory for four arrays: the small caps, the small bottles, the big caps, and the
    big bottles.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s possible to avoid this use of additional memory and perform the splitting
    directly in the `cap_nums` and `bottle_nums` arrays. This won’t decrease the number
    of queries that we need to make, but it does decrease the memory that our program
    uses. It’s also a common optimization that people perform when implementing Quicksort.
  prefs: []
  type: TYPE_NORMAL
- en: To make this work, we need to keep track of the border between small values
    and large values. We’ll maintain a variable called `border` to make this happen.
    Once we finish going through all of the caps and bottles, that `border` variable
    will tell us exactly where our problem is split in two; we need that in order
    to make our recursive calls. See [Listing B-6](app02.xhtml#app02ex06) for our
    new solution that uses this idea.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing B-6: Solution with no extra memory allocation*'
  prefs: []
  type: TYPE_NORMAL
- en: Rather than an `n` parameter giving the number of caps and bottles, now we need
    `left` and `right` parameters delimiting the operative part of the arrays ➊.
  prefs: []
  type: TYPE_NORMAL
- en: Prior to the first `while` loop, we choose our random cap ➋. The key invariant
    for the first `while` loop is that all bottles from `left` to `border - 1` are
    small bottles and all bottles from `border` to `i - 1` are big bottles. The loop
    will also eventually find the matching bottle; when it does, it puts that at the
    right ➌. We’ll then be able to ignore that bottle in future recursive calls.
  prefs: []
  type: TYPE_NORMAL
- en: If we find that the cap is too big for the current bottle ➍, it means that the
    current bottle is on the wrong side of `border`. After all, it’s a small bottle,
    and small bottles have to go to the left of `border`. To fix it, we swap that
    small bottle with the big bottle at `bottle_nums[border]` ➎, and then we increment
    `border` to take into account that we now have one more small bottle to the left
    of `border`.
  prefs: []
  type: TYPE_NORMAL
- en: When that `while` loop is done, we’ll have rearranged the bottles so the small
    bottles are first and the big bottles follow. We’ll also have placed the matching
    bottle at the right, so we tell the judge about that match now ➏.
  prefs: []
  type: TYPE_NORMAL
- en: The second `while` loop is nearly identical to the first, though this time it’s
    splitting the caps rather than the bottles.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final thing we need to do is make our two recursive calls. The first one
    goes from `left` to `border - 1` ➐—that’s all of the small caps and bottles. The
    second one goes from `border` to `right - 1` ➑—that’s all of the big caps and
    bottles. Be careful: we need `right - 1` here, not `right`. The bottle and cap
    at index `right` have already been matched and should therefore never again be
    passed to a recursive call.'
  prefs: []
  type: TYPE_NORMAL
