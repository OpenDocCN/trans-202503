- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An Overview of Machine Learning
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This book is about *deep learning*, a subfield of *machine learning*. The phrase
    *machine learning*describes a growing body of techniques that share a common goal:
    extracting meaningful information from data. Here, *data* refers to anything that
    can be represented numerically. Data can be raw numbers (like stock prices on
    successive days, the masses of different planets, or the heights of people visiting
    a county fair), but it can also be sounds (the words someone speaks into their
    cell phone), pictures (photographs of flowers or cats), words (the text of a newspaper
    article or a novel), behavior (what activities someone enjoys), preferences (the
    music or films someone likes), or anything else that we can collect and describe
    with numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to discover meaningful information, where it’s up to us to decide
    what’s meaningful. We usually want to find patterns that help us understand the
    data or use past measurements to predict future events. For example, we might
    want to predict a movie someone would like based on movies they’ve already rated,
    read the handwriting on a note, or identify a song from just a few notes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We generally find the information we’re after in three steps: we identify the
    information that we want to find, we collect data that we hope will hold that
    information, and then we design and run algorithms to extract as much of that
    information as possible from that data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover some of the major movements in machine learning.
    We’ll begin by discussing an early approach to machine learning called an expert
    system. We’ll then discuss three of the major approaches to learning: supervised
    learning, unsupervised learning, and reinforcement learning. We’ll end the chapter
    by looking at deep learning.'
  prefs: []
  type: TYPE_NORMAL
- en: Expert Systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before deep learning became practical on a widespread basis, a popular approach
    to learning from data involved creating *expert systems*. Still used today, these
    are computer programs intended to encapsulate the thought processes of human experts
    such as doctors, engineers, and even musicians. The idea is to study a human expert
    at work, watch what they do and how they do it, and perhaps ask them to describe
    their process out loud. We capture that thinking and behavior with a set of rules.
    The hope is that a computer could then do the expert’s job just by following those
    rules.
  prefs: []
  type: TYPE_NORMAL
- en: These kinds of systems can work well once they’re built, but they’re difficult
    to create and maintain. It’s worth taking a moment to see why. The problem is
    that the key step of producing the rules, called *feature engineering*, can require
    impractical amounts of human intervention and ingenuity. Part of deep learning’s
    success is that it addresses exactly this problem by creating the rules algorithmically.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s illustrate the problem faced by expert systems with a practical example:
    recognizing digits. Let’s say that we want to teach a computer to recognize the
    number 7\. By talking to people and asking questions, we might come up with a
    set of three small rules that let us distinguish a 7 from all other digits: first,
    7s have a mostly horizontal line near the top of the figure; second, they have
    a mostly northeast-southwest diagonal line; and third, those two lines meet in
    the upper right. The rules are illustrated in [Figure 1-1](#figure1-1).'
  prefs: []
  type: TYPE_NORMAL
- en: This might work well enough until we get a 7 like [Figure 1-2](#figure1-2).
  prefs: []
  type: TYPE_NORMAL
- en: '![f01001](Images/f01001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-1: Top: A handwritten 7\. Bottom: A set of rules for distinguishing
    a handwritten 7 from other digits.'
  prefs: []
  type: TYPE_NORMAL
- en: '![f01002](Images/f01002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-2: A 7 that would not be recognized by the rules of [Figure 1-1](#figure1-1)
    because of the extra horizontal line'
  prefs: []
  type: TYPE_NORMAL
- en: Our set of rules won’t recognize this as a 7, because we hadn’t originally considered
    that some people put a bar through the middle of the diagonal stroke. So now we
    need to add another rule for that special case. In practice, this kind of thing
    happens over and over again to anyone developing an expert system. In a problem
    of any complexity, finding a good and complete set of rules is frequently an overwhelmingly
    difficult task. Turning human expertise into a series of explicit instructions
    often means laboriously uncovering inferences and decisions that people make without
    even realizing it, turning those into huge numbers of instructions, then adjusting
    and hand-tuning those instructions to cover all of the situations that were initially
    overlooked, debugging the rules where they contradict, and so on, in a seemingly
    never-ending series of tasks performed on a massive, complicated set of rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'This process of finding the rules to accomplish a job is tough work: the rules
    human experts follow are often not explicit, and as we saw, it’s easy to overlook
    exceptions and special cases. Imagine trying to find a comprehensive set of rules
    that can mimic a radiologist’s thought process as they determine whether a smudge
    on an MRI image is benign or not, or the way an air-traffic controller handles
    heavily scheduled air traffic, or how someone drives a car safely in extreme weather
    conditions. To make things even more complex, the technology, laws, and social
    conventions around human activities are constantly changing, requiring us to constantly
    monitor, update, and repair this tangled web of interconnecting rules.'
  prefs: []
  type: TYPE_NORMAL
- en: Rule-based expert systems can be made to work in some cases, but the difficulties
    of crafting the right set of rules, making sure they work properly across a wide
    variety of data, and keeping them up to date, makes them impractical as a general
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: If we could only find and manage this set of rules, then computers could indeed
    emulate some forms of human decision making. This is just what deep learning is
    all about. These algorithms, given enough training data, can discover the decision-making
    rules *automatically.* We don’t have to explicitly tell the algorithm how to recognize
    a 2 or a 7, because the system figures that out for itself. It can work out whether
    an MRI smudge is benign or not, whether a cellphone’s photo has been ideally exposed,
    or whether a piece of text was really written by some historical figure. These
    are all among the many applications deep learning is already carrying out for
    us.
  prefs: []
  type: TYPE_NORMAL
- en: The computer discovers the decision-making rules by examining the input data
    and extracting patterns. The system never “understands” what it’s doing, as a
    person does. It has no common sense, awareness, or comprehension. It just measures
    patterns in the training data and then uses those patterns to evaluate new data,
    producing a decision or result based on the examples it was trained on.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, we train deep learning algorithms in one of three different
    ways, depending on the data we have and what we want the computer to produce for
    us. Let’s survey them briefly.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll first consider *supervised learning*. Here, the word *supervised* is
    a synonym for “labeled.” In supervised learning, we typically give the computer
    pairs of values: an item drawn from a dataset, and a label that we’ve assigned
    to that item.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, we might be training a system called an *image classifier*, with
    the goal of having it tell us what object is most prominent in a photograph. To
    train this system, we’d give it a collection of images, and accompany each image
    with a label describing the most prominent object. So, for example, we might give
    the computer a picture of a tiger and a label consisting of the word *tiger*.
  prefs: []
  type: TYPE_NORMAL
- en: This idea can be extended to any kind of input. Suppose that we have a few cookbooks
    full of recipes that we’ve tried out, and we’ve kept records on how much we liked
    each dish. In this case, the recipe would be the input, and our rating of it would
    be that recipe’s label. After training a program on all of our cookbooks, we could
    give our trained system a new recipe, and it could predict how much we’d enjoy
    eating the result. Generally speaking, the better we’re able to train the system
    (usually by providing more pieces of training data), the better its prediction
    will be.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the type of data, by giving the computer an enormous number of
    pairs of inputs and labels, a successful system designed for the task will gradually
    discover enough rules or patterns from the inputs that it will be able to correctly
    *predict* each provided label. That is, as a result of this training, the system
    has learnedwhat to measure in each input so that it can identify which of its
    learned labels it should return. When it gets the right answer frequently enough
    for our needs, we say that the system has been *trained*.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the computer has no sense of what a recipe actually is, or
    how things taste. It’s just using the data in the input to find the closest matching
    label, using the rules it learned during training.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 1-3](#figure1-3) shows the results of giving four photographs to a
    trained image classifier.'
  prefs: []
  type: TYPE_NORMAL
- en: These photos were found on the web, and the system had never seen them before.
    In response to each image, the classifier tells us the likelihood for each of
    the 1,000 labels it was trained to recognize. Here we show the top five predictions
    for each photo, with their associated probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: The picture in the upper left of [Figure 1-3](#figure1-3) is a bunch of bananas,
    so ideally we’d like to get back a label like bunch of bananas. But this particular
    classifier wasn’t trained on any images labeled bunch of bananas. The algorithm
    can only return one of the labels it was trained on, in the same way that we can
    only identify objects by the words we know. The closest match it could find from
    the labels it was trained on was just banana, so that’s the label it returned
    to us.
  prefs: []
  type: TYPE_NORMAL
- en: '![f01003](Images/f01003.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-3: Four images and their predicted labels, with probabilities, from
    a deep learning classifier'
  prefs: []
  type: TYPE_NORMAL
- en: In the upper left, the computer has very high confidence in the label of banana.
    In the lower right, the computer is about 60 percent confident that the proper
    label is ear. but it’s about 40 percent confident it could be corn. If we follow
    a common practice and return just one label per image to the user, it would be
    helpful to also return the computer’s confidence that the label is correct. If
    the confidence isn’t reassuring, such as only about 60 percent for ear, we might
    decide to try again with a different algorithm, or perhaps even ask a human for
    help.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we don’t have labels associated with our data, we use techniques that are
    known collectively as *unsupervised learning*. These algorithms learn about relationships
    between the elements of the input, rather than between each input and a label.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning is frequently used for *clustering*, or grouping, pieces
    of data that we think are related. For example, suppose that we’re digging out
    the foundation for a new house, and while excavating, we find the ground is filled
    with old clay pots and vases. We call an archaeologist friend who realizes that
    we’ve found a jumbled collection of ancient pottery, apparently from many different
    places and perhaps even different times.
  prefs: []
  type: TYPE_NORMAL
- en: The archaeologist doesn’t recognize any of the markings and decorations, so
    she can’t say for sure where each one came from. Some of the marks look like variations
    on the same theme, but other marks look like different symbols. To get a handle
    on the problem, she takes rubbings of the markings and then tries to sort them
    into groups. But there are far too many for her to sort through, and since all
    of her graduate students are working on other projects, she turns to a machine
    learning algorithm to automatically group the markings together in a sensible
    way.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 1-4](#figure1-4) shows her captured marks and the groupings an algorithm
    might produce.'
  prefs: []
  type: TYPE_NORMAL
- en: '![f01004](Images/f01004.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-4: Using a clustering algorithm to organize marks on clay pots. Left:
    The markings from the pots. Right: The marks grouped into similar clusters.'
  prefs: []
  type: TYPE_NORMAL
- en: Because this technique arranges our data into related groups (or *clusters*),
    we call the process *clustering*, and we refer to this algorithm as a *clustering
    algorithm*.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning algorithms can also be used to improve the quality of
    measured data (for example, removing speckles in a photo taken with a cellphone
    camera) or compress datasets so they take up less room on our disks, without losing
    any qualities we care about (such as what MP3 and JPG encoders do for sound and
    images).
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes we want to train a computer to learn how to perform a task, but we
    don’t even know the best way to do it ourselves. Maybe we’re playing a complex
    game or writing some music. What’s the next best move to take or the next best
    note to choose? Often there isn’t a single best answer. But we might be able to
    roughly say that one answer is better than another. It would be great to be able
    to train a computer to find the best steps toward a good result by letting it
    try out possible approaches, which we only need to rank in a very general manner,
    such as “probably good,” or “better than the last one.”
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose we’re responsible for designing the operation of the elevators
    in a new office building, as in [Figure 1-5](#figure1-5). Our job is to decide
    where elevator cars should wait when they’re not needed, and which car should
    answer a request when someone pushes a call button. Let’s say that our goal is
    to minimize the average wait time for all riders.
  prefs: []
  type: TYPE_NORMAL
- en: '![f01005](Images/f01005.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-5: We want to find the best schedule for these elevators.'
  prefs: []
  type: TYPE_NORMAL
- en: How should we do that? The quality of any solution we might imagine will depend
    entirely on the patterns of when and where people want to travel. Maybe in the
    morning everyone’s arriving for work, so we should always bring empty cars to
    the first floor where they’ll be ready for new arrivals. But perhaps at lunch
    everyone wants to go outside, so we should keep idle cars near the top floors,
    always ready to come down and take people to the ground floor. But if it’s raining,
    perhaps most people will instead want to go to the cafeteria on the top floor.
    Day by day, hour by hour, what’s the best policy?
  prefs: []
  type: TYPE_NORMAL
- en: There probably isn’t any single best policy, so the computer can’t learn to
    give it to us. All we can do is try out different approaches over time, and choose
    the one that seems to be giving us the best results. So we’ll have the computer
    invent a policy, or maybe make a variation on an existing one, and see how well
    it performs. We’ll then give it a score based on the average wait time of our
    riders. After trying out lots of variations, we can pick the policy with the best
    score. And then, over time, as patterns change, we can try out new approaches,
    always searching, but keeping the schedule with the best score.
  prefs: []
  type: TYPE_NORMAL
- en: This is an example of *reinforcement learning (RL)*. The technique of RL is
    at the heart of the recent game-playing algorithms that have been beating human
    masters at games like Go, and even online strategy games like *StarCraft*.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The phrase *deep learning* refers to machine learning algorithms that use a
    series of steps, or *layers,* of computation (Bishop 2006; Goodfellow, Bengio,
    and Courville 2017). We can draw these layers on the page in any way we like as
    long the structure is clear. If we draw the layers vertically, we can imagine
    looking up from the bottom and saying that the system is tall, or, looking down
    from the top and calling it deep. If we draw many layers horizontally, we might
    say that the system is wide. For no particular reason, the “deep” language is
    what caught on, lending its name to the whole field of deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to keep in mind that these systems are called “deep” only because
    of their appearance when we draw them stacked up vertically. They’re not deep
    in the sense of having profound understanding or penetrating insights. When a
    deep learning system attaches a name to a face in a photo, it has no knowledge
    of what faces are, or what people are, or even that people exist. The computer
    just measures pixels and, using the patterns it learned from the training data,
    produces the most likely label.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s jump many chapters ahead and take a quick look at a deep network, pictured
    in [Figure 1-6](#figure1-6). In this simple network, we start with four input
    numbers, shown at the bottom of the figure. These might be the values of the four
    pixels in a 2 by 2 grayscale image, the closing price of a stock over four sequential
    days, or four samples from a snippet of voice data. Each input value is just a
    floating-point number, such as –2.982 or 3.1142\.
  prefs: []
  type: TYPE_NORMAL
- en: '![f01006](Images/f01006.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-6: A simple deep neural network'
  prefs: []
  type: TYPE_NORMAL
- en: Those four values go upward in the diagram into a *layer*, or grouping, of three
    *artificial neurons*. Although they have the word *neuron* in their name and were
    distantly inspired by real neurons, these artificial neurons are extremely simple.
    We’ll see them in detail in Chapter 13, but it’s best to think of them as units
    that perform a tiny calculation and are not remotely as complex as real neurons.
  prefs: []
  type: TYPE_NORMAL
- en: In this diagram, each neuron on layer 1 receives each of the four starting numbers
    as input. Note that each of the 12 lines that take an input value into a neuron
    has a little dot on it. In this figure, each dot represents the idea that the
    input value traveling on that line is multiplied by another number, called the
    *weight,* before it reaches the neuron. These weights are vital to the network,
    and we’ll return to them in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: The output of each artificial neuron in layer 1 is a new number. In [Figure
    1-6](#figure1-6), each of those outputs is fed into each of the neurons on layer
    2, and again each value is multiplied by a weight along the way. Finally, the
    values produced by the two neurons on layer 2 are the output of the network. We
    might interpret these output values to be the chance that the input is in each
    of two classes, or the first and last name of the person who spoke that sound
    fragment, or the predicted price of the stock on each of the next two days.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of the big circles representing an artificial neuron turns its input values
    into a number. These computations are fixed: once we set up the network, each
    of these neurons will always compute the same output for a given input. So, once
    we’ve chosen the artificial neurons and arranged them into the network of [Figure
    1-6](#figure1-6), almost everything is specified.'
  prefs: []
  type: TYPE_NORMAL
- en: The only things in [Figure 1-6](#figure1-6) that can change are the inputs and
    the weights. That’s the key insight that makes it possible to train the network.
    The weights start out as random numbers. That means the output of the network
    will initially be nonsense, and we’ll never get back the results we want (unless
    we happen to occasionally get lucky).
  prefs: []
  type: TYPE_NORMAL
- en: To get the network to reliably produce the answers we want, we carefully change
    the weights, just a little at a time, after each mistaken output, to make the
    network more likely to produce the desired values at the output. If we do this
    carefully, then over time the output values will gradually get closer and closer
    to the results we want. Eventually, if we’ve done our job well, the network will
    produce the right answer in response to almost all the data in our training database,
    and we can release our network to the web, or offer it as a product or service.
  prefs: []
  type: TYPE_NORMAL
- en: In short, training this network, or teaching it, is nothing more than finding
    values for the weights so that every input produces the desired output. Amazingly,
    this is all there is to it! Even when our networks grow to hundreds of layers
    of many varieties, and tens of thousands of artificial neurons, and millions of
    weights, learning usually means just gradually changing the weights until we get
    the answers we want. More sophisticated networks might learn some other values
    as well, but the weights are always important.
  prefs: []
  type: TYPE_NORMAL
- en: One of the beautiful things about this process is that it makes good on the
    promise of feature engineering. For example, consider a system that takes a photo
    as input and tells us what breed of dog is in the picture. When the training process
    for this system has finished and the weights have settled into their best values,
    they have the effect of turning the neurons into little feature detectors. For
    example, one of the neurons on an early layer might produce a large value if it
    “sees” an eye, and another if it “sees” a floppy ear (we’ll see just how this
    is done in Chapter 16). Then later neurons might look for combinations of these,
    such as a bushy tail along with short legs, or dark eyes with a long nose and
    large body, to help it determine the breed. In short, the neurons are looking
    for features, though we never explicitly guided them to. Feature detection is
    just a natural result of training the weights to produce the correct answers.
  prefs: []
  type: TYPE_NORMAL
- en: So although manually building an expert system that acts like a radiologist
    is a near-impossible task, creating a complex deep network and training it successfully
    can implement that agenda automatically. The system finds its own ways of combining
    the values of the pixels in each image into features and then using those features
    to make a determination about whether that image shows healthy tissue or not (Saba
    et al. 2019).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we got a general sense of deep learning. We began with expert
    systems, which required too much manual work to be successful in practice. We
    saw that training a deep learning system usually follows one of three approaches.
    Supervised learning means that we provide a label with every piece of data so
    that we can train the system to predict the correct label for new data. Unsupervised
    learning means that we give the system just the data, without labels, so we train
    the system to cluster the data into similar groups. And reinforcement learning
    means that we score various proposals put forth by the computer in the hope that
    it will eventually come up with an acceptably good solution.
  prefs: []
  type: TYPE_NORMAL
- en: We then looked at a real, but tiny, deep learning system. The basic structure
    organized artificial neurons into layers. Neurons on each layer communicate with
    the neurons on the previous and following layer. It’s the shape of this structure
    when we draw it in this form (like a tall tower of layers) that gives deep learning
    its name.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we saw the importance of the weights, or the values that multiply every
    number before it arrives at the input of an artificial neuron. When we teach a
    system, or we say it’s learning, all we’re usually doing is adjusting these weights.
    When the weights have found sufficiently good values, the system is able to do
    the job we’ve asked of it.
  prefs: []
  type: TYPE_NORMAL
- en: The next few chapters will dig into the background that we’ll need to design
    and build deep learning systems.
  prefs: []
  type: TYPE_NORMAL
