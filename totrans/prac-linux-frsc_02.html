<html><head></head><body><div id="sbo-rt-content"><h2 class="h2" id="ch02"><span epub:type="pagebreak" id="page_11"/><strong><span class="big">2</span><br/>LINUX OVERVIEW</strong></h2>&#13;
<div class="image1"><img src="Images/common01.jpg" alt="Image" width="190" height="189"/></div>&#13;
<p class="noindent">This chapter provides an overview of Linux for digital forensic investigators. It describes the history of Linux, including the significance and influence of Unix, and establishes the definition of “modern Linux” used throughout this book. I explain the role of the Linux kernel, devices, systemd, and the command line shell. I also provide examples of shell and command line basics, followed by a tour of various desktop environments and an overview of the birth and evolution of popular Linux distributions. The chapter concludes with a focus on digital forensics applied to Linux systems, especially in comparison to forensic analysis of other operating systems such as Windows or macOS.</p>&#13;
<h3 class="h3" id="ch00lev1_5"><span epub:type="pagebreak" id="page_12"/><strong>History of Linux</strong></h3>&#13;
<p class="noindent">Understanding the historical roots of operating systems helps to explain the rationale and design decisions leading up to modern Linux systems. Software development, including operating system software, is largely an evolutionary process. Linux has been evolving since Linus Torvalds first announced it, but the core ideas and philosophy behind Linux started a few decades earlier.</p>&#13;
<h4 class="h4" id="ch00lev2_13"><strong><em>Unix Roots</em></strong></h4>&#13;
<p class="noindent">The creation and development of Linux and the associated GNU tools were heavily influenced by Unix, and many Linux concepts and philosophies are taken directly from Unix. To appreciate the Unix roots and similarities to Linux, a section on Unix history is helpful.</p>&#13;
<p class="indent">The early ideas for Unix were born out of a joint research project in the United States between MIT, General Electric, and Bell Telephone Labs. The group was developing the Multics (Multiplexed Information and Computing Service) time-share operating system, but in the spring of 1969, Bell withdrew involvement, leaving its researchers in search of other projects. A Digital Equipment Corporation (DEC) PDP-7 minicomputer was available at the time, and Ken Thompson spent the summer of 1969 developing the basic system components that included a filesystem, the kernel, shell, editor, and assembler. This initial implementation (not yet named) was written in assembly language and intended to be less complex than Multics. Dennis Ritchie and several others joined in the early development effort to create a functioning system. In 1970, the name <em>Unix</em> was coined, jokingly referring to an “emasculated Multics.” Interest in the system had grown within Bell Labs, and a proposal to create a text processing system helped justify the purchase of a PDP-11 in the summer of 1970.</p>&#13;
<p class="indent">The earliest Unix editions were written in assembly language, which was difficult to understand and ran only on hardware for which the code was intended. Dennis Ritchie created the C programming language, a high-level language that was easier to program and could be compiled into machine code for any hardware architecture. The kernel and tools were rewritten in C, which made Unix “portable,” meaning it could be compiled and run on any machine with a C compiler. In 1974, Ken Thompson and Dennis Ritchie submitted a paper to the Association for Computing Machinery (ACM) describing the Unix system.<sup><a id="ch02foot01" href="footnotes.xhtml#ch02foot_01">1</a></sup> The paper was only 11 pages long and described the basic design principles and operation of Unix. The filesystem was a central component of Unix, and everything, including hardware devices, was accessible as a file in a hierarchical tree. The paper described the shell, file redirection and the concept of pipes, and the execution of binary files and shell scripts.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_13"/>Publishing the Unix paper attracted the attention of academia, and free copies of Unix, including source code, were given to universities for research purposes (paying only for shipping and distribution media—much like Linux distributions later on). Further research and development by academic researchers grew, and Bill Joy at the University of California at Berkeley released a version of Unix called the Berkeley Software Distribution, or BSD. Over time, BSD grew to include extensive network hardware support and TCP/IP protocols for the ARPANET (which would become the internet as we know it today). Interest in network connectivity and BSD’s free implementation of TCP/IP was important to universities who wanted to connect to the early internet. BSD started to become a community-driven operating system with contributions from researchers and students from across academia and from around the world. One of the original BSD developers, Kirk McKusick, has a talk titled “A Narrative History of BSD” (multiple versions are available on YouTube).</p>&#13;
<p class="indent">Before Unix, selling computer products involved the development of hardware and writing an operating system (both proprietary). As Unix popularity grew, companies building proprietary computers began using Unix as the operating system.</p>&#13;
<p class="indent">An explosion of Unix systems hit the marketplace, including Silicon Graphics Irix, DEC Ultrix, Sun Microsystems SunOS and Solaris, IBM AIX, HP UX, and others. Versions of Unix software for commodity PCs were also available, including Microsoft’s Xenix, Santa Cruz Operation (SCO) Unix, Univel Unixware, and others. This commercialization led to the issue of Unix licensing and several decades-long legal sagas, first with BSD and AT&amp;T and later between SCO, Novell, and IBM.</p>&#13;
<p class="indent">The commercial proliferation led to many different Unix “flavors,” as each company introduced proprietary modifications for competitive advantage. Unix started to become fragmented and incompatible, leading to the creation of standards like POSIX, The Open Group’s Single Unix Specification, the Common Desktop Environment (CDE), and others.</p>&#13;
<p class="indent">Today, Unix is still found in enterprise computing environments. Steve Jobs made the decision to use Unix for NeXT computers, and this was adopted as the basis for Apple’s OS X Macintosh operating system and later for Apple’s iOS mobile devices.</p>&#13;
<p class="indent">The cost of commercial Unix led to the creation of free alternatives for hobbyists, students, researchers, and others. Two popular alternatives for a free Unix-like system were 386BSD and Minix. A series of articles in <em>Dr. Dobb’s Journal</em> described the 386BSD system, which was based on one of the last free releases of BSD Unix. Two user communities were writing patches for 386BSD and eventually formed FreeBSD and NetBSD, both of which are actively developed today.</p>&#13;
<p class="indent">Minix was a Unix clone developed by Andrew Tanenbaum for university teaching and research. It was initially intended to replace AT&amp;T Unix, which Tanenbaum had used to teach an operating systems class. Minix is still actively developed today, and it played a key role in the creation of Linux.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_14"/>In 1983, Richard Stallman created the GNU project, and named it using the recursive acronym “GNU’s Not Unix!". The goal of GNU was to create a free Unix-like operating system complete with a kernel and userspace. By the early 1990s, the userspace utilities were largely complete and only the kernel was missing. This missing piece was about to be completed by a young student in Finland.</p>&#13;
<p class="indent">The different Unix systems, Unix clones, and other Unix-like systems all share the same underlying <em>Unix philosophy</em>. In essence, this philosophy encourages programmers to create small programs that do one thing well and can interact with one another. Free and open source software has a tendency to follow this philosophy, and this philosophy can (or should) be applied to writing digital forensics software, as well. For example, The Sleuth Kit (TSK) is a forensics toolkit consisting of many small tools, each one performing a specific task, with the output from one tool being usable as input for another. Commercial software has a tendency to be the opposite, which often means massive monolithic tools that try to do everything and avoid interoperability for competitive reasons (although APIs are becoming more common).</p>&#13;
<h4 class="h4" id="ch00lev2_14"><strong><em>Early Linux Systems</em></strong></h4>&#13;
<p class="noindent">Linus Torvalds created Linux while studying at the University of Helsinki. He wanted an alternative to Minix that had a different license, and he preferred a monolithic kernel design (in contrast to Tanenbaum who favored a microkernel). He started writing his own kernel in 1991, using Minix as a development platform. After several months, he mentioned it in a Minix news group and asked for feedback. Some weeks later, he posted an announcement with an FTP site containing the code and a call to contribute:<sup><a id="ch02foot02" href="footnotes.xhtml#ch02foot_02">2</a></sup></p>&#13;
<pre>From: (Linus Benedict Torvalds)&#13;
Newsgroups: comp.os.minix&#13;
Subject: Free minix-like kernel sources for 386-AT&#13;
Date: 5 Oct 91 05:41:06 GMT&#13;
Organization: University of Helsinki&#13;
&#13;
Do you pine for the nice days of minix-1.1, when men were men and&#13;
wrote their own device drivers? Are you without a nice project and&#13;
just dying to cut your teeth on a OS you can try to modify for your&#13;
needs? Are you finding it frustrating when everything works on minix?&#13;
No more allnighters to get a nifty program working? Then this post&#13;
might be just for you :-)&#13;
...&#13;
I can (well, almost) hear you asking yourselves "why?". Hurd will be&#13;
out in a year (or two, or next month, who knows), and I've already got&#13;
minix. This is a program for hackers by a hacker. I've enjouyed doing&#13;
<span epub:type="pagebreak" id="page_15"/>it, and somebody might enjoy looking at it and even modifying it for&#13;
their own needs. It is still small enough to understand, use and&#13;
modify, and I'm looking forward to any comments you might have. I'm&#13;
also interested in hearing from anybody who has written any of the&#13;
utilities/library functions for minix. If your efforts are freely&#13;
distributable (under copyright or even public domain), I'd like to&#13;
hear from you, so I can add them to the system.&#13;
...&#13;
Drop me a line if you are willing to let me use your code.&#13;
Linus</pre>&#13;
<p class="indent">Linus Torvalds created the Linux kernel, which adopted the concepts and philosophy of Unix. GNU tools, like the C compiler, were required to build it. Other GNU tools, like the shell, were necessary to actually use the operating system. A community of curious and excited developers grew around this project, contributing patches and testing the code on different hardware. By 1994, the first kernel considered mature enough for general use was released as version 1.0. Linux kernel development evolved to include multiprocessor support and was ported to other CPU architectures. Developers were implementing support for every hardware device possible (proprietary undocumented hardware was a challenge and still is). This enthusiastic community under the direction of Linus Torvalds continues to develop and improve the Linux kernel we have today.</p>&#13;
<h4 class="h4" id="ch00lev2_15"><strong><em>Early Desktop Environments</em></strong></h4>&#13;
<p class="noindent">In the early days of Unix, graphics terminals (like the Tektronix 4010 series) were separate devices used by graphics programs like computer-aided design (CAD). Graphical terminals were not part of the user interface like graphical user interfaces (GUIs) today. Many experimental and proprietary windowing and desktop systems were available by the mid-1980s, but the introduction of the X Window System changed how users interfaced with computers.</p>&#13;
<p class="indent">In 1984, MIT introduced the open standard X, and after several years of rapid development (11 versions), X11 was released in 1987. This provided a standard protocol for graphical programs (the X11 client) to be displayed on a screen (the X11 server). The X11 protocol could be built into an application and could display windows on any X11 server, even over a network. X11 became generally adopted among commercial Unix vendors producing graphical workstations. Because building workstations included developing graphics hardware, the X11 server was often a proprietary component of the operating system.</p>&#13;
<p class="indent">Free Unix-like operating systems needed a free X11 server for commodity PC graphic cards. In 1992, the XFree86 project was created to fill this gap and allow the development of free X11 desktops on PCs running BSDs and Linux. In 2004, the <a href="http://X.Org">X.Org</a> Foundation (<em><a href="https://x.org/">https://x.org/</a></em>) was created and forked a version of XFree86 as an X11 reference implementation. A change <span epub:type="pagebreak" id="page_16"/>in license and disagreement among XFree86 developers caused <a href="http://X.Org">X.Org</a> to become the de facto standard Linux X11 implementation.<sup><a id="ch02foot03" href="footnotes.xhtml#ch02foot_03">3</a></sup></p>&#13;
<p class="indent">X11 is simply a protocol standard. It does not provide window management or a desktop environment. To manage X11 windows, a separate window manager is needed. A <em>window manager</em> (just another X11 client application) speaks the X11 protocol and is responsible for basic window functions such as resizing, moving, and minimizing. Window managers also provided window decorations, title bars, buttons, and other GUI features. Multiple window managers became available to offer choice in Linux distributions. Popular window managers in the first Linux distributions, commonly referred to as distros, were TWM and FVWM. For more information about classic window managers, see <em><a href="http://www.xwinman.org/">http://www.xwinman.org/</a></em>.</p>&#13;
<p class="indent">X11 applications are built with graphical <em>widgets</em> to create menus, buttons, scroll bars, toolbars, and so on. These widgets give the application a unique look and feel. Developers are free to create their own widgets, but most use the libraries included with a system. Early examples of widget toolkits include Athena, OPEN LOOK, and Motif. X11 desktop applications can use any style of graphical widget they want; no system-wide standard is enforced, which can lead to an inconsistent desktop appearance when every application uses a different toolkit. The two most common toolkits used with Linux today are GTK (used with GNOME) and Qt (used with KDE).</p>&#13;
<p class="indent">However, having window managers and widget toolkits was not enough to provide the full desktop experience that users expected. Functionality was needed for application launchers, trash cans, wallpaper, themes, panels, and other typical elements you’d expect in a modern computer desktop. The Unix community created CDE to provide a standard full-featured desktop that was vendor independent. This was (initially) not open, so the free and open source community developed its own desktop standards (XDG and <em><a href="http://freedesktop.org">freedesktop.org</a></em>).</p>&#13;
<h3 class="h3" id="ch00lev1_6"><strong>Modern Linux Systems</strong></h3>&#13;
<p class="noindent">The Linux kernel and Linux distributions have advanced beyond being basic Unix clones. Many new technologies have been independently developed for Linux that are not derived from Unix. Many legacy technologies also have been replaced in newer versions of Linux. These technological advancements help differentiate traditional Linux from modern Linux.</p>&#13;
<p class="indent">Rather than covering forensic analysis topics involving traditional Unix and early Linux systems, this book focuses on the forensic analysis of modern Linux system components. The rest of this section provides an overview of these new or different components for those who are less familiar with modern Linux.</p>&#13;
<h4 class="h4" id="ch00lev2_16"><span epub:type="pagebreak" id="page_17"/><strong><em>Hardware</em></strong></h4>&#13;
<p class="noindent">To analyze a Linux system in a forensic context, you want to determine (as accurately as possible) what hardware has been physically installed or attached to the system since it was installed. The kernel manages hardware devices and leaves traces of added or removed hardware in the logs.</p>&#13;
<p class="indent">Internal devices might be integrated on the mainboard (onboard), plugged in to PCI Express slots (including M.2 slots), plugged in to SATA ports, or attached to other pin-blocks on the mainboard. Examples of internal hardware components to identify may include:</p>&#13;
<ul>&#13;
<li class="noindent">Mainboard (describing the board itself)</li>&#13;
<li class="noindent">Onboard devices (integrated into mainboard)</li>&#13;
<li class="noindent">PCI Express devices (graphic cards and other PCIe cards)</li>&#13;
<li class="noindent">Internal drives (SATA or NVMe)</li>&#13;
<li class="noindent">Network devices (wireless or wired)</li>&#13;
</ul>&#13;
<p class="indent">Linux does not require a reinstallation when a mainboard is replaced (upgraded) with another one, so more than one mainboard might be identified. Physical examination of the mainboard may also include reading out the NVRAM to analyze the UEFI variables and other BIOS information.</p>&#13;
<p class="indent">Another internal interface is the Advanced Configuration and Power Interface (ACPI), which was developed so that operating systems could control various aspects of power management to the system and components. Linux supports the ACPI interface and typically manages events through systemd or the acpid daemon.</p>&#13;
<p class="indent">External hardware components are typically attached by USB, Thunderbolt, DisplayPort, HDMI, or other external connectors. Examples of external hardware components or peripherals to identify may include:</p>&#13;
<ul>&#13;
<li class="noindent">External storage media</li>&#13;
<li class="noindent">Mouse and keyboard</li>&#13;
<li class="noindent">Video monitors</li>&#13;
<li class="noindent">Printers and scanners</li>&#13;
<li class="noindent">Webcams, cameras, and video equipment</li>&#13;
<li class="noindent">Audio devices</li>&#13;
<li class="noindent">Mobile devices</li>&#13;
<li class="noindent">Any other external peripheral devices</li>&#13;
</ul>&#13;
<p class="indent">The identification of hardware from a forensically acquired disk image will rely on traces in the logs, configuration files, and other persistent data. Physical examination of seized hardware should correlate with traces found on the forensic image.</p>&#13;
<h4 class="h4" id="ch00lev2_17"><span epub:type="pagebreak" id="page_18"/><strong><em>The Kernel</em></strong></h4>&#13;
<p class="noindent">The kernel is the heart of a Linux system. It provides the interface between the user programs (called <em>userspace</em> or <em>userland</em>) and the hardware. The kernel detects when hardware is attached or removed from a system and makes those changes visible to the rest of the system. Overall, the kernel is responsible for many tasks, including the following:</p>&#13;
<ul>&#13;
<li class="noindent">Memory, CPU, and process management</li>&#13;
<li class="noindent">Hardware device drivers</li>&#13;
<li class="noindent">Filesystems and storage</li>&#13;
<li class="noindent">Network hardware and protocols</li>&#13;
<li class="noindent">Security policy enforcement</li>&#13;
<li class="noindent">Human interface and peripheral devices</li>&#13;
</ul>&#13;
<p class="indent"><a href="ch02.xhtml#ch02fig01">Figure 2-1</a> shows an architectural overview of the Linux kernel and its subsystems.<sup><a id="ch02foot04" href="footnotes.xhtml#ch02foot_04">4</a></sup></p>&#13;
<div class="image"><img id="ch02fig01" src="Images/ch02fig01.jpg" alt="Image" width="695" height="353"/></div>&#13;
<p class="figcap"><em>Figure 2-1: Linux kernel architecture (modified from</em> <span class="normal"><a href="https://github.com/makelinux/linux_kernel_map/">https://github.com/makelinux/linux_kernel_map/</a></span><em>)</em></p>&#13;
<p class="indent">The kernel has gained many new features over the years. The ability to perform advanced isolation of processes using cgroups and namespaces forms the basis for containers. New filesystems such as btrfs were designed specifically for Linux systems. The btrfs filesystem merges storage features previously found in separate components (like RAID or LVM) to provide snapshots, subvolumes, and other volume management capabilities. New firewall technology like nftables is replacing the traditional iptables with a faster, more efficient operation and cleaner rulesets. New VPN technology <span epub:type="pagebreak" id="page_19"/>like WireGuard is a simpler alternative to the aging IPsec and OpenVPN standards.</p>&#13;
<p class="indent">The kernel is executed by a bootloader when a system is started. The bootloader technology has transitioned from the traditional MBR (BIOS execution of sector zero) to the more advanced UEFI (firmware using GPT partitions, UEFI binaries, and EFI variables). During operation, the kernel can be dynamically changed and configured, and more functionality can be added with loadable kernel modules. When a system is shut down, the kernel is the last thing to stop running.</p>&#13;
<p class="indent">This book will cover all of these newer technologies from a digital forensic investigation perspective.</p>&#13;
<h4 class="h4" id="ch00lev2_18"><strong><em>Devices</em></strong></h4>&#13;
<p class="noindent">A Linux device is a special file, typically located in <em>/dev/</em>, that provides access to device drivers in the kernel. The device drivers in the kernel interface with physical hardware components or create pseudo-devices. Device files are created as either a <em>block</em> or <em>character</em> device type. Block devices move data in chunks (buffered blocks), and character devices move data in a continuous stream (unbuffered). Linux storage devices (hard disks, SSDs, and so forth) are typically block devices.</p>&#13;
<p class="indent">Most Linux forensic tools are designed to operate directly on forensically acquired image files. However, many useful troubleshooting, debugging, and diagnostic tools operate only on Linux device files. In those situations, the suspect drive either needs to be attached to the analysis system with a write blocker, or a loop device can be used. Linux is able to associate a regular file with a special loop device that behaves like a physically attached drive, which makes it possible to access forensic image files with tools that normally operate only on devices.</p>&#13;
<p class="indent">You can use the <code>losetup</code> tool to create loop devices. In this example, a loop device is created for a forensically acquired image file named <em>image.raw</em>:</p>&#13;
<pre>$ <span class="codestrong1">sudo losetup --find --read-only --partscan --show image.raw</span>&#13;
/dev/loop0&#13;
$ <span class="codestrong1">ls /dev/loop0*</span> &#13;
/dev/loop0 /dev/loop0p1 /dev/loop0p2</pre>&#13;
<p class="noindent">The <code>sudo</code> command executes <code>losetup</code> as a privileged user (root). The first two flags tell <code>losetup</code> to map the image file to the next available loop device it finds (<em>/dev/loop0</em>) in a read-only manner. The last two flags instruct the kernel to scan the image’s partition table and show the loop device’s name on completion (<em>/dev/loop0</em>).</p>&#13;
<p class="indent">The following <code>ls</code> command shows the partition loop devices that were created (<code>loop0p1</code> and <code>loop0p2</code>). You can view the partition table on <em>/dev/loop0</em> with regular forensic tools, as follows:</p>&#13;
<pre>$ <span class="codestrong1">sudo fdisk -l /dev/loop0</span>&#13;
Disk /dev/loop0: 20 GiB, 21474836480 bytes, 41943040 sectors&#13;
<span epub:type="pagebreak" id="page_20"/>Units: sectors of 1 * 512 = 512 bytes&#13;
Sector size (logical/physical): 512 bytes / 512 bytes&#13;
I/O size (minimum/optimal): 512 bytes / 512 bytes&#13;
Disklabel type: dos&#13;
Disk identifier: 0xce7b65de&#13;
&#13;
Device        Boot     Start       End   Sectors   Size Id Type&#13;
/dev/loop0p1            2048  24188109  24186062  11.5G 83 Linux&#13;
/dev/loop0p2        24188110  41929649  17741540   8.5G 82 Linux swap / Solaris</pre>&#13;
<p class="noindent">Here the <code>fdisk</code><sup><a id="ch02foot05" href="footnotes.xhtml#ch02foot_05">5</a></sup> command reads the device like a normal attached drive and displays the partition table of the image file. Any tool that works with block devices should also be able to access image files in this manner.</p>&#13;
<p class="indent">The examples shown in this book use a variety of tools and techniques. Each tool may require a different form of access to a drive, forensic image file, or even a mounted filesystem. To help avoid confusion, I’ll use the following naming scheme in subsequent examples:</p>&#13;
<div class="bqparan">&#13;
<p class="noindentin"><strong><em>image.raw</em></strong> A forensically acquired raw image file (using sector offsets for the filesystem)</p>&#13;
<p class="noindentin"><strong><em>partimageX.raw</em></strong> A separately extracted partition image file(s) containing only the partition contents (usually the filesystem)</p>&#13;
<p class="noindentin"><strong><em>/dev/sda</em></strong> A block device (in <em>/dev/</em>) physically attached or using a loopback (<code>losetup</code>)</p>&#13;
<p class="noindentin"><strong><em>/dev/loopX</em></strong> A block device associated with a forensic image file</p>&#13;
<p class="noindentin"><strong><em>/evidence/</em></strong> A path to a mounted filesystem of a suspect/victim drive</p>&#13;
</div>&#13;
<p class="noindent">If there is no leading forward slash (/), the paths to files and directories are relative to the current working directory.</p>&#13;
<h4 class="h4" id="ch00lev2_19"><strong><em>Systemd</em></strong></h4>&#13;
<p class="noindent">Throughout this book you will find many references to systemd. <em>Systemd</em> is an initialization system (called <em>init</em>), a system manager, and a service manager. Among popular Linux distros, systemd has become the de facto system layer between the kernel and userland. There are systemd commands to start and stop background programs (called daemons or services), power off and reboot the system, view logs, and check the status of services and the overall state of the system. You can edit different systemd text files (unit files and configuration files) to customize system behavior. Systemd basically manages the overall system running outside the kernel from initial startup to shutdown.</p>&#13;
<p class="indent">The introduction of systemd to the Linux community was not without debate, and involved a transition away from the traditional Unix sysvinit initialization system. This book contains significant coverage of systemd <span epub:type="pagebreak" id="page_21"/>because it has been adopted by all the major Linux distributions. From a digital forensics perspective, systemd provides many forensic artifacts and evidence traces that could be interesting for an investigation.</p>&#13;
<p class="indent">The systemd project is well documented and man pages are available for nearly everything in systemd. As a starting point, see the systemd(1) man page or type <span class="codestrong">apropos systemd</span> at a Linux command line.</p>&#13;
<p class="indent">The introduction of systemd has caused a fundamental shift toward starting daemons using on-demand activation rather than explicitly starting daemons at boot. This is done both at the system level and user level. At the user level, it becomes unnecessary to start many background programs from login shell scripts because those programs are now started automatically as needed. This was done mainly for performance reasons, but the additional log entries generated from starting and stopping programs can be useful in the forensic reconstruction of past activity.</p>&#13;
<h4 class="h4" id="ch00lev2_20"><strong><em>The Command Line</em></strong></h4>&#13;
<p class="noindent">The shell is a program that provides a command line interpreter used to interface with people (typing commands) or shell scripts (running commands from a file). The shell runs in userspace and is executed by either the system or a logged-in user. This is different from the graphical shell that is part of the desktop environment. The shell and associated concepts are taken directly from Unix.</p>&#13;
<p class="indent">The most common shell on Linux is <em>Bash (Bourne-again shell)</em>.<sup><a id="ch02foot06" href="footnotes.xhtml#ch02foot_06">6</a></sup> Users can change their default shell, and many shells are available to choose from. Two popular alternatives today are zsh and fish. The zsh shell is highly customizable and a favorite of some power users. The fish shell is designed more for comfortable human interaction. Shells are just normal programs that can be executed (you can even run another shell from your current shell).</p>&#13;
<p class="indent">Modern desktop users may never need to use a shell prompt. To interact with a shell, you need to log in to the console (locally or remotely with SSH) or open a terminal emulator in your desktop environment. Once you have a shell (typically a dollar sign followed by a cursor), you can enter commands.</p>&#13;
<p class="indent">Shell commands may be part of the shell program itself (built-in commands), or they can be the names of programs you want to run. You can specify configuration information by adding flags or parameters after a command and you can set environment variables to configure a shell.</p>&#13;
<p class="indent">The most powerful shell concepts are piping and redirection. Piping allows the output from one program to be sent directly to the input of another program. Redirection allows programs to take input from files and send output to files. The shell provides all of this functionality; it doesn’t need to be built in to each program (this is all part of the Unix philosophy mentioned earlier).</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_22"/>The command line symbols used to connect programs and files together are as follows:</p>&#13;
<div class="bqparan">&#13;
<p class="noindentin"><span class="codestrong">&gt;</span>     Sends data from a program to a file (creates file if needed)</p>&#13;
<p class="noindentin"><span class="codestrong">&gt;&gt;</span>    Appends data from a program to a file (creates file if needed)</p>&#13;
<p class="noindentin"><span class="codestrong">&lt;</span>     Sends data from a file to a program</p>&#13;
<p class="noindentin"><span class="codestrong">|</span>     Sends data from one program to another program</p>&#13;
</div>&#13;
<p class="indent">Here are some examples to illustrate piping and redirection with programs and files on the command line:</p>&#13;
<pre>$ <span class="codeitalic1">program</span> &lt; <span class="codeitalic1">file</span>&#13;
$ <span class="codeitalic1">program</span> &gt; <span class="codeitalic1">file</span>&#13;
$ <span class="codeitalic1">program</span> &gt;&gt; <span class="codeitalic1">file</span>&#13;
$ <span class="codeitalic1">program1</span> | <span class="codeitalic1">program2</span>&#13;
$ <span class="codeitalic1">program1</span> | <span class="codeitalic1">program2</span> | <span class="codeitalic1">program3</span>&#13;
$ <span class="codeitalic1">program1</span> &lt; <span class="codeitalic1">file1</span> | <span class="codeitalic1">program2</span> | <span class="codeitalic1">program3</span> &gt; <span class="codeitalic1">file2</span></pre>&#13;
<p class="noindent">The first three examples show a program run using input and output from a file. The next two examples show a program sending output to another program (or programs). You can also use multiple pipes and redirects in series on the command line. In the last example, data from <span class="codeitalic">file1</span> is redirected into <span class="codeitalic">program1</span>, output from <span class="codeitalic">program1</span> is piped into <span class="codeitalic">program2</span>, output from <span class="codeitalic">program2</span> is piped into <span class="codeitalic">program3</span>, and, lastly, output from <span class="codeitalic">program3</span> is redirected into <span class="codeitalic">file2</span>.</p>&#13;
<p class="indent">From a digital forensics perspective, the shell is interesting because it can save a history of the commands that a user entered. The forensic analysis of shell history is covered in a later section.</p>&#13;
<h4 class="h4" id="ch00lev2_21"><strong><em>Modern Desktop Environments</em></strong></h4>&#13;
<p class="noindent">Modern Linux desktop environments are either built on top of X11 and a window manager (discussed in an earlier section) or integrated with a Wayland compositor. Desktop environments (sometimes called DEs or desktop shells) provide functionality like application launchers, trash cans, wallpaper, themes, panels, and other features. The most common desktop environments in use today are GNOME and KDE. Other popular desktops include MATE, Cinnamon, Xfce, LXDE, and Enlightenment. Each of these environments provides a different look and feel.</p>&#13;
<p class="indent">A set of community standards was formed to provide underlying interoperability between desktop environments. These are known as the <em>Cross-Desktop Group (XDG) specifications</em>. See the specifications page at <em><a href="https://www.freedesktop.org/">https://www.freedesktop.org/</a></em> for more details.</p>&#13;
<p class="indent">Some features with documented specifications that standardize interoperability across desktop environments include the following:</p>&#13;
<ul>&#13;
<li class="noindent">Autostart applications</li>&#13;
<li class="noindent">Default applications</li>&#13;
<li class="noindent"><span epub:type="pagebreak" id="page_23"/>Trash cans or recycle bins</li>&#13;
<li class="noindent">Desktop bookmarks or recent files</li>&#13;
<li class="noindent">Clipboard management</li>&#13;
<li class="noindent">Thumbnails</li>&#13;
<li class="noindent">Desktop trays</li>&#13;
<li class="noindent">Status notifications</li>&#13;
<li class="noindent">Password managers</li>&#13;
</ul>&#13;
<p class="noindent">Clearly this list is also interesting for digital forensic examiners and will be covered in a later section.</p>&#13;
<p class="indent">To ease the learning curve for new users, the original computer desktops attempted to replicate physical desktops, which is referred to as the <em>desktop metaphor</em>. This included overlapping windows (like overlapping sheets of paper), folder icons (like paper folders), and so on. In recent years, the trend is moving away from the traditional desktop metaphor toward desktop shells that behave differently, using features such as tiling, tabbing, or fullscreen windows.</p>&#13;
<p class="indent">The current trend is to replace X11-based desktops with Wayland. The Wayland protocol was developed from scratch and is intended to modernize Linux graphics, eliminate unused functionality, and take better advantage of local hardware.</p>&#13;
<p class="indent">One of X11’s design goals was networking. If a site had a powerful central Unix server and distributed X11 terminals (called thin clients today), users could run programs on the central machine but display them on the screen of the terminal. This feature of X11 is largely obsolete today due to powerful client machines, client/server applications, and remote desktop protocols. Wayland drops support for integrated networking of individual windows.</p>&#13;
<p class="indent">X11 has security issues. Once a client application is able to use the X11 server, it is considered trusted. The client is then authorized to snoop around the rest of the desktop, observing the contents of other windows and intercepting keystrokes. This is how screenshot programs, remote screen sharing, and programmable hotkey programs work. Wayland was developed with security in mind and doesn’t trust applications.</p>&#13;
<p class="indent">Installing a graphical desktop environment is optional for Linux servers. Servers can operate with a monitor and text-based console for shell access. Even the monitor is optional, in which case the server is operating in <em>headless</em> mode, and logins must be done over a network.</p>&#13;
<h3 class="h3" id="ch00lev1_7"><strong>Linux Distributions</strong></h3>&#13;
<p class="noindent">Strictly speaking, only the Linux kernel is the actual operating system. The rest of the system, such as the shell, tools, GUI, software packages, and so on, are not Linux. Those things may be part of a Linux distribution, but Linux technically refers only to the kernel.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_24"/>However, practically speaking, people use the term <em>Linux</em> to refer to more than just the kernel and think about Linux in terms of distributions (or “distros"). This section describes the rise of the Linux distribution.</p>&#13;
<h4 class="h4" id="ch00lev2_22"><strong><em>The Evolution of Linux Distributions</em></strong></h4>&#13;
<p class="noindent">Originally, building a system based on a Linux kernel required a significant amount of technical knowledge. It meant downloading the sources (for the kernel and other programs) from FTP sites, unpacking, compiling on a Minix system, and manually copying the files to the target filesystem. Configuration was done by hand using text editors (like vi). Updates and patches were also done by hand (a repeat of the just-described process). This arrangement was fine for developers and hackers, but it wasn’t okay for regular users.<sup><a id="ch02foot07" href="footnotes.xhtml#ch02foot_07">7</a></sup></p>&#13;
<p class="indent">The first Linux systems required a significant amount of manual technical work to install and maintain. Before the proliferation of Linux distributions, nearly everything was a manual process. Linux distros were needed to fill this gap. Distributions were invented to make it easier for people to install, configure, and maintain their Linux-based systems. By the end of 1992, two complete and functional Linux distros were available. Peter MacDonald of Canada created the Softlanding Linux System (SLS), and Adam Richter of Berkeley, California, created Yggdrasil Linux. Once distributions made Linux easier for people to install, it started to become more popular outside the kernel developer community. Over time, the features offered by distros became significant enough to be commercially profitable.</p>&#13;
<p class="indent">The typical components that make up a distro today include:</p>&#13;
<ul>&#13;
<li class="noindent">Boot media (ISO images for CD, DVD, or USB stick)</li>&#13;
<li class="noindent">Installer scripts and tools</li>&#13;
<li class="noindent">Package management system</li>&#13;
<li class="noindent">Precompiled packages (compiling from source optional)</li>&#13;
<li class="noindent">Configuration management</li>&#13;
<li class="noindent">Preconfigured desktop environments</li>&#13;
<li class="noindent">Documentation (online or in print)</li>&#13;
<li class="noindent">Updates and security advisories</li>&#13;
<li class="noindent">Support forums and user mailing lists</li>&#13;
<li class="noindent">Distro philosophy, vision, mission, or style</li>&#13;
</ul>&#13;
<p class="indent">Distros may have periodic release dates that follow a traditional software life-cycle model. However, a more recent model is the <em>rolling release</em>, which simply means there are no fixed versions or release dates. The packages are constantly updated and the release version is associated with the last time <span epub:type="pagebreak" id="page_25"/>you updated. This system can introduce instability risks, but users don’t have to wait to get the latest software.</p>&#13;
<p class="indent">Linux distros can be non-profit or commercial. Non-profit distros like Debian, Arch, Slackware, or Gentoo are typically free and open source, and are maintained by volunteers. However, money is still needed for server hardware, network infrastructure, and network bandwidth, so project teams typically raise money from donations or selling swag (T-shirts, coffee mugs, stickers, and so on).</p>&#13;
<p class="indent">Commercial distros like SUSE, Red Hat, or Ubuntu (Canonical) have staff employed and are regular for-profit companies. Due to the GPL license, commercial companies are not permitted to sell Linux software; however, they are allowed to make money from distribution media, subscriptions, services, and support. Many commercial distros also have separate free distros (openSUSE and Fedora, for example), which are used as a testing ground for upcoming commercial releases.</p>&#13;
<p class="indent">A number of distros are based on other distros and simply add additional software, customization, and configuration. For example, Ubuntu is based on Debian, CentOS Stream is based on Red Hat Enterprise Linux, and Manjaro is based on Arch Linux. Some distros even are based on distros that are themselves based on another distro. For example, Linux Mint is based on Ubuntu, which is based on Debian.</p>&#13;
<p class="indent">There are also many specialty distributions that are typically based on another distro but built for a specific purpose. For example, Raspian is a distro for Raspberry Pi hardware, Kali Linux is designed for pentesting and forensics, Tails is designed for privacy and anonymity, and Android is designed for mobile devices.</p>&#13;
<p class="indent">Knowing which distro you’re analyzing is important because each one has slightly different forensic artifacts. The most common distributions are described in the following sections. See Distrowatch for a current list of popular Linux distributions (<em><a href="https://distrowatch.com/">https://distrowatch.com/</a></em>).</p>&#13;
<h4 class="h4" id="ch00lev2_23"><strong><em>Debian-Based Distributions</em></strong></h4>&#13;
<p class="noindent">Ian Murdock started Debian Linux in 1993 while a student at Purdue University. Debian was initially created out of Murdock’s dissatisfaction with SLS Linux, and grew to be one of the most popular distributions available.</p>&#13;
<p class="indent">The Debian distribution maintains three releases:</p>&#13;
<div class="bqparan">&#13;
<p class="noindentin"><strong>Stable</strong> The latest production release, which is recommended for general use</p>&#13;
<p class="noindentin"><strong>Testing</strong> The next upcoming release candidate being tested and matured</p>&#13;
<p class="noindentin"><strong>Unstable</strong> The current development snapshot (always has the code name <em>Sid</em>)</p>&#13;
</div>&#13;
<p class="noindent">Debian release code names are taken from characters in the Disney <em>Toy Story</em> movies and are assigned to major release numbers. New major versions are <span epub:type="pagebreak" id="page_26"/>released roughly every two years. Minor updates or <em>point releases</em> happen every few months and contain security and bug fixes.</p>&#13;
<p class="indent">Debian is focused on freedom and is closely aligned with the GNU project (the documentation even refers to Debian as “GNU/Linux”). Debian has well-documented policies, standards, guidelines, and a social contract outlining the project philosophy.</p>&#13;
<p class="indent">Many Debian-based distributions have been developed for non-technical end users. These distros are easy to install and use and have desktop environments on par with Windows and macOS (I present some of these in the lists that follow).</p>&#13;
<p class="indent">Ubuntu has been one of the more popular Debian-based distributions for Linux newcomers. It has a server version and a desktop version. Ubuntu has several flavors depending on the desktop environment used:</p>&#13;
<div class="bqparan">&#13;
<p class="noindentin"><strong>Ubuntu</strong> Uses the GNOME desktop environment (the main distro)</p>&#13;
<p class="noindentin"><strong>Kubuntu</strong> Uses the KDE desktop environment</p>&#13;
<p class="noindentin"><strong>Xubuntu</strong> Uses the Xfce desktop environment</p>&#13;
<p class="noindentin"><strong>Lubuntu</strong> Uses the LXDE desktop environment</p>&#13;
</div>&#13;
<p class="noindent">The underlying operating system is still Ubuntu (and is based on Debian), but the graphical interface varies with each flavor.</p>&#13;
<p class="indent">Linux Mint, also based on Ubuntu (with one release based on Debian), was designed to look elegant and be comfortable to use, and it uses the traditional desktop metaphor. It comes in several flavors:</p>&#13;
<div class="bqparan">&#13;
<p class="noindentin"><strong>Mint Cinnamon</strong> Based on Ubuntu with GNOME 3</p>&#13;
<p class="noindentin"><strong>Mint MATE</strong> Based on Ubuntu with GNOME 2</p>&#13;
<p class="noindentin"><strong>Mint Xfce</strong> Based on Ubuntu with Xfce</p>&#13;
<p class="noindentin"><strong>Linux Mint Debian Edition (LMDE)</strong> Based on Debian with GNOME 3</p>&#13;
</div>&#13;
<p class="indent">The Raspberry Pi ships with a version of Debian called Raspian. It is designed to be lightweight and integrates with Raspberry Pi hardware.</p>&#13;
<h4 class="h4" id="ch00lev2_24"><strong><em>SUSE-Based Distributions</em></strong></h4>&#13;
<p class="noindent">In 1992, Roland Dyroff, Thomas Fehr, Burchard Steinbild, and Hubert Mantel formed the German company SUSE. SUSE was an abbreviation for <em>Software und System-Entwicklung</em>, which translates to “software and systems development.” SUSE initially sold a German version of SLS Linux, but produced its own SUSE Linux distribution for the German market in 1994. Several years later, it expanded to other parts of Europe and then internationally. Today, it’s called SUSE Software Solutions Germany GmbH and is an independent company. OpenSUSE is a free community version of SUSE Linux and is sponsored by SUSE and others.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_27"/>The commercial and community releases of SUSE Linux are as follows:</p>&#13;
<div class="bqparan">&#13;
<p class="noindentin"><strong>SUSE Linux Enterprise Server (SLES)</strong> Commercial product</p>&#13;
<p class="noindentin"><strong>SUSE Linux Enterprise Desktop (SLED)</strong> Commercial product</p>&#13;
<p class="noindentin"><strong>openSUSE Leap</strong> Regular release version</p>&#13;
<p class="noindentin"><strong>openSUSE Tumbleweed</strong> Regular release version</p>&#13;
</div>&#13;
<p class="indent">Although SUSE has traditionally focused on the KDE desktop, it also has GNOME and other desktop versions. SUSE has a strong presence in German-speaking as well as other regions throughout Europe.</p>&#13;
<h4 class="h4" id="ch00lev2_25"><strong><em>Red Hat–Based Distributions</em></strong></h4>&#13;
<p class="noindent">Red Hat Linux (both a company and a Linux distribution) was created by Marc Ewing in 1994. It had its own package manager (called <em>pm</em>) and installer. Another small company run by Canadian Bob Young managed the product distribution. The two companies merged, and later became the Red Hat as we know it today. Red Hat is a popular name known to the public (largely due to press surrounding the stock market IPO), but it is actually based on the Fedora distribution. Fedora is Red Hat’s community distribution, and Fedora releases become part of Red Hat’s commercial products.</p>&#13;
<p class="indent">Several Linux distributions are associated with Red Hat:</p>&#13;
<div class="bqparan">&#13;
<p class="noindentin"><strong>Fedora</strong> Workstation and server editions</p>&#13;
<p class="noindentin"><strong>Fedora Spins</strong> Fedora workstation with alternative desktops</p>&#13;
<p class="noindentin"><strong>Fedora Rawhide</strong> Rolling release development version</p>&#13;
<p class="noindentin"><strong>Red Hat Enterprise Linux (RHEL)</strong> Commercial product built from Fedora</p>&#13;
<p class="noindentin"><strong>CentOS Stream</strong> A community rolling-release distro based on RHEL</p>&#13;
</div>&#13;
<p class="indent">The default Fedora and RHEL desktops use GNOME. Red Hat’s developers have taken a lead in developing various standards that other distros use, such as systemd, PulseAudio, and various GNOME components.</p>&#13;
<h4 class="h4" id="ch00lev2_26"><strong><em>Arch-Based Distributions</em></strong></h4>&#13;
<p class="noindent">Arch Linux was developed by Canadian Judd Vinet in 2001, with the first release in 2002. Arch is a non-commercial Linux distribution.</p>&#13;
<p class="indent">Arch is one of the first rolling-release distributions. The installation and configuration of Arch Linux is based on the command line (the install ISO boots to a root shell and waits for commands), and users are expected to follow instructions on the Arch wiki to install various components. Each component must be individually installed.</p>&#13;
<p class="indent">The terse installation process of Arch was difficult for new Linux users, but there was a demand for a rolling release. Manjaro Linux addresses both</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_28"/>needs, as it’s based on Arch and has a friendly graphical installation process. Manjaro Linux installs as a fully operational system.</p>&#13;
<h4 class="h4" id="ch00lev2_27"><strong><em>Other Distributions</em></strong></h4>&#13;
<p class="noindent">This book largely covers the forensic analysis of Debian-, Fedora-, SUSE-, and Arch-based distributions. These four distros are the foundation for the vast majority of Linux installations.</p>&#13;
<p class="indent">Other independent Linux distributions also have active communities of users and developers; for example:</p>&#13;
<div class="bqparan">&#13;
<p class="noindentin"><strong>Gentoo</strong> A distro built with scripts that compile packages from source</p>&#13;
<p class="noindentin"><strong>Devuan</strong> A fork of Debian that doesn’t use systemd</p>&#13;
<p class="noindentin"><strong>Solus</strong> A distro designed for an aesthetic appearance and that uses the Budgie desktop</p>&#13;
<p class="noindentin"><strong>Slackware</strong> A distro started in 1993 that aims to be “Unix-like”</p>&#13;
</div>&#13;
<p class="indent">You can forensically analyze all of these distros by employing the methods described in this book. The only differences will be with the distribution-specific areas, in particular the installers and package managers. In addition, the initialization process may be different on some distros and may use the traditional Unix sysvinit.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>As an aside, I’d like to highlight Linux From Scratch (LFS). LFS is not a traditional distro, but rather a book or instruction manual. The book describes the process of downloading packages directly from different developers, compiling and installing the source, and manually configuring the system. Anyone planning a technical career in Linux should install an LFS system once, as doing so provides a rich learning experience. You can find more information at</em> <a href="https://linuxfromscratch.org/">https://linuxfromscratch.org/</a><em>.</em></p>&#13;
</div>&#13;
<h3 class="h3" id="ch00lev1_8"><strong>Forensic Analysis of Linux Systems</strong></h3>&#13;
<p class="noindent">Performing a forensic examination of a Linux system has many similarities to Windows or macOS systems. Some examples of forensic tasks common to all three include:</p>&#13;
<ul>&#13;
<li class="noindent">Partition table analysis (DOS or GPT)</li>&#13;
<li class="noindent">Reconstructing the boot process</li>&#13;
<li class="noindent">Understanding user desktop activity</li>&#13;
<li class="noindent">Looking for photo and video directories</li>&#13;
<li class="noindent">Looking for recent documents</li>&#13;
<li class="noindent">Attempting to recover deleted files from the filesystem or trash/recycle bins</li>&#13;
<li class="noindent"><span epub:type="pagebreak" id="page_29"/>Building timelines to reconstruct events</li>&#13;
<li class="noindent">Analyzing thumbnail images, clipboard data, and desktop information</li>&#13;
<li class="noindent">Identifying applications used</li>&#13;
<li class="noindent">Finding configuration files, logs, and cache</li>&#13;
<li class="noindent">Analyzing installed software</li>&#13;
</ul>&#13;
<p class="indent">The main operating system differences are the locations and formats of the forensic artifacts on the drive image. Linux filesystems are different, file locations are different, and file formats can be different.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>When performing digital forensic examinations on Linux systems, it’s possible to mount suspect filesystems directly on a forensic analysis workstation. However, any symbolic links existing on a suspect system may point to files and directories on the investigator’s own system.</em></p>&#13;
</div>&#13;
<p class="indent">There are also several advantages when examining Linux systems compared to Windows or macOS. Linux distros use fewer proprietary tools and have a tendency to use open file formats and, in many cases, use plaintext files. Additionally, many free and open source tools are available for performing analysis. Many of these tools are included with the operating system and are intended for troubleshooting, debugging, data conversion, or data recovery.</p>&#13;
<p class="indent">I wrote this book with the expectation that many forensic examiners will be using commercial forensic tools under Windows or possibly macOS. Unfortunately, commercial forensic tools are lacking in some areas of Linux analysis. In those cases, using a Linux analysis system is advantageous and recommended.</p>&#13;
<p class="indent">The examples shown in this book use Linux tools, but only to illustrate the forensic artifacts that exist. You can extract or discover these same artifacts with other forensic tools, including commercial tools used by most forensic labs. The use of Linux tools here is not meant to imply that they are better or recommended (although sometimes no equivalent commercial tools exist). They are just different. All forensic examiners or forensic labs have their choice of tools and platforms that work best for them.</p>&#13;
<p class="indent">The forensic processes outlined in the rest of this book are conceptually the same as those on Windows or macOS. The details are different, but explaining those details is the intention of this book.<span epub:type="pagebreak" id="page_30"/></p>&#13;
</div></body></html>