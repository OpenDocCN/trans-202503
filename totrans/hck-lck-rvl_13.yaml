- en: <hgroup>
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <hgroup>
- en: <samp class="SANS_Futura_Std_Bold_Condensed_B_11">9</samp> <samp class="SANS_Dogma_OT_Bold_B_11">BLUELEAKS,
    BLACK LIVES MATTER, AND THE CSV FILE FORMAT</samp>
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_B_11">9</samp> <samp class="SANS_Dogma_OT_Bold_B_11">BLUELEAKS、黑人的命也是命运动与
    CSV 文件格式</samp>
- en: </hgroup>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: </hgroup>
- en: The BlueLeaks dataset is full of an overwhelming number of documents, but it’s
    not immediately obvious where to start or how to make sense of the data they contain.
    Before beginning an investigation, I needed a way to efficiently determine the
    significance of these documents. After manually digging through many files, I
    discovered that the context I needed was in the hundreds of CSV spreadsheets in
    each BlueLeaks folder. In this chapter, you’ll learn how to investigate CSV files
    like these yourself.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: BlueLeaks 数据集充满了大量的文档，但一开始并不容易找到从哪里开始，也不清楚如何理解它们所包含的数据。在开始调查之前，我需要一种方法来高效地确定这些文档的重要性。在手动翻阅了很多文件后，我发现我需要的背景信息其实就在每个
    BlueLeaks 文件夹中的几百个 CSV 表格里。在本章中，你将学习如何自己调查像这样的 CSV 文件。
- en: You’ll view CSVs in both graphical spreadsheet and text editing software, write
    Python code to loop through the rows of a CSV, and save CSVs of your own. You’ll
    then put this knowledge into practice by digging through the CSVs in the BlueLeaks
    dataset, focusing on data from the NCRIC fusion center. This is the data I myself
    have primarily focused on since BlueLeaks was published years ago, but there are
    over a hundred other folders in the dataset full of newsworthy revelations. By
    the end of this chapter, you’ll have the tools to continue investigating these
    folders, as well as similar datasets loaded with CSVs.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用图形化的电子表格软件和文本编辑软件查看 CSV 文件，编写 Python 代码遍历 CSV 的行，并保存你自己的 CSV 文件。然后，你将通过挖掘
    BlueLeaks 数据集中的 CSV 文件，将这些知识付诸实践，重点关注来自 NCRIC 融合中心的数据。这是我自从 BlueLeaks 发布以来，主要关注的数据，但数据集中还有上百个其他文件夹，充满了值得报道的新发现。到本章结束时，你将掌握继续调查这些文件夹以及类似数据集（充满
    CSV 文件）的工具。
- en: <samp class="SANS_Futura_Std_Bold_B_11">Installing Spreadsheet Software</samp>
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_B_11">安装电子表格软件</samp>
- en: The most user-friendly way to view the contents of a CSV file is to open it
    using spreadsheet software such as LibreOffice Calc, Microsoft Excel, Apple Numbers,
    or Google Sheets. Spreadsheet software is a great option to see the data you’re
    dealing with in an organized way, and it can also be a powerful tool to analyze
    CSVs. However, in many cases, depending on the data you’re working with, you’ll
    need to go beyond such software and write custom code to work with CSVs.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 CSV 文件内容的最用户友好方式是使用电子表格软件，如 LibreOffice Calc、Microsoft Excel、Apple Numbers
    或 Google Sheets 打开它。电子表格软件是查看你正在处理的数据的一种很好的方式，而且它也可以是一个强大的工具，用来分析 CSV 文件。然而，在许多情况下，根据你处理的数据，你需要超越这些软件，编写自定义代码来处理
    CSV 文件。
- en: If you already have a favorite spreadsheet program, you can use that for the
    projects in this book. If not, I suggest using LibreOffice Calc since it’s free,
    open source, and available for Windows, macOS, and Linux; it’s also what I’ve
    used for the examples in this chapter. Installing LibreOffice ([*https://<wbr>www<wbr>.libreoffice<wbr>.org*](https://www.libreoffice.org))
    installs a whole suite of office software, including Calc.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经有喜欢的电子表格程序，可以用它来进行本书中的项目。如果没有，我建议使用 LibreOffice Calc，因为它是免费的、开源的，适用于 Windows、macOS
    和 Linux 系统；它也是我在本章示例中使用的工具。安装 LibreOffice（[*https://www.libreoffice.org*](https://www.libreoffice.org)）将安装一整套办公软件，其中包括
    Calc。
- en: Alternatively, Microsoft Excel is a good option, but it costs money and isn’t
    available for Linux. If you have a Mac, you can also use Apple’s free spreadsheet
    software, Numbers. Finally, you can consider using Google Sheets, the spreadsheet
    feature of Google Docs. Google Docs is free and works in Windows, macOS, and Linux,
    since it’s web-based. The problem with Google Sheets and any other cloud-based
    spreadsheet software (like the web-based version of Microsoft Excel) is that you
    have to upload a copy of your CSV file to a third-party service before you can
    view it. For public datasets like BlueLeaks, this is okay. However, it’s better
    to use desktop spreadsheet software when you’re dealing with more sensitive datasets.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，Microsoft Excel 是一个不错的选择，但它需要付费并且在 Linux 上不可用。如果你使用的是 Mac，也可以使用 Apple 的免费电子表格软件
    Numbers。最后，你还可以考虑使用 Google Sheets，Google Docs 的电子表格功能。由于 Google Docs 是基于 Web 的，它在
    Windows、macOS 和 Linux 上都可以使用，而且是免费的。使用 Google Sheets 和任何其他基于云的电子表格软件（比如基于 Web
    的 Microsoft Excel）的问题是，你必须先将 CSV 文件上传到第三方服务才能查看。对于像 BlueLeaks 这样的公开数据集，这没问题。然而，在处理更敏感的数据集时，最好使用桌面电子表格软件。
- en: Spreadsheet software, when used with more complicated spreadsheet formats such
    as Microsoft Excel files (*.xlsx*) or ODF Spreadsheet files (*.ods*), is powerful
    and feature-rich. It can do math, like summing all of the values in a column,
    and visualize data, like creating pie charts or line graphs. None of these features
    are supported in CSV files, though, so I won’t discuss them in this book.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当用于处理更复杂的电子表格格式，如 Microsoft Excel 文件（*.xlsx*）或 ODF 电子表格文件（*.ods*）时，电子表格软件功能强大且功能丰富。它可以进行数学计算，比如求和列中的所有值，还可以可视化数据，比如创建饼图或折线图。然而，CSV
    文件不支持这些功能，因此我在本书中不会讨论这些内容。
- en: Once you have your spreadsheet software installed, you’re ready to learn more
    about the structure of CSV files.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了电子表格软件，你就可以开始了解 CSV 文件的结构了。
- en: <samp class="SANS_Futura_Std_Bold_B_11">Introducing the CSV File Format</samp>
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_B_11">介绍 CSV 文件格式</samp>
- en: You can think of spreadsheets as tables of data. The top row normally has headers
    for each column, and the rest of the rows represent data that matches those headers.
    CSV is the simplest spreadsheet format. You can open CSV files using software
    like Microsoft Excel or LibreOffice Calc, or you can view them in a text editor
    and use CLI tools like <samp class="SANS_TheSansMonoCd_W5Regular_11">grep</samp>
    to search them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以把电子表格看作是数据表格。顶行通常包含每列的标题，其他行代表与这些标题匹配的数据。CSV 是最简单的电子表格格式。你可以使用像 Microsoft
    Excel 或 LibreOffice Calc 这样的软件打开 CSV 文件，或者你可以在文本编辑器中查看它们，并使用 CLI 工具如 <samp class="SANS_TheSansMonoCd_W5Regular_11">grep</samp>
    来搜索它们。
- en: BlueLeaks is full of CSV files, but the original data from the fusion center
    websites wasn’t in that format. The BlueLeaks dataset includes source code for
    those websites, and by reviewing that, I discovered that each site had actually
    stored its data in a Microsoft Access database file. The BlueLeaks hacker exported
    tables from the Access databases and saved that data in CSV format before leaking
    it to DDoSecrets.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: BlueLeaks 充满了 CSV 文件，但来自融合中心网站的原始数据并不是这种格式。BlueLeaks 数据集包含了这些网站的源代码，通过审查这些源代码，我发现每个网站实际上是将数据存储在
    Microsoft Access 数据库文件中。BlueLeaks 黑客从 Access 数据库中导出了表格，并在将数据泄露到 DDoSecrets 之前将其保存为
    CSV 格式。
- en: CSV files are simply text files made up of multiple lines representing rows
    in a table. Each line contains a list of values, usually separated by commas (hence
    the name *comma-separated values*), with each value representing a *cell* in the
    spreadsheet. Sometimes a spreadsheet row is referred to as a *record*, with each
    cell in that row referred to as a *field* in that record. Typically, each row
    contains the same number of cells.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: CSV 文件只是由多行文本组成的文件，每一行代表表格中的一行。每一行包含一组值，这些值通常由逗号分隔（因此得名 *逗号分隔值*），每个值代表电子表格中的一个
    *单元格*。有时，电子表格中的一行称为 *记录*，而该行中的每个单元格称为该记录中的 *字段*。通常，每一行包含相同数量的单元格。
- en: 'Here’s an example CSV file called *city-populations.csv*:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个名为 *city-populations.csv* 的 CSV 文件示例：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You can find a copy of this file in the book’s GitHub repository at [*https://<wbr>github<wbr>.com<wbr>/micahflee<wbr>/hacks<wbr>-leaks<wbr>-and<wbr>-revelations<wbr>/blob<wbr>/main<wbr>/chapter<wbr>-9<wbr>/city<wbr>-populations<wbr>.csv*](https://github.com/micahflee/hacks-leaks-and-revelations/blob/main/chapter-9/city-populations.csv).
    I’ll use this file as an example CSV later in this chapter, so download it now
    (or re-enter it) and save it in a folder for this chapter’s exercises.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这本书的 GitHub 仓库中找到这个文件的副本：[*https://<wbr>github<wbr>.com<wbr>/micahflee<wbr>/hacks<wbr>-leaks<wbr>-and<wbr>-revelations<wbr>/blob<wbr>/main<wbr>/chapter<wbr>-9<wbr>/city<wbr>-populations<wbr>.csv*](https://github.com/micahflee/hacks-leaks-and-revelations/blob/main/chapter-9/city-populations.csv)。我将在本章后面使用这个文件作为
    CSV 示例，所以现在就下载（或重新输入）并将其保存在一个文件夹中以供本章练习使用。
- en: '[Table 9-1](#tab9-1) shows the data from the *city-populations.csv* file organized
    into rows and columns.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[表格 9-1](#tab9-1)展示了 *city-populations.csv* 文件中的数据，按行和列进行组织。'
- en: <samp class="SANS_Futura_Std_Heavy_B_11">Table 9-1:</samp> <samp class="SANS_Futura_Std_Book_11">City
    Populations</samp>
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Heavy_B_11">表格 9-1：</samp> <samp class="SANS_Futura_Std_Book_11">城市人口</samp>
- en: '| <samp class="SANS_Futura_Std_Heavy_B_11">City</samp> | <samp class="SANS_Futura_Std_Heavy_B_11">Country</samp>
    | <samp class="SANS_Futura_Std_Heavy_B_11">Population</samp> |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| <samp class="SANS_Futura_Std_Heavy_B_11">城市</samp> | <samp class="SANS_Futura_Std_Heavy_B_11">国家</samp>
    | <samp class="SANS_Futura_Std_Heavy_B_11">人口</samp> |'
- en: '| --- | --- | --- |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| <samp class="SANS_Futura_Std_Book_11">T</samp><samp class="SANS_FuturaStd_AN-Book_Book_11">ō</samp><samp
    class="SANS_Futura_Std_Book_11">ky</samp><samp class="SANS_FuturaStd_AN-Book_Book_11">ō</samp>
    | <samp class="SANS_Futura_Std_Book_11">Japan</samp> | <samp class="SANS_Futura_Std_Book_11">37,400,000</samp>
    |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| <samp class="SANS_Futura_Std_Book_11">东京</samp> | <samp class="SANS_Futura_Std_Book_11">日本</samp>
    | <samp class="SANS_Futura_Std_Book_11">37,400,000</samp> |'
- en: '| <samp class="SANS_Futura_Std_Book_11">Delhi</samp> | <samp class="SANS_Futura_Std_Book_11">India</samp>
    | <samp class="SANS_Futura_Std_Book_11">28,514,000</samp> |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| <samp class="SANS_Futura_Std_Book_11">德里</samp> | <samp class="SANS_Futura_Std_Book_11">印度</samp>
    | <samp class="SANS_Futura_Std_Book_11">28,514,000</samp> |'
- en: '| <samp class="SANS_Futura_Std_Book_11">Shanghai</samp> | <samp class="SANS_Futura_Std_Book_11">China</samp>
    | <samp class="SANS_Futura_Std_Book_11">25,582,000</samp> |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| <samp class="SANS_Futura_Std_Book_11">上海</samp> | <samp class="SANS_Futura_Std_Book_11">中国</samp>
    | <samp class="SANS_Futura_Std_Book_11">25,582,000</samp> |'
- en: '| <samp class="SANS_Futura_Std_Book_11">S</samp><samp class="SANS_FuturaStd_AN-Book_Book_11">ã</samp><samp
    class="SANS_Futura_Std_Book_11">o Paulo</samp> | <samp class="SANS_Futura_Std_Book_11">Brazil</samp>
    | <samp class="SANS_Futura_Std_Book_11">21,650,000</samp> |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| <samp class="SANS_Futura_Std_Book_11">圣保罗</samp> | <samp class="SANS_Futura_Std_Book_11">巴西</samp>
    | <samp class="SANS_Futura_Std_Book_11">21,650,000</samp> |'
- en: '| <samp class="SANS_Futura_Std_Book_11">Mexico City</samp> | <samp class="SANS_Futura_Std_Book_11">Mexico</samp>
    | <samp class="SANS_Futura_Std_Book_11">21,581,000</samp> |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| <samp class="SANS_Futura_Std_Book_11">墨西哥城</samp> | <samp class="SANS_Futura_Std_Book_11">墨西哥</samp>
    | <samp class="SANS_Futura_Std_Book_11">21,581,000</samp> |'
- en: '| <samp class="SANS_Futura_Std_Book_11">Cairo</samp> | <samp class="SANS_Futura_Std_Book_11">Egypt</samp>
    | <samp class="SANS_Futura_Std_Book_11">20,076,000</samp> |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| <samp class="SANS_Futura_Std_Book_11">开罗</samp> | <samp class="SANS_Futura_Std_Book_11">埃及</samp>
    | <samp class="SANS_Futura_Std_Book_11">20,076,000</samp> |'
- en: 'When a value includes commas, it must be surrounded by quotation marks. For
    example, the values “Hello, World” and “Hola, Mundo” both contain commas. Here’s
    how they look in a CSV file along with fields for their respective languages:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个值包含逗号时，必须将其用引号括起来。例如，“Hello, World”和“Hola, Mundo”这两个值都包含逗号。以下是它们在 CSV 文件中的表现形式，以及它们各自语言的字段：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[Table 9-2](#tab9-2) shows this data organized into rows and columns.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[表格 9-2](#tab9-2)展示了这些数据以行和列的形式组织。'
- en: <samp class="SANS_Futura_Std_Heavy_B_11">Table 9-2:</samp> <samp class="SANS_Futura_Std_Book_11">Translations
    of “Hello, World”</samp>
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Heavy_B_11">表格 9-2：</samp> <samp class="SANS_Futura_Std_Book_11">“Hello,
    World” 的翻译</samp>
- en: '| <samp class="SANS_Futura_Std_Heavy_B_11">Language</samp> | <samp class="SANS_Futura_Std_Heavy_B_11">Greeting</samp>
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| <samp class="SANS_Futura_Std_Heavy_B_11">语言</samp> | <samp class="SANS_Futura_Std_Heavy_B_11">问候语</samp>
    |'
- en: '| --- | --- |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| <samp class="SANS_Futura_Std_Book_11">English</samp> | <samp class="SANS_Futura_Std_Book_11">Hello,
    World</samp> |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| <samp class="SANS_Futura_Std_Book_11">英语</samp> | <samp class="SANS_Futura_Std_Book_11">Hello,
    World</samp> |'
- en: '| <samp class="SANS_Futura_Std_Book_11">Espa</samp><samp class="SANS_FuturaStd_AN-Book_Book_11">ñ</samp><samp
    class="SANS_Futura_Std_Book_11">ol</samp> | <samp class="SANS_Futura_Std_Book_11">Hola,
    Mundo</samp> |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| <samp class="SANS_Futura_Std_Book_11">Espa</samp><samp class="SANS_FuturaStd_AN-Book_Book_11">ñ</samp><samp
    class="SANS_Futura_Std_Book_11">ol</samp> | <samp class="SANS_Futura_Std_Book_11">Hola,
    Mundo</samp> |'
- en: 'It’s common to enclose every value in quotes, regardless of whether it includes
    commas. Here’s another version of the previous spreadsheet, now with every value
    in quotes:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，不论值中是否包含逗号，都将每个值用引号括起来。以下是之前电子表格的另一个版本，现在每个值都用引号括起来：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As with shell scripting and Python programming, you can escape quotes in CSVs
    by using a backslash and double quotes (<samp class="SANS_TheSansMonoCd_W5Regular_11">\"</samp>).
    For example, the value <samp class="SANS_TheSansMonoCd_W5Regular_11">"Not I,"
    said the cow</samp> contains both quotes and commas, so to add it to a CSV file
    you would surround the entire value in quotes and escape the inner quotes, like
    this:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 和shell脚本及Python编程一样，你可以通过使用反斜杠和双引号来转义CSV中的引号（<samp class="SANS_TheSansMonoCd_W5Regular_11">\"</samp>）。例如，值<samp
    class="SANS_TheSansMonoCd_W5Regular_11">"Not I," said the cow</samp>包含了引号和逗号，因此要将其添加到CSV文件中，你需要将整个值用引号括起来，并转义内部的引号，像这样：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Because the CSV file format is so simple, it’s one of the most commonly used
    spreadsheet formats, especially for anyone working with spreadsheets using code.
    Like CSVs, SQL databases also store *tabular data* (data that can be represented
    in a table), so CSVs are a convenient format for exporting tables from them. In
    fact, all of the CSVs in BlueLeaks are exported SQL tables from the databases
    that power law enforcement and fusion center websites. (You’ll learn about SQL
    databases in [Chapter 12](chapter12.xhtml); for now, you’ll work with the exported
    CSVs.)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CSV文件格式非常简单，它是最常用的电子表格格式之一，尤其适用于那些使用代码处理电子表格的人。与CSV类似，SQL数据库也存储*表格数据*（可以在表格中表示的数据），因此CSV是从它们中导出表格的便捷格式。事实上，BlueLeaks中的所有CSV文件都是从为执法和融合中心网站提供支持的数据库中导出的SQL表格。（你将在[第12章](chapter12.xhtml)学习SQL数据库；目前，你将处理导出的CSV文件。）
- en: Now that you understand a bit about the CSV file format, let’s take a look at
    some real CSV data from BlueLeaks.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你对CSV文件格式有了一些了解，让我们来看一下来自BlueLeaks的一些真实CSV数据。
- en: <samp class="SANS_Futura_Std_Bold_B_11">Exploring CSV Files with Spreadsheet
    Software and Text Editors</samp>
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_B_11">使用电子表格软件和文本编辑器探索CSV文件</samp>
- en: In your graphical file browser (such as Explorer in Windows or Finder in macOS),
    browse to the *BlueLeaks-extracted* folder on your USB disk. You’ll start by examining
    the *dediac* subfolder, which contains data from the Delaware Information Analysis
    Center. Scroll through the files in this folder—nearly all of them are CSVs—and
    open *Documents.csv* in your graphical spreadsheet software.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的图形文件浏览器（如Windows中的资源管理器或macOS中的Finder）中，浏览到USB磁盘上的*BlueLeaks-extracted*文件夹。你将首先检查*dediac*子文件夹，其中包含来自特拉华信息分析中心的数据。浏览该文件夹中的文件——几乎所有文件都是CSV——并在你的图形电子表格软件中打开*Documents.csv*。
- en: When you open a file in LibreOffice Calc or other spreadsheet software, you’ll
    likely be presented with a window asking you to confirm the settings for this
    CSV. [Figure 9-1](#fig9-1) shows the window that pops up when I open *Documents.csv*
    in LibreOffice Calc on my Mac.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在LibreOffice Calc或其他电子表格软件中打开文件时，通常会弹出一个窗口，要求你确认该CSV的设置。[图9-1](#fig9-1)展示了在Mac上我打开*Documents.csv*时弹出的窗口。
- en: '![A screenshot of the LibreOffice Calc “Text Import” dialog after opening Documents.csv.
    This dialog allows you to choose the separator character, which in this case is
    a comma.](Images/Figure9-1.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![这是LibreOffice Calc“文本导入”对话框的截图，显示打开Documents.csv后出现的对话框。此对话框允许你选择分隔符字符，在此情况下是逗号。](Images/Figure9-1.png)'
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-1: The LibreOffice
    Calc Text Import settings</samp>'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Book_Oblique_I_11">图9-1：LibreOffice Calc文本导入设置</samp>
- en: The most important setting to select is the correct separator character, which
    is, in this and most cases, a comma (<samp class="SANS_TheSansMonoCd_W5Regular_11">,</samp>).
    Some CSVs separate values with characters other than commas, like semicolons (<samp
    class="SANS_TheSansMonoCd_W5Regular_11">;</samp>) or tabs (<samp class="SANS_TheSansMonoCd_W5Regular_11">\t</samp>),
    though this is rare. In the future if you aren’t sure which character your CSV
    uses, you can open the CSV in a text editor first to check.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的设置是选择正确的分隔符字符，在这个和大多数情况下是逗号（<samp class="SANS_TheSansMonoCd_W5Regular_11">,</samp>）。有些CSV文件用其他字符分隔值，如分号（<samp
    class="SANS_TheSansMonoCd_W5Regular_11">;</samp>）或制表符（<samp class="SANS_TheSansMonoCd_W5Regular_11">\t</samp>），不过这种情况比较少见。如果以后你不确定CSV文件使用哪个字符，你可以先在文本编辑器中打开CSV文件进行检查。
- en: Click **OK** to open the spreadsheet. This one should open quickly, but sometimes
    CSVs are huge—hundreds of mega- or gigabytes—so you may need to wait several seconds,
    or even minutes, for a large CSV to finish loading.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**确定**以打开电子表格。这个应该会很快打开，但有时候CSV文件非常大——有几百兆或几千兆——所以你可能需要等待几秒钟，甚至几分钟，直到大文件的CSV加载完成。
- en: '[Figure 9-2](#fig9-2) shows part of the *Documents.csv* spreadsheet in LibreOffice
    Calc.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9-2](#fig9-2)显示了在LibreOffice Calc中打开的*Documents.csv*电子表格的一部分。'
- en: '![A screenshot of Documents.csv opened in LibreOffice. The column headers include
    DocumentID, DocFilename, and DocTitle. This is a list of documents hosted by the
    fusion center.](Images/Figure9-2.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![在LibreOffice中打开的Documents.csv的截图。列标题包括DocumentID、DocFilename和DocTitle。这是一个由融合中心托管的文档列表。](Images/Figure9-2.png)'
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-2: Viewing</samp>
    <samp class="SANS_Futura_Std_Book_11">Documents.csv</samp> <samp class="SANS_Futura_Std_Book_Oblique_I_11">in
    LibreOffice Calc</samp>'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Book_Oblique_I_11">图9-2：在LibreOffice Calc中查看</samp>
    <samp class="SANS_Futura_Std_Book_11">Documents.csv</samp> <samp class="SANS_Futura_Std_Book_Oblique_I_11">的显示</samp>
- en: This spreadsheet has 23 columns and 6,934 rows (one of which is the header row).
    At the top of the file, the dates in the DateEntered column are from 2011\. You
    can find the most recent data in a spreadsheet by *sorting* it, either in ascending
    (from smaller to bigger) or descending (bigger to smaller) order. I’ll show you
    how to sort this spreadsheet in LibreOffice Calc, but the instructions should
    be similar for other spreadsheet software and apply to any spreadsheet you want
    to sort.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个电子表格有23列和6,934行（其中一行为表头行）。在文件顶部，DateEntered列中的日期是2011年。你可以通过*排序*电子表格来找到最新的数据，排序可以是升序（从小到大）或降序（从大到小）。我将向你展示如何在LibreOffice
    Calc中排序这个电子表格，但其他电子表格软件的操作应该类似，并适用于任何你想排序的电子表格。
- en: First, since you don’t want to sort the header row, click **View**▸**Freeze
    Cells**▸**Freeze First Row**. This should freeze the header row, so now when you
    scroll up and down, the headers will remain at the top of the file.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，由于你不想排序表头行，点击**视图**▸**冻结单元格**▸**冻结首行**。这样可以冻结表头行，现在无论你如何上下滚动，表头都会始终显示在文件顶部。
- en: Next, you need to pick which column you want to sort by. To see the most recent
    documents at the top, sort by DateEntered descending. Before sorting this column,
    you must tell the spreadsheet software that those fields are dates with times
    and specify how they’re formatted (otherwise, the software might assume they’re
    strings and sort them alphabetically). Click column D to select all of the cells
    in that column and then click **Data**▸**Text to Columns**. This pops up a window
    that lets you define what type of data is in each column. At the bottom of the
    window, click the DateEntered column and choose **Date (MDY)** from the Column
    Type drop-down, because the dates in this data are formatted with month, then
    date, then year. Click **OK**.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要选择要排序的列。为了让最新的文档出现在最上面，按DateEntered列进行降序排序。在排序此列之前，你必须告诉电子表格软件这些字段是包含日期和时间的数据，并指定它们的格式（否则，软件可能会认为它们是字符串，并按字母顺序进行排序）。点击D列选择该列的所有单元格，然后点击**数据**▸**文本分列**。这将弹出一个窗口，允许你定义每列的数据类型。在窗口底部，点击DateEntered列，并从列类型下拉菜单中选择**日期（MDY）**，因为这些数据中的日期格式是“月-日-年”。点击**确定**。
- en: Now that the spreadsheet software knows the correct format for the DateEntered
    cells, you can sort it by this column. Click the DateEntered header cell to select
    it (make sure not to select the whole column, just the header cell) and then click
    **Data**▸**Sort Descending**. This should reorder all of the rows so that the
    row with the most recent DateEntered is at the top and the one with oldest is
    at the bottom. In *Documents.csv*, the most recent documents are from June 6,
    2020, during the Black Lives Matter protests. Some of the most recent document
    titles include “Special Bulletin Planned Protests 060620 1800 UPDATE,” “ANTIFA
    Sub Groups and Indicators – LES,” and “ANTIFA - Fighting in the Streets.”
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，电子表格软件已经知道了**DateEntered**单元格的正确格式，你可以根据这一列进行排序。点击**DateEntered**标题单元格进行选择（确保不要选择整个列，只选择标题单元格），然后点击**数据**▸**降序排序**。这应该会重新排列所有行，使得最近的**DateEntered**日期所在的行位于最上面，最旧的行位于最底部。在*Documents.csv*文件中，最近的文件是2020年6月6日的，恰逢黑人的命也是命抗议活动期间。一些最近的文件标题包括“特别公告
    计划抗议 060620 1800 更新”，“ANTIFA子组织及其标志 – LES”，以及“ANTIFA - 街头冲突”。
- en: I often use graphical spreadsheet programs to search CSVs. In LibreOffice, as
    well as in other spreadsheet programs, you can find specific cells using the Find
    feature. Press CTRL-F (or, in macOS, -F), enter your search term, and press ENTER.
    This should search every cell in the spreadsheet for your term. You can use this
    method to find a row containing, for example, a specific ID number or email address.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我经常使用图形化电子表格程序来搜索CSV文件。在LibreOffice以及其他电子表格程序中，你可以使用查找功能定位特定单元格。按CTRL-F（在macOS中为-F），输入你的搜索词并按回车。这将搜索电子表格中的每个单元格。你可以使用这种方法来查找包含特定ID号码或电子邮件地址的行。
- en: When you close the spreadsheet, don’t save your changes. It’s good practice
    to avoid changing original documents in a dataset. If you want to keep a record
    of your changes, save the file as a copy in either the ODF Spreadsheet (*.ods*)
    or Excel (*.xlsx*) format.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭电子表格时，不要保存更改。避免修改数据集中的原始文件是一个好习惯。如果你想保留更改的记录，可以将文件另存为副本，使用ODF电子表格格式（*.ods*）或Excel格式（*.xlsx*）。
- en: 'Now let’s look at the same CSV in a text editor instead of spreadsheet software.
    Here are the first few lines of the *Documents.csv* file, as viewed in a text
    editor like VS Code:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在文本编辑器中查看同一个CSV文件，而不是电子表格软件。以下是*Documents.csv*文件的前几行，在类似VS Code这样的文本编辑器中查看时的样子：
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Because text editors show you only the text when you view a CSV file, without
    lining up the columns like spreadsheet software does, it’s less clear which value
    matches to which header for each row. There’s no simple way to manipulate the
    data, either—you can’t sort it by DateEntered like you can in LibreOffice Calc
    or Microsoft Excel. However, it’s simple to write code that loads the data from
    CSVs into dictionaries, allowing you to manipulate it in any way you choose, as
    you’ll do later in this chapter.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于文本编辑器在查看CSV文件时只显示文本，而不像电子表格软件那样将列对齐，因此更难分辨每一行中哪个值对应哪个标题。数据的操作也不那么简单——你无法像在LibreOffice
    Calc或Microsoft Excel中那样按DateEntered排序。然而，写代码将CSV数据加载到字典中是很简单的，这样你就可以根据需要操作数据，正如你将在本章稍后看到的那样。
- en: Now that you’re familiar with the structure of CSVs, you’re ready to see how
    I began my investigation into the BlueLeaks dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你已经熟悉了CSV文件的结构，现在你准备好查看我如何开始对BlueLeaks数据集进行调查了。
- en: <samp class="SANS_Futura_Std_Bold_B_11">My BlueLeaks Investigation</samp>
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_B_11">我的BlueLeaks调查</samp>
- en: I didn’t even realize that my local police intelligence agency, the Northern
    California Regional Intelligence Center (NCRIC, pronounced “nick-rick”), existed
    until I discovered it in the BlueLeaks dataset in June 2020\. In this section
    I describe how I went about my investigation into BlueLeaks, what I discovered
    in the NCRIC portion of the dataset, and a specific revelation I found in one
    of the NCRIC CSV files.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我甚至没有意识到我的本地警察情报机构——北加州地区情报中心（NCRIC，发音为“尼克-里克”）的存在，直到我在2020年6月在BlueLeaks数据集中发现了它。在这一节中，我将描述我如何展开对BlueLeaks的调查，发现了NCRIC部分的数据集中的哪些内容，以及我在其中一个NCRIC
    CSV文件中发现的一个特定揭示。
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Focusing on a Fusion
    Center</samp>
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">专注于融合中心</samp>
- en: After downloading BlueLeaks, I indexed it in The Intercept’s Intella server
    to make it easier to search. This allowed me and journalists I worked with to
    quickly search it for keywords and find interesting documents. However, I could
    tell that searching for keywords would only get me so far. There was so much data
    that if I only searched terms like *Black Lives Matter*, I was bound to miss a
    lot of it. Moreover, the searches I did make often led me to CSVs, which would
    take more work to untangle.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 下载 BlueLeaks 后，我将其索引到 The Intercept 的 Intella 服务器中，以便更方便地搜索。这使我和我合作的记者们能够快速搜索关键词，找到有趣的文档。然而，我意识到，仅仅搜索关键词只能带我走到一定程度。数据量实在太大了，如果我只搜索像
    *Black Lives Matter* 这样的词汇，我肯定会错过很多重要内容。此外，我所做的搜索往往会把我带到 CSV 文件中，而这些文件需要更多的工作才能解开其中的复杂信息。
- en: BlueLeaks was split into hundreds of folders, each one belonging to a different
    law enforcement organization. Since almost all of these organizations were unfamiliar
    to me, though, I couldn’t tell from the names which folder belonged to which organization.
    I started my own spreadsheet to keep track of this, manually adding rows for each
    folder as I matched organizations and their websites to it. Eventually, I realized
    that I could automate this with a Python script.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: BlueLeaks 被拆分成了数百个文件夹，每个文件夹属于不同的执法组织。然而，由于几乎所有这些组织对我来说都不熟悉，我无法通过名称判断哪个文件夹属于哪个组织。于是，我开始了自己的电子表格，手动为每个文件夹添加行，并将组织及其网站与之对应。最终，我意识到我可以通过
    Python 脚本来自动化这个过程。
- en: I also used shell scripting to figure out which folders had the most data, because
    I guessed they were the largest or most active fusion centers. I quickly discovered
    that the *ncric* folder, one of the largest in the dataset, held documents for
    NCRIC, so that’s where I decided to focus my digging.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我还使用了 shell 脚本来找出哪些文件夹包含最多的数据，因为我猜测它们可能是最大的或最活跃的融合中心。我很快发现，*ncric* 文件夹是数据集中最大的文件夹之一，包含了关于
    NCRIC 的文件，因此我决定集中精力进行深入挖掘。
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Introducing NCRIC</samp>
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">介绍 NCRIC</samp>
- en: NCRIC, based in San Francisco, shares information between federal agencies,
    local police departments across Northern California, and private industry partners,
    including tech companies. As I discovered by combing through the CSVs in this
    dataset, it also provides services to local cops, like monitoring social media
    or helping break into locked smartphones, and it hosts events and classes for
    law enforcement officers.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: NCRIC，总部位于旧金山，在联邦机构、北加州各地的地方警察部门以及包括科技公司在内的私人行业合作伙伴之间共享信息。通过对数据集中的 CSV 文件的深入分析，我还发现它为地方警察提供服务，比如监控社交媒体或协助破解锁定的智能手机，并为执法人员举办活动和课程。
- en: Using a custom tool I developed called BlueLeaks Explorer, which I’ll discuss
    in detail in [Chapter 10](chapter10.xhtml), I examined everything I could find
    in the *ncric* folder dated within the 13 days between George Floyd’s murder and
    when NCRIC was hacked. I discovered that twice a day, NCRIC emailed over 14,000
    cops an updated list of Black Lives Matter protests. Local police and other partners
    could also log in to NCRIC’s website and submit suspicious activity reports (SARs)
    to distribute to the fusion center’s partners. Local police also requested NCRIC’s
    help with monitoring the social media accounts of protest organizers and, in two
    instances, with identifying threats against white female teenagers who were facing
    harassment after making racist statements and using anti-Black slurs.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我开发的一个名为 BlueLeaks Explorer 的自定义工具，我将在[第 10 章](chapter10.xhtml)中详细讨论它，我检查了我在
    *ncric* 文件夹中能找到的所有内容，这些内容的日期是在乔治·弗洛伊德遇害与 NCRIC 被黑客攻击之间的13天内。我发现，每天两次，NCRIC 会向超过
    14,000 名警察发送更新的“黑人的命也是命”抗议活动清单。地方警察和其他合作伙伴也可以登录 NCRIC 的网站，提交可疑活动报告（SAR），并分发给融合中心的合作伙伴。地方警察还请求
    NCRIC 协助监控抗议组织者的社交媒体账户，在两个案例中，NCRIC 帮助识别威胁白人女性青少年的行为，这些青少年因发表种族主义言论和使用反黑人侮辱语而遭遇骚扰。
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Investigating a SAR</samp>
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">调查 SAR</samp>
- en: By investigating a row from a CSV file, I found a PDF of a scanned letter that
    turned out to be newsworthy. The letter, written by an unhinged San Francisco–area
    lawyer to a local district attorney’s office, called a polite student from Oregon
    an “antifa terrorist.” In this section, I describe how I found this revelation
    in BlueLeaks, what it contains, and how the BlueLeaks CSVs reference other documents
    in the dataset.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调查一个CSV文件中的一行，我发现了一份扫描的信件PDF，内容值得关注。这封信由一名精神失常的旧金山地区律师写给当地的地区检察院，称一位来自俄勒冈州的学生为“反法西斯恐怖分子”。在这一部分，我将描述如何在BlueLeaks中发现这一发现，信件的内容是什么，以及BlueLeaks的CSV如何引用数据集中的其他文档。
- en: 'When I grepped the CSV files in the *ncric* folder for the word *antifa*, I
    found that there were only a handful of references in the files *EmailBuilder
    .csv*, *Requests.csv*, *SARs.csv*, and *Survey.csv*. In particular, this row in
    *SARs.csv* stood out because it referenced a student protester, allegedly a member
    of an antifa group, and mentioned “Radicalization/Extremism”:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在*ncric*文件夹中的CSV文件中使用grep查找*antifa*时，我发现文件*EmailBuilder.csv*、*Requests.csv*、*SARs.csv*和*Survey.csv*中只有少数几个引用。特别是在*SARs.csv*文件中的这一行很突出，因为它提到了一个学生抗议者，据称是反法西斯组织的成员，并且提到“激进化/极端主义”：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Looking into the *SARs.csv* file, I found that it lists one month of SARs submitted
    to NCRIC. The earliest report was May 6, 2020, and the latest was June 6, 2020,
    so my guess is that NCRIC retains SARs only for a month.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看*SARs.csv*文件时，我发现该文件列出了提交给NCRIC的一个月内的SAR报告。最早的报告日期是2020年5月6日，最新的是2020年6月6日，所以我猜NCRIC仅保留一个月的SAR记录。
- en: 'Try opening this file, *ncric/SARs.csv*, in your spreadsheet software, and
    you’ll see that it’s difficult to parse. There are 91 different columns, and some
    of the cells are filled with so much text that even with a large monitor, you
    can see only part of a row at a time. To make it easier to read, I copied the
    content of the BriefSummary cell from the spreadsheet and pasted it into my text
    editor, something that I frequently needed to do with the CSVs in this dataset
    before I developed BlueLeaks Explorer. Here are the relevant fields from the row
    that caught my eye:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试在你的电子表格软件中打开这个文件*ncric/SARs.csv*，你会发现它很难解析。该文件有91列，有些单元格填充了大量文本，即使使用大屏幕，你也只能看到一行的一部分。为了更容易阅读，我将电子表格中BriefSummary单元格的内容复制并粘贴到我的文本编辑器中，这是我在开发BlueLeaks
    Explorer之前，处理此数据集中的CSV文件时经常需要做的事。以下是我注意到的那一行中的相关字段：
- en: '**SARSid** 14277'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**SARSid** 14277'
- en: '**FormTimeStamp** 06/05/20 14:20:09'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**FormTimeStamp** 06/05/20 14:20:09'
- en: '**IncidentDate** 6/5/2020'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**IncidentDate** 6/5/2020'
- en: '**ThreatActivity** Radicalization/Extremism,Suspicious Incident'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**ThreatActivity** 激进化/极端主义, 可疑事件'
- en: '**BriefSummary** The attached letter was received via US Postal Service this
    morning. The letter was passed on from an anonymous party claiming to be a lawyer
    who was contacted by *[redacted name]* who is a University of Oregon student.
    *[Redacted name]* appears to be a member of the Antifa group and is assisting
    in planning protesting efforts in the Bay Area despite living in Oregon.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**BriefSummary** 附件信件今天早上通过美国邮政服务收到。该信件来自一名自称为律师的匿名人士，表示他是由*[已编辑姓名]*联系的，这位学生来自俄勒冈大学。*[已编辑姓名]*似乎是反法西斯组织的成员，并且虽然居住在俄勒冈州，却协助筹划在湾区的抗议活动。'
- en: '**Subjects** *[redacted name]*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**Subjects** *[已编辑姓名]*'
- en: '**AgencyOrganizationNameOther** Marin County District Attorney’s Office'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**AgencyOrganizationNameOther** 马林县地区检察院'
- en: '**File1** SARF100014\277.pdf'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**File1** SARF100014\277.pdf'
- en: '**File1Name** Letter.pdf'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**File1Name** Letter.pdf'
- en: '**EmailAddress** *[redacted]*@marincounty.org'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**EmailAddress** *[已编辑]*@marincounty.org'
- en: '**PhoneNumber** *[redacted phone number]*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**PhoneNumber** *[已编辑电话号码]*'
- en: The SAR listed the full name, email address, and phone number of the person
    who had submitted it. I looked them up online and discovered that they worked
    as an investigator for the district attorney’s office in Marin County (just north
    of San Francisco). On June 5 at 2:20 PM (per the FormTimestamp field), the day
    before NCRIC was hacked, they logged in to the NCRIC website and submitted the
    SAR form. They included a PDF called *Letter.pdf* (per the File1Name field), though
    the website saved it in the *SARF100014* folder as *277.pdf* (per the File1 field).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: SAR中列出了提交者的全名、电子邮件地址和电话号码。我在网上查找了这些信息，发现提交者是马林县（位于旧金山北部）地区检察院的一名调查员。根据表单中的时间戳字段，6月5日下午2:20（NCRIC被黑客攻击的前一天），他们登录了NCRIC网站并提交了SAR表单。他们附加了一个名为*Letter.pdf*的PDF文件（根据File1Name字段），尽管网站将其保存在*SARF100014*文件夹中，文件名为*277.pdf*（根据File1字段）。
- en: <samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp>
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <samp class="SANS_Dogma_OT_Bold_B_21">注意</samp>
- en: '*The server that hosted NCRIC’s website and all of the other BlueLeaks sites
    was running Windows, which is why folders in paths are separated by backslashes
    (\), like* SARF100014\277.pdf*, instead of forward slashes (/).*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*托管NCRIC网站及所有其他BlueLeaks网站的服务器运行的是Windows操作系统，这也是为什么路径中的文件夹使用反斜杠（\）分隔，例如* SARF100014\277.pdf*，而不是使用正斜杠（/）。*'
- en: Each BlueLeaks folder has a subfolder called *files*, where you can find the
    files referenced in the CSV. See if you can find the PDF referenced in the File1
    field in the *ncric* folder. It should be at the path *ncric/files/SARF100014/277.pdf*
    (see [Figure 9-3](#fig9-3)).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 每个BlueLeaks文件夹中都有一个名为*files*的子文件夹，里面存放着CSV中提到的文件。看看你能否找到在*ncric*文件夹中提到的PDF文件，路径应为*ncric/files/SARF100014/277.pdf*（见[图9-3](#fig9-3)）。
- en: '![A screenshot of the letter in 277.pdf, which was written and sent to the
    Marin County DA office by a Bay Area attorney.](Images/Figure9-3.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![277.pdf中的信件截图，这封信由一位湾区律师写并寄送给Marin County DA办公室。](Images/Figure9-3.png)'
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-3: A PDF attachment
    in the SAR submitted by an investigator from the Marin County DA’s office</samp>'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Book_Oblique_I_11">图9-3：Marin县DA办公室调查员提交的SAR中的PDF附件</samp>
- en: 'The PDF shows a letter in all caps mailed to the Marin County DA’s office by
    a Bay Area attorney: “PLEASE SEE THE ATTACHED SOLICITATION I RECEIVED FROM AN
    ANTIFA TERRORIST WANTING MY HELP TO BAIL HER AND HER FRIENDS OUT OF JAIL, IF ARRESTED
    FOR RIOTING.” He explained that he was remaining anonymous because he “CANNOT
    RISK THIS PIECE OF SHIT ANTIFA […] FILING A BAR COMPLAINT AGAINST ME,” and warned
    that “THE SAN FRANCISCO PUBLIC DEFENDERS WILL VIGOROUSLY DEFEND THESE TERRORISTS.”
    He ended his letter, “HAPPY HUNTING.”'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 该PDF显示了一封全大写的信件，寄给Marin县DA办公室的湾区律师：“请查看我收到的一封来自一位ANTIFA恐怖分子的请求，内容是想要我帮忙为她和她的朋友保释，如果他们因暴乱被逮捕。”他解释说，他保持匿名是因为“不能冒险让这个ANTIFA的混蛋[…]对我提出律师投诉”，并警告说，“旧金山公共辩护律师将会积极为这些恐怖分子辩护。”他在信的结尾写道，“祝你好运。”
- en: Further down in the PDF, the attorney included the solicitation from the “antifa
    terrorist,” shown in [Figure 9-4](#fig9-4).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在PDF的后面，律师附上了来自“antifa恐怖分子”的请求，见[图9-4](#fig9-4)。
- en: '![The email written by the Oregon student and sent to the Bay Area attorney.](Images/Figure9-4.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![俄勒冈州学生写给湾区律师的电子邮件。](Images/Figure9-4.png)'
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-4: The letter that
    the Oregon student sent to the California lawyer</samp>'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Book_Oblique_I_11">图9-4：俄勒冈州学生发送给加利福尼亚州律师的信件</samp>
- en: “I am a long time activist and ally of the Black Lives Matter movement,” the
    Oregon student wrote. “… Is there anyway [*sic*] that I could add your firm, or
    consenting lawyers under your firm, to a list of resources who will represent
    protesters pro bono if they were/are to be arrested? Thank you very much for your
    time.” The Marin County DA investigator apparently believed that this was useful
    enough intelligence that they logged in to their account on NCRIC’s website and
    submitted it as “suspicious activity” for other law enforcement officers around
    Northern California to access. Under threat activity, they chose Radicalization/Extremism.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: “我是长期支持并为‘黑人的命也是命’运动提供帮助的活动家和盟友，”这位俄勒冈州学生写道。 “… 有没有可能让我把你们的律所，或者你们律所下愿意为抗议者提供免费辩护的律师，加入一份资源清单？如果抗议者因示威被逮捕，你们是否愿意提供帮助？非常感谢你们的时间。”Marin县的检察官显然认为这条信息足够重要，因此他们登录了NCRIC网站，并将其提交为“可疑活动”，供北加州的其他执法人员查看。在活动类别下，他们选择了激进化/极端主义。
- en: <samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp>
  id: totrans-99
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <samp class="SANS_Dogma_OT_Bold_B_21">注释</samp>
- en: '*You can read more about my findings from this SAR in the first article I wrote
    about BlueLeaks, at* [https://theintercept.com/2020/07/15/blueleaks-anonymous-ddos-law-enforcement-hack/](https://theintercept.com/2020/07/15/blueleaks-anonymous-ddos-law-enforcement-hack/)*.*
    *To learn more about what I discovered while researching NCRIC in general, check
    out my in-depth article at* [https://theintercept.com/2020/08/17/blueleaks-california-ncric-black-lives-matter-protesters/](https://theintercept.com/2020/08/17/blueleaks-california-ncric-black-lives-matter-protesters/)*.*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*你可以从我写的关于BlueLeaks的第一篇文章中了解更多我的发现，文章链接是* [https://theintercept.com/2020/07/15/blueleaks-anonymous-ddos-law-enforcement-hack/](https://theintercept.com/2020/07/15/blueleaks-anonymous-ddos-law-enforcement-hack/)*。*
    *要了解我在研究NCRIC时发现的更多内容，可以查看我的深入文章，链接是* [https://theintercept.com/2020/08/17/blueleaks-california-ncric-black-lives-matter-protesters/](https://theintercept.com/2020/08/17/blueleaks-california-ncric-black-lives-matter-protesters/)*。*'
- en: In theory, I could have stumbled upon the PDF in [Figure 9-3](#fig9-3) on its
    own; I might have just randomly clicked through documents and happened to open
    *ncric/files/SARF100014/277.pdf*, the path to the PDF in question. I could also
    have indexed the *ncric* folder in Aleph, OCRing all of the documents, and searched
    for *antifa*. However, the PDF alone doesn’t explain who uploaded it to the NCRIC
    website, when and why they uploaded it, and how they described the document. Moreover,
    if you’re interested in focusing on activity in the fusion center from a specific
    time period, it’s easier to find which documents are relevant by their timestamps
    in the CSV files. If you’re researching BlueLeaks yourself, you can quickly find
    all of the documents associated with a time period by sorting the spreadsheets
    by date, reading all the rows in the CSVs for that time period, and looking at
    the documents that those rows reference.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，我本可以在 [图 9-3](#fig9-3) 中单独发现这份 PDF；我可能只是随机点击文档，恰巧打开了 *ncric/files/SARF100014/277.pdf*，即问题中的
    PDF 路径。我也可以在 Aleph 中对 *ncric* 文件夹进行索引，给所有文档进行 OCR，并搜索 *antifa*。然而，单凭这份 PDF 并不能解释是谁将其上传到
    NCRIC 网站、何时上传、为何上传以及他们如何描述该文档。此外，如果你对特定时间段内的融合中心活动感兴趣，通过 CSV 文件中的时间戳更容易找到相关的文档。如果你自己在研究
    BlueLeaks，可以通过按日期排序电子表格，读取该时间段内 CSV 中的所有行，并查看那些行引用的文档，快速找到所有与某个时间段相关的文档。
- en: Whenever you find an interesting document in BlueLeaks, search the CSVs for
    its filename to figure out why that document is there to begin with. It could
    be an attachment in a SAR, part of a bulk-email message the fusion center sent
    to thousands of local police, or included for other reasons. In the case of *277.pdf*,
    now you know this document was uploaded as an attachment to a SAR by an investigator
    in a DA’s office. The CSV provides the investigator’s summary of the document’s
    contents, along with their contact information, which you can use to reach out
    to them for comment before publishing your findings.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 每当你在 BlueLeaks 中找到有趣的文档时，搜索 CSV 文件中该文档的文件名，以弄清楚这个文档为何会出现在那儿。它可能是某个 SAR 的附件，或者是融合中心发送给数千名地方警察的批量电子邮件的一部分，或者由于其他原因包含在内。以
    *277.pdf* 为例，现在你知道这份文档是由 DA 办公室的调查员作为 SAR 的附件上传的。CSV 文件提供了调查员对文档内容的总结，以及他们的联系方式，你可以在发布调查结果之前联系他们获取评论。
- en: Now that you’ve seen the type of data *SARs.csv* contains, you need a way to
    easily read the long blocks of text in those CSV cells without having to copy
    and paste them into a text editor. We’ll cover that in Exercise 9-1, but first,
    let’s have a quick tutorial on how to write code that works with CSV files.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看过了 *SARs.csv* 中包含的数据类型，你需要一种方法来轻松阅读 CSV 单元格中那些长文本，而不必将它们复制并粘贴到文本编辑器中。我们将在练习
    9-1 中讨论这个问题，但首先，让我们快速学习如何编写与 CSV 文件配合使用的代码。
- en: <samp class="SANS_Futura_Std_Bold_B_11">Reading and Writing CSV Files in Python</samp>
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_B_11">在 Python 中读取和写入 CSV 文件</samp>
- en: 'As you learned in [Chapter 8](chapter8.xhtml), Python modules bring extra functionality
    into the script that you’re writing. It’s easy to load CSVs and turn each row
    into a Python dictionary using Python’s built-in <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp>
    module. You’ll need <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp> for
    this chapter’s exercises, so import it using the following command:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在 [第 8 章](chapter8.xhtml) 中学到的，Python 模块为你编写的脚本带来了额外的功能。使用 Python 内置的 <samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv</samp> 模块，可以轻松加载 CSV 文件并将每一行转换为 Python
    字典。你将在本章的练习中用到 <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp>，因此请使用以下命令导入它：
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: After importing it, you can take advantage of its functionality. The <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp>
    features I use the most are <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp>,
    which lets you parse rows of a CSV as dictionaries, and <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictWriter()</samp>,
    which lets you save your own CSVs from data stored in dictionaries.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 导入后，你可以利用它的功能。我最常用的 <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp>
    功能是 <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp>，它可以让你将
    CSV 的每一行解析为字典，以及 <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictWriter()</samp>，它允许你将存储在字典中的数据保存为
    CSV 文件。
- en: 'The following code loads a CSV file and loops through its rows by using <samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp>:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码加载一个 CSV 文件，并通过使用 <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp>
    来循环读取其行：
- en: '[PRE7]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This code assumes the path to the CSV filename is in the <samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>
    variable, which could be a string that you hardcoded or a CLI argument you passed
    into your program. After opening the CSV file with <samp class="SANS_TheSansMonoCd_W5Regular_11">open(csv
    _path)</samp> and storing the file objects as <samp class="SANS_TheSansMonoCd_W5Regular_11">f</samp>,
    the code defines a new variable called <samp class="SANS_TheSansMonoCd_W5Regular_11">reader</samp>
    and sets its value to <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader(f)</samp>,
    which prepares you to read rows from this CSV. The <samp class="SANS_TheSansMonoCd_W5Regular_11">reader</samp>
    object acts a little like a list of dictionaries, where each dictionary represents
    a row. Although it’s not actually a list, you can use a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp>
    loop to loop through it as if it were. Inside the <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp>
    loop, <samp class="SANS_TheSansMonoCd_W5Regular_11">row</samp> is a dictionary
    that represents the data in a row from the spreadsheet.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码假设CSV文件名的路径存储在<samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>变量中，这个路径可以是你硬编码的字符串，也可以是你传入程序的CLI参数。打开CSV文件后，使用<samp
    class="SANS_TheSansMonoCd_W5Regular_11">open(csv_path)</samp>并将文件对象存储为<samp class="SANS_TheSansMonoCd_W5Regular_11">f</samp>，代码定义了一个新变量<samp
    class="SANS_TheSansMonoCd_W5Regular_11">reader</samp>并将其值设置为<samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader(f)</samp>，这使得你可以开始读取CSV的每一行。<samp
    class="SANS_TheSansMonoCd_W5Regular_11">reader</samp>对象有点像一个字典列表，每个字典表示一行数据。虽然它实际上不是一个列表，但你可以像遍历列表一样使用<samp
    class="SANS_TheSansMonoCd_W5Regular_11">for</samp>循环遍历它。在<samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp>循环中，<samp
    class="SANS_TheSansMonoCd_W5Regular_11">row</samp>是一个字典，表示工作表中一行数据。
- en: 'The process of saving new CSVs is similar to loading them, except you use <samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv.DictWriter()</samp>. For example,
    the following code uses Python to save the *city-populations.csv* file discussed
    in the “Introducing the CSV File Format” section earlier in this chapter:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 保存新的CSV文件的过程与加载它们类似，只不过这次你使用的是<samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictWriter()</samp>。例如，下面的代码使用Python保存本章前面“介绍CSV文件格式”部分讨论的*city-populations.csv*文件：
- en: '[PRE8]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This code first defines the headers of the spreadsheet in the list <samp class="SANS_TheSansMonoCd_W5Regular_11">headers</samp>,
    then opens the output file (<samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>)
    for writing. Creating a <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictWriter()</samp>
    object allows you to save data into the CSV. You must pass the headers in as a
    keyword argument called <samp class="SANS_TheSansMonoCd_W5Regular_11">fieldnames</samp>.
    You must also run <samp class="SANS_TheSansMonoCd_W5Regular_11">writer .writeheader()</samp>,
    which saves the header row to the CSV file, before writing any of the data rows.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码首先在列表<samp class="SANS_TheSansMonoCd_W5Regular_11">headers</samp>中定义了工作表的表头，然后打开输出文件（<samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>）进行写入。创建<samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictWriter()</samp>对象可以让你将数据保存到CSV文件中。你必须将表头作为名为<samp
    class="SANS_TheSansMonoCd_W5Regular_11">fieldnames</samp>的关键字参数传入。你还必须运行<samp
    class="SANS_TheSansMonoCd_W5Regular_11">writer.writeheader()</samp>，它会将表头行保存到CSV文件中，然后才能写入数据行。
- en: 'You can then add rows to the spreadsheet by running <samp class="SANS_TheSansMonoCd_W5Regular_11">writer.writerow()</samp>,
    passing in a dictionary whose keys match your headers. For example, the first
    call of <samp class="SANS_TheSansMonoCd_W5Regular_11">writer.writerow()</samp>
    passes in the dictionary <samp class="SANS_TheSansMonoCd_W5Regular_11">{"City":
    "Tōkyō", "Country": "Japan", "Population": 37400000}</samp>. The keys for this
    dictionary are the same as the headers for the CSV: <samp class="SANS_TheSansMonoCd_W5Regular_11">City</samp>,
    <samp class="SANS_TheSansMonoCd_W5Regular_11">Country</samp>, and <samp class="SANS_TheSansMonoCd_W5Regular_11">Population</samp>.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '然后，你可以通过运行<samp class="SANS_TheSansMonoCd_W5Regular_11">writer.writerow()</samp>来向工作表添加新行，传入一个字典，其键与表头匹配。例如，第一次调用<samp
    class="SANS_TheSansMonoCd_W5Regular_11">writer.writerow()</samp>时，传入字典<samp class="SANS_TheSansMonoCd_W5Regular_11">{"City":
    "Tōkyō", "Country": "Japan", "Population": 37400000}</samp>。这个字典的键与CSV的表头相同：<samp
    class="SANS_TheSansMonoCd_W5Regular_11">City</samp>、<samp class="SANS_TheSansMonoCd_W5Regular_11">Country</samp>和<samp
    class="SANS_TheSansMonoCd_W5Regular_11">Population</samp>。'
- en: In the following exercises, you’ll use your new CSV programming skills to write
    scripts that make the data hidden in BlueLeaks CSVs easier to read and understand.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的练习中，你将使用新的CSV编程技能编写脚本，使得隐藏在BlueLeaks CSV文件中的数据更容易读取和理解。
- en: <samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp>
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <samp class="SANS_Dogma_OT_Bold_B_21">注意</samp>
- en: '*To learn more about the* <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">csv</samp>
    *module, you can find the full documentation, including plenty of example code,
    at* [https://docs.python.org/3/library/csv.html](https://docs.python.org/3/library/csv.html)*.*'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*要了解更多关于* <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">csv</samp>
    *模块的信息，你可以查看完整的文档，包括大量示例代码，网址是* [https://docs.python.org/3/library/csv.html](https://docs.python.org/3/library/csv.html)*。*'
- en: '<samp class="SANS_Futura_Std_Heavy_B_21">Exercise 9-1: Make BlueLeaks CSVs
    More Readable</samp>'
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Heavy_B_21">练习 9-1：使 BlueLeaks CSV 更易读</samp>
- en: While it’s easier to read *SARs.csv* in a spreadsheet program than in a text
    editor, it’s still quite difficult. As mentioned earlier, there are 91 columns
    (though most of their values are blank), and some of the text fields, like BriefSummary,
    contain way too much text to see at one time in a spreadsheet cell. In this exercise,
    you’ll write a script that makes *SARs.csv* (or any CSV with similar content)
    easier to read by showing you the data a single row at a time.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在电子表格程序中读取 *SARs.csv* 比在文本编辑器中更容易，但仍然相当困难。如前所述，该文件有91列（尽管大多数列的值是空的），并且一些文本字段，如
    BriefSummary，包含的文本太多，一次在电子表格单元格中无法显示完整。在本练习中，你将编写一个脚本，使 *SARs.csv*（或任何类似内容的CSV文件）通过一次显示一行数据变得更容易阅读。
- en: This exercise is designed not just to show you how to work with the *SARs.csv*
    file, but to give you practice looping through the rows and fields in a CSV. These
    skills will come in handy whenever you write code that reads data from CSVs.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习不仅旨在向你展示如何处理 *SARs.csv* 文件，还让你练习遍历 CSV 文件中的行和字段。这些技能将非常有用，每当你编写读取 CSV 数据的代码时。
- en: 'For a challenge, you could try programming your own script to meet the following
    requirements:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想挑战自己，可以尝试编写一个脚本，满足以下要求：
- en: Make this script accept an argument called <samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>
    using Click, which you first learned to use in Exercise 8-3.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使这个脚本接受一个名为 <samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp> 的参数，使用
    Click 库，这个你在练习 8-3 中已经学过。
- en: Import the <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp> module and
    loop through all of the rows in the CSV located at <samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>,
    loading each row as a dictionary, as discussed in the previous section.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入 <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp> 模块，并循环遍历位于 <samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp> 的 CSV 文件中的所有行，按照前一部分的内容将每行加载为字典。
- en: For each row, display all of the *non-empty* values for its columns. If a value
    is empty, meaning it’s an empty string (<samp class="SANS_TheSansMonoCd_W5Regular_11">""</samp>),
    skip it. There’s no reason to display all of the columns when so many of them
    have blank values.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每一行，显示其列中所有的 *非空* 值。如果某个值为空，意味着它是一个空字符串 (<samp class="SANS_TheSansMonoCd_W5Regular_11">""</samp>)，则跳过它。当许多列的值为空时，没有必要显示所有列。
- en: 'Display each field on its own line. For example, one line could show <samp
    class="SANS_TheSansMonoCd_W5Regular_11">SARSid: 14277</samp> and the next line
    could show <samp class="SANS_TheSansMonoCd_W5Regular_11">FormTimeStamp: 06/05/20
    14:20:09</samp>.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '将每个字段显示在单独的一行上。例如，一行可以显示 <samp class="SANS_TheSansMonoCd_W5Regular_11">SARSid:
    14277</samp>，下一行可以显示 <samp class="SANS_TheSansMonoCd_W5Regular_11">FormTimeStamp:
    06/05/20 14:20:09</samp>。'
- en: Output a separator line like <samp class="SANS_TheSansMonoCd_W5Regular_11">===</samp>
    between each row so that you can tell rows apart.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每一行之间输出一条分隔线，比如 <samp class="SANS_TheSansMonoCd_W5Regular_11">===</samp>，这样你就能区分不同的行。
- en: 'Alternatively, follow along with the rest of this exercise and I’ll walk you
    through the programming process. Start with the usual Python script template in
    a file called *exercise-9-1.py*:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，跟随本练习的其余部分，我将引导你完成编程过程。首先从一个通常的 Python 脚本模板开始，保存为 *exercise-9-1.py* 文件：
- en: '[PRE9]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Next, you’ll modify your script to accept the <samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>
    argument.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将修改脚本，使其接受 <samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>
    参数。
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Accept the CSV Path
    as an Argument</samp>
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">接受 CSV 路径作为参数</samp>
- en: 'Instead of hardcoding the path to a specific CSV, let’s use Click to accept
    the path as an argument. Here’s the code that does that (with modifications shown
    in bold):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 不再硬编码到特定的 CSV 文件路径，而是使用 Click 接受路径作为参数。下面是实现这一点的代码（修改部分以粗体显示）：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Just like in Exercise 8-4, this code imports the <samp class="SANS_TheSansMonoCd_W5Regular_11">click</samp>
    module, adds Click decorators before the <samp class="SANS_TheSansMonoCd_W5Regular_11">main()</samp>
    function to turn it into a command that accepts the <samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>
    argument, and adds a docstring. For now, it also displays the value of <samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>
    so you can test if the program works. Run the code to test it as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在练习8-4中一样，这段代码导入了<samp class="SANS_TheSansMonoCd_W5Regular_11">click</samp>模块，在<samp
    class="SANS_TheSansMonoCd_W5Regular_11">main()</samp>函数前添加了Click装饰器，使其成为一个接受<samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>参数的命令，并添加了文档字符串。目前，它还显示了<samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>的值，以便你测试程序是否工作。按如下方式运行代码进行测试：
- en: '[PRE11]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The script just displays the CSV path that was passed in. So far, so good.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本只显示了传入的CSV路径。到目前为止，一切顺利。
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Loop Through the
    CSV Rows</samp>
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">遍历CSV行</samp>
- en: 'Next, you’ll modify the code to open the CSV in <samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>,
    and, using the <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp> module,
    create a <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp>
    object to loop through the rows of that CSV:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将修改代码以打开位于<samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>的CSV文件，并使用<samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv</samp>模块，创建一个<samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp>对象来遍历该CSV的每一行：
- en: '[PRE12]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This code now imports the <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp>
    module at the top. When the <samp class="SANS_TheSansMonoCd_W5Regular_11">main()</samp>
    function runs, the code opens the file at <samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>
    for reading, creating a file object variable called <samp class="SANS_TheSansMonoCd_W5Regular_11">f</samp>.
    As noted in “Reading and Writing CSV Files in Python,” you can use <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp>
    to loop through a CSV file, getting access to each row as a dictionary. The code
    does this next, creating a variable called <samp class="SANS_TheSansMonoCd_W5Regular_11">reader</samp>
    and setting it equal to <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader(f)</samp>.
    Using <samp class="SANS_TheSansMonoCd_W5Regular_11">reader</samp>, the code then
    loops through each row and displays the dictionary containing its data.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码现在在顶部导入了<samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp>模块。当<samp
    class="SANS_TheSansMonoCd_W5Regular_11">main()</samp>函数运行时，代码会打开位于<samp class="SANS_TheSansMonoCd_W5Regular_11">csv_path</samp>的文件进行读取，并创建一个文件对象变量<samp
    class="SANS_TheSansMonoCd_W5Regular_11">f</samp>。正如《Python中的CSV文件读写》中所提到的，你可以使用<samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp>来遍历CSV文件，以字典形式访问每一行。接下来，代码创建了一个名为<samp
    class="SANS_TheSansMonoCd_W5Regular_11">reader</samp>的变量，并将其设置为<samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader(f)</samp>。通过使用<samp
    class="SANS_TheSansMonoCd_W5Regular_11">reader</samp>，代码随后遍历每一行并显示包含其数据的字典。
- en: 'Test the code again, this time passing in the path to *SARs.csv* as the CLI
    argument. Make sure you use the correct path for your copy of the BlueLeaks dataset:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 再次测试代码，这次将*SARs.csv*的路径作为CLI参数传入。确保你使用的是正确的BlueLeaks数据集路径：
- en: '[PRE13]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The output shows that during each loop, the <samp class="SANS_TheSansMonoCd_W5Regular_11">row</samp>
    variable is a dictionary containing the values for that row. So far, the code
    is simply displaying this whole dictionary. This is a good start, but it still
    doesn’t make the text much easier to read. To do that, you’ll display each field
    on its own row.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，在每次循环中，<samp class="SANS_TheSansMonoCd_W5Regular_11">row</samp>变量是一个包含该行数据的字典。到目前为止，代码只是简单地显示了整个字典。这是一个好的开始，但它仍然没有让文本更容易阅读。为了做到这一点，你将把每个字段单独显示在每一行上。
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Display CSV Fields
    on Separate Lines</samp>
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">将CSV字段显示在单独的行上</samp>
- en: 'The following modified code displays each row separately:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 以下修改后的代码将每一行单独显示：
- en: '[PRE14]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Rather than just displaying the <samp class="SANS_TheSansMonoCd_W5Regular_11">row</samp>
    dictionary, this code loops through all of its keys, storing each in the variable
    <samp class="SANS_TheSansMonoCd_W5Regular_11">key</samp>. Since <samp class="SANS_TheSansMonoCd_W5Regular_11">key</samp>
    is the key to the dictionary <samp class="SANS_TheSansMonoCd_W5Regular_11">row</samp>,
    you can look up its value by using <samp class="SANS_TheSansMonoCd_W5Regular_11">row[key]</samp>.
    You only want to display fields that aren’t blank, so after making sure that this
    key doesn’t have a blank value, the code displays both it and the value. Finally,
    after it has finished looping through all of the keys in each row, the code displays
    the separator <samp class="SANS_TheSansMonoCd_W5Regular_11">===</samp> between
    the rows.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码不是简单地显示<samp class="SANS_TheSansMonoCd_W5Regular_11">row</samp>字典，而是循环遍历其所有键，并将每个键存储在变量<samp
    class="SANS_TheSansMonoCd_W5Regular_11">key</samp>中。由于<samp class="SANS_TheSansMonoCd_W5Regular_11">key</samp>是字典<samp
    class="SANS_TheSansMonoCd_W5Regular_11">row</samp>的键，你可以通过使用<samp class="SANS_TheSansMonoCd_W5Regular_11">row[key]</samp>来查找其对应的值。你只想显示那些非空的字段，因此，在确保该键的值不为空后，代码会显示它和它的值。最后，在遍历完每一行中的所有键后，代码会在每行之间显示分隔符<samp
    class="SANS_TheSansMonoCd_W5Regular_11">===</samp>。
- en: 'You can find a copy of the complete script at [*https://<wbr>github<wbr>.com<wbr>/micahflee<wbr>/hacks<wbr>-leaks<wbr>-and<wbr>-revelations<wbr>/blob<wbr>/main<wbr>/chapter<wbr>-9<wbr>/exercise<wbr>-9<wbr>-1<wbr>.py*](https://github.com/micahflee/hacks-leaks-and-revelations/blob/main/chapter-9/exercise-9-1.py).
    Run the final script like so:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[*https://<wbr>github<wbr>.com<wbr>/micahflee<wbr>/hacks<wbr>-leaks<wbr>-and<wbr>-revelations<wbr>/blob<wbr>/main<wbr>/chapter<wbr>-9<wbr>/exercise<wbr>-9<wbr>-1<wbr>.py*](https://github.com/micahflee/hacks-leaks-and-revelations/blob/main/chapter-9/exercise-9-1.py)找到完整脚本的副本。按如下方式运行最终脚本：
- en: '[PRE15]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This time, the output should display <samp class="SANS_TheSansMonoCd_W5Regular_11">===</samp>
    between the rows and display each field of a row on its own line. If there are
    any blank fields, the program skips them.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，输出应在每行之间显示<samp class="SANS_TheSansMonoCd_W5Regular_11">===</samp>，并且每一行的每个字段显示在单独的一行。如果有空字段，程序会跳过它们。
- en: 'Using the command line skills you learned in [Chapters 3](chapter3.xhtml) and
    [4](chapter4.xhtml), redirect the output into a file with the following command:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用你在[第3章](chapter3.xhtml)和[第4章](chapter4.xhtml)中学到的命令行技巧，将输出重定向到一个文件，命令如下：
- en: '[PRE16]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This should run your script again, this time saving the output into *SARs.txt*
    instead of displaying it in your terminal. Now you can easily scroll through the
    saved output in a text editor like VS Code and search it for keywords to learn
    about the “suspicious activity” that occurred in Northern California from May
    6 to June 6, 2020.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会再次运行你的脚本，这次将输出保存到*SARs.txt*文件中，而不是在终端中显示。现在，你可以在文本编辑器（如VS Code）中轻松滚动浏览保存的输出，并搜索关键字，以了解2020年5月6日至6月6日期间在北加州发生的“可疑活动”。
- en: 'Next we’ll move on from SARs to explore another important spreadsheet in NCRIC:
    *EmailBuilder.csv*.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将从SARs转到探索NCRIC中的另一个重要电子表格：*EmailBuilder.csv*。
- en: <samp class="SANS_Futura_Std_Bold_B_11">How to Read Bulk Email from Fusion Centers</samp>
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_B_11">如何从融合中心读取批量电子邮件</samp>
- en: The primary purpose of fusion centers is to share information between local,
    state, and federal law enforcement agencies. They do this, essentially, by sending
    bulk email to a large list of local police officers. You can find the content
    of this email for all sites in BlueLeaks, including NCRIC, in the *EmailBuilder.csv*
    file located in each site’s folder. These files include the content of all of
    the bulk-email messages each fusion center sent until June 6, 2020, when it was
    hacked.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 融合中心的主要目的是在地方、州和联邦执法机构之间共享信息。它们基本上通过向大量地方警察发送批量电子邮件来完成这一任务。你可以在每个站点文件夹中找到BlueLeaks中所有站点的电子邮件内容，包括NCRIC，内容存储在*EmailBuilder.csv*文件中。这些文件包含每个融合中心直到2020年6月6日被黑客攻击之前发送的所有批量电子邮件的内容。
- en: Some of these messages are security bulletins from federal agencies like the
    FBI or the Department of Homeland Security (DHS). Others contain content directly
    created by the fusion center—for example, NCRIC and other fusion centers around
    the US generated detailed daily lists of protests against police brutality during
    the summer of 2020\. For the 13 days of NCRIC data that I looked at in detail,
    over half of the bulk email contained information about largely peaceful protests.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这些消息中有一些是来自联邦机构的安全公告，例如联邦调查局（FBI）或国土安全部（DHS）。其他则包含由融合中心直接创建的内容——例如，NCRIC及美国其他融合中心在2020年夏季生成了关于反对警察暴力的抗议活动的详细每日清单。在我详细查看的13天NCRIC数据中，超过一半的批量邮件包含关于主要是和平的抗议活动的信息。
- en: The SARs spreadsheet contains plaintext data, so it’s easy to read in a text
    editor. But the bulk-email spreadsheet contains data in HyperText Markup Language
    (HTML) format, making it difficult to read unless you use a web browser. In this
    section, you’ll learn to more easily read the HTML content of NCRIC’s bulk email,
    find the recipients of each email, and find the documents attached to the email
    messages. Open *ncric/EmailBuilder.csv* in your spreadsheet software to follow
    along.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: SARs电子表格包含纯文本数据，因此在文本编辑器中很容易阅读。但批量邮件电子表格包含的是超文本标记语言（HTML）格式的数据，除非使用网页浏览器，否则很难阅读。在本节中，你将学习如何更轻松地读取NCRIC批量邮件的HTML内容，找到每封邮件的收件人，以及查找附加在邮件中的文档。打开*ncric/EmailBuilder.csv*，并使用你的电子表格软件进行跟进。
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Lists of Black Lives
    Matter Demonstrations</samp>
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">“黑人的命也是命”示威活动清单</samp>
- en: Most of the intelligence on Black Lives Matter protests flowed through NCRIC’s
    Terrorism Liaison Officer (TLO) program, whose purpose is to keep the intelligence
    center’s members “engaged & knowledgeable about current terrorist tactics, techniques
    & trends, regional crime trends & threats, and Officer safety information,” according
    to the TLO page on NCRIC’s website. During the summer of 2020, this counterterrorism
    program didn’t focus on terrorism so much as upcoming racial justice protests.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 关于“黑人的命也是命”抗议活动的大部分情报都通过NCRIC的反恐联络官（TLO）计划流转。该计划的目的是让情报中心的成员“保持参与，并了解当前的恐怖主义战术、技术与趋势，地区犯罪趋势与威胁，以及警员安全信息”，根据NCRIC网站上的TLO页面。在2020年夏季，这个反恐项目并不专注于恐怖主义，而是集中在即将举行的种族正义抗议活动上。
- en: This section describes the twice-daily lists of upcoming protests that TLO sent
    to thousands of local cops. Not only is this incredibly newsworthy—a counterterrorism
    program abused to monitor racial justice protests—but these were the most common
    bulk-email messages that NCRIC sent during the 13-day period I examined.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了TLO每天两次向数千名地方警察发送即将举行的抗议活动清单。这不仅具有极大的新闻价值——一个反恐项目被滥用来监控种族正义抗议活动——而且这些是我在审查的13天期间，NCRIC发送的最常见的批量邮件。
- en: 'For example, here are the most interesting fields from the most recent row
    in *ncric/EmailBuilder.csv* (this CSV has 81 columns in total, most of which didn’t
    contain any relevant information):'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是从*ncric/EmailBuilder.csv*中最新一行最有趣的字段（该CSV文件总共有81列，大多数列不包含任何相关信息）：
- en: '**EmailBuilderID** 6170'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**EmailBuilderID** 6170'
- en: '**EmailFrom** NCRIC <info@ncric.net>'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**EmailFrom** NCRIC <info@ncric.net>'
- en: '**EmailSubject** NCRIC TLO Bulletin LES'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**EmailSubject** NCRIC TLO Bulletin LES'
- en: '**EmailBody** <base href="https://ncric.ca.gov/"><div style= "font-family:
    times; text-align: center;"><font face="Calibri, Times"> UNCLASSIFIED//<font color="#ee0000">LAW
    ENFORCEMENT SENSITIVE</font></font></div> […]'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**EmailBody** <base href="https://ncric.ca.gov/"><div style= "font-family:
    times; text-align: center;"><font face="Calibri, Times"> 未分类//<font color="#ee0000">执法敏感</font></font></div>
    […]'
- en: '**Attachment1** EBAT1\Events_060620_1800.pdf'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**Attachment1** EBAT1\Events_060620_1800.pdf'
- en: '**DateSent** 06/06/20 20:25:06'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**DateSent** 06/06/20 20:25:06'
- en: '**EmailTable** Registrations'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**EmailTable** Registrations'
- en: '**SentEmailList** EBSE00006\170.csv'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**SentEmailList** EBSE00006\170.csv'
- en: This row tells us that on the evening of June 6, 2020, NCRIC sent an email with
    the subject line “NCRIC TLO Bulletin LES” to the list of people described in *EBSE00006\170.csv*
    (LES stands for Law Enforcement Sensitive). The email included the PDF attachment
    located at *EBAT1\Events_060620_1800.pdf*.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这一行告诉我们，2020年6月6日晚上，NCRIC向*EBSE00006\170.csv*中描述的人员列表发送了一封主题为“NCRIC TLO Bulletin
    LES”的电子邮件（LES代表执法敏感）。邮件包含了位于*EBAT1\Events_060620_1800.pdf*的PDF附件。
- en: The body of the email is the HTML in the EmailBody column. HTML is the markup
    language that describes web pages, so it can be hard to make sense of when you’re
    not viewing it in a web browser. To read this email body, in your text editor,
    create a new file called *EmailBuilder-6170.html* (since 6170 is the EmailBuilderID).
    Copy the content of the EmailBody field from your spreadsheet software for this
    row, paste it into this file, and save it. You can now open this file in a web
    browser to view it, but before you do that, you may want to read the “Covering
    Your Tracks with a VPN Service” box to consider mitigating what information you
    might leak by opening it.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 邮件正文就是EmailBody列中的HTML。HTML是一种描述网页的标记语言，所以当你不是在网页浏览器中查看时，可能很难理解它。要读取这封邮件正文，在文本编辑器中创建一个名为*EmailBuilder-6170.html*的新文件（因为6170是EmailBuilderID）。将该行在电子表格软件中的EmailBody字段内容复制到此文件中，粘贴并保存。现在你可以在网页浏览器中打开该文件进行查看，但在此之前，你可能想先阅读“使用VPN服务掩盖你的踪迹”框，考虑在打开文件时可能泄露的信息。
- en: Whether or not you’ve connected to a VPN service (the choice is yours), open
    *EmailBuilder-6170.html* using a web browser by double-clicking on it in your
    file manager. [Figure 9-5](#fig9-5) shows what it looks like in a web browser.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是否已经连接到VPN服务（选择权在你），通过双击文件管理器中的*EmailBuilder-6170.html*，用网页浏览器打开它。[图9-5](#fig9-5)展示了它在网页浏览器中的样子。
- en: '![A screenshot of an HTML bulk email viewed in the Firefox web browser, complete
    with images and formatting.](Images/Figure9-5.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![在Firefox网页浏览器中查看的HTML批量邮件截图，包含图片和格式。](Images/Figure9-5.png)'
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-5: HTML from the EmailBody
    field in a row of</samp> <samp class="SANS_Futura_Std_Book_11">EmailBuilder.csv,</samp>
    <samp class="SANS_Futura_Std_Book_Oblique_I_11">viewed in a web browser</samp>'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Book_Oblique_I_11">图9-5：从</samp> <samp class="SANS_Futura_Std_Book_11">EmailBuilder.csv</samp>
    <samp class="SANS_Futura_Std_Book_Oblique_I_11">一行的EmailBody字段中获取的HTML，在网页浏览器中查看</samp>
- en: As you can see from the screenshot, this email body is a template, not the email
    itself. The HTML files stored inside CSVs for BlueLeaks sites are all templates.
    When sending the email, the NCRIC site would replace [AttachmentLinks] with the
    actual links to the email attachments as well as replacing other placeholders
    in the template. The attachments themselves are listed as fields in the CSV.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 从截图中可以看到，这封邮件正文是一个模板，而不是邮件本身。存储在CSV文件中的BlueLeaks网站的HTML文件都是模板。在发送邮件时，NCRIC网站会将[AttachmentLinks]替换为实际的邮件附件链接，并替换模板中的其他占位符。附件本身在CSV中作为字段列出。
- en: 'This email contained one attachment, as noted in the Attachment1 field of the
    most recent row in *EmailBuilder.csv*: the PDF file *EBAT1\Events_060620_1800.pdf*.
    [Figure 9-6](#fig9-6) shows the first page of that document.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 该邮件包含一个附件，如*EmailBuilder.csv*最新一行的Attachment1字段所示：PDF文件*EBAT1\Events_060620_1800.pdf*。[图9-6](#fig9-6)展示了该文档的第一页。
- en: The NCRIC Terrorism Liaison Officer program distributed this list to local police
    across Northern California. The events included Novato Peaceful Car Caravan, Taking
    a Knee for Change, and the Noe Valley Police Violence Protest with Social Distancing
    (the protests took place during the COVID-19 pandemic, after all).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: NCRIC恐怖主义联络官项目将此列表分发给了整个北加州的地方警察。事件包括诺瓦托和平汽车车队、为变革跪下、以及诺伊谷警察暴力抗议与社交距离（毕竟，这些抗议活动发生在COVID-19疫情期间）。
- en: '![A screenshot of a NCRIC document showing details about upcoming Black Lives
    Matter protests in Northern California.](Images/Figure9-6.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![NCRIC文档的截图，显示有关即将举行的北加州“黑人的命也是命”抗议活动的详细信息。](Images/Figure9-6.png)'
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-6: A list of upcoming
    Black Lives Matter protests in the file</samp> <samp class="SANS_Futura_Std_Book_11">Events_060620_1800.pdf</samp>'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Book_Oblique_I_11">图9-6：文件中即将举行的“黑人的命也是命”抗议活动列表</samp>
    <samp class="SANS_Futura_Std_Book_11">Events_060620_1800.pdf</samp>
- en: 'You can use the SentEmailList and EmailTable values to discover how many, and
    exactly which, local police officers received these daily bulletins. The value
    of SentEmailList is the path to a CSV file itself: *EBSE00006\170.csv*. When you
    open that CSV file (it’s in *ncric/files*), you can see that it has 14,459 rows
    (one of which is the header) and looks like this:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用SentEmailList和EmailTable值来发现多少地方警察以及哪些警察收到了这些每日简报。SentEmailList的值是CSV文件的路径：*EBSE00006\170.csv*。当你打开该CSV文件（它位于*ncric/files*文件夹中）时，你会看到它有14,459行（其中一行是表头），内容如下：
- en: '[PRE17]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In short, this CSV contains a huge list of ID numbers. The value of EmailTable
    in the *EmailBuilder.csv* row is <samp class="SANS_TheSansMonoCd_W5Regular_11">Registrations</samp>,
    which is a good hint. Since I knew that these IDs must match up to rows in some
    other table, I decided to check the file *Registrations.csv*.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这个CSV包含了一大堆ID号码。*EmailBuilder.csv*行中的EmailTable值是<samp class="SANS_TheSansMonoCd_W5Regular_11">Registrations</samp>，这是一个很好的提示。既然我知道这些ID必须与其他某个表格中的行匹配，我决定查看*Registrations.csv*文件。
- en: Open that spreadsheet yourself at *ncric/Registrations.csv*. It has 185 columns
    and over 29,000 rows, apparently listing everyone who had an account on NCRIC’s
    website. It includes each user’s full name; the agency they work for and whether
    it’s local, state, federal, or military; their email address, physical address,
    and cell phone number; their supervisor’s name and contact information; their
    password hash; and other details.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 自己打开那个电子表格，位于*ncric/Registrations.csv*。它有185列和超过29,000行，显然列出了所有在NCRIC网站上有账户的人。它包括每个用户的全名；他们所在的机构以及该机构是地方、州、联邦还是军事机构；他们的电子邮件地址、住址和手机号码；他们上司的姓名和联系方式；他们的密码哈希值；以及其他细节。
- en: The first column of *Registrations.csv* is called RegistrationsID. Each ID in
    the *EBSE00006\170.csv* file can be cross-referenced with one of these registrations.
    For example, the person in *Registrations.csv* with the RegistrationsID 63861
    works at the Santa Clara County Sheriff’s Office, lives in San Jose, has an email
    address at the domain pro.sccgov.org, and has a phone number with a 408 area code.
    In other words, NCRIC sent the email to this list of 14,458 contacts, whose contact
    details can be found in the *Registrations.csv* file. The BlueLeaks dataset includes
    this information about everyone who received bulk email through any of the websites.
    In Exercise 9-3, when you read through bulk email found in BlueLeaks, you’ll be
    able to look up exactly who received these email messages.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '*Registrations.csv*的第一列名为RegistrationsID。*EBSE00006\170.csv*文件中的每个ID都可以与这些注册记录中的一个交叉引用。例如，*Registrations.csv*中RegistrationsID为63861的人在圣塔克拉拉县警长办公室工作，住在圣荷西，电子邮件地址使用pro.sccgov.org域名，电话是408区号。换句话说，NCRIC将电子邮件发送给了这份包含14,458个联系人列表的人，而这些联系人的详细信息可以在*Registrations.csv*文件中找到。BlueLeaks数据集包含了所有通过这些网站接收群发邮件的人的信息。在练习9-3中，当你浏览BlueLeaks中找到的群发邮件时，你将能够查找出是谁收到了这些邮件。'
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">“Intelligence” Memos
    from the FBI and DHS</samp>
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">来自FBI和DHS的“智能”备忘录</samp>
- en: As mentioned earlier, in addition to detailed lists of upcoming protests, NCRIC
    also frequently forwarded memos from its federal partners—agencies like the FBI
    and DHS—to its list of over 14,000 local cops. These memos largely contained internet
    rumors, hoaxes that had already been debunked but that federal agencies apparently
    fell for, and warnings about violence from protesters that didn’t materialize.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，除了详细列出即将发生的抗议活动，NCRIC还经常将其联邦合作伙伴的备忘录转发给超过14,000名地方警察——这些合作伙伴包括FBI和DHS等机构。这些备忘录大多包含互联网谣言、已经被揭穿的恶作剧，但联邦机构显然上当受骗，还有关于抗议者暴力的警告，但这些暴力并未发生。
- en: For example, in the row in *EmailBuilder.csv* with the EmailBuilderID of 6169,
    the email body says, “The NCRIC is disseminating this (U//LES) Update on behalf
    of the FBI.” The Attachment1 value in that row is *EBAT1\SITREP-6-JUN-1300_OPE.pdf*,
    an unclassified FBI document dated June 6, 2020\. The document is full of cherry-picked
    quotes from social media posts threatening violence, but without any context.
    There was no way of knowing how many followers an account had, how much engagement
    their post had, or even if they were parodies.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在*EmailBuilder.csv*中，EmailBuilderID为6169的行中，电子邮件正文写道：“NCRIC代表FBI发布此(U//LES)更新。”该行中的Attachment1值是*EBAT1\SITREP-6-JUN-1300_OPE.pdf*，这是一个2020年6月6日的未分类FBI文件。文件中充满了从社交媒体帖子中挑选出来的威胁暴力的引用，但没有任何背景信息。无法知道一个账户有多少粉丝，帖子有多少互动，甚至是否是恶搞。
- en: The “Social Media Exploitation (SOMEX)” section of this FBI document describes
    people using Facebook, Snapchat, and Instagram to post “flyers seeking to hire
    ‘professional anarchists.’ ” This appears to reference an internet hoax from late
    May 2020\. In fact, I found multiple articles debunking this hoax on fact-checking
    sites, including Snopes, PolitiFact, and *Reuters*, dated a week before the FBI
    distributed this memo. The fake recruitment flyer offers to compensate “professional
    anarchists” with $200 per direct action, and includes the text “Funded by George
    Soros.” (Antisemitic right-wing Americans frequently and falsely claim that Soros,
    a Jewish billionaire, funds left-wing protesters.) The flyer also included the
    phone number for a local branch of the Democratic Party. Both this local Democratic
    Party branch and Soros’s Open Society Foundations confirmed that the flyer was
    a fake, but this didn’t stop the FBI from distributing it to NCRIC, which disseminated
    it to 14,458 local police across Northern California.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这份FBI文件中的“社交媒体利用（SOMEX）”部分描述了人们使用Facebook、Snapchat和Instagram发布“寻求雇佣‘专业无政府主义者’的传单。”这似乎指的是2020年5月下旬的一个网络骗局。事实上，我在事实核查网站上找到了多篇揭穿这个骗局的文章，包括Snopes、PolitiFact和*Reuters*，这些文章的发布时间比FBI发布该备忘录早了一周。这个虚假的招聘传单表示愿意以每次直接行动支付“专业无政府主义者”200美元，并附有“由乔治·索罗斯资助”字样。（反犹太的右翼美国人常常错误地声称，犹太亿万富翁索罗斯资助左翼抗议者。）传单上还附有一个当地民主党分支的电话号码。无论是该地方民主党分支，还是索罗斯的开放社会基金会，都确认该传单是伪造的，但这并没有阻止FBI将其分发给NCRIC，后者又将其分发给了北加州14,458名地方警察。
- en: The DHS also sent several memos to NCRIC to distribute to the center’s list.
    For example, take a look at the row in *EmailBuilder.csv* with the EmailBuilderID
    of 6144\. The email body says, “The NCRIC is disseminating the Intelligence Note
    ‘(U//FOUO) Some Violent Opportunists Probably Engaging in Organized Activities’
    on behalf of DHS,” and the attached document is *EBAT1\(U—FOUO) IN - Some Violent
    Opportunists Probably Engaging in Organized Activities 06012020.pdf*.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: DHS还向NCRIC发送了几份备忘录，要求其分发给中心的名单。例如，看看*EmailBuilder.csv*中EmailBuilderID为6144的那一行。邮件正文写道：“NCRIC代表DHS发布了情报备忘录‘(U//FOUO)一些暴力机会主义者可能参与有组织活动’”，附件是*EBAT1\(U—FOUO)
    IN - Some Violent Opportunists Probably Engaging in Organized Activities 06012020.pdf*。
- en: The attached PDF declares, “As the protests persist, we assess that the organized
    violent opportunists—including suspected anarchist extremists—could increasingly
    perpetrate nationwide targeting of law enforcement and critical infrastructure.”
    (This didn’t happen.) The memo goes on to say that an NYPD official “had strong
    evidence that suspected anarchist groups had planned to incite violence at protests,
    including by using encrypted communications.” Incidentally, if you completed Exercise
    2-2 and installed Signal, you too are now a user of encrypted communications.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 附件的PDF声明：“随着抗议活动的持续，我们评估认为，组织化的暴力机会主义者——包括涉嫌的无政府主义极端分子——可能会越来越频繁地在全国范围内对执法部门和关键基础设施进行针对性攻击。”（这并未发生。）该备忘录接着说，NYPD一名官员“有强有力的证据表明，涉嫌的无政府主义团体计划在抗议活动中煽动暴力，包括通过使用加密通信。”顺便提一下，如果你完成了练习2-2并安装了Signal，你现在也是加密通信的用户。
- en: As noted in [Chapter 1](chapter1.xhtml), it’s important to reach out to the
    people you’re investigating to get their side of the story. Mike Sena, NCRIC’s
    executive director, told me that his intelligence agency was monitoring Black
    Lives Matters protests in order to make sure that they remained safe. “We weren’t
    keeping track of the protests themselves, but we were identifying where we were
    gonna have gatherings of people,” he said. “That’s our concern; we want to make
    sure the events are safe—and if there are any threats that come up that may be
    associated with any of those events that we’re able to get that threat data to
    whatever agency may have protection responsibilities.”
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[第一章](chapter1.xhtml)中提到的，联系你所调查的人以了解他们的观点非常重要。NCRIC的执行董事Mike Sena告诉我，他的情报机构正在监控“黑人的命也是命”抗议活动，以确保它们保持安全。“我们不是在跟踪抗议活动本身，而是在确定我们将要集中人群的地方，”他说。“这是我们的关注点；我们想确保活动是安全的——如果在任何这些活动中出现与之相关的威胁，我们能够将这些威胁数据传递给任何有保护责任的机构。”
- en: It’s also good practice to contact outside experts—those who know more about
    the subject matter than you do—for comment. Vasudha Talla, a senior staff attorney
    with the American Civil Liberties Union of Northern California, told me, “Really
    what we have here is overbroad collection and dissemination of people’s protected
    First Amendment activity, and it’s untethered to any basis in the law.”
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 也建议联系外部专家——那些比你更了解该主题的人——进行评论。来自北加州美国公民自由联盟的资深律师Vasudha Talla告诉我：“实际上，我们这里涉及的是过度广泛地收集和传播人们受保护的第一修正案活动，这与法律没有任何联系。”
- en: As you can see, there are a lot of newsworthy details in *EmailBuilder.csv*.
    However, it’s still somewhat difficult to work with, especially because of the
    HTML email bodies. Soon you’ll write some code to make all of the bulk email easier
    to read. To do that, first you will need to learn the basics of HTML.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，*EmailBuilder.csv*中包含了许多值得注意的细节。然而，它仍然有些难以处理，特别是因为HTML邮件正文的存在。很快，你将编写一些代码，使大量邮件变得更容易阅读。为此，首先你需要学习HTML的基础知识。
- en: <samp class="SANS_Futura_Std_Bold_B_11">A Brief HTML Primer</samp>
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_B_11">简要的HTML入门</samp>
- en: In the following exercise, you’ll write some Python code that in turn writes
    some HTML code. This section covers just enough HTML syntax to get you through
    this chapter.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下练习中，你将编写一些Python代码，进而编写一些HTML代码。本节仅涉及足够的HTML语法，以便你完成本章内容。
- en: 'HTML is made up of components called *tags*. For example, consider the following
    HTML:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: HTML由称为*标签*的组件组成。例如，考虑以下HTML：
- en: '[PRE18]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This code opens a <samp class="SANS_TheSansMonoCd_W5Regular_11"><p></samp> tag
    (which represents a paragraph), includes some content (the text <samp class="SANS_TheSansMonoCd_W5Regular_11">Hello
    world</samp>), and then closes the <samp class="SANS_TheSansMonoCd_W5Regular_11"><p></samp>
    tag with <samp class="SANS_TheSansMonoCd_W5Regular_11"></p></samp>. You open a
    tag with <samp class="SANS_TheSansMonoCd_W5Regular_11"><</samp><samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">tag-name</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_11">></samp> and close it with <samp class="SANS_TheSansMonoCd_W5Regular_11"></</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">tag-name</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">></samp>.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码打开一个<samp class="SANS_TheSansMonoCd_W5Regular_11"><p></samp>标签（表示一个段落），包含一些内容（文本<samp
    class="SANS_TheSansMonoCd_W5Regular_11">Hello world</samp>），然后用<samp class="SANS_TheSansMonoCd_W5Regular_11"></p></samp>关闭<p>标签。你通过<samp
    class="SANS_TheSansMonoCd_W5Regular_11"><</samp><samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">tag-name</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_11">></samp>打开标签，通过<samp class="SANS_TheSansMonoCd_W5Regular_11"></</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">tag-name</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">></samp>关闭标签。
- en: 'HTML typically includes tags inside of tags inside of tags. It’s common to
    indent HTML code for legibility, but unlike in Python, indenting is completely
    optional. Here’s an example of a simple web page in HTML, indented to make it
    easier to read:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: HTML通常包括标签嵌套在标签中，再嵌套在标签中。为了可读性，HTML代码通常会进行缩进，但与Python不同，缩进完全是可选的。下面是一个简单的HTML网页示例，已经进行了缩进，以便更易于阅读：
- en: '[PRE19]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The whole page is wrapped in the <samp class="SANS_TheSansMonoCd_W5Regular_11"><html></samp>
    tag. Inside that, there’s a <samp class="SANS_TheSansMonoCd_W5Regular_11"><head></samp>
    tag, which includes metadata about the web page, and then a <samp class="SANS_TheSansMonoCd_W5Regular_11"><body></samp>
    tag, which includes the content of the web page. The <samp class="SANS_TheSansMonoCd_W5Regular_11"><title></samp>
    tag is a metadata tag that describes the title of the web page, which is what’s
    displayed in the browser tab itself. Inside the <samp class="SANS_TheSansMonoCd_W5Regular_11"><body></samp>,
    the biggest heading is <samp class="SANS_TheSansMonoCd_W5Regular_11"><h1></samp>,
    followed by a <samp class="SANS_TheSansMonoCd_W5Regular_11"><p></samp> paragraph.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 整个页面被包裹在<samp class="SANS_TheSansMonoCd_W5Regular_11"><html></samp>标签内。在里面，有一个<samp
    class="SANS_TheSansMonoCd_W5Regular_11"><head></samp>标签，其中包含有关网页的元数据，接着是一个<samp
    class="SANS_TheSansMonoCd_W5Regular_11"><body></samp>标签，包含网页的内容。<samp class="SANS_TheSansMonoCd_W5Regular_11"><title></samp>标签是一个元数据标签，用来描述网页的标题，它会显示在浏览器标签页上。在<samp
    class="SANS_TheSansMonoCd_W5Regular_11"><body></samp>内，最大的标题是<samp class="SANS_TheSansMonoCd_W5Regular_11"><h1></samp>，然后是一个<samp
    class="SANS_TheSansMonoCd_W5Regular_11"><p></samp>段落。
- en: 'There are plenty of other tags in HTML, but in the following exercise, you’ll
    use just two more: <samp class="SANS_TheSansMonoCd_W5Regular_11"><ul></samp> and
    <samp class="SANS_TheSansMonoCd_W5Regular_11"><li></samp>. The <samp class="SANS_TheSansMonoCd_W5Regular_11"><ul></samp>
    tag stands for “unordered list,” and it’s how you make bulleted lists in HTML.
    Inside the <samp class="SANS_TheSansMonoCd_W5Regular_11"><ul></samp> tag are <samp
    class="SANS_TheSansMonoCd_W5Regular_11"><li></samp> tags, which stand for “list
    item.” For example, here’s some HTML for a simple bulleted list:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: HTML中还有许多其他标签，但在接下来的练习中，你将只使用两个额外的标签：<samp class="SANS_TheSansMonoCd_W5Regular_11"><ul></samp>
    和 <samp class="SANS_TheSansMonoCd_W5Regular_11"><li></samp>。<samp class="SANS_TheSansMonoCd_W5Regular_11"><ul></samp>
    标签表示“无序列表”，它是用来在HTML中创建项目符号列表的。<samp class="SANS_TheSansMonoCd_W5Regular_11"><ul></samp>
    标签内是 <samp class="SANS_TheSansMonoCd_W5Regular_11"><li></samp> 标签，表示“列表项”。例如，这里有一段HTML代码，创建一个简单的项目符号列表：
- en: '[PRE20]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'When displayed in a web browser, that HTML code would look like this:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当在网页浏览器中显示时，该HTML代码会如下所示：
- en: Bash
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bash
- en: Python
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python
- en: HTML
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTML
- en: 'The less-than and greater-than characters (<samp class="SANS_TheSansMonoCd_W5Regular_11"><</samp>
    and <samp class="SANS_TheSansMonoCd_W5Regular_11">></samp>) are used to open and
    close tags in HTML. If you want to display literal less-than or greater-than characters
    in HTML, you have to *HTML escape* them. This is similar to escaping in shell
    scripts and Python code, but the syntax is different. Escape <samp class="SANS_TheSansMonoCd_W5Regular_11"><</samp>
    by replacing it with <samp class="SANS_TheSansMonoCd_W5Regular_11">&lt;</samp>
    and escape <samp class="SANS_TheSansMonoCd_W5Regular_11">></samp> by replacing
    it with <samp class="SANS_TheSansMonoCd_W5Regular_11">&gt;</samp>. For example,
    here’s some HTML code that displays the text <samp class="SANS_TheSansMonoCd_W5Regular_11">I</samp>
    <samp class="SANS_TheSansMonoCd_W5Regular_11"><3 you</samp> in a paragraph:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 小于号和大于号字符（<samp class="SANS_TheSansMonoCd_W5Regular_11"><</samp> 和 <samp class="SANS_TheSansMonoCd_W5Regular_11">></samp>）用于打开和关闭HTML标签。如果你想在HTML中显示字面意义的小于号或大于号字符，你必须进行*HTML转义*。这类似于在Shell脚本和Python代码中的转义，但语法不同。通过将
    <samp class="SANS_TheSansMonoCd_W5Regular_11"><</samp> 替换为 <samp class="SANS_TheSansMonoCd_W5Regular_11">&lt;</samp>，并将
    <samp class="SANS_TheSansMonoCd_W5Regular_11">></samp> 替换为 <samp class="SANS_TheSansMonoCd_W5Regular_11">&gt;</samp>
    来转义。例如，这里有一段HTML代码，显示文本 <samp class="SANS_TheSansMonoCd_W5Regular_11">I</samp>
    <samp class="SANS_TheSansMonoCd_W5Regular_11"><3 you</samp>，以段落形式展示：
- en: '[PRE21]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: There are a few other special characters in HTML that are each escaped in their
    own way. For example, you’d use <samp class="SANS_TheSansMonoCd_W5Regular_11">&amp;</samp>
    to escape an ampersand (<samp class="SANS_TheSansMonoCd_W5Regular_11">&</samp>).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: HTML中还有一些其他特殊字符，它们以各自的方式进行转义。例如，你可以使用 <samp class="SANS_TheSansMonoCd_W5Regular_11">&amp;</samp>
    来转义和符号（<samp class="SANS_TheSansMonoCd_W5Regular_11">&</samp>）。
- en: In the next exercise, you’ll make the email messages in *EmailBuilder.csv* easier
    to read by writing a script that automatically saves an HTML file for each one.
    This will also make it much simpler for you to find the newsworthy ones.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，你将通过编写一个脚本，自动为每封电子邮件保存一个HTML文件，使*EmailBuilder.csv*中的电子邮件信息更易读。这也将使你更容易找到那些值得关注的电子邮件。
- en: '<samp class="SANS_Futura_Std_Heavy_B_21">Exercise 9-2: Make Bulk Email Readable</samp>'
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '<samp class="SANS_Futura_Std_Heavy_B_21">练习 9-2: 使批量电子邮件易读</samp>'
- en: For this exercise, you’ll write a script similar to the one you wrote in Exercise
    9-1, but instead of displaying text output to the screen, you’ll save HTML output
    to files. This allows you to look through a folder full of HTML files, each one
    a different bulk email, open these files in a web browser, and read them in a
    more legible format. While this particular exercise is designed specifically for
    the *EmailBuilder.csv* files in BlueLeaks, it’s common to find HTML in datasets,
    so being able to write a similar script could help you in the future.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你将编写一个脚本，类似于在练习9-1中编写的那个脚本，但这次你将把HTML输出保存到文件中，而不是将文本输出到屏幕上。这样，你就可以查看一个包含HTML文件的文件夹，每个文件代表一个不同的批量电子邮件，将这些文件在网页浏览器中打开，并以更易读的格式阅读它们。虽然本练习专门为BlueLeaks中的*EmailBuilder.csv*文件设计，但在数据集中常常会遇到HTML，因此能够编写类似的脚本可能对你未来有所帮助。
- en: 'For a challenge, you can try programming your own script to meet the following
    requirements:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 作为挑战，你可以尝试编写自己的脚本，满足以下要求：
- en: Make this script accept two arguments called <samp class="SANS_TheSansMonoCd_W5Regular_11">emailbuilder_csv_path</samp>
    and <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp> using
    Click. The <samp class="SANS_TheSansMonoCd_W5Regular_11">emailbuilder_csv_path</samp>
    argument should be the path to an *EmailBuilder.csv* file, and the <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>
    argument should be the path to a folder in which to save the HTML files.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make sure the folder at <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>
    exists by importing the <samp class="SANS_TheSansMonoCd_W5Regular_11">os</samp>
    module and running <samp class="SANS_TheSansMonoCd_W5Regular_11">os.makedirs(output_folder_path,
    exist_ok=True)</samp>.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Import the <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp> module and
    loop through all of the rows in the CSV located at <samp class="SANS_TheSansMonoCd_W5Regular_11">emailbuilder_csv_path</samp>,
    loading each row as a dictionary.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For each row, save a new HTML file. This file should include information from
    the bulk-email fields most relevant for your purposes: EmailBuilderID, EmailFrom,
    EmailSubject, DateSent, Attachment1, and SentEmailList. It should also include
    the HTML body of the email itself, EmailBody.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Otherwise, follow along with the rest of this exercise and I’ll walk you through
    the programming process. Start with the usual Python script template in a file
    called *exercise-9-2.py*:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Next, you’ll modify your script to make the script accept command line arguments
    using Click.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Accept the Command
    Line Arguments</samp>
  id: totrans-222
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following code has been modified to import the <samp class="SANS_TheSansMonoCd_W5Regular_11">click</samp>
    module and accept some command line arguments:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: First, the code imports the <samp class="SANS_TheSansMonoCd_W5Regular_11">click</samp>
    module, and then it uses Click decorators to make the <samp class="SANS_TheSansMonoCd_W5Regular_11">main()</samp>
    function a Click command that accepts two arguments, <samp class="SANS_TheSansMonoCd_W5Regular_11">emailbuilder_csv_path</samp>
    and <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>. The
    code also has two <samp class="SANS_TheSansMonoCd_W5Regular_11">print()</samp>
    statements that display the values of the two arguments. The <samp class="SANS_TheSansMonoCd_W5Regular_11">emailbuilder_csv_path</samp>
    argument should point to the path of a BlueLeaks *EmailBuilder.csv*, which you’ll
    load and loop through, and the <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder
    _path</samp> argument should be the path to a folder in which you’ll store the
    HTML files for the bulk-email messages.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'Test your code and make sure it’s working as expected so far, replacing the
    path to *EmailBuilder.csv* with the appropriate path for your computer:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: As expected, the script displays the values of the two arguments.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Create the Output
    Folder</samp>
  id: totrans-229
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">创建输出文件夹</samp>
- en: 'Next, use Python to create the folder in <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>
    where you’ll save the HTML files:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用Python在<samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>中创建文件夹，用于保存HTML文件：
- en: '[PRE25]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: To be able to use the <samp class="SANS_TheSansMonoCd_W5Regular_11">os.makedirs()</samp>
    function, first the script imports the <samp class="SANS_TheSansMonoCd_W5Regular_11">os</samp>
    module. Then it uses the <samp class="SANS_TheSansMonoCd_W5Regular_11">os.makedirs()</samp>
    function to create a new folder in Python, passing in the path to the folder to
    create, <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够使用<samp class="SANS_TheSansMonoCd_W5Regular_11">os.makedirs()</samp>函数，脚本首先导入<samp
    class="SANS_TheSansMonoCd_W5Regular_11">os</samp>模块。然后它使用<samp class="SANS_TheSansMonoCd_W5Regular_11">os.makedirs()</samp>函数在Python中创建一个新文件夹，传入要创建的文件夹路径<samp
    class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>。
- en: The <samp class="SANS_TheSansMonoCd_W5Regular_11">exists_ok=True</samp> keyword
    argument tells this function that it’s fine if that folder already exists; otherwise,
    if the folder already existed, the script would crash with an error message. This
    way, the first time you run this script with a specific output folder, it will
    create that folder and use it to store the HTML files. If you run the script again
    in the future with that same output folder, it will use the folder that’s already
    there.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`<samp class="SANS_TheSansMonoCd_W5Regular_11">exists_ok=True</samp>`关键字参数告诉此函数，如果文件夹已经存在也没关系；否则，如果文件夹已存在，脚本将因错误信息而崩溃。通过这种方式，当你第一次使用特定输出文件夹运行脚本时，它会创建该文件夹并用它来存储HTML文件。如果将来再次运行脚本并使用相同的输出文件夹，它会使用已经存在的文件夹。'
- en: When you run the complete script at the end of this exercise, you’ll be able
    to browse the files in this folder to read through the bulk-email messages sent
    by a fusion center.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行此练习末尾的完整脚本时，你将能够浏览此文件夹中的文件，阅读由融合中心发送的大量电子邮件消息。
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Define the Filename
    for Each Row</samp>
  id: totrans-235
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">为每一行定义文件名</samp>
- en: 'The goal of this script is to save an HTML file for each row in the spreadsheet.
    To do this, you’ll need to load the CSV, loop through its rows, and figure out
    the filename for each HTML file that you’re going to save. Next, define the <samp
    class="SANS_TheSansMonoCd_W5Regular_11">filename</samp> variable, naming each
    HTML file based on data that you found in that row. To do so, make the following
    modifications:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本的目标是为电子表格中的每一行保存一个HTML文件。为此，你需要加载CSV，遍历它的每一行，并找出要保存的每个HTML文件的文件名。接下来，定义<samp
    class="SANS_TheSansMonoCd_W5Regular_11">filename</samp>变量，并根据该行中的数据命名每个HTML文件。为此，请做以下修改：
- en: '[PRE26]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The script starts by importing the <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp>
    module. As in the previous exercise, the code then opens the CSV file and creates
    a CSV reader using <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp>.
    Using a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop, the code
    loops through each row in the CSV.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本首先导入<samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp>模块。与前面的练习一样，代码接着打开CSV文件并使用<samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp>创建CSV读取器。通过<samp
    class="SANS_TheSansMonoCd_W5Regular_11">for</samp>循环，代码遍历CSV中的每一行。
- en: Rather than just displaying information, you ultimately want to save each row
    as an HTML file. To prepare to write the code that actually generates those files
    in the next section, this code defines a <samp class="SANS_TheSansMonoCd_W5Regular_11">filename</samp>
    variable with the name of the unique HTML file to be generated for each row. In
    order to make it unique, the code defines <samp class="SANS_TheSansMonoCd_W5Regular_11">filename</samp>
    using the current row’s EmailBuilderID, DateSent, and EmailSubject fields, and
    ends it with the.<samp class="SANS_TheSansMonoCd_W5Regular_11">html</samp> file
    extension. For example, according to this format, the filename for the bulk email
    described in the previous section would be *6170_06/06/20 20:25:06_NCRIC TLO Bulletin
    LES.html*.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'The code defines <samp class="SANS_TheSansMonoCd_W5Regular_11">filename</samp>
    as an f-string surrounded in double quotes (<samp class="SANS_TheSansMonoCd_W5Regular_11">"</samp>).
    The variables inside it, like <samp class="SANS_TheSansMonoCd_W5Regular_11">row["EmailSubject"]</samp>,
    have quotes of their own, but you can’t use the double-quote character inside
    a double-quoted f-string without Python mistakenly thinking you’re closing the
    f-string. Instead, this code uses single quotes (<samp class="SANS_TheSansMonoCd_W5Regular_11">''</samp>)
    for the variables within the f-string: <samp class="SANS_TheSansMonoCd_W5Regular_11">row[''EmailSubject'']</samp>.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: The slash characters (<samp class="SANS_TheSansMonoCd_W5Regular_11">/</samp>)
    contained in the DateSent column are invalid characters for filenames because
    slashes separate folders in a path. To address this, the line <samp class="SANS_TheSansMonoCd_W5Regular_11">filename</samp>
    <samp class="SANS_TheSansMonoCd_W5Regular_11">=</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11">filename.replace("/",
    "-")</samp> replaces any slashes it finds in the filename with dash characters
    (<samp class="SANS_TheSansMonoCd_W5Regular_11">-</samp>). This generates the valid
    filename *6170_06-06-20 20:25:06_NCRIC TLO Bulletin LES.html*.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Finally, this code uses <samp class="SANS_TheSansMonoCd_W5Regular_11">os.path.join()</samp>,
    discussed in [Chapter 8](chapter8.xhtml), to append <samp class="SANS_TheSansMonoCd_W5Regular_11">filename</samp>
    to the end of <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>,
    giving you the complete path to the file you’re going to write. You’ll ultimately
    save the HTML file in this path. For example, if the filename <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>
    is <samp class="SANS_TheSansMonoCd_W5Regular_11">output</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">filename</samp>
    is <samp class="SANS_TheSansMonoCd_W5Regular_11">6170_06-06-20 20:25:06_NCRIC
    TLO Bulletin LES.html</samp>, <samp class="SANS_TheSansMonoCd_W5Regular_11">os.path.join()</samp>
    updates <samp class="SANS_TheSansMonoCd_W5Regular_11">filename</samp> to be <samp
    class="SANS_TheSansMonoCd_W5Regular_11">output/6170_06-06-20 20:25:06_NCRIC TLO
    Bulletin LES.html</samp>.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，代码使用 <samp class="SANS_TheSansMonoCd_W5Regular_11">os.path.join()</samp>，该方法在[第8章](chapter8.xhtml)中讨论过，用来将
    <samp class="SANS_TheSansMonoCd_W5Regular_11">filename</samp> 添加到 <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>
    的末尾，从而为你提供要写入的文件的完整路径。最终，你会将HTML文件保存在这个路径中。例如，如果文件夹路径 <samp class="SANS_TheSansMonoCd_W5Regular_11">output_folder_path</samp>
    为 <samp class="SANS_TheSansMonoCd_W5Regular_11">output</samp>，而文件名 <samp class="SANS_TheSansMonoCd_W5Regular_11">filename</samp>
    为 <samp class="SANS_TheSansMonoCd_W5Regular_11">6170_06-06-20 20:25:06_NCRIC TLO
    Bulletin LES.html</samp>，则 <samp class="SANS_TheSansMonoCd_W5Regular_11">os.path.join()</samp>
    会将 <samp class="SANS_TheSansMonoCd_W5Regular_11">filename</samp> 更新为 <samp class="SANS_TheSansMonoCd_W5Regular_11">output/6170_06-06-20
    20:25:06_NCRIC TLO Bulletin LES.html</samp>。
- en: 'To make sure everything is working so far, the code displays this final filename.
    Pause and test your code, using the correct filepath for your operating system:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保到目前为止一切正常，代码会显示最终的文件名。暂停并测试代码，使用适合你操作系统的正确文件路径：
- en: '[PRE27]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The output should show a unique filename for each row in the *EmailBuilder.csv*
    spreadsheet. All you need to do now is actually write those HTML files.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该显示每一行在*EmailBuilder.csv*电子表格中的唯一文件名。现在你需要做的就是实际写入这些HTML文件。
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Write the HTML Version
    of Each Bulk Email</samp>
  id: totrans-246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">编写每个批量电子邮件的HTML版本</samp>
- en: 'The purpose of saving each row of *EmailBuilder.csv* as an HTML file is to
    more easily read these bulk-email messages by loading the HTML in a web browser.
    You’ll obviously want to see the email body, but it would also be helpful to display
    some basic metadata about the email: the date it was sent, the subject, and so
    on. The following code writes the HTML files, automatically filling in both the
    metadata and the email body with data from the CSV:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 将每行*EmailBuilder.csv*保存为HTML文件的目的是为了通过在网页浏览器中加载HTML文件，方便地阅读这些批量电子邮件信息。显然，你会希望查看电子邮件的正文，但展示一些关于电子邮件的基本元数据也会很有帮助：比如发送日期、主题等。以下代码会自动填写元数据和电子邮件正文，并写入HTML文件：
- en: '[PRE28]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: First, the code imports the <samp class="SANS_TheSansMonoCd_W5Regular_11">html</samp>
    module, which will be used later on to escape HTML code. The code starts by defining
    a list, called <samp class="SANS_TheSansMonoCd_W5Regular_11">important_keys</samp>,
    of all of the important keys to include in the final HTML file. This code is positioned
    near the top of the <samp class="SANS_TheSansMonoCd_W5Regular_11">main()</samp>
    function, before the <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp>
    loop, so that this variable will be available inside each loop, and therefore
    every HTML file will include these same fields.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，代码导入了 <samp class="SANS_TheSansMonoCd_W5Regular_11">html</samp> 模块，稍后将用于转义HTML代码。代码开始时定义了一个名为
    <samp class="SANS_TheSansMonoCd_W5Regular_11">important_keys</samp> 的列表，包含最终HTML文件中需要包含的所有重要键。该代码位于
    <samp class="SANS_TheSansMonoCd_W5Regular_11">main()</samp> 函数的顶部，在 <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp>
    循环之前，这样该变量就可以在每个循环中使用，从而确保每个HTML文件都会包含这些相同的字段。
- en: Inside the <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop, the
    code stores each row of the spreadsheet in the dictionary <samp class="SANS_TheSansMonoCd_W5Regular_11">row</samp>,
    so you can access its fields using keys. Then, the code opens the HTML file for
    writing with the command <samp class="SANS_TheSansMonoCd_W5Regular_11">with open(filename,
    "w") as</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11">html_f:</samp> (as
    you saw in “Reading and Writing Files” in [Chapter 8](chapter8.xhtml)). The file
    object for the HTML file is the <samp class="SANS_TheSansMonoCd_W5Regular_11">html_f</samp>
    variable. Inside this <samp class="SANS_TheSansMonoCd_W5Regular_11">with</samp>
    statement, the code then starts writing the HTML file by calling <samp class="SANS_TheSansMonoCd_W5Regular_11">html_f.write()</samp>
    and passing in a string containing HTML, first for <samp class="SANS_TheSansMonoCd_W5Regular_11"><html></samp>
    and <samp class="SANS_TheSansMonoCd_W5Regular_11"><body></samp> tags and then
    for a <samp class="SANS_TheSansMonoCd_W5Regular_11"><ul></samp> tag to represent
    a bulleted list.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在 <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> 循环中，代码将电子表格的每一行存储在字典
    <samp class="SANS_TheSansMonoCd_W5Regular_11">row</samp> 中，因此你可以通过键来访问其中的字段。然后，代码使用命令
    <samp class="SANS_TheSansMonoCd_W5Regular_11">with open(filename, "w") as</samp>
    <samp class="SANS_TheSansMonoCd_W5Regular_11">html_f:</samp> 打开 HTML 文件进行写入（正如你在
    [第 8 章](chapter8.xhtml) 中的“读取和写入文件”部分看到的）。HTML 文件的文件对象是 <samp class="SANS_TheSansMonoCd_W5Regular_11">html_f</samp>
    变量。在这个 <samp class="SANS_TheSansMonoCd_W5Regular_11">with</samp> 语句内，代码开始通过调用
    <samp class="SANS_TheSansMonoCd_W5Regular_11">html_f.write()</samp> 来写入 HTML 文件，并传入包含
    HTML 的字符串，首先是 <samp class="SANS_TheSansMonoCd_W5Regular_11"><html></samp> 和 <samp
    class="SANS_TheSansMonoCd_W5Regular_11"><body></samp> 标签，然后是表示项目符号列表的 <samp class="SANS_TheSansMonoCd_W5Regular_11"><ul></samp>
    标签。
- en: Next, the code fills in the bulleted list with the important metadata. Using
    a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop, it loops through
    the keys in <samp class="SANS_TheSansMonoCd_W5Regular_11">important_keys</samp>,
    writing each piece of metadata to the HTML file in its own <samp class="SANS_TheSansMonoCd_W5Regular_11"><li</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_11">></samp> tag, in the format
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，代码通过使用 <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> 循环，遍历 <samp
    class="SANS_TheSansMonoCd_W5Regular_11">important_keys</samp> 中的键，将每个元数据项写入 HTML
    文件中的 <samp class="SANS_TheSansMonoCd_W5Regular_11"><li</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">></samp>
    标签，格式如下：
- en: '[PRE29]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: where <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">metadata_item</samp>
    is the name of an important piece of metadata in <samp class="SANS_TheSansMonoCd_W5Regular_11">key</samp>,
    and <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">metadata_value</samp>
    is the value of that piece of metadata in <samp class="SANS_TheSansMonoCd_W5Regular_11">row[key]</samp>.
    For example, <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">metadata_item</samp>
    might be <samp class="SANS_TheSansMonoCd_W5Regular_11">EmailBuilderID</samp>,
    and <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">metadata_value</samp>
    might be <samp class="SANS_TheSansMonoCd_W5Regular_11">6170</samp>, as in the
    example CSV row in the “Lists of Black Lives Matter Demonstrations” section.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">metadata_item</samp>
    是 <samp class="SANS_TheSansMonoCd_W5Regular_11">key</samp> 中一个重要元数据项的名称，而 <samp
    class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">metadata_value</samp> 是该元数据项在
    <samp class="SANS_TheSansMonoCd_W5Regular_11">row[key]</samp> 中的值。例如，<samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">metadata_item</samp>
    可能是 <samp class="SANS_TheSansMonoCd_W5Regular_11">EmailBuilderID</samp>，而 <samp
    class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">metadata_value</samp> 可能是 <samp
    class="SANS_TheSansMonoCd_W5Regular_11">6170</samp>，正如“黑人的命也是命示威活动列表”部分中的示例 CSV
    行所示。
- en: Instead of displaying the value with <samp class="SANS_TheSansMonoCd_W5Regular_11">row[key]</samp>,
    though, this line of code uses <samp class="SANS_TheSansMonoCd_W5Regular_11">html.escape(row[key])</samp>.
    This is necessary because some of the fields you want to include use angle brackets
    (<samp class="SANS_TheSansMonoCd_W5Regular_11"><</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">></samp>),
    which indicate tags in HTML. For example, if the value of the FromEmail field
    is <samp class="SANS_TheSansMonoCd_W5Regular_11">NCRIC</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11"><info@ncric.net></samp>,
    your web browser will interpret <samp class="SANS_TheSansMonoCd_W5Regular_11"><info@ncric.net></samp>
    as an HTML tag called <samp class="SANS_TheSansMonoCd_W5Regular_11">info@ncric.net</samp>,
    which isn’t a real tag, so nothing will display. In Python, the <samp class="SANS_TheSansMonoCd_W5Regular_11">html.escape()</samp>
    function lets you HTML escape a string. For example, <samp class="SANS_TheSansMonoCd_W5Regular_11">html.escape("NCRIC</samp>
    <samp class="SANS_TheSansMonoCd_W5Regular_11"><info@ncric.net>")</samp> returns
    the string <samp class="SANS_TheSansMonoCd_W5Regular_11">NCRIC &lt;info@ncric.net&gt;</samp>
    and that’s what gets saved to the HTML file, so that when you later view that
    file, the string displays correctly as <samp class="SANS_TheSansMonoCd_W5Regular_11">NCRIC</samp>
    <samp class="SANS_TheSansMonoCd_W5Regular_11"><info@ncric.net></samp>.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: When the <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop finishes
    running, all of the important metadata will have been written to the HTML file.
    The code then writes <samp class="SANS_TheSansMonoCd_W5Regular_11"></ul></samp>
    to close the bulleted list tag. After displaying the bulleted list of important
    fields, the code displays the EmailBody field in a <samp class="SANS_TheSansMonoCd_W5Regular_11"><</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_11">div></samp> tag. This time, it doesn’t
    HTML escape this field, because you want to load the email’s HTML in a browser.
    Finally, the <samp class="SANS_TheSansMonoCd_W5Regular_11"><body></samp> and <samp
    class="SANS_TheSansMonoCd_W5Regular_11"><html></samp> tags are closed with <samp
    class="SANS_TheSansMonoCd_W5Regular_11"></body></html></samp>.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the complete script at [*https://<wbr>github<wbr>.com<wbr>/micahflee<wbr>/hacks<wbr>-leaks<wbr>-and<wbr>-revelations<wbr>/blob<wbr>/main<wbr>/chapter<wbr>-9<wbr>/exercise<wbr>-9<wbr>-2<wbr>.py*](https://github.com/micahflee/hacks-leaks-and-revelations/blob/main/chapter-9/exercise-9-2.py).
    This is the most complicated Python script you’ve written so far in this book,
    but it’s about to pay off. Run it on the NCRIC data, using the filepath appropriate
    for your operating system:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This output looks similar to the last time you ran the script, except now it
    also creates a folder full of 5,213 new HTML files—one for every row of NCRIC’s
    *EmailBuilder.csv* file—in the output folder you specified. The information now
    included in the filenames allows you to browse through the files in your file
    manager, exploring those that look most interesting.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 9-7](#fig9-7) shows the list of files generated when I ran this script.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a graphical file manager showing the folder full of HTML
    files that we just generated.](Images/Figure9-7.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-7: Viewing the HTML
    files generated by the Python script in macOS Finder</samp>'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: This folder contains the thousands of HTML files that your Python script just
    created. The first part of the filename is the EmailBuilderID, followed by DateSent,
    followed by EmailSubject. To read one of these bulk emails, just double-click
    the HTML file to open it in a web browser. If you want more information about
    a specific bulk email, you can always look it up by EmailBuilderID in the original
    spreadsheet.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'To see what the final HTML output looks like, open one of these files in your
    text editor. For example, here’s the final HTML output from the *6098_05-18-20
    12/45/12_Chasing Cell Phones presented via Zoom Webinar.html* file:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: All of the bolded parts have been filled in automatically by the Python code.
    In the bulleted list at the top, <samp class="SANS_TheSansMonoCd_W5Regular_11">EmailBuilderID</samp>,
    <samp class="SANS_TheSansMonoCd_W5Regular_11">EmailFrom</samp>, and so on are
    keys from the <samp class="SANS_TheSansMonoCd_W5Regular_11">important_keys</samp>
    list, and <samp class="SANS_TheSansMonoCd_W5Regular_11">6098</samp>, <samp class="SANS_TheSansMonoCd_W5Regular_11">NCRIC
    &lt;info@ncric.net&gt</samp>, and so on are HTML-escaped values from the <samp
    class="SANS_TheSansMonoCd_W5Regular_11">row</samp> dictionary. Below the bulleted
    list, inside the <samp class="SANS_TheSansMonoCd_W5Regular_11"><div></samp> tag,
    is the email body—the value of <samp class="SANS_TheSansMonoCd_W5Regular_11">row["EmailBody"]</samp>.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 9-8](#fig9-8) shows what these bulk email messages look like in a web
    browser. In this case, I opened a bulk email sent out on May 18, 2020, advertising
    a course called Chasing Cell Phones hosted by the Northern California High Intensity
    Drug Tracking Area. The class was designed to teach police how to get valuable
    evidence directly off of suspects’ cell phones or from third-party sources like
    cell phone providers.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot for a course called “Chasing Cell Phones,” to be held on Zoom
    on June 4, 2020\. The description starts with: “This class will explore the methods
    of exploiting a suspect’s cellular phone, phone company records, and third-party
    data sources records to assist investigations . . .”](Images/Figure9-8.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-8: Viewing a NCRIC
    bulk email in a web browser</samp>'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: You can use the script from this exercise to make the bulk email from any BlueLeaks
    folder more readable; just run the script on the appropriate *EmailBuilder.csv*
    file.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: The BlueLeaks folder names alone don’t immediately make clear which folders
    belong to which organizations. Let’s fix that by creating a spreadsheet that associates
    each BlueLeaks folder with its organization name, website title, and URL.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Discovering the Names and URLs of BlueLeaks
    Sites</samp>
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s obvious what organization some BlueLeaks folders belong to based on the
    folder name. You can reasonably guess that the *alabamafusioncenter* folder has
    data from the Alabama Fusion Center. But most aren’t so clear. Can you guess what
    *ciacco* is? How about *nvhidta* or *snorca*?
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: After manually looking through the CSV files in various BlueLeaks folders, I
    discovered that the file *Company.csv* contains, hidden among its 108 columns,
    the name and URL of each site. Some BlueLeaks folders, it turns out, host more
    than one site. For example, in [Table 9-3](#tab9-3), which shows these columns
    from NCRIC’s *Company.csv* file, you can see that the *ncric* folder hosts 18
    different sites at different URLs.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Heavy_B_11">Table 9-3:</samp> <samp class="SANS_Futura_Std_Book_11">Data
    from</samp> <samp class="SANS_Futura_Std_Book_Oblique_I_11">ncric/Company.csv</samp>
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '| <samp class="SANS_Futura_Std_Heavy_B_11">CompanyID</samp> | <samp class="SANS_Futura_Std_Heavy_B_11">CompanyName</samp>
    | <samp class="SANS_Futura_Std_Heavy_B_11">WebsiteTitle</samp> | <samp class="SANS_Futura_Std_Heavy_B_11">URL</samp>
    |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">1</samp> | <samp class="SANS_Futura_Std_Book_11">NCRIC.net</samp>
    | <samp class="SANS_Futura_Std_Book_11">Northern California Regional Intelligence
    Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">ncric.net</samp>
    |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">2</samp> | <samp class="SANS_Futura_Std_Book_11">NCRIC
    New</samp> | <samp class="SANS_Futura_Std_Book_11">Northern California Regional
    Intelligence Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">upinsmoke.ncric.net</samp>
    |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">3</samp> | <samp class="SANS_Futura_Std_Book_11">NCRIC</samp>
    | <samp class="SANS_Futura_Std_Book_11">Northern California Regional Intelligence
    Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">ncric.org</samp>
    |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">4</samp> | <samp class="SANS_Futura_Std_Book_11">NCHIDTA</samp>
    | <samp class="SANS_Futura_Std_Book_11">Northern California Regional Intelligence
    Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">nchidta.org</samp>
    |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">7</samp> | <samp class="SANS_Futura_Std_Book_11">NCHIDTA.net</samp>
    | <samp class="SANS_Futura_Std_Book_11">Northern California Regional Intelligence
    Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">nchidta.net</samp>
    |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">8</samp> | <samp class="SANS_Futura_Std_Book_11">NCRTTAC.org</samp>
    | <samp class="SANS_Futura_Std_Book_11">Northern California Regional Intelligence
    Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">ncrttac.org</samp>
    |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">10</samp> | <samp class="SANS_Futura_Std_Book_11">NCRTTAC.org</samp>
    | <samp class="SANS_Futura_Std_Book_11">Northern California Regional Intelligence
    Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">www.ncrttac.org</samp>
    |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">11</samp> | <samp class="SANS_Futura_Std_Book_11">Northern
    California Most Wanted</samp> | <samp class="SANS_Futura_Std_Book_11">Northern
    California Most Wanted - Serving The Bay Area and Surrounding Counties</samp>
    | <samp class="SANS_Futura_Std_Book_11">northerncaliforniamostwanted.org</samp>
    |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">12</samp> | <samp class="SANS_Futura_Std_Book_11">Northern
    California Most Wanted</samp> | <samp class="SANS_Futura_Std_Book_11">Northern
    California Most Wanted</samp> | <samp class="SANS_Futura_Std_Book_11">northerncaliforniamostwanted.com</samp>
    |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">14</samp> | <samp class="SANS_Futura_Std_Book_11">Northern
    California Most Wanted</samp> | <samp class="SANS_Futura_Std_Book_11">Northern
    California Most Wanted</samp> | <samp class="SANS_Futura_Std_Book_11">ncmostwanted.org</samp>
    |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">15</samp> | <samp class="SANS_Futura_Std_Book_11">NCRIC
    Private Sector Mobile Registration</samp> | <samp class="SANS_Futura_Std_Book_11">Northern
    California Regional Intelligence Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">psp.ncric.net</samp>
    |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">16</samp> | <samp class="SANS_Futura_Std_Book_11">NCHIDTA.com</samp>
    | <samp class="SANS_Futura_Std_Book_11">Northern California Regional Intelligence
    Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">nchidta.com</samp>
    |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">17</samp> | <samp class="SANS_Futura_Std_Book_11">NCRIC</samp>
    | <samp class="SANS_Futura_Std_Book_11">NCRIC Mobile</samp> |  |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">19</samp> | <samp class="SANS_Futura_Std_Book_11">NCRIC</samp>
    | <samp class="SANS_Futura_Std_Book_11">Northern California Regional Intelligence
    Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">passwordreset.ncric.ca.gov</samp>
    |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">20</samp> | <samp class="SANS_Futura_Std_Book_11">NCHIDTA</samp>
    | <samp class="SANS_Futura_Std_Book_11">NCHIDTA Mobile</samp> |  |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">21</samp> | <samp class="SANS_Futura_Std_Book_11">NCHIDTA
    (New)</samp> | <samp class="SANS_Futura_Std_Book_11">Northern California Regional
    Intelligence Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">new.nchidta.org</samp>
    |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">22</samp> | <samp class="SANS_Futura_Std_Book_11">NCRIC</samp>
    | <samp class="SANS_Futura_Std_Book_11">Northern California Regional Intelligence
    Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">ncric.ca.gov</samp>
    |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
- en: '| <samp class="SANS_Futura_Std_Book_11">23</samp> | <samp class="SANS_Futura_Std_Book_11">NCRIC
    NEW</samp> | <samp class="SANS_Futura_Std_Book_11">Northern California Regional
    Intelligence Center - NCRIC</samp> | <samp class="SANS_Futura_Std_Book_11">new.ncric.ca.gov</samp>
    |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
- en: As you can see here, the *ncric* folder hosts not only the NCRIC site but also
    the sites for the Northern California High Intensity Drug Trafficking Area (NCHIDTA);
    the Northern California Most Wanted, which lists wanted fugitives; and others.
    However, all these websites share the same code and databases.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: Since almost every BlueLeaks folder contains a *Company.csv* file listing all
    of the sites associated with that folder, we can write a script to automatically
    extract this information and format it as a CSV file. This will open the door
    for you to pick which fusion center you want to research—perhaps there’s one in
    a city near you.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '<samp class="SANS_Futura_Std_Heavy_B_21">Exercise 9-3: Make a CSV of BlueLeaks
    Sites</samp>'
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The script you write in this exercise will loop through each BlueLeaks folder,
    open its *Company.csv* file, and save information about the organizations whose
    websites are hosted in that folder into a CSV file that you create. For a challenge,
    you can try programming your own script to do the following:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: 'Accept two arguments: <samp class="SANS_TheSansMonoCd_W5Regular_11">blueleaks_path</samp>,
    the path to your extracted BlueLeaks data, and <samp class="SANS_TheSansMonoCd_W5Regular_11">output_csv_path</samp>,
    the path to the new CSV file that the script will create.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Include these headers: <samp class="SANS_TheSansMonoCd_W5Regular_11">BlueLeaksFolder</samp>
    (the BlueLeaks folder name), <samp class="SANS_TheSansMonoCd_W5Regular_11">CompanyID</samp>,
    <samp class="SANS_TheSansMonoCd_W5Regular_11">CompanyName</samp>, <samp class="SANS_TheSansMonoCd_W5Regular_11">WebsiteTitle</samp>,
    and <samp class="SANS_TheSansMonoCd_W5Regular_11">URL</samp> (you’ll find these
    latter fields in the various *Company.csv* files).'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open <samp class="SANS_TheSansMonoCd_W5Regular_11">output_csv_path</samp> for
    writing and create a <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictWriter()</samp>
    object (see “Reading and Writing CSV Files in Python” on page 248), passing in
    the file object and the headers.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loop through each folder in BlueLeaks. You can get a list of all the filenames
    with <samp class="SANS_TheSansMonoCd_W5Regular_11">os.listdir(blueleaks_path)</samp>.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inside each BlueLeaks folder, open the *Company.csv* file if it exists, and
    loop through all of the rows in that CSV. For each row, select the information
    you want to save and then write it to your CSV.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Map out exactly what websites each BlueLeaks folder hosts in your output CSV.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Otherwise, the rest of this exercise will walk you through the programming
    process. Start with the usual Python script template in a file called *exercise-9-3.py*:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, modify your script to accept the <samp class="SANS_TheSansMonoCd_W5Regular_11">blueleaks_path</samp>
    and <samp class="SANS_TheSansMonoCd_W5Regular_11">output_csv_path</samp> command
    line arguments:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: You’ve done this enough times at this point that you can safely assume the arguments
    are working properly without testing the script.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Open a CSV for Writing</samp>
  id: totrans-310
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The simplest way to program this script is to first open a CSV file for writing
    and then loop through each folder in BlueLeaks, adding rows to this CSV. Start
    by just opening the CSV file for writing, using the following code:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: First, the code imports the <samp class="SANS_TheSansMonoCd_W5Regular_11">csv</samp>
    module. It then defines what the headers of the output CSV will be in the variable
    <samp class="SANS_TheSansMonoCd_W5Regular_11">headers</samp>. As noted in “Reading
    and Writing CSV Files in Python,” in order to create a <samp class="SANS_TheSansMonoCd_W5Regular_11">csv.DictWriter()</samp>
    object, you’ll need to pass in this list of headers for your CSV file.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Next, the code opens the output CSV file for writing, this time calling it <samp
    class="SANS_TheSansMonoCd_W5Regular_11">output_f</samp>, and creates the <samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv.DictWriter()</samp> object, saving
    it in the <samp class="SANS_TheSansMonoCd_W5Regular_11">writer</samp> variable.
    Finally, the program writes the header row to the CSV. To write the remaining
    rows, you’ll need to run <samp class="SANS_TheSansMonoCd_W5Regular_11">writer.writerow()</samp>,
    passing in a dictionary that represents the row.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: 'Try running the script so far:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The script itself shouldn’t display any output; it should just create an output
    CSV file, *sites.csv*. Try displaying its contents using <samp class="SANS_TheSansMonoCd_W5Regular_11">cat</samp>:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: You should see that the file currently contains only header rows.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Find All the Company.csv
    Files</samp>
  id: totrans-320
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Now that you can write rows to your CSV, the next step is to loop through the
    BlueLeaks sites, looking for *Company.csv* files, using the following code:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This code imports the <samp class="SANS_TheSansMonoCd_W5Regular_11">os</samp>
    module. After creating the CSV writer, it loops through the return value of the
    <samp class="SANS_TheSansMonoCd_W5Regular_11">os.listdir()</samp> function, which
    returns a list of all the files inside the BlueLeaks folder. It then defines a
    new <samp class="SANS_TheSansMonoCd_W5Regular_11">company_csv _path</samp> variable
    as the path to the *Company.csv* file inside that BlueLeaks folder. Finally, the
    <samp class="SANS_TheSansMonoCd_W5Regular_11">os.path.exists()</samp> function
    makes sure that this specific *Company.csv* file actually exists, and if so, the
    code displays its path.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: 'Try running the code so far:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: As you can see, the script displays paths for all of the *Company.csv* files
    in BlueLeaks. (Yours might display them in a different order than mine.)
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Add BlueLeaks Sites
    to the CSV</samp>
  id: totrans-327
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The final step is to open all the *Company.csv* files whose paths you’ve just
    listed, loop through their rows, and add new rows to your output CSV file based
    on them:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The added code opens the <samp class="SANS_TheSansMonoCd_W5Regular_11">company_csv_path</samp>,
    this time for reading instead of writing, and now calling the file object <samp
    class="SANS_TheSansMonoCd_W5Regular_11">input_f</samp>. It then creates a <samp
    class="SANS_TheSansMonoCd_W5Regular_11">csv.DictReader()</samp> object to read
    the data from this CSV and loops through its rows.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: For each row, the code creates a new dictionary called <samp class="SANS_TheSansMonoCd_W5Regular_11">output_row</samp>
    that contains the name of the BlueLeaks folder you’re currently working in, as
    well as CompanyID, CompanyName, WebsiteTitle, and URL from *Company.csv*. It then
    uses the CSV writer you created in the previous section to save that row to your
    output CSV file. When the code finishes looping through all of the rows in a *Company.csv*
    file, it displays a message to show it’s done with that folder.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the complete script at [*https://<wbr>github<wbr>.com<wbr>/micahflee<wbr>/hacks<wbr>-leaks<wbr>-and<wbr>-revelations<wbr>/blob<wbr>/main<wbr>/chapter<wbr>-9<wbr>/exercise<wbr>-9<wbr>-3<wbr>.py*](https://github.com/micahflee/hacks-leaks-and-revelations/blob/main/chapter-9/exercise-9-3.py).
    Run your final script like so:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: When you run this script, the output displays a line for each BlueLeaks folder
    showing that it has finished running. But more importantly, it creates the file
    *sites.csv*. [Figure 9-9](#fig9-9) shows what that file looks like in LibreOffice
    Calc.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of sites.csv in LibreOffice Calc. You can see the names, website
    titles, and URLs for the sites hosted in each BlueLeaks folder.](Images/Figure9-9.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-9: The CSV output
    created by the final Exercise 9-3 script</samp>'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve created the CSV, you can use your graphical spreadsheet software
    to freeze the header row at the top and sort the columns however you’d like. If
    you live in the US, try finding the fusion center that covers your region; that
    might be a good place to start digging. You can use the skills you’ve learned
    in this chapter and the Python scripts you’ve written to make the files for your
    chosen fusion center easier to work with.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Before you get too deep into your BlueLeaks investigations, though, I recommend
    reading [Chapter 10](chapter10.xhtml), where I’ll introduce you to software that
    might save you time and allow you to uncover more interesting revelations.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Summary</samp>
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, you started investigating CSV spreadsheets. You’ve learned
    how to open and examine them using spreadsheet software, as well as how to read
    and write them using Python code, sharpening your programming skills along the
    way. You’ve also learned more about the BlueLeaks dataset structure and how to
    find hidden details, such as who posted which SARs and what documents were sent
    out as part of which bulk email messages, in the spreadsheets.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: You’ve explored just a few CSVs in BlueLeaks so far, including *SARs.csv* and
    *EmailBuilder.csv* in NCRIC and *Company.csv* in all of the folders, but there’s
    still much more to investigate. In the next chapter, you’ll learn how to research
    the BlueLeaks dataset in depth using my custom-built software, BlueLeaks Explorer.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
