- en: '**19'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: FROM HYPOTHESIS TESTING TO PARAMETER ESTIMATION**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So far, we’ve used posterior odds to compare only two hypotheses. That’s fine
    for simple problems; even if we have three or four hypotheses, we can test them
    all by conducting multiple hypothesis tests, as we did in the previous chapter.
    But sometimes we want to search a really large space of possible hypotheses to
    explain our data. For example, you might want to guess how many jelly beans are
    in a jar, the height of a faraway building, or the exact number of minutes it
    will take for a flight to arrive. In all these cases, there are many, many possible
    hypotheses—too many to conduct hypothesis tests for all of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Luckily, there’s a technique for handling this scenario. In [Chapter 15](ch15.xhtml#ch15),
    we learned how to turn a parameter estimation problem into a hypothesis test.
    In this chapter, we’re going to do the opposite: by looking at a virtually continuous
    range of possible hypotheses, we can use the Bayes factor and posterior odds (a
    hypothesis test) as a form of parameter estimation! This approach allows us to
    evaluate more than just two hypotheses and provides us with a simple framework
    for estimating any parameter.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Is the Carnival Game Really Fair?**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Suppose you’re at a carnival. While walking through the games, you notice someone
    arguing with a carnival attendant near a pool of little plastic ducks. Curious,
    you get closer and hear the player yelling, “This game is rigged! You said there
    was a 1 in 2 chance of getting a prize and I’ve picked up 20 ducks and only received
    one prize! It looks to me like the chance of getting a prize is only 1 in 20!”
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have a strong understanding of probability, you decide to settle
    this argument yourself. You explain to the attendant and the angry customer that
    if you observe some more games that day, you’ll be able to use the Bayes factor
    to determine who’s right. You decide to break up the results into two hypotheses:
    *H*[1], which represents the attendant’s claim that the probability of a prize
    is 1/2, and *H*[2], the angry customer’s claim that the probability of a prize
    is just 1/20:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0184-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The attendant argues that because he didn’t watch the customer pick up ducks,
    he doesn’t think you should use his reported data, since no one else can verify
    it. This seems fair to you. You decide to watch the next 100 games and use that
    as your data instead. After the customer has picked up 100 ducks, you observe
    that 24 of them came with prizes.
  prefs: []
  type: TYPE_NORMAL
- en: Now, on to the Bayes factor! Since we don’t have a strong opinion about the
    claim from either the customer or the attendant, we won’t worry about the prior
    odds or calculating our full posterior odds yet.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get our Bayes factor, we need to compute *P*(*D* | *H*) for each hypothesis:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(*D* | *H*[1]) = (0.5)^(24) × (1 – 0.5)^(76)'
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(*D* | *H*[2]) = (0.05)^(24) × (1 – 0.05)^(76)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, individually, both of these probabilities are quite small, but all we
    care about is the ratio. We’ll look at our ratio in terms of *H*[2]/*H*[1] so
    that our result will tell us how many times better the customer’s hypothesis explains
    the data than the attendant’s:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0185-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Our Bayes factor tells us that *H*[1], the attendant’s hypothesis, explains
    the data 653 times as well as *H*[2], which means that the attendant’s hypothesis
    (that the probability of getting a prize when picking up a duck is 0.5) is the
    more likely one.
  prefs: []
  type: TYPE_NORMAL
- en: 'This should immediately seem strange. Clearly, the probability of getting only
    24 prizes out of a total of 100 ducks seems really unlikely if the true probability
    of a prize is 0.5\. We can use R’s `pbinom()` function (introduced in [Chapter
    13](ch13.xhtml#ch13)) to calculate the binomial distribution, which will tell
    us the probability of seeing 24 *or fewer* prizes, assuming that the probability
    of getting a prize is really 0.5:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the probability of getting 24 or fewer prizes if the true probability
    of a prize is 0.5 is extremely low; expanding it out to the full decimal values,
    we get a probability of 0.00000009050013! Something is definitely up with *H*[1].
    Even though we don’t believe the attendant’s hypothesis, it still explains the
    data much better than the customer’s.
  prefs: []
  type: TYPE_NORMAL
- en: 'So what’s missing? In the past, we’ve often found that the prior probability
    usually matters a lot when the Bayes factor alone doesn’t give us an answer that
    makes sense. But as we saw in [Chapter 18](ch18.xhtml#ch18), there are cases in
    which the prior isn’t the root cause of our problem. In this case, using the following
    equation seems reasonable, since we don’t have a strong opinion either way:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0185-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'But maybe the problem here is that you have a preexisting mistrust in carnival
    games. Because the result of the Bayes factor favors the attendant’s hypothesis
    so strongly, we’d need our prior odds to be at least 653 to get a posterior odds
    that favors the customer’s hypothesis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0185-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: That’s a really deep distrust of the fairness of the game! There must be some
    problem here other than the prior.
  prefs: []
  type: TYPE_NORMAL
- en: '***Considering Multiple Hypotheses***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One obvious problem is that, while it seems intuitively clear that the attendant
    is wrong in his hypothesis, the customer’s alternative hypothesis is just too
    extreme to be right, either, so we have two wrong hypotheses. What if the customer
    thought the probability of winning was 0.2, rather than 0.05? We’ll call this
    hypothesis *H*[3]. Testing *H*[3] against the attendant’s hypothesis radically
    changes the results of our likelihood ratio:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0186-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here we see that *H*[3] explains the data wildly better than *H*[1]. With a
    Bayes factor of 917,399, we can be certain that *H*[1] is far from the best hypothesis
    for explaining the data we’ve observed, because *H*[3] blows it out of the water.
    The trouble we had in our first hypothesis test was that the customer’s belief
    was a far worse description of the event than the attendant’s belief. As we can
    see, though, that doesn’t mean the attendant was right. When we came up with an
    alternative hypothesis, we saw that it was a much better guess than either the
    attendant’s or the customer’s.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we haven’t really solved our problem. What if there’s an even better
    hypothesis out there?
  prefs: []
  type: TYPE_NORMAL
- en: '***Searching for More Hypotheses with R***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We want a more general solution that searches all of our possible hypotheses
    and picks out the best one. To do this, we can use R’s `seq()` function to create
    a sequence of hypotheses we want to compare to our *H*[1].
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll consider every increment of 0.01 between 0 and 1 as a possible hypothesis.
    That means we’ll consider 0.01, 0.02, 0.03, and so on. We’ll call 0.01—the amount
    we’re increasing each hypothesis by—`dx` (a common notation from calculus representing
    the “smallest change”) and use it to define a `hypotheses` variable, which represents
    all of the possible hypotheses we want to consider. Here we use R’s `seq()` function
    to generate a range of values for each hypothesis between 0 and 1 by incrementing
    the values by our `dx`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need a function that can calculate our likelihood ratio for any two
    hypotheses. Our `bayes.factor()` function will take two arguments: `h_top`, which
    is the probability of getting a prize for the hypothesis on the top (the numerator)
    and `h_bottom`, which is the hypothesis we’re competing against (the attendant’s
    hypothesis). We set this up like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we compute the likelihood ratio for all of these possible hypotheses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we use R’s base plotting functionality to see what these likelihood ratios
    look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 19-1](ch19.xhtml#ch19fig01) shows the resulting plot.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/19fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 19-1: Plotting the Bayes factor for each of our hypotheses*'
  prefs: []
  type: TYPE_NORMAL
- en: Now we can see a clear distribution of different explanations for the data we’ve
    observed. Using R, we can look at a wide range of possible hypotheses, where each
    point in our line represents the Bayes factor for the corresponding hypothesis
    on the x-axis.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also see how high the largest Bayes factor is by using the `max()` function
    with our vector of `bfs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can check which hypothesis corresponds to the highest likelihood ratio,
    telling us which hypothesis we should believe in the most. To do this, enter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now we know that a probability of 0.24 is our best guess, since this hypothesis
    produces the highest likelihood ratio when compared with the attendant’s. In [Chapter
    10](ch10.xhtml#ch10), you learned that using the mean or expectation of our data
    is often a good way to come up with a parameter estimate. Here we’ve simply chosen
    the hypothesis that individually explains the data the best, because we don’t
    currently have a way to weigh our estimates by their probability of occurring.
  prefs: []
  type: TYPE_NORMAL
- en: '***Adding Priors to Our Likelihood Ratios***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now suppose you present your findings to the customer and the attendant. Both
    agree that your findings are pretty convincing, but then another person walks
    up to you and says, “I used to make games like these, and I can tell you that
    for some strange industry reason, the people who design these duck games never
    put the prize rate between 0.2 and 0.3\. I’d bet you the odds are 1,000 to 1 that
    the real prize rate is not in this range. Other than that, I have no clue.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have some prior odds that we’d like to use. Since the former game maker
    has given us some solid odds about his prior beliefs in the probability of getting
    a prize, we can try to multiply this by our current list of Bayes factors and
    compute the posterior odds. To do this, we create a list of prior odds ratios
    for every hypothesis we have. As the former game maker told us, the prior odds
    ratio for all probabilities between 0.2 and 0.3 should be 1/1,000\. Since the
    maker has no opinion about other hypotheses, the odds ratio for these will just
    be 1\. We can use a simple `ifelse` statement, using our vector of `hypotheses`,
    to create a vector of our odds ratios:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can once again use `plot()` to display this distribution of priors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 19-2](ch19.xhtml#ch19fig02) shows our distribution of prior odds.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Because R is a vector-based language (for more information on this, see [Appendix
    A](app01.xhtml#app01)), we can simply multiply our `priors` by our `bfs` and get
    a new vector of `posteriors` representing our Bayes factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can plot a chart of the posterior odds of each of our many hypotheses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 19-3](ch19.xhtml#ch19fig03) shows the plot.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/19fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 19-2: Visualizing our prior odds ratios*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/19fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 19-3: Plotting our distribution of Bayes factors*'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, we get a very strange distribution of possible beliefs. We have
    reasonable confidence in the values between 0.15 and 0.2 and between 0.3 and 0.35,
    but find the range between 0.2 and 0.3 to be extremely unlikely. But this distribution
    is an honest representation of the strength of belief in each hypothesis, given
    what we’ve learned about the duck game manufacturing process.
  prefs: []
  type: TYPE_NORMAL
- en: While this visualization is helpful, we really want to be able to treat this
    data like a true probability distribution. That way, we can ask questions about
    how much we believe in ranges of possible hypotheses and calculate the expectation
    of our distribution to get a single estimate for what we believe the hypothesis
    to be.
  prefs: []
  type: TYPE_NORMAL
- en: '**Building a Probability Distribution**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A true probability distribution is one where the sum of all possible beliefs
    equals 1\. Having a probability distribution would allow us to calculate the expectation
    (or mean) of our data to make a better estimate about the true rate of getting
    a prize. It would also allow us to easily sum ranges of values so we could come
    up with confidence intervals and other similar estimates.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem is that if we add up all the posterior odds for our hypotheses,
    they don’t equal 1, as shown in this calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This means we need to normalize our posterior odds so that they do sum to 1\.
    To do so, we simply divide each value in our `posteriors` vector by the sum of
    all the values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can see that our `p.posteriors` values add up to 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let’s plot our new `p.posteriors`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 19-4](ch19.xhtml#ch19fig04) shows the plot.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/19fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 19-4: Our normalized posterior odds (note the scale on the y-axis)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use our `p.posteriors` to answer some common questions we might
    have about our data. For example, we can now calculate the probability that the
    true rate of getting a prize is less than what the attendant claims. We just add
    up all the probabilities for values less than 0.5:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the probability that the prize rate is lower than the attendant’s
    hypothesis is nearly 1\. That is, we can be almost certain that the attendant
    is overstating the true prize rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also calculate the expectation of our distribution and use this result
    as our estimate for the true probability. Recall that the expectation is just
    the sum of the estimates weighted by their value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, we can see our distribution is a bit atypical, with a big gap in
    the middle, so we might want to simply choose the most *likely* estimate, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Now we’ve used the Bayes factor to come up with a range of probabilistic estimates
    for the true possible rate of winning a prize in the duck game. This means that
    we’ve used the Bayes factor as a form of parameter estimation!
  prefs: []
  type: TYPE_NORMAL
- en: '**From the Bayes Factor to Parameter Estimation**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s take a moment to look at our likelihood ratios alone again. When we weren’t
    using a prior probability for any of the hypotheses, you might have felt that
    we already had a perfectly good approach to solving this problem without needing
    the Bayes factor. We observed 24 ducks with prizes and 76 ducks without prizes.
    Couldn’t we just use our good old beta distribution to solve this problem? As
    we’ve discussed many times since [Chapter 5](ch05.xhtml#ch05), if we want to estimate
    the rate of some event, we can always use the beta distribution. [Figure 19-5](ch19.xhtml#ch19fig05)
    shows a plot of a beta distribution with an alpha of 24 and a beta of 76.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/19fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 19-5: The beta distribution with an alpha of 24 and a beta of 76*'
  prefs: []
  type: TYPE_NORMAL
- en: Except for the scale of the y-axis, the plot looks nearly identical to the original
    plot of our likelihood ratios! In fact, if we do a few simple tricks, we can get
    these two plots to line up perfectly. If we scale our beta distribution by the
    size of our `dx` and normalize our `bfs`, we can see that these two distributions
    get quite close ([Figure 19-6](ch19.xhtml#ch19fig06)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/19fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 19-6: Our initial distribution of likelihood ratios maps pretty closely
    to Beta(24,76).*'
  prefs: []
  type: TYPE_NORMAL
- en: There seems to be only a slight difference now. We can fix it by using the weakest
    prior that indicates that getting a prize and not getting a prize are equally
    likely—that is, by adding 1 to both the alpha and beta parameters, as shown in
    [Figure 19-7](ch19.xhtml#ch19fig07).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/19fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 19-7: Our likelihood ratios map perfectly to a Beta(24+1,76+1) distribution.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can see that the two distributions are perfectly aligned. [Chapter 5](ch05.xhtml#ch05)
    mentioned that the beta distribution was difficult to derive from our basic rules
    of probability. However, by using the Bayes factor, we’ve been able to empirically
    re-create a modified version of it that assumes a prior of Beta(1,1). And we did
    it without any fancy mathematics! All we had to do was:'
  prefs: []
  type: TYPE_NORMAL
- en: Define the probability of the evidence given a hypothesis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Consider all possible hypotheses.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Normalize these values to create a probability distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Every time we’ve used the beta distribution in this book, we’ve used a beta-distributed
    prior. This made the math easier, since we can arrive at the posterior by combining
    the alpha and beta parameters from the likelihood and prior beta distributions.
    In other words:'
  prefs: []
  type: TYPE_NORMAL
- en: Beta(α[posterior], β[posterior]) = Beta(α[prior] + α[likelihood], β[prior] +
    β[likelihood])
  prefs: []
  type: TYPE_NORMAL
- en: However, by building our distribution from the Bayes factor, we were able to
    easily use a unique prior distribution. Not only is the Bayes factor a great tool
    for setting up hypothesis tests, but, as it turns out, it’s also all we need to
    create any probability distribution we might want to use to solve our problem,
    whether that’s hypothesis testing or parameter estimation. We just need to be
    able to define the basic comparison between two hypotheses, and we’re on our way.
  prefs: []
  type: TYPE_NORMAL
- en: When we built our A/B test in [Chapter 15](ch15.xhtml#ch15), we figured out
    how to reduce many hypothesis tests to a parameter estimation problem. Now you’ve
    seen how the most common form of hypothesis testing can also be used to perform
    parameter estimation. Given these two related insights, there is virtually no
    limit to the type of probability problems we can solve using only the most basic
    rules of probability.
  prefs: []
  type: TYPE_NORMAL
- en: '**Wrapping Up**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you’ve finished your journey into Bayesian statistics, you can appreciate
    the true beauty of what you’ve been learning. From the basic rules of probability,
    we can derive Bayes’ theorem, which lets us convert evidence into a statement
    expressing the strength of our beliefs. From Bayes’ theorem, we can derive the
    Bayes factor, a tool for comparing how well two hypotheses explain the data we’ve
    observed. By iterating through possible hypotheses and normalizing the results,
    we can use the Bayes factor to create a parameter estimate for an unknown value.
    This, in turn, allows us to perform countless other hypothesis tests by comparing
    our estimates. And all we need to do to unlock all this power is use the basic
    rules of probability to define our likelihood, *P*(*D* | *H*)!
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Try answering the following questions to see how well you understand using the
    Bayes factor and posterior odds to do parameter estimation. The solutions can
    be found at *[https://nostarch.com/learnbayes/](https://nostarch.com/learnbayes/)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our Bayes factor assumed that we were looking at *H*[1]: *P*(prize) = 0.5\.
    This allowed us to derive a version of the beta distribution with an alpha of
    1 and a beta of 1\. Would it matter if we chose a different probability for *H*[1]?
    Assume *H*[1]: *P*(prize) = 0.24, then see if the resulting distribution, once
    normalized to sum to 1, is any different than the original hypothesis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a prior for the distribution in which each hypothesis is 1.05 times more
    likely than the previous hypothesis (assume our `dx` remains the same).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Suppose you observed another duck game that included 34 ducks with prizes and
    66 ducks without prizes. How would you set up a test to answer “What is the probability
    that you have a better chance of winning a prize in this game than in the game
    we used in our example?” Implementing this requires a bit more sophistication
    than the R used in this book, but see if you can learn this on your own to kick
    off your adventures in more advanced Bayesian statistics!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
