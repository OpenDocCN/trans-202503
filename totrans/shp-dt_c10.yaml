- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Multicore and Quantum Computing
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 多核与量子计算
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: In the previous chapters, we overviewed many tools that come from the fields
    of geometry and topology. We saw how these algorithms can impact network analytics,
    natural language processing, supervised learning, time-series analytics, visualization,
    and unsupervised learning. Many more algorithms rooted in topology exist, including
    hybrid algorithms that improve existing models such as convolutional or recurrent
    neural networks, and the field has the potential to contribute thousands more
    to the field of machine learning.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们概述了许多来自几何和拓扑学领域的工具。我们看到了这些算法如何影响网络分析、自然语言处理、监督学习、时间序列分析、可视化以及无监督学习。还有许多更多根植于拓扑学的算法，包括改进现有模型（如卷积神经网络或递归神经网络）的混合算法，这一领域有潜力为机器学习领域贡献成千上万的算法。
- en: However, one of the major issues facing the development and application of topological
    and geometric machine learning algorithms is computational cost. While most will
    not, calculating certain network metrics can scale to network sizes of one million
    or one billion (or more!). Other classes of algorithms, such as persistent homology
    or manifold learning, won’t scale well; some will reach issues on a standard laptop
    at around 20,000 rows of data. Calculating a distance matrix for a large set of
    data will also require a lot of time and computing resources.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，拓扑学和几何学机器学习算法开发和应用中的一个主要问题是计算成本。虽然大多数情况下不会出现问题，但计算某些网络度量可以扩展到一百万或十亿（甚至更多！）的网络规模。其他类算法，如持久同调或流形学习，则扩展性较差；有些算法在标准笔记本电脑上大约20,000行数据时就会遇到问题。对于大规模数据集，计算距离矩阵也需要大量的时间和计算资源。
- en: Yet there are a couple of potential options for practitioners who hope to scale
    these methods. In this chapter, we’ll review multicore approaches and quantum
    computing solutions. Solutions like the ones presented in this chapter are in
    their infancy, and as the algorithms in this book are adopted as big data algorithms,
    it’s likely standard packages will be developed for quantum topological data analysis
    (TDA) algorithms and distributed TDA algorithms.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于希望扩展这些方法的实践者来说，有几个潜在的选择。在本章中，我们将回顾多核方法和量子计算解决方案。本章中提出的解决方案仍处于初期阶段，随着本书中的算法被采纳为大数据算法，可能会开发出标准的软件包用于量子拓扑数据分析（TDA）算法和分布式TDA算法。
- en: Multicore Approaches to Topological Data Analysis
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多核方法在拓扑数据分析中的应用
- en: One approach to algorithm scaling is to map pieces of the data to different
    computer cores or systems, compute the desired quantities on each core’s worth
    of data at the same time, and reassemble each core’s data quantity computations
    into a single dataset. For instance, suppose we want to calculate betweenness
    centrality for each vertex in a million-vertex network. Even if this is a sparse
    network without many edges, each betweenness centrality calculation will take
    a long time to compute. However, if we have access to a million cores, we can
    map the network to each core and compute betweenness centrality for one vertex
    in the network with each core. While the compute time may still be long, the total
    time needed to compute betweenness centrality for all one million vertices will
    be much less than what it would take computing each betweenness centrality one
    after another in a loop (as we did in prior chapters for much smaller networks).
    While a million cores isn’t possible for most organizations, the time savings
    from 10 cores or 30 cores can be a substantial speedup.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一种算法扩展方法是将数据的不同部分映射到不同的计算核心或系统，在每个核心的数据上同时计算所需的量，并将每个核心的数据量计算结果重新组合成一个单一的数据集。例如，假设我们想计算一个百万顶点网络中每个顶点的介数中心性。即使这是一个稀疏网络，边缘不多，每次计算介数中心性仍然需要很长时间。然而，如果我们有百万个核心，我们可以将网络映射到每个核心，并用每个核心计算网络中一个顶点的介数中心性。虽然计算时间可能依然很长，但计算所有一百万个顶点的介数中心性所需的总时间会远少于依次计算每个介数中心性（如我们在前几章对较小网络所做的那样）。虽然对于大多数组织来说，百万个核心是不可能的，但10个核心或30个核心所带来的时间节省可以显著加速计算。
- en: It’s also possible to map only part of a dataset to each core to compute some
    sort of metric. For instance, say we have a dataset of 300,000 individuals who
    completed an online customer survey. Calculating the distance between all 300,000
    individuals’ responses would take a lot of computing resources. However, distance
    matrices are necessary in many manifold learning and topological data analysis
    algorithms; it’d be good to have a quicker way to calculate this. We can map different
    pieces of the data to different cores to compute smaller distances matrices that
    can be assembled into the full 300,000-by-300,000-distance matrix after the cores
    have computed each piece. Again, we’ll see large time savings.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以将数据集的部分内容映射到每个核心，来计算某种度量。例如，假设我们有一个包含30万人完成的在线客户调查的数据集。计算这30万人回答之间的距离会消耗大量计算资源。然而，距离矩阵在许多流形学习和拓扑数据分析算法中是必要的；因此，找到一种更快的方法来计算这些矩阵是很有意义的。我们可以将数据的不同部分映射到不同的核心，来计算更小的距离矩阵，这些矩阵在每个核心计算完之后可以组合成完整的30万乘30万的距离矩阵。同样，我们将看到显著的时间节省。
- en: In general, these multicore approaches fall under the umbrella of *distributed
    computing*, where multiple cores are leveraged to compute pieces of a problem
    to assemble when all cores have their solutions computed. Most cloud computing
    resources will have support for distributed computing, and some R and Python packages
    that can be run on the cloud support distributed computing options. However, it’s
    usually up to the machine learning or data engineer to define distributed computing
    steps into the algorithm being used. [Figure 10-1](#figure10-1) shows a simple
    example of how data might be parsed and sent to different cores.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，这些多核方法属于*分布式计算*的范畴，在这种方式下，多个核心被用来计算问题的各个部分，当所有核心计算出它们的解决方案时，这些部分会被组合起来。大多数云计算资源都支持分布式计算，一些可以在云上运行的R和Python包也支持分布式计算选项。然而，通常是由机器学习或数据工程师来定义算法中的分布式计算步骤。[图10-1](#figure10-1)展示了数据如何被解析并发送到不同核心的一个简单示例。
- en: '![](image_fi/503083c10/f010001.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/503083c10/f010001.png)'
- en: 'Figure 10-1: A mapping of three sections of data to three cores that will perform
    a mathematical or algorithmic step in the machine learning pipeline'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图10-1：数据的三个部分映射到三个核心，这些核心将在机器学习流程中执行数学或算法步骤
- en: In [Figure 10-1](#figure10-1), we parse our dataset into three pieces to map
    to three cores that will compute the quantities we desire. In a simple big data
    case, this might involve computing the minimum and maximum values found in each
    column of the dataset. We’d then compute the minimum and maximum values across
    cores, save that value, and spit out the minimum and maximum values for each column
    from the full set of data. It may not help much if we have a dataset of only a
    few million rows, but it will speed up the computational process a lot if we’re
    dealing with trillions of rows of data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图10-1](#figure10-1)中，我们将数据集划分为三部分，分别映射到三个核心，以计算我们需要的量。在一个简单的大数据案例中，这可能涉及到计算数据集每一列中的最小值和最大值。然后，我们会计算跨核心的最小值和最大值，保存该值，并输出完整数据集中每一列的最小值和最大值。如果数据集只有几百万行，这可能帮助不大，但如果我们处理的是万亿行数据，这将大大加速计算过程。
- en: Multicore approaches work well for network algorithms, such as those encountered
    in Chapters [2](c02.xhtml) through [4](c04.xhtml), and they have had some success
    with persistent homology and discrete exterior calculus. As long as the problem
    is local in nature or can be broken into smaller pieces for some steps, multicore
    approaches are viable. For instance, in robotics path-planning homotopy algorithms,
    we can break up the potential routes around obstacles and calculate some optimality
    for each route.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 多核方法在网络算法中效果很好，例如在第[2章](c02.xhtml)到第[4章](c04.xhtml)中遇到的那些算法，它们在持久同调和离散外微积分方面也取得了一些成功。只要问题是局部性质的，或者可以在某些步骤中将问题分解为更小的部分，多核方法都是可行的。例如，在机器人路径规划的同伦算法中，我们可以将绕过障碍物的潜在路径分开，并计算每条路径的某些最优值。
- en: Unfortunately, few multicore versions of the algorithms in this book currently
    exist in R or Python. However, it is an area being actively explored in research,
    and if you’re familiar with multicore frameworks on big data platforms, you are
    encouraged to play around with ways to apply this approach to persistent homology,
    manifold learning, or other geometry-based algorithms.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，目前在R或Python中很少存在此书中算法的多核版本。然而，这是一个正在积极探索的领域，如果你熟悉大数据平台上的多核框架，鼓励你尝试将这种方法应用于持久同调、流形学习或其他基于几何的算法。
- en: Quantum Computing Approaches
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量子计算方法
- en: Another approach to scaling geometry-based algorithms is to implement them on
    a different type of computer that can leverage distributed computing natively.
    *Quantum computing* is a recent buzzword, and a lot of mystery and myths still
    surround the field, even within data science and software engineering. Progress
    has been faster than expected, but the technology is still in its early stages,
    with current systems having stark limitations and companies pouring money into
    hardware research and development. However, some question network algorithms already
    exist, and network science is one of the areas of machine learning that could
    benefit the most from quantum computing. In this section, we’ll go through some
    basics of quantum computing and list some of the quantum algorithms related to
    graph theory and network science that exist as of 2023.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展基于几何的算法的另一种方法是将它们实现到一种可以本地利用分布式计算的不同类型的计算机上。*量子计算*是一个最近的流行词，尽管即使在数据科学和软件工程领域，围绕这一领域仍然充满神秘和误解。尽管进展比预期的要快，但该技术仍处于早期阶段，当前系统存在显著的限制，许多公司正投入资金进行硬件研究和开发。然而，一些网络算法已经存在，网络科学是机器学习中最有可能从量子计算中受益的领域之一。在本节中，我们将介绍一些量子计算的基础知识，并列出截至2023年与图论和网络科学相关的一些量子算法。
- en: To start, quantum computing hardware can take on several different forms, each
    of which has its advantages and disadvantages. The type of circuit in the computer
    dictates what sort of algorithms can be developed on the machine, and some types
    of circuits are more amenable to network analytics. Two types of hardware seem
    to be the focus of most research and development these days, and they’ll be the
    focus of this discussion.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，量子计算硬件可以采用几种不同的形式，每种形式都有其优缺点。计算机中的电路类型决定了可以在机器上开发何种算法，而某些类型的电路更适合进行网络分析。目前，两个硬件类型似乎是大多数研究和开发的重点，它们也将是本讨论的重点。
- en: The current systems have many limitations, including the need to cool the circuits,
    effects due to quantum scales (tunneling through energy barriers, fields created
    by interacting particles, and so on), and random error inherent in the qubits.
    Nevertheless, researchers have been able to explore potential new algorithms and
    quantum versions of existing algorithms through the quantum computers that exist
    and the simulation packages in Python. Graph theory and network algorithms, in
    particular, seem well suited to quantum computing, and the ability to search through
    combinatorics solutions simultaneously with qubits suggests that network science
    will get a boost when quantum computing scales to larger circuits.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的系统有许多限制，包括需要冷却电路、由于量子尺度的效应（穿越能量障碍、相互作用粒子产生的场等），以及量子比特固有的随机误差。尽管如此，研究人员已经能够通过现有的量子计算机和Python中的模拟包，探索潜在的新算法和现有算法的量子版本。特别是图论和网络算法似乎非常适合量子计算，而同时通过量子比特搜索组合学解法的能力表明，当量子计算扩展到更大电路时，网络科学将迎来一次飞跃。
- en: Using the Qubit-Based Model
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用基于量子比特的模型
- en: 'We’ll start with the version of quantum hardware that is most like classical
    computers: the *qubit-based model*, which replaces classical bits with a quantum
    version of the bit, *qubits*, the quantum version of the 0 and 1 bits that underlie
    classical circuits. Rather than taking values of only 0 or 1 at a given time,
    qubits can exist simultaneously in the 1 and 0 state until the qubit is observed
    (where it will collapse to a 0 or a 1 state), and they can also rotate through
    computer gates to take fractional values. This means qubits can exist in many
    different states and be evolved through quantum gates into a final, optimized
    state. This makes them very flexible. [Figure 10-2](#figure10-2) shows the difference
    between bits and qubits.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从最类似经典计算机的量子硬件版本开始：*基于量子比特的模型*，它用量子版本的比特——*量子比特*——替代经典比特，量子比特是经典电路中 0 和 1
    比特的量子版本。量子比特与经典比特不同，它们在某一时刻不仅能取 0 或 1 的值，而是可以同时处于 1 和 0 状态，直到量子比特被观察（此时它会塌缩为 0
    或 1 状态）。此外，量子比特还可以通过计算门进行旋转，从而取到分数值。这意味着量子比特可以存在于多种不同的状态，并且可以通过量子门演化成最终的优化状态。这样，它们非常灵活。[图
    10-2](#figure10-2) 显示了比特和量子比特之间的差异。
- en: '![](image_fi/503083c10/f010002r.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/503083c10/f010002r.png)'
- en: 'Figure 10-2: A plot comparing classical bits with qubits'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10-2：比较经典比特与量子比特的图表
- en: Let’s quickly go through the two main types of hardware that use qubits. Don’t
    worry if you don’t understand every term here; just keep the high-level ideas
    in mind. Two types of chipsets use qubits. Both rely on quantum principles of
    qubits (such as superposition) to speed up computation and improve accuracy. The
    first is a *gate-based circuit*that’s similar to classical hardware, in which
    gate operations act on qubit states (such as the rotation gate). Gate-based circuits
    are the most common, and some examples include IBM’s machines and Rigetti’s machines;
    in general, gate-based algorithms speed up algorithms and provide easy benchmarking
    of algorithms. The other option, currently used by D-Wave on its machines, relies
    on quantum annealing (physical heating and cooling processes) through the changing
    of magnetic fields to act on qubit states rather than manipulating qubits through
    gates. In general, there aren’t as many performance and accuracy guarantees or
    bounds on this type of system as a gate-based quantum hardware.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速浏览一下两种主要使用量子比特的硬件类型。如果你不理解这里的每个术语也不用担心，只要记住整体思路即可。两种芯片组使用量子比特。它们都依赖量子比特的量子原理（如叠加）来加速计算和提高精度。第一种是*基于门电路*，它类似于经典硬件，其中门操作作用于量子比特的状态（例如旋转门）。基于门的电路是最常见的，IBM
    和 Rigetti 的机器就是例子；通常，基于门的算法能加速算法并提供便于基准测试的算法。另一种选择是目前 D-Wave 机器上使用的量子退火（通过磁场变化作用于量子比特状态，而不是通过门操作量子比特）。这种方法依赖物理加热和冷却过程。通常，与基于门的量子硬件相比，这种系统的性能和精度保证较少。
- en: Using the Qumodes-Based Model
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用基于 Qumodes 的模型
- en: Besides the qubit model, the other dominant model is the *qumodes*-based circuit
    model, which is a photon-based circuit being developed by Xanadu, a Canadian company.
    Currently, software and algorithms based on photonic computing—which uses photons
    in place of qubits—are only simulations of the machine, but this type of simulation
    allows for the development of some interesting applications. This type of circuit
    employs wave functions, which are continuous distributions, in place of qubits
    (which collapse to a 1 or 0 when measured). Wave functions can then be squeezed,
    mapped, or operated on by other types of geometric transformations of the function
    without collapsing to a 1 or 0\. This computer doesn’t exist yet, but simulation
    programs do exist in Python (as of 2023), similar to simulation programs available
    for qubit circuits.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 除了量子比特模型，另一个主流模型是*基于量子模式的*电路模型，它是由加拿大公司 Xanadu 开发的基于光子的电路。当前，基于光子计算的软件和算法——它用光子代替量子比特——仅是机器的模拟，但这种模拟使得一些有趣的应用得以开发。这种电路使用波函数作为替代量子比特（量子比特在被测量时会塌缩为
    1 或 0），波函数是连续分布的。波函数可以被压缩、映射，或通过其他几何变换进行操作，而不会塌缩成 1 或 0。这个计算机尚不存在，但已有相似的 Python
    模拟程序（截至 2023 年），与量子比特电路的模拟程序类似。
- en: Using Quantum Network Algorithms
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用量子网络算法
- en: Several quantum network science algorithms exist that relate to properties of
    graphs. Clique-finding algorithms are particularly useful in network science,
    and quantum clique-finding algorithms already exist. Maximal clique algorithms
    seem to enjoy a speedup on the very small problems they’ve been tested on.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 存在几种与图的性质相关的量子网络科学算法。团体查找算法在网络科学中尤为有用，量子团体查找算法已经存在。最大团算法似乎在它们被测试的非常小的 problém
    中享受加速。
- en: One important caveat of quantum algorithms is their probabilistic nature. Rather
    than getting, say, a list of cliques in the output, a quantum algorithm will run
    multiple times, creating arrays of clique lists, which can be combined into probabilistic
    scores of clique existence in the network. This can be helpful in prioritizing
    cliques for further parts of a project or zeroing in on the cliques of most interest
    within a very large network, though the latter will require much larger circuits
    than exist today.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 量子算法的一个重要警告是它们的概率性质。与其说得到一个输出中的团体列表，不如说量子算法会多次运行，创建团体列表的数组，这些数组可以合并为网络中团体存在的概率分数。这对于优先考虑项目的后续部分中的团体，或在一个非常大的网络中聚焦于最感兴趣的团体是有帮助的，尽管后者将需要比现有技术更大的电路。
- en: Quantum maximum flow and minimum cut algorithms also exist; these algorithms
    aim to partition the graph into communities with the fewest possible cuts that
    maximize information flow on the graph. Applications thus far have explored importance-scoring
    uses to rank edges and vertices by importance to the graph structure and communication
    potential. They show some promise for sparse graphs and provide a probabilistic
    framework for deriving importance scores.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 量子最大流和最小割算法也存在；这些算法旨在将图划分为具有尽可能少割的社区，从而最大化图上的信息流。到目前为止，应用主要探索了重要性评分的用途，以根据对图结构和通信潜力的影响对边和顶点进行排名。它们在稀疏图中显示出一些潜力，并为推导重要性评分提供了一个概率框架。
- en: A basic quantum maximum flow and minimum cut algorithm using the R package QuantumOps
    does exist, though the capability is limited to small, sparse graphs. Using a
    qubits approach, the problem is first translated to a *quantum approximation optimization
    algorithm*, or *QAOA*. A QAOA formulation is a combinatorial algorithm that relies
    on the superposition of qubit states and something called *unitary operators*
    to solve optimization problems. Unitary operators are a type of linear algebra
    operator with special properties that match well to the underlying quantum mechanics
    of qubit circuits. Because of the probabilistic nature of solutions, it’s best
    to run the algorithm multiple times for more exact answers. In this case, let’s
    run the algorithm 10 times (an arbitrary number large enough to generate usable
    results with a probabilistic solution) and explore this function in a bit more
    depth by using the script in [Listing 10-1](#listing10-1), which reloads Graph
    1 from [Listing 4-1](c04.xhtml#listing4-1).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 确实存在使用 R 包 QuantumOps 的基本量子最大流和最小割算法，但该能力仅限于小型稀疏图。采用量子比特方法时，问题首先被转换为*量子近似优化算法*，或
    *QAOA*。QAOA 公式是一种组合算法，依赖于量子比特状态的叠加和称为*单位算符*的东西来解决优化问题。单位算符是一种具有特殊属性的线性代数算符，能够很好地与量子比特电路的底层量子力学相匹配。由于解的概率性质，最好多次运行该算法以获得更精确的答案。在这种情况下，我们将运行算法
    10 次（这是一个足够大的任意数字，可以生成具有概率解的可用结果），并通过使用[列表 10-1](#listing10-1)中的脚本，进一步探索该功能，脚本会重新加载来自[列表
    4-1](c04.xhtml#listing4-1)的图 1。
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Listing 10-1: Running the maxcut algorithm on Graph 1, first seen in [Chapter
    4](c04.xhtml), 10 times'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10-1：在[第4章](c04.xhtml)首次看到的图 1 上运行 maxcut 算法 10 次
- en: Note that the output from this algorithm contains 2⁷ items, with our original
    graph containing six vertices. In general, this version of quantum maximum cut
    algorithms will include 2^(^(*n*)^(+1)) items in the output, with problems scaling
    to larger graphs. The output is also in raw format with this algorithm, leaving
    the user to translate the output to the most likely cuts made. A couple of existing
    Python packages give a more usable output, but this package provides a way for
    you to explore some qubit-based computing simulations within R.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个算法的输出包含 2⁷ 个项目，而我们的原始图包含六个顶点。通常，这种版本的量子最大割算法会在输出中包含 2^(^(+n)^(+1)) 个项目，并且问题会扩展到更大的图。该算法的输出也是原始格式的，用户需要将输出转换为最可能的割。几个现有的
    Python 包提供了更可用的输出，但此包为您提供了一种在 R 中探索一些基于量子比特的计算模拟的方式。
- en: In addition to maximum flow and minimum cut algorithms, there are quantum versions
    of random walk algorithms, and it would be possible to build a community-finding
    algorithm or PageRank-type algorithm from them. In fact, some quantum PageRank
    algorithms have been proposed in the past few years and studied theoretically.
    However, this type of application has not been explored much in practice thus
    far. It does provide an avenue for further research and potential applications
    to network science in the future.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 除了最大流和最小割算法之外，还有量子版本的随机游走算法，并且有可能基于这些算法构建社区发现算法或类似PageRank的算法。事实上，过去几年已经提出并在理论上研究了一些量子PageRank算法。然而，这类应用在实践中尚未得到广泛探索。但它为未来网络科学的进一步研究和潜在应用提供了一个途径。
- en: Other examples that are more tied to graph theory than network science include
    graph-coloring algorithms and algorithms focused on testing graph properties (such
    as isomorphism and connectivity). Quantum querying on graphs and quantum versions
    of Dijkstra’s algorithm or other shortest path algorithms are in their infancy,
    but they show promise in the future of quantum graph theory algorithms and quantum
    network science algorithms.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与网络科学关系较少但更贴近图论的其他示例包括图着色算法和专注于测试图属性（如同构性和连通性）的算法。量子图查询和量子版本的Dijkstra算法或其他最短路径算法仍处于初级阶段，但它们在量子图论算法和量子网络科学算法的未来中展现出潜力。
- en: Though quantum computing is a nascent technology, graph theory and network science
    have already seen the potential gains from quantum algorithms, and it is likely
    more algorithms will be developed in the future. The extant algorithms generally
    run in Python for now, but it’s likely that new interfaces to quantum computers
    will exist in the future, as more companies develop quantum computers and provide
    access to researchers.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管量子计算是一项新兴技术，但图论和网络科学已经看到了量子算法的潜在收益，未来可能会开发出更多的算法。目前，现有的算法通常是在Python中运行，但随着越来越多的公司开发量子计算机并为研究人员提供访问接口，未来很可能会出现新的量子计算机接口。
- en: Speeding Up Algorithms with Quantum Computing
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用量子计算加速算法
- en: Most algorithms do not have quantum computing or simulated quantum computing
    packages available yet. However, it’s possible to leverage basic mathematical
    tools that do exist in quantum computing and simulated quantum computing packages
    to assemble algorithms such as the ones in this book step-by-step. The R package
    QuantumOps has some of these tools available for us to explore, so let’s dive
    into an example of basic mathematics computations on a quantum system. Please
    note, this package only simulates algorithms that would be run on a quantum computer,
    so the speedups on your classical laptop won’t be what you’d see on a real quantum
    computer. However, the following example will show one way that quantum algorithms
    are being developed to run on quantum computers to speed up computation for problems
    that require a lot of computational power as the complexity grows.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数算法目前还没有可用的量子计算或模拟量子计算软件包。然而，可以利用量子计算和模拟量子计算软件包中已有的基本数学工具，逐步构建本书中提到的算法。R软件包QuantumOps提供了一些这样的工具供我们探索，因此，让我们深入了解量子系统中基本数学计算的一个示例。请注意，此软件包仅模拟将在量子计算机上运行的算法，因此，在你的经典笔记本上看到的加速效果并不等同于在真实量子计算机上运行时的效果。然而，下面的示例将展示量子算法是如何被开发以在量子计算机上运行，从而在问题复杂度增加时加速计算，解决需要大量计算力的问题。
- en: There are many algorithms that find the greatest common denominator between
    two numbers, and it’s possible to do this within a quantum computing framework.
    The *greatest common denominator* refers to the largest number that will divide
    both numbers of interest; for instance, the largest number that divides both 12
    and 20 is 4\. We can factor 12 into its divisors (1, 2, 3, 4, 6, 12) and factor
    20 into its divisors (1, 2, 4, 5, 10, 20). We can then see that 4 is the largest
    number to occur in both sets of divisors. This is a simple problem for us to do
    by hand when the numbers are small; however, in many encryption applications,
    the numbers to factor or determine to be prime can involve 12 or more digits.
    Factoring these requires a computer.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多算法可以找到两个数字之间的最大公约数，并且可以在量子计算框架内实现这一点。*最大公约数*是指能够同时整除这两个数字的最大数字；例如，能够同时整除12和20的最大数字是4。我们可以将12分解为它的因数（1、2、3、4、6、12），将20分解为它的因数（1、2、4、5、10、20）。然后我们可以看到，4是两个因数集中的最大共同元素。当数字较小时，这对我们来说是一个简单的手工计算问题；然而，在许多加密应用中，待因式分解或判定为质数的数字可能涉及12位或更多的数字。因式分解这些数字需要计算机的帮助。
- en: The `gcd()` function in QuantumOps finds the greatest common denominator between
    two numbers the way they would be found on a quantum computer. Let’s try our example
    with 12 and 20 as our input numbers and see how this works with the `gcd()` function;
    see [Listing 10-2](#listing10-2).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`gcd()`函数在QuantumOps中找到两个数字之间的最大公约数，就像它们在量子计算机上被计算的方式一样。让我们用12和20作为输入数字，尝试一下这个例子，并看看`gcd()`函数是如何工作的；请参见[列表
    10-2](#listing10-2)。'
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Listing 10-2: Finding the greatest common denominator of 12 and 20'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10-2：找到12和20的最大公约数
- en: 'You should see an output of `4` from [Listing 10-2](#listing10-2)’s code, which
    corresponds to the greatest common denominator of 12 and 20 that we found by hand.
    This function can compute common denominators of much larger numbers that would
    be impractical to compute by hand. Let’s plug in two new, larger numbers (say,
    14,267 and 11,345) and find their greatest common denominator with this function
    by modifying the `gcd()` function in [Listing 10-2](#listing10-2) to take these
    parameters:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该从[列表 10-2](#listing10-2)的代码输出中看到`4`，这对应于我们手工找到的12和20的最大公约数。这个函数可以计算远大于手工计算范围的公共约数。让我们输入两个新的更大的数字（比如，14,267和11,345），通过修改[列表
    10-2](#listing10-2)中的`gcd()`函数来找到它们的最大公约数：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: According to our output, the greatest common denominator between these two numbers
    is 1\. Neither of these numbers is a prime, but they do not share any divisors.
    This algorithm runs quickly for numbers this large, and if you are interested
    in cybersecurity applications of factoring algorithms, you are encouraged to try
    numbers on the scale that you are using in your applications to further explore
    this function and its capabilities. On quantum systems, it’s possible to run this
    algorithm for much larger numbers in a reasonable compute time. This means that
    security algorithms based on factoring will not perform well once quantum computing
    becomes more accessible outside of research settings.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的输出，这两个数字之间的最大公约数是1。虽然这两个数字都不是质数，但它们没有共同的因数。对于这样大的数字，这个算法运行得很快，如果你对因式分解算法在网络安全中的应用感兴趣，建议你尝试在你应用中使用的规模上的数字，以进一步探索这个函数及其能力。在量子系统上，运行这个算法以处理更大的数字在合理的计算时间内是可能的。这意味着，一旦量子计算超越研究领域变得更加普及，基于因式分解的安全算法将无法有效运行。
- en: The QuantumOps package does not include some of the more advanced mathematical
    tools upon which algorithms are built, but it’s possible to define dot products,
    norms, and other linear algebra tools important to distance metric design, as
    well as define other linear algebra tools underlying common machine learning tasks.
    On a real quantum computer, we’d be able to run algorithms much more quickly and
    for much larger problems than the ones we’ve considered. However, the QuantumOps
    package allows us to explore some of what does exist in the quantum algorithm
    research that is done on quantum computers.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: QuantumOps包并不包含一些更高级的数学工具，而这些工具是算法构建的基础，但它可以定义点积、范数以及其他对距离度量设计至关重要的线性代数工具，还可以定义机器学习任务中常见的其他线性代数工具。在真实的量子计算机上，我们能够更快速地运行算法，并处理比我们目前考虑的问题要大的许多倍。然而，QuantumOps包使我们能够探索一些量子计算机上进行的量子算法研究中存在的内容。
- en: Using Image Classifiers on Quantum Computers
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在量子计算机上使用图像分类器
- en: One of the hot topics in machine learning today is *image classification*, in
    which machine learning is used to classify input images according to the category
    labels it is given. Typically, you’ll have a set of images with category labels
    associated to them that can be used to train a machine learning algorithm to identify
    characteristics (such as color, lines, circles, or more complicated patterns)
    that signal an image belongs to a certain class. For instance, consider the problem
    of labeling certain types of plants or animals based on pictures that may or may
    not contain one or more of the categories we’re hoping to automatically tag. Consider
    [Figure 10-3](#figure10-3), which depicts the flowering part of a cannonball tree.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当前机器学习中的热门话题之一是*图像分类*，即利用机器学习根据给定的类别标签对输入图像进行分类。通常，你会拥有一组带有类别标签的图像，可以用来训练机器学习算法，识别出表明图像属于某个类别的特征（如颜色、线条、圆形或更复杂的模式）。例如，考虑标记某些植物或动物种类的问题，基于图片，这些图片可能包含或不包含我们希望自动标记的一个或多个类别。请看[图
    10-3](#figure10-3)，它展示了一棵炮弹树的开花部分。
- en: '![](image_fi/503083c10/f010003.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/503083c10/f010003.png)'
- en: 'Figure 10-3: A picture of a blooming cannonball tree at Fairchild Tropical
    Gardens (native to Central and South America)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10-3：一张费尔柴尔德热带花园中盛开的炮弹树的图片（原产于中美洲和南美洲）
- en: Now look at [Figure 10-4](#figure10-4), which depicts an elephant.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在请看[图 10-4](#figure10-4)，它展示了一只大象。
- en: '![](image_fi/503083c10/f010004.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/503083c10/f010004.png)'
- en: 'Figure 10-4: A picture of an elephant walking down a road in Kruger National
    Park, South Africa'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10-4：一张大象在南非克鲁格国家公园的路上行走的图片
- en: There are many challenges to classifying images such as these. In [Figure 10-3](#figure10-3),
    for instance, we don’t see the entire tree in the image (making it difficult to
    recognize as a tree rather than a bush or vine), and the tree is in bloom (meaning
    that other pictures of a cannonball tree may not have flowers in them). In [Figure
    10-4](#figure10-4), the elephant is walking away from the camera (meaning there
    is no animal face), the image has a lens filter applied (changing the natural
    color), and the image contains other types of things (plants, a road, and so on).
    Most real-world sets of images don’t contain full images of only the category
    of interest that are plainly visible in the same color scheme (think of all the
    images of a cat that come up when you try searching Google Images for a cat).
    A good classifier needs to generalize to a lot of different types of cats in different
    lighting with other things included in the image.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对这些图像进行分类有很多挑战。例如在[图 10-3](#figure10-3)中，我们看不到整棵树（这使得它难以被识别为树，而不是灌木或藤蔓），而且树正在开花（这意味着其他炮弹树的照片可能没有花）。在[图
    10-4](#figure10-4)中，大象正朝着远离摄像头的方向走（这意味着没有动物面部），图像应用了镜头滤镜（改变了自然颜色），而且图像中包含了其他类型的事物（如植物、道路等）。大多数现实世界中的图像集并不会包含只有目标类别的完整图像，且颜色方案一致（想想你在谷歌图片搜索“猫”时出现的所有猫的图片）。一个好的分类器需要能够对不同光照下、图像中包含其他物体的不同类型的猫进行泛化。
- en: We might also be facing category imbalance among the set of images we’re using
    to train the algorithm. We might have a lot of pictures of orchids, tulips, jaguars,
    and kangaroos, but we may have relatively few pictures of black bat flowers, Gaboon
    vipers, or African dwarf sawsharks. For instance, we may have an entirely new
    plant that isn’t found in nature or a rare plant or flower for which many images
    don’t exist, such as the hybrid shown in [Figure 10-5](#figure10-5).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能还会面临用于训练算法的图像集中的类别不平衡问题。我们可能有大量的兰花、郁金香、美洲豹和袋鼠的照片，但我们可能只有相对较少的黑色蝙蝠花、加蓬眼镜蛇或非洲矮锯鲨的照片。例如，我们可能会遇到一种全新的植物，这种植物在自然界中不存在，或者是罕见的植物或花卉，许多图片并不存在，例如[图
    10-5](#figure10-5)中展示的杂交品种。
- en: '![](image_fi/503083c10/f010005.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/503083c10/f010005.png)'
- en: 'Figure 10-5: A picture of a genetically engineered new species of plant at
    Fairchild Tropical Gardens'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10-5：一张在费尔柴尔德热带花园拍摄的基因工程新植物物种的图片
- en: Typically, image classification algorithms involve pretrained or custom-built
    convolutional neural networks, which were discussed in [Chapter 1](c01.xhtml).
    To quickly review, convolutional neural networks (CNNs), a type of deep learning
    algorithm, find relevant features by optimizing maps from the input image layer
    to a series of different types of layers to the output layer containing the category
    labels. Within a CNN architecture, some layers find salient features within categories
    of images, which are pooled in other layers that find the best feature sets from
    prior layers and feed them into the next layer of feature-finding layers. It’s
    common for these architectures to involve many layers, and they usually require
    a large set of training data to perform well. Further, they require a lot of computational
    power.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，图像分类算法涉及预训练的或自定义构建的卷积神经网络（CNN），这些在[第1章](c01.xhtml)中有讨论。简单回顾一下，卷积神经网络（CNNs）是一种深度学习算法，通过优化从输入图像层到多个不同类型的层，再到包含类别标签的输出层的映射，来寻找相关特征。在CNN架构中，某些层会在图像类别中找到显著特征，这些特征会在其他层中汇聚，这些层从前一层中找到最佳特征集并将其输入到下一层的特征提取层。通常，这些架构涉及多个层，而且通常需要大量的训练数据才能表现良好。此外，它们还需要大量的计算能力。
- en: Because quantum computing offers faster runtimes for many algorithms and can
    leverage superposition to broaden search capabilities, the merging of deep learning
    algorithms such as CNNs with quantum computing offers a synergy to find relevant
    features more quickly and with less input data. In many real-world applications,
    we don’t have access to every image that comes up on a Google search. We might
    have only a few hundred medical images of a rare condition or not have the computational
    power to optimize hundreds of parameters on an animal image set that includes
    thousands of pictures of hundreds of snake species that pose a threat to farmers
    or villages in the developing world.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 由于量子计算为许多算法提供了更快的运行时间，并且能够利用叠加态来扩展搜索能力，深度学习算法（如CNN）与量子计算的结合提供了一种协同效应，能够更快速且使用更少的输入数据来找到相关特征。在许多现实应用中，我们并不能访问每一张在Google搜索中出现的图像。我们可能只有几百张关于罕见病症的医学图像，或者没有足够的计算能力来优化包含成千上万张蛇类图片的动物图像集，这些蛇类可能对发展中国家的农民或村庄构成威胁。
- en: However, many quantum neural network algorithms exist as of 2023, and many show
    competitive performance on problems such as image classification (though scaling
    is still an issue given the qubit number limitations of current quantum computers).
    We’ll explore one recently developed in South Africa to handle image classification
    problems similarly to CNNs, the circuit-centric quantum classifier that exists
    in the QuantumOps package for general usage and usage on a famous image analytics
    benchmark dataset.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，到2023年为止，许多量子神经网络算法已经存在，且许多算法在图像分类等问题上显示出了竞争力的表现（尽管考虑到当前量子计算机的量子比特数量限制，扩展仍然是一个问题）。我们将探讨一个最近在南非开发的量子神经网络，它与CNN类似，用于处理图像分类问题，这就是QuantumOps包中用于一般用途和著名图像分析基准数据集的电路中心量子分类器。
- en: The details of circuit-centric quantum classifiers are a bit physics-heavy.
    It’s okay if you don’t follow all of this; we’ll see it in action later in this
    section.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 电路中心量子分类器的细节有些物理学内容较重。如果你没有完全跟上也没关系；我们将在本节后续看到它的实际应用。
- en: The basic approach of the circuit-centric quantum classifier is to learn the
    quantum gate parameters of the circuit through supervised learning, such as fitting
    hidden neural network–layer parameters in deep learning algorithms. The independent
    variables are coded into quantum systems amplitudes, which are manipulated by
    quantum gates. These single- and two-qubit gates are optimized through single-qubit
    measurement, which collapses the system from superposition into a single state.
    Gradients are learned by multiple runs of the algorithm, as in the approach in
    the quantum min cut and max flow algorithm earlier in this chapter. As with deep
    learning algorithms, we use dropout regularization fractions, which prune and
    add to the circuit during each iteration. The result is an optimized quantum architecture
    that modifies independent variable sets to create high-quality suggested dependent
    variable labels based on the training set independent and dependent variables.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以电路为中心的量子分类器的基本方法是通过监督学习来学习电路的量子门参数，类似于在深度学习算法中拟合隐藏的神经网络层参数。独立变量被编码成量子系统的幅度，这些幅度会通过量子门进行操作。这些单比特和双比特量子门通过单比特测量来优化，测量会将系统从叠加态坍缩为单一态。通过多次运行算法来学习梯度，类似于本章前面提到的量子最小割和最大流算法的方法。与深度学习算法一样，我们使用丢弃正则化（dropout）分数，这会在每次迭代中修剪并添加到电路中。最终结果是一个优化过的量子架构，它通过修改独立变量集来创建基于训练集的独立变量和因变量的高质量建议标签。
- en: While the exact details of how the quantum operators train the algorithm are
    beyond the scope of this book, the algorithm essentially modifies the quantum
    physics governing the processing of independent variables through the quantum
    circuit to produce accurate predictions of the dependent variable. One of the
    advantages of this approach is fewer parameters in the neural network architecture
    and training process to train compared to CNNs, which speeds up the fitting process
    and avoids the need for deep expertise in architecture design to obtain an architecture
    that fits the problem well.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然量子算子如何训练算法的具体细节超出了本书的范围，但该算法本质上是通过量子电路修改处理独立变量的量子物理规律，从而准确预测因变量。这种方法的一个优势是，相较于卷积神经网络（CNNs），神经网络架构和训练过程中所需的参数更少，能够加速拟合过程，并避免在架构设计中需要深入的专业知识，从而得到一个适合问题的架构。
- en: The data we’ll explore comes from one of the most common image analytics benchmark
    datasets. The MNIST dataset contains tens of thousands of images of handwritten
    digits (0–9). These were collected from sets of 250 and 500 writers and combined
    into a single dataset. Because different people and different cultures have different
    ways of writing numbers (such as the slashed 7 in certain parts of Europe to distinguish
    it from a 1) and different people often have different slants to their writing
    (right, left, center, down, up, straight, and so on), classifying which digit
    is in the image is a more challenging problem than it first appears.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要探讨的数据来自于最常见的图像分析基准数据集之一。MNIST 数据集包含了成千上万张手写数字（0–9）的图片。这些图片分别从 250 位和 500
    位书写者的集合中收集，并合并成一个数据集。由于不同的人和不同的文化有不同的书写数字方式（例如，在欧洲某些地区为了区分 1 和 7，会在 7 上加斜线），而且不同的人书写时也常常有不同的倾斜角度（右倾、左倾、正中、向下、向上、直立等），因此，判断图像中是哪一个数字，实际上比表面看起来要更具挑战性。
- en: Let’s dive into an example that applies this circuit-centric quantum classifier
    in QuantumOps to the recognition of a single digit in the MNIST dataset with [Listing
    10-3](#listing10-3).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个示例来详细了解如何将这个以电路为中心的量子分类器应用到 QuantumOps 中，并用于识别 MNIST 数据集中的单个数字，参考[示例
    10-3](#listing10-3)。
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Listing 10-3: Training a quantum classifier to recognize the digit 0'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 10-3：训练量子分类器以识别数字 0
- en: '[Listing 10-3](#listing10-3) creates a sample of images with the target class
    set to the digit 0 (classifying 0 versus any other number), a learning parameter
    of 1, no decay of the learning rate over each iteration, a low bias (which allows
    other parameters to update faster), and one training iteration. Depending on your
    machine, it may take a while to run, as the algorithm is simulating a quantum
    system; it may even require a machine with more computational power. With a CNN,
    we’d need many more parameters associated with the network (not to mention needing
    to tune the architecture for the number and type of hidden layers), more training
    time, and more computational power. With this code, we optimize 33 quantum gates
    and find a matrix of the entire optimized classifier circuit. This represents
    the quantum architecture that will parse handwritten digits corresponding to 0
    versus every other digit. We could repeat this process until we find quantum classifiers
    for each digit class in MNIST. On an actual quantum computer, this implementation
    would be much faster, as none of the circuitry would need to be simulated on a
    classical circuit.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[Listing 10-3](#listing10-3) 创建了一个图像样本，其中目标类别设置为数字0（即分类0与任何其他数字），学习参数为1，每次迭代没有学习率衰减，偏置较低（允许其他参数更新得更快），并且只有一次训练迭代。根据你的机器，运行可能需要一些时间，因为该算法正在模拟一个量子系统；甚至可能需要更强大的计算能力。使用CNN时，我们需要与网络相关的更多参数（更不用说需要调整架构以适应隐藏层的数量和类型），更多的训练时间，以及更多的计算能力。使用这段代码，我们优化了33个量子门并找到了整个优化后的分类器电路矩阵。这代表了量子架构，能够解析手写数字0与其他数字的区别。我们可以重复这个过程，直到为MNIST中的每个数字类找到量子分类器。在实际的量子计算机上，这个实现会更快，因为电路不需要在经典电路上进行模拟。'
- en: While other incarnations of quantum neural networks exist, most don’t have open
    source implementations yet. We encourage you to explore extant papers and tinker
    around with possible implementations of quantum neural networks on existing quantum
    systems. Most quantum computing companies have partnerships available for researchers
    in academia and industry to accelerate quantum algorithm design progress, and
    if you have access to a quantum computer, you can run the algorithms of this chapter
    (and other simulated packages) on a real quantum computer to leverage gains in
    computational speed.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然量子神经网络的其他版本已经存在，但大多数还没有开源实现。我们鼓励你探索现有的论文，并尝试在现有的量子系统上实现量子神经网络的可能实现。大多数量子计算公司都提供与学术界和工业界研究人员的合作伙伴关系，以加速量子算法设计进展，如果你可以访问量子计算机，你可以在真实的量子计算机上运行本章的算法（以及其他模拟的包），从而利用计算速度的提升。
- en: Summary
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored distributed computing solutions to scale algorithms,
    such as our computationally intensive network and TDA algorithms. We also introduced
    quantum computing frameworks, simulated a quantum graph algorithm for finding
    min flow and max cut solutions, ran a simulation of quantum greatest common denominator
    algorithms, and explored a simulated quantum classifier in the spirit of CNNs
    to explore the potential of quantum. As quantum computers grow in size and availability
    to researchers and industry data scientists, it’s likely that you’ll have access
    to quantum computers in the future to implement these types of algorithms on real
    systems that will improve performance over classical algorithms.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了分布式计算解决方案来扩展算法，例如我们的计算密集型网络和TDA算法。我们还介绍了量子计算框架，模拟了一个用于寻找最小流和最大割解的量子图算法，运行了量子最大公约数算法的模拟，并探索了一个模拟的量子分类器，灵感来源于CNN，用来探索量子计算的潜力。随着量子计算机的规模扩大并且越来越多的研究人员和行业数据科学家可以使用它们，你未来可能会有机会在实际系统上实施这些类型的算法，这将比经典算法提供更好的性能。
- en: Given the current pace of circuit design, other solutions may be developed in
    the future to help scale the algorithms in this book that struggle on big data
    within current computational infrastructure, and we hope that tools to scale algorithms
    will help accelerate the development of new tools from the fields of geometry
    and topology. The field of topological data analysis is rapidly growing. More
    research in the field may lead to novel algorithms that solve general or niche
    problems in machine learning and data analysis.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于当前电路设计的进展，未来可能会开发其他解决方案，帮助扩展本书中的算法，这些算法在现有计算基础设施下在大数据处理上存在困难，我们希望扩展算法的工具能够加速几何和拓扑领域新工具的发展。拓扑数据分析领域正在迅速发展。该领域的更多研究可能会导致新算法的出现，解决机器学习和数据分析中的一般性或特定问题。
