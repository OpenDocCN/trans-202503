<html><head></head><body><div id="sbo-rt-content"><section>&#13;
<header>&#13;
<h1 class="chapter">&#13;
<span class="ChapterNumber"><span epub:type="pagebreak" title="15" id="Page_15"/>2</span><br/>&#13;
<span class="ChapterTitle">Guarding with Special Care</span><br/>&#13;
<span class="ChapterSubtitle">Even castles with strong fortifications should be guarded, paying particular attention to the recessed corners.</span></h1></header>&#13;
<blockquote class="Epigraph" epub:type="epigraph">&#13;
<p class="Epigraph">What shinobi should keep in mind when stealing into a castle or camp are the naturally fortified and difficult directions, the woods, and blind spots.</p>&#13;
<p class="EpigraphSource">—Yoshimori Hyakushu #10</p>&#13;
</blockquote>&#13;
<p class="ChapterIntro">Shinobi were historically proficient infiltrators. The ancient scrolls describe how to quickly identify and brutally exploit weak spots in an enemy’s fortifications. The scrolls also stress that shinobi should use higher-order thinking to creatively apply their knowledge when building their own defenses. <em>Bansenshūkai </em>advises commanders tasked with defending a camp or castle to identify, inspect, and guard with special care the areas where shinobi are most likely to attempt entry, such as the recessed corners of a castle’s stone walls, rubbish disposal areas, water pipes, and nearby woods or bushes.<sup class="endnote"><a id="c02-noteref-28" href="b01.xhtml#endnote-28">1</a></sup></p>&#13;
<h2 id="h1-500549c02-0001"><span epub:type="pagebreak" title="16" id="Page_16"/>Understanding Attack Vectors</h2>&#13;
<p class="BodyFirst">Consider the castle’s wall an <em>attack surface</em> and weak points in the castle’s wall (for example, the water pipe or poorly placed stones in the wall that provide footholds) <em>attack vectors</em>. The term <em>attack surface</em> refers to all the software, networks, and systems that the adversary has the opportunity to attack. Any point within the attack surface can be an attack vector, or the means an attacker uses to gain access. In cybersecurity, it’s always advisable to reduce your attack surface. That said, while reducing the castle footprint would shrink the attack surface that needs to be defended, it wouldn’t mitigate the amount of damage the adversary could inflict or prevent any given attack vector from being exploited. Nonetheless, attack surface reduction can make guarding the target easier.</p>&#13;
<p><em>Bansenshūkai</em>’s volume on hidden infiltration includes a list of well-intentioned defensive techniques, weapons, and modes of thought that can actually expose a camp to risk. It implores commanders to consider how everything in their environment could be used against them. For example, the scroll instructs infiltrators to look for <em>shinobi-gaeshi</em>, spikes set up around an enemy’s encampment to deter would-be attackers.<sup class="endnote"><a id="c02-noteref-29" href="b01.xhtml#endnote-29">2</a></sup> Because defenders placed these spikes in locations they considered vulnerable, the spikes’ presence told enemy shinobi where the defenses were inadequate; defenders were essentially broadcasting their insecurities. Shinobi knew they could remove these spikes—doing so was relatively easy, as they were almost always attached as an afterthought—and gain passage through the weakest spot in the target’s perimeter.<sup class="endnote"><a id="c02-noteref-30" href="b01.xhtml#endnote-30">3</a></sup> </p>&#13;
<p>A succinct example of such security that is “bolted on” as an afterthought is found in Microsoft Windows’ PowerShell. The multitude of security features added on top of the .NET framework with each new version of PowerShell do not address the product’s core flaws and, in fact, have allowed threat actors to create an armory of tools and weapons that can be used to infiltrate systems that support PowerShell. This is an excellent case study for any security researcher wishing to examine <em>shinobi-gaeshi</em> more closely.</p>&#13;
<p>The ancient castles still standing in Japan are not typically adorned with spikes, but they do tend to have water pipes that are too small for a human to climb through, perimeters cleared of vegetation, and no recessed corners in the outer walls—all of which suggest that emperors, taking their cues from shinobi, made efforts over time to eliminate these vulnerabilities. However, while it is ideal to eliminate weaknesses so they do not require guarding, it is not always possible. </p>&#13;
<p>In this chapter, we’ll discuss the concept of guarding and its proposed place within the five functions of cybersecurity. We will then <span epub:type="pagebreak" title="17" id="Page_17"/>discuss how to identify the vulnerable areas that may require guarding with threat modeling. </p>&#13;
<h2 id="h1-500549c02-0002">The Concept of Guarding</h2>&#13;
<p class="BodyFirst"><em>Guarding</em> is the act of exercising protective control over assets by observing the environment, detecting threats, and taking preventative action. For example, the lord of a castle identifies a fairly large water drainage pipe in the castle wall as a weak point. The lord retains the pipe, which performs an important function in allowing water to exit, but requires a guard to stand nearby, preventing attackers from using the pipe as a means of access. </p>&#13;
<p>In general, organizations tend to keep cybersecurity staff in the dark about weak systems, network blind spots, or vulnerable attack vectors that should be guarded with special care. Some organizations assume it’s entirely the cybersecurity staff’s responsibility to discover security flaws in the network. Many stakeholders have not identified these attack vectors in the first place, or if no commercial solution exists or no commonly accepted countermeasure can be applied easily, they simply ignore the weaknesses and hope they will not be exploited. </p>&#13;
<p>In some instances, management directs security personnel <em>not</em> to perform basic logging, scanning, or patching of legacy systems for fear that touching them will disrupt business operations. In more political organizations, it’s common for a threat to not be recognized as a valid concern unless it’s identified through a formal documentation process. Imagine seeing that a castle is missing its west wall, reporting this obvious vulnerability to the king, and having the king dismiss your concerns because his guards have not mentioned it in their official reports.</p>&#13;
<h2 id="h1-500549c02-0003">Guarding Within a Cybersecurity Framework</h2>&#13;
<p class="BodyFirst">The <em>National Institute of Standards and Technology (NIST) Cybersecurity Framework</em><sup class="endnote"><a id="c02-noteref-31" href="b01.xhtml#endnote-31">4</a></sup> seeks to prevent these common missteps and improve organizations’ resilience to cyber threats through five core cybersecurity functions: identify, protect, detect, respond, and recover. These functions help identify vulnerabilities in networks and systems by using common information security tools and processes. </p>&#13;
<p>For instance, most organizations begin the process of identifying weaknesses by conducting vulnerability or application scans of systems on their network—this is the <em>identify</em> function. Effective and reliable, these scans identify obvious security issues such as unpatched software, active accounts with blank passwords, default factory credentials, unparameterized input, and SSH ports open to the internet. Next comes the <em>protect</em> <span epub:type="pagebreak" title="18" id="Page_18"/>function. Upon discovery of an unsecured system, the scanner documents the problem, and then security staff fixes or mitigates the vulnerability with patches; configuration changes; or long-term architectural, security system, or software implementations. </p>&#13;
<p>If the security staff is unable to protect a system that has been identified as an attack vector, I believe they should <em>guard</em> it through human controls. However, a guard function is missing from the NIST framework. Instead, we move straight to the <em>detect</em> function: the security staff attempts to detect an adversary by monitoring and investigating anomalous events. Once the security staff detects infiltration, only then do they execute the <em>respond</em> function by containing the threat, neutralizing the threat, and reporting it. </p>&#13;
<p>Last is the <em>recovery</em> function: restoring the systems and data to operational status, as well as improving their ability to resist future attacks.   </p>&#13;
<p>While essential to a robust security profile, these safeguards are prevention-, protection-, or response-based functions. The cybersecurity industry rarely applies the concept of guarding—using human controls and protection—to information systems, because it’s not feasible for a human defender to manually inspect and approve every email, web page, file, or packet that leaves or enters the environment in the way that a gate guard could watch people or packages entering a building. </p>&#13;
<p>For example, computers with 1GB network connections can process more than 100,000 packets per second, far more than any human could inspect. Instead of using human guards, defenders either rely heavily on automated security controls or simply accept/ignore risk as part of doing business. Guarding can still be feasible within a modern digital network, however, if guards are inserted only into areas that need special care and attention, such as the most likely attack vectors. This is why threat modeling to identify these areas in your organization will be useful.</p>&#13;
<h2 id="h1-500549c02-0004">Threat Modeling</h2>&#13;
<p class="BodyFirst">The closest thing to guarding in cybersecurity is <em>threat hunting</em>, which involves vigorously seeking out indicators of infiltration in logs, forensic data, and other observable evidence. Few organizations perform threat hunting, and even in those that do, a hunter’s job is to detect, not guard.</p>&#13;
<p>Nonetheless, it’s important that cyber defenders go beyond the conventional framework, continually imagining new ways in which networks and information systems could be attacked, and implement the necessary defenses. To this end, defenders can use threat modeling to implement information flow controls and design safeguards against threats rather than simply react to them. </p>&#13;
<p><span epub:type="pagebreak" title="19" id="Page_19"/>Typically performed only by cyber-mature organizations, threat modeling involves documenting a <em>data flow diagram (DFD)</em>, which describes the flow of data and processes inside systems. DFDs are typically documented as a type of flowchart, but can be roughly represented by a detailed network map. A DFD can be used as a tool for structured analysis of your attack surface that allows you to think of attack scenarios within the parameters of the documented information systems. It doesn’t require vulnerability scanning, proving of the attack scenario by red teams, or validation from a compliance framework, and organizations don’t need to wait for a security incident to prove a threat model before acting to guard against the vulnerability. </p>&#13;
<p>Understanding the modern cyber equivalents to “recessed corners of a castle’s stone walls, rubbish disposal areas, water pipes, and nearby woods or bushes” of your environment could help you identify attack vectors that may need guarding with special care.</p>&#13;
<p>Consider this example: as part of their nightly duties, a security guard pulls on every doorknob in an office to make sure the doors are locked. If they find an unlocked door, they lock it, secure the keys, and file a security incident ticket. </p>&#13;
<p>It is later determined that a security incident occurred because door keys were copied or stolen, so the organization adds a second-level authenticator control (such as a keypad or badge reader) to the doors, changes the locks, and issues new keys. These new preventive security controls satisfy compliance auditors, and the ticket reporting the unsecured doors is closed. The chief information security officer (CISO) even hires a red team to perform a narrow-scope physical penetration test of the new door-locking mechanisms, and the team confirms that they were denied access because of the enhanced security measures.</p>&#13;
<p>However, once we conduct threat-modeling exercises, we identify that it’s possible to push moveable ceiling tiles out of the way and climb over the office wall, bypassing the new security measures altogether. To counteract this, we could add controls, such as security cameras or motion detectors in the ceiling crawl space, or we could install solid, tunnel-resistant ceilings and floors. Guards could even be hired and trained to look for evidence of disturbed ceiling tiles, ceiling particulate on the floor, or footprints on the walls. Guarding against this threat would require that guards be posted inside the room or stationed within the ceiling crawl space, armed with the authority and tools to protect the room from intruders.</p>&#13;
<p>The feasibility of implementing such countermeasures is low—you might be laughed out of your manager’s office for even suggesting them. It’s easy to see why organizations are more likely to accept or ignore <span epub:type="pagebreak" title="20" id="Page_20"/>certain threats than attempt to repel them, and this is likely why the NIST Cybersecurity Framework doesn’t include a guard function. If thoughtfully informed by detailed threat modeling and carefully implemented in a creative and deliberate manner, however, this guard-centric mode of thinking can bolster the security of information systems and networks. </p>&#13;
<p>An example of a scenario suitable for the implementation of the guard function is in <em>jump boxes</em>. Jump boxes are systems that span two or more network boundaries, allowing administrators to log in remotely to the jump box from one network and “jump” to another network to gain access to it. The conventional cybersecurity framework advises hardening jump box systems by patching all known vulnerabilities, restricting access with various firewall rules, and monitoring audit logs for anomalous events such as unauthorized access. However, such technical controls are often attacked or bypassed. A guard, on the other hand, could physically disconnect the internal network cable from the other network and connect it directly only after verifying with the administrator that they have approval to execute remote commands against these systems. The guard could also actively monitor actions on the machine in real time and forcibly terminate the session anytime they observe malicious or unauthorized actions. Implementing the guard function in this way might mean hiring a human guard to sit in the data center to protect both physical and remote access to these sensitive systems.     </p>&#13;
<h2 id="h1-500549c02-0005">Using Threat Modeling to Find Potential Attack Vectors </h2>&#13;
<p class="BodyFirst">The basic steps for identifying attack vectors are to follow the guidelines for threat modeling, starting with creating a DFD. Once potential attack vectors are identified from the DFD, the shinobi scrolls recommend inspecting them to determine what technical security controls can be implemented to protect them. Then, as a last resort, use guards to defend these areas as well. You can use the network map you made in the previous chapter to help create the DFD or use it as a rough substitute.</p>&#13;
<ol class="decimal">&#13;
<li value="1"><em>Model your information systems.</em> Create an accurate DFD with the help of your organization’s network, security, development, business, and other IT system owners and experts. It does not need to use Unified Modeling Language (UML) or other advanced <span epub:type="pagebreak" title="21" id="Page_21"/>concepts—it simply needs to accurately represent your systems and the information within them. Note that large, complex systems can easily take a team more than six months to diagram.</li>&#13;
<li value="2"><em>STRIDE and guard.</em> STRIDE is a threat-modeling methodology developed by Microsoft<sup class="endnote"><a id="c02-noteref-32" href="b01.xhtml#endnote-32">5</a></sup> to describe what could go wrong in an information system. The acronym comes from the ways in which an attacker could violate six properties of the system:&#13;
<table id="tabular-500549c02-0001" border="1"><tbody>&#13;
<tr>&#13;
<td><b>S</b>poofing Identity</td>&#13;
<td>=</td>&#13;
<td>Authentication</td>&#13;
</tr>&#13;
<tr>&#13;
<td><b>T</b>ampering with Data</td>&#13;
<td>=</td>&#13;
<td>Integrity</td>&#13;
</tr>&#13;
<tr>&#13;
<td><b>R</b>epudiation/Deniability</td>&#13;
<td>=</td>&#13;
<td>Nonrepudiation</td>&#13;
</tr>&#13;
<tr>&#13;
<td><b>I</b>nformation Disclosure</td>&#13;
<td>=</td>&#13;
<td>Confidentiality</td>&#13;
</tr>&#13;
<tr>&#13;
<td><b>D</b>enial of Service</td>&#13;
<td>=</td>&#13;
<td>Availability</td>&#13;
</tr>&#13;
<tr>&#13;
<td><b>E</b>levation of Privilege</td>&#13;
<td>=</td>&#13;
<td>Authorization</td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="ListBody">To use STRIDE, you will review your DFD and, at every point where there is data input, data processing, data output, or other data flows/rules, hypothesize how an adversary may threaten it. For example, if a system requires a thumbprint to verify a user’s identity before allowing access to the system, you might consider how they could spoof the thumbprint to impersonate a different user. Similarly, you could think about ways they could tamper with the fingerprint database to insert their print, or you could explore a scenario in which the attacker causes the fingerprint scanner to go down, allowing unauthorized access through a weaker authentication process.  </p>&#13;
<p class="ListBody">After learning this framework, you can use it to challenge any imagined threat models that do not accurately represent your systems or scenarios that do not describe how a plausible threat impacts a specific component, surface, or vector. This may require inviting technical subject matter experts to threat-modeling sessions.</p>&#13;
<p class="ListBody">Suppose, for example, that an organizational threat-modeling session produces the following scenario: “The threat of malware compromises the integrity of internal databases.”</p>&#13;
<p class="ListBody">This threat is not properly modeled. Among other pieces of critical information, the scenario does not describe how malware could be delivered and installed. Nor does it describe how the malware would compromise the integrity of the database: does it encrypt, delete, or corrupt data? It does not describe <span epub:type="pagebreak" title="22" id="Page_22"/>which vectors allow the threat to impact the system, and it doesn’t consider the information flow and controls currently in place or provide realistic countermeasures. If, for example, we determined that the most plausible way to infect an internal business database with malware would be through a malicious USB drive, then security may need to draft policies detailing how staff must use USB drives or install cameras to monitor access to USB ports. The organization might decide to grant security the ability to turn USBs on or off, dictate which drives can interface with USBs, control the information flow and direction of USB ports, inspect the files on USB drives before granting access to the requestor, control access with hardware or software locks, or even hot-glue the USB ports shut. Such measures, resulting from thorough threat modeling, allow security personnel to guard against specific threats with special care, rather than having to accept the risk or being limited to protect and detect functions.</p></li>&#13;
<li value="3"><em>Do not advertise bolted-on security.</em> Threat modeling is an iterative, infinite process of evaluating new threats and developing protective countermeasures. In your haste to protect your systems, avoid the use of <em>shinobi-gaeshi</em> security controls—defensive efforts that may backfire by drawing attention to your vulnerable areas. Often because of time, resource, or operational restrictions, you may have taken only half measures that a motivated, sophisticated threat actor can defeat. For example, hot glue in a USB port can be removed with isopropyl alcohol. Where possible, assess the viability of a pure security-first defense approach.&#13;
<p class="ListBody">In the USB threat example, the USB interacts with the hardware abstraction layer (HAL) that sits below the OS kernel. It cannot be fully protected or mitigated with software and policy controls, as those exist above the kernel and can be bypassed. Therefore, a more complete solution might be to implement a motherboard and chassis configuration in which USB ports do not even exist. In contrast, hot glue in the USB port advertises to motivated threat actors that you have not properly addressed the security of USBs, and it will likely be a successful attack vector for them should they be able to pull it free—just as the shinobi pulled out the spikes bolted onto pipes and walls in ancient times.</p>&#13;
<aside epub:type="sidebar">&#13;
<div class="top hr"><hr/></div>&#13;
<section class="box">&#13;
<h2><span epub:type="pagebreak" title="23" id="Page_23"/>Castle Theory Thought Exercise</h2>&#13;
<p class="BoxBodyFirst">Consider the scenario in which you are the ruler of a medieval castle with valuable assets within your stronghold. You receive credible threat intelligence that a ninja plans to infiltrate your castle and set fire to the food supply in your dungeon. The dungeon has multiple ingress/egress points whereby staff transport food, moving freely and without monitoring.</p>&#13;
<p>Consider what measures guards could take to protect food from a fire in the basement. What staffing changes could you implement to control human interactions with the food and protect it from harm? What measures would ensure that guards could quickly observe, report, and respond to fire in the basement? How could guards detect a ninja infiltrating the basement, and what architectural changes could be made to mitigate blind spots that allow access to the food?</p>&#13;
<p>Note that while it would be advisable to have backup food supplies in alternate locations or to store the food within fire-resistant material, for this exercise, consider how guards could control and protect the food rather than directly address the fire threat.</p>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside></li>&#13;
</ol>&#13;
<h2 id="h1-500549c02-0006">Recommended Security Controls and Mitigations</h2>&#13;
<p class="BodyFirst">Where relevant, each recommendation is presented with an applicable security control from the NIST 800-53 standard, and it should be evaluated through the lens of guarding with special care.</p>&#13;
<ol class="decimal">&#13;
<li value="1">Review the results of auditors, red team assessments, vulnerability scans, and incident reports to find vulnerabilities in your environment that cannot be easily patched or mitigated with controls (that is, those that require special guarding). [CA-2: Security Assessments; CA-8: Penetration Testing; IR-6: Incident Reporting | (2) Vulnerabilities Related to Incidents; RA-5: Vulnerability Scanning]</li>&#13;
<li value="2">Perform threat modeling of your environment to identify vulnerabilities. Then determine which ones can be designed out of your environment. Explore the concept of guarding security functions and apply those controls to threats that cannot be easily purged. [SA-8: Security Engineering Principles; SA-14: Criticality Analysis; SA-15: Development Process, Standards, and Tools | (4) Threat Modeling/Vulnerability Analysis; SA-17: Developer Security Architecture and Design]</li>&#13;
<li value="3"><span epub:type="pagebreak" title="24" id="Page_24"/>To deter, protect against, and ensure rapid response to threats, hire real-time security personnel as guards and integrate them into vulnerable areas of business operations. [IR-10: Integrated Information Security Analysis Team] </li>&#13;
</ol>&#13;
<h2 id="h1-500549c02-0007">Debrief</h2>&#13;
<p class="BodyFirst">This chapter has helped you think about the places in a network environment that an adversary is likely to target for infiltration. You have also been introduced to the concept of guarding with direct human interaction between information systems and processes. You may have utilized your network map from the previous chapter or created your own data flow diagram (DFD) as a representation of your environment to identify likely attack vectors and potential STRIDE threats that could be mitigated with guards.</p>&#13;
<p>In the next chapter, we’ll explore a “xenophobic” security concept used by the ancient ninja that may hinder adversaries from finding any common ground or footholds in your environment to even start their attack vector process.  </p>&#13;
</section>&#13;
</div></body></html>