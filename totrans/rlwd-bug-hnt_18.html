<html><head></head><body>
<h2 class="h2" id="ch18"><span epub:type="pagebreak" id="page_177"/><strong><span class="big">18</span><br/>APPLICATION LOGIC AND CONFIGURATION VULNERABILITIES</strong></h2>&#13;
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>&#13;
<p class="noindent">Unlike the previous bugs covered in this book, which rely on the ability to submit malicious input, application logic and configuration vulnerabilities take advantage of mistakes made by developers. <em>Application logic</em> vulnerabilities occur when a developer makes a coding logic mistake that an attacker can exploit to perform some unintended action. <em>Configuration</em> vulnerabilities occur when a developer misconfigures a tool, framework, third-party service, or other program or code in a way that results in a vulnerability.</p>&#13;
<p class="indent">Both vulnerabilities involve exploiting bugs from decisions a developer made when coding or configuring a website. The impact is often an attacker having unauthorized access to some resource or action. But because these <span epub:type="pagebreak" id="page_178"/>vulnerabilities result from coding and configuration decisions, they can be difficult to describe. The best way to understand these vulnerabilities is to walk through an example.</p>&#13;
<p class="indent">In March 2012, Egor Homakov reported to the Ruby on Rails team that its default configuration for the Rails project was insecure. At the time, when a developer installed a new Rails site, the code Rails generated by default would accept all parameters submitted to a controller action to create or update database records. In other words, a default installation would allow anyone to send an HTTP request to update any user object’s user ID, username, password, and creation date parameters regardless of whether the developer meant for them to be updatable. This example is commonly referred to as a <em>mass assignment</em> vulnerability because all parameters can be used to assign to object records.</p>&#13;
<p class="indent">This behavior was well-known within the Rails community but few appreciated the risk it posed. Rails core developers believed that web developers should be responsible for closing this security gap and defining which parameters a site accepts to create and update records. You can read some of the discussion at <em><a href="https://github.com/rails/rails/issues/5228/">https://github.com/rails/rails/issues/5228/</a></em>.</p>&#13;
<p class="indent">The Rails core developers disagreed with Homakov’s assessment, so Homakov exploited the bug on GitHub (a large site developed with Rails). He guessed an accessible parameter that was used to update the creation date of GitHub issues. He included the creation date parameter in an HTTP request and submitted an issue with a creation date years in the future. This shouldn’t have been possible for a GitHub user. He also updated GitHub’s SSH access keys to gain access to the official GitHub code repository—a critical vulnerability.</p>&#13;
<p class="indent">In response, the Rails community reconsidered its position and started requiring developers to whitelist parameters. Now, the default configuration won’t accept parameters unless a developer marks them as safe.</p>&#13;
<p class="indent">The GitHub example combines application logic and configuration vulnerabilities. The GitHub developers were expected to add security precautions, but because they used the default configuration, they created a vulnerability.</p>&#13;
<p class="indent">Application logic and configuration vulnerabilities might be tougher to find than the vulnerabilities previously covered in this book (not that any of the others are easy). That’s because they rely on creative thinking about coding and configuration decisions. The more you know about the internal workings of various frameworks, the more easily you’ll find these types of vulnerabilities. For example, Homakov knew the site was built with Rails and how Rails handled user input by default. In other examples, I’ll show how bug reporters invoked direct API calls, scanned thousands of IPs for misconfigured servers, and discovered functionality not intended to be publicly accessible. These vulnerabilities require background knowledge of web frameworks and investigative skills, so I’ll focus on reports that will help you develop this knowledge rather than reports with a high payout.</p>&#13;
<h3 class="h3" id="ch18lev1sec1"><span epub:type="pagebreak" id="page_179"/><strong>Bypassing Shopify Administrator Privileges</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Low</p>&#13;
<p class="hang"><strong>URL:</strong> <em>&lt;shop&gt;.myshopify.com/admin/mobile_devices.json</em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://hackerone.com/reports/100938/">https://hackerone.com/reports/100938/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> November 22, 2015</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $500</p>&#13;
<p class="noindent">Like GitHub, Shopify is built using the Ruby on Rails framework. Rails is popular because, when you develop a site with it, the framework handles many common and repetitive tasks, such as parsing parameters, routing requests, serving files, and so on. But Rails doesn’t provide permissions handling by default. Instead, developers must code their own permissions handling or install a third-party gem with that functionality (<em>gems</em> are Ruby libraries). As a result, when hacking Rails applications, it’s always a good idea to test user permissions: you might find application logic vulnerabilities, as you would when searching for IDOR vulnerabilities.</p>&#13;
<p class="indent">In this case, rms, the reporter, noticed that Shopify defined a user permission called Settings. This permission allowed administrators to add phone numbers to the application through an HTML form when placing orders on the site. Users without this permission weren’t given a field to submit a phone number on the user interface (UI).</p>&#13;
<p class="indent">By using Burp as a proxy to record the HTTP requests made to Shopify, rms found the endpoint that HTTP requests for the HTML form were being sent to. Next, rms logged into an account that was assigned the Settings permission, added a phone number, and then removed that number. Burp’s history tab recorded the HTTP request to add the phone number, which was sent to the <em>/admin/mobile_numbers.json</em> endpoint. Then rms removed the Settings permission from the user account. At this point, the user account shouldn’t have been permitted to add a phone number.</p>&#13;
<p class="indent">Using the Burp Repeater tool, rms bypassed the HTML form and sent the same HTTP request to <em>/admin/mobile_number.json</em> while still logged into the account without the Settings permission. The response indicated a success, and placing a test order on Shopify confirmed that the notification was sent to the phone number. The Settings permission had removed only the frontend UI element where users could enter phone numbers. But the Settings permission wasn’t blocking a user without permissions from submitting a phone number on the site’s backend.</p>&#13;
<h4 class="h4" id="ch18lev2sec1"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">When you’re working on Rails applications, be sure to test all user permissions because Rails doesn’t handle that functionality by default. Developers must implement user permissions, so it’s easy for them to forget to add a permission check. Additionally, it’s always a good idea to proxy your traffic. That way, you can easily identify endpoints and replay HTTP requests that might not be available through the website’s UI.</p>&#13;
<h3 class="h3" id="ch18lev1sec2"><span epub:type="pagebreak" id="page_180"/><strong>Bypassing Twitter Account Protections</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Easy</p>&#13;
<p class="hang"><strong>URL:</strong> <em><a href="https://twitter.com">https://twitter.com</a></em></p>&#13;
<p class="hang"><strong>Source:</strong> N/A</p>&#13;
<p class="hang"><strong>Date reported:</strong> October 2016</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $560</p>&#13;
<p class="noindent">When you’re testing, make sure you consider the differences between an application’s website and its mobile versions. There could be application logic differences between the two experiences. When developers don’t properly consider these differences, they could create vulnerabilities, which is what occurred in this report.</p>&#13;
<p class="indent">In the fall of 2016, Aaron Ullger noticed that when he logged into Twitter from an unrecognized IP address and browser for the first time, the Twitter website required additional information before authentication. The information Twitter requested was typically an email or phone number associated with the account. This security feature was meant to ensure that if your account login were compromised, an attacker couldn’t access the account if they didn’t have that additional information.</p>&#13;
<p class="indent">But during his tests, Ullger used his phone to connect to a VPN, which assigned the device a new IP address. He would have been prompted for additional information when signing in from an unrecognized IP address on a browser, but he was never prompted to do so on his phone. This meant that if attackers compromised his account, they could avoid the additional security checks by using the mobile application to log in. In addition, attackers could view the user’s email address and phone number within the app, which would allow them to log in through the website.</p>&#13;
<p class="indent">In response, Twitter validated and fixed the issue, awarding Ullger $560.</p>&#13;
<h4 class="h4" id="ch18lev2sec2"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">Consider whether security-related behaviors are consistent across platforms when you access an application using different methods. In this case, Ullger only tested the application’s browser and mobile versions. But other websites might use third-party apps or API endpoints.</p>&#13;
<h3 class="h3" id="ch18lev1sec3"><strong>HackerOne Signal Manipulation</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Low</p>&#13;
<p class="hang"><strong>URL:</strong> <em>hackerone.com/reports/&lt;X&gt;</em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://hackerone.com/reports/106305">https://hackerone.com/reports/106305</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> December 21, 2015</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $500</p>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_181"/>When developing a site, programmers will likely test new features they implement. But they might neglect to test rare types of input or how the feature they’re developing interacts with other parts of the site. When you’re testing, focus on these areas, and especially on edge cases, which are easy ways developers might accidentally introduce application logic vulnerabilities.</p>&#13;
<p class="indent">At the end of 2015, HackerOne introduced new functionality to its platform called Signal, which shows a hacker’s average reputation based on the resolved reports they’ve submitted. For example, reports closed as spam receive –10 reputation, not applicable receive –5, informative receive 0, and resolved receive 7. The closer your Signal is to 7, the better.</p>&#13;
<p class="indent">In this case, the reporter Ashish Padelkar recognized that a person could manipulate this statistic by self-closing reports. Self-closing is a separate feature that allows hackers to retract their report if they made a mistake, and it sets the report to 0 reputation. Padelkar realized that HackerOne was using the 0 from self-closed reports to calculate Signal. So anyone with a negative Signal could raise their average by self-closing reports.</p>&#13;
<p class="indent">As a result, HackerOne removed self-closed reports from Signal calculations and awarded Padelkar a $500 bounty.</p>&#13;
<h4 class="h4" id="ch18lev2sec3"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">Keep an eye out for new site functionality: it represents an opportunity to test new code and could cause bugs even in existing functionality. In this example, the interaction of self-closed reports and the new Signal feature resulted in unintended consequences.</p>&#13;
<h3 class="h3" id="ch18lev1sec4"><strong>HackerOne Incorrect S3 Bucket Permissions</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> <em>[REDACTED].s3.amazonaws.com</em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://hackerone.com/reports/128088/">https://hackerone.com/reports/128088/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> April 3, 2016</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $2,500</p>&#13;
<p class="noindent">It’s easy to assume every bug in an application has been found before you’ve even started testing. But don’t overestimate a site’s security or what other hackers have tested. I had to overcome this mindset when testing for an application configuration vulnerability on HackerOne.</p>&#13;
<p class="indent">I noticed that Shopify had disclosed reports about misconfigured Amazon Simple Store Services (S3) buckets and decided to see whether I could find similar bugs. S3 is a file management service from Amazon Web Services (AWS) that many platforms use to store and serve static content, such as images. Like all AWS services, S3 has complex permissions that are easy to misconfigure. At the time of this report, permissions included the ability to read, write, and read/write. The write and read/write permissions meant that anyone with an AWS account could modify files, even if that file was stored in a private bucket.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_182"/>While looking for bugs on the HackerOne website, I realized the platform was serving user images from an S3 bucket named <code>hackerone-profile-photos</code>. The bucket name gave me a clue to the naming convention HackerOne was using for buckets. To learn more about compromising S3 buckets, I started looking at previous reports of similar bugs. Unfortunately, the reports I found about misconfigured S3 buckets didn’t include how reporters found the buckets or how they had validated their vulnerability. I searched for information on the web instead and found two blog posts: <em><a href="https://community.rapid7.com/community/infosec/blog/2013/03/27/1951-open-s3-buckets/">https://community.rapid7.com/community/infosec/blog/2013/03/27/1951-open-s3-buckets/</a></em> and <em><a href="https://digi.ninja/projects/bucket_finder.php/">https://digi.ninja/projects/bucket_finder.php/</a></em>.</p>&#13;
<p class="indent">The Rapid7 article details their approach to discovering publicly readable S3 buckets using <em>fuzzing</em>. To do so, the team gathered a list of valid S3 bucket names and generated a wordlist of common permutations, like <code>backup</code>, <code>images</code>, <code>files</code>, <code>media</code> and so on. The two lists gave them thousands of bucket name combinations to test access to using the AWS command line tools. The second blog post includes a script called <em>bucket_finder</em> that accepts a word list of possible bucket names and checks whether each bucket in the list exists. If the bucket does exist, it attempts to read the contents using the AWS command line tools.</p>&#13;
<p class="indent">I created a list of potential bucket names for HackerOne, such as <code>hackerone</code>, <code>hackerone.marketing</code>, <code>hackerone.attachments</code>, <code>hackerone.users</code>, <code>hackerone.files</code>, and so on. I gave the list to the <em>bucket_finder</em> tool and it found a few buckets, but none were publicly readable. However, I noticed that the script didn’t test if they were publicly writeable. To test that, I created and attempted to copy a text file to the first bucket I found using the command <code>aws s3 mv test.txt s3://hackerone.marketing</code>. This resulted in the following:</p>&#13;
<pre>move failed: ./test.txt to s3://hackerone.marketing/test.txt A client error<br/>&#13;
(AccessDenied) occurred when calling the PutObject operation: Access Denied</pre>&#13;
<p class="indent">Trying the next one, <code>aws s3 mv test.txt s3://hackerone.files</code>, resulted in this:</p>&#13;
<pre>move: ./test.txt to s3://hackerone.files/test.txt</pre>&#13;
<p class="indent">Success! Next, I tried to delete the file using the command <code>aws s3 rm s3://hackerone.files/test.txt</code> and received another success.</p>&#13;
<p class="indent">I was able to write and delete files from a bucket. An attacker could theoretically move a malicious file into that bucket so a HackerOne staff member might access it. As I was writing my report, I realized I couldn’t confirm that HackerOne owned the bucket because Amazon lets users register any bucket name. I wasn’t sure whether to report without ownership confirmation, but I figured: what the hell. Within hours, HackerOne confirmed the report, fixed it, and discovered other misconfigured buckets. To HackerOne’s credit, when it awarded the bounty, it factored in the additional buckets and increased my payout.</p>&#13;
<h4 class="h4" id="ch18lev2sec4"><span epub:type="pagebreak" id="page_183"/><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">HackerOne is an awesome team: the hacker-minded developers know common vulnerabilities to look out for. But even the best developer can make mistakes. Don’t be intimidated and shy away from testing an application or feature. As you’re testing, focus on third-party tools that are easily misconfigured. Additionally, if you find write-ups or publicly accessible reports about new concepts, try to understand how those reporters discovered the vulnerability. In this case, doing so was a matter of researching how people were finding and exploiting S3 misconfigurations.</p>&#13;
<h3 class="h3" id="ch18lev1sec5"><strong>Bypassing GitLab Two-Factor Authentication</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> N/A</p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://hackerone.com/reports/128085/">https://hackerone.com/reports/128085/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> April 3, 2016</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> N/A</p>&#13;
<p class="noindent"><em>Two-factor authentication (2FA)</em> is a security feature that adds a second step to website login processes. Traditionally, when logging into a website, users only enter their username and password to be authenticated. With 2FA, the site requires an additional authentication step beyond a password. Commonly, sites will send an authorization code via email, text, or an authenticator app that the user must enter after they’ve submitted their username and password. These systems can be tough to implement correctly and are good candidates for application logic vulnerability testing.</p>&#13;
<p class="indent">On April 3, 2016, Jobert Abma found a vulnerability in GitLab. It allowed an attacker to log into a target’s account without knowing the target’s password when 2FA was enabled. Abma noticed that once a user entered their username and password during the sign-in process, a code would be sent to the user. Submitting the code to the site would result in the following <code>POST</code> request:</p>&#13;
<pre>   POST /users/sign_in HTTP/1.1<br/>&#13;
   Host: 159.xxx.xxx.xxx<br/>&#13;
   <span class="codeitalic1">--snip--</span><br/>&#13;
   ----------1881604860<br/>&#13;
   Content-Disposition: form-data; name="user[otp_attempt]"<br/>&#13;
<span class="ent">➊</span> 212421<br/>&#13;
   ----------1881604860--</pre>&#13;
<p class="indent">The <code>POST</code> request would include an OTP token <span class="ent">➊</span> that authenticates the user for the second step of 2FA. An OTP token would be generated only after the user has already entered their username and password, but if an attacker attempted to log in to their own account, they could intercept the <span epub:type="pagebreak" id="page_184"/>request using a tool like Burp and add a different username to the request. This would change the account they were being logged in to. For example, the attacker could attempt to log in to the user account called <code>john</code> as follows:</p>&#13;
<pre>   POST /users/sign_in HTTP/1.1<br/>&#13;
   Host: 159.xxx.xxx.xxx<br/>&#13;
   <span class="codeitalic1">--snip--</span><br/>&#13;
   ----------1881604860<br/>&#13;
   Content-Disposition: form-data; name="user[otp_attempt]"<br/>&#13;
   212421<br/>&#13;
   ----------1881604860<br/>&#13;
<span class="ent">➊</span> Content-Disposition: form-data; name="user[login]"<br/>&#13;
   john<br/>&#13;
   ----------1881604860--</pre>&#13;
<p class="indent">The <code>user[login]</code> request tells the GitLab website that a user has attempted to log in with their username and password, even when the user has not attempted to log in. The GitLab website would generate an OTP token for <code>john</code> regardless, which the attacker could guess and submit to the site. If the attacker guessed the correct OTP token, they could log in without having ever known the password.</p>&#13;
<p class="indent">One caveat of this bug is that an attacker had to either know or guess a valid OTP token for the target. An OTP token changes every 30 seconds and is only generated when a user is logging in or a <code>user[login]</code> request is submitted. Exploiting this vulnerability would be difficult. Nonetheless, GitLab confirmed and fixed the vulnerability within two days of the report.</p>&#13;
<h4 class="h4" id="ch18lev2sec5"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">Two-factor authentication is a tricky system to get right. When you notice a site is using it, be sure to test its functionalities, such as any token lifetimes, maximum number of attempts limitations, and so on. Also, check whether expired tokens can be reused, the likelihood of guessing a token, and other token vulnerabilities. GitLab is an open source application, and Abma likely found this issue by reviewing the source code because he identified the error in the code for developers in his report. Nonetheless, watch for HTTP responses that reveal parameters you can potentially include in HTTP requests, like Abma did.</p>&#13;
<h3 class="h3" id="ch18lev1sec6"><strong>Yahoo! PHP Info Disclosure</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> <em>http://nc10.n9323.mail.ne1.yahoo.com/phpinfo.php/</em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://blog.it-securityguard.com/bugbounty-yahoo-phpinfo-php-disclosure-2/">https://blog.it-securityguard.com/bugbounty-yahoo-phpinfo-php-disclosure-2/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> October 16, 2014</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> N/A</p>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_185"/>This report wasn’t awarded a bounty like the others in this chapter. But it demonstrates the importance of network scanning and automation for finding application configuration vulnerabilities. In October 2014, Patrik Fehrenbach of HackerOne found a Yahoo! server that returned the contents of the <code>phpinfo</code> function. The <code>phpinfo</code> function outputs information about the current state of PHP. This information includes compilation options and extensions, the version number, information about the server and environment, HTTP headers, and so on. Because every system is set up differently, <code>phpinfo</code> is commonly used to check configuration settings and the predefined variables available on a given system. This type of detailed information should not be publicly accessible on production systems, because it gives attackers significant insight into a target’s infrastructure.</p>&#13;
<p class="indent">Additionally, although Fehrenbach didn’t mention this, note that <code>phpinfo</code> will include the contents of <code>httponly</code> cookies. If a domain has an XSS vulnerability <em>and</em> a URL disclosing the contents of <code>phpinfo</code>, an attacker could use the XSS to make an HTTP request to the URL. Because the contents of <code>phpinfo</code> are disclosed, the attacker could steal the <code>httponly</code> cookie. This exploit is possible because the malicious JavaScript could read the HTTP response body with the value, even though it’s not permitted to read the cookie directly.</p>&#13;
<p class="indent">To discover this vulnerability, Fehrenbach pinged <em><a href="http://yahoo.com">yahoo.com</a></em>, which returned 98.138.253.109. He used the <code>whois</code> command line tool on the IP, which returned the following record:</p>&#13;
<pre>NetRange: 98.136.0.0 - 98.139.255.255<br/>&#13;
CIDR: 98.136.0.0/14<br/>&#13;
OriginAS:<br/>&#13;
NetName: A-YAHOO-US9<br/>&#13;
NetHandle: NET-98-136-0-0-1<br/>&#13;
Parent: NET-98-0-0-0-0<br/>&#13;
NetType: Direct Allocation<br/>&#13;
RegDate: 2007-12-07<br/>&#13;
Updated: 2012-03-02<br/>&#13;
Ref: http://whois.arin.net/rest/net/NET-98-136-0-0-1</pre>&#13;
<p class="indent">The first line confirms that Yahoo! owns a large block of IP addresses from 98.136.0.0 to 98.139.255.255 or 98.136.0.0/14, which is 260,000 unique IP addresses. That’s a lot of potential targets! Using the following simple bash script, Fehrenbach searched for the IP address’s <code>phpinfo</code> files:</p>&#13;
<pre>   #!/bin/bash<br/>&#13;
<span class="ent">➊</span> for ipa in 98.13{6..9}.{0..255}.{0..255}; do<br/>&#13;
<span class="ent">➋</span> wget -t 1 -T 5 http://${ipa}/phpinfo.php; done &amp;</pre>&#13;
<p class="indent">The code at <span class="ent">➊</span> enters a <code>for</code> loop that iterates through all the possible numbers for each range in each pair of braces. The first IP tested would be 98.136.0.0, then 98.136.0.1, then 98.136.0.2, and so on through 98.139.255.255. Each IP address would be stored in the variable <code>ipa</code>. The code at <span class="ent">➋</span> uses the <code>wget</code> command line tool to make a <code>GET</code> request to the IP address being tested by replacing <code>${ipa}</code> with the current value of the IP address in the <code>for</code> loop. <span epub:type="pagebreak" id="page_186"/>The <code>-t</code> flag denotes the number of times the <code>GET</code> request should be retried when unsuccessful, which in this case is <code>1</code>. The <code>-T</code> flag denotes the number of seconds to wait before considering the request to have timed out. Running his script, Fehrenbach found the URL <em>http://nc10.n9323.mail.ne1.yahoo.com</em> had the <code>phpinfo</code> function enabled.</p>&#13;
<h4 class="h4" id="ch18lev2sec6"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">When you’re hacking, consider a company’s entire infrastructure fair game unless you’re told it’s out of scope. Although this report didn’t pay a bounty, you can employ similar techniques to find some significant payouts. Additionally, look for ways to automate your testing. You’ll often need to write scripts or use tools to automate processes. For example, the 260,000 potential IP addresses Fehrenbach found would have been impossible to test manually.</p>&#13;
<h3 class="h3" id="ch18lev1sec7"><strong>HackerOne Hacktivity Voting</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> <em><a href="https://hackerone.com/hacktivity/">https://hackerone.com/hacktivity/</a></em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://hackerone.com/reports/137503/">https://hackerone.com/reports/137503/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> May 10, 2016</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> Swag</p>&#13;
<p class="noindent">Although this report technically didn’t uncover a security vulnerability, it’s a great example of how to use JavaScript files to find new functionality to test. In the spring of 2016, HackerOne had been developing functionality to allow hackers to vote on reports. This feature wasn’t enabled in the user interface and shouldn’t have been available to use.</p>&#13;
<p class="indent">HackerOne uses the React framework to render its website, so much of its functionality is defined in JavaScript. One common way of using React to build functionality is to enable UI elements based on responses from the servers. For example, a site might enable admin-related functionality, such as a Delete button, based on whether the server identifies a user as an administrator. But the server might not verify that an HTTP request invoked via the UI was made by a legitimate administrator. According to the report, the hacker, apok, tested whether disabled UI elements could still be used to make HTTP requests. The hacker modified HackerOne’s HTTP responses to change any false value to true, likely using a proxy like Burp. Doing so revealed new UI buttons for voting on reports, which invoked <code>POST</code> requests when clicked.</p>&#13;
<p class="indent">Other ways of discovering hidden UI features would be to use the browser developer tools or a proxy like Burp to search for the word <code>POST</code> within the JavaScript files to identify HTTP requests the site uses. <span epub:type="pagebreak" id="page_187"/>Searching for URLs is an easy way to find new functionality without having to browse through the entire application. In this case, the JavaScript file included the following:</p>&#13;
<pre>vote: function() {<br/>&#13;
var e = this;<br/>&#13;
a.ajax({<br/>&#13;
  <span class="ent">➊</span> url: this.url() + "/votes",<br/>&#13;
    method: "POST",<br/>&#13;
    datatype: "json",<br/>&#13;
    success: function(t) {<br/>&#13;
        return e.set({<br/>&#13;
            vote_id: t.vote_id,<br/>&#13;
            vote_count: t.vote_count<br/>&#13;
        })<br/>&#13;
    }<br/>&#13;
})<br/>&#13;
},<br/>&#13;
unvote: function() {<br/>&#13;
var e = this;<br/>&#13;
a.ajax({<br/>&#13;
  <span class="ent">➋</span> url: this.url() + "/votes" + this.get("vote_id"),<br/>&#13;
    method: "DELETE":,<br/>&#13;
    datatype: "json",<br/>&#13;
    success: function(t) {<br/>&#13;
        return e.set({<br/>&#13;
            vote_id: t.void 0,<br/>&#13;
            vote_count: t.vote_count<br/>&#13;
        })<br/>&#13;
    }<br/>&#13;
})<br/>&#13;
}</pre>&#13;
<p class="indent">As you can see, there are two paths for the voting functionality through the two URLs at <span class="ent">➊</span> and <span class="ent">➋</span>. At the time of this report, you could perform <code>POST</code> requests to these URL endpoints. Then you could vote on the reports despite the functionality not being available or complete.</p>&#13;
<h4 class="h4" id="ch18lev2sec7"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">When a site relies on JavaScript, especially on frameworks like React, AngularJS, and so on, using JavaScript files is a great way to find more areas of the application to test. Using JavaScript files can save you time and might help you identify hidden endpoints. Use tools like <em><a href="https://github.com/nahamsec/JSParser">https://github.com/nahamsec/JSParser</a></em> to make tracking JavaScript files over time easier.</p>&#13;
<h3 class="h3" id="ch18lev1sec8"><span epub:type="pagebreak" id="page_188"/><strong>Accessing PornHub’s Memcache Installation</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> <em><a href="http://stage.pornhub.com">stage.pornhub.com</a></em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://blog.zsec.uk/pwning-pornhub/">https://blog.zsec.uk/pwning-pornhub/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> March 1, 2016</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $2,500</p>&#13;
<p class="noindent">In March 2016, Andy Gill was working on the PornHub bug bounty program, which had a scope of <em>*.pornhub.com</em> domains. This meant all the site’s subdomains were in scope and eligible for a bounty. Using a custom list of common subdomain names, Gill discovered 90 PornHub subdomains.</p>&#13;
<p class="indent">It would have been time-consuming to visit all of these sites, so as Fehrenbach did in the earlier example, Gill automated the process using EyeWitness. EyeWitness captures screenshots of websites and provides a report of open 80, 443, 8080, and 8443 ports (which are common HTTP and HTTPS ports). Networking and ports are beyond the scope of this book, but by opening a port, the server can use software to send and receive internet traffic.</p>&#13;
<p class="indent">This task didn’t reveal much, so Gill focused on <em><a href="http://stage.pornhub.com">stage.pornhub.com</a></em> because staging and development servers are more likely to be misconfigured. To begin, he used the command line tool <code>nslookup</code> to get the IP address of the site. This returned the following record:</p>&#13;
<pre>   Server:     8.8.8.8<br/>&#13;
   Address:    8.8.8.8#53<br/>&#13;
   Non-authoritative answer:<br/>&#13;
   Name:       stage.pornhub.com<br/>&#13;
<span class="ent">➊</span> Address:    31.192.117.70</pre>&#13;
<p class="indent">The address is the notable value <span class="ent">➊</span> because it shows the IP address of <em><a href="http://stage.pornhub.com">stage.pornhub.com</a></em>. Next, Gill used the tool Nmap to scan the server for open ports using the command <code>nmap -sV -p- 31.192.117.70 -oA stage__ph -T4</code>.</p>&#13;
<p class="indent">The first flag (<code>-sV</code>) in the command enables version detection. If an open port is found, Nmap attempts to determine what software is running on it. The <code>–p-</code> flag instructs Nmap to scan all 65,535 possible ports (by default, Nmap only scans the most popular 1,000 ports). Next, the command lists the IP to scan: the IP of <em><a href="http://stage.pornhub.com">stage.pornhub.com</a></em> (<code>31.192.117.70</code>) in this case. Then the flag <code>-oA</code> outputs the results of the scan as all three major output formats, which are normal, grepable, and XML. In addition, the command includes a base filename <code>stage__ph</code> for the output files. The final flag, <code>-T4</code>, makes Nmap run a bit faster. The default value is 3: the value 1 is the slowest and 5 is the fastest setting. Slower scans can evade intrusion <span epub:type="pagebreak" id="page_189"/>detection systems, and faster scans require more bandwidth and might be less accurate. When Gill ran the command, he received the following result:</p>&#13;
<pre>   Starting Nmap 6.47 ( http://nmap.org ) at 2016-06-07 14:09 CEST<br/>&#13;
   Nmap scan report for 31.192.117.70<br/>&#13;
   Host is up (0.017s latency).<br/>&#13;
   Not shown: 65532 closed ports<br/>&#13;
   PORT    STATE    SERVICE      VERSION<br/>&#13;
   80/tcp  open     http         nginx<br/>&#13;
   443/tcp open     http         nginx<br/>&#13;
<span class="ent">➊</span> 60893/tcp open   memcache<br/>&#13;
   Service detection performed. Please report any incorrect results at http://<br/>&#13;
   nmap.org/submit/.<br/>&#13;
   Nmap done: 1 IP address (1 host up) scanned in 22.73 seconds</pre>&#13;
<p class="indent">The key part of the report is that port 60893 is open and running what Nmap identifies as <code>memcache</code> <span class="ent">➊</span>. Memcache is a caching service that uses key-value pairs to store arbitrary data. Typically, it’s used to increase the speed of websites by serving content faster through the cache.</p>&#13;
<p class="indent">Finding this port open isn’t a vulnerability, but it’s definitely a red flag. The reason is that Memcache’s installation guides recommend making it publicly inaccessible as a security precaution. Gill then used the command line utility Netcat to attempt a connection. He wasn’t prompted for authentication, which is an application configuration vulnerability, so Gill was able to run harmless stats and version commands to confirm his access.</p>&#13;
<p class="indent">The severity of accessing a Memcache server depends on what information it’s caching and how an application is using that information.</p>&#13;
<h4 class="h4" id="ch18lev2sec8"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">Subdomains and broader network configurations represent great potential for hacking. If a program is including a broad scope or all subdomains in its bug bounty program, you can enumerate subdomains. As a result, you might find attack surfaces that others haven’t tested. This is particularly helpful when you’re looking for application configuration vulnerabilities. It’s worth your time to become familiar with tools like EyeWitness and Nmap, which can automate enumeration for you.</p>&#13;
<h3 class="h3" id="ch18lev1sec9"><strong>Summary</strong></h3>&#13;
<p class="noindent">Discovering application logic and configuration vulnerabilities requires you to watch for opportunities to interact with an application in different ways. The Shopify and Twitter examples demonstrate this well. Shopify wasn’t validating permissions during HTTP requests. Similarly, Twitter omitted security checks on its mobile application. Both involved testing the sites from different vantage points.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_190"/>Another trick to locating logic and configuration vulnerabilities is to find the surface areas of an application you can explore. For example, new functionality is a great entry point for these vulnerabilities. It always provides a good opportunity to find bugs in general. New code presents the chance for you to test edge cases or the new code’s interaction with existing functionality. You can also delve into a site’s JavaScript source code to discover functional changes that wouldn’t be visible in the site’s UI.</p>&#13;
<p class="indent">Hacking can be time-consuming, so it’s important to learn tools that automate your work. Examples in this chapter included small bash scripts, Nmap, EyeWitness, and <em>bucket_finder</em>. You’ll find more tools in <a href="app01.xhtml#app01">Appendix A</a>.</p>&#13;
</body></html>