- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: '15'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Biasing the Computer
  prefs: []
  type: TYPE_NORMAL
- en: '![Alphabet-I](Images/Alphabet-I.png)n the last chapter, you saw how it’s possible
    to accidentally train an ML system in a way that causes it to give the wrong answer,
    by introducing *bias* into your training examples.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you’ll see how bias is sometimes introduced intentionally to
    influence the answers that an ML system gives. You’ll create an app that recommends
    movies to people based on the sort of films that they like. But you’ll train your
    model in a way that lets you affect the recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Build Your Project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Choose three movies to begin building the movie library that your recommendation
    app will have to choose from.
  prefs: []
  type: TYPE_NORMAL
- en: I want my recommendation app to help people find classic movies, so I chose
    three films from the 1920s, as shown in [Figure 15-1](#figure15-1), but you can
    choose newer movies for your project.
  prefs: []
  type: TYPE_NORMAL
- en: '![f15001](Images/f15001.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-1:](#figureanchor15-1) The movies I chose to start my project'
  prefs: []
  type: TYPE_NORMAL
- en: Choose three very different films that different sorts of people might enjoy.
  prefs: []
  type: TYPE_NORMAL
- en: I chose the science-fiction film *Metropolis*, the comedy movie *The Gold Rush*,
    and the horror film *Nosferatu*.
  prefs: []
  type: TYPE_NORMAL
- en: Train Your Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Go to *[https://machinelearningforkids.co.uk](https://machinelearningforkids.co.uk)/*.
    Create a new ML project, name it `Bias`, and set it to learn to recognize text
    in your preferred language.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Train**, as shown in [Figure 15-2](#figure15-2).![f15002](Images/f15002.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 15-2:](#figureanchor15-2) Train is the first phase of an ML project.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Add new label**, as shown in [Figure 15-3](#figure15-3), to add a training
    bucket for each of your three movies.![f15003](Images/f15003.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 15-3:](#figureanchor15-3) Create a training bucket for each movie.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Add example**, as shown in [Figure 15-4](#figure15-4), in the first
    of your movie training buckets. Type something that you think someone who would
    like your first movie might say.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For example, my first movie, *Metropolis*, is a sci-fi film set in the future,
    so I typed `I love futuristic films`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f15004](Images/f15004.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 15-4:](#figureanchor15-4) Add an example of something someone who likes
    the first movie would say.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Add**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat steps 4 and 5 until you’ve got five examples of statements for each movie,
    as shown in [Figure 15-5](#figure15-5).![f15005](Images/f15005.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 15-5:](#figureanchor15-5) Add five examples for each movie.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Back to project** in the top-left corner of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Learn & Test**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Train new machine learning model**, as shown in [Figure 15-6](#figure15-6).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It will take a minute for the computer to learn from your examples and create
    a new ML model, but you can continue to the next step while you’re waiting.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f15006](Images/f15006.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-6:](#figureanchor15-6) Create an ML model.'
  prefs: []
  type: TYPE_NORMAL
- en: Prepare Your Project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you have an ML model, it’s time to create the recommendations app that
    will use it.
  prefs: []
  type: TYPE_NORMAL
- en: Click **Back to project** in the top-left corner of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Make**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Scratch 3**, and then click **Open in Scratch 3** to open a new window
    with Scratch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Costumes** tab, move your mouse pointer over the Choose a Costume
    icon (the cat face) at the bottom left, and then click **Upload Costume** to upload
    a poster of your movie, as shown in [Figure 15-7](#figure15-7).![f15007](Images/f15007.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 15-7:](#figureanchor15-7) Upload a costume.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Upload a poster for the first of your movies, as shown in [Figure 15-8](#figure15-8).![f15008](Images/f15008.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 15-8:](#figureanchor15-8) Create a costume to represent your first
    movie.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Repeat steps 4 and 5 to add the posters for all three of your movies as costumes
    *for the same sprite* so that it looks like [Figure 15-9](#figure15-9).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name each costume to match its film title.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f15009](Images/f15009.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 15-9:](#figureanchor15-9) Create a costume for each movie.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the **Code** tab and copy the script shown in [Figure 15-10](#figure15-10).
    You’ll need to update it to use the names of your three movies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This script will ask someone what sort of movies they like and then use your
    ML model to make a recommendation from the three movies in your library.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f15010](Images/f15010.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 15-10:](#figureanchor15-10) Create this script.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Design your project to look how you think a movie recommendation app should
    look. You can use the paint editor (Chapter 3), take photos with a webcam (Chapter
    4), upload a picture you’ve saved to the computer (Chapter 5), or choose a premade
    design from the Scratch libraries (Chapter 5) to update the backdrop and sprite.
    Be creative! [Figure 15-11](#figure15-11) shows my app.![f15011](Images/f15011.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 15-11:](#figureanchor15-11) Design your movie recommendation app.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **File**▶**Save to your computer** to save your project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test Your Project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Click the Green Flag and test your project.
  prefs: []
  type: TYPE_NORMAL
- en: Try typing a variety of sentences that describe the movies that you enjoy and
    see what your project recommends. Avoid using words or phrases that you put in
    the original training buckets to see if your ML model has learned to recognize
    new sentences.
  prefs: []
  type: TYPE_NORMAL
- en: Introduce Bias
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Click **Back to project** and then **Train** to return to the Train phase.
  prefs: []
  type: TYPE_NORMAL
- en: Now choose a fourth movie that is a bit similar to one of your first three.
    For my project, I chose *Frankenstein*, a horror film that’s a little similar
    to *Nosferatu*.
  prefs: []
  type: TYPE_NORMAL
- en: Click **Add new label** to add a new training bucket for your fourth film.
  prefs: []
  type: TYPE_NORMAL
- en: Delete a few of the training examples from the first film (*Nosferatu* in my
    case) and add them to your new film (*Frankenstein* for me) instead.
  prefs: []
  type: TYPE_NORMAL
- en: You should end up with something like [Figure 15-12](#figure15-12).
  prefs: []
  type: TYPE_NORMAL
- en: '![f15012](Images/f15012.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-12:](#figureanchor15-12) Move a few of the examples to the new film.'
  prefs: []
  type: TYPE_NORMAL
- en: Add another 12 examples to your new movie. You should end up with something
    like [Figure 15-13](#figure15-13).
  prefs: []
  type: TYPE_NORMAL
- en: '![f15013](Images/f15013.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-13:](#figureanchor15-13) Training examples for the new movie'
  prefs: []
  type: TYPE_NORMAL
- en: Click **Back to project** and then **Learn & Test**. Train a new ML model with
    the updated training examples.
  prefs: []
  type: TYPE_NORMAL
- en: When the training is finished, click **Back to project** and **Make** and then
    open **Scratch 3** again.
  prefs: []
  type: TYPE_NORMAL
- en: Click **File**▶**Load from your computer** to open the Scratch project that
    you saved before. Update it to add your new movie. This will mean adding a costume
    with the poster for your new movie and updating the script with a fourth `if`
    block to recognize and recommend your new movie, as shown in [Figure 15-14](#figure15-14).
  prefs: []
  type: TYPE_NORMAL
- en: '![f15014](Images/f15014.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-14:](#figureanchor15-14) Update your project to add the fourth movie.'
  prefs: []
  type: TYPE_NORMAL
- en: Test Your Biased Project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Try testing your project again. You should find that it has a preference for
    the new fourth movie, particularly over the one that’s similar to it.
  prefs: []
  type: TYPE_NORMAL
- en: For my project, that means if I mention anything about scary films, getting
    my heart racing or my adrenaline pumping, or monsters, my ML model will always
    recommend *Frankenstein* now—not *Nosferatu* as it did before. It isn’t balanced
    between sometimes recommending one and sometimes the other. It seems to have a
    preference, or a bias, toward *Frankenstein*. In fact, it’s difficult to get it
    to recommend *Nosferatu* at all unless I type a sentence exactly like one of my
    training examples.
  prefs: []
  type: TYPE_NORMAL
- en: Experiment with your project to see how it performs. Every ML model behaves
    a little differently, so try to get a feel for how the one you’ve trained is working.
  prefs: []
  type: TYPE_NORMAL
- en: Review Your Project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We talked in Chapter 8 about ways to measure the performance of an ML model,
    such as *precision* *and *recall**. If you calculate some of these values before
    and after you intentionally bias your ML model, you can measure how bias impacts
    your project.**
  prefs: []
  type: TYPE_NORMAL
- en: '**When you think you’ve identified the way your ML model is behaving, the next
    step is to understand why. Look at [Figure 15-13](#figure15-13) again. Why is
    my ML model recommending *Frankenstein* more often?'
  prefs: []
  type: TYPE_NORMAL
- en: When you collect training examples, you’re asking the computer to identify patterns
    in those examples, which it uses to learn to recognize new samples in the future.
    The number of examples you put in each bucket is one area where the computer looks
    for patterns. By putting many more examples in the *Frankenstein* training bucket,
    I influenced the ML model in a way that went beyond the individual training examples.
  prefs: []
  type: TYPE_NORMAL
- en: Say you’re teaching a child to recommend movies. Imagine you tell them 5 times
    that they should recommend Movie A, and 1,000 times you tell them that they should
    recommend Movie B. What impact would that have on their expectations? If you tell
    them over and over again that the right answer is Movie B, they’ll probably learn
    that the movie they should recommend is almost always Movie B.
  prefs: []
  type: TYPE_NORMAL
- en: This is similar to the way ML systems behave. The computer looks for patterns
    in all of your training examples in many, many ways. Your training tells it which
    of those ways it should trust more than others. If the training examples tell
    it over and over again that the patterns, techniques, and processes that tend
    to result in the answer Movie B are correct, it learns to trust those patterns,
    techniques, and processes. If the training examples tell it over and over again
    that the patterns, techniques, and processes that result in the answer Movie A
    are wrong, it learns not to trust them.
  prefs: []
  type: TYPE_NORMAL
- en: Even if it identifies patterns, techniques, and processes that result in the
    answer Movie A in the future, your training examples have trained it not to trust
    them and to prefer instead those that suggest Movie B.
  prefs: []
  type: TYPE_NORMAL
- en: As you have seen, the amount of training data in each bucket is an important
    factor in creating ML systems. An imbalance in the number of training examples
    in the different buckets can result in what we call a *biased* system.
  prefs: []
  type: TYPE_NORMAL
- en: The Case for Bias
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In most of the projects in this book so far, we’ve tried to keep the number
    of training examples in each bucket roughly the same. This is a common principle
    in many ML projects in an attempt to minimize bias.
  prefs: []
  type: TYPE_NORMAL
- en: But while bias is an important factor to keep in mind, it’s not necessarily
    always a bad thing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say you’re training a computer to recognize the difference between three possible
    outcomes: X, Y, and Z. Imagine that X and Y are very common; they are almost always
    the right answer. Outcome Z is possible, but it’s very, very rare. Even though
    Z hardly ever happens, you want to train the computer to be able to recognize
    it when it does.'
  prefs: []
  type: TYPE_NORMAL
- en: A balanced set of training examples, with the same number of examples for X,
    Y, and Z, might not be appropriate here. Having more training examples for X and
    Y, and fewer for Z, might train the ML model that X and Y are more likely, and
    in this case that’s correct. Outcomes X and Y *are*more common, and Z is rare.
    Such a system would still be biased, but the bias reflects the statistical likelihood
    of the different outcomes, and so it might actually be appropriate and helpful.
  prefs: []
  type: TYPE_NORMAL
- en: AI and Ethics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout this chapter, we’ve seen that the training you provide to an ML system
    will strongly influence the answers that it gives. What do you think this means
    for the responsibilities of the people who create AI systems? Do you think AI
    developers have an ethical responsibility to balance their training data or to
    avoid creating biased systems?
  prefs: []
  type: TYPE_NORMAL
- en: Does intention make a difference? If someone accidentally develops a biased
    system, is this more or less ethical than someone who wanted to influence the
    output of their system and intentionally skewed their training data?
  prefs: []
  type: TYPE_NORMAL
- en: Does money make a difference? In other words, if the producer of my fourth movie
    paid me lots of money to make my movie recommendation app prefer their movie over
    their competitors’ movies, would this be more or less ethical than me making a
    biased app that wouldn’t personally benefit me?
  prefs: []
  type: TYPE_NORMAL
- en: Does the subject make a difference? In other words, do you think that a biased
    AI movie recommendation app is less of an ethical concern than an AI app that
    makes medical treatment recommendations to doctors?
  prefs: []
  type: TYPE_NORMAL
- en: Imagine an ML recommendation app that recommends which medicines should be prescribed
    to patients. Each training bucket is a type of medicine, and the training examples
    it contains are medical records of patients for whom that medicine was the best
    treatment. Systems like this are in use today. ML systems can learn to recognize
    patterns in massive numbers of detailed medical records and combine this with
    evidence extracted from equally massive amounts of medical research and literature.
    It’s still early days for this sort of medical AI assistant application, but usage
    is going to increase significantly in the next few years.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you’ve seen for yourself how easy it is for such a system to be influenced
    to prefer one answer over another, does this affect your opinion of how such systems
    are used? In theory, it’s possible that the manufacturer of one drug could reward
    the developers of a medical AI application for biasing their ML model to prefer
    that drug over drugs from other manufacturers.
  prefs: []
  type: TYPE_NORMAL
- en: We are increasingly relying on ML systems to make important decisions that affect
    people’s lives. It’s not just in healthcare, either. ML systems make financial
    recommendations that banks and loan companies use to determine whether someone
    should be offered insurance, whether they can get a loan, or what interest rate
    they should be charged. ML systems will soon be driving the cars and trucks on
    our roads. And there are many more examples.
  prefs: []
  type: TYPE_NORMAL
- en: Forcing companies to be transparent and disclose how their ML systems are trained
    might be one way to protect against ethical problems. But you’ve seen how much
    effort is involved in preparing training data. Companies invest a lot of time
    and money in the training data they collect to make their ML systems better than
    those of their competitors, so many prefer to keep their training data secret.
    How would you balance these ethics issues with the commercial interests of companies?
  prefs: []
  type: TYPE_NORMAL
- en: Do you think protections are needed over how AI systems are trained or applied?
    If so, should AI ethics policies be developed by individual companies or by the
    government?
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is ending with more questions than answers, and this reflects the
    current state of ethics in AI. ML systems have the potential to improve all of
    our lives by training computers to do things that we couldn’t do otherwise. However,
    as a society, we need to address a number of questions about how comfortable we
    are applying this technology.
  prefs: []
  type: TYPE_NORMAL
- en: What You Learned
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this final project, you built on your knowledge of bias from Chapter 14 and
    created an ML model for a movie recommendation app that preferred one result over
    the others. You saw that having an imbalance in the number of examples used to
    train an ML model is another way to intentionally introduce bias into a system.
    You also learned that bias isn’t necessarily bad—and in some cases may even be
    appropriate—but it’s important to be aware of the ethical issues surrounding it,
    especially as AI systems become more common.**
  prefs: []
  type: TYPE_NORMAL
