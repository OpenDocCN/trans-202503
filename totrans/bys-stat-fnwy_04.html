<html><head></head><body>
<h2 class="h2" id="ch03"><span epub:type="pagebreak" id="page_21"/><strong><span class="big">3</span><br/>THE LOGIC OF UNCERTAINTY</strong></h2>&#13;
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>&#13;
<p class="noindent">In <a href="ch02.xhtml#ch02">Chapter 2</a>, we discussed how probabilities are an extension of the true and false values in logic and are expressed as values between 1 and 0. The power of probability is in the ability to express an infinite range of possible values between these extremes. In this chapter, we’ll discuss how the rules of logic, based on these logical operators, also apply to probability. In traditional logic, there are three important operators:</p>&#13;
<ul>&#13;
<li class="noindent">AND</li>&#13;
<li class="noindent">OR</li>&#13;
<li class="noindent">NOT</li>&#13;
</ul>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_22"/>With these three simple operators we can reason about any argument in traditional logic. For example, consider this statement: <em>If it is raining AND I am going outside, I will need an umbrella</em>. This statement contains just one logical operator: AND. Because of this operator we know that if it’s true that it is raining, AND it is true that I am going outside, I’ll need an umbrella.</p>&#13;
<p class="indent">We can also phrase this statement in terms of our other operators: <em>If it is NOT raining OR if I am NOT going outside, I will NOT need an umbrella</em>. In this case we are using basic logical operators and facts to make a decision about when we do and don’t need an umbrella.</p>&#13;
<p class="indent">However, this type of logical reasoning works well only when our facts have absolute true or false values. This case is about deciding whether I need an umbrella <em>right now</em>, so we can know for certain if it’s currently raining and whether I’m going out, and therefore I can easily determine if I need an umbrella. Suppose instead we ask, “Will I need an umbrella tomorrow?” In this case our facts become uncertain, because the weather forecast gives me only a probability for rain tomorrow and I may be uncertain whether or not I need to go out.</p>&#13;
<p class="indent">This chapter will explain how we can extend our three logical operators to work with probability, allowing us to reason about uncertain information the same way we can with facts in traditional logic. We’ve already seen how we can define NOT for probabilistic reasoning:</p>&#13;
<p class="equ">¬<em>P</em>(<em>X</em>) = 1 – <em>P</em>(<em>X</em>)</p>&#13;
<p class="indent">In the rest of this chapter we’ll see how we can use the two remaining operators, AND and OR, to combine probabilities and give us more accurate and useful data.</p>&#13;
<h3 class="h3" id="ch03lev1sec1"><strong>Combining Probabilities with AND</strong></h3>&#13;
<p class="noindent">In statistics we use AND to talk about the probability of combined events. For example, the probability of:</p>&#13;
<ul>&#13;
<li class="noindent">Rolling a 6 AND flipping a heads</li>&#13;
<li class="noindent">It raining AND you forgetting your umbrella</li>&#13;
<li class="noindent">Winning the lottery AND getting struck by lightning</li>&#13;
</ul>&#13;
<p class="indent">To understand how we can define AND for probability, we’ll start with a simple example involving a coin and a six-sided die.</p>&#13;
<h4 class="h4" id="ch03lev2sec1"><strong><em>Solving a Combination of Two Probabilities</em></strong></h4>&#13;
<p class="noindent">Suppose we want to know the probability of getting a heads in a coin flip AND rolling a 6 on a die. We know that the probability of <em>each</em> of these events individually is:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0022-01.jpg"/></div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_23"/>Now we want to know the probability of <em>both</em> of these things occurring, written as:</p>&#13;
<p class="equ"><em>P</em>(heads, six) = ?</p>&#13;
<p class="indent">We can calculate this the same way we did in <a href="ch02.xhtml#ch02">Chapter 2</a>: we count the outcomes we care about and divide that by the total outcomes.</p>&#13;
<p class="indent">For this example, let’s imagine these events happening in sequence. When we flip the coin we have two possible outcomes, heads and tails, as depicted in <a href="ch03.xhtml#ch03fig01">Figure 3-1</a>.</p>&#13;
<div class="image"><a id="ch03fig01"/><img alt="Image" src="../images/03fig01.jpg"/></div>&#13;
<p class="figcap"><em>Figure 3-1: Visualizing the two possible outcomes from a coin toss as distinct paths</em></p>&#13;
<p class="indent">Now, for each possible coin flip there are six possible results for the roll of our die, as depicted in <a href="ch03.xhtml#ch03fig02">Figure 3-2</a>.</p>&#13;
<div class="image"><a id="ch03fig02"/><img alt="Image" src="../images/03fig02.jpg"/></div>&#13;
<p class="figcap"><em>Figure 3-2: Visualizing the possible outcomes from a coin toss and the roll of a die</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_24"/>Using this visualization, we can just count our possible solutions. There are 12 possible outcomes of flipping a coin and rolling a die, and we care about only one of these outcomes, so:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0024-01.jpg"/></div>&#13;
<p class="indent">Now we have a solution for this particular problem. However, what we really want is a general rule that will help us calculate this for any number of probability combinations. Let’s see how to expand our solution.</p>&#13;
<h4 class="h4" id="ch03lev2sec2"><strong><em>Applying the Product Rule of Probability</em></strong></h4>&#13;
<p class="noindent">We’ll use the same problem for this example: what is the probability of flipping a heads and rolling a 6? First we need to figure out the probability of flipping a heads. Looking at our branching paths, we can figure out how many paths split off given the probabilities. We care only about the paths that include heads. Because the probability of heads is 1/2, we eliminate half of our possibilities. Then, if we look only at the remaining branch of possibilities for the heads, we can see that there is only a 1/6 chance of getting the result we want: rolling a 6 on a six-sided die. In <a href="ch03.xhtml#ch03fig03">Figure 3-3</a> we can visualize this reasoning and see that there is only one outcome we care about.</p>&#13;
<div class="image"><a id="ch03fig03"/><img alt="Image" src="../images/03fig03.jpg"/></div>&#13;
<p class="figcap"><em>Figure 3-3: Visualizing the probability of both getting a heads and rolling a 6</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_25"/>If we multiply these two probabilities, we can see that:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0025-01.jpg"/></div>&#13;
<p class="indent">This is exactly the answer we had before, but rather than counting all possible events, we counted only the probabilities of the events we care about by following along the branches. This is easy enough to do visually for such a simple problem, but the real value of showing you this is that it illustrates a general rule for combining probabilities with AND:</p>&#13;
<p class="equ"><em>P</em>(<em>A</em>,<em>B</em>) = <em>P</em>(<em>A</em>) × <em>P</em>(<em>B</em>)</p>&#13;
<p class="indent">Because we are multiplying our results, also called taking the <em>product</em> of these results, we refer to this as the <em>product rule</em> of probability.</p>&#13;
<p class="indent">This rule can then be expanded to include more probabilities. If we think of <em>P</em>(<em>A</em>,<em>B</em>) as a single probability, we can combine it with a third probability, <em>P</em>(<em>C</em>), by repeating this process:</p>&#13;
<p class="equ"><em>P</em>(<em>P</em>(<em>A</em>,<em>B</em>),<em>C</em>) = <em>P</em>(<em>A</em>,<em>B</em>) × <em>P</em>(<em>C</em>) = <em>P</em>(<em>A</em>) × <em>P</em>(<em>B</em>) × <em>P</em>(<em>C</em>)</p>&#13;
<p class="indent">So we can use our product rule to combine an unlimited number of events to get our final probability.</p>&#13;
<h4 class="h4" id="ch03lev2sec3"><strong><em>Example: Calculating the Probability of Being Late</em></strong></h4>&#13;
<p class="noindent">Let’s look at an example of using the product rule for a slightly more complex problem than rolling dice or flipping coins. Suppose you promised to meet a friend for coffee at 4:30 on the other side of town, and you plan to take public transportation. It’s currently 3:30. Thankfully the station you’re at has both a train and bus that can take you where you need to go:</p>&#13;
<ul>&#13;
<li class="noindent">The next bus comes at 3:45 and takes 45 minutes to get you to the coffee shop.</li>&#13;
<li class="noindent">The next train comes at 3:50, and will get you within a 10-minute walk in 30 minutes.</li>&#13;
</ul>&#13;
<p class="indent">Both the train and the bus will get you there at 4:30 exactly. Because you’re cutting it so close, any delay will make you late. The good news is that, since the bus arrives before the train, if the bus is late and the train is not you’ll still be on time. If the bus is on time and the train is late, you’ll also be fine. The only situation that will make you late is if both the bus and the train are late to arrive. How can you figure out the probability of being late?</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_26"/>First, you need to establish the probability of both the train being late and the bus being late. Let’s assume the local transit authority publishes these numbers (later in the book, you’ll learn how to estimate this from data).</p>&#13;
<p class="equ"><em>P</em>(Late<sub>train</sub>) = 0.15<br/><em>P</em>(Late<sub>bus</sub>) = 0.2</p>&#13;
<p class="indent">The published data tells us that 15 percent of the time the train is late, and 20 percent of the time the bus is late. Since you’ll be late only if <em>both</em> the bus and the train are late, we can use the product rule to solve this problem:</p>&#13;
<p class="equ"><em>P</em>(Late) = <em>P</em>(Late<sub>train</sub>) × <em>P</em>(Late<sub>bus</sub>) = 0.15 × 0.2 = 0.03</p>&#13;
<p class="indent">Even though there’s a pretty reasonable chance that either the bus or the train will be late, the probability that they will both be late is significantly less, at only 0.03. We can also say there is a 3 percent chance that both will be late. With this calculation done, you can be a little less stressed about being late.</p>&#13;
<h3 class="h3" id="ch03lev1sec2"><strong>Combining Probabilities with OR</strong></h3>&#13;
<p class="noindent">The other essential rule of logic is combining probabilities with OR, some examples of which include:</p>&#13;
<ul>&#13;
<li class="noindent">Catching the flu OR getting a cold</li>&#13;
<li class="noindent">Flipping a heads on a coin OR rolling a 6 on a die</li>&#13;
<li class="noindent">Getting a flat tire OR running out of gas</li>&#13;
</ul>&#13;
<p class="indent">The probability of one event OR another event occurring is slightly more complicated because the events can either be mutually exclusive or not mutually exclusive. Events are <em>mutually exclusive</em> if one event happening implies the other possible events cannot happen. For example, the possible outcomes of rolling a die are mutually exclusive because a single roll cannot yield both a 1 and a 6. However, say a baseball game will be cancelled if it is either raining or the coach is sick; these events are <em>not</em> mutually exclusive because it is perfectly possible that the coach is sick and it rains.</p>&#13;
<h4 class="h4" id="ch03lev2sec4"><strong><em>Calculating OR for Mutually Exclusive Events</em></strong></h4>&#13;
<p class="noindent">The process of combining two events with OR feels logically intuitive. If you’re asked, “What is the probability of getting heads or tails on a coin toss?” you would say, “1.” We know that:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0026-01.jpg"/></div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_27"/>Intuitively, we might just add the probability of these events together. We know this works because heads and tails are the only possible outcomes, and the probability of all possible outcomes must equal 1. If the probabilities of all possible events did not equal 1, then we would have some outcome that was missing. So how do we know that there would need to be a missing outcome if the sum was less than 1?</p>&#13;
<p class="indent">Suppose we know that the probability of heads is <em>P</em>(heads) = 1/2, but someone claimed that the probability of tails was <em>P</em>(tails) = 1/3. We also know from before that the probability of not getting heads must be:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0027-01.jpg"/></div>&#13;
<p class="indent">Since the probability of not getting heads is 1/2 and the claimed probability for tails is only 1/3, either there is a missing event or our probability for tails is incorrect.</p>&#13;
<p class="indent">From this we can see that, as long as events are mutually exclusive, we can simply add up all of the probabilities of each possible event to get the probability of either event happening to calculate the probability of one event OR the other. Another example of this is rolling a die. We know that the probability of rolling a 1 is 1/6, and the same is true for rolling a 2:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0027-02.jpg"/></div>&#13;
<p class="indent">So we can perform the same operation, adding the two probabilities, and see that the combined probability of rolling either a 1 OR a 2 is 2/6, or 1/3:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0027-03.jpg"/></div>&#13;
<p class="noindent">Again, this makes intuitive sense.</p>&#13;
<p class="indent">This addition rule applies only to combinations of <em>mutually exclusive</em> outcomes. In probabilistic terms, mutually exclusive means that:</p>&#13;
<p class="equ"><em>P</em>(<em>A</em>) AND <em>P</em>(<em>B</em>) = 0</p>&#13;
<p class="indent">That is, the probability of getting both <em>A</em> AND <em>B</em> together is 0. We see that this holds for our examples:</p>&#13;
<ul>&#13;
<li class="noindent">It is impossible to flip one coin and get both heads and tails.</li>&#13;
<li class="noindent">It is impossible to roll both a 1 and a 2 on a single roll of a die.</li>&#13;
</ul>&#13;
<p class="indent">To really understand combining probabilities with OR, we need to look at the case where events are <em>not</em> mutually exclusive.</p>&#13;
<h4 class="h4" id="ch03lev2sec5"><span epub:type="pagebreak" id="page_28"/><strong><em>Using the Sum Rule for Non–Mutually Exclusive Events</em></strong></h4>&#13;
<p class="noindent">Again using the example of rolling a die and flipping a coin, let’s look at the probability of either flipping heads OR rolling a 6. Many newcomers to probability may naively assume that adding probabilities will work in this case as well. Given that we know that <em>P</em>(heads) = 1/2 and <em>P</em>(six) = 1/6, it might initially seem plausible that the probability of either of these events is simply 4/6. It becomes obvious that this doesn’t work, however, when we consider the possibility of either flipping a heads or rolling a number less than 6. Because <em>P</em>(less than six) = 5/6, adding these probabilities together gives us 8/6, which is greater than 1! Since this violates the rule that probabilities must be between 0 and 1, we must have made a mistake.</p>&#13;
<p class="indent">The trouble is that flipping a heads and rolling a 6 are not mutually exclusive. As we know from earlier in the chapter, <em>P</em>(heads, six) = 1/12. Because the probability of both events happening at the same time is not 0, we know they are, by definition, not mutually exclusive.</p>&#13;
<p class="indent">The reason that adding our probabilities doesn’t work for non–mutually exclusive events is that doing so doubles the counting of events where both things happen. As an example of overcounting, let’s look at all of the outcomes of our combined coin toss and die roll that contain heads:</p>&#13;
<p class="equ">Heads — 1<br/>Heads — 2<br/>Heads — 3<br/>Heads — 4<br/>Heads — 5<br/>Heads — 6</p>&#13;
<p class="indent">These outcomes represent 6 out of the 12 possible outcomes, which we expect since <em>P</em>(heads) = 1/2. Now let’s look at all outcomes that include rolling a 6:</p>&#13;
<p class="equ">Heads — 6<br/>Tails — 6</p>&#13;
<p class="indent">These outcomes represent the 2 out of 12 possible outcomes that will result in us rolling a 6, which again we expect because <em>P</em>(six) = 1/6. Since there are six outcomes that satisfy the condition of flipping a heads and two that satisfy the condition of rolling a 6, we might be tempted to say that there are eight outcomes that represent getting either heads or rolling a 6. However, we would be double-counting because <em>Heads — 6</em> appears in both lists. There are, in fact, only 7 out of 12 unique outcomes. If we naively add <em>P</em>(heads) and <em>P</em>(six), we end up overcounting.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_29"/>To correct our probabilities, we must add up all of our probabilities and then subtract the probability of both events occurring. This leads us to the rule for combining non–mutually exclusive probabilities with OR, known as the <em>sum rule</em> of probability:</p>&#13;
<p class="equ"><em>P</em>(<em>A</em>) OR <em>P</em>(<em>B</em>) = <em>P</em>(<em>A</em>) + <em>P</em>(<em>B</em>) – <em>P</em>(<em>A</em>,<em>B</em>)</p>&#13;
<p class="indent">We add the probability of each event happening and then subtract the probability of both events happening, to ensure we are not counting these probabilities twice since they are a part of both <em>P</em>(<em>A</em>) and <em>P</em>(<em>B</em>). So, using our die roll and coin toss example, the probability of rolling a number less than 6 or flipping a heads is:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0029-01.jpg"/></div>&#13;
<p class="indent">Let’s take a look at a final OR example to really cement this idea.</p>&#13;
<h4 class="h4" id="ch03lev2sec6"><strong><em>Example: Calculating the Probability of Getting a Hefty Fine</em></strong></h4>&#13;
<p class="noindent">Imagine a new scenario. You were just pulled over for speeding while on a road trip. You realize you haven’t been pulled over in a while and may have forgotten to put either your new registration or your new insurance card in the glove box. If either one of these is missing, you’ll get a more expensive ticket. Before you open the glove box, how can you assign a probability that you’ll have forgotten one or the other of your cards and you’ll get the higher ticket?</p>&#13;
<p class="indent">You’re pretty confident that you put your registration in the car, so you assign a 0.7 probability to your registration being in the car. However, you’re also pretty sure that you left your insurance card on the counter at home, so you assign only a 0.2 chance that your new insurance card is in the car. So we know that:</p>&#13;
<p class="equ"><em>P</em>(registration) = 0.7<br/><em>P</em>(insurance) = 0.2</p>&#13;
<p class="indent">However, these values are the probabilities that you <em>do</em> have these things in the glove box. You’re worried about whether either one is <em>missing</em>. To get the probabilities of missing items, we simply use negation:</p>&#13;
<p class="equ"><em>P</em>(Missing<sub>reg</sub>) = 1 – <em>P</em>(registration) = 0.3<br/><em>P</em>(Missing<sub>ins</sub>) = 1 – <em>P</em>(insurance) = 0.8</p>&#13;
<p class="indent">If we try using our addition method, instead of the complete sum rule, to get the combined probability, we see that we have a probability greater than 1:</p>&#13;
<p class="equ"><em>P</em>(Missing<sub>reg</sub>) + <em>P</em>(Missing<sub>ins</sub>) = 1.1</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_30"/>This is because these events are non–mutually exclusive: it’s entirely possible that you have forgotten both cards. Therefore, using this method we’re double-counting. That means we need to figure out the probability that you’re missing both cards so we can subtract it. We can do this with the product rule:</p>&#13;
<p class="equ"><em>P</em>(Missing<sub>reg</sub>, Missing<sub>ins</sub>) = 0.24</p>&#13;
<p class="indent">Now we can use the sum rule to determine the probability that either one of these cards is missing, just as we worked out the probability of a flipping a heads or rolling a 6:</p>&#13;
<p class="equ"><em>P</em>(Missing) = <em>P</em>(Missing<sub>reg</sub>) + <em>P</em>(Missing<sub>ins</sub>) – <em>P</em>(Missing<sub>reg</sub>, Missing<sub>ins</sub>) = 0.86</p>&#13;
<p class="indent">With an 0.86 probability that one of these important pieces of paper is missing from your glove box, you should make sure to be extra nice when you greet the officer!</p>&#13;
<h3 class="h3" id="ch03lev1sec3"><strong>Wrapping Up</strong></h3>&#13;
<p class="noindent">In this chapter you developed a complete logic of uncertainty by adding rules for combining probabilities with AND and OR. Let’s review the logical rules we have covered so far.</p>&#13;
<p class="indent">In <a href="ch02.xhtml#ch02">Chapter 2</a>, you learned that probabilities are measured on a scale of 0 to 1, 0 being <em>false</em> (definitely not going to happen), and 1 being <em>true</em> (definitely going to happen). The next important logical rule involves combining two probabilities with AND. We do this using the product rule, which simply states that to get the probability of two events occurring together, <em>P</em>(<em>A</em>) and <em>P</em>(<em>B</em>), we just multiply them together:</p>&#13;
<p class="equ"><em>P</em>(<em>A</em>,<em>B</em>) = <em>P</em>(<em>A</em>) × <em>P</em>(<em>B</em>)</p>&#13;
<p class="indent">The final rule involves combining probabilities with OR using the sum rule. The tricky part of the sum rule is that if we add non–mutually exclusive probabilities, we’ll end up overcounting for the case where they both occur, so we have to subtract the probability of both events occurring together. The sum rule uses the product rule to solve this (remember, for mutually exclusive events, <em>P</em>(<em>A</em>, <em>B</em>) = 0):</p>&#13;
<p class="equ"><em>P</em>(<em>A</em> OR <em>B</em>) = <em>P</em>(<em>A</em>) + <em>P</em>(<em>B</em>) – <em>P</em>(<em>A</em>,<em>B</em>)</p>&#13;
<p class="indent">These rules, along with those covered in <a href="ch02.xhtml#ch02">Chapter 2</a>, allow us to express a very large range of problems. We’ll be using these as the foundation for our probabilistic reasoning throughout the rest of the book.</p>&#13;
<h3 class="h3" id="ch03lev1sec4"><span epub:type="pagebreak" id="page_31"/><strong>Exercises</strong></h3>&#13;
<p class="noindent">Try answering the following questions to make sure you understand the rules of logic as they apply to probability. The solutions can be found at <em><a href="https://nostarch.com/learnbayes/">https://nostarch.com/learnbayes/</a></em>.</p>&#13;
<ol>&#13;
<li class="noindent">What is the probability of rolling a 20 three times in a row on a 20-sided die?</li>&#13;
<li class="noindent">The weather report says there’s a 10 percent chance of rain tomorrow, and you forget your umbrella half the time you go out. What is the probability that you’ll be caught in the rain without an umbrella tomorrow?</li>&#13;
<li class="noindent">Raw eggs have a 1/20,000 probability of having salmonella. If you eat two raw eggs, what is the probability you ate a raw egg with salmonella?</li>&#13;
<li class="noindent">What is the probability of either flipping two heads in two coin tosses or rolling three 6s in three six-sided dice rolls?<span epub:type="pagebreak" id="page_32"/></li>&#13;
</ol>&#13;
</body></html>