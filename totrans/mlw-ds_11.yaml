- en: '**11**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BUILDING A NEURAL NETWORK MALWARE DETECTOR WITH KERAS
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/common01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A decade ago, building a functioning, scalable, and fast neural network was
    time consuming and required quite a lot of code. In the past few years, however,
    this process has become far less painful, as more and more high-level interfaces
    to neural network design have been developed. The Python package `Keras` is one
    of these interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I walk you through how to build a sample neural network using
    the `Keras` package. First, I explain how to define a model’s architecture in
    `Keras`. Second, we train this model to differentiate between benign and malicious
    HTML files, and you learn how to save and load such models. Third, using the Python
    package `sklearn`, you learn how to evaluate the model’s accuracy on validation
    data. Finally, we use what you’ve learned to integrate validation accuracy reporting
    into the model training process.
  prefs: []
  type: TYPE_NORMAL
- en: I encourage you to read this chapter while reading and editing the associated
    code in the data accompanying this book. You can find all the code discussed in
    this chapter there (organized into parameterized functions to make things easier
    to run and adjust), as well as a few extra examples. By the end of this chapter,
    you’ll feel ready to start building some networks of your own!
  prefs: []
  type: TYPE_NORMAL
- en: 'To run code listings in this chapter, you not only need to install the packages
    listed in this chapter’s *ch11/requirements.txt* file (`pip install –r requirements.txt`),
    but also follow the directions to install one of `Keras`’s backend engines on
    your system (TensorFlow, Theano, or CNTK). Install TensorFlow by following the
    directions here: *[https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)*.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Defining a Model’s Architecture**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To build a neural network, you need to define its architecture: which neurons
    go where, how they connect to subsequent neurons, and how data flows through the
    whole thing. Luckily, `Keras` provides a simple, flexible interface to define
    all this. `Keras` actually supports two similar syntaxes for model definition,
    but we’re going to use the Functional API syntax, as it’s more flexible and powerful
    that the other (“sequential”) syntax.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When designing a model, you need three things: input, stuff in the middle that
    processes the input, and output. Sometimes your models will have multiple inputs,
    multiple outputs, and very complex stuff in the middle, but the basic idea is
    that when defining a model’s architecture, you’re just defining how the input—your
    data, such as features relating to an HTML file—flows through various neurons
    (stuff in the middle), until finally the last neurons end up yielding some output.'
  prefs: []
  type: TYPE_NORMAL
- en: To define this architecture, `Keras` uses layers. A *layer* is a group of neurons
    that all use the same type of activation function, all receive data from a previous
    layer, and all send their outputs to a subsequent layer of neurons. In a neural
    network, input data is generally fed to an initial layer of neurons, which sends
    its outputs to a subsequent layer, which sends its outputs to another layer, and
    so on and so forth, until the last layer of neurons generates the network’s final
    output.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 11-1](ch11.xhtml#ch11list1) is an example of a simple model defined
    using `Keras`’s functional API syntax. I encourage you to open a new Python file
    to write and run the code yourself as we walk through the code, line by line.
    Alternatively, you can try running the associated code in the data accompanying
    this book, either by copying and pasting parts of the *ch11/model_architecture.py*
    file into an ipython session or by running `python` `ch11``/model_architecture.py`
    in a terminal window.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-1: Defining a simple model using functional API syntax*'
  prefs: []
  type: TYPE_NORMAL
- en: First, we import the `Keras` package’s `layers` submodule ➊ as well as the `Model`
    class from `Keras`’s `models` submodule ➋.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we specify what kind of data this model will accept for one observation
    by passing a `shape` value (a tuple of integers) ➌ and a data type (string) ➍
    to the `layers.Input()` function. Here, we declared that the input data to our
    model will be an array of 1,024 floats. If our input was, for example, a matrix
    of integers instead, the first line would look more like `input = Input(shape=(100,
    100,) dtype='int32')`.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*If the model takes in variable-sized inputs on one dimension, you can use*
    None *instead of a number—for example,* (100, None,)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we specify the layer of neurons that this input data will be sent to.
    To do this, we again use the `layers` submodule we imported, specifically the
    `Dense` function ➎, to specify that this layer will be a densely connected (also
    called fully connected) layer, which means that every output from the previous
    layer is sent to every neuron in this layer. `Dense` is the most common type of
    layer you’ll likely use when developing `Keras` models. Others allow you to do
    things like change the shape of the data (`Reshape`) and implement your own custom
    layer (`Lambda`).
  prefs: []
  type: TYPE_NORMAL
- en: 'We pass the `Dense` function two arguments: `units=512`, to specify that we
    want 512 neurons in this layer, and `activation=''relu''`, to specify that we
    want these neurons to be rectified linear unit (ReLU) neurons. (Recall from [Chapter
    10](ch10.xhtml#ch10) that ReLU neurons use a simple type of activation function
    that outputs whichever is larger: either 0, or the weighted sum of the neuron’s
    inputs.) We use `layers.Dense(units=512, activation=''relu'')` to define the layer,
    and then the last part of the line—`(input)`—declares the input to this layer
    (namely, our `input` object). It’s important to understand that this passing of
    `input` to our layer is how data flow is defined in the model, as opposed to the
    ordering of the lines of the code.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next line, we define our model’s output layer, which again uses the `Dense`
    function. But this time, we designate only a single neuron to the layer and use
    a `'sigmoid'` activation function ➏, which is great for combining a lot of data
    into a single score between 0 and 1\. The output layer takes the `(middle)` object
    as input, declaring that the outputs from our 512 neurons in our `middle` layer
    should all be sent to this neuron.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve defined our layers, we use the `Model` class from the `models`
    submodule to wrap up all these layers together as a model ➐. Note that you *only*
    have to specify your input layer(s) and output layer(s). Because each layer after
    the first is given the preceding layer as input, the final output layer contains
    all the information the model needs about the previous layers. We could have 10
    more `middle` layers declared between our `input` and `output` layers, but the
    line of code at ➐ would remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: '**Compiling the Model**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, we need to compile our model. We’ve defined the model’s architecture
    and flow of data, but we haven’t yet specified how we want the model to perform
    its training. To do this, we use our `model`’s own `compile` method and pass it
    three parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: The first parameter, `optimizer` ➑, specifies the type of backpropagation algorithm
    to use. You can specify the name of the algorithm you wish to use via a character
    string like we did here, or you can import an algorithm directly from `keras.optimizers`
    to pass in specific parameters to the algorithm or even design your own.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `loss` parameter ➒ specifies the thing that is minimized during the training
    process (backpropagation). Specifically, this specifies the formula you wish to
    use to represent the difference between your true training labels and your model’s
    predicted labels (output). Again, you can specify the name of a loss function,
    or pass in an actual function, like `keras.losses.mean_squared_error`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, for the `metrics` parameter ➓, you can pass a list of metrics that you
    want `Keras` to report when analyzing model performance during and after training.
    Again, you can pass strings or actual metric functions, like `['categorical_accuracy',
    keras.metrics.top_k_categorical_accuracy]`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After running the code in [Listing 11-1](ch11.xhtml#ch11list1), run `model.summary()`
    to see the model structure printed to your screen. Your output should look something
    like [Figure 11-1](ch11.xhtml#ch11fig1).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0202-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-1: Output of* model.summary()'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 11-1](ch11.xhtml#ch11fig1) shows the output of `model.summary()`. Each
    layer’s description is printed to the screen, along with the number of parameters
    associated with that layer. For example, the `dense_1` layer has 524,800 parameters
    because each of its 512 neurons gets a copy of each of the 1,024 input values
    from the input layer, meaning that there are 1,024 × 512 weights. Add 512 bias
    parameters, and you get 1,024 × 512 + 512 = 524,800.'
  prefs: []
  type: TYPE_NORMAL
- en: Although we haven’t yet trained our model or tested it on validation data, this
    is a compiled `Keras` model that is ready to train!
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Check out the sample code in* ch11/model_architecture.py *for an example of
    a slightly more complex model!*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Training the Model**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To train our model, we need training data. The virtual machine that comes with
    this book includes a set of about half a million benign and malicious HTML files.
    This consists of two folders of benign (*ch11/data/html/benign_files/*) and malicious
    (*ch11/data/html/malicious_files/*) HTML files. (Remember not to open these files
    in a browser!) In this section, we use these to train our neural network to predict
    whether an HTML file is benign (0) or malicious (1).
  prefs: []
  type: TYPE_NORMAL
- en: '***Extracting Features***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To do this, we first need to decide how to represent our data. In other words,
    what features do we want to extract from each HTML file to use as input to our
    model? For example, we could simply pass the first 1,000 characters in each HTML
    file to the model, we could pass in the frequency counts of all letters in the
    alphabet, or we could use an HTML parser to develop some more complex features.
    To make things easier, we’ll transform each variable-length, potentially very
    large HTML file into a uniformly sized, compressed representation that allows
    our model to quickly process and learn important patterns.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we transform each HTML file into a 1,024-length vector of category
    counts, where each category count represents the number of tokens in the HTML
    file whose hash resolved to the given category. [Listing 11-2](ch11.xhtml#ch11list2)
    shows the feature extraction code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-2: Feature extraction code*'
  prefs: []
  type: TYPE_NORMAL
- en: You don’t have to understand all the details of this code to understand how
    `Keras` works, but I encourage you to read through the comments in the code to
    better understand what’s going on.
  prefs: []
  type: TYPE_NORMAL
- en: The `extract_features` function starts by reading in an HTML file as a big string
    ➋ and then splits up this string into a set of tokens based on a regular expression
    ➌. Next, the numeric hash of each token is taken, and these hashes are divided
    into categories by taking the modulo of each hash ➍. The final set of features
    is the number of hashes in each category ➎, like a histogram bin count. If you
    want, you can try altering the regular expression `split_regex` ➊ that splits
    up the HTML file into chunks to see how it affects the resulting tokens and features.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you skipped or didn’t understand all that, that’s okay: just know that our
    `extract_features` function takes the path to an HTML file as input and then transforms
    it into a feature array of length 1,024, or whatever `hash_dim` is.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Creating a Data Generator***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now we need to make our `Keras` model actually train on these features. When
    working with small amounts of data already loaded into memory, you can use a simple
    line of code like [Listing 11-3](ch11.xhtml#ch11list3) to train your model in
    `Keras`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-3: Training your model when data is already loaded into memory*'
  prefs: []
  type: TYPE_NORMAL
- en: However, this isn’t really useful when you start working with large amounts
    of data, because you can’t fit all your training data into your computer’s memory
    at once. To get around this, we use the slightly more complex but more scalable
    `model.fit_generator` function. Instead of passing in all the training data at
    once to this function, you pass a generator that yields training data in batches
    so that your computer’s RAM won’t choke.
  prefs: []
  type: TYPE_NORMAL
- en: Python generators work just like Python functions, except they have a `yield`
    statement. Instead of returning a single result, generators return an object that
    can be called again and again to yield many, or infinite, sets of results. [Listing
    11-4](ch11.xhtml#ch11list4) shows how we can create our own data generator using
    our feature extraction function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-4: Writing a data generator*'
  prefs: []
  type: TYPE_NORMAL
- en: First, the code makes two `assert` statements to check that enough data is there
    ➊. Then inside a `while` ➋ loop (so it’ll just iterate forever), both benign and
    malicious features are grabbed by choosing a random sample ➍ of file keys and
    then extracting features for those files using our `extract_features` function
    ➌. Next, the benign and malicious features and associated labels (0 and 1) are
    concatenated ➎ and shuffled ➏. Finally, these features and labels are returned
    ➐.
  prefs: []
  type: TYPE_NORMAL
- en: Once instantiated, this generator should yield `batch_size` features and labels
    for the model to train on (50 percent malicious, 50 percent benign) each time
    the generator’s `next()` method is called.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 11-5](ch11.xhtml#ch11list5) shows how to create a training data generator
    using the data that comes with this book, and how to train our model by passing
    the generator to our model’s `fit_generator` method.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-5: Creating the training generator and using it to train the model*'
  prefs: []
  type: TYPE_NORMAL
- en: Try reading through this code to understand what’s happening. After importing
    a necessary package and creating some parameter variables, we read the filenames
    for our benign ➊ and malicious training data ➋ into memory (but not the files
    themselves). We pass these values to our new `my_generator` function ➌ to get
    our training data generator. Finally, using our `model` from [Listing 11-1](ch11.xhtml#ch11list1),
    we use the `model`’s built-in `fit_generator` method ➍ to start training.
  prefs: []
  type: TYPE_NORMAL
- en: The `fit_generator` method takes three parameters. The `generator` parameter
    ➎ specifies the data generator that produces training data for each *batch*. During
    training, parameters are updated once per batch by averaging all the training
    observations’ signals for that batch. The `steps_per_epoch` parameter ➏ sets the
    number of batches we want the model to process each *epoch*. As a result, the
    total number of observations the model sees per epoch is `batch_size*steps_per_epoch`.
    By convention, the number of observations a model sees per epoch should be equal
    to the dataset size, but in this chapter and in the virtual machine sample code,
    I reduce `steps_per_epoch` to make our code run faster. The `epochs` parameter
    ➐ sets the number of epochs we want to run.
  prefs: []
  type: TYPE_NORMAL
- en: Try running this code in the *ch11/* directory that accompanies this book. Depending
    on the power of your computer, each training epoch will take a certain amount
    of time to run. If you’re using an interactive session, feel free to cancel the
    process (CTRL-C) after a few epochs if it’s taking a while. This will stop the
    training without losing progress. After you cancel the process (or the code completes),
    you’ll have a trained model! The readout on your virtual machine screen should
    look something like [Figure 11-2](ch11.xhtml#ch11fig2).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0207-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-2: Console output from training a* Keras *model*'
  prefs: []
  type: TYPE_NORMAL
- en: The top few lines note that TensorFlow, which is the default backend to `Keras`,
    has been loaded. You’ll also see some warnings like in [Figure 11-2](ch11.xhtml#ch11fig2);
    these just mean that the training will be done on CPUs instead of GPUs (GPUs are
    often around 2–20 times faster for training neural networks, but for the purposes
    of this book, CPU-based training is fine). Finally, you’ll see a progress bar
    for each epoch indicating how much longer the given epoch will take, as well as
    the epoch’s loss and accuracy metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '***Incorporating Validation Data***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the previous section, you learned how to train a `Keras` model on HTML files
    using the scalable `fit_generator` method. As you saw, the model prints statements
    during training, indicating each epoch’s current loss and accuracy statistics.
    However, what you really care about is how your trained model does on *validation
    data*, or data that it has never seen before. This better represents the kind
    of data your model will face in a real-life production environment.
  prefs: []
  type: TYPE_NORMAL
- en: When trying to design better models and figure out how long to train your model
    for, you should try to maximize *validation accuracy* rather than *training accuracy*,
    the latter of which was shown in [Figure 11-2](ch11.xhtml#ch11fig2). Even better
    would be using validation files originating from dates after the training data
    to better simulate a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 11-6](ch11.xhtml#ch11list6) shows how to load our validation features
    into memory using our `my_generator` function from [Listing 11-4](ch11.xhtml#ch11list4).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-6: Reading validation features and labels into memory by using
    the* my_generator *function*'
  prefs: []
  type: TYPE_NORMAL
- en: This code is very similar to how we created our training data generator, except
    that the file paths have changed and now we want to load all the validation data
    into memory. So instead of just creating the generator, we create a validation
    data generator ➊ with a large `batch_size` ➋ equal to the number of files we want
    to validate on, and we immediately call its `.next()` ➌ method just once.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have some validation data loaded into memory, `Keras` allows us
    to simply pass `fit_generator()` our validation data during training, as shown
    in [Listing 11-7](ch11.xhtml#ch11list7).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-7: Using validation data for automatic monitoring during training*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 11-7](ch11.xhtml#ch11list7) is almost identical to the end of [Listing
    11-5](ch11.xhtml#ch11list5), except that `validation_data` is now passed to `fit_generator`
    ➊. This helps enhance model monitoring by ensuring that validation loss and accuracy
    are calculated alongside training loss and accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, training statements should look something like [Figure 11-3](ch11.xhtml#ch11fig3).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0208-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-3: Console output from training a* Keras *model with validation
    data*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 11-3](ch11.xhtml#ch11fig3) is similar to [Figure 11-2](ch11.xhtml#ch11fig2),
    except that instead of just showing training `loss` and `acc` metrics for each
    epoch, now `Keras` also calculates and shows `val_loss` (validation loss) and
    `val_acc` (validation accuracy) for each epoch. In general, if validation accuracy
    is going down instead of up, that’s an indication your model is overfitting to
    your training data, and it would be best to halt training. If validation accuracy
    is going up, as is the case here, it means your model is still getting better
    and you should continue training.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Saving and Loading the Model***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now that you know how to build and train a neural network, let’s go over how
    to save it so you can share it with others.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 11-8](ch11.xhtml#ch11list8) shows how to save our trained model to
    an *.h5* file ➊ and reload ➋ it (at a potentially later date).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-8: Saving and loading* Keras *models*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Evaluating the Model**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the model training section, we observed some default model evaluation metrics
    like training loss and accuracy as well as validation loss and accuracy. Let’s
    now review some more complex metrics to better evaluate our models.
  prefs: []
  type: TYPE_NORMAL
- en: One useful metric for evaluating the accuracy of a binary predictor is called
    *area under the curve (AUC)*. The curve refers to a Receiver Operating Characteristic
    (ROC) curve (see [Chapter 8](ch08.xhtml#ch08)), which plots false-positive rates
    (x-axis) against true-positive rates (y-axis) for all possible score thresholds.
  prefs: []
  type: TYPE_NORMAL
- en: For example, our model tries to predict whether a file is malicious by using
    a score between 0 (benign) and 1 (malicious). If we choose a relatively high score
    threshold to classify a file as malicious we’ll get fewer false-positives (good)
    but also fewer true-positives (bad). On the other hand, if we choose a low score
    threshold, we’ll likely have a high false-positive rate (bad) but a very high
    detection rate (good).
  prefs: []
  type: TYPE_NORMAL
- en: These two sample possibilities would be represented as two points on our model’s
    ROC curve, where the first would be located toward the left side of the curve
    and the second near the right side. AUC represents all these possibilities by
    simply taking the area under this ROC curve, as shown in [Figure 11-4](ch11.xhtml#ch11fig4).
  prefs: []
  type: TYPE_NORMAL
- en: In simple terms, an AUC of 0.5 represents the predictive capability of a coin
    flip, while an AUC of 1 is perfect.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0210-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-4: Various sample ROC curves. Each ROC curve (line) corresponds
    to a different AUC value.*'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use our validation data to calculate validation AUC using the code in
    [Listing 11-9](ch11.xhtml#ch11list9).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-9: Calculating validation AUC using* sklearn*’s* metric *submodule*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we split our `validation_data` tuple into two objects: the validation
    labels represented by `validation_labels` ➊, and flattened validation model predictions
    represented by `validation_scores` ➋. Then, we use the `metrics.roc_curve` function
    from `sklearn` to calculate false-positive rates, true-positive rates, and associated
    threshold values for the model predictions ➌. Using these, we calculate our AUC
    metric, again using an `sklearn` function ➍.'
  prefs: []
  type: TYPE_NORMAL
- en: Although I won’t go over the function code here, you can also use the `roc_plot()`
    function included in the *ch11/model_evaluation.py* file in the data accompanying
    this book to plot the actual ROC curve, as shown in [Listing 11-10](ch11.xhtml#ch11list10).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-10: Creating a ROC curve plot using the* roc_plot *function from
    this book’s accompanying data, in* ch11/model_evaluation.py'
  prefs: []
  type: TYPE_NORMAL
- en: Running the code in [Listing 11-10](ch11.xhtml#ch11list10) should generate a
    plot (saved to *roc_curve.png*) that looks like [Figure 11-5](ch11.xhtml#ch11fig5).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0211-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-5:* A ROC curve!'
  prefs: []
  type: TYPE_NORMAL
- en: Each point in the ROC curve in [Figure 11-5](ch11.xhtml#ch11fig5) represents
    a specific false-positive rate (x-axis) and true-positive rate (y-axis) associated
    with various model prediction thresholds ranging from 0 to 1\. As false-positive
    rates increase, true-positive rates increase, and vice versa. In production environments,
    you generally have to pick a single threshold (a single point on this curve, assuming
    validation data mimics production data) with which to make your decision, based
    on your willingness to tolerate false positives, versus your willingness to risk
    allowing a malicious file to slip through the cracks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Enhancing the Model Training Process with Callbacks**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, you’ve learned how to design, train, save, load, and evaluate `Keras`
    models. Although this is really all you need to get a fairly good start, I also
    want to introduce `Keras` callbacks, which can make our model training process
    even better.
  prefs: []
  type: TYPE_NORMAL
- en: A `Keras` callback represents a set of functions that `Keras` applies during
    certain stages of the training process. For example, you can use a `Keras` callback
    to make sure that an *.h5* file is saved at the end of each epoch, or that validation
    AUC is printed to the screen at the end of each epoch. This can help record and
    inform you more precisely of how your model is doing during the training process.
  prefs: []
  type: TYPE_NORMAL
- en: We begin by using a built-in callback, and then we try writing our own custom
    callback.
  prefs: []
  type: TYPE_NORMAL
- en: '***Using a Built-in Callback***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To use a built-in callback, simply pass your model’s `fit_generator()` method
    a callback instance during training. We’ll use the `callbacks.ModelCheckpoint`
    callback, which evaluates validation loss after each training epoch, and saves
    the current model to a file *if* the validation loss is smaller than any previous
    epoch’s validation losses. To do this, the callback needs access to our validation
    data, so we’ll pass that in to the `fit_generator()` method, as shown in [Listing
    11-11](ch11.xhtml#ch11list11).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-11: Adding a* ModelCheckpoint *callback to the training process*'
  prefs: []
  type: TYPE_NORMAL
- en: This code ensures that the model is overwritten ➊ to a single file, `'results/best_model.h5'`
    ➋, whenever `'val_loss'` ➌ (validation loss) reaches a new low. This ensures that
    the current saved model (`'results/best_model.h5'`) always represents the best
    model across all completed epochs with regard to validation loss.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, we can use the code in [Listing 11-12](ch11.xhtml#ch11list12)
    to save the model after every epoch to a *separate* file regardless of validation
    loss.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-12: Adding a* ModelCheckpoint *callback to the training process
    that saves the model to a different file after each epoch*'
  prefs: []
  type: TYPE_NORMAL
- en: To do this, we use the same code in [Listing 11-11](ch11.xhtml#ch11list11) and
    the same function `ModelCheckpoint`, but with `save_best_only=False` ➍ and a `filepath`
    that asks `Keras` to fill in the epoch number ➎. Instead of only saving the single
    “best” version of our model, [Listing 11-12](ch11.xhtml#ch11list12)’s callback
    saves each epoch’s version of our model, in *results/model_epoch_0.h5*, *results/model_epoch_1.h5*,
    *results/model_epoch_2.h5*, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '***Using a Custom Callback***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although `Keras` doesn’t support AUC, we can design our own custom callback
    to, for example, allow us to print AUC to the screen after each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a custom `Keras` callback, we need to create a class that inherits
    from `keras.callbacks.Callback`, the abstract base class used to build new callbacks.
    We can add one or more of a selection of methods, which will be run automatically
    during training, at times that their names specify: `on_epoch_begin`, `on_epoch_end`,
    `on_batch_begin`, `on_batch_end`, `on_train_begin`, and `on_train_end`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 11-13](ch11.xhtml#ch11list13) shows how to create a callback that
    calculates and prints validation AUC to the screen at the end of each epoch.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 11-13: Creating and using a custom callback to print AUC to the screen
    after each training epoch*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we first create our `MyCallback` class ➊, which inherits from
    `callbacks.Callbacks`. Keeping things simple, we overwrite a single method, `on_epoch_end`
    ➋, and give it two arguments expected by `Keras`: `epoch` and `logs` (a dictionary
    of log information), both of which `Keras` will supply when it calls the function
    during training.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, we grab the `validation_data` ➌, which is already stored in the `self`
    object thanks to `callbacks.Callback` inheritance, and we calculate and print
    out AUC ➍ like we did in “[Evaluating the Model](ch11.xhtml#lev191)” on [page
    209](ch11.xhtml#page_209). Note that for this code to work, the validation data
    needs to be passed to `fit_generator()` so that the callback has access to `self.validation_data`
    during training ➎. Finally, we tell the model to train and specify our new callback
    ➏. The result should look something like [Figure 11-6](ch11.xhtml#ch11fig6).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0214-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-6: Console output from training a* Keras *model with a custom AUC
    callback*'
  prefs: []
  type: TYPE_NORMAL
- en: If what you really care about is minimizing validation AUC, this callback makes
    it easy to see how your model is doing during training, thus helping you assess
    whether you should stop the training process (for example, if validation accuracy
    is going consistently down over time).
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, you learned how to build your own neural network using `Keras`.
    You also learned to train, evaluate, save, and load it. You then learned how to
    enhance the model training process by adding built-in and custom callbacks. I
    encourage you to play around with the code accompanying this book to see what
    changes model architecture and feature extraction can have on model accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is meant to get your feet wet, but is not meant as a reference
    guide. Visit *[https://keras.io](https://keras.io)* for the most up-to-date official
    documentation. I strongly encourage you to spend time researching aspects of `Keras`
    that interest you. Hopefully, this chapter has served as a good jumping-off point
    for all your security deep learning adventures!
  prefs: []
  type: TYPE_NORMAL
