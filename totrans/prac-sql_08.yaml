- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Table Design That Works for You
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: Obsession with order and detail can be a good thing. When you’re running out
    the door, it’s reassuring to see your keys hanging on the hook where you *always*
    leave them. The same holds true for database design. When you need to excavate
    a nugget of information from dozens of tables and millions of rows, you’ll appreciate
    a dose of that same detail obsession. With data organized into a finely tuned,
    smartly named set of tables, the analysis experience becomes much more manageable.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I’ll build on Chapter 7 by introducing best practices for organizing
    and speeding up SQL databases, whether they’re yours or ones you inherit for analysis.
    We’ll dig deeper into table design by exploring naming rules and conventions,
    ways to maintain the integrity of your data, and how to add indexes to tables
    to speed up queries.
  prefs: []
  type: TYPE_NORMAL
- en: Following Naming Conventions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Programming languages tend to have their own style patterns, and even various
    factions of SQL coders prefer certain conventions when naming tables, columns,
    and other objects (called *identifiers*). Some like *camel case*, as in `berrySmoothie`,
    where words are strung together and the first letter of each word is capitalized
    except for the first word. *Pascal case*, as in `BerrySmoothie`, follows a similar
    pattern but capitalizes the first letter too. With *snake case*, as in `berry_smoothie`,
    all the words are lowercase and separated by underscores.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll find passionate supporters of each naming convention, with some preferences
    tied to individual database applications or programming languages. For example,
    Microsoft uses Pascal case in the documentation for its SQL Server database. In
    this book, for PostgreSQL-related reasons I’ll explain in a moment, we’re using
    snake case, as in the table `us_counties_pop_est_2019`. Whichever convention you
    prefer or find yourself required to use, it’s important to apply it consistently.
    Be sure to check whether your organization has a style guide or offer to collaborate
    on one, and then follow it religiously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mixing styles or following none generally leads to a mess. For example, imagine
    connecting to a database and finding the following collection of tables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Customers`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`customers`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`custBackup`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`customer_analysis`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`customer_test2`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`customer_testMarch2012`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`customeranalysis`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You would have questions. For one, which table actually holds the current data
    on customers? A disorganized naming scheme—and a general lack of tidiness—makes
    it hard for others to dive into your data and makes it challenging for you to
    pick up where you left off.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore considerations related to naming identifiers and suggestions for
    best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Quoting Identifiers Enables Mixed Case
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Regardless of any capitalization you supply, PostgreSQL treats identifiers
    as lowercase unless you place double quotes around the identifier. Consider these
    two `CREATE TABLE` statements for PostgreSQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When you execute these statements in order, the first command creates a table
    called `customers`. The second statement, rather than creating a separate table
    called `Customers`, will throw an error: `relation "customers" already exists`.
    Because you didn’t quote the identifier, PostgreSQL treats `customers` and `Customers`
    as the same identifier, disregarding the case. To preserve the uppercase letter
    and create a separate table named `Customers`, you must surround the identifier
    with quotes, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'However, because this requires that to query `Customers` rather than `customers`,
    you have to quote its name in the `SELECT` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: That can be a chore to remember and makes a user vulnerable to a mix-up. Make
    sure your tables have names that are clear and distinct from other tables in the
    database.
  prefs: []
  type: TYPE_NORMAL
- en: Pitfalls with Quoting Identifiers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Quoting identifiers also allows you to use characters not otherwise allowed,
    including spaces. That may appeal to some folks, but there are negatives. You
    may want to throw quotes around `"trees planted"` as a column name in a reforestation
    database, but then all users will have to provide quotes on every reference to
    that column. Omit the quotes in a query, and the database will respond with an
    error, identifying `trees` and `planted` as separate columns and responding that
    `trees` does not exist. A more readable and reliable option is to use snake case,
    as in `trees_planted`.
  prefs: []
  type: TYPE_NORMAL
- en: Quotes also let you use SQL *reserved keywords*, which are words that have special
    meaning in SQL. You’ve already encountered several, such as `TABLE`, `WHERE`,
    or `SELECT`. Most database developers frown on using reserved keywords as identifiers.
    At a minimum it’s confusing, and at worst neglecting or forgetting to quote that
    keyword later may result in an error because the database will interpret the word
    as a command instead of an identifier.
  prefs: []
  type: TYPE_NORMAL
- en: Guidelines for Naming Identifiers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Given the extra burden of quoting and its potential problems, it’s best to
    keep your identifier names simple, unquoted, and consistent. Here are my recommendations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use snake case. Snake case is readable and reliable, as shown in the earlier
    `trees_planted` example. It’s used throughout the official PostgreSQL documentation
    and helps make multiword names easy to understand: `video_on_demand` makes more
    sense at a glance than `videoondemand`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make names easy to understand and avoid cryptic abbreviations. If you’re building
    a database related to travel, `arrival_time` is a clearer column name than `arv_tm`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For table names, use plurals. Tables hold rows, and each row represents one
    instance of an entity. So, use plural names for tables, such as `teachers`, `vehicles`,
    or `departments`. I do make exceptions at times. For example, to preserve the
    names of imported CSV files, I use them as a table name, especially when they
    are one-off imports.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Mind the length. The maximum number of characters allowed for an identifier
    name varies by database application: the SQL standard is 128 characters, but PostgreSQL
    limits you to 63, and older Oracle systems have a maximum of 30\. If you’re writing
    code that may get reused in another database system, lean toward shorter identifier
    names.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When making copies of tables, use names that will help you manage them later.
    One method is to append a `_YYYY_MM_DD` date to the table name when you create
    the copy, such as `vehicle_parts_2021_04_08`. An additional benefit is that the
    table names will sort in date order.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Controlling Column Values with Constraints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can maintain further control over the data a column will accept by using
    certain constraints. A column’s data type broadly defines the kind of data it
    will accept: integers versus characters, for example. Additional constraints let
    us further specify acceptable values based on rules and logical tests. With constraints,
    we can avoid the “garbage in, garbage out” phenomenon, which happens when poor-quality
    data results in inaccurate or incomplete analysis. Well-designed constraints help
    maintain the quality of the data and ensure the integrity of the relationships
    among tables.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Chapter 7, you learned about *primary* and *foreign keys*, which are two
    of the most commonly used constraints. SQL also has the following constraint types:'
  prefs: []
  type: TYPE_NORMAL
- en: '`CHECK` Allows only those rows where a supplied Boolean expression evaluates
    to `true`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`UNIQUE` Ensures that values in a column or group of columns are unique in
    each row in the table'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`NOT NULL` Prevents `NULL` values in a column'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can add constraints in two ways: as a *column constraint* or as a *table
    constraint*. A column constraint applies only to that column. We declare it with
    the column name and data type in the `CREATE TABLE` statement, and it gets checked
    whenever a change is made to the column. With a table constraint, we can supply
    criteria that apply to one or more columns. We declare it in the `CREATE TABLE`
    statement immediately after defining all the table columns, and it gets checked
    whenever a change is made to a row in the table.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore these constraints, their syntax, and their usefulness in table
    design.
  prefs: []
  type: TYPE_NORMAL
- en: 'Primary Keys: Natural vs. Surrogate'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As explored in Chapter 7, a *primary key* is a column or collection of columns
    whose values uniquely identify each row in a table. A primary key is a constraint,
    and it imposes two rules on the column or columns that make up the key:'
  prefs: []
  type: TYPE_NORMAL
- en: Values must be unique for each row.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No column can have missing values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a table of products stored in a warehouse, the primary key could be a column
    of unique product codes. In the simple primary key examples in “Relating Tables
    with Key Columns” in Chapter 7, our tables had a primary key made from a single
    ID column with an integer inserted by us, the user. Often, the data will suggest
    the best path and help us decide whether to use a *natural key* or a *surrogate
    key* as the primary key.
  prefs: []
  type: TYPE_NORMAL
- en: Using Existing Columns for Natural Keys
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A natural key uses one or more of the table’s existing columns that meet the
    criteria for a primary key: unique for every row and never empty. Values in the
    columns can change as long as the new value doesn’t cause a violation of the constraint.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A natural key might be a driver’s license identification number issued by a
    local Department of Motor Vehicles. Within a governmental jurisdiction, such as
    a state in the United States, we’d reasonably expect that all drivers would receive
    a unique ID on their licenses, which we could store as `driver_id`. However, if
    we were compiling a national driver’s license database, we might not be able to
    make that assumption; several states could independently issue the same ID code.
    In that case, the `driver_id` column may not have unique values and cannot be
    used as the natural key. As a solution, we could create a *composite primary key*
    by combining `driver_id` with a column holding the state name, which would give
    us a unique combination for each row. For example, both rows in this table have
    a unique combination of the `driver_id` and `st` columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We’ll visit both approaches in this chapter, and as you work with data, keep
    an eye out for values suitable for natural keys. A part number, a serial number,
    or a book’s ISBN are all good examples.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Columns for Surrogate Keys
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A *surrogate* key is a single column that you fill with artificial values;
    we might use it when a table doesn’t have data that supports creating a natural
    primary key. The surrogate key might be a sequential number autogenerated by the
    database. We’ve already done this with the serial data type and the `IDENTITY`
    syntax (covered in “Auto-Incrementing Integers” in Chapter 4). A table using an
    autogenerated integer for a surrogate key might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Some developers like to use a *universally unique identifier (UUID)*, which
    is a code comprised of 32 hexadecimal digits in groups separated by hyphens. Often,
    UUIDs are used to identify computer hardware or software and look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'PostgreSQL offers a UUID data type as well as two modules that generate UUIDs:
    `uuid-ossp` and `pgcrypto`. The PostgreSQL documentation at [https://www.postgresql.org/docs/current/datatype-uuid.html](https://www.postgresql.org/docs/current/datatype-uuid.html)
    is a good starting point for diving deeper.'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the Pros and Cons of Key Types
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There are well-reasoned arguments for using either type of primary key, but
    both have drawbacks. Points to consider about natural keys include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The data already exists in the table, so you don’t need to add a column to create
    a key.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because the natural key data has meaning, it can reduce the need to join tables
    when querying.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your data changes in a way that violates the requirements for a key—the sudden
    appearance of duplicate values, for instance—you’ll be forced to change the setup
    of the table.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are points to consider about surrogate keys:'
  prefs: []
  type: TYPE_NORMAL
- en: Because a surrogate key doesn’t have any meaning in itself and its values are
    independent of the data in the table, you’re not limited by the key structure
    if your data changes later.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key values are guaranteed to be unique.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding a column for a surrogate key requires more space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a perfect world, a table should have one or more columns that can serve as
    a natural key, such as a unique product code in a table of products. But real-world
    limitations arise all the time. In a table of employees, it might be difficult
    to find any single column, or even multiple columns, that would be unique on a
    row-by-row basis to serve as a primary key. In such cases where you can’t reconsider
    the table structure, you may need to use a surrogate key.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Single-Column Primary Key
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s work through several primary key examples. In “Understanding JOIN Types”
    in Chapter 7, you created primary keys on the `district_2020` and `district_2035`
    tables to try `JOIN` types. In fact, these were surrogate keys: in both tables,
    you created columns called `id` to use as the key and used the keywords `CONSTRAINT`
    `key_name` `PRIMARY KEY` to declare them as primary keys.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to declare constraints: as a column constraint or as a table
    constraint. In [Listing 8-1](#listing8-1), we try both methods, declaring a primary
    key on a table similar to the driver’s license example mentioned earlier. Because
    we expect the driver’s license IDs to always be unique, we’ll use that column
    as a natural key.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-1: Declaring a single-column natural key as a primary key'
  prefs: []
  type: TYPE_NORMAL
- en: 'We first create a table called `natural_key_example` and use the column constraint
    syntax `CONSTRAINT` to declare `license_id` as the primary key 1 followed by a
    name for the constraint and the keywords `PRIMARY KEY`. This syntax makes it easy
    to understand at a glance which column is designated as the primary key. Note
    that you can omit the `CONSTRAINT` keyword and name for the key and simply use
    `PRIMARY KEY`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In that case, PostgreSQL will name the primary key on its own, using the convention
    of the table name followed by `_pkey`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we delete the table from the database with `DROP TABLE` 2 to prepare for
    the table constraint example.
  prefs: []
  type: TYPE_NORMAL
- en: To add a table constraint, we declare the `CONSTRAINT` after listing all the
    columns 3, with the column we want to use as the key in parentheses. (Again, you
    can omit the `CONSTRAINT` keyword and key name.) In this example, we end up with
    the same `license_id` column for the primary key. You must use the table constraint
    syntax when you want to create a primary key using more than one column; in that
    case, you would list the columns in parentheses, separated by commas. We’ll explore
    that in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s look at how the qualities of a primary key—unique for every row
    and no `NULL` values—protect you from harming your data’s integrity. [Listing
    8-2](#listing8-2) has two `INSERT` statements.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-2: An example of a primary key violation'
  prefs: []
  type: TYPE_NORMAL
- en: 'When you execute the first `INSERT` statement on its own, the server loads
    a row into the `natural_key_example` table without any issue. When you attempt
    to execute the second, the server replies with an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Before adding the row, the server checked whether a `license_id` of `T229901`
    was already present in the table. Because it was and because a primary key by
    definition must be unique for each row, the server rejected the operation. The
    rules of the fictional DMV state that no two drivers can have the same license
    ID, so checking for and rejecting duplicate data is one way for the database to
    enforce that rule.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Composite Primary Key
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If a single column doesn’t meet the requirements for a primary key, we can create
    a *composite primary key*.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll make a table that tracks student school attendance. The combination of
    `student_id` and `school_day` columns gives us a unique value for each row, which
    records whether a student was in school on that day in a column called `present`.
    To create a composite primary key, you must declare it using the table constraint
    syntax, as shown in [Listing 8-3](#listing8-3).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-3: Declaring a composite primary key as a natural key'
  prefs: []
  type: TYPE_NORMAL
- en: Here we pass two (or more) columns as arguments rather than one. We’ll simulate
    a key violation by attempting to insert a row where the combination of values
    in the two key columns—`student_id` and `school_day`—is not unique to the table.
    Run the `INSERT` statements in [Listing 8-4](#listing8-4) one at a time (by highlighting
    them in pgAdmin before clicking **Execute/Refresh**).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-4: Example of a composite primary key violation'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first two `INSERT` statements execute fine because there’s no duplication
    of values in the combination of the key columns. But the third statement causes
    an error because the `student_id` and `school_day` values it contains match a
    combination that already exists in the table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: You can create composite keys with more than two columns. The limit to the number
    of columns you can use depends on your database.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Auto-Incrementing Surrogate Key
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As you learned in “Auto-Incrementing Integers” in Chapter 4, there are two
    ways to have a PostgreSQL database add an automatically increasing unique value
    to a column. The first is to set the column to one of the PostgreSQL-specific
    serial data types: `smallserial`, `serial`, and `bigserial`. The second is to
    use the `IDENTITY` syntax; because it is part of the ANSI SQL standard, we’ll
    employ this for our examples.'
  prefs: []
  type: TYPE_NORMAL
- en: Use `IDENTITY` with one of the integer types `smallint`, `integer`, and `bigint`.
    For a primary key, it may be tempting to try to save disk space by using `integer`,
    which handles numbers as large as 2,147,483,647\. But many a database developer
    has received a late-night call from a user frantic to know why an application
    is broken, only to discover that the database is trying to generate a number one
    greater than the data type’s maximum. So, if it’s remotely possible that your
    table will grow past 2.147 billion rows, it’s wise to use `bigint`, which accepts
    numbers as high as 9.2 *quintillion*. You can set it and forget it, as shown in
    the first column defined in [Listing 8-5](#listing8-5).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-5: Declaring a `bigint` column as a surrogate key using `IDENTITY`'
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 8-5](#listing8-5) shows how to declare an auto-incrementing `bigint`
    1 column called `order_number` using the `IDENTITY` syntax and then set the column
    as the primary key 2. When you insert data into the table 3, you omit `order_number`
    from the list of columns and values. The database will create a new value for
    that column as each row is inserted, and that value will be one greater than the
    largest already created for the column.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run `SELECT * FROM surrogate_key_example;` to see how the column fills in automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We see these sorts of auto-incrementing order numbers reflected in the receipts
    for the purchases we make every day. Now you know how it’s done.
  prefs: []
  type: TYPE_NORMAL
- en: 'A few details worth noting: if you delete a row, the database won’t fill the
    gap in the `order_number` sequence, nor will it change any of the existing values
    in that column. It will generally add one to the largest existing value in the
    sequence (though there are exceptions related to operations, including restoring
    a database from a backup). Also, we used the syntax `GENERATED ALWAYS AS IDENTITY`.
    As discussed in Chapter 4, this prevents a user from inserting a value in `order_number`
    without manually overriding the setting. Generally, you want to prevent such meddling
    to avoid problems. Let’s say a user were to manually insert a value of `4` into
    the `order_number` column of your existing `surrogate_key_example` table. That
    manual insert will not increment the `IDENTITY` sequence for the `order_number`
    column; that occurs only when the database generates a new value. Thus, on the
    next row insert, the database also would try to also insert a `4`, as that’s the
    next number in the sequence. The result will be an error, because a duplicate
    value violates the primary key constraint.'
  prefs: []
  type: TYPE_NORMAL
- en: You can, however, allow manual insertions by restarting the `IDENTITY` sequence.
    You might allow this in case you need to insert a row that was mistakenly deleted.
    [Listing 8-6](#listing8-6) shows how to add a row to the table that has an `order_number`
    of `4`, which is the next value in the sequence.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-6: Restarting an `IDENTITY` sequence'
  prefs: []
  type: TYPE_NORMAL
- en: You start with an `INSERT` statement that includes the keywords `OVERRIDING
    SYSTEM VALUE` 1. Next we include the `VALUES` clause and specify the integer `4`
    for the first column, `order_number`, in the `VALUES` list, which overrides the
    `IDENTITY` restriction. We’re using `4`, but we could choose any number that’s
    not already present in the column.
  prefs: []
  type: TYPE_NORMAL
- en: After the insert, you need to reset the `IDENTITY` sequence so that it begins
    at a number larger than the `4` you just inserted. To do this, use an `ALTER TABLE
    ... ALTER COLUMN` statement 2 that includes the keywords `RESTART WITH 5`. An
    `ALTER TABLE` modifies tables and columns in various ways, which we’ll explore
    more thoroughly in Chapter 10, “Inspecting and Modifying Data.” Here, you use
    it to change the beginning number of the `IDENTITY` sequence; so, when the next
    row gets added to the table, the value for `order_number` will be `5`. Finally,
    insert a new row 3 and omit a value for the `order_number`, as you did in [Listing
    8-5](#listing8-5).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you select all rows again from the `surrogate_key_example` table, you’ll
    see that the `order_number` column populated as intended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This task isn’t one you necessarily want to tackle often, but it’s good to know
    if the need arises.
  prefs: []
  type: TYPE_NORMAL
- en: Foreign Keys
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We use *foreign keys* to establish relationships between tables. A foreign key
    is one or more columns whose values match those in another table’s primary key
    or other unique key. Foreign key values must already exist in the primary key
    or other unique key of the table it references. If not, the value is rejected.
    With this constraint, SQL enforces *referential integrity*—ensuring that data
    in related tables doesn’t end up unrelated, or orphaned. We won’t end up with
    rows in one table that have no relation to rows in the other tables we can join
    them to.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 8-7](#listing8-7) shows two tables from a hypothetical database tracking
    motor vehicle activity.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-7: A foreign key example'
  prefs: []
  type: TYPE_NORMAL
- en: The first table, `licenses`, uses a driver’s unique `license_id` 1 as a natural
    primary key. The second table, `registrations`, is for tracking vehicle registrations.
    A single license ID might be connected to multiple vehicle registrations, because
    each licensed driver can register multiple vehicles—this is called a *one-to-many
    relationship* (Chapter 7).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how that relationship is expressed via SQL: in the `registrations` table,
    we designate the column `license_id` 2 as a foreign key by adding the `REFERENCES`
    keyword, followed by the table name and column for it to reference.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, when we insert a row into `registrations`, the database will test whether
    the value inserted into `license_id` already exists in the `license_id` primary
    key column of the `licenses` table. If it doesn’t, the database returns an error,
    which is important. If any rows in `registrations` didn’t correspond to a row
    in `licenses`, we’d have no way to write a query to find the person who registered
    the vehicle.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see this constraint in action, create the two tables and execute the `INSERT`
    statements one at a time. The first adds a row to `licenses` 3 that includes the
    value `T229901` for the `license_id`. The second adds a row to `registrations`
    4 where the foreign key contains the same value. So far, so good, because the
    value exists in both tables. But we encounter an error with the third insert,
    which tries to add a row to `registrations` 5 with a value for `license_id` that’s
    not in `licenses`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting error is actually helpful: the database is enforcing referential
    integrity by preventing a registration for a nonexistent license holder. But it
    also indicates a few practical implications. First, it affects the order in which
    we insert data. We cannot add data to a table that contains a foreign key before
    the other table referenced by the key has the related records, or we’ll get an
    error. In this example, we’d have to create a driver’s license record before inserting
    a related registration record (if you think about it, that’s what your local department
    of motor vehicles probably does).'
  prefs: []
  type: TYPE_NORMAL
- en: Second, the reverse applies when we delete data. To maintain referential integrity,
    the foreign key constraint prevents us from deleting a row from `licenses` before
    removing any related rows in `registrations`, because doing so would leave an
    orphaned record. We would have to delete the related row in `registrations` first
    and then delete the row in `licenses`. However, ANSI SQL provides a way to handle
    this order of operations automatically using the `ON DELETE` `CASCADE` keywords.
  prefs: []
  type: TYPE_NORMAL
- en: How to Automatically Delete Related Records with CASCADE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To delete a row in `licenses` and have that action automatically delete any
    related rows in `registrations`, we can specify that behavior by adding `ON DELETE
    CASCADE` when defining the foreign key constraint.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how we would modify the [Listing 8-7](#listing8-7) `CREATE TABLE` statement
    for `registrations`, adding the keywords at the end of the definition of the `license_id`
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Deleting a row in `licenses` should also delete all related rows in `registrations`.
    This allows us to delete a driver’s license without first having to manually remove
    any registrations linked to it. It also maintains data integrity by ensuring deleting
    a license doesn’t leave orphaned rows in `registrations`.
  prefs: []
  type: TYPE_NORMAL
- en: The CHECK Constraint
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A `CHECK` constraint evaluates whether data added to a column meets the expected
    criteria, which we specify with a logical test. If the criteria aren’t met, the
    database returns an error. The `CHECK` constraint is extremely valuable because
    it can prevent columns from getting loaded with nonsensical data. For example,
    a baseball player’s total number of hits shouldn’t be negative, so you should
    limit that data to values of zero or greater. Or, in most schools, `Z` isn’t a
    valid letter grade for a course (although my barely passing algebra grade felt
    like it), so we might insert constraints that only accept the values A–F.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with primary keys, we can implement a `CHECK` constraint at the column or
    table level. For a column constraint, declare it in the `CREATE TABLE` statement
    after the column name and data type: `CHECK (``logical expression``)`. As a table
    constraint, use the syntax `CONSTRAINT` `constraint_name` `CHECK (``logical expression``)`
    after all columns are defined.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 8-8](#listing8-8) shows a `CHECK` constraint applied to two columns
    in a table we might use to track the user role and salary of employees within
    an organization. It uses the table constraint syntax for the primary key and the
    `CHECK` constraint.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-8: Examples of `CHECK` constraints'
  prefs: []
  type: TYPE_NORMAL
- en: We create the table and set the `user_id` column as an auto-incrementing surrogate
    primary key. The first `CHECK` 1 tests whether values entered into the `user_role`
    column match one of two predefined strings, `Admin` or `Staff`, by using the SQL
    `IN` operator. The second `CHECK` 2 tests whether values entered in the `salary`
    column are greater than or equal to 0, because a negative amount wouldn’t make
    sense. Both tests are an example of a *Boolean expression*, a statement that evaluates
    as either true or false. If a value tested by the constraint evaluates as `true`,
    the check passes.
  prefs: []
  type: TYPE_NORMAL
- en: When values are inserted or updated, the database checks them against the constraint.
    If the values in either column violate the constraint—or, for that matter, if
    the primary key constraint is violated—the database will reject the change.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the table constraint syntax, we also can combine more than one test
    in a single `CHECK` statement. Say we have a table related to student achievement.
    We could add the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we combine two logical tests by enclosing them in parentheses and
    connecting them with `AND`. Here, both Boolean expressions must evaluate as `true`
    for the entire check to pass. You can also test values across columns, as in the
    following example where we want to make sure an item’s sale price is a discount
    on the original, assuming we have columns for both values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Inside the parentheses, the logical expression checks that the sale price is
    less than the retail price.
  prefs: []
  type: TYPE_NORMAL
- en: The UNIQUE Constraint
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can also ensure that a column has a unique value in each row by using the
    `UNIQUE` constraint. If ensuring unique values sounds similar to the purpose of
    a primary key, it is. But `UNIQUE` has one important difference. In a primary
    key, no values can be `NULL`, but a `UNIQUE` constraint permits multiple `NULL`
    values in a column. This is useful in cases where we won’t always have values
    but want to ensure that the ones we do have are unique.
  prefs: []
  type: TYPE_NORMAL
- en: To show the usefulness of `UNIQUE`, look at the code in [Listing 8-9](#listing8-9),
    which is a table for tracking contact info.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-9: A `UNIQUE` constraint example'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this table, `contact_id` serves as a surrogate primary key, uniquely identifying
    each row. But we also have an `email` column, the main point of contact with each
    person. We’d expect this column to contain only unique email addresses, but those
    addresses might change over time. So, we use `UNIQUE` 1 to ensure that any time
    we add or update a contact’s email, we’re not providing one that already exists.
    If we try to insert an email that already exists 2, the database will return an
    error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Again, the error shows the database is working for us.
  prefs: []
  type: TYPE_NORMAL
- en: The NOT NULL Constraint
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Chapter 7, you learned about `NULL`, a special SQL value that represents
    missing data or unknown values. We know that `NULL` is not allowed for primary
    key values because they need to uniquely identify each row in a table. But there
    may be other times when you’ll want to disallow empty values in a column. For
    example, in a table listing each student in a school, requiring that columns containing
    first and last names be filled for each row makes sense. To require a value in
    a column, SQL provides the `NOT NULL` constraint, which simply prevents a column
    from accepting empty values.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 8-10](#listing8-10) demonstrates the `NOT NULL` syntax.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-10: A `NOT NULL` constraint example'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we declare `NOT NULL` for the `first_name` and `last_name` columns because
    it’s likely we’d require those pieces of information in a table tracking student
    information. If we attempt an `INSERT` on the table and don’t include values for
    those columns, the database will notify us of the violation.
  prefs: []
  type: TYPE_NORMAL
- en: How to Remove Constraints or Add Them Later
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can remove a constraint or later add one to an existing table using `ALTER
    TABLE`, the command you used earlier in the chapter in “Creating an Auto-incrementing
    Surrogate Key” to reset the `IDENTITY` sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'To remove a primary key, foreign key, or `UNIQUE` constraint, you write an
    `ALTER TABLE` statement in this format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'To drop a `NOT NULL` constraint, the statement operates on the column, so you
    must use the additional `ALTER COLUMN` keywords, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Let’s use these statements to modify the `not_null_example` table you just made,
    as shown in [Listing 8-11](#listing8-11).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-11: Dropping and adding a primary key and a `NOT NULL` constraint'
  prefs: []
  type: TYPE_NORMAL
- en: Execute the statements one at a time. Each time, you can view the changes to
    the table definition in pgAdmin by clicking the table name once and then clicking
    the **SQL** tab above the query window. (Note that it will display a more verbose
    syntax for the table definition than what you used when creating the table.)
  prefs: []
  type: TYPE_NORMAL
- en: With the first `ALTER TABLE` statement, we use `DROP CONSTRAINT` to remove the
    primary key named `student_id_key`. We then add the primary key back using `ADD
    CONSTRAINT`. We’d use that same syntax to add a constraint to any existing table.
  prefs: []
  type: TYPE_NORMAL
- en: In the third statement, `ALTER COLUMN` and `DROP NOT NULL` remove the `NOT NULL`
    constraint from the `first_name` column. Finally, `SET NOT NULL` adds the constraint.
  prefs: []
  type: TYPE_NORMAL
- en: Speeding Up Queries with Indexes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the same way that a book’s index helps you find information more quickly,
    you can speed up queries by adding an *index*—a separate data structure the database
    manages—to one or more columns in a table. The database uses the index as a shortcut
    rather than scanning each row to find data. That’s admittedly a simplistic picture
    of what, in SQL databases, is a nontrivial topic. We could spend several chapters
    delving into the workings of SQL indexes and tuning databases for performance,
    but instead I’ll offer general guidance on using indexes and a PostgreSQL-specific
    example that demonstrates their benefits.
  prefs: []
  type: TYPE_NORMAL
- en: 'B-Tree: PostgreSQL’s Default Index'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’ve already created several indexes, perhaps without knowing. Each time you
    add a primary key or `UNIQUE` constraint, PostgreSQL (as well as most database
    systems) creates an index on the column or columns included in the constraint.
    Indexes are stored separately from the table data and are accessed automatically
    (if needed) when you run a query and updated every time a row is added, removed,
    or updated.
  prefs: []
  type: TYPE_NORMAL
- en: In PostgreSQL, the default index type is the *B-tree index*. It’s created automatically
    on the columns designated for the primary key or a `UNIQUE` constraint, and it’s
    also the type created by default with the `CREATE INDEX` statement. B-tree, short
    for *balanced tree*, is so named because when you search for a value, the structure
    looks from the top of the tree down through branches until it locates the value.
    (Of course, the process is a lot more complicated than that.) A B-tree index is
    useful for data that can be ordered and searched using equality and range operators,
    such as `<`, `<=`, `=`, `>=`, `>`, and `BETWEEN`. It also works with `LIKE` if
    there’s no wildcard in the pattern at the beginning of the search string. An example
    is `WHERE chips LIKE 'Dorito%'`.
  prefs: []
  type: TYPE_NORMAL
- en: PostgreSQL also supports additional index types, such as the *Generalized Inverted
    Index (GIN)* and the *Generalized Search Tree* *(GiST)*. Each has distinct uses,
    and I’ll incorporate them in later chapters on full-text search and queries using
    geometry types.
  prefs: []
  type: TYPE_NORMAL
- en: For now, let’s see a B-tree index speed up a simple search query. For this exercise,
    we’ll use a large dataset comprising more than 900,000 New York City street addresses,
    compiled by the OpenAddresses project at [https://openaddresses.io/](https://openaddresses.io/).
    The file with the data, *city_of_new_york.csv*, is available for you to download
    along with all the resources for this book from [https://nostarch.com/practical-sql-2nd-edition/](https://nostarch.com/practical-sql-2nd-edition/).
  prefs: []
  type: TYPE_NORMAL
- en: After you’ve downloaded the file, use the code in [Listing 8-12](#listing8-12)
    to create a `new_york_addresses` table and import the address data. The import
    will take longer than the tiny datasets you’ve loaded so far because the CSV file
    is about 50MB.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-12: Importing New York City address data'
  prefs: []
  type: TYPE_NORMAL
- en: When the data loads, run a quick `SELECT` query to visually check that you have
    940,374 rows and seven columns. A common use for this data might be to search
    for matches in the `street` column, so we’ll use that example for exploring index
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking Query Performance with EXPLAIN
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We’ll measure the performance before and after adding an index by using the
    PostgreSQL-specific `EXPLAIN` command, which lists the *query plan* for a specific
    database query. The query plan might include how the database plans to scan the
    table, whether or not it will use indexes, and so on. When we add the `ANALYZE`
    keyword, `EXPLAIN` will carry out the query and show the actual execution time.
  prefs: []
  type: TYPE_NORMAL
- en: Recording Some Control Execution Times
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We’ll use the three queries in [Listing 8-13](#listing8-13) to analyze query
    performance before and after adding an index. We’re using typical `SELECT` queries
    with a `WHERE` clause with `EXPLAIN ANALYZE` included at the beginning. These
    keywords tell the database to execute the query and display statistics about the
    query process and how long it took to execute, rather than show the results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-13: Benchmark queries for index performance'
  prefs: []
  type: TYPE_NORMAL
- en: 'On my system, the first query returns these stats in the pgAdmin output pane:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Not all the output is relevant here, so I won’t decode it all, but two lines
    are pertinent. The first indicates that to find any rows where `street = ''BROADWAY''`,
    the database will conduct a sequential scan 1 of the table. That’s a synonym for
    a full table scan: the database will examine each row and remove any where `street`
    doesn’t match `BROADWAY`. The execution time (on my computer about 389 milliseconds)
    2 is how long the query took to run. Your time will depend on factors including
    your computer hardware.'
  prefs: []
  type: TYPE_NORMAL
- en: For the test, run each query in [Listing 8-13](#listing8-13) several times and
    record the fastest execution time for each. You’ll notice that execution times
    for the same query will vary slightly on each run. That can be the result of several
    factors, from other processes running on the server to the effect of data being
    held in memory after a prior run of the query.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the Index
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now, let’s see how adding an index changes the query’s search method and execution
    time. [Listing 8-14](#listing8-14) shows the SQL statement for creating the index
    with PostgreSQL.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 8-14: Creating a B-tree index on the `new_york_addresses` table'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that it’s similar to the commands for creating constraints. We give the
    `CREATE INDEX` keywords followed by a name we choose for the index, in this case
    `street_idx`. Then `ON` is added, followed by the target table and column.
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the `CREATE INDEX` statement, and PostgreSQL will scan the values in
    the `street` column and build the index from them. We need to create the index
    only once. When the task finishes, rerun each of the three queries in [Listing
    8-13](#listing8-13) and record the execution times reported by `EXPLAIN ANALYZE`.
    Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Do you notice a change? First, we see that the database is now using an index
    scan on `street_idx` 1 instead of visiting each row in a sequential scan. Also,
    the query speed is now markedly faster 2. [Table 8-1](#table8-1) shows the fastest
    execution times (rounded) from my computer before and after adding the index.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8-1: Measuring Index Performance'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Query filter** | **Before index** | **After index** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `WHERE street = ''BROADWAY''` | 92 ms | 5 ms |'
  prefs: []
  type: TYPE_TB
- en: '| `WHERE street = ''52 STREET''` | 94 ms | 1 ms |'
  prefs: []
  type: TYPE_TB
- en: '| `WHERE street = ''ZWICKY AVENUE''` | 93 ms | <1 ms |'
  prefs: []
  type: TYPE_TB
- en: The execution times are much, much better, nearly a tenth of a second faster
    or more per query. Is a tenth of a second that impressive? Well, whether you’re
    seeking answers in data using repeated querying or creating a database system
    for thousands of users, the time savings adds up.
  prefs: []
  type: TYPE_NORMAL
- en: If you ever need to remove an index from a table—perhaps if you’re testing the
    performance of several index types—use the `DROP INDEX` command followed by the
    name of the index to remove.
  prefs: []
  type: TYPE_NORMAL
- en: Considerations When Using Indexes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You’ve seen that indexes have significant performance benefits, so does that
    mean you should add an index to every column in a table? Not so fast! Indexes
    are valuable, but they’re not always needed. In addition, they do enlarge the
    database and impose a maintenance cost on writing data. Here are a few tips for
    judging when to uses indexes:'
  prefs: []
  type: TYPE_NORMAL
- en: Consult the documentation for the database system you’re using to learn about
    the kinds of indexes available and which to use on particular data types. PostgreSQL,
    for example, has five more index types in addition to B-tree. One, called GiST,
    is particularly suited to the geometry data types discussed later in the book.
    Full-text search, which you’ll learn in Chapter 14, also benefits from indexing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider adding indexes to columns you’ll use in table joins. Primary keys are
    indexed by default in PostgreSQL, but foreign key columns in related tables are
    not and are a good target for indexes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An index on a foreign key will help avoid an expensive sequential scan during
    a cascading delete.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add indexes to columns that will frequently end up in a query `WHERE` clause.
    As you’ve seen, search performance is significantly improved via indexes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `EXPLAIN ANALYZE` to test the performance under a variety of configurations.
    Optimization is a process! If an index isn’t being used by the database—and it’s
    not backing up a primary key or other constraint—you can drop it to reduce the
    size of your database and speed up inserts, updates, and deletes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the tools you’ve added to your toolbox in this chapter, you’re ready to
    ensure that the databases you build or inherit are best suited for your collection
    and exploration of data. It’s crucial to define constraints that match the data
    and the expectation of users by not allowing values that don’t make sense, making
    sure values are filled in, and setting up proper relationships between tables.
    You’ve also learned how to make your queries run faster and how to consistently
    organize your database objects. That’s a boon for you and for others who share
    your data.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter concludes the first part of the book, which focused on giving you
    the essentials to dig into SQL databases. We’ll continue building on these foundations
    as we explore more complex queries and strategies for data analysis. In the next
    chapter, we’ll use SQL aggregate functions to assess the quality of a dataset
    and get usable information from it.
  prefs: []
  type: TYPE_NORMAL
