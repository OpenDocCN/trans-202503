<html><head></head><body>
<div id="sbo-rt-content"><h2 class="h2" id="ch01"><span epub:type="pagebreak" id="page_3"/><strong><span class="big">1</span><br/>SECURE DEVELOPMENT PROCESS</strong></h2>
<div class="image1"><img alt="Image" height="252" src="../images/common.jpg" width="252"/></div>
<p class="noindent">When I was a student, I thought organizational processes were among the most boring topics in engineering. However, after working in security engineering for over a decade and helping organizations optimize their security efforts, I have to admit that processes are more interesting than I thought and not at all irrelevant when developing secure products.</p>
<p class="indent">Although a product’s technical protection features can be fulfilled and marked as <em>done</em>, a secure development process is <em>never done</em>; it must be maintained and improved continuously, which is why the qualitative measure for security engineering processes is called <em>maturity</em>. It can rise and fall, depending on the regularity, quality, and organizational structures of activities supporting the development of a secure product within an organization.</p>
<p class="indent">This chapter’s goal is to convince students, engineers, and developers that there is more to processes than creating documents nobody reads. A <em>secure development life cycle (SDL)</em> is about culture and day-to-day human behavior; it’s about maintaining quality and security under changing conditions, and it clarifies how everybody involved in a product engineering process can continuously contribute to a secure end product.</p>
<h3 class="h3" id="ch00lev1_6"><span epub:type="pagebreak" id="page_4"/><strong>On the Variety of Guidelines</strong></h3>
<p class="noindent">Recommendations for secure development processes have been around for quite some time. However, depending on your industry, it’s possible that nobody in your organization has considered pursuing such a systematic approach until now, or at least not explicitly.</p>
<p class="indent">Companies developing operating systems and web applications were confronted with security issues relatively early, so it’s not surprising that Microsoft and the Open Web Application Security Project (OWASP) were some of the first to work on and talk about SDLs. Since the IEC’s publication of IEC 62443 Part 4-1, more and more manufacturers of the industrial components used in production facilities, critical infrastructures, and a variety of automation applications have been aware of the necessity to implement a secure development process.</p>
<p class="indent">Microsoft’s SDL follows 12 practices (<em><a href="https://www.microsoft.com/en-us/securityengineering/sdl/practices">https://www.microsoft.com/en-us/securityengineering/sdl/practices</a></em>) that describe the processes the company uses in order to develop secure (software) products. These processes range from training to requirements engineering and threat modeling to security testing. Also targeted at the software community, OWASP uses five categories to summarize its Software Assurance Maturity Model (SAMM, <em><a href="https://owaspsamm.org/model/">https://owaspsamm.org/model/</a></em>): governance, design, implementation, verification, and operations. Part 4-1 of IEC 62443 (<em><a href="https://webstore.iec.ch/publication/33615">https://webstore.iec.ch/publication/33615</a></em>) aims at establishing a secure development process for industrial component manufacturers. It’s structured into 8 practices, each containing 2 to 13 subpractices detailing recommended activities from security management to design and implementation to update management in the field.</p>
<p class="indent">All three of these guidelines use a different structure to explain the idea of a secure development process; however, you might notice that they overlap significantly. For example, the Microsoft SDL tells you to perform <em>threat modeling</em>, while OWASP uses the term <em>threat assessment</em> in its <em>design</em> category, and IEC 62443-4-1, requirement SR-2 (which is part of the <em>specification of security requirements</em> practice) explains the necessity to establish a process to create and maintain a <em>threat model</em> for a product.</p>
<p class="indent">In addition, the importance of security knowledge and abilities is present in all three: Microsoft lists <em>provide training</em> as its first practice, while OWASP considers <em>education</em> as part of <em>governance</em>, and IEC 62443-4-1 uses the term <em>security expertise</em> to summarize the identification and development of skills in requirement SM-4 of its <em>security management</em> practice. As a final example, <em>penetration testing</em> is an explicitly named practice at Microsoft; it’s included by the same name in requirement SVV-4 in IEC 62443-4-1’s practice of <em>security verification and validation testing</em>, and the SAMM refers to it in the <em>security testing</em> task under the <em>verification</em> item.</p>
<p class="indent">We could continue in this manner for topics like the use of state-of-the-art cryptography, clarification of third-party dependencies, and vulnerability management. The point is that content-wise, these guidelines have many similarities, so the answer to the question “Which of the many available resources is the best one?” is “It doesn’t make a big difference.”</p>
<p class="indent"><span epub:type="pagebreak" id="page_5"/>Microsoft has more than 30 years of experience in secure software engineering. OWASP provides not only valuable recommendations but also open source tooling to support these processes. On the other hand, IEC 62443-4-1 targets the industrial domain and component manufacturers that are different from classic IT companies. Also, independent bodies can certify compliance with IEC 62443, but that’s not possible for Microsoft’s and OWASP’s SDLs, which can be a further decisive factor.</p>
<p class="indent">These three documents are just common examples. The NIST <em>Special Publication 800-160</em> (<em><a href="https://csrc.nist.gov/pubs/sp/800/160/v1/r1/final?">https://csrc.nist.gov/pubs/sp/800/160/v1/r1/final?</a></em>), the Building Security In Maturity Model (BSIMM, <em><a href="https://www.bsimm.com">https://www.bsimm.com</a></em>) initiative, and the European Union Agency for Cybersecurity (ENISA) <em>Good Practices for Security of IoT—Secure Software Development Lifecycle</em> (<em><a href="https://www.enisa.europa.eu/publications/good-practices-for-security-of-iot-1">https://www.enisa.europa.eu/publications/good-practices-for-security-of-iot-1</a></em>) are also helpful.</p>
<h3 class="h3" id="ch00lev1_7"><strong>Responsibility for Product Security</strong></h3>
<p class="noindent">Every product’s security success starts with the clarification of responsibilities. It doesn’t matter whether it’s the founder of a startup, a product security officer (PSO) of a global company, or a member of the development team who takes the responsibility, but it’s of great importance that <em>someone</em> does and that this someone has the necessary time and resources to do the job.</p>
<p class="indent">A secure development process consists of a heterogeneous set of activities, which also means the person responsible for security has to be involved in many product development phases. That person has to ensure that <em>security by design</em> is part of the development culture. Of course, that’s not the most charming position, especially when security hasn’t been a focus in your organization before. Although (product) management usually loves to talk about the potential of new technologies and device features, regularly stressing the involved risks doesn’t make you everybody’s darling.</p>
<p class="indent">However, in the long run, this someone will eliminate the sources of errors, vulnerabilities, and internal misunderstandings. They will not only increase device security but also contribute to transparency within the product development team and toward management.</p>
<div class="box">
<p class="box-title"><strong>IN PRACTICE: SECURITY ENGINEERING EXPERTS</strong></p>
<p class="noindent">I once worked as a consultant for a medium-sized company to introduce security into its product engineering processes. At the time, the company had a security expert working for the IT department, but nobody with security knowledge was available on the embedded system engineering team.</p>
<p class="indent">Luckily, the company was able to hire a motivated young professional with sound security expertise and even device engineering experience to fill that gap and take responsibility for product security. With several ideas in mind on how <span epub:type="pagebreak" id="page_6"/>to establish a secure development process, he made himself comfortable with the organization’s specific processes, people, and products.</p>
<p class="indent">From time to time, he was asked to support the development team in software and hardware engineering projects because of urgency. Sadly, the number of those tasks rose while management’s interest in product security decreased significantly. After about two years, he quit. And this company lost twice: it lost committed security talent and the chance to establish a secure development process before its competitors did.</p>
</div>
<h3 class="h3" id="ch00lev1_8"><strong>Awareness and Training</strong></h3>
<p class="noindent">Some years ago, I attended a talk by a German security consultant about how European companies are prepared (or not prepared) for upcoming cyber threats and how much stress and frustration people working in the security area must experience every day. Aimed at management representatives, he concluded with this: “Neither tools nor technologies—<em>people</em> create security!”</p>
<p class="indent">From requirements engineering to software and hardware development to vulnerability handling, it’s people who creatively identify ways to misuse a product feature, meticulously follow secure coding rules agreed upon within the team, and separate relevant from irrelevant security issues reported by third parties.</p>
<p class="indent">To put it another way, if your development team isn’t able to imagine potential attack scenarios; regards security practices as hindrances; and counters vulnerability reports with anger, fear, or a complete lack of understanding, your product won’t improve in security, even if you bought the most expensive licenses for top tools in order to “support” them. The obvious question to pose is, “Who has to have what security knowledge to follow the security-by-design principle each workday?”</p>
<p class="indent">For the majority of employees, general security awareness is a fundamental requirement. This requirement is also true for engineers, developers, and device architects. However, security awareness is not something you learn at school (at least until now). It’s also not a mandatory part of university education or typical on-the-job training programs. Further, awareness often vanishes over time, which means it must be refreshed regularly. Within your teams, it’s essential to address and discuss the perspectives of attackers, their intentions, and the possibilities for countering those strategies.</p>
<p class="indent">From my experience, web-based training is often a “click-and-forget” activity for employees, while social gatherings, workshops, and team-building events lead to interaction, discussions, and, most preferably, reflection, which enables people to link security knowledge with their day-to-day jobs.</p>
<p class="indent">Besides security basics, individuals on your product engineering teams might need specific capabilities. For example, developers can benefit from secure coding training, while testers can improve their skills by attending a penetration testing course. Often neglected, especially in medium-sized companies, participating in a security engineering community may be a <span epub:type="pagebreak" id="page_7"/>worthwhile way to exchange ideas, challenges, and lessons learned with other organizations for both management-level and technical employees.</p>
<p class="indent">Again, training is not a one-shot activity. Continuously nudging people to reflect on the security of their work and daily processes is an integral part of a vivid security culture.</p>
<h3 class="h3" id="ch00lev1_9"><strong>Assets and Protection Goals</strong></h3>
<p class="noindent">Imagine a sunny Monday morning. The week ahead seems to get busy as usual, but then somebody from management asks if you can spare a minute:</p>
<div class="blockquote">
<p class="noindent">Manager: “Please turn our product into a secure product!”</p>
<p class="noindent">You: “What exactly do you mean?”</p>
<p class="noindent">Manager: “Hacking it should be impossible!”</p>
<p class="noindent">You: “Where does this requirement come from?”</p>
<p class="noindent">Manager: “Don’t you read the news? Everything is being hacked these days!”</p>
<p class="noindent">You: “Okay. Well, which part of our product would be worth hacking?”</p>
<p class="noindent">Manager: “I have no idea; you tell me!”</p>
</div>
<p class="indent">This dialogue is fictional, but you may have had similar discussions. It makes one trivial point obvious: you can’t secure a device if you don’t know what to protect. Essentially everybody in your company should know what’s worth protecting or what’s fundamentally important to keep your business running. We usually call this an <em>asset</em>.</p>
<h4 class="h4" id="ch00lev2_1"><strong><em>Valuable Product Parts</em></strong></h4>
<p class="noindent">Assets can be of various kinds—for example, a cryptographic key necessary for a pay-per-use scenario, measurement data that is transferred from your device to a cloud application in order to enable predictive maintenance services, a configuration file that activates or disables product features, code in your firmware that issues an alert in case of an emergency, or a web service necessary for even basic device operation. In a nutshell, assets are everything that’s somehow important and valuable.</p>
<p class="indent">Identifying these assets is the initial analysis to kick off a secure development process and the basis for all your protection efforts. Logically, you should determine what your assets are before implementing countermeasures or ordering a penetration test, because if you don’t know what you want to protect, how can you implement effective countermeasures and specify worst-case attack scenarios? However, since most modern devices aren’t standalone, this process also involves establishing a <em>common system understanding</em> within your organization, which includes the relevant objects, data flows, people, third-party components, and life-cycle processes, as well as the business model behind all that.</p>
<p class="indent">Reading that list, you might think it covers a whole lot of information, and you’re right. The topics range from business insights to deep technical knowledge to processes and organizational structures. No matter how small <span epub:type="pagebreak" id="page_8"/>or large your company is, one single person likely isn’t responsible for all those tasks, especially not within a development team, so approaching this analysis in a multidimensional way is crucial.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>I’ve had good experiences with setting up a workshop with a moderator, a security expert, and a diverse group of employees involved in the business operations around a specific device. Besides a developer, tester, and product manager, it makes sense to invite people from maintenance, customer support, digital services, device safety, sales, and whatever other departments might be relevant for your product.</em></p>
</div>
<p class="indent">The starting point for discussing cybersecurity with team members is a basic overview that collects the information available on the architecture. <a href="ch01.xhtml#ch01fig01">Figure 1-1</a> shows an example of such a representation for a fictional Wi-Fi-controlled industrial ventilator.</p>
<div class="image"><img alt="Image" height="532" id="ch01fig01" src="../images/01fig01.jpg" width="912"/></div>
<p class="figcap"><em>Figure 1-1: An example of a basic device context overview</em></p>
<p class="indent">This initial overview should be simple but as detailed as necessary. Later, in a sometimes chaotic process during a workshop or discussion, this overview will be enriched and refined with information, maybe with data flows not obvious from the original documents, relations to third parties not known before, or implicit process steps known only by those who perform them every day.</p>
<p class="indent">After everybody is satisfied with the detail and correctness of the overall system representation, the actual asset identification starts with this question: “Which parts of the system are critical for our business model and/or our organization?”</p>
<h4 class="h4" id="ch00lev2_2"><strong><em>Relevant Protection Needs</em></strong></h4>
<p class="noindent">Determining not only <em>what</em> is important to protect but also <em>why</em> it is important directly leads us to the definition of <em>protection goals</em>.</p>
<p class="indentb"><span epub:type="pagebreak" id="page_9"/>Every asset should have at least one protection goal; otherwise, the asset isn’t likely relevant (from a security point of view). The following list, starting with the famous C-I-A triad (confidentiality, integrity, availability), indicates typical protection goals that define which property of an asset is worth protecting. However, if you identify a specific protection need that doesn’t fit the standard goals in this list, there’s nothing wrong with writing it down in your own words.</p>
<p class="hanga"><strong>Confidentiality (C)</strong>    This protection goal is probably the most widely known. We could say that a corresponding asset has to stay “secret” to be “secure.” More formally, it means that read access on a specific asset should not be possible, except for authorized entities. Although this goal likely comes to every layperson’s mind when talking about security, it’s not always the correct one, and it’s not necessary for all possible assets. Typical examples of assets requiring confidentiality are stored cryptographic keys or executables that contain intellectual property.</p>
<p class="hanga"><strong>Integrity (I)</strong>    Only authorized subjects should be able to alter a given object or data, and if others alter it, you should be able to detect the manipulation. Common use cases include a monotonic counter for billing purposes or control commands sent over a communication channel. Further, you can apply this goal to whole devices or machines in order to stress the importance of <em>system integrity</em>, for example, if it is possible to replace parts of the system. Be aware that the term <em>integrity</em> is used differently in the safety domain, where a cyclic redundancy check (CRC) is often regarded as “integrity protection.” This doesn’t hold for the security area, where an active attacker can easily forge a CRC.</p>
<p class="hanga"><strong>Availability (A)</strong>    While most parts of a device should be available to operate correctly, this protection goal is used for data or services (on the device or on the backend) if an attacker could possibly interrupt or delay access to them. Examples of corresponding assets are a web service that delivers live data to the device, a stream of random numbers within the device’s main processing unit, or even backups on a server system. Especially in automotive and industrial use cases, a similar requirement exists in the context of <em>hard real-time communication</em>. There, current information (for example, from a safety sensor or a brake controller) has to be available <em>before a given deadline</em>.</p>
<p class="hanga"><strong>Authenticity (Au)</strong>    We can consider this protection goal an extension of integrity. In addition to ensuring that data is free from manipulation, this goal demands that we can clearly verify that the data originates from a specific identity. Authenticity is especially relevant if parts of your device have to be “original,” such as spare parts, the firmware stored in flash memory, or a license file.</p>
<p class="hanga"><strong>Nonrepudiation (Nr)</strong>    Closely related to authenticity, nonrepudiation means that an entity can’t plausibly deny having performed a given operation. In general, this requirement is useful for device and/or user activities that lead to a contract—for example, ordering refill ink for your <span epub:type="pagebreak" id="page_10"/>printer on the device directly, but also if your product includes a pay-per-use functionality.</p>
<p class="hanga"><strong>Privacy (Pr), pseudonymity (Ps), and anonymity (An)</strong>    At least since the introduction of the European General Data Protection Regulation (GDPR) in 2018, privacy and data protection have gained attention. If your device works with personal data (for example, medical equipment), you might want to specify protection goals for that data as well. Typical goals could be <em>pseudonymity</em>, which means that data can be tracked to an alias but not to a real person, or <em>anonymity</em>, which means that processed or collected data can be linked to neither a real person nor an alias.</p>
<p class="indentt">Finally, you might end up with a table of assets and corresponding protection goals, as shown in <a href="ch01.xhtml#ch01tab01">Table 1-1</a>. Note that the Comment column might be useful if you want to give the chosen protection goal more context.</p>
<p class="tabcap" id="ch01tab01"><strong>Table 1-1:</strong> Example Assets and Corresponding Protection Goals</p>
<table class="table-h">
<colgroup>
<col style="width:10%"/>
<col style="width:30%"/>
<col style="width:30%"/>
<col style="width:30%"/>
</colgroup>
<thead>
<tr>
<th class="tab_th"><strong>ID</strong></th>
<th class="tab_th"><strong>Asset</strong></th>
<th class="tab_th"><strong>Protection goal(s)</strong></th>
<th class="tab_th"><strong>Comment</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="bg1">AS01</td>
<td class="bg1">Firmware</td>
<td class="bg1">I, Au</td>
<td class="bg1">Only original firmware</td>
</tr>
<tr>
<td class="bg">AS02</td>
<td class="bg">Certificate private key</td>
<td class="bg">C</td>
<td class="bg">If leaked, device can be cloned</td>
</tr>
<tr>
<td class="bg1">AS03</td>
<td class="bg1">Temperature sensor data</td>
<td class="bg1">I, Au, A</td>
<td class="bg1">Essential to detect device misuse</td>
</tr>
<tr>
<td class="bg">AS04</td>
<td class="bg">Debug interface</td>
<td class="bg">C</td>
<td class="bg">Access only for internal technicians</td>
</tr>
<tr>
<td class="bg1">AS05</td>
<td class="bg1">. . .</td>
<td class="bg1">. . .</td>
<td class="bg1">. . .</td>
</tr>
</tbody>
</table>
<p class="indent">After working through such a heap of information, people are often stunned about the entanglement of device security with various areas of product development and operation. However, they are usually satisfied that the first step toward a secure device is taken and that they learned something new about the product they thought they knew from A to Z.</p>
<div class="box">
<p class="box-title"><strong>IN PRACTICE: THREAT-MODELING WORKSHOPS</strong></p>
<p class="noindent">Several years ago, I was asked to perform a two-day risk analysis workshop at an industrial control system manufacturer. Following my suggestion, the company invited several people from various disciplines.</p>
<p class="indent">During the first hours of the workshop, a developer was explaining how the separation of the critical industrial network and the IT network was implemented in the device, when a guy from technical maintenance intervened: “This is not how we do it out there.” He continued explaining that during maintenance, it’s much more convenient to bridge these networks, and that this bridging connection sometimes remains even during operation.</p>
<p class="indent">This single moment initiated many discussions, contributed to one of the top identified risks and, in the end, led to the development of an additional network-monitoring feature of the device. Subsequently, the maintenance instructions manual was also updated with security in mind. This issue emerged only because <span epub:type="pagebreak" id="page_11"/>of the heterogeneous, interdisciplinary group of people talking about the security of a product.</p>
</div>
<h3 class="h3" id="ch00lev1_10"><strong>Attackers, Threats, and Risks</strong></h3>
<p class="noindent">After establishing a common system for understanding and identifying your device’s assets and environment, the road is paved to analyze the threats and risks for your specific use cases. The goal of this second phase is to develop a set of scenarios that represent your current threat landscape and rate them according to their probability of occurrence and their potential impact on your business and your organization.</p>
<p class="indent">A <em>threat scenario</em> usually consists of a <em>threat actor</em> (the person doing the attacking), a possible <em>vulnerability</em> (an exploitable weakness of your device), <em>attack vectors</em> (the path or method used to attack), and an effect on at least one of the assets you identified earlier. This phase tries to predict which threats your device might face in the future, even if it’s neither developed nor produced yet.</p>
<p class="indent">Of course, you can’t achieve this prediction comprehensively with 100 percent accuracy. It’s a creative process demanding that participants slip into the roles of attackers and imagine ways to reach their malicious goals. Yes, developing threat scenarios might be a bit unstructured for technical staff, surprises could arise, and the results are not cast in stone. You’ll also need to update your scenarios in the future if you discover new threats.</p>
<h4 class="h4" id="ch00lev2_3"><strong><em>Potential Adversaries</em></strong></h4>
<p class="noindentb">A good starting point is usually imagining potential attackers who vary in motivation, opportunities, and resources. The following may serve as basic examples:</p>
<p class="hanga"><strong>Script kiddies</strong>    These attackers don’t necessarily have to be teenagers, but they’re people who analyze devices and services out of curiosity and as a pastime. They usually have few resources (other than spare time), use standard tools available on the internet, and acquire their basic skills from watching videos.</p>
<p class="hanga"><strong>Security researchers</strong>    These people have specialized knowledge and access to powerful equipment, typically at universities. Although they usually don’t have a financial interest, they aim to publish their found vulnerabilities and the preparation of corresponding fixes. In contrast to other attacker types, they’re usually willing to cooperate with companies to improve product security.</p>
<p class="hanga"><strong>Cybercriminals</strong>    Driven by financial profit, organized crime attacks IT products on a daily basis. Whether they’re focused on ransomware, denial-of-service (DoS) attacks, or sale of personal data, these attackers have at least a moderate amount of resources, are actively monitoring industries, and are able to adapt their tools to new scenarios.</p>
<p class="hanga"><span epub:type="pagebreak" id="page_12"/><strong>Product pirates</strong>    Cloning devices is a major concern for embedded systems. These attackers are well equipped to copy hardware designs and software components for their own purposes. They take advantage of the development investments made by the original device manufacturers in order to offer fake products at lower prices.</p>
<p class="hanga"><strong>Nation-state attackers</strong>    Sophisticated equipment, almost endless resources, and unique access to intelligence data are only a few properties of these attackers. They act out of political or military motivation, so they’re usually rather beyond the scope of standard business solutions. However, especially for devices that operate in federal or critical infrastructures, considering such adversaries is important.</p>
<p class="indentt">These broad and general attacker types are helpful for identifying common risks, but usually a device and its applications will have more specific adversaries that allow you to make the threat scenarios more concrete and help you identify individual risks for your organization. For example, in the automotive and motorcycle domain, engine tuning could be a goal of a specific group of attackers who aim to circumvent protection measures in order to apply their custom performance settings.</p>
<p class="indent">Maybe even the customers themselves could have an interest in manipulating their devices. Looking at farming IoT systems, environmental and animal protection activists might be quite realistic attackers with their own objectives, resources, and approaches.</p>
<p class="indent">Finally, don’t forget <em>insiders as attackers</em>, because they have unique knowledge about and access to internal documents, data, and processes. Of course, most employees likely are trustworthy, but thinking about what colleagues could do if they had bad intentions can be worthwhile for this phase. <a href="ch01.xhtml#ch01tab02">Table 1-2</a> shows a sample list of attackers for the assets listed in <a href="ch01.xhtml#ch01tab01">Table 1-1</a> and their corresponding properties.</p>
<p class="tabcap" id="ch01tab02"><strong>Table 1-2:</strong> Examples of Possible Attackers and Properties</p>
<table class="table-h">
<colgroup>
<col style="width:10%"/>
<col style="width:30%"/>
<col style="width:30%"/>
<col style="width:30%"/>
</colgroup>
<thead>
<tr>
<th class="tab_th"><strong>ID</strong></th>
<th class="tab_th"><strong>Attacker</strong></th>
<th class="tab_th"><strong>Motivation</strong></th>
<th class="tab_th"><strong>Resources</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="bg1">AT01</td>
<td class="bg1">Cybercriminal</td>
<td class="bg1">Financial</td>
<td class="bg1">Medium, access to malware</td>
</tr>
<tr>
<td class="bg">AT02</td>
<td class="bg">Script kiddie</td>
<td class="bg">Fun</td>
<td class="bg">Low, internet tools, spare time</td>
</tr>
<tr>
<td class="bg1">AT03</td>
<td class="bg1">Environmental activist</td>
<td class="bg1">Publicity</td>
<td class="bg1">Medium, PR contacts</td>
</tr>
<tr>
<td class="bg">AT04</td>
<td class="bg">Maintenance insider</td>
<td class="bg">Financial/anger</td>
<td class="bg">Technical documents, device account, read access to source code</td>
</tr>
<tr>
<td class="bg1">AT05</td>
<td class="bg1">Customer</td>
<td class="bg1">Financial</td>
<td class="bg1">Daily device usage, time to experiment</td>
</tr>
<tr>
<td class="bg">AT06</td>
<td class="bg">. . .</td>
<td class="bg">. . .</td>
<td class="bg">. . .</td>
</tr>
</tbody>
</table>
<p class="indent">While generating this list, people sometimes remember real-world stories about theft, sabotage, or piracy that occurred in the past. This information can be really helpful in optimizing your future protection efforts.</p>
<h4 class="h4" id="ch00lev2_4"><span epub:type="pagebreak" id="page_13"/><strong><em>Potential Negative Impacts</em></strong></h4>
<p class="noindent">On one side, we have assets that are of central importance for our business, and on the other side, we have suspects waiting for their chance to attack them. The logical next question is, “How could these potentially malicious actors have an impact on our assets?”</p>
<p class="indent">Constructing attack vectors and imagining possible vulnerabilities in your system may result in myriad threat scenarios that probably overlap, increase processing efforts, and still won’t cover everything. One way to address this issue is to try the pragmatic approach of running through your list of assets and applying relevant threats suggested by the <em>STRIDE methodology</em> developed at Microsoft.</p>
<p class="indent"><a href="ch01.xhtml#ch01tab03">Table 1-3</a> explains this methodology by showing what the STRIDE acronym stands for—namely, five standard threats—and then referencing the targets they aim to break as well as sample questions the moderator can ask all participants. For AS01 in <a href="ch01.xhtml#ch01tab01">Table 1-1</a>—a firmware image that carries the protection goals of integrity and authenticity—the task would be to think creatively about ways to tamper with it or spoof the identity of the image’s original manufacturer.</p>
<p class="tabcap" id="ch01tab03"><strong>Table 1-3:</strong> The STRIDE Checklist of Threats</p>
<table class="table-h">
<colgroup>
<col style="width:30%"/>
<col style="width:35%"/>
<col style="width:35%"/>
</colgroup>
<thead>
<tr>
<th class="tab_th"><strong>Threat</strong></th>
<th class="tab_th"><strong>Target</strong></th>
<th class="tab_th"><strong>Question to pose</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="bg1"><strong>S</strong>poofing</td>
<td class="bg1">Authenticity</td>
<td class="bg1">Is there a way to impersonate any entity?</td>
</tr>
<tr>
<td class="bg"><strong>T</strong>ampering</td>
<td class="bg">Integrity</td>
<td class="bg">Is there a way to manipulate any data?</td>
</tr>
<tr>
<td class="bg1"><strong>R</strong>epudiation</td>
<td class="bg1">Nonrepudiation</td>
<td class="bg1">Is there a way to plausibly deny an action?</td>
</tr>
<tr>
<td class="bg"><strong>I</strong>nformation disclosure</td>
<td class="bg">Confidentiality</td>
<td class="bg">Is there a way to read/extract information?</td>
</tr>
<tr>
<td class="bg1"><strong>D</strong>enial of service</td>
<td class="bg1">Availability</td>
<td class="bg1">Is there a way to interrupt/delay a service?</td>
</tr>
<tr>
<td class="bg"><strong>E</strong>levation of privilege</td>
<td class="bg">Authorization</td>
<td class="bg">Is there a way to act without permission?</td>
</tr>
</tbody>
</table>
<p class="indent">If any of the other STRIDE threats seem applicable, add them to your discussion. In the firmware case, for example, you might have confidential intellectual property that hasn’t been considered before. Finally, match any additional threat to your list of attackers and discuss who would be a suitable actor for that threat.</p>
<p class="indentb">In addition to threats that devices and software have in common, physical products face another issue that should be in the back of everyone’s mind while brainstorming threats: <em>they can be attacked physically</em>. In some cases that might not be critical, because if people have physical access to a device, they can also destroy other parts of the machine or system that the device controls. However, physical accessibility makes a difference in at least two situations:</p>
<p class="hanga"><strong>Pre-attack device analysis</strong>    In many cases, devices can be purchased and analyzed for vulnerabilities, cryptographic secrets, and relevant behavior in an attacker-controlled environment. Physical access allows attackers to extract the device’s firmware and perform detailed reverse <span epub:type="pagebreak" id="page_14"/>engineering or to eavesdrop on communication on traces of the printed circuit board (PCB), which might reveal confidential data.</p>
<p class="hanga"><strong>Invisible manipulation</strong>    Using a hammer to “manipulate” a machine usually involves noise and visible damage that humans can detect. However, any physical access or proximity that can be used to alter device or system parameters that aren’t recognizable without deeper analysis of the attacked system might represent a rather strong attack vector that can cause long-lasting impact.</p>
<p class="indentt">Repeating the process for all assets takes time. However, since this format often involves experts from several fields, it is usually restricted to one or a few days in practice. After putting your assets through the mill, you obtain a collection of threat scenarios for your product. <a href="ch01.xhtml#ch01tab04">Table 1-4</a> shows the first rows of a result from an example workshop.</p>
<p class="tabcap" id="ch01tab04"><strong>Table 1-4:</strong> Example Threat Scenarios</p>
<table class="table-h">
<colgroup>
<col style="width:10%"/>
<col style="width:10%"/>
<col style="width:10%"/>
<col style="width:40%"/>
<col style="width:30%"/>
</colgroup>
<thead>
<tr>
<th class="tab_th"><strong>ID</strong></th>
<th class="tab_th"><strong>Asset</strong></th>
<th class="tab_th"><strong>Attacker(s)</strong></th>
<th class="tab_th"><strong>Threat(s)</strong></th>
<th class="tab_th"><strong>Impact(s)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="bg1">TS01</td>
<td class="bg1">AS01</td>
<td class="bg1">AT04</td>
<td class="bg1">Currently no integrity and authenticity protection; maintenance staff has physical access to many devices; knows how to open device and tamper with firmware</td>
<td class="bg1">Dysfunctional product and customer complaints</td>
</tr>
<tr>
<td class="bg">TS02</td>
<td class="bg">AS02</td>
<td class="bg">AT01, AT03</td>
<td class="bg">If purchased, attackers can extract the private key from device firmware; attackers can act as device</td>
<td class="bg">Injection of forged data into backend</td>
</tr>
<tr>
<td class="bg1">TS03</td>
<td class="bg1">AS02</td>
<td class="bg1">AT01, AT03, AT04</td>
<td class="bg1">Attackers might publish the private key online to damage company reputation; anyone in the world can impersonate our devices</td>
<td class="bg1">Media attention; maybe even product recall</td>
</tr>
<tr>
<td class="bg">TS04</td>
<td class="bg">AS03</td>
<td class="bg">AT05</td>
<td class="bg">Physical manipulation of temperature sensor; secure communication channel does not protect against that; temperature is always measured to be cool while actually being continuously over the limit</td>
<td class="bg">Misuse can’t be proven in damage case</td>
</tr>
<tr>
<td class="bg1">TS05</td>
<td class="bg1">. . .</td>
<td class="bg1">. . .</td>
<td class="bg1">. . .</td>
<td class="bg1">. . .</td>
</tr>
</tbody>
</table>
<p class="indent">The noted scenarios will help you illustrate the identified issues and communicate them within your company or to management.</p>
<h4 class="h4" id="ch00lev2_5"><strong><em>No Risks, No Priorities</em></strong></h4>
<p class="noindent">Up to this point, every potential attack vector and every potential vulnerability has been collected without discarding anything as being “not relevant.” <span epub:type="pagebreak" id="page_15"/>However, the list might be long, and resources to handle the identified issues are typically limited. It’s time to separate the wheat from the chaff by rating (at least) two properties of each threat scenario: its probability of occurrence and, if it occurs, its potential impact.</p>
<p class="indent">In the safety domain, you can describe almost every probability of occurrence with a number. If functional safety experts are part of your interdisciplinary workshop, they might offer this methodology and argue that probabilities have to be expressed in numbers. However, no one could ever distill an imagined human adversary into a percentage that has any meaning at all, so ranking probability by a qualitative scale of low, medium, or high is likely best.</p>
<p class="indent">For impact, I also prefer to use the same simple scale of low, medium, or high. However, defining what those terms stand for in each individual analysis is important and depends on the product, the size of your company, and your business cases. For example, your team could agree on relating your impact rating to damage values, as shown in <a href="ch01.xhtml#ch01tab05">Table 1-5</a>.</p>
<p class="tabcap" id="ch01tab05"><strong>Table 1-5:</strong> Example Impact Ratings</p>
<table class="table-h">
<colgroup>
<col style="width:60%"/>
<col style="width:40%"/>
</colgroup>
<thead>
<tr>
<th class="tab_th"><strong>Impact</strong></th>
<th class="tab_th"><strong>Damage</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="bg1">Low</td>
<td class="bg1">$10,000</td>
</tr>
<tr>
<td class="bg">Medium</td>
<td class="bg">$100,000</td>
</tr>
<tr>
<td class="bg1">High</td>
<td class="bg1">$1,000,000</td>
</tr>
</tbody>
</table>
<p class="indent">To get a final <em>risk score</em> per threat scenario, I have one last thing to explain: the probability and impact ratings of low, medium, and high take values of 1, 2, and 3. If you multiply them for a given scenario, you obtain a corresponding risk score.</p>
<p class="indent">After rating all threat scenarios, you end up with a list similar to the one shown in <a href="ch01.xhtml#ch01tab06">Table 1-6</a>. Adding explanations to the ratings allows for better understanding and reasoning, especially weeks after everybody forgets the details of the workshop discussions.</p>
<p class="tabcap" id="ch01tab06"><strong>Table 1-6:</strong> Example Threat Scenario Ratings</p>
<table class="table-h">
<colgroup>
<col style="width:10%"/>
<col style="width:40%"/>
<col style="width:40%"/>
<col style="width:10%"/>
</colgroup>
<thead>
<tr>
<th class="tab_th"><strong>Threat scenario</strong></th>
<th class="tab_th"><strong>Probability of occurrence</strong></th>
<th class="tab_th"><strong>Impact</strong></th>
<th class="tab_th"><strong>Risk score</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="bg1">TS01</td>
<td class="bg1">Low (few opportunities)</td>
<td class="bg1">Low (single device)</td>
<td class="bg1">1</td>
</tr>
<tr>
<td class="bg">TS02</td>
<td class="bg">Medium (offline attack)</td>
<td class="bg">Medium (few cases)</td>
<td class="bg">4</td>
</tr>
<tr>
<td class="bg1">TS03</td>
<td class="bg1">Medium (know-how necessary)</td>
<td class="bg1">High (product recall)</td>
<td class="bg1">6</td>
</tr>
<tr>
<td class="bg">TS04</td>
<td class="bg">Medium (financial interest)</td>
<td class="bg">Medium (if several cases)</td>
<td class="bg">4</td>
</tr>
<tr>
<td class="bg1">TS05</td>
<td class="bg1">. . .</td>
<td class="bg1">. . .</td>
<td class="bg1">. . .</td>
</tr>
</tbody>
</table>
<p class="indent">After you and your colleagues have compiled a list of rated threat scenarios, you can sort it by risk score or present it in a two-dimensional risk matrix with probability and impact as the axes. This approach enables device architects and product managers to better prioritize risks, as there are <span epub:type="pagebreak" id="page_16"/>never enough resources to implement every mitigation and protect from all possible threats.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Spreadsheets and dedicated threat-modeling software can support you in creating and visualizing the threat scenarios described here. But whatever method you use, the process of identifying assets and their protection goals, creatively thinking about attackers and their objectives, and judging the relevance of collected threat scenarios is up to you.</em></p>
</div>
<h3 class="h3" id="ch00lev1_11"><strong>Security Requirements and Security Architecture</strong></h3>
<p class="noindent">Threat modeling and risk analysis are essential for your own company to separate your device’s necessary protection needs from the ones that are only nice to have. However, it’s important to understand that your organization is not the only stakeholder. Customers, certification bodies, and governments all might impose additional security requirements on your product.</p>
<p class="indent">Some of those requirements might overlap with your own interests, and others might be opposed to them. Make sure to handle your identified top-priority risks, but also consider external requirements like legal obligations, customer needs, and industrial standards in your security requirement process.</p>
<p class="indent">If product certification is your goal, this is the point where you should take a look at the detailed requirements of your intended certificate. For example, industrial component manufacturers can align their device security requirements with the protection features demanded by IEC 62443 Part 4-2. But even without a clear certification perspective, documents like ARM’s Platform Security Architecture (PSA) Level 1 questionnaire can serve as guidance and inspiration for creating solid security requirements for your specific product.</p>
<p class="indent">In addition, security requirements always compete with other requirements, such as device performance, backward compatibility, and lower prices for components without security features. Therefore, you need to consider any interference with other requirements at an early stage.</p>
<p class="indent">Considering the whole product life cycle—from development to production to usage in the field to decommissioning—is often neglected in the process of identifying security requirements. Each phase has its own requirements and dependencies. However, if a device’s owner might change or if confidential data on the device has to be destroyed before its disposal has ever been discussed, there might be no corresponding requirement for such purposes, which can lead to headaches later.</p>
<h4 class="h4" id="ch00lev2_6"><strong><em>Risk Treatment</em></strong></h4>
<p class="noindentb">When it comes to defining a security architecture, all previous work on threats, risks, and requirements has to be funneled into a selection of technologies, protection measures, and organizational arrangements that lead to a secure product in the end. You can address risks in multiple ways:</p>
<p class="hanga"><span epub:type="pagebreak" id="page_17"/><strong>Reduce</strong>    A common approach to handling risks is to reduce them. Integrating suitable protection measures can either reduce the probability of a successful attack or limit the damage that could be done. Both strategies lower the risk of a certain threat scenario.</p>
<p class="hanga"><strong>Eliminate</strong>    Sometimes the removal of software components, interfaces, or product features can completely eliminate a given risk. This strategy is perfect from a security point of view, but it’s usually a hard decision to make from a business and marketing perspective.</p>
<p class="hanga"><strong>Transfer</strong>    You can transfer security risks from your company to a supplier or from the manufacturer to the product’s users. Usually, this transfer requires appropriate documentation and/or legal agreements, but it might further contribute to transparency and awareness among your partners and customers.</p>
<p class="hanga"><strong>Accept</strong>    Responsible entities in your company can accept risks, which might be an option if mitigation would be more expensive than handling any security incident that occurs in practice.</p>
<h4 class="h4" id="ch00lev2_7"><strong><em>Secure Development Principles</em></strong></h4>
<p class="noindent">Although Parts II and III of this book are intended to support architects in deciding for or against certain technical security features, you should also keep conceptual principles in mind when developing a security architecture.</p>
<h5 class="h5" id="ch00lev3_1"><strong>Perform Defense in Depth</strong></h5>
<p class="noindent">Every protection measure might fail someday, either because of a sophisticated attacker or an exceptional circumstance. A security architecture should implement multiple layers of protection. If one layer breaks, one or more remaining layers might guarantee security or at least limit potential damage.</p>
<h5 class="h5" id="ch00lev3_2"><strong>Use Proven Secure Technology or Components</strong></h5>
<p class="noindent">Some companies refuse to use existing technology and components from external parties, even if they are of high quality. Of course, in some cases, developing a security component from scratch is reasonable. However, doing so might involve a steep learning curve with many failures. Use software and hardware that has proven to be robust and secure if you don’t have good reasons not to.</p>
<h5 class="h5" id="ch00lev3_3"><strong>Implement Least Privilege</strong></h5>
<p class="noindent">For a solid security architecture, all involved roles and permissions must be documented. When it comes to granting or denying access rights to people and services, specific roles should be allowed access only to the resources necessary to fulfill their tasks. This practice also helps limit the threat potential of insider attacks.</p>
<h5 class="h5" id="ch00lev3_4"><span epub:type="pagebreak" id="page_18"/><strong>Keep It Simple</strong></h5>
<p class="noindent">Complexity and nontransparency are the natural enemies of security because they make it even harder to analyze risks, identify attack paths, and implement effective countermeasures. Maintaining simplicity in your device and security architecture leads to better chances that security efforts actually reach your defined protection goals.</p>
<h5 class="h5" id="ch00lev3_5"><strong>Reduce the Attack Surface</strong></h5>
<p class="noindent">You can add by subtracting! This idiom is very true when it comes to a product’s attack surface. A wireless interface that doesn’t exist can’t be attacked, and a debug port that was removed from the PCB can’t be the entrance point for a physical attacker. Remove all unnecessary features, interfaces, hardware, and software components from your device architecture or at least from the final product design that enters the market.</p>
<div class="box">
<p class="box-title"><strong>IN PRACTICE: DISCARDING FEATURES</strong></p>
<p class="noindent">I was once part of a security consulting team that was invited to participate in architecture discussions for a new industrial product at an early stage. Topics ranged from secure communication to secure storage of device secrets to location tracking of the device while it was moved from one customer’s site to another. Back then, the latter topic was somehow critical, and we spent quite some time discussing it.</p>
<p class="indent">In the end, considerations about security and international laws led to the removal of that tracking mechanism from the list of product features. The risks of forged tracking data and similar attacks were completely eliminated, and product management had peace of mind again.</p>
</div>
<h3 class="h3" id="ch00lev1_12"><strong>Secure Implementation and Security Testing</strong></h3>
<p class="noindent">While the previous sections focused mainly on <em>doing the right things</em>, this section is concerned with <em>doing the things right</em>. Naturally, hardware and software developers want to implement a fully functional, working product. However, if security is not on everybody’s mind (and maybe even on nobody’s mind), you’ll end up with a fully functional product that has several weaknesses and vulnerabilities that might be discovered by criminals, researchers, or customers sooner or later after market launch.</p>
<h4 class="h4" id="ch00lev2_8"><strong><em>Shift Left</em></strong></h4>
<p class="noindent">One strategy to avoid this situation is to <em>shift left</em>, which means that the detection of implementation errors doesn’t happen after rollout, but as soon as possible (as far left as possible) in the development process. Besides enabling fast feedback loops, this also lowers the costs of error detection and correction.</p>
<p class="indent">These considerations are already relevant at the very beginning of the implementation phase as your team makes important decisions that may <span epub:type="pagebreak" id="page_19"/>have crucial security implications, such as central hardware components, an operating system (OS), secure coding rules, and so on. Let’s look at two examples.</p>
<h5 class="h5" id="ch00lev3_6"><strong>Hardware Component Selection</strong></h5>
<p class="noindent">The hardware development for a physical product usually starts earlier than the software development. At some point in time, a project deadline called a <em>hardware freeze</em> will occur, after which you can’t change the components of the device’s hardware anymore. Detecting hardware security issues after that deadline leads to dirty fixes, expensive redesigns, or bad device security.</p>
<p class="indent">Be sure to consider security requirements when selecting the basic hardware components for a device. If component costs aren’t a key factor, choose components that have more security features rather than those that have fewer, which might save you a lot of trouble and money later in the development process.</p>
<h5 class="h5" id="ch00lev3_7"><strong>Programming Language Selection</strong></h5>
<p class="noindent">Ask 10 people for the best programming language for a specific task and you might get 11 answers. However, we’ve seen, especially in the area of embedded systems and IoT devices, that the C language laid the ground for a myriad of memory safety issues that resulted in security vulnerabilities. According to statistics from Android, Chromium, and Microsoft, 70 to 90 percent of their common vulnerabilities and exposures (CVEs) can be traced back to memory management issues. Just imagine how much money and effort you could save if code analysis tools, code reviews, and incident handling for memory management problems were no longer necessary.</p>
<p class="indent">It’s not surprising that Rust is gaining more and more attention in development communities that work on embedded, system-level, and high-performance software, because it’s one solution to overcome the security issues and all the consequential costs of using C or C++.</p>
<div class="box">
<p class="box-title"><strong>IN PRACTICE: PLANNING FOR SECURITY</strong></p>
<p class="noindent">I once had a conversation with a hidden champion at a company in the industrial automation industry. My team and I analyzed one of the company’s products and were surprised to find a secure element (SE) on its PCB. When approached on the subject, the chief technical officer (CTO) explained that the costs of the chip weren’t critical but that security would be one day, so they integrated the SE into their device, even though they didn’t use it at product launch. They were able to activate it for secret storage and secure communication at a later time; preparation for future security challenges is key.</p></div>
<h4 class="h4" id="ch00lev2_9"><strong><em>Continuous Testing and Analysis</em></strong></h4>
<p class="noindent">Of course, initial design decisions can’t anticipate all possible security issues. The second puzzle piece of secure implementations is robust automation of the building, testing, and review processes. Especially during software <span epub:type="pagebreak" id="page_20"/>development, developers must get immediate feedback after weaknesses and potential problems are identified in their code. While security is not the primary target for automation and continuous integration (CI), they contribute to higher quality and reduce human errors, which are typically the origin of security vulnerabilities.</p>
<p class="indent">From a security point of view, be sure to cover the following areas when automating an SDL (some of these are software-specific, but most can also be applied to the hardware development process).</p>
<h5 class="h5" id="ch00lev3_8"><strong>Third-Party Component Transparency</strong></h5>
<p class="noindent">In hardware design, generating a bill of materials (BOM) is a daily routine, but the demand for a software bill of materials (SBOM) for certain products is growing. Both aren’t primarily intended for security purposes but are important for tracking security vulnerabilities in third-party dependencies, including software libraries, microcontrollers, and OSs.</p>
<h5 class="h5" id="ch00lev3_9"><strong>Static Security Testing</strong></h5>
<p class="noindent">Using static application security testing (SAST) in software development is an important part of issue detection. These tools can help you identify insecure functions in the C language: they may detect hardcoded secrets that have to be removed before release and can highlight code sections that might be vulnerable to common security risks like the OWASP Top 10. These static code-analysis tools can be seamlessly integrated into CI pipelines and provide developers with timely feedback.</p>
<h5 class="h5" id="ch00lev3_10"><strong>Dynamic Security Testing</strong></h5>
<p class="noindent">Static analysis can’t detect some vulnerabilities because the related issues result from <em>insecure behavior</em> of software or a device, which means dynamic security testing is necessary. You can automate this testing to a certain extent—for example, by deploying software built in a CI pipeline to a test device that can, in turn, be challenged with test cases. However, since the test space is huge, and dynamic application security testing (DAST) requires specific runtime environments, this discipline usually comes with a significantly higher effort than static analysis.</p>
<h5 class="h5" id="ch00lev3_11"><strong>Implementation Review</strong></h5>
<p class="noindent">While we often reserve the term <em>code review</em> for software processes, we might just as well apply reviews to device hardware design in order to discover implementation weaknesses, the use of forbidden components, or bad design patterns that facilitate physical attacks. Although this is a human task, automation may support you in scheduling reviews or triggering reviews upon changes to critical hardware or software parts.</p>
<h4 class="h4" id="ch00lev2_10"><span epub:type="pagebreak" id="page_21"/><strong><em>Attackers as a Service</em></strong></h4>
<p class="noindent">All the described techniques aim for verification and validation of explicit security requirements and protection features or for avoidance of implementation flaws that might undermine device security. However, while secure implementation and security testing continue to converge to form a secure, incremental, and agile development process, one security testing method is usually applied manually and outside a CI environment: penetration testing.</p>
<p class="indent">In a <em>penetration test</em>, internal or external security experts slip into the role of attackers. By simulating attacks on the device at hand, they try to trigger worst-case scenarios that demonstrate the feasibility of attacks, the involved efforts, and the possible attack paths. In turn, this type of test enables a manufacturer to rework relevant product parts and discover further related issues.</p>
<p class="indent">Since penetration testing is usually a time-limited service, it’s important to use the available days efficiently. If you order a penetration test for your device, make sure to specify three important aspects: the scope; the worst case; and whether you expect black-, gray-, or white-box testing.</p>
<h5 class="h5" id="ch00lev3_12"><strong>Scope</strong></h5>
<p class="noindent">If you don’t set a defined scope for a penetration test, the tester will just look for the easiest way into your device. However, that might include opening up the device, which might be far from the attack model you had in mind.</p>
<p class="indent">Clarify your expectations. Are physical attacks in scope? Which interfaces should be attacked, and which are out of scope? Is it okay to manipulate the device’s firmware?</p>
<p class="indent">The focus isn’t to narrow the scope to a minimum in order to get a positive test result. The aim of a clear scope is to yield results that support your protection efforts in the best possible way.</p>
<h5 class="h5" id="ch00lev3_13"><strong>Worst Case</strong></h5>
<p class="noindent">Usually, your device carries a few critical assets, the crown jewels that, if compromised, would lead to severe damage. Optimally, you’ve already identified them in your risk analysis earlier in the process, and you’re probably most interested in attacks that have an effect on those assets. If you don’t specify them, penetration testers might spend days trying to find fancy ways to manipulate a graphical user interface (GUI) that is relevant only for internal purposes.</p>
<h5 class="h5" id="ch00lev3_14"><strong>Black-/Gray-/White-Box Testing</strong></h5>
<p class="noindent"><em>Black-box attacks</em> assume that an attacker has no information about a device at all, which makes sense if you want to see what information an attacker can collect about a given product in a short amount of time. However, it doesn’t make sense to do this for weeks and essentially pay a penetration tester for reverse engineering information you already know.</p>
<p class="indent"><span epub:type="pagebreak" id="page_22"/>One way to improve efficiency for the manufacturer could be a phased approach. After a few days of black-box testing, the testers could present initial results and propose possible next (reverse-engineering) steps. However, instead of actually reversing the device afterward, the manufacturer could supply the testers with information about protocols, hardware, and/or software so they can continue their appreciated penetration-testing work. You can repeat this procedure multiple times, resulting in a time-saving process that’s much more likely to identify valuable security insights.</p>
<div class="box">
<p class="box-title"><strong>IN PRACTICE: PENETRATION-TESTING GOALS</strong></p>
<p class="noindent">“Could you perform a penetration test for our product?” That was the question that started off my interesting journey with an industrial partner some years ago. I could have said, “Sure! Give me one or two of your devices, and I’ll see what we can do for you!” Instead, I initiated a discussion about security testing, an SDL, and where the latter should actually start, namely, at the beginning.</p>
<p class="indent">Luckily, I encountered open-minded and motivated people willing to establish an SDL and to really improve their device’s security. We ended up doing a solid threat and risk analysis and, based on the results, set priorities for mitigation development. The bottom line is that driving the security of a product solely by the results of a penetration test is not a reasonable strategy. It bears repeating.</p>
</div>
<p class="indent">Finally, don’t forget that for a physical product like an IoT device, the last steps of implementation do not happen in the offices of the development team but during production in a factory. Selecting a secure production environment, protecting your device assets while being transferred to a production site, and performing post-production testing to validate the proper activation of protection features are essential for a securely implemented device.</p>
<h3 class="h3" id="ch00lev1_13"><strong>Vulnerability Monitoring and Response</strong></h3>
<p class="noindent">No matter how large your company is, how much effort you put into organizing your secure development process, or how smart your engineering team is, a chance always remains that vulnerabilities are hidden in your device. Some might result from human failure during development, others might originate in third-party components, and still others might emerge because of advancements in attacker tools and methodologies that you couldn’t foresee. If you acknowledge that fact, the best thing you can do is be prepared and plan for the following phases to run in a structured way.</p>
<h4 class="h4" id="ch00lev2_11"><strong><em>Reporting Vulnerabilities</em></strong></h4>
<p class="noindent">Some customers, penetration testers, and security researchers honestly care about your product’s security and will report found vulnerabilities to manufacturers in a responsible, coordinated disclosure process. However, if your website doesn’t list a security contact, such as a simple <em><a href="mailto:security@company.com">security@company.com</a></em>, <span epub:type="pagebreak" id="page_23"/>those people might have trouble reporting their findings to somebody who cares. They might then use the <em><a href="mailto:info@company.com">info@company.com</a></em> contact, but the message might drown in that inbox, and you’ll never learn about the discovered issue.</p>
<p class="indent">In other cases, finders of vulnerabilities will turn to national or international security organizations or even to the media to cause attention, which is probably not what you want. Establish a simple, visible security contact on your web page. Second, some people report security issues to mailing lists or vulnerability databases instead of contacting the manufacturer. Monitoring relevant sources for your industry is essential for detecting and learning about vulnerabilities as early as possible.</p>
<h4 class="h4" id="ch00lev2_12"><strong><em>Reviewing and Assessing Vulnerability Reports</em></strong></h4>
<p class="noindent">A vulnerability report can range from a short email message to a comprehensive analysis document. After receiving a report, first review it to check whether it actually is a security issue or intended device behavior, or whe- ther the researcher made some mistakes. If your product is prone to the described attack vector, the follow-up task is to clarify why. The result of this phase should be an internal understanding and rating of the vulnerability at hand.</p>
<h4 class="h4" id="ch00lev2_13"><strong><em>Fixing or Addressing the Issue</em></strong></h4>
<p class="noindent">If the cause of the problem lies within device software that can be updated, you can develop a patch with two goals in mind. On the one hand, it should eliminate the vulnerability as comprehensively as possible. On the other hand, it shouldn’t impact any other device features or properties.</p>
<p class="indent">In addition, consider the possibility of mitigating the vulnerability by device reconfiguration that even the customer can perform. In some cases, hardware or non-updatable software is responsible for a security issue. These situations are hard to handle because they might require physical access to every single device or even a product recall.</p>
<h4 class="h4" id="ch00lev2_14"><strong><em>Testing</em></strong></h4>
<p class="noindent">Whether the solution is a software patch, a physical rework, or a configuration workaround, it must be tested before it’s rolled out to all devices in the field. In some cases, updates might impair device performance; in others, changes to the software could transfer the issue to another part of the device and create a new vulnerability. Make sure your solution does exactly what it is supposed to do.</p>
<h4 class="h4" id="ch00lev2_15"><strong><em>Disclosing the Solution</em></strong></h4>
<p class="noindent">One day, your fix will be released to customers. Depending on industry standards, the severity of the found issue, and the efficiency of your vulnerability-response handling, one week or more than a year might have passed since the initial report. However, even at that point, the world doesn’t know the <span epub:type="pagebreak" id="page_24"/>details. Make sure your proposed solution is accompanied by a helpful explanation of the problem that clearly indicates actions for customers, administrators, or operators. Be prepared to answer media requests if your product is of public interest.</p>
<h4 class="h4" id="ch00lev2_16"><strong><em>Avoiding Future Issues</em></strong></h4>
<p class="noindent">A secure development process is a continuous improvement cycle. Every found vulnerability should lead to discussions about possible enhancements for your development process in order to avoid similar issues in the future.</p>
<h4 class="h4" id="ch00lev2_17"><strong><em>Establishing Trust</em></strong></h4>
<p class="noindent">It’s in every manufacturer’s best interest to establish a trusting relationship with the people who discover and report vulnerabilities. These people actually support your secure development process without being on your payroll. Clear and regular communication about the status of the vulnerability-handling process is essential.</p>
<p class="indent">Depending on the severity and extent of the found issue, you might consider rewards or security bounties to express your appreciation. But even if you feel like the reported issue is only a trifle, offering a little thank-you might be worthwhile to acknowledge the reporters’ efforts and encourage them to find more critical weaknesses in the future.</p>
<div class="box">
<p class="box-title"><strong>IN PRACTICE: VULNERABILITY REPORTING</strong></p>
<p class="noindent">I once was part of a team that identified several vulnerabilities in a product of an international corporation. After a quick online search, we found a vulnerability-reporting form provided by its Asian headquarters and were confident that the company had a solid vulnerability-response process in place. We filled in all the details, attached our comprehensive 25-page analysis, and hoped for the best.</p>
<p class="indent">We soon received an email message that more or less read like this: “Thank you for your report, but we think there is not much for us to do.” A bit stunned, we tried to stress again that we found critical issues, without success. Next, we reported the issues to a German security organization that forwarded them to the manufacturer’s European contact and stressed their relevance. After several months, a team of experts concluded that the vulnerability-handling engineer in Asia just misjudged our report. They assigned multiple CVEs.</p>
<p class="indent">However, if we had been less forgiving, the issue could have gone public, cybercriminals could have been developing exploits within weeks, and the reputation of that corporation could have been severely damaged, merely because a single person in the vulnerability-handling process said, “I don’t think that has much relevance.”</p>
</div>
<p class="indent">If you still think, “Nah, nobody will look for or find vulnerabilities in our devices,” consider the consequences if someone does. If you don’t prepare for a vulnerability-handling process, one of two scenarios might result. A device vulnerability might get too little attention because nobody cares or feels responsible, which might lead to attacks in the field, real damages on the <span epub:type="pagebreak" id="page_25"/>customer side, bad press, and loss of reputation for your product or company. Or, if a vulnerability report causes everybody in your team or even beyond to run around like frightened chickens, vulnerability response becomes a chaotic process that exhausts emotions and resources and will not deliver a reliable solution for the issue.</p>
<h3 class="h3" id="ch00lev1_14"><strong>Summary</strong></h3>
<p class="noindent">This chapter summarized important activities and processes that organizations should follow when aiming for secure products. In the beginning, I explained that you can choose from multiple guidelines that are similar in content. While the Microsoft and OWASP recommendations are targeted at software products, IEC 62443 Part 4 is clearly meant for industrial components that can be certified.</p>
<p class="indent">A basic requirement for all secure development processes is that people are aware of risks and receive the security training they need for their daily tasks. The key to creating a secure product is a solid analysis of assets, corresponding protection goals, possible attackers, threats, and involved risks. You can tackle this task with a structured approach that leads to transparency, explicit trust and risk decisions, and clear documentation.</p>
<p class="indent">Based on this preliminary work, you can subsequently implement product-specific security requirements and an individual security architecture. Cultivate secure implementation habits like secure coding among developers and engineers, and check implementation results with security testing regularly. Vulnerability monitoring together with efficient and effective vulnerability-response processes complete the security life cycle of a high-quality product.</p>
<p class="indent">If you want to dive deeper into the area of secure development processes and corresponding methodologies, take a look at <em>Designing Secure Software</em> by Loren Kohnfelder (No Starch Press, 2021) and Adam Shostack’s <em>Threat Modeling: Designing for Security</em> (Wiley, 2014).<span epub:type="pagebreak" id="page_26"/></p>
</div></body></html>