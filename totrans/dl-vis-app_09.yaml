- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Classification
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: An important application of machine learning involves looking at a set of inputs,
    comparing each one to a list of possible classes (or categories), and assigning
    each input to its most probable class. This process is called *classification*
    or *categorization*, and we say that it’s carried out by a *classifier.* We can
    use classes for tasks as diverse as identifying the words someone has spoken into
    their cell phone, what animals are visible in a photograph, or whether a piece
    of fruit is ripe or not.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we look at the basic ideas behind classification. We don’t
    consider specific classification algorithms here because we will get into those
    in Chapter 11\. Our goal now is just to become familiar with the principles. We
    also look at *clustering*, which is a way to automatically group together samples
    that don’t have labels. We wrap up by looking at how spaces of four and more dimensions
    can often foil our intuition, leading to potential problems when we’re training
    a deep learning system. Things can work in unexpected and surprising ways in spaces
    of more than three dimensions.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Two-Dimensional Binary Classification
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Classification is a big topic. Let’s start with a high-level overview of the
    process and then dig into some specifics.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: A popular way to train a classifier uses *supervised learning*. We begin by
    gathering a collection of *samples*, or pieces of data, that we want to classify.
    We call this the *training set*. We also prepare a list of *classes,* or categories,
    such as what animals might be in a photo, or what genre of music should be assigned
    to an audio sample. Finally, we manually consider each example in the training
    set, and determine which class it should be assigned to. This is called that sample’s
    *label.*
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Then we provide the computer with each sample, one at a time, but we don’t give
    it the label. The computer processes the sample and comes up with its own *prediction*
    of what class it should be assigned to. Now we compare the computer’s prediction
    with our label. If the classifier’s prediction doesn’t match our label, we modify
    the classifier a little so that it’s more likely to predict the correct class
    if it sees this sample again. We call this *training*, and say that the system
    is *learning*. We do this over and over, often with thousands or even millions
    of samples, recycled over and over. Our goal is to gradually improve the algorithm
    until its predictions match our labels so often that we feel it’s ready to be
    released to the world, where we expect it will be able to correctly classify new
    samples it’s never seen before. At that point we test it with new data to see
    how well it really works, and if it’s ready to be used for real.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at this process a little more closely.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: To get started, let’s assume that our input data belongs to only two different
    classes. Using only two classes simplifies our discussion of classification, without
    missing any key points. Because there are only two possible labels (or classes)
    for every input, we call this *binary classification*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Another way to make things easy is to use two-dimensional (2D) data, so every
    input sample is represented by exactly two numbers. This is just complicated enough
    to be interesting, but still easy to draw, because we can show each sample as
    a point on the plane. In practical terms, it means that we have a bunch of points,
    or dots, on the page. We can use color and shape coding to show each sample’s
    label and the computer’s prediction. Our goal is to develop an algorithm that
    can predict every label accurately. When it does, we can turn the algorithm loose
    on new data that doesn’t have labels and rely on it to tell us which inputs belong
    to which class.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: We call this a *2D binary classification system*, where “2D” refers to the two
    dimensions of the point data, and “binary” refers to the two classes.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: The first set of techniques that we’re going to look at are collectively called
    *boundary methods*. The idea behind these methods is that we can look at the input
    samples drawn on the plane and find a line or curve that divides up the space
    so that all the samples with one label are on one side of the curve (or boundary),
    and all those with the other label are on the other side. We’ll see that some
    boundaries are better than others when it comes to predicting future data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Let’s make things concrete using chicken eggs. Suppose that we’re farmers with
    a lot of egg-laying hens. Each of these eggs might be fertilized and growing a
    new chick, or unfertilized. Let’s suppose that if we carefully measure some characteristics
    of each egg (say, its weight and length), we can tell if it’s fertilized or not.
    (This is completely imaginary, because eggs don’t work that way! But let’s pretend
    they do.) We bundle the two *features* of weight and length together to make a
    *sample*. Then we hand the sample to the classifier, which assigns it either the
    class “fertilized” or “unfertilized.”
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Because each egg that we use for training needs a label, or a known correct
    answer, we use a technique called *candling* to decide if an egg is fertilized
    or not (Nebraska 2017). Someone skilled at candling is called a *candler*. Candling
    involves holding up the egg in front of a bright light source. Originally candlers
    used a candle, but now they use any strong light source. By interpreting the fuzzy
    dark shadows cast by the egg’s contents onto the eggshell, a skilled candler can
    tell if that egg is fertilized or not. Our goal is to get the classifier to give
    us the same results as the labels determined by a skilled candler.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, we want our *classifier* (the computer) to consider each *sample*
    (an egg) and use its *features* (weight and length) to make a *prediction* (fertilized
    or unfertilized). Let’s start with a bunch of *training data* that gives the weight
    and length of some eggs. We can plot this data on a grid with weight on one axis
    and length on the other. [Figure 7-1](#figure7-1) shows our starting data. Fertilized
    eggs are shown with a red circle and unfertilized eggs with a blue box. With this
    data, we can draw a straight line between the two groups of eggs. Everything on
    one side of the line is fertilized, and everything on the other is unfertilized.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们希望我们的*分类器*（计算机）能够考虑每个*样本*（鸡蛋），并利用其*特征*（重量和长度）做出*预测*（受精或未受精）。让我们从一批*训练数据*开始，这些数据给出了某些鸡蛋的重量和长度。我们可以在一个网格上绘制这些数据，将重量作为一个轴，长度作为另一个轴。[图
    7-1](#figure7-1)展示了我们的初始数据。受精的鸡蛋用红色圆圈表示，未受精的鸡蛋用蓝色方框表示。通过这些数据，我们可以在两个鸡蛋群体之间画一条直线。直线一侧的所有鸡蛋都是受精的，另一侧的则是未受精的。
- en: '![F07001](Images/F07001.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![F07001](Images/F07001.png)'
- en: 'Figure 7-1: Classifying eggs. The red circles are fertilized. The blue squares
    are unfertilized. Each egg is plotted as a point given by its two dimensions of
    weight and length. The orange line separates the two clusters.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-1：鸡蛋分类。红色圆圈表示受精的，蓝色方块表示未受精的。每个鸡蛋被绘制为一个点，依据其重量和长度的两个维度。橙色线将两类分开。
- en: We’re done with our classifier! When we get new eggs (without known labels),
    we can just look to see which side of the line they lie on when plotted. The eggs
    that are on the fertilized side get assigned the class “fertilized,” and those
    on the unfertilized side are assigned the class “unfertilized.” [Figure 7-2](#figure7-2)
    shows the idea.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分类器完成了！当我们得到新的鸡蛋（没有已知标签时），只需要查看它们被绘制时位于哪一边。位于受精一侧的鸡蛋被归类为“受精”，位于未受精一侧的鸡蛋被归类为“未受精”。[图
    7-2](#figure7-2)展示了这个概念。
- en: '![F07002](Images/F07002.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![F07002](Images/F07002.png)'
- en: 'Figure 7-2: Classifying eggs. Left: The boundary. Second from left: Showing
    the two regions, or domains, made by the boundary. Third from left: Four new samples
    to be classified. Far right: The classes assigned to the new samples.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-2：鸡蛋分类。左：边界。第二个从左：显示由边界划分的两个区域或域。第三个从左：四个新的样本待分类。最右边：新样本被分配的类别。
- en: Let’s say that this works out great for a few seasons, and then we buy a whole
    lot of chickens of a new breed. Just in case their eggs are different than the
    ones we’ve had before, we candle a day’s worth of new eggs from both breeds manually
    to determine if they’re fertilized or not, and then we plot the results as before.
    [Figure 7-3](#figure7-3) shows our new data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这几季都进展顺利，然后我们购买了一大批新种类的鸡。为了防止它们的鸡蛋和我们之前的不同，我们手动检查了来自两种鸡的新鸡蛋，并记录是否受精，然后像之前一样绘制结果。[图
    7-3](#figure7-3)展示了我们的新数据。
- en: '![F07003](Images/F07003.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![F07003](Images/F07003.png)'
- en: 'Figure 7-3: When we add some new types of chickens to our flock, determining
    which eggs are fertilized based just on the weight and length may get trickier.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-3：当我们将一些新的鸡种加入到我们的鸡群中时，仅根据重量和长度来判断鸡蛋是否受精可能会变得更加复杂。
- en: The two groups are still distinct, which is great, but now they’re separated
    by a squiggly curve rather than a straight line. That’s no problem, because we
    can use the curve just like the straight line from before. When we have additional
    eggs to classify, each egg gets placed on this diagram. If it’s in the red zone
    it’s predicted to be fertilized, and if it’s in the blue zone it’s predicted to
    be unfertilized. When we can split things up this nicely, we call the sections
    into which we chop up the plane *decision regions*, or *domains*, and the lines
    or curves between them *decision boundaries*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个群体仍然很清晰可分，这很棒，但现在它们是通过一条弯曲的曲线而不是直线来分开的。这没问题，因为我们可以像之前一样使用这条曲线。当我们有额外的鸡蛋需要分类时，每个鸡蛋会被放置在这个图表上。如果它位于红色区域，就预测为受精；如果它位于蓝色区域，就预测为未受精。当我们能够这样清晰地将事物区分开时，我们称将平面划分成的区域为*决策区域*，它们之间的线或曲线称为*决策边界*。
- en: Let’s suppose that word gets out and people love the eggs from our farm, so
    the next year we buy yet another group of chickens of a third variety. As before,
    we manually candle a bunch of eggs and plot the data, this time getting the diagram
    shown in [Figure 7-4](#figure7-4).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 假设消息传开了，人们都喜欢我们农场的鸡蛋，于是第二年我们又买了一批第三种品种的鸡。像之前一样，我们手动检查了一些鸡蛋并绘制了数据，这次得到的图表如[图
    7-4](#figure7-4)所示。
- en: '![F07004](Images/F07004.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![F07004](Images/F07004.png)'
- en: 'Figure 7-4: Our new purchase of chickens has made it much harder to distinguish
    the fertilized eggs from the unfertilized eggs.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: We still have a mostly red region and a mostly blue region, but we don’t have
    a clear way to draw a line or curve to separate them. Let’s take a more general
    approach and, rather than predict a single class with absolute certainty, let’s
    assign each possible class its own *probability.*
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 7-5](#figure7-5) uses color to represent the probability that a point
    in our grid has a particular class. For each point, if it’s bright red, then we’re
    very sure that egg is fertilized, while diminishing intensities of red correspond
    to diminishing probabilities of fertility. The same interpretation holds for the
    unfertilized eggs, shown in blue.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '![F07005](Images/F07005.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-5: Given the overlapping results shown at the far left, we can give
    every point a probability of being fertilized, as shown in the center where brighter
    red means the egg is more likely to be fertilized. The image at the far right
    shows a probability for the egg being unfertilized.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: An egg that lands solidly in the dark-red region is probably fertilized, and
    an egg in the dark-blue region is probably unfertilized. In other places, the
    right class isn’t so clear. How we proceed depends on our farm’s policy. We can
    use our ideas of accuracy, precision, and recall from Chapter 3 to shape that
    policy and tell us what kind of curve to draw to separate the classes. For example,
    let’s say that “fertilized” corresponds to “positive.” If we want to be very sure
    we catch all the fertilized eggs and don’t mind some false positives, we might
    draw a boundary as in the center of [Figure 7-6](#figure7-6).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if we want to find all the unfertilized eggs, and don’t mind
    false negatives, we might draw the boundary as in the right of [Figure 7-6](#figure7-6).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '![F07006](Images/F07006.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-6: Given the results at the far left, we may choose a policy shown
    in the center, which accepts some false positives (unfertilized eggs classified
    as fertilized). Or we may prefer to correctly classify all unfertilized eggs,
    with the policy shown at the right.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'When the decision regions have sharp boundaries and don’t overlap, as in the
    center and right images in [Figure 7-6](#figure7-6), the probabilities for each
    sample are easy: the class where the sample falls is a certainty with probability
    1, and the other classes have probability 0\. But in the more frequent case, when
    the regions are fuzzy or overlap, as in [Figure 7-5](#figure7-5), both classes
    might have nonzero probabilities.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, eventually we always have to convert probabilities into a decision:
    is this egg fertilized or not? Our final decision is influenced by the computer’s
    prediction, but ultimately, we also need to account for human factors and what
    the decision means for us.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 2D Multiclass Classification
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our eggs are selling great, but there’s a problem. We’ve only been distinguishing
    between fertilized and unfertilized eggs. As we learn more about eggs, we discover
    that there are two different ways an egg ends up as unfertilized. An egg that
    is unfertilized because it was never fertilized is called a *yolker*. These are
    good for eating. Fertilized eggs we can sell to other farmers are called *winners*.
    But in some fertilized eggs the developing embryo stopped growing for some reason
    and died. Such an egg is called a *quitter* (Arcuri 2016). We don’t want to sell
    quitters, because they can burst unexpectedly and spread harmful bacteria. We
    want to identify the quitters and dispose of them.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have three classes of egg: winners (viable fertilized eggs), yolkers
    (safe unfertilized eggs), and quitters (unsafe fertilized eggs). As before, let’s
    pretend that we can tell these three kinds of eggs apart just on the basis of
    their weight and length. [Figure 7-7](#figure7-7) shows a set of measured eggs,
    along with the classes we manually assigned to them by candling the eggs.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![F07007](Images/F07007.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-7: Left: Three classes of eggs. The red circles are fertilized. The
    blue squares are unfertilized but edible yolkers. The yellow triangles are quitters
    that we want to remove from our incubators. Right: Possible boundaries and regions
    for each class.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: The job of assigning one of these three classes to new inputs is called *multiclass
    classification*. When we have multiple classes, we again find the boundaries between
    the regions associated with different classes. When a trained multiclass classifier
    has been released to the world and receives a new sample, it determines which
    region the sample falls into, and then assigns that sample the class corresponding
    to that region.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we might add in more features (or dimensions) to each sample,
    such as egg color, average circumference, and the time of day the egg was laid.
    This would give us a total of five numbers per egg. Five dimensions is a weird
    place to think about, and we definitely can’t draw a useful picture of it. But
    we can reason by analogy to the situation we can picture. In 2D, our data points
    tended to clump together in their locations, allowing us to draw boundary lines
    (and curves) between them. In higher dimensions, the same thing is true for the
    most part (we discuss this idea more near the end of the chapter). Just as we
    broke up our 2D square into several smaller 2D shapes, each one for a different
    class, we can break up our 5D space into multiple, smaller 5D shapes. These 5D
    regions also each define a different class.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: The math doesn’t care how many dimensions we have, and the algorithms we build
    upon the math don’t care, either. That’s not to say that we, as people, don’t
    care, because typically, as the number of dimensions goes up, the running time
    and memory consumption of our algorithms goes up as well. We’ll come back to some
    more issues involved in working with high-dimensional data at the end of the chapter.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 数学原理不关心我们有多少个维度，我们基于这些数学原理构建的算法也不在乎。这并不是说我们作为人类不在乎，因为通常情况下，维度数越多，算法的运行时间和内存消耗也会相应增加。我们将在本章末尾回到处理高维数据时涉及的一些问题。
- en: Multiclass Classification
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多分类分类
- en: Binary classifiers are generally simpler and faster than multiclass classifiers.
    But in the real world, most data have multiple classes. Happily, instead of building
    a complicated multiclass classifier, we can build a whole bunch of binary classifiers
    and combine their results to produce a multiclass answer. Let’s look at two popular
    methods for this technique.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类器通常比多分类器更简单、更快速。但在实际应用中，大多数数据都有多个类别。幸运的是，我们可以通过构建多个二分类器并结合它们的结果来生成一个多分类的答案，而无需构建一个复杂的多分类器。让我们看看两种流行的方法来实现这一技术。
- en: One-Versus-Rest
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一对其余
- en: 'Our first technique goes by several names: *one-versus-rest* *(OvR)*, *one-versus-all*
    *(OvA)*, *one-against-all* *(OAA)*, or the *binary relevance* method. Let’s suppose
    that we have five classes for our data, named with the letters A through E. Instead
    of building one complicated classifier that assigns one of these five labels,
    let’s instead build five simpler, binary classifiers and name them A through E
    for the class each one focuses on. Classifier A tells us whether a given piece
    of data does or does not belong to class A. Because it’s a binary classifier,
    it has one decision boundary that splits the space into two regions: class A and
    everything else. We can now see where the name “one-versus-rest” comes from. In
    this classifier, class A is the one, and classes B through E are the rest.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一种技术有几个名字：*一对多*（*OvR*）、*一对所有*（*OvA*）、*一对其余*（*OAA*）或*二元相关性*方法。假设我们有五个类别的数据，分别用字母
    A 到 E 命名。我们不是构建一个复杂的分类器来分配这五个标签，而是构建五个更简单的二分类器，并分别命名为 A 到 E，表示每个分类器专注于的类别。分类器
    A 告诉我们一个给定数据是否属于类别 A。由于它是一个二分类器，它有一个决策边界，将空间划分为两个区域：类别 A 和其他类别。我们现在可以理解“一对其余”这个名称的来源了。在这个分类器中，类别
    A 是“一个”，类别 B 到 E 是“其余”。
- en: Our second classifier, named Classifier B, is another binary classifier. This
    time it tells us whether a sample is, or is not, in class B. In the same way,
    Classifier C tells us whether a sample is or is not in class C, and Classifiers
    D and E do the same thing for classes D and E. [Figure 7-8](#figure7-8) summarizes
    the idea. Here we used an algorithm that takes into account all of the data when
    it builds the boundary for each classifier.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二个分类器，命名为分类器 B，是另一个二分类器。它告诉我们一个样本是否属于类别 B。以此类推，分类器 C 告诉我们一个样本是否属于类别 C，而分类器
    D 和 E 则分别对类别 D 和 E 执行相同的操作。[图 7-8](#figure7-8) 总结了这个概念。在这里，我们使用了一种算法，它在为每个分类器构建边界时考虑了所有数据。
- en: '![f07008](Images/f07008.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![f07008](Images/f07008.png)'
- en: 'Figure 7-8: One-versus-rest classification. Top row: Samples from five different
    classes. Bottom row: The decision regions for five different binary classifiers.
    The colors from purple to pink show increasing probability that a point belongs
    to that class.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-8：一对多分类。上排：来自五个不同类别的样本。下排：五个不同二分类器的决策区域。从紫色到粉色的颜色显示了该点属于某类别的概率逐渐增加。
- en: Note that some locations in the 2D space can belong to more than one class.
    For example, points in the upper-right corner have nonzero probabilities from
    classes A, B, and D.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，二维空间中的某些位置可能属于多个类别。例如，右上角的点来自类别 A、B 和 D，且它们的概率非零。
- en: To classify an example, we run it through each of our five binary classifiers
    in turn, getting back the probability that the point belongs to each class. We
    then find the class with the largest probability, and that’s the class the point
    is assigned to. [Figure 7-9](#figure7-9) shows this in action.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对一个样本进行分类，我们依次通过我们的五个二分类器，得到该点属于每个类别的概率。然后，我们找到概率最大的类别，这就是该点被分配到的类别。[图 7-9](#figure7-9)
    展示了这一过程的实际操作。
- en: '![F07009](Images/F07009.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![F07009](Images/F07009.png)'
- en: 'Figure 7-9: Classifying a sample using one-versus-rest. The new sample is the
    black dot.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-9：使用一对其余方法对样本进行分类。新样本是黑色的点。
- en: In [Figure 7-9](#figure7-9), the first four classifiers all return low probabilities.
    The classifier for class E assigns the point a larger probability than the others,
    so the point is predicted to be from class E.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 7-9](#figure7-9)中，前四个分类器的返回概率都较低。类别E的分类器为该点分配了比其他分类器更大的概率，因此该点被预测为来自类别E。
- en: The appeals of this approach are its conceptual simplicity and its speed. The
    downside is that we have to teach (that is, learn boundaries for) five classifiers
    instead of just one, and we have to then classify every input sample five times
    to find which class it belongs to. When we have large numbers of classes with
    complex boundaries, the time required to run the sample through lots of binary
    classifiers can add up. On the other hand, we can run all five classifiers in
    parallel, so if we have the right equipment, we can get our answers in the same
    amount of time it takes for any one of them. For any application, we need to balance
    the tradeoffs depending on our time, budget, and hardware constraints.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的吸引力在于它的概念简单且速度较快。缺点是我们需要训练五个分类器，而不是仅仅一个，并且随后我们必须对每一个输入样本进行五次分类，才能找出它属于哪个类别。当类别数较多且边界复杂时，运行大量二元分类器所需的时间会积累起来。另一方面，我们可以将所有五个分类器并行运行，因此如果我们有合适的设备，所有分类器的运行时间将与其中任何一个分类器的运行时间相同。对于任何应用，我们需要根据时间、预算和硬件限制来平衡这些权衡。
- en: One-Versus-One
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一对一
- en: Our second approach that uses binary classifiers for multiple classes is called
    *one-versus-one* *(OvO)*, and it uses even more binary classifiers than OvR. The
    general idea is to look at every pair of classes in our data and build a classifier
    for just those two classes. Because the number of possible pairings goes up quickly
    as the number of classes increases, the number of classifiers in this method also
    grows quickly with the number of classes. To keep things manageable, let’s work
    with only four classes this time, as shown in [Figure 7-10](#figure7-10).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二种方法是使用二元分类器处理多类别问题，称为*一对一*（*OvO*），它使用的二元分类器数量比一对多（OvR）还要多。一般来说，方法的核心思想是查看数据中每一对类别，并为这两类建立一个分类器。由于随着类别数的增加，可能的配对数迅速增加，因此这种方法中的分类器数量也会随着类别数的增加而迅速增长。为了让事情更容易管理，这次我们只考虑四个类别，如[图
    7-10](#figure7-10)所示。
- en: '![F07010](Images/F07010.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![F07010](Images/F07010.png)'
- en: 'Figure 7-10: Left: Four classes of points for demonstrating OvO classification.
    Right: Names for the clusters.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-10：左侧：展示OvO分类的四个类别点。右侧：各簇的名称。
- en: We start with a binary classifier that is trained with data that is onlyfrom
    classes A and B. For the purposes of training this classifier, we simply leave
    out all the samples that are not labeled A or B, as if they don’t even exist.
    This classifier finds a boundary that separates the classes A and B. Now every
    time we feed a new sample to this classifier, it tells us whether it belongs to
    class A or B. Since these are the only two options available to this classifier,
    it classifies every point in our dataset as either A or B, even when it’s neither
    one. We’ll soon see why this is okay.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个二元分类器开始，该分类器仅使用来自类别A和B的数据进行训练。为了训练这个分类器，我们仅仅排除掉所有未标记为A或B的样本，就好像它们根本不存在一样。这个分类器找到一个边界，将类别A和B分开。现在，每次我们将一个新样本输入到这个分类器时，它会告诉我们该样本属于类别A还是B。由于这是该分类器唯一可以选择的两个选项，因此它会将数据集中每个点都分类为A或B，即使它其实不是这两个中的任何一个。我们很快就会明白为什么这样做是可以的。
- en: Next, we make a classifier trained with only data from classes A and C and another
    for classes A and D. The top row of [Figure 7-11](#figure7-11) shows this graphically.
    Now we keep going for all the other pairings, building binary classifiers that
    are trained with data onlyfrom classes B and C, and B and D, as in the second
    row of [Figure 7-11](#figure7-11). Finally, we get to the last pairing of classes
    C and D, in the bottom row of [Figure 7-11](#figure7-11). The result is that we
    have six binary classifiers, each of which tells us which of two specific classes
    the data most belongs to.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们建立一个仅使用类别A和C的数据进行训练的分类器，另一个则用于类别A和D。[图 7-11](#figure7-11)的顶部行以图形方式展示了这一过程。接着，我们继续进行所有其他配对，构建仅使用类别B和C以及B和D的数据进行训练的二元分类器，正如[图
    7-11](#figure7-11)第二行所示。最后，我们到达类别C和D的配对，这一过程展示在[图 7-11](#figure7-11)的底行。最终的结果是我们有了六个二元分类器，每个分类器告诉我们数据最可能属于哪个特定的类别。
- en: To classify a new example, we run it through all six classifiers, and then we
    select the label that comes up the most often. In other words, each classifier
    votes for one of two classes, and we declare the winner to be the class with the
    most votes. [Figure 7-12](#figure7-12) shows one-versus-one in action.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对一个新示例进行分类，我们需要将其传入所有六个分类器，然后选择出现次数最多的标签。换句话说，每个分类器都会投票选出两个类中的一个，最终我们将出现最多票数的类别作为该样本的预测类。[图
    7-12](#figure7-12) 展示了 OvO 方法的实际应用。
- en: '![F07011](Images/F07011.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![F07011](Images/F07011.png)'
- en: 'Figure 7-11: Building the six binary classifiers we use for performing OvO
    classification on four classes. Top row: Left to right, binary classifiers for
    classes A and B, A and C, and A and D. Second row: Left to right, binary classifiers
    for classes B and C, and B and D. Bottom row: A binary classifier for classes
    C and D.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-11：构建用于执行 OvO 分类的六个二元分类器，分类四个类。顶部行：从左到右，分别是 A 和 B、A 和 C、A 和 D 的二元分类器。第二行：从左到右，分别是
    B 和 C、B 和 D 的二元分类器。底部行：C 和 D 类的二元分类器。
- en: In this example, class A got three votes, B got one, C got two, and D got none.
    The winner is A, so that’s the predicted class for this sample.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，A 类得到了三票，B 类得到了四票，C 类得到了两票，而 D 类没有得到任何票数。最终的赢家是 A 类，因此它是该样本的预测类别。
- en: One-versus-one usually requires far more classifiers than one-versus-rest, but
    it’s sometimes appealing because it provides a clearer understanding of how the
    sample was evaluated with respect to each possible pair of classes. This can make
    a system more transparent, or explainable, when we want to know how it came up
    with its final answer. When there’s a lot of messy overlap between multiple classes,
    it can be easier for us humans to understand the final results using one-versus-one.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: One-versus-one 方法通常需要比 one-versus-rest 方法更多的分类器，但有时它更具吸引力，因为它可以提供关于样本如何在每一对可能的类别之间进行评估的更清晰理解。这可以使得系统更具透明性，或者在我们想了解系统如何得出最终答案时具有更好的可解释性。当多个类别之间存在大量混杂的重叠时，One-versus-one
    方法能够帮助我们人类更容易理解最终结果。
- en: The cost of this clarity is significant. The number of classifiers that we need
    for one-versus-one grows very fast as the number of classes increases. We’ve seen
    that with 4 classes we’d need 6 classifiers. Beyond that, [Figure 7-13](#figure7-13)
    shows just how quickly the number of binary classifiers we need grows with the
    number of classes. With 5 classes we’d need 10, with 20 classes we’d need 190,
    and to handle 30 classes we’d need 435 classifiers! Past about 46 classes we need
    more than 1,000\.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这种清晰性的代价是巨大的。One-versus-one 方法需要的分类器数量随着类别数量的增加而迅速增长。我们已经看到，当类别数量为 4 时，我们需要
    6 个分类器。更进一步，[图 7-13](#figure7-13) 展示了随着类别数量增加，所需的二元分类器数量增长的速度有多快。对于 5 类，我们需要 10
    个分类器，20 类时需要 190 个，30 类时需要 435 个分类器！当类别数量超过 46 时，我们需要超过 1,000 个分类器。
- en: '![F07012](Images/F07012.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![F07012](Images/F07012.png)'
- en: 'Figure 7-12: OvO in action, classifying a new sample shown as a black dot.
    Top row: Left to right, votes are A, A, and A. Second row: Left to right, votes
    are C and B. Bottom row: Vote is class C.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-12：OvO 方法的实际应用，分类一个显示为黑点的新样本。顶部行：从左到右，投票结果为 A、A 和 A。第二行：从左到右，投票结果为 C 和 B。底部行：投票结果为
    C 类。
- en: '![F07013](Images/F07013.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![F07013](Images/F07013.png)'
- en: 'Figure 7-13: As we increase the number of classes, the number of binary classifiers
    we need for OvO grows very quickly.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-13：随着类别数量的增加，我们需要的 OvO 二元分类器数量增长得非常快。
- en: Each of these binary classifiers has to be trained, and then we need to run
    every new sample through every classifier, which is going to consume a lot of
    computer memory and time. At some point, it becomes more efficient to use a single,
    complex, multiclass classifier.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 每个二元分类器都需要进行训练，之后我们需要将每个新样本传入每个分类器，这将消耗大量的计算机内存和时间。某些情况下，使用一个单一、复杂的多类分类器会更高效。
- en: Clustering
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚类
- en: We’ve seen that one way to classify new samples is to break up the space into
    different regions and then test a point against each region. A different way to
    approach the problem is to group the training set data itself into *clusters*,
    or similar chunks. Let’s suppose that our data has associated labels. How can
    we use those to make clusters?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，一种对新样本进行分类的方法是将空间划分为不同的区域，然后测试每个点与每个区域的关系。另一种方法是将训练集数据本身分成*簇*，或者相似的块。假设我们的数据有相关的标签，我们如何利用这些标签来进行聚类？
- en: In the left image of [Figure 7-14](#figure7-14) we have data with five different
    labels, shown by color. For these nicely separated groups, we can make clusters
    just by drawing a curve around each set of points, as in the middle image. If
    we extend those curves outward until they hit one another so that each point in
    the grid is colored by the cluster that it’s closest to, we can cover the entire
    plane as in the right image.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 7-14](#figure7-14)的左图中，我们有五个不同标签的数据，通过颜色显示。对于这些分离得很好的组，我们只需画出每组点的曲线，就能形成簇，如中间的图所示。如果我们将这些曲线向外延伸，直到它们互相交汇，让网格中的每个点都根据它最接近的簇被上色，我们就可以覆盖整个平面，如右图所示。
- en: '![F07014](Images/F07014.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![F07014](Images/F07014.png)'
- en: 'Figure 7-14: Growing clusters. Left: Starting data with five classes. Middle:
    Identifying the five groups. Right: Growing the groups outward so that every point
    has been assigned to one class.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-14：聚簇增长。左图：开始时的数据，包含五个类别。中图：识别出五个组。右图：将这些组向外扩展，直到每个点都被分配到一个类别。
- en: This scheme required that our input data had labels. What if we don’t have labels?
    If we can somehow automatically group our unlabeled data into clusters, we can
    still apply the technique we just described.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法要求我们的输入数据有标签。如果我们没有标签呢？如果我们能以某种方式自动将未标记的数据分成簇，我们仍然可以应用我们刚才描述的技术。
- en: Recall that problems that involve data without labels fall into the type of
    learning we call *unsupervised learning*.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，涉及无标签数据的问题属于我们称之为 *无监督学习* 的学习类型。
- en: When we use an algorithm to automatically derive clusters from unlabeled data,
    we have to tell it how many clusters we want it to find. This “number of clusters”
    value is often represented with the letter *k* (this is an arbitrary letter and
    doesn’t stand for anything in particular). We say that *k* is a *hyperparameter*,
    or a value that we choose before training our system. Our chosen value of *k*
    tells the algorithm how many regions to build (that is, how many classes to break
    up our data into). Because the algorithm uses the geometric means, or averages,
    of groups of points to develop the clusters, the algorithm is called *k-means
    clustering*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用算法自动从未标记的数据中推导出簇时，我们必须告诉它我们希望它找到多少个簇。这个“簇的数量”值通常用字母 *k* 来表示（这是一个任意的字母，并没有特别的含义）。我们说
    *k* 是一个 *超参数*，即我们在训练系统之前选择的一个值。我们选择的 *k* 值告诉算法应该构建多少个区域（即，将我们的数据分成多少个类）。由于该算法使用点群的几何均值或平均值来构建簇，因此该算法被称为
    *k-均值聚类*。
- en: The freedom to choose the value of *k* is a blessing and a curse. The upside
    of having this choice is that if we know in advance how many clusters there ought
    to be, we can say so, and the algorithm produces what we want. Keep in mind that
    the computer doesn’t know where we think the cluster boundaries ought to go, so
    although it chops things up into *k* pieces, they may not be the pieces we’re
    expecting. But if our data is well separated, so samples are clumped together
    with big spaces between the clumps, we usually get what we expect. The more the
    cluster boundaries get fuzzy, or overlap, the more things can potentially surprise
    us.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 *k* 值的自由是一个祝福也是一个诅咒。拥有这一选择的好处是，如果我们事先知道应该有多少个簇，我们可以直接告诉算法，算法就会产生我们想要的结果。请记住，计算机并不知道我们认为簇的边界应该在哪里，因此尽管它将数据分成了
    *k* 个部分，但这些部分可能不是我们预期的样子。但是，如果我们的数据已经很好地分开了，样本聚集在一起且之间有较大的空隙，我们通常会得到我们期望的结果。簇的边界越模糊或重叠，事情就越有可能让我们感到意外。
- en: The downside of specifying *k* upfront is that we may not have any idea of how
    many clusters best describe our data. If we pick too few clusters, then we don’t
    separate our data into the most useful distinct classes. But if we pick too many
    clusters, then we end up with similar pieces of data going into different classes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 提前指定 *k* 的缺点是我们可能不知道多少个簇最能描述我们的数据。如果我们选择的簇太少，那么我们就无法将数据分成最有用的不同类别。但是，如果我们选择的簇太多，那么我们最终可能会把相似的数据分到不同的类别中。
- en: To see this in action, consider the data in [Figure 7-15](#figure7-15). There
    are 200 unlabeled points, deliberately bunched up into five groups.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看这个过程，考虑一下[图 7-15](#figure7-15)中的数据。这里有 200 个未标记的点，故意将它们聚集成五组。
- en: '![F07015](Images/F07015.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![F07015](Images/F07015.png)'
- en: 'Figure 7-15: A set of 200 unlabeled points. They seem to visually fall into
    five groups.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-15：一组 200 个未标记的点。它们似乎在视觉上被分成了五组。
- en: '[Figure 7-16](#figure7-16) shows how *k*-means clustering splits up this set
    of points for different values of *k*. Remember, we give the algorithm the value
    of *k* as an argument before it begins working.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 7-16](#figure7-16)展示了*k*-均值聚类如何为不同的*k*值划分这组点。记住，我们在算法开始工作之前会提供*k*值作为参数。'
- en: '![F07016](Images/F07016.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![F07016](Images/F07016.png)'
- en: 'Figure 7-16: The result of automatically clustering our data in [Figure 7-15](#figure7-15)
    for values of *k* from 2 to 7'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7-16：自动对[图 7-15](#figure7-15)中的数据进行聚类，*k*值从 2 到 7
- en: It’s no surprise that *k* = 5 is doing the best job on this data, but we’re
    using a cooked example in which the boundaries are easy to see. With more complicated
    data, particularly if it has more than two or three dimensions, it can be all
    but impossible for us to easily identify the most useful number of clusters beforehand.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 不足为奇的是，*k* = 5 在这组数据上表现得最好，但我们使用的是一个简单的示例，边界容易辨识。在更复杂的数据中，尤其是当数据维度超过两三个时，我们几乎不可能轻松地在事前识别出最有用的聚类数。
- en: All is not lost, though. A popular option is to train our clustering model several
    times, each time using a different value for *k*. By measuring the quality of
    the results, this *hyperparameter tuning* lets us automatically search for a good
    value of *k*, evaluating the predictions of each choice and reporting the value
    of *k* that performed the best. The downside, of course, is that this takes computational
    resources and time. This is why it’s so useful to *preview* our data with some
    kind of visualization tool prior to clustering. If we can pick the best value
    of *k* right away, or even come up with a range of likely values, it can save
    us the time and effort of evaluating values of *k* that won’t do a good job.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 但并非一切都失去希望。一种常见的选择是多次训练我们的聚类模型，每次使用不同的*k*值。通过衡量结果的质量，这种*超参数调优*让我们能够自动搜索一个合适的*k*值，评估每个选择的预测结果，并报告表现最好的*k*值。当然，缺点是，这需要计算资源和时间。这就是为什么在聚类之前使用某种可视化工具来*预览*数据如此有用。如果我们能够立刻选出最佳的*k*值，或者甚至给出一个可能值的范围，就能节省评估那些无法提供良好结果的*k*值的时间和精力。
- en: The Curse of Dimensionality
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维度灾难
- en: We’ve been using examples of data with two features, because two dimensions
    are easy to draw on the page. But in practice, our data can have any number of
    features or dimensions. It might seem that the more features we have, the better
    our classifiers will be. It makes sense that the more features the classifiers
    have to work with, the better they should be able to find the boundaries (or clusters)
    in the data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在使用具有两个特征的数据示例，因为二维数据很容易在页面上绘制。但实际上，我们的数据可以有任意数量的特征或维度。似乎特征越多，我们的分类器效果越好。因为更多的特征意味着分类器可以使用更多的信息来找到数据中的边界（或聚类），这似乎是合乎逻辑的。
- en: That’s true to a point. Past that point, adding more features to our data actually
    makes things *worse*. In our egg-classifying example, we could add in more features
    to each sample, like the temperature at the time the egg was laid, the age of
    the hen, the number of other eggs in the nest at the time, the humidity, and so
    on. But, as we’ll see, adding more features often makes it harder, not easier,
    for the system to accurately classify the inputs.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这在某种程度上是正确的。超过这个点后，向数据中添加更多特征实际上会让情况变得*更糟*。在我们的鸡蛋分类示例中，我们可以为每个样本添加更多的特征，例如蛋下的温度、母鸡的年龄、巢中同时有的其他鸡蛋数量、湿度等。但正如我们将看到的，添加更多特征通常会使得系统更难，而不是更容易，准确地分类输入。
- en: 'This counterintuitive idea shows up so frequently that it has earned a special
    name: *the curse of dimensionality* (Bellman 1957). This phrase has come to mean
    different things in different fields. We’re using it in the sense that applies
    to machine learning (Hughes 1968). Let’s see how this curse comes about, and what
    it tells us about training.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个反直觉的观点出现得如此频繁，以至于它有了一个特别的名字：*维度灾难*（Bellman 1957）。这个词在不同领域有不同的含义。在这里我们使用它指的是机器学习中的含义（Hughes
    1968）。让我们来看看这个“灾难”是如何产生的，以及它告诉我们关于训练的哪些信息。
- en: Dimensionality and Density
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 维度与密度
- en: One way to picture the curse of dimensionality is to think about how a classifier
    goes about finding a boundary curve or surface. If there are only a few points,
    then the classifier can invent a huge number of curves or surfaces that all divide
    the data. In order to pick the boundary that will do the best job on future data,
    we’d want more training samples. Then the classifier can choose the boundary that
    best separates that denser collection. [Figure 7-17](#figure7-17) shows the idea
    visually.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![F07017](Images/F07017.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-17: To find the best boundary curve, we need a good density of samples.
    Left: We have very few samples, so we can construct lots of different boundary
    curves. Right: With a higher density of samples, we can find a good boundary curve.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'As [Figure 7-17](#figure7-17) shows, finding a good curve requires a dense
    collection of points. But here’s the key insight: as we add dimensions (or features)
    to our samples, the number of samples we need in order to maintain a reasonable
    density in the sample space explodes. If we can’t keep up with the demand, a classifier
    does its best, but it doesn’t have enough information to draw a good boundary.
    It is stuck in the situation of the left diagram in [Figure 7-17](#figure7-17),
    where it’s just guessing at the best boundary, which may lead to poor results
    on future data.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the problem of loss of density using our egg example. To keep
    things simple, let’s use a convention that all the features we may measure for
    our eggs (their volume, length, etc.) lie in the range 0 to 1\. Let’s start with
    a dataset that contains 10 samples, each with one feature (the egg’s weight).
    Since we have one dimension describing each egg, we can plot it on a one-dimensional
    line segment from 0 to 1\. Because we want to see how well our samples cover every
    part of this line, let’s break it up into pieces, or bins, and see how many samples
    fall into each bin. The bins are just conceptual devices to help us estimate density.
    [Figure 7-18](#figure7-18) shows how one set of data might fall on an interval
    [0,1] with 5 bins.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '![f07018](Images/f07018.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-18: Our 10 pieces of data have one dimension each.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: There’s nothing special about the choices of 10 samples and 5 bins. We just
    chose them because it makes the pictures easy to draw. The core of our discussion
    is unchanged if we pick 300 eggs or 1,700 bins.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: The *density* of our space is the number of samples divided by the number of
    bins. It gives us a rough way to measure how well our data is filling up the space
    of possible values. In other words, do we have examples to learn from for most
    values of the input? We can see problems start to creep in if we have too many
    empty bins. In this case, the density is 10 / 5 = 2, telling us each bin (on average)
    has 2 samples. Looking at [Figure 7-18](#figure7-18), we see that this is a pretty
    good estimate for the average number of samples per bin. In one dimension, for
    this data, a density of 2 lets us find a good boundary.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now include the weight in each egg’s description. Because we now have
    two dimensions, we can pull our line segment of [Figure 7-18](#figure7-18) upward
    to make a 2D square, as in [Figure 7-19](#figure7-19).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '![f07019](Images/f07019.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-19: Our 10 samples are now each described by two measurements, or
    dimensions.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Breaking up each of the sides into 5 segments, as before, we have 25 bins inside
    the square. But we still have only 10 samples. That means most of the regions
    won’t have any data. The density now is 10 / (5 × 5) = 10 / 25 = 0.4, a big drop
    from the density of 2 we had in one dimension. As a result, we can draw lots of
    different boundary curves to split the data of [Figure 7-19](#figure7-19).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s add a third dimension, such as the temperature at the time the egg
    was laid (scaled to a value from 0 to 1). To represent this third dimension, we
    push our square back into the page to form a 3D cube, as in [Figure 7-20](#figure7-20).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '![F07020](Images/F07020.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-20: Now our 10 pieces of data are represented by three measurements,
    so we draw them in a 3D space.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: By splitting each axis into 5 pieces, we now have 125 little cubes, but we still
    have only 10 samples. Our density has dropped to 10 / (5 × 5 × 5) = 10 / 125 =
    0.08\. In other words, the average cell contains 0.08 samples. We’ve gone from
    a density of 2, to 0.4, to 0.08\. No matter where the data is located in 3D, the
    vast majority of the space is empty.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Any classifier that splits this 3D data into two pieces with a boundary surface
    is going to have to make a big guess. The issue isn’t that it’s hard to separate
    the data, but rather that it’s too easy. It’s not clear how to best separate the
    data so that our system will *generalize*, that is, correctly classify points
    we get in the future. The classifier is going to have to classify lots of empty
    boxes as belonging to either one class or the other, and it just doesn’t have
    enough information to do that in a principled way.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: In other words, who knows where new samples are going to end up once our system
    is deployed? At this point, nobody. [Figure 7-21](#figure7-21) shows one guess
    at a boundary surface, but as we saw in [Figure 7-17](#figure7-17), we can fit
    all kinds of planes and curvy sheets through the big open spaces between the two
    sets of samples. Most of them are probably not going to generalize very well.
    Maybe this one is too close to the red balls. Or maybe it’s not close enough.
    Or maybe it should be a curved surface rather than a plane.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: The expected low quality of this boundary surface when we use it to predict
    the classes for new data is not the fault of the classifier. This plane is a perfectly
    good boundary surface, given the data available to the classifier. The problem
    is that because the density of the samples is so low, the classifier just doesn’t
    have enough information to do a good job. The density drops like a rock with each
    added dimension, and as we add yet more features, the density continues to plummet.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '![F07021](Images/F07021.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-21: Passing a boundary surface through our cube, separating the red
    and blue samples'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: It’s hard to draw pictures for spaces with more than three dimensions, but we
    can calculate their densities. [Figure 7-22](#figure7-22) shows a plot of the
    density of a space for our 10 samples as the number of dimensions goes up. Each
    curve corresponds to a different number of bins for each axis. Notice that as
    the number of dimensions goes up, the density drops to 0 no matter how many bins
    we use.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: If we have fewer bins, we have a better chance of filling each one, but before
    long, the number of bins becomes irrelevant. As the number of dimensions goes
    up, our density always heads to 0\. This means our classifier ends up guessing
    at where the boundary should be. Including more features with our egg data improves
    the classifier for a while, because the boundary is better able to follow where
    the data is located. But eventually we need enormous amounts of data to keep up
    with the density demands made by those new features.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: There are some special cases where the lack of density resulting from new features
    won’t cause problems. If our new features are redundant, then our existing boundaries
    are already fine and don’t need to change. Or if the ideal boundary is simple,
    like a plane, then increasing the number of dimensions doesn’t change that boundary’s
    shape. But in the general case, new features add refinement and details to our
    boundary. Because adding new dimensions to accommodate those features causes the
    density to drop toward 0, that boundary becomes harder to find, so the computer
    ends up essentially guessing at its shape and location.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '![F07022](Images/F07022.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-22: This is how the density of our points drops off as the number
    of dimensions increases for a fixed number of samples. Each of the colored curves
    shows a different number of bins along each axis.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: The curse of dimensionality is a serious problem, and it could have made all
    attempts at classification fruitless. After all, without a good boundary, a classifier
    can’t do a good job of classifying. What saved the day is the *blessing of non-uniformity*
    (Domingos 2012), which we prefer to think of as the *blessing of structure*. This
    is the name for the observation that, in practice, the features that we typically
    measure, even in very high-dimensional spaces, tend not to spread around uniformly
    in the space of the samples. That is, they’re not distributed equally across the
    line, square, and cube we’ve seen, or the higher-dimensional versions of those
    shapes we can’t draw. Instead, they’re often clumped in small regions, or spread
    out on much simpler, lower-dimensional surfaces (such as a bumpy sheet or a curve).
    That means our training data and all future data will generally land in the same
    regions. Those regions will be dense, while the great majority of the rest of
    the space will be empty. This is good news, because it says that it doesn’t matter
    how we draw the boundary surface in those big empty regions, because no data will
    appear there. Having good density where the samples themselves actually fall is
    what we want and what we usually find.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see this structuring in action. In our cube of [Figure 7-20](#figure7-20),
    instead of having the samples spread around more or less uniformly throughout
    the cube, we might find that the samples from each class are located on the same
    horizontal plane. That means that any roughly horizontal boundary surface that
    splits the groups probably does a good job on new data, too, as long as those
    new values also tend to fall into those horizontal planes. [Figure 7-23](#figure7-23)
    shows the idea.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '![F07023](Images/F07023.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-23: In practice, our data often has some structure in the sample space.
    Left: Each group of samples is mostly in the same horizontal slice of the cube.
    Right: A boundary plane passed between the two sets of points.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Most of the cube in [Figure 7-23](#figure7-23) is empty, and thus has low density,
    but the parts we’re interested in have high densities, so we can find a sensible
    boundary. Although the curse of dimensionality dooms us to have a low density
    in our overall space, even with enormous amounts of data, the blessing of structure
    says that we usually get reasonably high density where we need it. On the right
    side of [Figure 7-23](#figure7-23), we show a boundary plane across the middle
    of the cube. This does the job of separating the classes, but since they’re so
    well clumped, and since the space between them is empty, almost any boundary surface
    that splits the groups would probably do a good job of generalizing.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Note that both the curse and blessing are empirical observations, and not hard
    facts we can always rely on. So the best solution for this important practical
    problem is usually to fill out the sample space with as much data as we can get.
    In Chapter 10, we’ll see some ways to reduce the number of features in our data
    if it seems to be producing bad boundaries.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: The curse of dimensionality is one reason why machine learning systems are famous
    for requiring enormous amounts of data when they’re being trained. If the samples
    have lots of features (or dimensions), we need lots and lots of samples to get
    enough density to make good class predictions.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we want enough points to get a specific density, say 0.1 or 0.5\. How
    many points do we need as the number of dimensions increases? [Figure 7-24](#figure7-24)
    shows that the number of points needed explodes in a hurry.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '![F07024](Images/F07024.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-24: The number of points we need to achieve different densities, assuming
    we have five divisions on each axis'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Speaking generally, if the number of dimensions is low, and we have lots of
    points, then we probably have enough density for the classifier to find a surface
    that has a good chance of generalizing well to new data. The values for *low*
    and *lots* in that sentence depend on the algorithm we’re using and what our data
    looks like. There’s no hard and fast rule for predicting these values; we generally
    take a guess, see what performance we get, and then make adjustments. Generally
    speaking, when it comes to training data, more really is more. Get all the data
    you ethically can.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: High-Dimensional Weirdness
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since the samples in real-world data usually have many features, we often work
    in spaces with many dimensions. We saw earlier that if the data is locally structured,
    we are often okay: our ignorance of the boundary in the big empty regions doesn’t
    work against us, since no input data lands there. But what if our data isn’t structured
    or clumped?'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s tempting to look at pictures like Figures 7-19 and 7-20 and let our intuition
    guide our choices in designing a learning system, thinking that spaces of many
    dimensions are like the spaces we’re used to, only bigger. This is very much not
    true! There’s a technical term for the characteristics of high-dimensional spaces:
    *weird*. Things simply work out in ways that we don’t expect. Let’s look at two
    cautionary tales about the weirdness of geometry in higher dimensions in order
    to train our intuitions not to jump to generalizations from the low-dimensional
    spaces we’re familiar with. This will help us stay on our toes when designing
    learning systems.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: The Volume of a Sphere Inside a Cube
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A famous example of the weirdness of high-dimensional spaces involves the volume
    of a sphere inside a cube (Spruyt 2014). The setup is simple: take a sphere and
    put it into a cube, then measure how much of the cube is occupied by the sphere.
    Let’s first do this in one, two, and three dimensions. Then we’ll keep going to
    higher dimensions and track the percentage of the cube occupied by the sphere
    as the number of dimensions goes up.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 7-25](#figure7-25) gets us started in the 1D, 2D, and 3D cases.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '![F07025](Images/F07025.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-25: Spheres in cubes. Left: A 1D “cube” is a line segment, and the
    “sphere” covers it completely. Middle: A 2D “cube” is a square, and the “sphere”
    is a circle that touches the edges. Right: A 3D cube surrounds a sphere, which
    touches the center of each face.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: In one dimension, our “cube” is just a line segment, and the sphere is a line
    segment that covers the whole thing. The ratio of the contents of the sphere to
    the contents of the “cube” is 1:1\. In 2D, our “cube” is a square, and the sphere
    is a circle that just touches the center of each of the four sides. The area of
    the circle divided by the area of the box is about 0.8\. In 3D, our cube is a
    normal 3D cube, and the sphere fits inside, just touching the center of each of
    the six faces. The volume of the sphere divided by the volume of the cube is about
    0.5.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: The amount of space taken up by the sphere relative to the box enclosing it
    is dropping. If we work out the math and calculate the volume of the sphere to
    the volume of its cube for higher dimensions (where they’re called a *hypersphere*
    and *hypercube*), we get the results in [Figure 7-26](#figure7-26).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![F07026](Images/F07026.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-26: The amount of a box occupied by the largest sphere that fits into
    that box for different numbers of dimensions'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: The amount of volume taken up by the hypersphere drops down toward 0\. By the
    time we reach 10 dimensions, the largest sphere we can fit into its enclosing
    box takes up almost none of the box’s volume!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: This is not what most of us would expect based on our experience in the 3D world.
    We’ve found that if we take a hypercube (of many dimensions) and place inside
    of it the largest possible hypersphere (of the same number of dimensions) that
    will fit, the volume of that hypersphere is just about 0\.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: There’s no trick to this, and nothing’s going wrong. When we work out the math,
    this is what happens. We saw the pattern starting in the first three dimensions,
    but we can’t really draw the rest, so it’s hard to picture how in the heck this
    can be going on. But it does happen this way, because higher dimensions are weird.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Packing Hyperspheres into Hypercubes
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To make sure our intuitions get the message, let’s look at another weird result
    from packing hyperspheres into hypercubes. Let’s suppose we want to transport
    some particularly fancy oranges and make sure they’re not damaged in any way.
    Each orange’s shape is close to spherical, so we decide to ship them in cubical
    boxes protected by air-filled balloons. We put one balloon in each corner of the
    box, so that each balloon touches both the orange and the sides of the box. The
    balloons and orange are all perfect spheres. What’s the biggest orange we can
    put into a cube of a given size?
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: We want to answer this question for cubes (and balloons and oranges) with any
    number of dimensions, so let’s start with just two dimensions. Our box is then
    a 2D square of size 4 by 4, and the four balloons are each a circle of radius
    1, placed in the corners, as in [Figure 7-27](#figure7-27).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '![F07027](Images/F07027.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-27: Shipping a circular 2D orange in a square box, surrounded by circular
    balloons in each corner. Left: The four balloons each have a radius of 1, so they
    fit perfectly into a square box of side 4\. Right: The orange sitting inside the
    balloons.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Our orange in this 2D diagram is also a circle. In [Figure 7-27](#figure7-27)
    we show the biggest orange we can fit. A little geometry tells us that the radius
    of this orange circle is about 0.4.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s move to 3D, so we have a cube (again, 4 units on a side). We can now
    fit eight spherical balloons, each of radius 1, into the corners, as in [Figure
    7-28](#figure7-28). As always, the orange goes into the space in the middle of
    the balloons.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '![F07028](Images/F07028.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-28: Shipping a spherical orange in a cubical box surrounded by spherical
    balloons in each corner. Left: The box is 4 by 4 by 4, and the eight balloons
    each have a radius of 1\. Right: The orange sits in the middle of the balloons.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Another bit of geometry (this time in 3D) tells us that this orange has a radius
    of about 0.7\. This is larger than the radius of the orange in the 2D case, because
    in 3D, there’s more room for the orange in the central gap between spheres.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take this scenario into 4, 5, 6, and even more dimensions, where we have
    hypercubes, hyperspheres, and *hyperoranges*. For any number of dimensions, our
    hypercubes are always 4 units on every side, there is always a hypersphere balloon
    in every corner of the hypercube, and these balloons always have a radius of 1.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: We can write a formula that tells us the radius of the biggest hyperorange we
    can fit for this scenario in any number of dimensions (Numberphile 2017). [Figure
    7-29](#figure7-29) plots this radius for different numbers of dimensions.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: We can see from [Figure 7-29](#figure7-29) that in four dimensions, the biggest
    hyperorange we can ship has a radius of exactly 1\. That means that it’s as large
    as the hyperballoons around it. That’s hard to picture, but it gets much stranger.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 7-29](#figure7-29) also tells us that in nine dimensions, the hyperorange
    has a radius of 2, so its diameter is 4\. That means the hyperorange is as large
    as the box itself, like the 3D sphere in [Figure 7-25](#figure7-25). That’s despite
    being surrounded by 512 hyperspheres of radius 1, each in one of the 512 corners
    of this 9D hypercube. If the orange is as large as the box, how are the balloons
    protecting anything?'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'But things get much crazier. At 10 dimensions and higher, the hyperorange has
    a radius that’s *more* than 2\. The hyperorange is now *bigger* than the hypercube
    that was meant to protect it. It seems to be extending beyond the sides of the
    cube, even though we constructed it to fit both inside the box and the protective
    balloons that are still in every corner. It’s hard for those of us with 3D brains
    to picture 10 dimensions (or more), but the equations check out: the orange is
    simultaneously inside the box and extending beyond the box.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '![F07029](Images/F07029.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-29: The radius of a hyperorange in a hypercube with sides 4, surrounded
    by hyperspheres of radius 1 in each corner of the cube'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: The moral here is that our intuition can fail us when we get into spaces of
    many dimensions (Aggarwal 2001). This is important because we routinely work with
    data that has tens or hundreds of features.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Any time we work with data that has more than three features, we’ve entered
    the world of higher dimensions, and we should not reason by analogy with what
    we know from our experience with two and three dimensions. We need to keep our
    eyes open and rely on math and logic, rather than intuition and analogy.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: In practice, that means keeping a close eye on how a deep learning system is
    behaving during training when we have multidimensional data, and we should always
    be alert to seeing it act strangely. The techniques of Chapter 10 can reduce the
    number of features in our data, which may help. Throughout the book we’ll see
    other ways to improve a system that isn’t learning well, whether because of high-dimensional
    weirdness or other causes.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter we looked at the mechanics of classifying. We saw that classifiers
    can break up the space of data into domains that are separated by boundaries.
    A new piece of data is classified by identifying which domain it falls into. The
    domains may be fuzzy, representing probabilities, so the result of the classifier
    is a probability for each class. We also looked at an algorithm for clustering.
    Lastly, we saw that our intuition often gets it wrong when we work in spaces of
    more than three dimensions. Things frequently just don’t work the way we expect.
    Those higher-dimensional spaces are weird, and full of surprises. We learned that
    when working with multidimensional data, we should proceed carefully and monitor
    our system as it learns. We should never rely on guesswork based on our experience
    in 3D!
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll look at how to efficiently train a learning system,
    even when we don’t have a lot of data.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
