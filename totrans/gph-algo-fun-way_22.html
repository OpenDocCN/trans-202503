<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><section epub:type="chapter" role="doc-chapter" aria-labelledby="ch17">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_299" aria-label="299"/>&#13;
<hgroup>&#13;
&#13;
<h2 class="CHAPTER" id="ch17">&#13;
<span class="CN"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">17</samp></span>&#13;
<span class="CT"><samp class="SANS_Dogma_OT_Bold_B_11">CLIQUES, INDEPENDENT SETS, AND VERTEX COVERS</samp></span>&#13;
</h2>&#13;
</hgroup>&#13;
<figure class="opener"><img class="opener" src="../images/opener.jpg" role="presentation" alt="" width="386" height="386"/>&#13;
</figure>&#13;
<p class="ChapterIntro">In the previous chapter, we saw how the seemingly simple problem of assigning colors rapidly explodes into costly searches. Here, we consider the similarly challenging problems of assembling sets of nodes that satisfy various criteria: maximum cliques, maximum independent sets, and minimum vertex covers.</p>&#13;
<p class="TX">For each of these problems, we want to find the largest or smallest set of nodes that fulfills some criteria based on immediate neighbors or adjacent edges. While it is easy to check whether a single proposed solution satisfies various constraints, it can be computationally expensive to find the best solution. Like the graph-coloring problem, these problems are classified as NP-hard. Again, we can attack these problems with either heuristic or exhaustive approaches.</p>&#13;
<p class="TX">This chapter begins by returning to the exhaustive backtracking search with pruning that was introduced in the previous chapter, adapting it to exhaustively search for solutions to each of the three problems covered <span role="doc-pagebreak" epub:type="pagebreak" id="pg_300" aria-label="300"/>here. In addition, we consider a variety of greedy or heuristic approaches. We’ll also discuss real-world applications for each problem, from choosing office locations with cliques to avoiding grudges with independent sets to building guard towers with vertex covers.</p>&#13;
<section epub:type="division" aria-labelledby="sec1">&#13;
&#13;
<h3 class="H1" id="sec1"><span id="h-236"/><samp class="SANS_Futura_Std_Bold_B_11">Backtracking Search for Sets of Nodes</samp></h3>&#13;
<p class="TNI1">For each of the problems in this chapter, we want to find a set of nodes that satisfies given constraints. We use a modified version of the backtracking search with pruning introduced in <span class="Xref"><a href="chapter16.xhtml">Chapter 16</a></span> to find potential solutions by exploring the different assignments for whether each node is included in the set. As with their use in graph coloring, these backtracking searches enumerate all valid solutions. While they’ll check every possible valid assignment, they are rarely efficient.</p>&#13;
<p class="TX">The basic concept behind this search is to explore every possible set of nodes by considering the nodes one at a time and branching the search into two paths at each decision point. In the first path, the search explores the possible sets constructed without including the current node in the set. In the second path, it explores those possible sets constructed with the current node included in the set.</p>&#13;
<p class="TX"><a href="#fig17-1">Figure 17-1</a> shows this approach with each node’s inclusion in the set marked as <samp class="SANS_TheSansMonoCd_W5Regular_11">True</samp> (included) or <samp class="SANS_TheSansMonoCd_W5Regular_11">False</samp> (excluded). The empty entries in the list indicate nodes we have yet to decide whether to include. At each level, the search considers the next unassigned node and branches out over both potential assignments.</p>&#13;
<figure class="IMG"><img id="fig17-1" class="img100" src="../images/f17001.jpg" alt="A tree showing the branching for set assignment. At the top level, a five-element array has no items filled in. This array branches into two paths. The one on the left has F in the first element. The one on the right has T in the first element." width="1523" height="816"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 17-1: A backtracking search to exhaustively try all set assignments</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Because we split each branch into two subbranches in <a href="#fig17-1">Figure 17-1</a>, the number of possible options doubles at each level. For a tree with <span role="doc-pagebreak" epub:type="pagebreak" id="pg_301" aria-label="301"/><i>N</i> decisions, we explore 2<i><sup>N</sup></i> full assignments. In the case of subsets of graph nodes, we consider each node as a separate decision, so <i>N</i> = |<i>V</i> | and we have 2<sup>|</sup><i><sup>V</sup></i> <sup>|</sup> options to explore. While pruning invalid paths will help remove some obviously infeasible results, it will not save us from the full explosion of complexity this search can entail.</p>&#13;
<p class="TX">We can think of this search as a method of solving a puzzle in a magical dungeon. Upon entering the cold stone room, we find five massive switches along the wall. We know from our previous studies of magical dungeons that only one correct configuration of switches will unlock the door to where the treasure is hidden. Unfortunately, the dungeon’s designer was not simply trying to create a fun puzzle; they want to protect their treasure and therefore provide absolutely no hints. While it doesn’t take long to check any single guess, we might need to try every combination to find the right one.</p>&#13;
<p class="TX">Determined to get the treasure, we start with a guess for the leftmost switch (Off), then the second from the left (Off), and so forth until all the switches are in the Off position. When the vault door inevitably doesn’t open, we backtrack to the last decision point (where we had set the rightmost switch to Off) and try the On option. When that doesn’t work, we backtrack further (to the second rightmost switch), change that to On, and once again explore each possible setting for the final switch. We should consider ourselves lucky that the dungeon designer only had the budget for five switches, meaning we need to test only 2<sup>5</sup> = 32 settings. But we find it hard to muster such positive thoughts as we backtrack again and again.</p>&#13;
<p class="TX">For all the algorithms in this chapter, we describe the same two algorithmic approaches for finding solutions. We start by describing an approximate greedy search to establish the fundamentals of the problem and the factors that impact the solutions. We then show how to adapt backtracking search for that problem and how to add pruning.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec2">&#13;
&#13;
<h3 class="H1" id="sec2"><span id="h-237"/><samp class="SANS_Futura_Std_Bold_B_11">Cliques</samp></h3>&#13;
<p class="TNI1"><i>Cliques</i> are subsets of nodes within an undirected graph that are fully connected. Formally, we say that a clique is a set of nodes <i>V</i><span class="symbol">′ ⊆</span> <i>V</i> such that:</p>&#13;
<p class="EQ">(<i>u</i>, <i>v</i>) <span class="symbol">∈</span> <i>E</i> for all <i>u</i> <span class="symbol">∈</span> <i>V</i><span class="symbol">′</span> and <i>v</i> <span class="symbol">∈</span> <i>V</i><span class="symbol">′</span></p>&#13;
<p class="BodyContinued">In a social network, a clique would be a set of people who are all friends with each other.</p>&#13;
<p class="TX"><a href="#fig17-2">Figure 17-2</a> shows a graph with two shaded subsets of nodes. The shaded nodes {1, 2, 5} in <a href="#fig17-2">Figure 17-2(a)</a> form a clique because the graph contains an edge between each pair of nodes in the subset. In contrast, the shaded nodes {0, 1, 4} in <a href="#fig17-2">Figure 17-2(b)</a> do not form a clique, as there is no edge between nodes 0 and 4 nor between nodes 1 and 4.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_302" aria-label="302"/>&#13;
<figure class="IMG"><img id="fig17-2" class="img80" src="../images/f17002.jpg" alt="A graph with six nodes and undirected edges (0, 1), (0, 3), (1, 2), (1, 5), (2, 5), (3, 4), and (4, 5). On the left, the shaded nodes 1, 2, and 5 all have edges between them. On the right, the shaded nodes 0, 1, 4 do not.&gt;" width="1127" height="342"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 17-2: A graph with a subset of nodes forming a clique (a) and a non-clique subset of nodes (b)</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">We can determine whether a set of nodes forms a clique by checking each pair of nodes and confirming that an edge between them exists, as shown in <a href="#list17-1">Listing 17-1</a>.</p>&#13;
<span id="list17-1"/>&#13;
<pre><code>def is_clique(g: Graph, nodes: list) -&gt; bool: &#13;
    num_nodes: int = len(nodes)&#13;
    for i in range(num_nodes):&#13;
        for j in range(i + 1, num_nodes):&#13;
            if not g.is_edge(nodes[i], nodes[j]):&#13;
                return False&#13;
    return True&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 17-1: Checking if a set of nodes forms a valid clique</samp></p>&#13;
<p class="TX">The code uses a pair of <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loops to iterate over each pair of nodes in the list and check whether the corresponding edge exists. If the edge is missing, the code immediately returns <samp class="SANS_TheSansMonoCd_W5Regular_11">False</samp>. If the code successfully examines all pairs of nodes in the list without finding any missing edges, it returns <samp class="SANS_TheSansMonoCd_W5Regular_11">True</samp>.</p>&#13;
<p class="TX">We can visualize this check as a nosy outsider in a social network. Hearing tales of the Great Friend Group within a high school, the skeptical outsider proclaims, “There’s no way they all actually like each other,” and sets out to expose the group’s hidden divisions. Firmly in junior detective mode, they corner each person and ask them about their relationship with all the other members of the group: “Are you really friends with Jonny? How about Suzy?” It is not until they have confirmed every pairing is genuine that they finally abandon their skepticism.</p>&#13;
<p class="TX">While determining whether a given set of nodes forms a clique is straightforward, it’s significantly more difficult to build the largest possible clique in a graph. The problem of finding the <i>maximum clique</i> consists of finding the largest subset of nodes <i>V</i><span class="symbol">′ ⊆</span> <i>V</i> in the graph that form a valid clique. This problem is significantly more difficult than finding an arbitrary clique in the graph because the validity of a node’s membership depends on the other nodes in the clique. If adding nodes one by one, early choices can take us in suboptimal directions and exclude later nodes.</p>&#13;
<section epub:type="division" aria-labelledby="sec3">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_303" aria-label="303"/>&#13;
<h4 class="H2" id="sec3"><span id="h-238"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Use Cases</samp></h4>&#13;
<p class="TNI1">We can visualize the importance of cliques by considering locations (nodes) that need to be directly joined by transportation routes (edges). The kingdom’s Guild of Adventurers, Explorers, and Cartographers is looking to set up regional headquarters in locations with magical dungeons. After spending hours debating the importance of various criteria, including such considerations as dungeon difficulty and access to fresh produce, they conclude that the number one priority is easy transportation between the offices. After all, the guild offices share a single list of open quests for their members. If an adventurer in the city of Old Melbourne learns of a promising quest at the Cliffs of Indecision, they will want to travel there directly. The guild leaders enlist their senior cartographers to find the largest set of cities such that each city is directly connected by a road. The cartographers, familiar with the problem of finding maximum cliques, set to work enumerating the possibilities.</p>&#13;
<p class="TX">In a less fantastical world, we might want to use maximum clique detection to choose locations for businesses with direct transportation connections or computational nodes with direct links. Each of these problems consists of finding fully connected subsets within a graph.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec4">&#13;
&#13;
<h4 class="H2" id="sec4"><span id="h-239"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Greedy Search</samp></h4>&#13;
<p class="TNI1">We can define a greedy algorithm for building cliques by starting with an arbitrary node as our clique and continually adding compatible nodes. We always choose to add new nodes that would keep our clique <i>valid</i>, which is any node that shares edges with each of the clique members.</p>&#13;
<p class="TX"><a href="#list17-2">Listing 17-2</a> shows how to list the options for clique expansion by checking each node to see whether we could add it to the set and still have a valid clique.</p>&#13;
<span id="list17-2"/>&#13;
<pre><code>def clique_expansion_options(g: Graph, clique: list) -&gt; list: &#13;
    options: list = []&#13;
    for i in range(g.num_nodes):&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> if i not in clique:&#13;
            valid: bool = True&#13;
            for j in clique:&#13;
              <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> valid = valid and g.is_edge(i, j)&#13;
            if valid:&#13;
                options.append(i)&#13;
    return options&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 17-2: Checking which nodes can be added to a clique</samp></p>&#13;
<p class="TX">The code iterates through each node in the graph and tests whether that node could be added to the clique, first checking whether the node is already part of the clique <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. If not, the code checks a node’s validity by checking that it shares an edge with every node in the current clique <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>. If those tests pass for each node in the clique, the code adds the current node to the list of expansion options.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_304" aria-label="304"/>This function could help the Great Friend Group identify prospective members. Every student in the school is a prospective candidate. For each student who is not already in the group, the friend group’s chosen representative asks every member of the group, “Are you two friends?” If the prospective member is already friends with all members of the existing group (there is an edge from the new node to every node in the group), the current members quickly welcome in their mutual friend.</p>&#13;
<p class="TX">In <a href="#list17-3">Listing 17-3</a>, we construct a greedy algorithm that incrementally builds a clique one node at a time.</p>&#13;
<span id="list17-3"/>&#13;
<pre><code>def clique_greedy(g: Graph) -&gt; list: &#13;
    clique: list = []&#13;
    to_add: list = clique_expansion_options(g, clique)&#13;
    while len(to_add) &gt; 0:&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> clique.append(to_add[0])&#13;
        to_add = clique_expansion_options(g, clique)&#13;
    return clique&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 17-3: A greedy algorithm to find cliques</samp></p>&#13;
<p class="TX">The code starts with an empty list to represent the clique being constructed. It uses a <samp class="SANS_TheSansMonoCd_W5Regular_11">while</samp> loop to continually find a list of potential options with the <samp class="SANS_TheSansMonoCd_W5Regular_11">clique_expansion_options()</samp> function from <a href="#list17-2">Listing 17-2</a> and adds the first option from the returned list to the clique <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. It stops and returns the list when there are no more nodes that can be added to the current clique (<samp class="SANS_TheSansMonoCd_W5Regular_11">len(to_add)</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11">==</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11">0</samp>).</p>&#13;
<p class="TX">When adding nodes one at a time, we immediately run into the question, “Which node do we add next?” In the code in <a href="#list17-3">Listing 17-3</a>, we added just the first option, but this could be a <i>terrible</i> choice. Consider what happens if we apply this greedy algorithm to the graph in <a href="#fig17-3">Figure 17-3</a>. As written, the greedy algorithm would choose node 0 first and ultimately return {0, 1} instead of the larger clique {1, 2, 4, 5}.</p>&#13;
<figure class="IMG"><img id="fig17-3" class="img40" src="../images/f17003.jpg" alt="A graph with six nodes and undirected edges (0, 1), (0, 3), (1, 2), (1, 4), (1, 5), (2, 4), (2, 5), (3, 4), and (4, 5)." width="461" height="273"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 17-3: A graph for which the greedy search for a maximum clique fails</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The greedy search is not guaranteed to find the maximum clique because decisions at each iteration of greedy search are not independent. Each time the algorithm adds a node <i>u</i> to the clique, this prevents it from adding any future nodes that do not have an edge to <i>u</i>. We can easily get stuck in a local maximum by adding the wrong node early on. We could improve our selection heuristics, such as by choosing nodes with the most <span role="doc-pagebreak" epub:type="pagebreak" id="pg_305" aria-label="305"/>edges, but this only helps so much. To build a maximum clique, we need a more comprehensive (and expensive) search.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec5">&#13;
&#13;
<h4 class="H2" id="sec5"><span id="h-240"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Backtracking Search</samp></h4>&#13;
<p class="TNI1"><i>Backtracking search</i> for a maximum clique recursively tries to set one node of the graph as either a member or non-member of the clique, as shown in <a href="#list17-4">Listing 17-4</a>. At each level of recursion, the search function takes the clique built so far (<samp class="SANS_TheSansMonoCd_W5Regular_11">clique</samp>) and the next node to test (<samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp>) and recursively tests all combinations of unassigned nodes, returning the biggest clique found down that branch of the search. This branching effectively tests all 2<sup>|</sup><i><sup>V</sup></i> <sup>|</sup> possible subsets of nodes, while using pruning to cut off invalid options.</p>&#13;
<span id="list17-4"/>&#13;
<pre><code>def maximum_clique_recursive(g: Graph, clique: list, index: int) -&gt; list: &#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> if index &gt;= g.num_nodes:&#13;
        return copy.copy(clique)&#13;
&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> best: list = maximum_clique_recursive(g, clique, index + 1)&#13;
&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation3">❸</span> can_add: bool = True&#13;
    for n in clique:&#13;
        can_add = can_add and g.is_edge(n, index)&#13;
&#13;
    if can_add:&#13;
        clique.append(index)&#13;
        candidate: list = maximum_clique_recursive(g, clique, index + 1)&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation4">❹</span> clique.pop()&#13;
&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation5">❺</span> if len(candidate) &gt; len(best):&#13;
            best = candidate&#13;
&#13;
    return best&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 17-4: Recursively exploring possible cliques</samp></p>&#13;
<p class="TX">The code for backtracking search starts by checking whether it has reached the termination condition (iterated past the last node in the graph) <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. If so, there is nothing left to check, and <samp class="SANS_TheSansMonoCd_W5Regular_11">clique</samp> is the largest subset down this branch of the search. The code returns a copy of the current clique to effectively snapshot the state and separate it from the <samp class="SANS_TheSansMonoCd_W5Regular_11">clique</samp> object that it will continue to modify during the rest of the search.</p>&#13;
<p class="TX">If the search has not reached the end of the recursion, the code tries building cliques both with and without <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp>. It tests the subset without <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp> by calling <samp class="SANS_TheSansMonoCd_W5Regular_11">maximum_clique_recursive()</samp> with the current <samp class="SANS_TheSansMonoCd_W5Regular_11">clique</samp> and the index of the next node <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>, then saves the best result down that branch for comparison.</p>&#13;
<p class="TX">Before testing the subset with the current node, the code avoids exploring invalid subtrees by checking whether this node is compatible with the current <samp class="SANS_TheSansMonoCd_W5Regular_11">clique</samp> <span class="CodeAnnotationCode" aria-label="annotation3">❸</span>. As with <samp class="SANS_TheSansMonoCd_W5Regular_11">clique_expansion_options()</samp> in <a href="#list17-2">Listing 17-2</a>, the <samp class="SANS_TheSansMonoCd_W5Regular_11">maximum_clique_recursive()</samp> function checks that the prospective node <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp> has edges to all the nodes in the current clique. If even a single edge is <span role="doc-pagebreak" epub:type="pagebreak" id="pg_306" aria-label="306"/>missing, adding <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp> would result in an invalid clique. The code skips recursive exploration on such invalid sets.</p>&#13;
<p class="TX">If the current node is compatible with the current clique, the code tries adding it to the clique and recursively testing the remaining options. It then cleans up the <samp class="SANS_TheSansMonoCd_W5Regular_11">clique</samp> data by removing <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp> so that the <samp class="SANS_TheSansMonoCd_W5Regular_11">clique</samp> list can continue to be used in other branches <span class="CodeAnnotationCode" aria-label="annotation4">❹</span>. The code compares the results of the two branches and keeps the larger valid subset of nodes <span class="CodeAnnotationCode" aria-label="annotation5">❺</span>.</p>&#13;
<p class="TX">We call the function in <a href="#list17-4">Listing 17-4</a> with an initial <samp class="SANS_TheSansMonoCd_W5Regular_11">clique=[]</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">index=0</samp> or use a wrapper function:</p>&#13;
<pre><code>def maximum_clique_backtracking(g: Graph) -&gt; list: &#13;
    return maximum_clique_recursive(g, [], 0)&#13;
</code></pre>&#13;
<p class="TX"><a href="#fig17-4">Figure 17-4</a> shows a visualization of the search. Each level shows the algorithm branching on the inclusion (or not) of a single node. The first level considers whether to include node 0. The second level considers including node 1. Nodes assigned to the clique are shaded, excluded nodes are white, and unassigned nodes are dashed circles.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_307" aria-label="307"/>&#13;
<figure class="IMG"><img id="fig17-4" class="img100" src="../images/f17004.jpg" alt="A tree where each node corresponds to a four-node graph with undirected edges (0, 1), (0, 3), (1, 2), and (1, 3). At the root node all graph nodes are dashed. At each level of the tree, another node becomes either solid white or solid gray." width="2386" height="1173"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 17-4: The steps of a backtracking search for the maximum clique</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_308" aria-label="308"/>The subgraphs in <a href="#fig17-4">Figure 17-4</a> show the state of the <samp class="SANS_TheSansMonoCd_W5Regular_11">clique</samp> list at the start of each function call. As you can see, the function follows only branches that contain valid cliques. For example, when evaluating <samp class="SANS_TheSansMonoCd_W5Regular_11">clique=[0]</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">index=2</samp>, the search cannot follow the right-hand branch because {0, 2} is not a valid clique. As a result, the search tests only 10 of the 16 possible full combinations, as shown in the final row.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec6">&#13;
&#13;
<h3 class="H1" id="sec6"><span id="h-241"/><samp class="SANS_Futura_Std_Bold_B_11">Independent Sets</samp></h3>&#13;
<p class="TNI1">An <i>independent set</i> is effectively the opposite of a clique. We define an independent set within an undirected graph as a subset of nodes such that no two nodes in the set are neighbors. Formally, an independent set is a set of nodes <i>V</i><span class="symbol">′ ⊆</span> <i>V</i> such that:</p>&#13;
<p class="EQ">(<i>u</i>, <i>v</i>) <span class="symbol">∉</span> <i>E</i> for all <i>u</i> <span class="symbol">∈</span> <i>V</i><span class="symbol">′</span> and <i>v</i> <span class="symbol">∈</span> <i>V</i><span class="symbol">′</span></p>&#13;
<p class="BodyContinued">We can envision choosing an independent set as planning the world’s most awkward party: we invite a group of people from our school or office such that no one at the party likes anyone else.</p>&#13;
<p class="TX"><a href="#fig17-5">Figure 17-5</a> shows a graph with two shaded subsets of nodes. The shaded nodes {0, 2, 4} in <a href="#fig17-5">Figure 17-5(a)</a> form an independent set because the graph does not contain any edges connecting these nodes. In contrast, the shaded nodes {0, 1, 4} in <a href="#fig17-5">Figure 17-5(b)</a> do not form an independent set, as there is an edge between nodes 0 and 1.</p>&#13;
<figure class="IMG"><img id="fig17-5" class="img100" src="../images/f17005.jpg" alt="A graph with six nodes and undirected edges (0, 1), (0, 3), (1, 2), (1, 5), (2, 5), (3, 4), and (4, 5). On the left, the shaded nodes are 0, 2, and 4. On the right, the shaded nodes are 0, 1, and 4." width="1127" height="344"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 17-5: A graph with independent (a) and non-independent (b) subsets of nodes</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Determining whether a set of nodes forms an independent set requires us to check each pair of nodes and confirm there is no edge between them:</p>&#13;
<pre><code>def is_independent_set(g: Graph, nodes: list) -&gt; bool: &#13;
    num_nodes: int = len(nodes)&#13;
    for i in range(num_nodes):&#13;
        for j in range(i + 1, num_nodes):&#13;
            if g.is_edge(nodes[i], nodes[j]):&#13;
                return False&#13;
    return True&#13;
</code></pre>&#13;
<p class="TX">This code is almost identical to the clique-checking algorithm in <a href="#list17-1">Listing 17-1</a>. It iterates over each pair of nodes in the list and checks whether they violate the independent set criteria.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_309" aria-label="309"/>In the context of our awkward party, the <samp class="SANS_TheSansMonoCd_W5Regular_11">is_independent_set()</samp> function plays the role of another skeptical outsider. Unable to bear the silence, they insist, “Some people here must be friends.” They query every member of the party about their relationships with each other attendee, asking, “Are you sure you’re not friends with them?” and “How about them?” Only when every single question comes back that no pair are friends do they admit that the awkward atmosphere is understandable and that the host must be a bit of a jerk.</p>&#13;
<p class="TX">As with cliques, generating large independent sets can be difficult because adding a single node to our independent set may impact the validity of other nodes. The problem of finding the <i>maximum independent set</i> consists of finding the largest subset of nodes <i>V</i><span class="symbol">′ ⊆</span> <i>V</i> in the graph that form a valid independent set.</p>&#13;
<section epub:type="division" aria-labelledby="sec7">&#13;
&#13;
<h4 class="H2"><span id="sec7"/><span id="h-242"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Use Cases</samp></h4>&#13;
<p class="TNI1">We can visualize the importance of independent sets by considering a problem where we want to select people (nodes) without negative connections (edges). Imagine being tasked with building a functional project team in a highly dysfunctional organization. Every employee holds a collection of grudges against their coworkers for “misplaced” lunches or forgotten birthdays. In fact, the HR department has gone so far as to build a graph indicating pairwise grudges. Each node represents an employee and undirected edges indicate mutual ill will. The problem of finding a team of employees who do not dislike each other consists of finding a set of nodes within this graph such that no two share an edge.</p>&#13;
<p class="TX">Alternatively, we can visualize the independent set problem in the context of designing a magical dungeon. Aiming to provide adventurers with an appropriate but not impossible challenge, an evil wizard resolves not to include boss-level monsters in any two adjacent rooms. They model the dungeon level as a graph with nodes as rooms and the tunnels between them as edges. They then set about finding the largest possible independent set of rooms that will contain their boss-level monsters. The rest of the rooms can consist of low-level slimes to give the adventurers a break.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec8">&#13;
&#13;
<h4 class="H2"><span id="sec8"/><span id="h-243"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Greedy Search</samp></h4>&#13;
<p class="TNI1">As with the clique algorithm, we can define a greedy algorithm that builds independent sets one node at a time by adding compatible nodes. We list the options for independent expansion by checking whether each node is valid, as shown in <a href="#list17-5">Listing 17-5</a>.</p>&#13;
<span id="list17-5"/>&#13;
<pre><code>def independent_set_expansion_options(g: Graph, current: list) -&gt; list: &#13;
    options: list = []&#13;
    for i in range(g.num_nodes):&#13;
        if i not in current:&#13;
            valid: bool = True&#13;
            for j in current:&#13;
              <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> valid = valid and not g.is_edge(i, j)<span role="doc-pagebreak" epub:type="pagebreak" id="pg_310" aria-label="310"/>&#13;
            if valid:&#13;
                options.append(i)&#13;
    return options&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 17-5: Finding nodes that can be added to an independent set</samp></p>&#13;
<p class="TX">The code iterates through each node in the graph and tests whether that node could be added to the independent set. For this function, the code checks that the node under consideration does not share an edge with any node in the current set <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. Only if those checks pass for every node in the set (and <samp class="SANS_TheSansMonoCd_W5Regular_11">valid</samp> is still <samp class="SANS_TheSansMonoCd_W5Regular_11">True</samp>) does the code add the current node to the list of options.</p>&#13;
<p class="TX">Rather than choosing just any viable node, we can often extend greedy searches by choosing the next node with a heuristic. This heuristic will not guarantee correct results 100 percent of the time, but it can help guide the set construction in better directions. One reasonable heuristic for the independent set problem is to choose nodes with the fewest number of edges, which are likely to have fewer conflicts with other nodes and thus be more compatible with our needs. In the context of our dysfunctional organization, this corresponds to choosing team members who hold the fewest grudges.</p>&#13;
<p class="TX"><a href="#list17-6">Listing 17-6</a> shows how we can codify this heuristic by modifying <a href="#list17-5">Listing 17-5</a> to return the feasible node with the fewest number of edges.</p>&#13;
<span id="list17-6"/>&#13;
<pre><code>def independent_set_lowest_expansion(g: Graph, current: list) -&gt; int: &#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> best_option: int = -1&#13;
    best_num_edges: int = g.num_nodes + 1&#13;
&#13;
    for i in range(g.num_nodes):&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> if i not in current and g.nodes[i].num_edges() &lt; best_num_edges:&#13;
            valid: bool = True&#13;
          <span class="CodeAnnotationCode-1" aria-label="annotation3">❸</span> for j in current:&#13;
                valid = valid and not g.is_edge(i, j)&#13;
            if valid:&#13;
                best_num_edges = g.nodes[i].num_edges()&#13;
                best_option = i&#13;
    return best_option&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 17-6: Finding the node with the fewest edges that is compatible with the independent set</samp></p>&#13;
<p class="TX">The code largely mirrors that of <a href="#list17-5">Listing 17-5</a> but tracks the best node seen (<samp class="SANS_TheSansMonoCd_W5Regular_11">best_option</samp>) and its number of edges (<samp class="SANS_TheSansMonoCd_W5Regular_11">best_num_edges</samp>). It starts by setting the best node seen to the invalid option <samp class="SANS_TheSansMonoCd_W5Regular_11">-1</samp> and the best number of edges to more than could be adjacent to a single node <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. The code then uses a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop to check each node for feasibility. However, before the feasibility test itself, the code checks whether the node under consideration has fewer edges than the best found so far <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>. If not, it does not matter whether the node is feasible, as the code will not be returning it anyway. It can therefore skip the feasibility test and move on to the next node.</p>&#13;
<p class="TX">The actual feasibility test is identical to that in <a href="#list17-5">Listing 17-5</a> <span class="CodeAnnotationCode" aria-label="annotation3">❸</span>. The code uses a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop through the existing independent set to test each node <span role="doc-pagebreak" epub:type="pagebreak" id="pg_311" aria-label="311"/>against the current candidate <samp class="SANS_TheSansMonoCd_W5Regular_11">i</samp>. Only if those checks pass for every node in the set does the code save the current node as the new <samp class="SANS_TheSansMonoCd_W5Regular_11">best_option</samp>. After exhausting all possible nodes, the code returns the best found.</p>&#13;
<p class="TX">We can build the greedy search by continually adding the best candidate to the independent set:</p>&#13;
<pre><code>def independent_set_greedy(g: Graph) -&gt; list: &#13;
    i_set: list = []&#13;
    to_add: int = independent_set_lowest_expansion(g, i_set)&#13;
    while to_add != -1:&#13;
        i_set.append(to_add)&#13;
        to_add = independent_set_lowest_expansion(g, i_set)&#13;
    return i_set&#13;
</code></pre>&#13;
<p class="TX">The code starts with an empty list <samp class="SANS_TheSansMonoCd_W5Regular_11">i_set</samp> and uses the <samp class="SANS_TheSansMonoCd_W5Regular_11">independent_set _lowest_expansion()</samp> function from <a href="#list17-6">Listing 17-6</a> to find the best-looking node to add. It uses a <samp class="SANS_TheSansMonoCd_W5Regular_11">while</samp> loop to continually find and add nodes until no other nodes can be added.</p>&#13;
<p class="TX">In the context of our dysfunctional organization example, the greedy search algorithm for finding independent sets consists of building a team one person at a time by always selecting the employee with the fewest grudges who is compatible with everyone previously selected. We start by selecting employees (nodes) who have no conflicts (no edges). We can always add these employees to an independent set. Next, we consider employees with only a single conflict, and so forth, always skipping employees who are incompatible with anyone on the current team.</p>&#13;
<p class="TX">Greedy search will not always find the maximum independent set. Despite the use of an informative heuristic, this greedy search can still make suboptimal choices that relegate the solution to a local minimum. Consider what happens if we apply this greedy algorithm to the graph in <a href="#fig17-6">Figure 17-6</a>.</p>&#13;
<figure class="IMG"><img id="fig17-6" class="img80" src="../images/f17006.jpg" alt="A graph with six nodes and undirected edges (0, 2), (0, 4), (1, 3), (1, 5), (2, 3), (2, 4), (2, 5), and (4, 5). (A) has nodes 0 and 1 shaded. (B) has nodes 0, 3, and 5 shaded." width="1127" height="346"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 17-6: The results of a greedy search for maximum independent sets (a) and the true maximum independent set (b)</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">As shown in <a href="#fig17-6">Figure 17-6(a)</a>, the greedy search will choose node 0 and then node 1, locking itself into a local minimum. If the search had instead selected node 3 as its second choice, as shown in <a href="#fig17-6">Figure 17-6(b)</a>, it would have found {0, 3, 5}.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec9">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_312" aria-label="312"/>&#13;
<h4 class="H2"><span id="sec9"/><span id="h-244"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Backtracking Search</samp></h4>&#13;
<p class="TNI1">The backtracking search for constructing a maximum independent set again tries to label each node a member or non-member of the set. This branching allows the function to test all combinations of nodes and return the largest independent set found through each branch of the search. At each level of recursion, the function in <a href="#list17-7">Listing 17-7</a> takes the independent set (<samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp>) constructed so far and the next node to test (<samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp>).</p>&#13;
<span id="list17-7"/>&#13;
<pre><code>def maximum_independent_set_rec(g: Graph, current: list, index: int) -&gt; list: &#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> if index &gt;= g.num_nodes:&#13;
        return copy.copy(current)&#13;
&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> best: list = maximum_independent_set_rec(g, current, index + 1)&#13;
&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation3">❸</span> can_add: bool = True&#13;
    for n in current:&#13;
        can_add = can_add and not g.is_edge(n, index)&#13;
&#13;
    if can_add:&#13;
        current.append(index)&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation4">❹</span> candidate: list = maximum_independent_set_rec(g, current, index + 1)&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation5">❺</span> current.pop()&#13;
&#13;
        if len(candidate) &gt; len(best):&#13;
            best = candidate&#13;
&#13;
    return best&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 17-7: Recursively exploring possible independent sets</samp></p>&#13;
<p class="TX">Following the same pattern as the <samp class="SANS_TheSansMonoCd_W5Regular_11">maximum_clique_recursive()</samp> function from <a href="#list17-4">Listing 17-4</a>, the <samp class="SANS_TheSansMonoCd_W5Regular_11">maximum_independent_set_rec()</samp> function starts by testing whether it has reached the end of the recursion and there are no nodes left to check <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. If so, it returns a copy of the current independent set as the best found down this branch.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_313" aria-label="313"/>If the search has not reached the end of the recursion, it tries building out independent sets both with and without <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp>. It tests the subset without <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp> by calling the function with the current independent set and the index of the next node <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>. This effectively skips adding the current index and moves on to considering later nodes. The code saves the best result found down that branch as the baseline for other branches.</p>&#13;
<p class="TX">The code then checks whether the current node (<samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp>) is compatible with the independent set under construction <span class="CodeAnnotationCode" aria-label="annotation3">❸</span>. If the current node shares an edge with any node in <samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp>, adding it would result in an invalid independent set. The code explores only paths that result in valid independent sets (<samp class="SANS_TheSansMonoCd_W5Regular_11">can_add</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11">==</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11">True</samp>).</p>&#13;
<p class="TX">If the current node is compatible with the current set, the code tries adding the node to <samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp> and recursively testing the remaining options <span class="CodeAnnotationCode" aria-label="annotation4">❹</span>. Afterward, it cleans up the <samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp> list by removing <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp> so that it can continue to use the list in other branches <span class="CodeAnnotationCode" aria-label="annotation5">❺</span>. The code compares the results of the two branches and keeps the larger valid subset of nodes.</p>&#13;
<p class="TX">We call the function in <a href="#list17-7">Listing 17-7</a> with an initial <samp class="SANS_TheSansMonoCd_W5Regular_11">current=[]</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">index=0</samp> or use a wrapper function:</p>&#13;
<pre><code>def maximum_independent_set_backtracking(g: Graph) -&gt; list: &#13;
    return maximum_independent_set_rec(g, [], 0)&#13;
</code></pre>&#13;
<p class="TX"><a href="#fig17-7">Figure 17-7</a> shows a visualization of the search where each level depicts the algorithm branching on the inclusion (or not) of a single node. Nodes assigned to the independent set are shaded, nodes excluded are white, and unassigned nodes are dashed circles.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_314" aria-label="314"/>&#13;
<figure class="IMG"><img id="fig17-7" class="img100" src="../images/f17007.jpg" alt="A tree where each node corresponds to a four-node graph with undirected edges (0, 1), (0, 3), (1, 2), and (1, 3). At the root node, all graph nodes are dashed. At each level of the tree, another node become either solid white or solid gray." width="2125" height="1276"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 17-7: The exploration of a backtracking search for maximum independent sets</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_315" aria-label="315"/>The subgraphs in <a href="#fig17-7">Figure 17-7</a> show the state of <samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp> at the start of each function call. The first level considers whether to include node 0; the second considers including node 1. Since the function explores only branches containing valid independent sets, it reaches only 7 of the 16 possible full assignments.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec10">&#13;
&#13;
<h3 class="H1" id="sec10"><span id="h-245"/><samp class="SANS_Futura_Std_Bold_B_11">Vertex Cover</samp></h3>&#13;
<p class="TNI1">Whereas the problems of finding cliques and independent sets both focus on whether a pair of nodes are neighbors, the problem of <i>vertex cover</i> considers the edges that each node touches. We define a vertex cover within an undirected graph as a subset of nodes such that every edge has at least one endpoint in the set. In other words, each edge is covered by at least one vertex (node). Formally, the vertex cover is a set of nodes <i>V</i><span class="symbol">′ ⊆</span> <i>V</i> such that:</p>&#13;
<p class="EQ">For every edge (<i>u</i>, <i>v</i>) <span class="symbol">∈</span> <i>E</i>, we have <i>u</i> <span class="symbol">∈</span> <i>V</i><span class="symbol">′</span>, <i>v</i> <span class="symbol">∈</span> <i>V</i><span class="symbol">′</span>, or both.</p>&#13;
<p class="TX">We can envision vertex covers in the context of a kingdom that consists of an archipelago of islands (nodes) connected by bridges (edges). To maintain security, the kingdom constructs tall watchtowers to survey each bridge. The watchtower on each island views every bridge touching the island, allowing the kingdom to be strategic about the towers’ locations. However, each bridge (edge) must end on at least one island containing a watchtower (selected node).</p>&#13;
<p class="TX"><a href="#fig17-8">Figure 17-8</a> shows a graph with two shaded subsets of nodes. The shaded nodes {1, 3, 5} in <a href="#fig17-8">Figure 17-8(a)</a> form a vertex cover because each edge touches at least one shaded node. In contrast, the shaded nodes {0, 1, 4} in <a href="#fig17-8">Figure 17-8(b)</a> do not form a vertex cover, as the edge (2, 5) is not covered by any node in the set.</p>&#13;
<figure class="IMG"><img id="fig17-8" class="img80" src="../images/f17008.jpg" alt="A graph with six nodes and undirected edges (0, 1), (0, 3), (1, 2), (1, 5), (2, 5), (3, 4), and (4, 5). In (A), the shaded nodes are 1, 3, and 5. In (B), the shaded nodes are 0, 1, and 4." width="1127" height="344"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 17-8: A graph with a subset of nodes forming a vertex cover (a) and a subset of nodes that is not a vertex cover (b)</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Determining whether a set of nodes forms a vertex cover requires us to check whether each edge in the graph is covered by at least one node in the set:</p>&#13;
<pre><code>def is_vertex_cover(g: Graph, nodes: list) -&gt; bool: &#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> node_set: set = set(nodes)<span role="doc-pagebreak" epub:type="pagebreak" id="pg_316" aria-label="316"/>&#13;
    for edge in g.make_edge_list():&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> if edge.from_node not in node_set and edge.to_node not in node_set:&#13;
            return False&#13;
    return True&#13;
</code></pre>&#13;
<p class="TX">This code starts by creating a set of the included nodes (<samp class="SANS_TheSansMonoCd_W5Regular_11">node_set</samp>) to enable fast lookups by using the <samp class="SANS_TheSansMonoCd_W5Regular_11">set</samp> data structure instead of searching through a <samp class="SANS_TheSansMonoCd_W5Regular_11">list</samp> <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. It then loops through each edge in the graph and checks whether both the origin and destination nodes are missing from the set <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>. If neither node is included in the set, the edge is not covered, and the function immediately returns <samp class="SANS_TheSansMonoCd_W5Regular_11">False</samp>. If the code makes it through all edges, it returns <samp class="SANS_TheSansMonoCd_W5Regular_11">True</samp>.</p>&#13;
<p class="TX">The problem of finding the <i>minimum vertex cover</i> consists of finding the smallest subset of nodes <i>V</i><span class="symbol">′ ⊆</span> <i>V</i> in the graph that form a vertex cover. This problem has direct analogies in cost savings. In the watchtower example, the kingdom wants to build the minimum number of watchtowers that will secure every bridge.</p>&#13;
<section epub:type="division" aria-labelledby="sec11">&#13;
&#13;
<h4 class="H2"><span id="sec11"/><span id="h-246"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Use Cases</samp></h4>&#13;
<p class="TNI1">The problem of vertex cover arises naturally in the context of maintenance. Imagine that an evil but tidy wizard has constructed a magical dungeon. Knowing that they cannot leave passages unswept or risk torches burning out, they need to station a crew of emergency-repair minions near each passage. After adventurers blunder down tunnels, knocking stones loose in their fights with monsters, the minions rush forth to repair the damage. For the sake of expediency, the wizard needs to station a crew in at least one of the two rooms at the end of each passage. To minimize costs, the wizard meticulously finds the smallest number of crews they can employ.</p>&#13;
<p class="TX">In a non-magical context, we might be interested in employing maintenance crews or toll collectors for transportation networks. To keep costs low, we plan a single set of tollbooths through which all incoming and outgoing traffic to the island flows.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec12">&#13;
&#13;
<h4 class="H2"><span id="sec12"/><span id="h-247"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Greedy Search</samp></h4>&#13;
<p class="TNI1">We can build on the greedy algorithm presented for independent sets to create a greedy approach for finding a vertex cover using a subset of the nodes, as shown in <a href="#list17-8">Listing 17-8</a>. This time, we use the heuristic of selecting the node that covers the largest number of uncovered edges.</p>&#13;
<span id="list17-8"/>&#13;
<pre><code>def vertex_cover_greedy_choice(g: Graph, nodes: list) -&gt; int: &#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> edges_covered: set = set([])&#13;
    for index in nodes:&#13;
        for edge in g.nodes[index].get_edge_list():&#13;
            edges_covered.add((edge.from_node, edge.to_node))&#13;
            edges_covered.add((edge.to_node, edge.from_node))&#13;
&#13;
    best_option: int = -1&#13;
    best_num_edges: int = 0<span role="doc-pagebreak" epub:type="pagebreak" id="pg_317" aria-label="317"/>&#13;
    for i in range(g.num_nodes):&#13;
        new_covered: int = 0&#13;
        for edge in g.nodes[i].get_edge_list():&#13;
          <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> if (edge.from_node, edge.to_node) not in edges_covered:&#13;
                new_covered = new_covered + 1&#13;
&#13;
        if new_covered &gt; best_num_edges:&#13;
            best_num_edges = new_covered&#13;
            best_option = i&#13;
&#13;
    return best_option&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 17-8: Heuristically selecting a node to add to a vertex cover</samp></p>&#13;
<p class="TX">In comparison to the code in <a href="#list17-6">Listing 17-6</a>, this code does additional bookkeeping to track edges already covered in the set <samp class="SANS_TheSansMonoCd_W5Regular_11">edges_covered</samp>. It starts by creating an empty set of covered edges <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. Because of our <samp class="SANS_TheSansMonoCd_W5Regular_11">Graph</samp> class’s implementation of undirected edges, the code adds each undirected edge in both directions to <samp class="SANS_TheSansMonoCd_W5Regular_11">edges_covered</samp>.</p>&#13;
<p class="TX">The main <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop is similar to the heuristic for independent sets, where the code iterates through each node in the graph and checks its heuristic value. In this case, the code counts how many of the current node’s edges would be newly covered <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>, keeps the best option seen so far, and returns it. If there are no nodes that would increase the number of covered edges (that is, <samp class="SANS_TheSansMonoCd_W5Regular_11">nodes</samp> already forms a valid vertex covering), the code returns <samp class="SANS_TheSansMonoCd_W5Regular_11">-1</samp>.</p>&#13;
<p class="TX">We create a full greedy algorithm by putting a loop around the selection logic within <a href="#list17-8">Listing 17-8</a>:</p>&#13;
<pre><code>def vertex_cover_greedy(g: Graph) -&gt; list: &#13;
    nodes: list = []&#13;
    to_add: int = vertex_cover_greedy_choice(g, nodes)&#13;
    while to_add != -1:&#13;
        nodes.append(to_add)&#13;
        to_add = vertex_cover_greedy_choice(g, nodes)&#13;
    return nodes&#13;
</code></pre>&#13;
<p class="TX">The code starts with an empty list of nodes (<samp class="SANS_TheSansMonoCd_W5Regular_11">nodes</samp>) to represent the current selection and uses <samp class="SANS_TheSansMonoCd_W5Regular_11">vertex_cover_greedy_choice()</samp> from <a href="#list17-8">Listing 17-8</a> to add nodes one by one until it has constructed a valid vertex covering and no additions would increase the coverage.</p>&#13;
<p class="TX">Note that we could improve the efficiency of this greedy algorithm by maintaining the <samp class="SANS_TheSansMonoCd_W5Regular_11">edges_covered</samp> set in the outer loop and passing it into the <samp class="SANS_TheSansMonoCd_W5Regular_11">vertex_cover_greedy_choice()</samp> function. This avoids the cost of recomputing it with each iteration. For the context of this description, we intentionally recompute <samp class="SANS_TheSansMonoCd_W5Regular_11">edges_covered</samp> so as to keep the selection function stand-alone.</p>&#13;
<p class="TX">As was the case with all the other greedy algorithms in this chapter, the greedy algorithm for minimum vertex cover is not guaranteed to be optimal. A seemingly good-looking initial choice might prove to be suboptimal in the context of the entire graph.</p>&#13;
<p class="TX">Imagine the planner in our watchtower example working on the islands shown in <a href="#fig17-9">Figure 17-9</a>. Determined to keep costs low, the planner <span role="doc-pagebreak" epub:type="pagebreak" id="pg_318" aria-label="318"/>selects the island with the highest number of bridges (node 0) for first watchtower. This is generally a good strategy, as that node covers the most edges. However, in this case, it leads to the suboptimal solution shown in <a href="#fig17-9">Figure 17-9(a)</a>. By choosing node 0 first, the planner needs to choose three more islands to cover the rightmost edges. Worse, they will repeat this mistake again and again. As long as the greedy algorithm is using deterministic choices, it will always produce the same results.</p>&#13;
<figure class="IMG"><img id="fig17-9" class="img80" src="../images/f17009.jpg" alt="A graph with seven nodes and edges (0, 1), (0, 2), (0, 3), (1, 4), (2, 5), and (3, 6). In (A), nodes 0, 1, 2, and 3 are shaded. In (B), nodes 1, 2, and 3 are shaded." width="1127" height="551"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 17-9: The results of a non-optimal greedy search (a) compared to the optimal solution (b) on a minimum vertex cover problem</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">In contrast, <a href="#fig17-9">Figure 17-9(b)</a> shows a vertex cover that uses fewer nodes. Once we have included nodes 1, 2, and 3, we no longer need to include node 0.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec13">&#13;
&#13;
<h4 class="H2"><span id="sec13"/><span id="h-248"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Backtracking Search</samp></h4>&#13;
<p class="TNI1">While the backtracking search for minimum vertex cover follows a similar node-by-node approach to both maximum clique and independent set construction, constructing a vertex cover by adding nodes does not offer the same pruning opportunities. Our general pruning approach requires us to start with a valid solution and skip choices that make our candidate set invalid. However, a subset of a valid vertex cover may not cover each edge and thus may not be a valid vertex cover itself. We therefore cannot start with an empty set and build up from there.</p>&#13;
<p class="TX">We regain the opportunity to prune if we start with a full set of nodes and remove them one by one, instead of adding nodes to a set. Since the set of all nodes is itself a valid vertex cover, we regain the constraint that we are following only branches that remain valid vertex covers.</p>&#13;
<p class="TX">At each level of recursion, the backtracking search function takes the current vertex cover (<samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp>) and the next node to test for removal (<samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp>) and explores the possibilities if it both does and does not remove that node, as shown in <a href="#list17-9">Listing 17-9</a>.</p>&#13;
<span id="list17-9"/>&#13;
<pre><code>def minimum_vertex_cover_rec(g: Graph, current: set, index: int) -&gt; set: &#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> if index &gt;= g.num_nodes:&#13;
        return copy.copy(current)<span role="doc-pagebreak" epub:type="pagebreak" id="pg_319" aria-label="319"/>&#13;
&#13;
    best: set = minimum_vertex_cover_rec(g, current, index + 1)&#13;
&#13;
    can_remove: bool = True&#13;
    for edge in g.nodes[index].get_edge_list():&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> can_remove = can_remove and edge.to_node in current&#13;
&#13;
    if can_remove:&#13;
        current.remove(index)&#13;
        candidate: set = minimum_vertex_cover_rec(g, current, index + 1)&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation3">❸</span> current.add(index)&#13;
&#13;
        if len(candidate) &lt; len(best):&#13;
            best = candidate&#13;
&#13;
    return best&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 17-9: Recursively exploring possible vertex covers</samp></p>&#13;
<p class="TX">The code starts by testing whether it has reached the end of the recursion and there are no nodes left to check <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. If so, it returns a copy of the current vertex cover as the best found down this branch.</p>&#13;
<p class="TX">If the function has not reached the end of the recursion, the code tries vertex covers with and without <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp>. In contrast to the searches in Listings 17-4 and 17-7, however, it is considering whether to <i>remove</i> <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp>. The default option is to leave <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp> in the set by recursively calling the function with the current set and the index of the next node. The code saves the result of this branch as the baseline best result.</p>&#13;
<p class="TX">Before removing the node, the code checks whether this removal would break the vertex cover. For the set to remain valid without <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp>, all the edges currently covered by that node must be covered by another node in <samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp> <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>. The code checks this by iterating over each of the current node’s edges and checking whether the corresponding neighbor (<samp class="SANS_TheSansMonoCd_W5Regular_11">edge.to_node</samp>) is in <samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp>.</p>&#13;
<p class="TX">If it is viable to remove the current node, the code tries removing <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp> from <samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp> and recursively testing the remaining options. It then cleans up the <samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp> data by re-adding <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp> so the set can be used in other branches <span class="CodeAnnotationCode" aria-label="annotation3">❸</span>. The code compares the results of the two branches and keeps the smaller valid subset of nodes.</p>&#13;
<p class="TX">We call the function in <a href="#list17-9">Listing 17-9</a> with an initial <samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp> equal to a set of all node indices and <samp class="SANS_TheSansMonoCd_W5Regular_11">index=0</samp> by using a wrapper function:</p>&#13;
<pre><code>def minimum_vertex_cover_backtracking(g: Graph) -&gt; list: &#13;
    current: set = set([i for i in range(g.num_nodes)])&#13;
    best: set = minimum_vertex_cover_rec(g, current, 0)&#13;
    return list(best)&#13;
</code></pre>&#13;
<p class="TX"><a href="#fig17-10">Figure 17-10</a> provides a visualization of this search where each level shows the algorithm branching on the removal (or not) of a single node. Nodes assigned to the vertex cover are shaded, excluded nodes are white, and unassigned nodes are dashed circles initially included in the vertex cover.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_320" aria-label="320"/>&#13;
<figure class="IMG"><img id="fig17-10" class="img100" src="../images/f17010.jpg" alt="A tree where each node corresponds to a four-node graph with undirected edges (0, 1), (0, 3), (1, 2), and (1, 3). At the root node, all graph nodes are dashed and gray. At each level of the tree, another node becomes either solid white or solid gray." width="2396" height="1232"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 17-10: A backtracking search for finding vertex covers</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_321" aria-label="321"/>The subgraphs in <a href="#fig17-10">Figure 17-10</a> show the state of <samp class="SANS_TheSansMonoCd_W5Regular_11">current</samp> at the start of each function call. Since the function explores only branches containing valid vertex covers, it reaches only 7 of the possible 16 full assignments.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec14">&#13;
&#13;
<h3 class="H1" id="sec14"><span id="h-249"/><samp class="SANS_Futura_Std_Bold_B_11">Randomized Algorithms</samp></h3>&#13;
<p class="TNI1">Another approach to solving the types of assignment problems discussed in this chapter is to evaluate solutions using <i>randomized algorithms</i>. Such algorithms use a random number generator to select which node to add to or remove from the set next. At first this might seem unlikely to work. Deterministically minded users might exclaim, “Why add a random node when we could add the best node with greedy search? Won’t we waste a lot of time on bad choices?” While randomized algorithms can and will explore suboptimal choices, they offer a few important advantages to consider.</p>&#13;
<p class="TX">First, randomized algorithms avoid the local minima that can trap greedy algorithms. As we saw in <a href="#fig17-9">Figure 17-9(a)</a>, greedy searches can lead to suboptimal solutions by making each choice in isolation. In contrast, the randomized algorithm will occasionally guess a good solution, like the one in <a href="#fig17-9">Figure 17-9(b)</a>.</p>&#13;
<p class="TX">Second, a randomized algorithm lends itself well to parallelization: we can run many randomized searches in parallel (without significant coordination), then compare the best results found in each. This is equivalent to having multiple watchtower planners perform their own randomized searches and compare the results, perhaps as part of a kingdom-wide competition where contestants vie to produce the best watchtower plan. Each group can work in isolation without the need for kingdom-wide coordination.</p>&#13;
<p class="TX">In its simplest form, there is nothing to prevent a randomized search from trying the same solution multiple times. While we could use additional tracking to avoid or at least discourage evaluating duplicate options, this adds complexity and, in the case of parallel searches, the need for coordination. In this section, we focus on the basics of how randomization works and thus keep the implementations simple.</p>&#13;
<section epub:type="division" aria-labelledby="sec15">&#13;
&#13;
<h4 class="H2" id="sec15"><span id="h-250"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Basic Randomized Search</samp></h4>&#13;
<p class="TNI1">The simplest randomized search selects viable options completely at random. Let’s consider how this works in the context of finding maximum independent sets. We can use the <samp class="SANS_TheSansMonoCd_W5Regular_11">independent_set_expansion_options()</samp> function from <a href="#list17-5">Listing 17-5</a> as follows to provide a list of feasible options:</p>&#13;
<pre><code>def independent_set_random(g: Graph) -&gt; list: &#13;
    i_set: list = []&#13;
    options: list = independent_set_expansion_options(g, i_set)&#13;
    while len(options) &gt; 0:&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> index: int = random.randint(0, len(options)-1)&#13;
        i_set.append(options[index])&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> options = independent_set_expansion_options(g, i_set)&#13;
    return i_set&#13;
</code></pre>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_322" aria-label="322"/>The code starts with an empty independent set (<samp class="SANS_TheSansMonoCd_W5Regular_11">i_set</samp>) and a list of all nodes as potential options (<samp class="SANS_TheSansMonoCd_W5Regular_11">options</samp>). The code operates by continuously choosing one of the feasible nodes at random <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>, adding it to the independent set, and rebuilding the set of feasible expansion options <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>. The code uses the <samp class="SANS_TheSansMonoCd_W5Regular_11">randint()</samp> function from Python’s <samp class="SANS_TheSansMonoCd_W5Regular_11">random</samp> library to select a node, requiring the inclusion of <samp class="SANS_TheSansMonoCd_W5Regular_11">import random</samp> at the top of the file. The loop continues until there are no more options to add, at which point the code returns the current independent set.</p>&#13;
<p class="TX">Despite being randomized, this function is guaranteed to produce valid independent sets. During each iteration, the algorithm considers only expansions from a list of feasible options, meaning the independent set remains valid after each addition. We can use a loop to keep searching for a better solution until we hit some maximum number of iterations:</p>&#13;
<pre><code>def build_independent_set_random(g: Graph, iterations: int) -&gt; list: &#13;
    best_iset: list = []&#13;
    for i in range(iterations):&#13;
        current_iset: list = independent_set_random(g)&#13;
        if len(current_iset) &gt; len(best_iset):&#13;
            best_iset = current_iset&#13;
    return best_iset&#13;
</code></pre>&#13;
<p class="TX">The code starts with an empty independent set (<samp class="SANS_TheSansMonoCd_W5Regular_11">best_iset</samp>) as the best result seen so far. It then uses a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop to generate and test more options. During each iteration, the code generates a random independent set using <samp class="SANS_TheSansMonoCd_W5Regular_11">independent_set_random()</samp> and compares its size to the best it has seen so far. It tracks the largest independent set seen as <samp class="SANS_TheSansMonoCd_W5Regular_11">best_iset</samp> and returns it after testing <samp class="SANS_TheSansMonoCd_W5Regular_11">iterations</samp> options.</p>&#13;
<p class="TX">We can picture this search in the context of the earlier example of building teams in a dysfunctional organization. The planner is determined to build the biggest team but lacks the time to do an exhaustive search. Panicked by their tight deadline, they resolve to build 100 random but valid teams and present the best one to their boss. For each of their 100 attempts to create a team, they use random selection to make sure they at least have the possibility of trying options they have not previously considered. After 100 tries, they write up the best team and run to their boss’s office to meet the deadline.</p>&#13;
<p class="TX">Like the greedy search, the randomized search is not guaranteed to find the optimal solution. However, unlike the greedy search, the randomized search can avoid making the same mistake over and over.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec16">&#13;
&#13;
<h4 class="H2" id="sec16"><span id="h-251"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Weighted Randomized Search</samp></h4>&#13;
<p class="TNI1">One potential downside of completely randomized searches is that we have an equal probability of picking a promising node or a terrible node. While there must be some probability of selecting each node to fully explore the solution space, we are not constrained to selecting nodes with equal probability. There’s no reason we need to give the office diplomat (who has no interpersonal conflicts) and office troublemaker (who has ongoing feuds with half the company) equal shots at being on the team.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_323" aria-label="323"/>A <i>weighted randomized algorithm</i> uses information about the problem structure to define a custom probability distribution for selecting nodes. As a simple example, consider selecting the next node in the maximum independent set problem. Given a subset of nodes <i>V</i><span class="symbol">′ ⊆</span> <i>V</i> representing the current independent set, we can define a set of viable candidates <i>C</i> as the set of nodes that are not already in <i>V</i><span class="symbol">′</span> and do not share an edge with a node in <i>V</i><span class="symbol">′</span>. Formally, we say:</p>&#13;
<p class="EQ">For each <i>u</i> <span class="symbol">∈</span> <i>C</i> and <i>v</i> <span class="symbol">∈</span> <i>V</i><span class="symbol">′</span>: <i>u</i> ≠ <i>v</i> and (<i>u</i>, <i>v</i>) <span class="symbol">∉</span> <i>E</i>.</p>&#13;
<p class="BodyContinued">Given this candidate set <i>C,</i> we can define a probability distribution <i>p</i>(<i>v</i>) of selecting node <i>v</i> <span class="symbol">∈</span> <i>V</i> where:</p>&#13;
<p class="EQ"><i>p</i>(<i>v</i>) = 0 if <i>v</i> <span class="symbol">∉</span> <i>C</i></p>&#13;
<p class="BodyContinued">and</p>&#13;
<p class="EQ">∑<span class="ePub-I-SUB">v</span> <i>p</i>(<i>v</i>) = 1</p>&#13;
<p class="BodyContinued">For example, we could assign each node a weight that is inversely proportional to the number of adjacent edges, making it more likely that we will select nodes with fewer neighbors.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec17">&#13;
&#13;
<h3 class="H1" id="sec17"><span id="h-252"/><samp class="SANS_Futura_Std_Bold_B_11">Why This Matters</samp></h3>&#13;
<p class="TNI1">For all the problems covered in this chapter and the previous one, it’s easy to evaluate a proposed solution but difficult to find the best solution. We’ve examined a variety of approaches for solving NP-hard graph assignment problems, including greedy searches, randomized searches, exhaustive searches, and customized (heuristic) algorithms. Yet no known approach is efficient for all cases.</p>&#13;
<p class="TX">These problems represent only a subset of the NP-hard graph problems. While they do not have known general-purpose efficient algorithms, they often correspond to vital real-world questions. Therefore, it is important to understand not only the structure of the problems but also practical techniques for solving them.</p>&#13;
<p class="TX">We presented two approaches for each of the problems in this chapter—an approximate greedy solution and an exhaustive solution using backtracking search—to illustrate the problems and the factors making them computationally difficult. These approaches barely scratch the surface of the range of techniques that have been studied. For example, the interested reader can find a bounded approximation algorithm for vertex cover in Cormen, Leiserson, Rivest, and Stein’s <i>Introduction to Algorithms</i>, 4th edition (MIT Press, 2022). Russell and Norvig’s <i>Artificial Intelligence: A Modern Approach</i>, 4th edition (Pearson, 2020), provides a good introduction to the powerful world of constraint satisfaction algorithms and applying those to problems such as graph coloring.</p>&#13;
<p class="TX">In the next chapter, rather than selecting nodes for a set, we tackle the problem of choosing which edges to traverse as part of a tour through the graph.</p>&#13;
</section>&#13;
</section>&#13;
</div>
</div>
</body></html>