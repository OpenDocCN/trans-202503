- en: '16'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with JSON Data
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: '*JavaScript Object Notation (JSON)* is a widely used text format for storing
    data in a platform-independent way so it can be shared between computer systems.
    In this chapter, you’ll learn the structure of JSON as well as how to store and
    query JSON data types in PostgreSQL. After we explore PostgreSQL’s JSON query
    operators, we’ll analyze a month’s worth of data about earthquakes.'
  prefs: []
  type: TYPE_NORMAL
- en: The American National Standards Institute (ANSI) SQL standard added syntax definitions
    for JSON and specified functions for creating and accessing JSON objects in 2016\.
    Major database systems have added JSON support in recent years as well, although
    implementations vary. PostgreSQL, for example, supports some of the ANSI standard
    while implementing a number of nonstandard operators. I’ll note which aspects
    of PostgreSQL’s JSON support are part of standard SQL as we work through exercises.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding JSON Structure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'JSON data primarily comprises two structures: an *object*, which is an unordered
    set of name/value pairs, and an *array*, which is an ordered collection of values.
    If you’ve used programming languages such as JavaScript, Python, or C#, these
    aspects of JSON should look familiar.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside an object, we use name/value pairs as a structure for storing and referencing
    individual data items. The object in its entirety is enclosed within curly brackets,
    and each name, more often referred to as a *key*, is enclosed in double quotes,
    followed by a colon and its corresponding value. The object can encapsulate multiple
    key/value pairs, separated by commas. Here’s an example using movie information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The keys are `title` and `year`, and their values are `"The Incredibles"` and
    `2004`. If the value is a string, it goes in double quotes. If it’s a number,
    a Boolean value, or a `null`, we omit the quotes. If you’re familiar with the
    Python language, you’ll recognize this structure as a *dictionary*.
  prefs: []
  type: TYPE_NORMAL
- en: 'An array is an ordered list of values enclosed in square brackets. We separate
    each value in the array with a comma. For example, we might list movie genres
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Arrays are common in programming languages, and we’ve used them already in SQL
    queries. In Python, this structure is called a *list*.
  prefs: []
  type: TYPE_NORMAL
- en: We can create many permutations of these structures, including nesting objects
    and arrays inside each other. For example, we can create an array of objects or
    use an array as the value of a key. We can add or omit key/value pairs or create
    additional arrays of objects without violating a preset schema. This flexibility—in
    contrast to the strict definition of a SQL table—is both part of the appeal of
    using JSON as a data store as well as one of the biggest difficulties in working
    with JSON data.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, [Listing 16-1](#listing16-1) shows information about two of my
    favorite films stored as JSON. The outermost structure is an array with two elements—one
    object for each film. We know the outermost structure is an array because the
    entire JSON begins and ends with square brackets.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-1: JSON with information about two films'
  prefs: []
  type: TYPE_NORMAL
- en: Inside the outermost array, each film object is surrounded by curly brackets.
    The open brace at 1 starts the object for the first film *The Incredibles*. For
    both films, we store the `title` and `year` as key/value pairs, and they have
    string and integer values, respectively. The third key, `rating` 2, has a JSON
    object for its value. That object contains a single key/value pair showing the
    film’s rating from the Motion Picture Association of America.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we can see the flexibility JSON affords us as a storage medium. First,
    if we later wanted to add another country’s rating for the film, we could easily
    add a second key/value pair to the `rating` value object. Second, we’re not required
    to include `rating`—or any key/value pair—in every film object. In fact, I omitted
    a `rating` for *Cinema Paradiso*. If a particular piece of data isn’t available,
    in this case a rating, some systems that generate JSON might simply exclude that
    pair. Other systems might include `rating` but with a `null` value. Both are valid,
    and that flexibility is one of JSON’s advantages: its data definition, or *schema*,
    can flex as needed.'
  prefs: []
  type: TYPE_NORMAL
- en: The final two key/value pairs show other ways to structure JSON. For `characters`
    3, the value is an array of objects, with each object surrounded by curly brackets
    and separated by a comma. The value for `genre` 4 is an array of strings.
  prefs: []
  type: TYPE_NORMAL
- en: Considering When to Use JSON with SQL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are advantages to using *NoSQL* or *document* databases that store data
    in JSON or other text-based data formats, as opposed to the relational tables
    SQL uses. Document databases are flexible in terms of data definitions. You can
    redefine a data structure on the fly if needed. Document databases are often also
    used for high-volume applications because they can be scaled by adding servers.
    On the flip side, you may give up SQL advantages such as easily added constraints
    that enforce data integrity and support for transactions.
  prefs: []
  type: TYPE_NORMAL
- en: The arrival of JSON support in SQL has made it possible to enjoy the best of
    both worlds by adding JSON data as columns in relational tables. The decision
    to use a SQL or NoSQL database should be multifaceted. PostgreSQL performs favorably
    relative to NoSQL in terms of speed, but we must also consider the kinds and volume
    of data being stored, the applications being served, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'That said, some cases where you might want to take advantage of JSON in SQL
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: When users or applications need to arbitrarily create key/value pairs. For example,
    if tagging a collection of medical research papers, one user might want to add
    a key to track chemical names, and another user might want a key to track food
    names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When storing related data in a JSON column instead of a separate table. An employees
    table could have the usual columns for name and contact information plus a JSON
    column with a flexible collection of key/value pairs that might hold additional
    attributes that don’t apply to every employee, such as company awards or performance
    metrics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When saving time by analyzing JSON data fetched from other systems without first
    parsing it into a set of tables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep in mind that using JSON in PostgreSQL or other SQL databases can also present
    challenges. Constraints that are trivial to set up on regular SQL tables can be
    more difficult to set and enforce on JSON data. JSON data can consume more space
    as key names get repeated in text along with the quotes, commas, and braces that
    define its structure. Finally, the flexibility of JSON can create issues for the
    code that interacts with it—whether SQL or another language—if keys unexpectedly
    disappear or the data type of a value changes.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping all this in mind, let’s review PostgreSQL’s two JSON data types and
    load some JSON into a table.
  prefs: []
  type: TYPE_NORMAL
- en: Using json and jsonb Data Types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PostgreSQL provides two data types for storing JSON. Both allow insertion of
    valid JSON only—text that includes required elements of the JSON specification,
    such as open and closing curly brackets around an object, commas separating objects,
    and proper quoting of keys. If you try to insert invalid JSON, the database will
    generate an error.
  prefs: []
  type: TYPE_NORMAL
- en: The main difference between the two is that one stores JSON as text and the
    other as binary data. The binary implementation is newer to PostgreSQL and generally
    preferred because it’s faster at querying and has indexing capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The two types are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '****json****'
  prefs: []
  type: TYPE_NORMAL
- en: Stores JSON as text, keeping white space and maintaining the order of keys.
    If a single JSON object contains a particular key more than once (which is valid),
    the `json` type will preserve each of the repeated key/value pairs. Finally, each
    time a database function processes `json`-stored text, it must parse the object
    to interpret its structure. This can make reads from the database slower than
    with the `jsonb` type. Indexing is not supported. Typically, the `json` type is
    useful when an application has duplicate keys or needs to preserve the order of
    keys.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '****jsonb****'
  prefs: []
  type: TYPE_NORMAL
- en: Stores JSON in a binary format, removing white space and not maintaining the
    order of keys. If a single JSON object contains a particular key more than once,
    the `jsonb` type will preserve only the last of the key/value pairs. The binary
    format adds some overhead to writing data to the table, but processing is faster.
    Indexing is supported.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Neither `json` nor `jsonb` is part of the ANSI SQL standard, which doesn’t specify
    a JSON data type and leaves it to database makers to decide how to implement support.
    The PostgreSQL documentation at [https://www.postgresql.org/docs/current/datatype-json.html](https://www.postgresql.org/docs/current/datatype-json.html)
    recommends using `jsonb` unless there’s a need to preserve the order of key/value
    pairs.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use `jsonb` exclusively in the remainder of the chapter, both because
    of speed considerations but also because many of PostgreSQL’s JSON functions work
    the same way with both `json` and `jsonb`—and there are more functions available
    for `jsonb`. We’ll continue by adding the films JSON from [Listing 16-1](#listing16-1)
    to a table and exploring JSON query syntax.
  prefs: []
  type: TYPE_NORMAL
- en: Importing and Indexing JSON Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The file *films.json* in the Chapter 16 folder of the book’s resources at [https://nostarch.com/practical-sql-2nd-edition/](https://nostarch.com/practical-sql-2nd-edition/)
    contains a modified form of the JSON in [Listing 16-1](#listing16-1). View the
    file with a text editor, and you’ll see each film’s JSON object is placed on a
    single line, with no line breaks between elements. I’ve also removed the outermost
    square brackets and the comma separating the two film objects. Each remains a
    valid JSON object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: I set up the file this way so that PostgreSQL’s `COPY` command will interpret
    each film’s JSON object as a separate row on import, the same way it does when
    importing a CSV file. The code in [Listing 16-2](#listing16-2) makes a simple
    `films` table with a surrogate primary key and a `jsonb` column called `film`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-2: Creating a table to hold JSON data and adding an index'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the `COPY` statement ends with the `FROM` clause 1 instead of continuing
    to include a `WITH` statement as in previous examples. The reason we no longer
    need the `WITH` statement, which we’ve used to specify options for file headers
    and CSV formatting, is that this file has no header and isn’t delimited. We just
    want the database to read each line and process it.
  prefs: []
  type: TYPE_NORMAL
- en: After import, we add an index 2 to the `jsonb` column using the GIN index type.
    We discussed the generalized inverted index (GIN) with full-text search in Chapter
    14. GIN’s implementation of indexing the location of words or key values within
    text is particularly suited to JSON data. Note that because index entries point
    to rows in a table, `jsonb` column indexing works best when each row contains
    a relatively small chunk of JSON—as opposed to a table with one row that has a
    single, enormous JSON value and repeated keys.
  prefs: []
  type: TYPE_NORMAL
- en: Execute the commands to create and fill the table and add the index. Run `SELECT
    * FROM films;` and you should see two rows containing the autogenerated `id` and
    the JSON object text. Now you’re ready to explore querying the data using with
    PostgreSQL’s JSON operators.
  prefs: []
  type: TYPE_NORMAL
- en: Using json and jsonb Extraction Operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To retrieve values from our stored JSON, we can use PostgreSQL-specific *extraction
    operators*, which return either a JSON object, an element of an array, or an element
    that exists at a path in the JSON structure we specify. [Table 16-1](#table16-1)
    shows the operators and their functions, which can vary based on the data type
    of the input. Each works with `json` and `jsonb` data types.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 16-1: `json` and `jsonb` Extraction Operators'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Operator, syntax** | **Function** | **Returns** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `json` `->` `text` `jsonb` `->` `text` | Extracts a key value, specified
    as text | `json` or `jsonb` (matching the input) |'
  prefs: []
  type: TYPE_TB
- en: '| `json` `->>` `text` `jsonb` `->>` `text` | Extracts a key value, specified
    as text | `text` |'
  prefs: []
  type: TYPE_TB
- en: '| `json` `->` `integer` `jsonb` `->` `integer` | Extracts an array element,
    specified as an integer denoting its array position | `json` or `jsonb` (matching
    the input) |'
  prefs: []
  type: TYPE_TB
- en: '| `json` `->>` `integer` `jsonb` `->>` `integer` | Extracts an array element,
    specified as an integer denoting its array position | `text` |'
  prefs: []
  type: TYPE_TB
- en: '| `json` `#>` `text array` `jsonb` `#>` `text array` | Extracts a JSON object
    at a specified path | `json` or `jsonb` (matching the input) |'
  prefs: []
  type: TYPE_TB
- en: '| `json` `#>>` `text array` `jsonb` `#>>` `text array` | Extracts a JSON object
    at a specified path | `text` |'
  prefs: []
  type: TYPE_TB
- en: Let’s try the operators with our films JSON to learn more about how they vary
    in function.
  prefs: []
  type: TYPE_NORMAL
- en: Key Value Extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In [Listing 16-3](#listing16-3) we use the `->` and `->>` operators followed
    by text naming the key value to retrieve. In that context, with text input, these
    are called *field extraction operators* because they extract a field, or key value,
    from the JSON. The difference between the two is that `->` returns the key value
    as JSON in the same type as stored, and `->>` returns the key value as text.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-3: Retrieving a JSON key value with field extraction operators'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `SELECT` list, we specify our JSON column name followed by the operator
    and the key name in single quotes. In the first example, the syntax `->` `''title''`
    1 returns the value of the `title` key as JSON in the same data type as stored,
    `jsonb`. Run the first query, and you should see the output like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In pgAdmin, the data type listed in the `title` column header should indicate
    `jsonb`, and the film titles remain quoted, as they are in the JSON object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Changing the field extraction operator to `->>` 2 returns the film titles as
    text instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we’ll return an array. In our films JSON, the value of the key `genre`
    is an array of values. Using the field extraction operator `->` 3 returns the
    array as `jsonb`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If we used `->>` here, we’d return the arrays as text. Let’s look at how to
    extract elements from an array.
  prefs: []
  type: TYPE_NORMAL
- en: Array Element Extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To retrieve a specific value from an array, we follow the `->` and `->>` operators
    with an integer specifying the value’s position, or *index*, in the array. We
    call these *element extraction operators* because they retrieve an element from
    a JSON array. As with field extraction, `->` returns the value as JSON in the
    same type as stored, and `->>` returns it as text.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 16-4](#listing16-4) shows four examples using the array values of
    `"genre"`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-4: Retrieving a JSON array value with element extraction operators'
  prefs: []
  type: TYPE_NORMAL
- en: We must first retrieve the array value from the key as JSON and then retrieve
    the desired element from the array. In the first example, we specify the JSON
    column `film`, followed by the field extraction operator `->` and the `genre`
    key name in single quotes. This returns the `genre` value as `jsonb`. We follow
    the key name with `->` and the integer `0` 1 to get the first element.
  prefs: []
  type: TYPE_NORMAL
- en: Why not use `1` for the first value in the array? In many languages, including
    Python and JavaScript, index values start at zero, and that’s also true when accessing
    JSON arrays with SQL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the first query, and your results should look like this, showing the first
    element in each film’s `genre` array, returned as `jsonb`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also access the last element of the array, even if we aren’t sure of
    its index, because the number of genres per film can vary. We count backward from
    the end of the list using a negative index number. Supplying `-1` 2 tells `->`
    to get the first element from the end of the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We can count back further if we want—an index of `-2` will get the next-to-last
    element.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that PostgreSQL won’t return an error if there’s no element at the supplied
    index position; it will simply return a `NULL` for that row. For example, if we
    supply `2` 3 for the index, we see results for one of our films and a `NULL` for
    the other:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We get a `NULL` back for *Cinema Paradiso* because it has only two elements
    in its `genre` value array, and index `2` (since we count up starting with zero)
    represents the third element. Later in the chapter, we’ll learn how to count array
    lengths.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, changing the element extraction operator to `->>` 4 returns the desired
    element as a `text` data type rather than JSON:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the same pattern as we saw when extracting key values: `->` returns
    a JSON data type, and `->>` returns text.'
  prefs: []
  type: TYPE_NORMAL
- en: Path Extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Both `#>` and `#>>` are *path extraction operators* that return an object located
    at a JSON path. A path is a series of keys or array indices that lead to the location
    of a value. In our example JSON, it might be just the `title` key if we want the
    name of the film. Or it could be more complex, such as the `characters` key followed
    by an index value of `1`, then the `actor` key; this would provide the path to
    the name of the actor at index `1`. The `#>` path extraction operator returns
    a JSON data type matching the stored data, and `#>>` returns text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the MPAA rating for the film *The Incredibles*, which appears in our
    JSON like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The structure is a key named `rating` with an object for its value; inside that
    object is a key/value pair with `MPAA` as the key name. Thus, the path to the
    film’s MPAA rating begins with the `rating` key and ends with the `MPAA` key.
    To denote the path’s elements, we use the PostgreSQL string syntax for arrays,
    creating a comma-separated list inside curly brackets and single quotes. We then
    feed that string to the path extraction operators. [Listing 16-5](#listing16-5)
    shows three examples of setting paths.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-5: Retrieving a JSON key value with path extraction operators'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get each film’s MPAA rating, we specify the path in an array: `{rating,
    MPAA}` 1 with each item separated by commas. Run the query, and you should see
    these results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The query returns the PG rating for *The Incredibles* and a `NULL` for *Cinema
    Paradiso* because, in our data, the latter film has no MPAA rating present.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second example works with the array of `characters`, which in our JSON
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The `characters` array shown is for the second movie, but both films have a
    similar structure. Array objects each represent a character and the name and the
    actor who played them. To locate the name of the first character in the array,
    we specify a path 2 that starts at the `characters` key, continues to the first
    element of the array using the index `0`, and ends at the `name` key. The query
    results should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The `#>` operator returns results as a JSON data type, in our case `jsonb`.
    If we want the results as text, we use `#>>` 3 with the same path.
  prefs: []
  type: TYPE_NORMAL
- en: Containment and Existence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The final collection of operators we’ll explore performs two kinds of evaluations.
    The first concerns *containment* and checks whether a specified JSON value contains
    a second specified JSON value. The second tests for *existence*: whether a string
    of text within a JSON object exists as a top-level key (or as an element of an
    array nested inside a deeper object). Both kinds of operators return a Boolean
    value, which means we can use them in a `WHERE` clause to filter query results.'
  prefs: []
  type: TYPE_NORMAL
- en: This set of operators works only with the `jsonb` data type—another good reason
    to favor `jsonb` over `json`—and can make use of our GIN index for efficient searching.
    [Table 16-2](#table16-2) lists the operators with their syntax and function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 16-2: `jsonb` Containment and Existence Operators'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Operator, syntax** | **Function** | **Returns** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `jsonb` `@>` `jsonb` | Tests whether the first JSON value contains the second
    JSON value | `boolean` |'
  prefs: []
  type: TYPE_TB
- en: '| `jsonb` `<@` `jsonb` | Tests whether the second JSON value contains the first
    JSON value | `boolean` |'
  prefs: []
  type: TYPE_TB
- en: '| `jsonb` `?` `text` | Tests whether the text exists as a top-level (not nested)
    key or an array value | `boolean` |'
  prefs: []
  type: TYPE_TB
- en: '| `jsonb` `?&#124;` `text array` | Tests whether any of the text elements in
    the array exist as a top-level (not nested) key or as an array value | `boolean`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `jsonb` `?&` `text array` | Tests whether all of the text elements in the
    array exist as a top-level (not nested) key or as an array value | `boolean` |'
  prefs: []
  type: TYPE_TB
- en: Using Containment Operators
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In [Listing 16-6](#listing16-6), we use `@>` to evaluate whether one JSON value
    contains a second JSON value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-6: Demonstrating the `@>` containment operator'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our `SELECT` list, we check whether the JSON stored in the `film` column
    in each row contains the key/value pair for *The Incredibles*. We use the `@>`
    containment operator 1 in an expression that generates a column with the Boolean
    result `true` if `film` contains `"title": "The Incredibles"`. We give the name
    of our JSON column, `film`, then the `@>` operator, and then a string (cast to
    `jsonb`) specifying the key/value pair. In our `SELECT` list, we also return the
    text of the film title as a column. Running the query should produce these results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As expected, the expression evaluates to `true` for *The Incredibles* and `false`
    for *Cinema Paradiso*.
  prefs: []
  type: TYPE_NORMAL
- en: Because the expression evaluates to a Boolean result, we can use it in a query’s
    `WHERE` 2 clause, as shown in [Listing 16-7](#listing16-7).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-7: Using a containment operator in a `WHERE` clause'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we again check that the JSON in the `film` column contains the key/value
    pair for the title of *The Incredibles*. By placing the evaluation in a `WHERE`
    clause, the query should return just the row where the expression returns `true`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Finally, in [Listing 16-8](#listing16-8), we flip the order of evaluation to
    check whether the key/value pair specified is contained within the `film` column.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-8: Demonstrating the `<@` containment operator'
  prefs: []
  type: TYPE_NORMAL
- en: Here we use the `<@` operator 3 instead of `@>` to flip the order of evaluation.
    This expression also evaluates to `true`, returning the same result as the previous
    query.
  prefs: []
  type: TYPE_NORMAL
- en: Using Existence Operators
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Next, in [Listing 16-9](#listing16-9), we explore three existence operators.
    These check whether the text we supply exists as a top-level key or as an element
    of an array. All return a Boolean value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-9: Demonstrating existence operators'
  prefs: []
  type: TYPE_NORMAL
- en: The `?` operator checks for the existence of a single key or array element.
    In the first query’s `WHERE` clause, we give the `film` column, the `?` operator
    1, and then the string `rating`. This syntax says, “In each row, does `rating`
    exist as a key in the JSON in the `film` column?” When we run the query, the results
    show the one film that has a `rating` key, *The Incredibles*.
  prefs: []
  type: TYPE_NORMAL
- en: The `?|` and `?&` operators act as `or` and `and`. For example, using `?|` 2
    tests whether either `rating` or `genre` exist as top-level keys. Running that
    second query returns both films, because both have at least one of those keys.
    Using `?&` 3, however, tests whether both `rating` and `genre` exist as keys,
    and that’s true for only *The Incredibles*.
  prefs: []
  type: TYPE_NORMAL
- en: All these operators provide options for fine-tuning your exploration of your
    JSON data. Now, let’s use some of them on a larger dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing Earthquake Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we’ll analyze a collection of JSON data about earthquakes compiled
    by the US Geological Survey, an agency of the US Department of the Interior that
    monitors natural phenomenon including volcanoes, landslides, and water quality.
    The USGS uses a network of seismographs that record the earth’s vibrations, compiling
    data on each seismic event’s location and intensity. Minor earthquakes occur around
    the world many times a day; the big ones are less frequent but potentially devastating.
  prefs: []
  type: TYPE_NORMAL
- en: For our exercise, I fetched a month’s worth of JSON-formatted earthquake data
    from a USGS *application programming interface*, better known as an API. An *API*
    is a resource for transmitting data and commands between computers, and JSON is
    often used for APIs. You’ll find the data in the file *earthquakes.json* in the
    folder for this chapter included in the book’s resources.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring and Loading the Earthquake Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Listing 16-10](#listing16-10) shows the data structure for each earthquake
    record in the file, along with a selection of its key/value pairs (your *Chapter_16.sql*
    file has the nonsnipped version).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-10: JSON with data on one earthquake'
  prefs: []
  type: TYPE_NORMAL
- en: 'This data is in *GeoJSON* format, a JSON-based specification for spatial data.
    GeoJSON will include one or more `Feature` objects, denoted by inclusion of the
    key/value pair `"type": "Feature"` 1. Each `Feature` describes a single spatial
    object and contains both descriptive attributes (such as event time or related
    codes) under `properties` 2 plus a `geometry` 3 key that includes the coordinates
    of the spatial object. In our data, each `geometry` is a Point, a simple feature
    with the coordinates of one earthquake’s longitude, latitude, and depth in kilometers.
    We discussed Points and simple features in Chapter 15 when working with PostGIS;
    GeoJSON incorporates it and other spatial simple features. You can read more about
    the GeoJSON specification at [https://geojson.org/](https://geojson.org/) and
    see definitions of the keys in the USGS documentation at [https://earthquake.usgs.gov/data/comcat/data-eventterms.php/](https://earthquake.usgs.gov/data/comcat/data-eventterms.php/).'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s load our data into a table called `earthquakes` using the code in [Listing
    16-11](#listing16-11).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-11: Creating and loading an earthquakes table'
  prefs: []
  type: TYPE_NORMAL
- en: As with our `films` table, we use `COPY` to copy the data into a single `jsonb`
    column 1 and add a GIN index 2. Running `SELECT * FROM earthquakes;` should return
    12,899 rows. Now let’s see what we can learn from the data.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Earthquake Times
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `time` key/value pair represents the moment the earthquake occurred. In
    [Listing 16-12](#listing16-12), we retrieve the value of `time` using a path extraction
    operator.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-12: Retrieving the earthquake time'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `SELECT` list, we give the `earthquake` column followed by a `#>>` path
    extraction operator and the path 1 to the time value denoted as an array. The
    `#>>` operator will return our value as text. Running the query should return
    five rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: If those values don’t look like times to you, that’s not surprising. By default,
    the USGS represents time as milliseconds since the Unix epoch at 00:00 UTC on
    January 1, 1970\. That’s a variant of the standard epoch time we covered in Chapter
    12, which measures seconds since the epoch. We can convert this USGS `time` value
    to something understandable using `to_timestamp()` and a little math, as shown
    in [Listing 16-13](#listing16-13).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-13: Converting the `time` value to a timestamp'
  prefs: []
  type: TYPE_NORMAL
- en: Inside the parentheses of the `to_timestamp()` 1 function, we repeat the code
    to extract the `time` value. The `to_timestamp()` function requires a number representing
    seconds, but the extracted value is text and in milliseconds, so we also cast
    the extracted text to `bigint` and divide by 1,000 2 to convert it to seconds.
  prefs: []
  type: TYPE_NORMAL
- en: 'On my machine, the query generates the following results showing the extracted
    `time` value and its converted timestamp (your values will vary depending on your
    PostgreSQL server’s time zone, so `time_formatted` will show when the earthquake
    occurred in your server’s time zone time):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have an understandable timestamp, let’s find the oldest and newest
    earthquake times using the `min()` and `max()` aggregate functions in [Listing
    16-14](#listing16-14).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-14: Finding the minimum and maximum earthquake times'
  prefs: []
  type: TYPE_NORMAL
- en: 'We place `to_timestamp()` and our milliseconds-to-seconds conversion inside
    both the `min()` 1 and `max()` 3 functions in our `SELECT` list. This time, we
    add the keywords `AT TIME ZONE ''UTC''` 2 after both functions; regardless of
    our server time zone settings, the results will display the timestamps in UTC,
    as USGS records them. Your results should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This collection of earthquakes spans a month—from early morning January 1, 2021,
    through the end of day on January 31\. That’s helpful context as we continue to
    dig for usable information.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the Largest and Most-Reported Earthquakes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next, we’ll look at two data points that measure an earthquake’s size and the
    degree to which citizens reported feeling it and apply JSON extraction techniques
    to simple sorting of results.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting by Magnitude
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The USGS reports each earthquake’s magnitude in the `mag` key, beneath `properties`.
    Magnitude, according to the USGS, is a number representing the size of an earthquake
    at its source. Its scale is logarithmic: a magnitude 4 earthquake has seismic
    waves whose amplitude is about 10 times bigger than a quake with a magnitude of
    3\. With that context, let’s find the five largest earthquakes in our data using
    the code in [Listing 16-15](#listing16-15).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-15: Finding the five earthquakes with the largest magnitude'
  prefs: []
  type: TYPE_NORMAL
- en: 'We again use path extraction operators to retrieve our desired elements, including
    values for `place` 1 and `mag`. To show the largest five in our results, we add
    an `ORDER BY` clause 2 with `mag`. We cast the value to numeric 3 here and in
    the `SELECT` because we want to display and sort the value as a number rather
    than as text. We also add the `DESC NULLS LAST` keywords, which sorts the results
    in descending order and places `NULL` values (of which there are two) last. Your
    results should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The largest, of magnitude 7, was located beneath the ocean southeast of the
    small city of Pondaguitan in the Philippines. The second was in the Antarctic
    near the South Shetland Islands.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting by Citizen Reports
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The USGS operates a Did You Feel It? website at [https://earthquake.usgs.gov/data/dyfi/](https://earthquake.usgs.gov/data/dyfi/)
    where people can report their earthquake experiences. Our JSON includes the number
    of reports for each earthquake under the key `felt`, beneath `properties`. Let’s
    see which earthquakes in our data generated the most reports using the code in
    [Listing 16-16](#listing16-16).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-16: Finding earthquakes with the most Did You Feel It? reports'
  prefs: []
  type: TYPE_NORMAL
- en: 'Structurally, this query is similar to [Listing 16-15](#listing16-15) that
    found the largest quakes. We add a path extraction operator for the `felt` 1 key,
    casting the returned text value to an `integer` type. We cast to `integer` so
    the extracted text is treated as a number for sorting and display. Finally, we
    place the extraction code in `ORDER BY` 2, using `NULLS LAST` because there are
    many earthquakes with no reports and we want those to appear last in the list.
    You should see these results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The top five are in California, which makes sense. Did You Feel It? is a US
    government-run system, so we’d expect more US reports—particularly in earthquake-prone
    California. Also, some of the largest quakes in our data occurred beneath oceans
    or in remote regions. The quake with more than 19,900 reports was moderate, but
    its nearness to cities meant more chance for people to notice it.
  prefs: []
  type: TYPE_NORMAL
- en: Converting Earthquake JSON to Spatial Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our JSON data has longitude and latitude values for each earthquake, meaning
    we can perform spatial analysis using the GIS techniques discussed in Chapter
    15. For example, we’ll use a PostGIS distance function to locate earthquakes that
    occurred within 50 miles from a city. First, though, we must convert the coordinates
    stored in JSON to a PostGIS data type.
  prefs: []
  type: TYPE_NORMAL
- en: 'The longitude and latitude values are found in the array of the `coordinates`
    key, under `geometry`. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The first coordinate, at position `0` in the array, represents longitude; the
    second, at position `1`, is latitude. The third value denotes depth in kilometers,
    which we won’t use. To extract these elements as text, we make use of a `#>>`
    path operator, as in [Listing 16-17](#listing16-17).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-17: Extracting the earthquake’s location data'
  prefs: []
  type: TYPE_NORMAL
- en: 'The query should return five rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: A quick visual compare of our result to the JSON `longitude` and `latitude`
    values tells us we’ve extracted the values properly. Next, we’ll use a PostGIS
    function to convert those values to a Point in the `geography` data type.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 16-18](#listing16-18) generates a Point of type `geography` for each
    earthquake, which we can use as input for PostGIS spatial functions.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-18: Converting JSON location data to PostGIS geography'
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside `ST_MakePoint()`1, we place our code to extract longitude and latitude,
    casting both values to type `numeric` as required by the function. We nest that
    function inside `ST_SetSRID()` to set a spatial reference system identifier (SRID)
    for the resulting Point. In Chapter 15, you learned that the SRID specifies a
    coordinate grid for plotting spatial objects. The SRID value `4326` 2 denotes
    the commonly used WGS 84 coordinate system. Finally, we cast the entire output
    to the `geography` type. The first several rows should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: We can’t interpret those strings of digits and letters directly, but we can
    use pgAdmin’s Geometry Viewer to see the Points plotted on a map. With your query
    results visible in the pgAdmin Data Output pane, click the eye icon in the `earthquake_point`
    result header. You should see the earthquakes plotted on a map that uses OpenStreetMap
    as the base layer, as in [Figure 16-1](#figure16-1).
  prefs: []
  type: TYPE_NORMAL
- en: Even with only a month of data, it’s easy to see the abundance of earthquakes
    concentrated around the edges of the Pacific Ocean, in the so-called Ring of Fire
    where tectonic plates meet and volcanos are more active.
  prefs: []
  type: TYPE_NORMAL
- en: '![f16001](Images/f16001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16-1: Viewing earthquake locations in pgAdmin'
  prefs: []
  type: TYPE_NORMAL
- en: Finding Earthquakes Within a Distance
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Next, let’s narrow our study to earthquakes that occurred near Tulsa, Oklahoma—a
    part of the country that has seen increased seismic activity since 2009 as a result
    of oil and gas processing, according to the USGS.
  prefs: []
  type: TYPE_NORMAL
- en: To perform more complex GIS tasks like this, it’s easier if we permanently convert
    the JSON coordinates to a column of PostGIS type `geography` in the `earthquakes`
    table. That allows us to avoid the clutter of adding conversion code in each query.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 16-19](#listing16-19) adds a column called `earthquake_point` to the
    `earthquakes` table and fills the new column with the JSON coordinates converted
    to type `geography`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-19: Converting JSON coordinates to a PostGIS geometry column'
  prefs: []
  type: TYPE_NORMAL
- en: We use `ALTER TABLE` 1 to add a column `earthquake_point` of type `geography`,
    specifying that the column will hold Points with an SRID of `4326`. Next, we `UPDATE`
    2 the table, setting the `earthquake_point` column using the same syntax as in
    [Listing 16-18](#listing16-18), and add a spatial index using GIST 3 to the new
    column.
  prefs: []
  type: TYPE_NORMAL
- en: That done, we can use [Listing 16-20](#listing16-20) to find earthquakes within
    50 miles of Tulsa.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-20: Finding earthquakes within 50 miles of downtown Tulsa, Oklahoma'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `WHERE` clause 1, we employ the `ST_DWithin()` function, which returns
    a Boolean value of `true` if one spatial object is within a specified distance
    of another object. Here, we want to evaluate each earthquake Point to check whether
    it’s within 50 miles of downtown Tulsa. We designate the city’s coordinates in
    `ST_GeogFromText()` 2 and supply the value of 50 miles using its meters equivalent,
    `80468`, as meters is the required input. The query should return 19 rows (I’ve
    omitted the `earthquake_point` column and truncated the results for brevity):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: View the earthquake locations by clicking the eye icon atop the `earthquake_point`
    column in the results in pgAdmin. You should see 19 dots around the city, as in
    [Figure 16-2](#figure16-2) (and you can adjust the underlying map style by clicking
    the layer icon at top right).
  prefs: []
  type: TYPE_NORMAL
- en: Achieving these results required some coding gymnastics that would have been
    unnecessary if the data had arrived in a shapefile or in a typical SQL table.
    Nevertheless, it’s possible to extract meaningful insights from JSON data using
    PostgreSQL’s support for the format. In the last part of the chapter, we’ll cover
    useful PostgreSQL functions for generating and manipulating JSON.
  prefs: []
  type: TYPE_NORMAL
- en: '![f16002](Images/f16002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16-2: Viewing earthquakes near Tulsa, Oklahoma, in pgAdmin'
  prefs: []
  type: TYPE_NORMAL
- en: Generating and Manipulating JSON
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use PostgreSQL functions to create JSON from existing rows in a SQL table
    or to modify JSON stored in a table to add, subtract, or change keys and values.
    The PostgreSQL documentation at [https://www.postgresql.org/docs/current/functions-json.html](https://www.postgresql.org/docs/current/functions-json.html)
    lists several dozen JSON-related functions—we’ll work through a few you might
    find handy.
  prefs: []
  type: TYPE_NORMAL
- en: Turning Query Results into JSON
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because JSON is primarily a format for sharing data, it’s useful to be able
    to quickly convert the results of a SQL query into JSON for delivery to another
    computer system. [Listing 16-21](#listing16-21) uses the PostgreSQL-specific `to_json()`
    function to turn rows from the `employees` table you made in Chapter 7 into JSON.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-21: Turning query results into JSON with `to_json()`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `to_json()` function does what it says: transforms a supplied SQL value
    to JSON. To convert all values in each row of the `employees` table, we use `to_json()`
    in a `SELECT` 1 and supply the table name as the function’s argument; that returns
    each row as a JSON object with column names as keys:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: We can modify our query a few ways to limit which columns to include in the
    results. In [Listing 16-22](#listing16-22), we use a `row()` constructor as the
    argument for `to_json()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-22: Specifying columns to convert to JSON'
  prefs: []
  type: TYPE_NORMAL
- en: 'A `row()` constructor (which is ANSI SQL compliant) builds a row value from
    the arguments passed to it. In this case, we supply the column names `emp_id`
    and `last_name` 1 and place `row()` inside `to_json()`. This syntax returns just
    those columns in the JSON result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Notice, however, that the keys are named `f1` and `f2` instead of their source
    column names. That’s a side effect of `row()`, which doesn’t preserve column names
    when it builds the row record. We can set the names of the keys, which is often
    done to keep the names short and reduce JSON file size, improving transfer speeds.
    [Listing 16-23](#listing16-23) shows how via a subquery.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-23: Generating key names with a subquery'
  prefs: []
  type: TYPE_NORMAL
- en: We write a subquery 1 that grabs the columns we want and alias the result as
    `employees`. In the process, we alias a column name 2 to shorten its appearance
    as a key in the JSON.
  prefs: []
  type: TYPE_NORMAL
- en: 'The results should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Finally, [Listing 16-24](#listing16-24) shows how to compile all the rows of
    JSON into a single array of objects. You may want to do this if you’re providing
    this data to another application that will iterate over the array of objects to
    perform a task, such as a calculation, or to render data on a device.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-24: Aggregating the rows and converting to JSON'
  prefs: []
  type: TYPE_NORMAL
- en: 'We wrap `to_json()` in the PostgreSQL-specific `json_agg()` 1 function, which
    aggregates values, including `NULL`, into a JSON array. Its output should look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: These are simple examples, but you can build more complex JSON structures using
    subqueries to generate nested objects. We’ll consider one way to do that as part
    of our “Try It Yourself” exercises at the end of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Adding, Updating, and Deleting Keys and Values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can add to, update, and delete from JSON with a combination of concatenation
    and PostgreSQL-specific functions. Let’s work through some examples.
  prefs: []
  type: TYPE_NORMAL
- en: Adding or Updating a Top-Level Key/Value Pair
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In [Listing 16-25](#listing16-25), we return to our `films` table and add a
    top-level key/value pair `"studio": "Pixar"` to the film *The Incredibles* using
    two different techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-25: Adding a top-level key/value pair via concatenation'
  prefs: []
  type: TYPE_NORMAL
- en: Both examples use `UPDATE` statements to set new values for the `jsonb` column
    `film`. In the first, we use the PostgreSQL concatenation operator `||` 1 to combine
    the existing film JSON with the new key value/pair that we cast to `jsonb`. In
    the second, we use concatenation again but with `jsonb_build_object()`. This function
    takes a series of key and value names as arguments and returns a `jsonb` object,
    letting us concatenate several key/value pairs at a time if we wanted.
  prefs: []
  type: TYPE_NORMAL
- en: Both statements will insert the new key/value pair if the key doesn’t exist
    in the JSON being concatenated; it will overwrite a key that’s present. There’s
    no functional difference between the two statements, so feel free to use whichever
    you prefer. Note that this behavior is specific to `jsonb`, which doesn’t allow
    duplicate key names.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you `SELECT * FROM films;` and double-click the updated data in the `film`
    column, you should see the new key/value pair:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Updating a Value at a Path
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Currently we have two entries for the `genre` key for *Cinema Paradiso*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: To add a third entry to the array, we use the function `jsonb_set()`, which
    allows us to specify a value to update at a specific JSON path. In [Listing 16-26](#listing16-26),
    we use the `UPDATE` statement and `jsonb_set()` to add the genre `World War II`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-26: Adding an array value at a path with `jsonb_set()`'
  prefs: []
  type: TYPE_NORMAL
- en: In `UPDATE`, we `SET` the value of `film` to the result of `jsonb_set()` and
    use `WHERE` to limit the update to just the row with *Cinema Paradiso*. The function’s
    first argument 1 is the target JSON we want to modify, here `film`. The second
    argument is the path 2 to the array value—the `genre` key. Third, we give the
    new value for `genre`, which we specify as the current value of `genre` concatenated
    with an array 3 with one value, `"World War II"`. That concatenation will produce
    an array with three elements. The final argument is an optional Boolean value
    4 that dictates whether `jsonb_set()` should create the value if it’s not already
    present. It’s redundant here since `genre` already exists; I’ve shown it for reference.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the query and then perform a quick `SELECT` to check the updated JSON.
    You should see the `genre` array including three values: `["romance", "drama",
    "World War II"]`.'
  prefs: []
  type: TYPE_NORMAL
- en: Deleting a Value
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We can remove keys and values from a JSON object by pairing two operators. [Listing
    16-27](#listing16-27) shows two `UPDATE` examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-27: Deleting values from JSON'
  prefs: []
  type: TYPE_NORMAL
- en: The minus sign 1 acts as a *deletion operator*, removing the key `studio` and
    its value, which we added earlier for *The Incredibles*. Supplying a text string
    after the minus sign indicates we want to remove a key and its value; supplying
    an integer will remove the element at that index.
  prefs: []
  type: TYPE_NORMAL
- en: The `#-` 2 sign is a *path deletion operator* that removes the JSON element
    that exists at a path we specify. The syntax is similar to that of the path extraction
    operators `#>` and `#>>`. Here, we use `{genre, 2}` to indicate the third element
    of the array for `genre` (remember, JSON array indexes begin counting at zero).
    This will remove the value `World War II` that we added earlier to *Cinema Paradiso*.
  prefs: []
  type: TYPE_NORMAL
- en: Run both statements and then use `SELECT` to view the altered film JSON. You
    should see both elements removed.
  prefs: []
  type: TYPE_NORMAL
- en: Using JSON Processing Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To finish our JSON studies, we’ll review a selection of PostgreSQL-specific
    functions for processing JSON data, including expanding array values into table
    rows and formatting output. You can find a complete listing of functions in the
    PostgreSQL documentation at [https://www.postgresql.org/docs/current/functions-json.html](https://www.postgresql.org/docs/current/functions-json.html).
  prefs: []
  type: TYPE_NORMAL
- en: Finding the Length of an Array
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Counting the number of items in an array is a routine programming and analysis
    task. We might, for example, want to know how many actors are stored for each
    film in our JSON. To do this, we can use the `jsonb_array_length()` function in
    [Listing 16-28](#listing16-28).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-28: Finding the length of an array'
  prefs: []
  type: TYPE_NORMAL
- en: 'As its only argument, the function 1 takes an expression that extracts the
    value of the `character` key from `film`. Running the query should produce these
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: The output correctly shows that we have three characters for *The Incredibles*
    and two for *Cinema Paradiso*. Note there’s a similar `json_array_length()` function
    for the `json` type.
  prefs: []
  type: TYPE_NORMAL
- en: Returning Array Elements as Rows
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `jsonb_array_elements()` and `jsonb_array_elements_text()` functions convert
    array elements into rows, with one row per element. This is a useful tool for
    data processing. To convert JSON into structured SQL data, for example, we could
    use this function to generate the rows to `INSERT` into a table or to generate
    rows that we can aggregate by grouping and counting.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 16-29](#listing16-29) uses both functions to turn the `genre` key’s
    array values into rows. Each function takes a `jsonb` array as an argument. The
    difference between the two is that `jsonb_array_elements()` returns the array
    elements as rows of `jsonb` values, while `jsonb_array_elements_text()` returns
    elements as, you guessed it, `text`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-29: Returning array elements as rows'
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the code should produce these results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: On an array with a simple list of values, that works nicely, but if an array
    contains a collection of JSON objects with their own key/value pairs, like `character`
    in our `film` JSON, we need additional processing to unpack the values first.
    [Listing 16-30](#listing16-30) walks through the process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-30: Returning key values from each item in an array'
  prefs: []
  type: TYPE_NORMAL
- en: 'We use `jsonb_array_elements()` to return the elements of the `characters`
    1 array, which should return each JSON object in the array as a row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'To convert the `name` and `actor` values to columns, we employ a common table
    expression (CTE) as covered in Chapter 13. Our CTE 2 uses `jsonb_array_elements()`
    to generate a simple temporary `characters` table with two columns: the film’s
    `id` and the unpacked array values in a column called `json`. We follow with a
    `SELECT` statement 3 that queries the temporary table, extracting the values of
    `name` and `actor` from the `json` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Those values are neatly parsed into a standard SQL structure and suitable for
    further analysis using standard SQL.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: JSON is such a ubiquitous format that it’s likely you’ll encounter it often
    in your journey analyzing data. You’ve learned that PostgreSQL easily handles
    loading, indexing, and parsing JSON, but JSON sometimes requires extra steps to
    process that aren’t needed with data handled via standard SQL conventions. As
    with many areas of coding, your decision on whether to make use of JSON will depend
    on your specific circumstances. Now, you’re equipped to understand the context.
  prefs: []
  type: TYPE_NORMAL
- en: JSON itself is a standard, but the data types and the majority of functions
    and syntax in this chapter were PostgreSQL-specific. That’s because the ANSI SQL
    standard leaves it to database vendors to decide how to implement most JSON support.
    If your work involves using Microsoft SQL Server, MySQL, SQLite, or another system,
    consult their documentation. You’ll find many similarities in capabilities even
    if the function names differ.
  prefs: []
  type: TYPE_NORMAL
