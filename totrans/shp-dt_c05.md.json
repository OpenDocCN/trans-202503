["```\n#create data\na<-rbinom(5,4,0.2)\nb<-rbinom(5,1,0.5)\nc<-rbinom(5,2,0.1)\nmydata<-as.data.frame(cbind(a,b,c))\n\n#create plot\nlibrary(scatterplot3d)\nscatterplot3d(a,b,c,main=\"Scatterplot of 3-Dimensional Data\")\n```", "```\n> **mydata**\n  a b c\n1 2 1 0\n2 0 0 1\n3 1 0 0\n4 0 0 0\n5 3 0 0\n```", "```\n#run distance metrics on example dataset\nd1<-dist(mydata,\"euclidean\",upper=T,diag=T)\nd2<-dist(mydata,\"manhattan\",upper=T,diag=T)\nd3<-dist(mydata,\"canberra\",upper=T,diag=T)\nd4<-dist(mydata,\"minkowski\",p=1,upper=T,diag=T)\nd5<-dist(mydata,\"minkowski\",p=2,upper=T,diag=T)\nd6<-dist(mydata,\"minkowski\",p=10,upper=T,diag=T)\n```", "```\n#run Mahalanobis distance metrics\n#first use the covariance to center the data\nd7<-mahalanobis(mydata,center=F,cov=cov(mydata))\n\n#then center to one of the points of the data, in this case point 1\nd8<-mahalanobis(mydata,center=c(2,1,0),cov=cov(mydata))\n\n#then use the column means to center the data\nd9<-mahalanobis(mydata,center=colMeans(mydata),cov=cov(mydata))\n```", "```\n#add point to dataset created earlier in this section\ncolmean<-c(1.2,0.2,0.2)\nmydata<-rbind(mydata,colmean)\n\n#create plot\nlibrary(scatterplot3d)\nscatterplot3d(mydata[,1],mydata[,2],mydata[,3],\nmain=\"Scatterplot of 3-Dimensional Data\")\n```", "```\n#create samples from two different binomial probability distributions\na<-rbinom(1000,5,0.1)\nb<-rbinom(1000,5,0.4)\n\n#create plot of probability density\nplot(density(b),ylim=c(0,2),main=\"Comparison of Probability Distributions\")\nlines(density(a),col=\"blue\")\n```", "```\n#load package\nlibrary(philentropy)\n\n#calculate Kullback-Leibler divergence\nkullback_leibler_distance(P=a,Q=b,testNA=T,unit=\"log2\",epsilon=1e-05)\n```", "```\n#create a nonparametric test\n#create a vector to hold results from the simulation loop\ntest<-rep(NA,1000)\n\n#loop to draw from one of the binomial distributions to generate\n#a null distribution for one of our samples\nfor (i in 1:1000){\n  new<-rbinom(1000,5,0.1)\n  test[i]<-kullback_leibler_distance(P=a,Q=new,testNA=T,unit=\"log10\",epsilon=1e-05)\n}\n\n#obtain the cut-off score for 95% confidence intervals, corresponding\n#to values above/below which a sample would be considered statistically\n#different than the null distribution\nquantile(test,c(0.025,0.0975))\n```", "```\n#load package and time series contained in the TSdist package\nlibrary(TSdist)\ndata(example.series4)\ndata(example.series3)\nmy1<-example.series4\nmy2<-example.series3\n\n#plot both time series\nplot(my1,main=\"Time Series Plots of Series 4\")\nplot(my2,main=\"Time Series Plots of Series 3\")\n```", "```\n#calculate Frechet distance\ndis1<-FrechetDistance(my1,my2,FrechetSumOrMax=\"sum\")\ndis2<-FrechetDistance(my1,my2,FrechetSumOrMax=\"min\")\ndis3<-FrechetDistance(my1,my2,FrechetSumOrMax=\"max\")\n```", "```\n#create two-dimensional disc sample\na<-runif(100,min=-1,max=1)\nb<-runif(100,min=-1,max=1)\n\n#create circle from uniform distribution and restrict to points within the\n#circle\nd<-a^2+b^2\nw<-which(d>1)\nmydata<-cbind(a,b)\nmydata<-mydata[-w,-w]\n\n#plot sample\nplot(mydata,main=\"2-Dimensional Disc Sample\",ylab=\"y\",xlab=\"x\")\n```", "```\n#create a uniform sample from a line segment\nx<-sort(runif(dim(as.data.frame(mydata))[[1]],min=-1,max=1))\n```", "```\n#load the package and calculate the distance matrices for use in calculations\nlibrary(gromovlab)\nm1<-dist(as.matrix(mydata))\nm2<-dist(as.matrix(x))\n\n#calculate distance metric and compare distances with Gromov-Hausdorff\ngromovdist(m1,m2,\"lp\",p=2)\n```", "```\n#install package (and devtools if not installed)\n#your local computer might save the .tar file in a different path than ours\nlibrary(devtools)\ninstall_local(\"~/Downloads/knnGarden.tar\")\n\n#create data\na<-rbinom(500,4,0.2)\nb<-rbinom(500,1,0.5)\nc<-rbinom(500,2,0.1)\nd<-rbinom(500,2,0.2)\ne<-rbinom(500,1,0.3)\nf<-rbinom(500,1,0.8)\nclass<-a+e-d-rbinom(500,2,0.3)\nclass[class>=0]<-1\nclass[class<0]<-0\nmydata<-as.data.frame(cbind(a,b,c,d,e,f,class))\n\n#partition data into training and test sets (60% train, 40% test)\ns<-sample(1:500,300)\ntrain<-mydata[s,]\ntest<-mydata[-s,]\n\n#create KNN models with different distances and five nearest neighbors\nlibrary(knnGarden)\n\n#Euclidean\nke<-knnVCN(TrnX=train[,-7],OrigTrnG=train[,7],TstX=test[,-7],\nK=5,method=\"euclidean\")\naccke<-length(which(ke==test[,7]))/length(test[,7])\n\n#Canberra\nkc<-knnVCN(TrnX=train[,-7],OrigTrnG=train[,7],TstX=test[,-7],\nK=5,method=\"canberra\")\nacckc<-length(which(kc==test[,7]))/length(test[,7])\n\n#Manhattan\nkm<-knnVCN(TrnX=train[,-7],OrigTrnG=train[,7],TstX=test[,-7],\nK=5,method=\"manhattan\")\nacckm<-length(which(km==test[,7]))/length(test[,7])\n```", "```\n#create KNN models with different distance metrics and 20 nearest neighbors\n\n#Euclidean\nke<-knnVCN(TrnX=train[,-7],OrigTrnG=train[,7],TstX=test[,-7],\n**K=20**,method=\"euclidean\")\naccke<-length(which(ke==test[,7]))/length(test[,7])\n\n#Canberra\nkc<-knnVCN(TrnX=train[,-7],OrigTrnG=train[,7],TstX=test[,-7],\n**K=20**,method=\"canberra\")\nacckc<-length(which(kc==test[,7]))/length(test[,7])\n\n#Manhattan\nkm<-knnVCN(TrnX=train[,-7],OrigTrnG=train[,7],TstX=test[,-7],\n**K=20**,method=\"manhattan\")\nacckm<-length(which(km==test[,7]))/length(test[,7])\n```", "```\n#create data\na<-rbinom(100,4,0.2)\nb<-rbinom(100,1,0.5)\nc<-rbinom(100,2,0.1)\nd<-rbinom(100,2,0.2)\ne<-rbinom(100,1,0.3)\nf<-rbinom(100,1,0.8)\nmydata<-as.data.frame(cbind(a,b,c,d,e,f))\n\n#create distance matrices using different distance metrics\nm1<-dist(mydata,upper=T,diag=T)\nm2<-dist(mydata,\"minkowski\",p=10,upper=T,diag=T) \nm3<-dist(mydata,\"manhattan\",upper=T,diag=T)\n```", "```\n#reduce dimensionality with MDS to two dimensions\nc1<-cmdscale(m1,k=2)\nc2<-cmdscale(m2,k=2)\nc3<-cmdscale(m3,k=2)\n\n#plot results\nplot(c1,xlab=\"Coordinate 1\",ylab=\"Coordinate 2\",\nmain=\"Euclidean Distance MDS Results\")\nplot(c2,xlab=\"Coordinate 1\",ylab=\"Coordinate 2\",\nmain=\"Minkowski p=10 Distance MDS Results\")\nplot(c3,xlab=\"Coordinate 1\",ylab=\"Coordinate 2\",\nmain=\"Manhattan Distance MDS Results\")\n```", "```\n#create Isomap projections of the data generated in [Listing 5-6](#listing5-6)\nlibrary(vegan)\n\ni1<-scores(isomap(dist(mydata),ndim=2,k=5))\ni2<-scores(isomap(dist(mydata),ndim=2,k=10))\ni3<-scores(isomap(dist(mydata),ndim=2,k=20))\n\n#plot results\nplot(i1,xlab=\"Coordinate 1\",ylab=\"Coordinate 2\",main=\"K=5 Isomap Results\")\nplot(i2,xlab=\"Coordinate 1\",ylab=\"Coordinate 2\",main=\"K=10 Isomap Results\")\nplot(i3,xlab=\"Coordinate 1\",ylab=\"Coordinate 2\",main=\"K=20 Isomap Results\")\n```", "```\n#install package\nlibrary(devtools)\ninstall_local(\"~/Downloads/lle.tar\")\n\n#create LLE projections of the data generated in [Listing 5-6](#listing5-6)\nlibrary(lle)\n\nl1<-lle(mydata,m=2,k=5)\nl2<-lle(mydata,m=2,k=10)\nl3<-lle(mydata,m=2,k=20)\n\n#plot results\nplot(l1$Y,xlab=\"Coordinate 1\",ylab=\"Coordinate 2\",main=\"K=5 LLE Results\")\nplot(l2$Y,xlab=\"Coordinate 1\",ylab=\"Coordinate 2\",main=\"K=10 LLE Results\")\nplot(l3$Y,xlab=\"Coordinate 1\",ylab=\"Coordinate 2\",main=\"K=20 LLE Results\")\n```", "```\n#create t-SNE projections of the data generated in [Listing 5-7](#listing5-7)\nlibrary(Rtsne)\nlibrary(dimRed)\n\nt1<-getDimRedData(embed(mydata,\"tSNE\",ndim=2,perplexity=5))\nt2<-getDimRedData(embed(mydata,\"tSNE\",ndim=2,perplexity=15))\nt3<-getDimRedData(embed(mydata,\"tSNE\",ndim=2,perplexity=25))\n\n#plot results\nplot(as.data.frame(t1),xlab=\"Coordinate 1\",ylab=\"Coordinate2\",\nmain=\"Perplexity=5 t-SNE Results\")\nplot(as.data.frame(t2),xlab=\"Coordinate 1\",ylab=\"Coordinate2\",\nmain=\"Perplexity=15 t-SNE Results\")\nplot(as.data.frame(t3),xlab=\"Coordinate 1\",ylab=\"Coordinate2\",\nmain=\"Perplexity=25 t-SNE Results\")\n```", "```\n#load and parse stock market data\nstocks<-read.csv(\"Example_Stock_Data.csv\")\nJune2019<-stocks[stocks$Month==\"June\",]\nJuly2019<-stocks[stocks$Month==\"July\",]\nAugust2019<-stocks[stocks$Month==\"August\",]\nSeptember2019<-stocks[stocks$Month==\"September\",]\nOctober2019<-stocks[stocks$Month==\"October\",]\nNovember2019<-stocks[stocks$Month==\"November\",]\nDecember2019<-stocks[stocks$Month==\"December\",]\nJanuary2020<-stocks[stocks$Month==\"January\",]\nFebruary2020<-stocks[stocks$Month==\"February\",]\nMarch2020<-stocks[stocks$Month==\"March\",]\nApril2020<-stocks[stocks$Month==\"April\",]\nMay2020<-stocks[stocks$Month==\"May\",]\n\n#calculate fractal dimension for each series\nlibrary(fractaldim)\njunedim<-fd.estimate(June2019[,2],methods=\"hallwood\")$fd\njulydim<-fd.estimate(July2019[,2],methods=\"hallwood\")$fd\naugustdim<-fd.estimate(August2019[,2],methods=\"hallwood\")$fd\nseptemberdim<-fd.estimate(September2019[,2],methods=\"hallwood\")$fd\noctoberdim<-fd.estimate(October2019[,2],methods=\"hallwood\")$fd\nnovemberdim<-fd.estimate(November2019[,2],methods=\"hallwood\")$fd\ndecemberdim<-fd.estimate(December2019[,2],methods=\"hallwood\")$fd\njanuarydim<-fd.estimate(January2020[,2],methods=\"hallwood\")$fd\nfebruarydim<-fd.estimate(February2020[,2],methods=\"hallwood\")$fd\nmarchdim<-fd.estimate(March2020[,2],methods=\"hallwood\")$fd\naprildim<-fd.estimate(April2020[,2],methods=\"hallwood\")$fd\nmaydim<-fd.estimate(May2020[,2],methods=\"hallwood\")$fd\n\n#combine fractal dimension results into a vector\nmonthlyfd<-c(junedim,julydim,augustdim,septemberdim,octoberdim,novemberdim,\ndecemberdim,januarydim,februarydim,marchdim,aprildim,maydim)\n\n#examine monthly stock price range\nmonthlymax<-c(max(June2019[,2]),max(July2019[,2]),max(August2019[,2]),\nmax(September2019[,2]),max(October2019[,2]),max(November2019[,2]),\nmax(December2019[,2]),max(January2020[,2]),max(February2020[,2]),\nmax(March2020[,2]),max(April2020[,2]),max(May2020[,2]))\n\nmonthlymin<-c(min(June2019[,2]),min(July2019[,2]),min(August2019[,2]),\nmin(September2019[,2]),min(October2019[,2]),min(November2019[,2]),\nmin(December2019[,2]),min(January2020[,2]),min(February2020[,2]),\nmin(March2020[,2]),min(April2020[,2]),min(May2020[,2]))\n\nmonthlyrange<-monthlymax-monthlymin\n\n#examine relationship between monthly fractal dimension and monthly range\ncor.test(monthlyfd,monthlyrange,\"greater\")\n```"]