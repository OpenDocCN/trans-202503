- en: '## **20'
  prefs: []
  type: TYPE_NORMAL
- en: COMPILER VARIATIONS**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](Images/com.jpg)'
  prefs: []
  type: TYPE_IMG
- en: At this point, if we have done our job properly, you now possess the essential
    skills to use Ghidra effectively and, more importantly, to bend it to your will.
    The next step is to learn to adapt to the challenges that binaries (as opposed
    to Ghidra) will throw at you. Depending on your motives for staring at assembly
    language, either you may be very familiar with what you are looking at or you
    may never know what you are going to be faced with. If you spend all of your time
    examining code that was compiled using `gcc` on a Linux platform, you’ll become
    quite familiar with the style of code that it generates, but you may be baffled
    by a debug version of a program compiled using the Microsoft C/C++ compiler. If
    you are a malware analyst, you may see code created using `gcc`, clang, Microsoft's
    C++ compiler, Delphi, and others, all in the same afternoon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like you, Ghidra is more familiar with the output of some compilers than other
    compilers, and familiarity with code generated by one compiler in no way guarantees
    that you will recognize high-level constructs compiled using an entirely different
    compiler (or even different versions of the same compiler family). Rather than
    relying entirely on Ghidra’s analysis capabilities to recognize commonly used
    code and data constructs, you should always be prepared to utilize your own skills:
    your familiarity with a given assembly language, your knowledge of compilers,
    and your research skills to properly interpret a disassembly.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we cover some of the ways that compiler differences manifest
    themselves in disassembly listings. We primarily use compiled C code for our examples,
    as the variability of C compilers and target platforms provides foundational concepts
    that can be extended to other compiled languages.
  prefs: []
  type: TYPE_NORMAL
- en: '**High-Level Constructs**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In some cases, the differences between compilers may just be cosmetic, but in
    other cases, they are much more significant. In this section, we look at high-level
    language constructs and demonstrate how different compilers and compiler options
    may significantly impact the resulting disassembly listing. We begin with `switch`
    statements and the two mechanisms most commonly employed to resolve `switch` case
    selection. Following that, we look at the way that compiler options affect code
    generation for common expressions before moving on to discuss how different compilers
    implement C++-specific constructs and handle program startup.
  prefs: []
  type: TYPE_NORMAL
- en: '***switch Statements***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The C `switch` statement is a frequent target for compiler optimizations. The
    goal of these optimizations is to match the `switch` variable to a valid case
    label in the most efficient manner possible, but the distribution of the `switch`
    statement’s case labels constrains the type of search that can be used.
  prefs: []
  type: TYPE_NORMAL
- en: Since the efficiency of a search is measured by the number of comparisons required
    to find the correct case, we can trace the logic a compiler might use to determine
    the best way to represent a `switch` table. A constant time algorithm, such as
    a table lookup, is the most efficient.^([1](footnotes.xhtml#ch20fn1)) At the other
    end of the continuum is linear search, which, in the worst case, requires comparing
    the `switch` variable against every case label before finding a match or resolving
    to the default and thus is the least efficient.^([2](footnotes.xhtml#ch20fn2))
    The efficiency of a binary search is much better, on average, than linear search
    but introduces additional constraints, as it requires a sorted list.^([3](footnotes.xhtml#ch20fn3))
  prefs: []
  type: TYPE_NORMAL
- en: In order to select the most efficient implementation for a particular `switch`
    statement, it helps to understand how the case label distribution affects the
    compiler’s decision-making process. When case labels are closely clustered, as
    in the source code in [Listing 20-1](ch20.xhtml#exa20_1), compilers generally
    resolve the `switch` variable by performing a table lookup to match the `switch`
    variable to the address of its associated case—specifically by using a jump table.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 20-1: A* `switch` *statement with consecutive case labels*'
  prefs: []
  type: TYPE_NORMAL
- en: 'A *jump table* is an array of pointers, with each pointer in the array referencing
    a possible jump target. At runtime, a dynamic index into the table chooses one
    of the many potential jumps each time the jump table is referenced. Jump tables
    work well when `switch` case labels are closely spaced (dense), with most of the
    cases falling into a consecutive number sequence. Compilers take this into account
    when deciding whether to utilize a jump table. For any `switch` statement, we
    can compute the minimum number of entries an associated jump table will contain
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The *density*, or utilization rate, of the jump tables can then be computed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'A completely contiguous list with every value represented would have a density
    value of 100 percent (1.0). Finally, the total amount of space required to store
    the jump table is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'A `switch` statement with 100 percent density will be implemented using a jump
    table. A set of cases with a density of 30 percent might not be implemented using
    a jump table, since jump table entries would still need to be allocated for the
    absent cases, which would be 70 percent of the jump table. If `num_entries` is
    30, the jump table would contain entries for 21 unreferenced case labels. On a
    64-bit system, this is 168 of the 240 bytes allocated to the table, which is not
    a lot of overhead, but if `num_entries` jumps to 300, then the overhead becomes
    1680 bytes, which may not be worth the trade-off for 90 possible cases. A compiler
    that is optimizing for speed may favor jump table implementations, while a compiler
    that is optimizing for size may choose an alternative implementation with lower
    memory overhead: binary search.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Binary search* is efficient when the case labels are widely spread (low density),
    as seen in [Listing 20-2](ch20.xhtml#exa20_2) (density 0.0008).^([4](footnotes.xhtml#ch20fn4))
    Because binary search works only on sorted lists, the compiler must ensure that
    the case labels are ordered before it begins the search with the median value.
    This may result in the reordering of case blocks when viewed in a disassembly,
    as compared to the order they appear in the corresponding source.^([5](footnotes.xhtml#ch20fn5))'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 20-2: Sample* `switch` *statement with nonconsecutive case labels*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 20-3](ch20.xhtml#exa20_3) shows an outline for a non-iterative binary
    search through a fixed number of constant values. This is the rough framework
    that the compiler uses to implement the `switch` from [Listing 20-2](ch20.xhtml#exa20_2).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 20-3: Non-iterative binary search through a fixed number of constant
    values*'
  prefs: []
  type: TYPE_NORMAL
- en: Compilers are also capable of performing more fine-grained optimizations across
    a range of case labels. For example, when confronted with the case labels
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: a less aggressive compiler might see a density of 0.0015 here and generate a
    binary search through all 15 cases. A more aggressive compiler might emit a jump
    table to resolve cases 1 to 8, and a binary search for the remaining cases, achieving
    optimal performance for over half of the cases.
  prefs: []
  type: TYPE_NORMAL
- en: Before we look at the disassembled versions of [Listings 20-1](ch20.xhtml#exa20_1)
    and [20-2](ch20.xhtml#exa20_2), let’s look at the Ghidra Function Graph windows
    corresponding to the listings, shown side by side in [Figure 20-1](ch20.xhtml#fig20_1).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig20-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-1: Ghidra Function Graph* `switch` *statement examples*'
  prefs: []
  type: TYPE_NORMAL
- en: On the left, the graph for [Listing 20-1](ch20.xhtml#exa20_1) shows a nice vertical
    stack of cases. Each stacked code block resides at the same nesting depth, as
    is true for cases in a `switch` statement. The stack suggests that we can use
    an index to quickly select one block from the many (think array access). This
    is precisely how jump table resolution works, and the left-hand graph provides
    us with a visual hint that this is the case, even before we have looked at a single
    line of the disassembly.
  prefs: []
  type: TYPE_NORMAL
- en: The right-hand graph is Ghidra’s result based solely on its understanding of
    the disassembly of [Listing 20-2](ch20.xhtml#exa20_2). The lack of a jump table
    makes it much more challenging to identify this as a `switch` statement. What
    you are seeing is a visual representation of the `switch` statement using Ghidra’s
    Nested Code Layout. This is the default layout for function graphs in Ghidra and
    is intended to represent the flow structures in a program. The horizontal branching
    in this graph suggests conditional execution (`if`/`else`) branching to mutually
    exclusive alternatives. The vertical symmetry suggests that the alternative execution
    paths have been very carefully balanced to place equal numbers of blocks in each
    vertical half of the graph. Finally, the distance that the graph traverses horizontally
    is an indicator of the depth reached by the search, which in turn is dictated
    by the total number of case labels present in the `switch`. For a binary search,
    this depth will always be on the order of `log[2]``(num_cases)`. The similarity
    between the indentation of the graphical representation and the algorithm outlined
    in [Listing 20-3](ch20.xhtml#exa20_3) is easily observable.
  prefs: []
  type: TYPE_NORMAL
- en: Turning our attention to the Decompiler window, [Figure 20-2](ch20.xhtml#fig20_2)
    shows the partial decompilation of the functions displayed in [Figure 20-1](ch20.xhtml#fig20_1).
    On the left is the decompiled version of [Listing 20-1](ch20.xhtml#exa20_1). As
    with the graph, the presence of a jump table in the binary helps Ghidra identify
    the code as a `switch` statement.
  prefs: []
  type: TYPE_NORMAL
- en: On the right is the decompiled version of [Listing 20-2](ch20.xhtml#exa20_2).
    The decompiler has presented the `switch` statement as a nested `if`/`else` structure
    consistent with a binary search, and similar in structure to [Listing 20-3](ch20.xhtml#exa20_3).
    You can see that first comparison is against 719, the median value in the list,
    and that subsequent comparisons continue to divide the search space in half. Referring
    to [Figure 20-1](ch20.xhtml#fig20_1) (as well as [Listing 20-3](ch20.xhtml#exa20_3)),
    we can again observe that the graphical representations of each function closely
    correspond to the indentation patterns observed in the Decompiler window.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have an idea of what is happening from a high level, let’s look
    inside the binaries and investigate what is happening at a low level. Since our
    objective in this chapter is to observe differences between compilers, we present
    this example as a series of comparisons between two compilers, `gcc` and Microsoft
    C/C++.^([6](footnotes.xhtml#ch20fn6))
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig20-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-2: Ghidra decompiled* `switch` *statement examples*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Example: Comparing gcc with Microsoft C/C++ Compiler***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this example, we compare two 32-bit x86 binaries generated for [Listing
    20-1](ch20.xhtml#exa20_1) by two distinct compilers. We will attempt to identify
    components of a `switch` statement in each binary, locate the associated jump
    table in each binary, and point out significant differences between the two binaries.
    Let’s start by looking at the `switch`-related components for [Listing 20-1](ch20.xhtml#exa20_1)
    in the binary built with `gcc`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Ghidra recognizes the switch bounds test ➊, the jump table ➍, and individual
    case blocks by value, such as the one at `switchD_00010771::caseD_1` ➌. The compiler
    generated a jump table with 13 entries, although [Listing 20-1](ch20.xhtml#exa20_1)
    contained only 12 cases. The additional case, case 0 (the first entry ➎ in the
    jump table), shares a target address with every value outside the range 1 to 12\.
    In other words, case 0 is part of the default case. While it may seem that negative
    numbers are being excluded from the default, the `CMP,` `JA` sequence works as
    a comparison on unsigned values; thus, `-1` (`0xFFFFFFFF`) would be seen as `4294967295`,
    which is much larger than 12 and therefore excluded from the valid range for indexing
    the jump table. The `JA` instruction directs all such cases to the default location:
    `switchD_00010771::caseD_0` ➋.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we understand the basic components of the code generated by the `gcc`
    compiler, let’s shift our focus to the same components in code generated by the
    Microsoft C/C++ compiler in debug mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Here, the `switch` variable (`local_d4` in this case) is decremented ➊ to shift
    the range of valid values from 0 to 11 ➋, eliminating the need for a dummy table
    entry for the value 0\. As a result, the first entry (or 0 index entry) in the
    jump table ➌ actually refers to the code for switch case 1.
  prefs: []
  type: TYPE_NORMAL
- en: Another, perhaps more subtle difference between the two listings is the location
    of the jump table within the file. The `gcc` compiler places switch jump tables
    in the read-only data (`.rodata`) section of the binary, providing a logical separation
    between the code associated with the `switch` statement and the data required
    to implement the jump table. The Microsoft C/C++ compiler, on the other hand,
    inserts jump tables into the `.text` section, immediately following the function
    containing the associated `switch` statement. Positioning the jump table in this
    manner has little effect on the behavior of the program. In this example, Ghidra
    is able to recognize the `switch` statements for both compilers and uses the term
    `switch` within the associated labels.
  prefs: []
  type: TYPE_NORMAL
- en: One of the key points here is that there is no single correct way to compile
    source to assembly. As a result, you cannot assume that something is not a `switch`
    statement simply because Ghidra fails to label it as such. Understanding the `switch`
    statement characteristics that factor into the compiler implementation can help
    you make a more accurate inference about the original source code.
  prefs: []
  type: TYPE_NORMAL
- en: '**Compiler Build Options**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A compiler converts high-level code that solves a particular problem into low-level
    code that solves the same problem. Multiple compilers may solve the same problem
    in rather different ways. Further, a single compiler may solve a problem very
    differently based on the associated compiler options. In this section, we look
    at the assembly language code that results from using different compilers and
    different command line options. (Some differences will have a clear explanation;
    others will not.)
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft’s Visual Studio can build either debug or release versions of program
    binaries.^([7](footnotes.xhtml#ch20fn7)) To see how the two versions are different,
    compare the build options specified for each. Release versions are generally optimized,
    while debug versions are not, and debug versions are linked with additional symbol
    information and debugging versions of the runtime library, while release versions
    are not.^([8](footnotes.xhtml#ch20fn8)) Debugging-related symbols allow debuggers
    to map assembly language statements back to their source code counterparts and
    to determine the names of local variables (such information is otherwise lost
    during the compilation process). The debugging versions of Microsoft’s runtime
    libraries have also been compiled with debugging symbols included, optimizations
    disabled, and additional safety checks enabled to verify that some function parameters
    are valid.
  prefs: []
  type: TYPE_NORMAL
- en: When disassembled using Ghidra, debug builds of Visual Studio projects look
    significantly different from release builds. This is a result of compiler and
    linker options specified only in debug builds, such as basic runtime checks (`/RTCx`),
    which introduce extra code into the resulting binary.^([9](footnotes.xhtml#ch20fn9))
    Let’s jump right in and look at some of these differences in disassemblies.
  prefs: []
  type: TYPE_NORMAL
- en: '***Example 1: Modulo Operator***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We begin our examples with a simple mathematical operation, modulo. The following
    listing contains the source code for a program whose only goal is to accept an
    integer value from the user and demonstrate integer division and the modulo operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Let’s investigate how the disassembly varies across compilers for the modulo
    operator in this example.
  prefs: []
  type: TYPE_NORMAL
- en: '##### **Modulo with Microsoft C/C++ Win x64 Debug**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following listing shows the code that Visual Studio generates when configured
    to build a debug version of the binary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: A straightforward x86 `IDIV` instruction ➊ leaves the quotient in `EAX` and
    the remainder of the division in `EDX`. The result is then moved to lower 32 bits
    of `R8` (`R8D`) ➋, which is the third argument in the call to `printf`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Modulo with Microsoft C/C++ Win x64 Release**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Release builds optimize software for speed and size in order to enhance performance
    and minimize storage requirements. When optimizing for speed, compiler writers
    may resort to non-obvious implementations of common operations. The following
    listing shows us how Visual Studio generates the same modulo operation in a release
    binary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In this case, multiplication ➊ is used rather than division, and after a long
    sequence of arithmetic operations, what must be the result of the modulo operation
    ends up in `R8D` ➋ (again the third argument in the call to `printf` ➌). Intuitive,
    right? An explanation of this code follows our next example.
  prefs: []
  type: TYPE_NORMAL
- en: '**Modulo with gcc for Linux x64**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We’ve seen how differently one compiler can behave simply by changing the compile-time
    options used to generate a binary. We might expect that a completely unrelated
    compiler would generate entirely different code yet again. The following disassembly
    shows us the `gcc` version of the same modulus operation, and it turns out to
    look somewhat familiar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The code is very similar to the assembly produced by the Visual Studio release
    version. We again see multiplication ➊ rather than division followed by a sequence
    of arithmetic operations that eventually leaves the result in `EDX` ➋ (where it
    is eventually used as the third argument to `printf`).
  prefs: []
  type: TYPE_NORMAL
- en: The code is using a multiplicative inverse to perform division by multiplying
    because hardware multiplication is faster than hardware division. You may also
    see multiplication implemented using a series of additions and arithmetic shifts,
    as each of these operations is significantly faster in hardware than multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: Your ability to recognize this code as modulo 10 depends on your experience,
    patience, and creativity. If you’ve seen similar code sequences in the past, you
    are probably more apt to recognize what’s taking place here. Lacking that experience,
    you might instead work through the code manually with sample values, hoping to
    recognize a pattern in the results. You might even take the time to extract the
    assembly language, wrap it in a C test harness, and do some high-speed data generation
    to assist you. Ghidra’s decompiler can be another useful resource for reducing
    complex or unusual code sequences to their more recognizable C equivalents.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a last resort, or first resort (don’t be ashamed), you might turn to the
    internet for answers. But what should you be searching for? Usually, unique, specific
    searches yield the most relevant results, and the most unique feature in the sequence
    of code is the integer constant `0x66666667`. When we searched for this constant,
    the top three results were all helpful, but one in particular was worth bookmarking:
    *[http://flaviojslab.blogspot.com/2008/02/integer-division.html](http://flaviojslab.blogspot.com/2008/02/integer-division.html)*.
    Unique constants are also used rather frequently in cryptographic algorithms,
    and a quick internet search may be all it takes to identify exactly what crypto
    routine you are staring at.'
  prefs: []
  type: TYPE_NORMAL
- en: '#### ***Example 2: The Ternary Operator***'
  prefs: []
  type: TYPE_NORMAL
- en: 'The ternary operator evaluates an expression and then yields one of two possible
    results, depending on the boolean value of that expression. Conceptually, the
    ternary operator can be thought of as an `if`/`else` statement (and can even be
    replaced with an `if`/`else` statement). The following intentionally unoptimized
    source code demonstrates the use of this operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*The volatile keyword asks the compiler not to optimize code involving the
    associated variables. Without its use here, some compilers will optimize away
    the entire body of this function since none of the statements contribute to the
    function’s result. This is one of the challenges you might face when coding examples
    for yourself or for others.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the behavior of the unoptimized code, the assignment into variable `z`
    ➊ could be replaced with the following `if`/`else` statement without changing
    the semantics of the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see how the ternary operator code is handled by different compilers and
    different compiler options.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ternary Operator with gcc on Linux x64**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`gcc`, with no options, generated the following assembly for the initialization
    of `z`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This code uses the `if`/`else` implementation. Local variable `y` is compared
    to `30` ➊ to decide whether to set `EAX` to `0` or `0xffffffff` in opposing branches
    of the `if`/`else` before assigning the result into `z` ➋.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ternary Operator with Microsoft C/C++ Win x64 Release**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Visual Studio yields a very different implementation of the statement containing
    the ternary operator. Here, the compiler recognizes that a single instruction
    can be used to conditionally generate either `0` or `-1` (and no other possible
    value) and uses this instruction in lieu of the `if`/`else` construct we saw earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `SBB` instruction ➌ (*subtract with borrow*) subtracts the second operand
    from the first operand and then subtracts the carry flag, `CF` (which can be only
    0 or 1). The equivalent arithmetic expression to `SBB EAX,EAX` is `EAX – EAX –
    CF`, which reduces to `0 – CF`. This, in turn, can result only in `0` (when `CF
    == 0`) or `-1` (when `CF == 1`). For this trick to work, the compiler must set
    the carry properly prior to executing the `SBB` instruction. This is accomplished
    by comparing `EAX` to the constant `0x1e` (`30`) ➊ using a subtraction that leaves
    `EAX` equal to `0` only when `EAX` was initially `0x1e`. The `NEG` instruction
    ➋ then sets the carry flag for the `SBB` instruction that follows.^([10](footnotes.xhtml#ch20fn10))
  prefs: []
  type: TYPE_NORMAL
- en: '**Ternary Operator with gcc on Linux x64 (Optimized)**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'When we ask `gcc` to try a little harder by optimizing its code (`-O2`), the
    result is not unlike the Visual Studio code in the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In this case, `gcc` uses `SETNZ` ➊ to conditionally set the `AL` register to
    either 0 or 1 based on the state of the zero flag resulting from the preceding
    comparison. The result is then negated ➋ to become either `0` or `-1` before assignment
    into variable `z` ➌.
  prefs: []
  type: TYPE_NORMAL
- en: '#### ***Example 3: Function Inlining***'
  prefs: []
  type: TYPE_NORMAL
- en: When a programmer marks a function `inline`, they are suggesting to the compiler
    that any calls to the function should be replaced with a copy of the entire function
    body. The intent is to speed up the function call by eliminating parameter and
    stack frame setup and teardown. The trade-off is that many copies of an inlined
    function make the binary larger. Inlined functions can be very difficult to recognize
    in binaries because the distinctive `call` instruction is eliminated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Even when the `inline` keyword has not been used, compilers may elect to inline
    a function on their own initiative. In our third example, we are making a call
    to the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '**Function Call with gcc on Linux x86**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'After building a Linux x86 binary using `gcc` with no optimizations, we disassemble
    it to see the following listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We can clearly see the call ➊ to the `maybe_inline` function in this disassembly,
    even though it is just a single line of code returning a constant value.
  prefs: []
  type: TYPE_NORMAL
- en: '**Optimized Function Call with gcc on Linux x86**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Next, we look at an optimized (`-O2`) version of the same source code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Contrasting this code with the unoptimized code, we see that the call to `maybe_inline`
    has been eliminated, and the constant value ➊ returned by `maybe_inline` is pushed
    directly onto the stack to be used as an argument for the call to `printf`. This
    optimized version of the function call is identical to what you would see if the
    function had been designated inline.
  prefs: []
  type: TYPE_NORMAL
- en: Having examined some of the ways that optimizations can influence the code generated
    by compilers, let’s turn our attention to the different ways that compiler designers
    choose to implement language-specific features when language designers leave implementation
    details to the compiler writers.
  prefs: []
  type: TYPE_NORMAL
- en: '**Compiler-Specific C++ Implementation**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Programming languages are designed by programmers for programmers. Once the
    dust of the design process has settled, it’s up to compiler writers to build the
    tools that faithfully translate programs written in the new high-level language
    into semantically equivalent machine language programs. When a language permits
    a programmer to do A, B, and C, it’s up to the compiler writers to find a way
    to make these things possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'C++ gives us three excellent examples of behaviors required by the language,
    but whose implementation details were left to the compiler writer to sort out:'
  prefs: []
  type: TYPE_NORMAL
- en: Within a nonstatic member function of a class, programmers may refer to a variable
    named `this`, which is never explicitly declared anywhere. (See [Chapters 6](ch06.xhtml#ch06)
    and [8](ch08.xhtml#ch08) for compilers’ treatment of `this`.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Function overloading is allowed. Programmers are free to reuse function names
    as often as they like, subject to restrictions on their parameter lists.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type introspection is supported through the use of the `dynamic_cast` and `typeid`
    operators.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Function Overloading***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Function overloading in C++ allows programmers to name functions identically,
    with the caveat that any two functions that share a name must have different parameter
    sequences. Name mangling, introduced in [Chapter 8](ch08.xhtml#ch08), is the under-the-hood
    mechanism that allows overloading to work by ensuring that no two symbols share
    the same name by the time the linker is asked to do its job.
  prefs: []
  type: TYPE_NORMAL
- en: 'Often, one of the earliest signs that you are working with a C++ binary is
    the presence of mangled names. The two most popular name mangling schemes are
    Microsoft’s and the Intel Itanium ABI.^([11](footnotes.xhtml#ch20fn11)) The Intel
    standard has been widely adopted by other Unix compilers such as `g++` and clang.
    The following shows a C++ function name and the mangled version of that name under
    both the Microsoft and Intel schemes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Function** `void SubClass::vfunc1()`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Microsoft scheme** `?vfunc1@SubClass@@UAEXXZ`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Intel scheme** `_ZN8SubClass6vfunc1Ev`'
  prefs: []
  type: TYPE_NORMAL
- en: Most languages that permit overloading, including Objective-C, Swift, and Rust,
    incorporate some form of name mangling at the implementation level. A passing
    familiarity with name-mangling styles can provide you with clues about a program’s
    original source language as well as the compiler used to build the program.
  prefs: []
  type: TYPE_NORMAL
- en: '***RTTI Implementations***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In [Chapter 8](ch08.xhtml#ch08), we discussed C++ Runtime Type Identification
    (RTTI) and the lack of a standard for implementing RTTI by a compiler. In fact,
    runtime type identification is not mentioned anywhere in the C++ standard, so
    it should be no surprise that implementations differ. To support the `dynamic_cast`
    operator, RTTI data structures record not only a class’s name, but its entire
    inheritance hierarchy, including any multiple inheritance relationships. Locating
    RTTI data structures can be extremely useful in recovering the object model of
    a program. Automatic recognition of RTTI-related constructs within a binary is
    another area in which Ghidra’s capabilities vary across compilers.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft C++ programs contain no embedded symbol information, but Microsoft’s
    RTTI data structures are well understood, and Ghidra will locate them when present.
    Any RTTI-related information Ghidra does locate will be summarized in the Symbol
    Tree’s *Classes* folder, which will contain an entry for each class that Ghidra
    locates using its RTTI analyzer.
  prefs: []
  type: TYPE_NORMAL
- en: Programs built with `g++` include symbol table information unless they have
    been stripped. For unstripped `g++` binaries, Ghidra relies exclusively on the
    mangled names it finds in the binary, and it uses those names to identify RTTI-related
    data structures and the classes they are associated with. As with Microsoft binaries,
    any RTTI-related information will be included in the Symbol Tree’s *Classes* folder.
  prefs: []
  type: TYPE_NORMAL
- en: One strategy for understanding how a specific compiler embeds type information
    for C++ classes is to write a simple program that uses classes containing virtual
    functions. After compiling the program, you can load the resulting executable
    into Ghidra and search for instances of strings that contain the names of classes
    used in the program. Regardless of the compiler used to build a binary, one thing
    that RTTI data structures have in common is that they all reference, in some manner,
    a string containing the mangled name of the class that they represent. Using extracted
    strings and data cross-references, it should be possible to locate candidate RTTI-related
    data structures within the binary. The last step is to link a candidate RTTI structure
    back to the associated class’s vftable, which is best accomplished by following
    data cross-references backward from the candidate RTTI structure until a table
    of function pointers (the vftable) is reached. Let’s walk through an example that
    uses this method.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example: Locating RTTI Information in a Linux x86-64 g++ Binary**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'To demonstrate these concepts, we created a small program with a `BaseClass`,
    a `SubClass`, a `SubSubClass`, and a collection of virtual functions unique to
    each. The following listing shows part of the main program we used to reference
    our classes and functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We compiled the program using `g++` to build a 64-bit Linux binary with symbols.
    After we analyze the program, the Symbol Tree provides the information shown in
    [Figure 20-3](ch20.xhtml#fig20_3).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig20-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-3: Symbol Tree classes for an unstripped binary*'
  prefs: []
  type: TYPE_NORMAL
- en: The *Classes* folder contains entries for all three of our classes. The expanded
    *SubClass* entry reveals additional information that Ghidra has uncovered about
    it. The stripped version of the same binary contains a lot less information, as
    shown in [Figure 20-4](ch20.xhtml#fig20_4).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig20-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-4: Symbol Tree classes for a stripped binary*'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we might, incorrectly, assume that the binary contains no C++
    classes of interest, although it is likely a C++ binary based on the reference
    to a core C++ class (`basic_ostream`). Since stripping removes only symbol information,
    we may still be able to find RTTI information by searching for class names in
    the program’s strings and walking our way back to any RTTI data structure. A string
    search yields the results shown in [Figure 20-5](ch20.xhtml#fig20_5).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig20-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-5: String Search results revealing class names*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we click the `"8SubClass"` string, we are taken to this portion of the Listing
    window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In `g++` binaries, RTTI-related structures contain references to the corresponding
    class name string. If we follow the cross-reference on the first line to its source,
    we arrive at the following section of the disassembly listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The source of the cross-reference ➍ is the second field within `SubClass`’s
    `typeinfo` structure, which starts at address `00301d18` ➌. Unfortunately, unless
    you are willing to dive into the source code for `g++`, structure layouts like
    this are just something you need to learn by experience. Our last remaining task
    is to locate `SubClass`’s vftable. In this example, if we follow the lone cross-reference
    to the `typeinfo` structure that originates from a data region ➋ (the other cross-reference
    ➊ originates from a function and can’t possibly be the vftable), we hit a dead
    end. A little math tells us that the cross-reference originates from the location
    immediately preceding the `typeinfo` struct (`00301d18` – `8` == `00301d10`).
    Under normal circumstances, a cross-reference would exist from the vftable to
    the `typeinfo` structure; however, lacking symbols, Ghidra fails to create that
    reference. Since we know that another pointer to our `typeinfo` structure must
    exist somewhere, we can ask Ghidra for help. With the cursor positioned at the
    start of the structure ➌, we can use the menu option Search ▸ For Direct References,
    which asks Ghidra to find the current address in memory for us. The results are
    shown in [Figure 20-6](ch20.xhtml#fig20_6).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig20-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-6: Results of direct reference search*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ghidra has found two additional references to this `typeinfo` structure. Investigating
    each of them finally leads us to a vftable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Ghidra has not formatted the source ➊ of the `typeinfo` cross-reference as a
    pointer (which explains the lack of a cross-reference), but it does provide an
    EOL comment that hints at it being a pointer ➋. The vftable itself begins 8 bytes
    later ➌ and contains five pointers to virtual functions belonging to `SubClass`.
    The table contains no mangled names because the binary has been stripped.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we apply this “follow the bread crumbs” analysis technique
    to help identify the `main` function in C binaries generated by several compilers.
  prefs: []
  type: TYPE_NORMAL
- en: '**Locating the main Function**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: From a programmer’s perspective, program execution typically begins with the
    `main` function, so it’s not a bad strategy to start analyzing a binary from the
    `main` function. However, compilers and linkers (and the use of libraries) add
    code that executes before `main` is reached. Thus, it’s often inaccurate to assume
    that the entry point of a binary corresponds to the `main` function written by
    the program’s author. In fact, the notion that all programs have a `main` function
    is a C/C++ compiler convention rather than a hard-and-fast rule for writing programs.
    If you have ever written a Windows GUI application, you may be familiar with the
    `WinMain` variation on `main`. Once you step away from C/C++, you may find that
    other languages use other names for their primary entry-point function. We refer
    to this function generically as the `main` function.
  prefs: []
  type: TYPE_NORMAL
- en: If there is a symbol named `main` in your binary, you can simply ask Ghidra
    to take you there, but if you happen to be analyzing a stripped binary, you will
    be dropped at the file header and have to find `main` on your own. With a little
    understanding of how executables operate, and a little experience, this shouldn’t
    prove too daunting a task.
  prefs: []
  type: TYPE_NORMAL
- en: All executables must designate an address within the binary as the first instruction
    to execute after the binary file has been mapped into memory. Ghidra refers to
    this address as `entry` or `_start`, depending on the file type and the availability
    of symbols. Most executable file formats specify this address within the file’s
    header region, and Ghidra loaders know exactly how to find it. In an ELF file,
    the entry point address is specified in a field named `e_entry`, while PE files
    contain a field named `AddressOfEntryPoint`. A compiled C program, regardless
    of the platform the executable is running on, has code at the entry point, inserted
    by the compiler, to make the transition from a brand-new process to a running
    C program. Part of this transition involves ensuring that arguments and environment
    variables provided to the kernel at process creation are gathered and provided
    to `main` utilizing the C calling convention.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Your operating system kernel neither knows nor cares in what language any
    executable was written. Your kernel knows exactly one way to pass parameters to
    a new process, and that way may not be compatible with your program’s entry function.
    It is the compiler’s job to bridge this gap.*'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know that execution begins at a published entry point and eventually
    reaches the `main` function, we can take a look at some compiler-specific code
    for effecting this transition.
  prefs: []
  type: TYPE_NORMAL
- en: '***Example 1: _start to main with gcc on Linux x86-64***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'By examining the start code in an unstripped executable, we can learn exactly
    how `main` is reached for a given compiler on a given operating system. Linux
    `gcc` offers one of the simpler approaches for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The address of `main` is loaded into `RDI` ➊ immediately before a call ➋ is
    made to a library function named `__libc_start_main`, which means that the address
    of `main` is passed as the first argument to `__libc_start_main`. Armed with this
    knowledge, we can easily locate `main` in a stripped binary. The following listing
    shows the lead-up to the call to `__libc_start_main` in a stripped binary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Though the code contains references to three generically named functions, we
    conclude that `FUN_0040080a` must be `main` because it is being passed as the
    first argument to `__libc_start_main` ➊.
  prefs: []
  type: TYPE_NORMAL
- en: '***Example 2: _start to main with clang on FreeBSD x86-64***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: On current versions of FreeBSD, clang is the default C compiler, and the `_start`
    function is somewhat more substantial and harder to follow than the simple Linux
    `_start` stub. To keep things simple, we’ll use Ghidra’s decompiler to look at
    the tail end of `_start`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, `main` is the penultimate function called in `_start`, and the
    return value from `main` is immediately passed to `exit` to terminate the program.
    Using Ghidra’s decompiler on a stripped version of the same binary yields the
    following listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again, we can pick `main` ➊ out of the crowd, even when the binary has
    been stripped. If you are wondering why this listing shows two function names
    that have not been stripped, the reason is that this particular binary is dynamically
    linked. The functions `atexit` and `exit` are not symbols in the binary; they
    are external dependencies. These external dependencies remain, even after stripping,
    and continue to be visible in the decompiled code. The corresponding code for
    a statically linked, stripped version of this binary is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '***Example 3: _start to main with Microsoft’s C/C++ compiler***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Microsoft C/C++ compiler’s startup stub is a bit more complicated because
    the primary interface to the Windows kernel is via *kernel32.dll* (rather than
    *libc* on most Unix systems), which provides no C library functions. As a result,
    the compiler often statically links many C library functions directly into executables.
    The startup stub uses these and other functions to interface with the kernel to
    set up your C program’s runtime environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, in the end, the startup stub still needs to call `main` and exit after
    it returns. Tracking down `main` among all of the startup code is usually a matter
    of identifying a three-argument function (`main`) whose return value is passed
    to a one-argument function (`exit`). The following excerpt from this type of binary
    contains calls to the two functions we are looking for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Here, `FUN_140001060` ➋ is the three-argument function that turns out to be
    `main`, and `FUN_140002b30` ➌ is the one-argument `exit`. Note that Ghidra has
    been able to recover the name ➊ of one of the statically linked functions called
    by the startup stub because the function matches an FidDb entry. We can use clues
    provided by any identified symbols to save some time in our search for `main`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The sheer volume of compiler-specific behaviors is too numerous to cover in
    a single chapter (or even a single book, for that matter). Among other behaviors,
    compilers differ in the algorithms they select to implement various high-level
    constructs and the manner in which they optimize generated code. Because a compiler’s
    behavior is heavily influenced by the arguments supplied to the compiler during
    the build process, it is possible for one compiler to generate radically different
    binaries when fed the same source with different build options selected.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, coping with all of these variations only comes with experience,
    and it is often very difficult to search for help on specific assembly language
    constructs, as it is very difficult to craft search expressions that will yield
    results applicable to your particular case. When this happens, your best resource
    is generally a forum dedicated to reverse engineering in which you can post code
    and benefit from the knowledge of others who have had similar experiences.
  prefs: []
  type: TYPE_NORMAL
