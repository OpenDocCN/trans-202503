<html><head></head><body>
<h2 class="h2" id="ch10"><span epub:type="pagebreak" id="page_175"/><strong><span class="big">10</span></strong><br/><strong>DEEP LEARNING BASICS</strong></h2>
<div class="image1"><img alt="image" src="../images/common01.jpg"/></div>
<p class="noindent">Deep learning is a type of machine learning that has advanced rapidly in the past few years, due to improvements in processing power and deep learning techniques. Usually, <em>deep learning</em> refers to deep, or many-layered, neural networks, which excel at performing very complex, often historically human-centric tasks, like image recognition and language translation.</p>
<p class="indent">For example, detecting whether a file contains an exact copy of some malicious code you’ve seen before is simple for a computer program and doesn’t require advanced machine learning. But detecting whether a file contains malicious code that is somewhat similar to malicious code you’ve seen before is a far more complex task. Traditional signature-based detection schemes are rigid and perform poorly on never-before-seen or obfuscated malware, whereas deep learning models can see through superficial changes and identify core features that make a sample malicious. The same <span epub:type="pagebreak" id="page_176"/>goes for network activity, behavioral analysis, and other related fields. This ability to pick out useful characteristics within a mass of noise makes deep learning an extremely powerful tool for cybersecurity applications.</p>
<p class="indent">Deep learning is just a type of machine learning (we covered machine learning in general in <a href="ch06.xhtml#ch06">Chapters 6</a> and <a href="ch07.xhtml#ch07">7</a>). But it often leads to models that achieve better accuracy than approaches we discussed in these preceding chapters, which is why the entire field of machine learning has emphasized deep learning in the last five years or so. If you’re interested in working at the cutting edge of security data science, it’s essential to learn how to use deep learning. A note of caution, however: deep learning is harder to understand than the machine learning approaches we discussed early in this book, and it requires some commitment, and high-school level calculus, to fully understand. You’ll find that the time you invest in understanding it will pay dividends in your security data science work in terms of your ability to build more accurate machine learning systems. So we urge you to read this chapter carefully and work at understanding it until you get it! Let’s get started.</p>
<h3 class="h3" id="lev164"><strong>What Is Deep Learning?</strong></h3>
<p class="noindent">Deep learning models learn to view their training data as a nested hierarchy of concepts, which allows them to represent incredibly complex patterns. In other words, these models not only take into consideration the original features you give them, but automatically combine these features to form new, optimized meta-features, which they then combine to form even more features, and so on.</p>
<p class="indent">“Deep” also refers to the architecture used to accomplish this, which usually consists of multiple layers of processing units, each using the previous layer’s outputs as its inputs. Each of these processing units is called a <em>neuron</em>, and the model architecture as a whole is called a <em>neural network</em>, or a <em>deep neural network</em> when there are many layers.</p>
<p class="indent">To see how this architecture can be helpful, let’s think about a program that attempts to classify images either as a bicycle or a unicycle. For a human, this is an easy task, but programming a computer to look at a grid of pixels and tell which object it represents is quite difficult. Certain pixels that indicate that a unicycle exists in one image will mean something else entirely in the next if the unicycle has moved slightly, been placed at a different angle, or has a different color.</p>
<p class="indent">Deep learning models get past this by breaking the problem down into more manageable pieces. For example, a deep neural network’s first layer of neurons might first break down the image into parts and just identify low-level visual features, like edges and borders of shapes in the image. These created features are fed into the next layer of the network to find patterns among the features. These patterns are then fed into subsequent layers, until the network is identifying general shapes and, eventually, complete objects. In our unicycle example, the first layer might find lines, the second might see lines forming circles, and the third might identify that certain circles are actually wheels. In this way, instead of looking at a mass of pixels, <span epub:type="pagebreak" id="page_177"/>the model can see that each image has a certain number of “wheel” meta-features. It can then, for example, learn that two wheels likely indicate a bicycle, whereas one wheel means a unicycle.</p>
<p class="indent">In this chapter, we focus on how neural networks actually work, both mathematically and structurally. First, I use a very basic neural network as an example to explain exactly what a neuron is and how it connects to other neurons to create a neural network. Second, I describe the mathematical processes used to train these networks. Finally, I describe some popular types of neural networks, how they’re special, and what they’re good at. This will set you up nicely for <a href="ch11.xhtml#ch11">Chapter 11</a>, where you’ll actually create deep learning models in Python.</p>
<h3 class="h3" id="lev165"><strong>How Neural Networks Work</strong></h3>
<p class="noindent">Machine learning models are simply big mathematical functions. For example, we take input data (such as an HTML file represented as a series of numbers), apply a machine learning function (such as a neural network), and we get an output that tells us how malicious the HTML file looks. Every machine learning model is just a function containing adjustable parameters that get optimized during the training process.</p>
<p class="indent">But how does a deep learning function actually work and what does it look like? Neural networks are, as the name implies, just networks of many neurons. So, before we can understand how neural networks work, we first need to know what a neuron is.</p>
<h4 class="h4" id="lev166"><strong><em>Anatomy of a Neuron</em></strong></h4>
<p class="noindent">Neurons themselves are just a type of small, simple function. <a href="ch10.xhtml#ch10fig1">Figure 10-1</a> shows what a single neuron looks like.</p>
<div class="image"><a id="ch10fig1"/><img alt="image" src="../images/f0177-01.jpg"/></div>
<p class="figcap"><em>Figure 10-1: Visualization of a single neuron</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_178"/>You can see that input data comes in from the left, and a single output number comes out on the right (though some types of neurons generate multiple outputs). The value of the output is a function of the neuron’s input data and some parameters (which are optimized during training). Two steps occur inside every neuron to transform the input data into the output.</p>
<p class="indent">First, a weighted sum of the neuron’s inputs is calculated. In Figuree 10-1, each input number, <em>x</em><sub>i</sub>, travelling into the neuron gets multiplied by an associated <em>weight</em> value, <em>w</em><sub>i</sub>. The resulting values are added together (yielding a weighted sum) to which a <em>bias</em> term is added. The bias and weights are the parameters of the neuron that are modified during training to optimize the model.</p>
<p class="indent">Second, an <em>activation function</em> is applied to the weighted sum plus bias value. The purpose of an activation function is to apply a nonlinear transformation to the weighted sum, which is a <em>linear</em> transformation of the neuron’s input data. There are many common types of activation functions, and they tend to be quite simple. The only requirement of an activation function is that it’s differentiable, which enables us to use backpropagation to optimize parameters (we discuss this process shortly in “<a href="ch10.xhtml#lev172">Training Neural Networks</a>” on <a href="ch10.xhtml#page_189">page 189</a>).</p>
<p class="indent"><a href="ch10.xhtml#ch10tab1">Table 10-1</a> shows a variety of other common activation functions and explains which ones tend to be good for which purposes.</p>
<p class="tabcap" id="ch10tab1"><strong>Table 10-1:</strong> Common Activation Functions</p>
<table class="topbot-d">
<thead>
<tr>
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Name</strong></p></td>
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Plot</strong></p></td>
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Equation</strong></p></td>
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Description</strong></p></td>
</tr>
</thead>
<tbody>
<tr>
<td class="table-a" style="vertical-align: top;"><p class="taba">Identity</p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0178-01.jpg"/></p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba"><em>f</em>(<em>x</em>) = <em>x</em></p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba">Basically: no activation function!</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">ReLU</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0178-02.jpg"/></p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0178-03.jpg"/></p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">Just max(0, <em>x</em>).</p>
<p class="taba">ReLUs enable fast learning and are more resilient to the vanishing gradient problem (explained later in this chapter) compared to other functions, like the sigmoid.</p></td>
</tr>
<tr>
<td class="table-a" style="vertical-align: top;"><p class="taba"><span epub:type="pagebreak" id="page_179"/>Leaky ReLU</p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0179-01.jpg"/></p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0179-02.jpg"/></p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba">Like normal ReLU, but instead of 0, a small constant fraction of <em>x</em> is returned. Generally you choose <em>α</em> to be very small, like 0.01. Also, <em>α</em> stays fixed during training.</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">PReLU</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0179-03.jpg"/></p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0179-04.jpg"/></p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">This is just like leaky ReLU, but in PReLU, <em>α</em> is a parameter whose value is optimized during the training process, along with the standard weight and bias parameters.</p></td>
</tr>
<tr>
<td class="table-a" style="vertical-align: top;"><p class="taba">ELU</p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0179-05.jpg"/></p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0179-06.jpg"/></p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba">Like PReLU in that <em>α</em> is a parameter, but instead of going down infinitely with a slope of <em>α</em> when <em>x</em> &lt; 0, the curve is bounded by <em>α</em>, because <em>e</em><sup><em>x</em></sup> will always be between 0 and 1 when <em>x</em> &lt; 0.</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">Step</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0179-07.jpg"/></p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0179-08.jpg"/></p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">Just a step function: the function returns 0 unless <em>x</em> ≤ 0, in which case the function returns 1.</p></td>
</tr>
<tr>
<td class="table-a" style="vertical-align: top;"><p class="taba">Gaussian</p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0179-09.jpg"/></p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba"><em>f</em>(<em>x</em>) = <em>e</em><sup><em>-x</em><sup>2</sup></sup></p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba">A bell-shaped curve whose maximum value tops out at 1 when <em>x</em> = 0.</p></td>
</tr>
<tr>
<td class="table-a" style="vertical-align: top;"><p class="taba"><span epub:type="pagebreak" id="page_180"/>Sigmoid</p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0180-01.jpg"/></p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0180-02.jpg"/></p></td>
<td class="table-a" style="vertical-align: top;"><p class="taba">Because of the vanishing gradient problem (explained later in this chapter), sigmoid activation functions are often only used in the final layer of a neural network. Because the output is continuous and bounded between 0 and 1, sigmoid neurons are a good proxy for output probabilities.</p></td>
</tr>
<tr>
<td class="table-ba" style="vertical-align: top;"><p class="taba">Softmax</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">(multi-output)</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba"><img alt="image" src="../images/f0180-03.jpg"/></p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">Outputs multiple values that sum to 1. Softmax activation functions are often used in the final layer of a network to represent classification probabilities, because Softmax forces all outputs from a neuron to sum to 1.</p></td>
</tr>
</tbody>
</table>
<p class="indent"><em>Rectified linear unit (ReLU)</em> is by far the most common activation function used today, and it’s simply max(0, <em>s</em>). For example, let’s say your weighted sum plus bias value is called <em>s</em>. If <em>s</em> is above zero, then your neuron’s output is <em>s</em>, and if <em>s</em> is equal to or below zero, then your neuron’s output is 0. You can express the entire function of a ReLU neuron as simply max(0, <em>weighted-sum-of-inputs</em> + <em>bias</em>), or more concretely, as the following for <em>n</em> inputs:</p>
<div class="imagec"><img alt="image" src="../images/f0180-04.jpg"/></div>
<p class="indent">Nonlinear activation functions are actually a key reason why networks of such neurons are able to approximate any continuous function, which is a big reason why they’re so powerful. In the following sections, you learn how neurons are connected together to form a network, and later you’ll gain an understanding of why nonlinear activation functions are so important.</p>
<h4 class="h4" id="lev167"><strong><em>A Network of Neurons</em></strong></h4>
<p class="noindent">To create a neural network, you arrange neurons in a <em>directed graph</em> (a network) with a number of layers, connecting to form a much larger function. <a href="ch10.xhtml#ch10fig2">Figure 10-2</a> shows an example of a small neural network.</p>
<div class="image"><span epub:type="pagebreak" id="page_181"/><a id="ch10fig2"/><img alt="image" src="../images/f0181-01.jpg"/></div>
<p class="figcap"><em>Figure 10-2: Example of a very small, four-neuron neural network, where data is passed from neuron to neuron via the connections.</em></p>
<p class="indent">In <a href="ch10.xhtml#ch10fig2">Figure 10-2</a>, we have our original inputs: <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, and <em>x</em><sub>3</sub> on the left side. Copies of these <em>x</em><sub><em>i</em></sub> values are sent along the connections to each neuron in the <em>hidden layer</em> (a layer of neurons whose output is not the final output of the model), resulting in three output values, one from each neuron. Finally, each output of these three neurons is sent to a final neuron, which outputs the neural network’s final result.</p>
<p class="indent">Every connection in a neural network is associated with a <em>weight</em> parameter, <em>w</em>, and every neuron also contains a <em>bias</em> parameter, <em>b</em> (added to the weighted sum), so the total number of optimizable parameters in a basic neural network is the number of edges connecting an input to a neuron, plus the number of neurons. For example, in the network shown in <a href="ch10.xhtml#ch10fig2">Figure 10-2</a>, there are 4 total neurons, plus 9 + 3 edges, yielding a total of 16 optimizable parameters. Because this is just an example, we’re using a very small neural network—real neural networks often have thousands of neurons and millions of connections.</p>
<h4 class="h4" id="lev168"><strong><em>Universal Approximation Theorem</em></strong></h4>
<p class="noindent">A striking aspect of neural networks is that they are <em>universal approximators</em>: given enough neurons, and the right weight and bias values, a neural network can emulate basically any type of behavior. The neural network shown in <a href="ch10.xhtml#ch10fig2">Figure 10-2</a> is <em>feed-forward</em>, which means the data is always flowing forward (from left to right in the image).</p>
<p class="indent">The <em>universal approximation theorem</em> describes the concept of universality more formally. It states that a feed-forward network with a single hidden layer of neurons with nonlinear activation functions can approximate (with an arbitrarily small error) any continuous function on a compact subset of <strong>R</strong><sup><strong>n</strong></sup>.<a id="ch10fn_1"/><a href="footnote.xhtml#ch10fn1"><sup>1</sup></a> That’s a bit of a mouthful, but it just means that with enough neurons, a neural network can <em>very</em> closely approximate any continuous, bounded function with a finite number of inputs and outputs.</p>
<p class="indent"><span epub:type="pagebreak" id="page_182"/>In other words, the theorem states that regardless of the function we want to approximate, there’s theoretically some neural network with the right parameters that can do the job. For example, if you draw a squiggly, continuous function, <em>f</em>(<em>x</em>), like in <a href="ch10.xhtml#ch10fig3">Figure 10-3</a>, there exists some neural network such that for every possible input of <em>x</em>, <em>f</em>(<em>x</em>) ≈ network(<em>x</em>), no matter how complicated the function <em>f</em>(<em>x</em>). This is one reason neural networks can be so powerful.</p>
<div class="image"><a id="ch10fig3"/><img alt="image" src="../images/f0182-01.jpg"/></div>
<p class="figcap"><em>Figure 10-3: Example of how a small neural net could approximate a funky function. As the number of neurons grows, the difference between</em> y <em>and ŷ will approach 0.</em></p>
<p class="indent">In the next sections, we build a simple neural network by hand to help you understand how and why we can model such different types of behavior, given the right parameters. Although we do this on a very small scale using just a single input and output, the same principle holds true when you’re dealing with multiple inputs and outputs, and incredibly complex behaviors.</p>
<h4 class="h4" id="lev169"><strong><em>Building Your Own Neural Network</em></strong></h4>
<p class="noindent">To see this universality in action, let’s try building our own neural network. We start with two ReLU neurons, using a single input <em>x</em>, as shown in <a href="ch10.xhtml#ch10fig4">Figure 10-4</a>. Then, we see how different weight and bias values (parameters) can be used to model different functions and outcomes.</p>
<div class="image"><a id="ch10fig4"/><img alt="image" src="../images/f0182-02.jpg"/></div>
<p class="figcap"><em>Figure 10-4: Visualization of two neurons being fed input data</em> x</p>
<p class="indent"><span epub:type="pagebreak" id="page_183"/>Here, both neurons have a weight of 1, and both use a ReLU activation function. The only difference between the two is that neuron<sub>1</sub> applies a bias value of –1, while neuron<sub>2</sub> applies a bias value of –2. Let’s see what happens when we feed neuron<sub>1</sub> a few different values of <em>x</em>. <a href="ch10.xhtml#ch10tab2">Table 10-2</a> summarizes the results.</p>
<p class="tabcap" id="ch10tab2"><strong>Table 10-2:</strong> Neuron<sub>1</sub></p>
<table class="topbot-d">
<thead>
<tr>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Input</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Weighted sum</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Weighted sum + bias</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Output</strong></p></td>
</tr>
<tr>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th"><em>x</em></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th"><em>x</em>* <em>w</em><sub><em>x</em>→1</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th"><em>x</em>* <em>w</em><sub><em>x</em>→1</sub> + bias<sub>1</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">max(0, <em>x</em>* <em>w</em><sub><em>x</em>→1</sub> + bias<sub>1</sub>)</p></td>
</tr>
</thead>
<tbody>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0 * 1 = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0 + –1 = –1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, –1) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">1 * 1 = 1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">1 + –1 = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 0) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2 * 1 = 2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2 + –1 = 1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 1) = 1</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">3 * 1 = 3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">3 + –1 = 2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 2) = 2</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">4 * 1 = 4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">4 + –1 = 3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 3) = 3</p></td>
</tr>
<tr>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5 * 1 = 5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5 + –1 = 4</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">max(0, 4) = 4</p></td>
</tr>
</tbody>
</table>
<p class="indent">The first column shows some sample inputs for <em>x</em>, and the second shows the resulting weighted sum. The third column adds the bias parameter, and the fourth column applies the ReLU activation function to yield the neuron’s output for a given input of <em>x</em>. <a href="ch10.xhtml#ch10fig5">Figure 10-5</a> shows the graph of the neuron<sub>1</sub> function.</p>
<div class="image"><a id="ch10fig5"/><img alt="image" src="../images/f0183-01.jpg"/></div>
<p class="figcap"><em>Figure 10-5: Visualization of neuron<sub>1</sub> as a function. The x-axis represents the neuron’s single input value, and the y-axis represents the neuron’s output.</em></p>
<p class="indent">Because neuron<sub>1</sub> has a bias of –1, the output of neuron<sub>1</sub> stays at 0 until the weighted sum goes above 1, and then it goes up with a certain slope, as you can see in <a href="ch10.xhtml#ch10fig5">Figure 10-5</a>. That slope of 1 is associated with the <em>w</em><sub><em>x</em>→1</sub> weight value of 1. Think about what would happen with a weight of 2: because the weighted sum value would double, the angle in <a href="ch10.xhtml#ch10fig5">Figure 10-5</a> would occur at <em>x</em> = 0.5 instead of <em>x</em> = 1, and the line would go up with a slope of 2 instead of 1.</p>
<p class="indent">Now let’s look at neuron<sub>2</sub>, which has a bias value of –2 (see <a href="ch10.xhtml#ch10tab3">Table 10-3</a>).</p>
<p class="tabcap" id="ch10tab3"><span epub:type="pagebreak" id="page_184"/><strong>Table 10-3:</strong> Neuron<sub>2</sub></p>
<table class="topbot-d">
<thead>
<tr>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Input</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Weighted sum</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Weighted sum + bias</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Output</strong></p></td>
</tr>
<tr>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th"><em>x</em></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th"><em>x</em>* <em>w</em><sub><em>x</em>→2</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th"><em>x</em>* <em>w</em><sub><em>x</em>→2</sub> + bias<sub>2</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">max(0, <em>x</em>* <em>w</em><sub><em>x</em>→2</sub>) + bias<sub>2</sub>)</p></td>
</tr>
</thead>
<tbody>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0 * 1 = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0 + –2 = –2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, –2) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">1 * 1 = 1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">1 + –2 = –1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, –1) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2 * 1 = 2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2 + –2 = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 0) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">3 * 1 = 3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">3 + –2 = 1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 1) = 1</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">4 * 1 = 4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">4 + –2 = 2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 2) = 2</p></td>
</tr>
<tr>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5 * 1 = 5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5 + –2 = 3</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">max(0, 3) = 3</p></td>
</tr>
</tbody>
</table>
<p class="indent">Because neuron<sub>2</sub>’s bias is –2, the angle in <a href="ch10.xhtml#ch10fig6">Figure 10-6</a> occurs at <em>x</em> = 2 instead of <em>x</em> = 1.</p>
<div class="image"><a id="ch10fig6"/><img alt="image" src="../images/f0184-01.jpg"/></div>
<p class="figcap"><em>Figure 10-6: Visualization of neuron<sub>2</sub> as a function</em></p>
<p class="indent">So now we’ve built two very simple functions (neurons), both doing nothing over a set period, then going up infinitely with a slope of 1. Because we’re using ReLU neurons, the slope of each neuron’s function is affected by its weights, while its bias and weight terms both affect where the slope begins. When you use other activation functions, similar rules apply. By adjusting parameters, we could change the angle and slope of each neuron’s function however we wanted.</p>
<p class="indent">In order to achieve universality, however, we need to combine neurons together, which will allow us to approximate more complex functions. Let’s connect our two neurons up to a third neuron, as shown in <a href="ch10.xhtml#ch10fig7">Figure 10-7</a>. This will create a small three-neuron network with a single hidden layer, composed of neuron<sub>1</sub> and neuron<sub>2</sub>.</p>
<p class="indent">In <a href="ch10.xhtml#ch10fig7">Figure 10-7</a>, input data <em>x</em> is sent to both neuron<sub>1</sub> and neuron<sub>2</sub>. Then, neuron<sub>1</sub> and neuron<sub>2</sub>’s outputs are sent as inputs to neuron<sub>3</sub>, which yields the network’s final output.</p>
<div class="image"><span epub:type="pagebreak" id="page_185"/><a id="ch10fig7"/><img alt="image" src="../images/f0185-01.jpg"/></div>
<p class="figcap"><em>Figure 10-7: Visualization of a small three-neuron network</em></p>
<p class="indent">If you inspect the weights in <a href="ch10.xhtml#ch10fig7">Figure 10-7</a>, you’ll notice that the weight <em>w</em><sub>1→3</sub> is 2, doubling neuron<sub>1</sub>’s contribution to neuron<sub>3</sub>. Meanwhile, <em>w</em><sub>2→3</sub> is –1, inverting neuron<sub>2</sub>’s contribution. In essence, neuron<sub>3</sub> is simply applying its activation function to neuron<sub>1</sub> * 2 – neuron<sub>2</sub>. <a href="ch10.xhtml#ch10tab4">Table 10-4</a> summarizes the inputs and corresponding outputs for the resulting network.</p>
<p class="tabcap" id="ch10tab4"><strong>Table 10-4:</strong> A Three-Neuron Network</p>
<table class="topbot-d">
<thead>
<tr>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Original network input</strong></p></td>
<td class="table-ha" colspan="2" style="vertical-align: middle;"><p class="tab_th"><strong>Inputs to neuron<sub>3</sub></strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Weighted sum</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Weighted sum + bias</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Final network output</strong></p></td>
</tr>
<tr>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th"><em>x</em></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">neuron<sub>1</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">neuron<sub>2</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">(neuron<sub>1</sub> * <em>w</em><sub>1→3</sub>) + (neuron<sub>2</sub> * <em>w</em><sub>2→3</sub>)</p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">(neuron<sub>1</sub> * <em>w</em><sub>1→3</sub>) + (neuron<sub>2</sub> * <em>w</em><sub>2→3</sub>) + bias<sub>3</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">max(0, (neuron<sub>1</sub> * <em>w</em><sub>1→3</sub>) + (neuron<sub>2</sub> * <em>w</em><sub>2→3</sub>) + bias<sub>3</sub>)</p></td>
</tr>
</thead>
<tbody>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">(0 * 2) + (0 * –1) = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0 + 0 + 0 = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 0) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">(0 * 2) + (0 * –1) = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0 + 0 + 0 = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 0) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">(1 * 2) + (0 * –1) = 2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2 + 0 + 0 = 2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 2) = 2</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">(2 * 2) + (1 * –1) = 3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">4 + –1 + 0 = 3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 3) = 3</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">(3 * 2) + (2 * –1) = 4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">6 + –2 + 0 = 4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 4) = 4</p></td>
</tr>
<tr>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">4</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">3</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">(4 * 2) + (3 * –1) = 5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">8 + –3 + 0 = 5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">max(0, 5) = 5</p></td>
</tr>
</tbody>
</table>
<p class="indent">The first column shows original network input, <em>x</em>, followed by the resulting outputs of neuron<sub>1</sub> and neuron<sub>2</sub>. The rest of the columns show how neuron<sub>3</sub> processes the outputs: the weighted sum is calculated, bias is added, and finally in the last column the ReLU activation function is applied to achieve the neuron and network outputs for each original input value for <em>x</em>. <a href="ch10.xhtml#ch10fig8">Figure 10-8</a> shows the network’s function graph.</p>
<div class="image"><span epub:type="pagebreak" id="page_186"/><a id="ch10fig8"/><img alt="image" src="../images/f0186-01.jpg"/></div>
<p class="figcap"><em>Figure 10-8: Visualization of our network’s inputs and associated outputs</em></p>
<p class="indent">We can see that through the combination of these simple functions, we can create a graph that goes up for any period or slope desired over different points, as we did in <a href="ch10.xhtml#ch10fig8">Figure 10-8</a>. In other words, we’re much closer to being able to represent any finite function for our input <em>x</em>!</p>
<h4 class="h4" id="lev170"><strong><em>Adding Another Neuron to the Network</em></strong></h4>
<p class="noindent">We’ve seen how to make our network’s function’s graph go up (with any slope) by adding neurons, but how would we make the graph go down? Let’s add another neuron (neuron<sub>4</sub>) to the mix, as shown in <a href="ch10.xhtml#ch10fig9">Figure 10-9</a>.</p>
<div class="image"><a id="ch10fig9"/><img alt="image" src="../images/f0186-02.jpg"/></div>
<p class="figcap"><em>Figure 10-9: Visualization of a small four-neuron network with a single hidden layer</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_187"/>In <a href="ch10.xhtml#ch10fig9">Figure 10-9</a>, input data <em>x</em> is sent to neuron<sub>1</sub>, neuron<sub>2</sub>, and neuron<sub>4</sub>. Their outputs are then fed as inputs to neuron<sub>3</sub>, which yields the network’s final output. Neuron<sub>4</sub> is the same as neuron<sub>1</sub> and neuron<sub>2</sub>, but with its bias set to –4. <a href="ch10.xhtml#ch10tab5">Table 10-5</a> summarizes the output of neuron<sub>4</sub>.</p>
<p class="tabcap" id="ch10tab5"><strong>Table 10-5:</strong> Neuron<sub>4</sub></p>
<table class="topbot-d">
<thead>
<tr>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Input</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Weighted sum</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Weighted sum + bias</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Output</strong></p></td>
</tr>
<tr>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th"><em>x</em></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th"><em>x</em> * <em>w</em><sub><em>x</em>→4</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">(<em>x</em> * <em>w</em><sub><em>x</em>→4</sub>) + bias<sub>4</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">max(0, (<em>x</em> * <em>w</em><sub><em>x</em>→4</sub>) + bias<sub>4</sub>)</p></td>
</tr>
</thead>
<tbody>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0 * 1 = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0 + –4 = –4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, –4) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">1 * 1 = 1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">1 + –4 = –3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, –3) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2 * 1 = 2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2 + –4 = –2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, –2) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">3 * 1 = 3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">3 + –4 = –1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, –1) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">4 * 1 = 4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">4 + –4 = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 0) = 0</p></td>
</tr>
<tr>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5 * 1 = 5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5 + –4 = 1</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">max(0, 1) = 1</p></td>
</tr>
</tbody>
</table>
<p class="indent">To make our network graph descend, we subtract neuron<sub>4</sub>’s function from that of neuron<sub>1</sub> and neuron<sub>2</sub> in neuron<sub>3</sub>’s weighted sum by setting the weight connecting neuron<sub>4</sub> to neuron<sub>3</sub> to –2. <a href="ch10.xhtml#ch10tab6">Table 10-6</a> shows the new output of the entire network.</p>
<p class="tabcap" id="ch10tab6"><strong>Table 10-6:</strong> A Four-Neuron Network</p>
<table class="topbot-d">
<thead>
<tr>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Original network input</strong></p></td>
<td class="table-ha" colspan="3" style="vertical-align: middle;"><p class="tab_th"><strong>Inputs to neuron<sub>3</sub></strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Weighted sum</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Weighted sum + bias</strong></p></td>
<td class="table-ha" style="vertical-align: top;"><p class="tab_th"><strong>Final network output</strong></p></td>
</tr>
<tr>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th"><em>x</em></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">neuron<sub>1</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">neuron<sub>2</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">neuron<sub>4</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">(neuron<sub>1</sub> * <em>w</em><sub>1→3</sub>) + (neuron<sub>2</sub> * <em>w</em><sub>2→3</sub>) + (neuron<sub>4</sub> * <em>w</em><sub>4→3</sub>)</p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">(neuron<sub>1</sub> * <em>w</em><sub>1→3</sub>) + (neuron<sub>2</sub> * <em>w</em><sub>2→3</sub>) + (neuron<sub>4</sub> * <em>w</em><sub>4→3</sub>) + bias<sub>3</sub></p></td>
<td class="table-haa" style="vertical-align: top;"><p class="tab_th">max(0, (neuron<sub>1</sub> * <em>w</em><sub>1→3</sub>) + (neuron<sub>2</sub> * <em>w</em><sub>2→3</sub>) + (neuron<sub>4</sub> * <em>w</em><sub>4→3</sub>) + bias<sub>3</sub>)</p></td>
</tr>
</thead>
<tbody>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">(0 * 2) + (0 * –1) + (0 * –2) = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0 + 0 + 0 + 0 = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max(0, 0) = 0</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">(0 * 2) + (0 * –1) + (0 * –2) = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0 + 0 + 0 + 0 = 0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max (0, 0) = 1</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">(1 * 2) + (0 * –1) + (0 * –2) = 2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2 + 0 + 0 + 0 = 2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max (0, 2) = 2</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">1</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">(2 * 2) + (1 * –1) + (0 * –2) = 3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">4 + –1 + 0 + 0 = 3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max (0, 3) = 3</p></td>
</tr>
<tr>
<td class="table-b" style="vertical-align: top;"><p class="taba">4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">3</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">2</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">0</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">(3 * 2) + (2 * –1) + (0 * –2) = 4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">6 + –2 + 0 + 0 = 4</p></td>
<td class="table-b" style="vertical-align: top;"><p class="taba">max (0, 4) = 4</p></td>
</tr>
<tr>
<td class="table-ba" style="vertical-align: top;"><p class="taba">5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">4</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">3</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">1</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">(4 * 2) + (3 * –1) + (1 * –2) = 5</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">8 + –3 + –2 + 0 = 3</p></td>
<td class="table-ba" style="vertical-align: top;"><p class="taba">max (0, 3) = 3</p></td>
</tr>
</tbody>
</table>
<p class="indent"><a href="ch10.xhtml#ch10fig10">Figure 10-10</a> shows what this looks like.</p>
<div class="image"><span epub:type="pagebreak" id="page_188"/><a id="ch10fig10"/><img alt="image" src="../images/f0188-01.jpg"/></div>
<p class="figcap"><em>Figure 10-10: Visualization of our four-neuron network</em></p>
<p class="indent">Hopefully, now you can see how the neural network architecture allows us to move up and down at any rate over any points on the graph, just by combining a number of simple neurons (universality!). We could continue adding more neurons to create far more sophisticated functions.</p>
<h4 class="h4" id="lev171"><strong><em>Automatic Feature Generation</em></strong></h4>
<p class="noindent">You’ve learned that a neural network with a single hidden layer can approximate any finite function with enough neurons. That’s a pretty powerful idea. But what happens when we have multiple hidden layers of neurons? In short, automatic feature generation happens, which is perhaps an even more powerful aspect of neural networks.</p>
<p class="indent">Historically, a big part of the process of building machine learning models was feature extraction. For an HTML file, a lot of time would be spent deciding what numeric aspects of an HTML file (number of section headers, number of unique words, and so on) might aid the model.</p>
<p class="indent">Neural networks with multiple layers and automatic feature generation allow us to offload a lot of that work. In general, if you give fairly raw features (such as characters or words in an HTML file) to a neural network, each layer of neurons can learn to represent those raw features in ways that work well as inputs to later layers. In other words, a neural network will learn to count the number of times the letter <em>a</em> shows up in an HTML document, if that’s particularly relevant to detecting malware, with no real input from a human saying that it is or isn’t.</p>
<p class="indent">In our image-processing bicycle example, nobody specifically told the network that edges or wheel meta-features were useful. The model learned that those features were useful as inputs to the next neuron layer during the training process. What’s especially useful is that these lower-level learned features can be used in different ways by later layers, which means that deep neural networks can estimate many incredibly complex patterns using far fewer neurons and parameters than a single-layered network could.</p>
<p class="indent">Not only do neural networks perform a lot of the feature extraction work that previously took a lot of time and effort, they do it in an optimized and space-efficient way, guided by the training process.</p>
<h3 class="h3" id="lev172"><span epub:type="pagebreak" id="page_189"/><strong>Training Neural Networks</strong></h3>
<p class="noindent">So far, we’ve explored how, given a large number of neurons and the right weights and bias terms, a neural network can approximate complex functions. In all our examples so far, we set those weight and bias parameters manually. However, because real neural networks normally contain thousands of neurons and millions of parameters, we need an efficient way to optimize these values.</p>
<p class="indent">Normally, when training a model, we start with a training dataset and a network with a bunch of non-optimized (randomly initialized) parameters. Training requires optimizing parameters to minimize an objective function. In supervised learning, where we’re trying to train our model to be able to predict a label, like 0 for “benign” and 1 for “malware,” that <em>objective function</em> is going to be related to the network’s prediction error during training. For some given input <em>x</em> (for example, a specific HTML file), this is the difference between the label <em>y</em> we know is correct (for example, 1.0 for “is malware”) and the output <em>ŷ</em> we get from the current network (for example, 0.7). You can think of the error as the difference between the predicted label <em>ŷ</em> and the known, true label <em>y</em>, where network (<em>x</em>) = <em>ŷ</em>, and the network is trying to approximate some unknown function <em>f</em>, such that <em>f</em>(<em>x</em>) = <em>y</em>. In other words, network = <img alt="images" src="../images/fcap.jpg"/>.</p>
<p class="indent">The basic idea behind training networks is to feed a network an observation, <em>x</em>, from your training dataset, receive some output, <em>ŷ</em> , and then figure out how changing your parameters will shift <em>ŷ</em> closer to your goal, <em>y</em>. Imagine you’re in a spaceship with various knobs. You don’t know what each knob does, but you know the direction you want to go in (<em>y</em>). To solve the problem, you step on the gas and note the direction you went (<em>ŷ</em> ). Then, you turn a knob just a <em>tiny</em> bit and step on the gas again. The difference between your first and second directions tells you how much that knob affects your direction. In this way, you can eventually figure out how to fly the spaceship quite well.</p>
<p class="indent">Training a neural network is similar. First, you feed a network an observation, <em>x</em>, from your training dataset, and you receive some output, <em>ŷ</em> . This step is called <em>forward propagation</em> because you feed your input <em>x</em> forward through the network to get your final output <em>ŷ</em> . Next, you determine how each parameter affects your output <em>ŷ</em> . For example, if your network’s output is 0.7, but you know the correct output should be closer to 1, you can try increasing a parameter, <em>w</em>, just a little bit, seeing whether <em>ŷ</em> gets closer to or further away from <em>y</em>, and by how much.<a id="ch10fn_2"/><a href="footnote.xhtml#ch10fn2"><sup>2</sup></a> This is called the partial derivative of <em>ŷ</em> with respect to <em>w</em>, or <em>∂ŷ/∂w</em>.</p>
<p class="indent">Parameters all throughout the network are then nudged just a <em>tiny</em> bit in a direction that causes <em>ŷ</em> to shift a little closer to <em>y</em> (and therefore network closer to <em>f</em> ). If <em>∂ŷ/∂w</em> is positive, then you know you should increase <em>w</em> by a <span epub:type="pagebreak" id="page_190"/>small amount (specifically, proportional to <em>∂</em>(<em>y</em> – <em>ŷ</em>)/<em>∂w</em>), so that your new <em>ŷ</em> will move slightly away from 0.7 and toward 1 (<em>y</em>). In other words, you teach your network to approximate the <em>unknown</em> function <em>f</em> by correcting its mistakes on training data with <em>known</em> labels.</p>
<p class="indent">The process of iteratively calculating these partial derivatives, updating parameters, and then repeating is called <em>gradient descent.</em> However, with a network of thousands of neurons, millions of parameters, and often millions of training observations, all of that calculus requires a lot of computation. To get around this, we use a neat algorithm called <em>backpropagation</em> that makes these calculations computationally feasible. At its core, backpropagation allows us to efficiently calculate partial derivatives along computational graphs like a neural network!</p>
<h4 class="h4" id="lev173"><strong><em>Using Backpropagation to Optimize a Neural Network</em></strong></h4>
<p class="noindent">In this section, we construct a simple neural network to showcase how backpropagation works. Let’s assume that we have a training example whose value is <em>x</em> = 2 and an associated true label of <em>y</em> = 10. Usually, <em>x</em> would be an array of many values, but let’s stick to a single value to keep things simple. Plugging in these values, we can see in <a href="ch10.xhtml#ch10fig11">Figure 10-11</a> that our network outputs a <em>ŷ</em> value of 5 with an input <em>x</em> value of 2.</p>
<div class="image"><a id="ch10fig11"/><img alt="image" src="../images/f0190-01.jpg"/></div>
<p class="figcap"><em>Figure 10-11: Visualization of our three-neuron network, with an input of</em> x <em>= 2</em></p>
<p class="indent">To nudge our parameters so that our network’s output <em>ŷ</em> , given <em>x</em> = 2, moves closer to our known <em>y</em> value of 10, we need to calculate how <em>w</em><sub>1→3</sub> affects our final output <em>ŷ</em> . Let’s see what happens when we increase <em>w</em><sub>1→3</sub> by just a bit (say, 0.01). The weighted sum in neuron<sub>3</sub> becomes 1.01 * 2 + (1 * 3), making the final output <em>ŷ</em> change from 5 to 5.02, resulting in an increase of 0.02. In other words, the partial derivative of <em>ŷ</em> with respect to <em>w</em><sub>1→3</sub> is 2, because changing <em>w</em><sub>1→3</sub> yields twice that change in <em>ŷ</em> .</p>
<p class="indent">Because <em>y</em> is 10 and our current output <em>ŷ</em> (given our current parameter values and <em>x</em> = 2) is 5, we now know that we should increase <em>w</em><sub>1→3</sub> by a small amount to move <em>y</em> closer to 10.</p>
<p class="indent"><span epub:type="pagebreak" id="page_191"/>That’s fairly simple. But we need to be able to know which direction to push <em>all</em> parameters in our network, not just ones in a neuron in the final layer. For example, what about <em>w</em><sub><em>x</em>→1</sub>? Calculating <em>∂ŷ</em>/<em>∂w</em><sub><em>x</em>→1</sub> is more complicated because it only <em>indirectly</em> affects <em>ŷ</em> . First, we ask neuron<sub>3</sub>’s function how <em>ŷ</em> is affected by neuron<sub>1</sub>’s output. If we change the output of neuron<sub>1</sub> from 2 to 2.01, the final output of the neuron<sub>3</sub> changes from 5 to 5.01, so <em>∂ŷ</em>/<em>∂</em>neuron<sub>1</sub> = 1. To know how much <em>w</em><sub><em>x</em>→1</sub> affects <em>ŷ</em> , we just have to multiply <em>∂ŷ</em>/<em>∂</em>neuron<sub>1</sub> by how much <em>w</em><sub><em>x</em>→1</sub> affects the output of neuron<sub>1</sub>. If we change <em>w</em><sub><em>x</em>→1</sub> from 1 to 1.01, the output of neuron<sub>1</sub> changes from 2 to 2.02, so <em>∂</em>neuron<sub>1</sub>/<em>∂w</em><sub><em>x</em>→1</sub> is 2. Therefore:</p>
<div class="imagec"><img alt="image" src="../images/f0191-01.jpg"/></div>
<p class="noindent">Or:</p>
<div class="imagec"><img alt="image" src="../images/f0191-02.jpg"/></div>
<p class="indent">You may have noticed that we just used the chain rule.<a id="ch10fn_3"/><a href="footnote.xhtml#ch10fn3"><sup>3</sup></a></p>
<p class="indent">In other words, to figure out how a parameter like <em>w</em><sub><em>x</em>→1</sub> deep inside a network affects our final output <em>ŷ</em> , we multiply the partial derivatives at each point along the path between our parameter <em>w</em><sub><em>x</em>→1</sub> and <em>ŷ</em> . This means that if <em>w</em><sub><em>x</em>→1</sub> is fed into a neuron whose outputs are fed into ten other neurons, calculating <em>w</em><sub><em>x</em>→1</sub>’s effect on <em>ŷ</em> would involve summing over all the paths that led from <em>w</em><sub><em>x</em>→1</sub> to <em>ŷ</em> , instead of just one. <a href="ch10.xhtml#ch10fig12">Figure 10-12</a> visualizes the paths affected by the sample weight parameter <em>w</em><sub><em>x</em>→2</sub>.</p>
<div class="image"><a id="ch10fig12"/><img alt="image" src="../images/f0191-03.jpg"/></div>
<p class="figcap"><em>Figure 10-12: Visualization of the paths affected by</em> w<sub><em>x</em>→2</sub> <em>(shown in dark gray): the weight associated with the connection between input data</em> x <em>and the middle neuron in the first (leftmost) layer</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_192"/>Note that the hidden layers in this network are not fully connected layers, which helps explain why the second hidden layer’s bottom neuron isn’t highlighted.</p>
<h4 class="h4" id="lev174"><strong><em>Path Explosion</em></strong></h4>
<p class="noindent">But what happens when our network gets even larger? The number of paths we need to add to calculate the partial derivative of a low-level parameter increases exponentially. Consider a neuron whose output is fed into a layer of 1,000 neurons, whose outputs are fed into 1,000 more neurons, whose outputs are then fed into a final output neuron.</p>
<p class="indent">That results in one million paths! Luckily, going over every single path and then summing them to get the <em>∂ŷ</em>/(<em>∂</em>parameter) is not necessary. This is where backpropagation comes in handy. Instead of walking along every single path that leads to our final output(s), <em>ŷ</em> , partial derivatives are calculated layer by layer, starting from the top down, or backward.</p>
<p class="indent">Using the chain rule logic from the last section, we can calculate any partial derivative <em>∂ŷ</em>/<em>∂w</em>, where <em>w</em> is a parameter connecting an output from layer<sub><em>i</em>–1</sub> to a neuron<sub><em>i</em></sub> in layer<sub><em>i</em></sub>, by summing over the following for all neuron<sub><em>i</em></sub><sub>+1</sub>, where each neuron<sub><em>i</em></sub><sub>+1</sub> is a neuron in layer<sub><em>i</em></sub><sub>+1</sub> to which neuron<sub><em>i</em></sub> (<em>w</em>’s neuron) is connected:</p>
<div class="imagec"><img alt="image" src="../images/f0192-01.jpg"/></div>
<p class="indent">By doing this layer by layer from the top down, we limit path explosion by consolidating derivatives at each layer. In other words, derivatives calculated in a top-level layer<sub><em>i</em>+1</sub> (like <em>∂ŷ</em>/<em>∂</em>neuron<sub><em>i</em>+1</sub>) are recorded to help calculate derivatives in layer<sub><em>i</em></sub>. Then to calculate derivatives in layer<sub><em>i</em></sub><sub>–1</sub>, we use the saved derivatives from layer<sub><em>i</em></sub> (like <em>∂ŷ</em>/<em>∂</em>neuron<sub><em>i</em></sub>). Then, layer<sub><em>i</em></sub><sub>–2</sub> uses derivatives from layer<sub><em>i</em>–1</sub>, and so on and so forth. This trick greatly reduces the amount of calculations we have to repeat and helps us to train neural networks quickly.</p>
<h4 class="h4" id="lev175"><strong><em>Vanishing Gradient</em></strong></h4>
<p class="noindent">One issue that very deep neural networks face is the <em>vanishing gradient</em> problem. Consider a weight parameter in the first layer of a neural network that has ten layers. The signal it gets from backpropagation is the summation of all paths’ signals from this weight’s neuron to the final output.</p>
<p class="indent">The problem is that each path’s signal is likely to be incredibly tiny, because we calculate that signal by multiplying partial derivatives at each point along the ten-neuron-deep path, all of which tend to be numbers smaller than 1. This means that a low-level neuron’s parameters are updated based on the summation of a massive number of very tiny numbers, many of which end up canceling one another out. As a result, it can be difficult for a network to coordinate sending a strong signal down <span epub:type="pagebreak" id="page_193"/>to parameters in lower layers. This problem gets exponentially worse as you add more layers. As you learn in the following section, certain network designs try to get around this pervasive problem.</p>
<h3 class="h3" id="lev176"><strong>Types of Neural Networks</strong></h3>
<p class="noindent">For simplicity’s sake, every example I’ve shown you so far uses a type of network called a feed-forward neural network. In reality, there are many other useful network structures you can use for different classes of problems. Let’s discuss some of the most common classes of neural networks and how they could be applied in a cybersecurity context.</p>
<h4 class="h4" id="lev177"><strong><em>Feed-Forward Neural Network</em></strong></h4>
<p class="noindent">The simplest (and first) kind of neural network, a feed-forward neural network, is kind of like a Barbie doll with no accessories: other types of neural networks are usually just variations on this “default” structure. The feed-forward architecture should sound familiar: it consists of stacks of layers of neurons. Each layer of neurons is connected to some or all neurons in the next layer, but connections never go backward or form cycles, hence the name “feed forward.”</p>
<p class="indent">In feed-forward neural networks, every connection that exists is connecting a neuron (or original input) in layer <em>i</em> to a neuron in layer <em>j</em> &gt; <em>i</em>. Each neuron in layer <em>i</em> doesn’t necessarily have to connect to every neuron in layer <em>i</em> + 1, but all connections must be feeding forward, connecting previous layers to later layers.</p>
<p class="indent">Feed-forward networks are generally the kind of network you throw at a problem first, unless you already know of another architecture that works particularly well on the problem at hand (such as convolutional neural networks for image recognition).</p>
<h4 class="h4" id="lev178"><strong><em>Convolutional Neural Network</em></strong></h4>
<p class="noindent">A <em>convolutional neural network (CNN)</em> contains convolutional layers, where the input that feeds into each neuron is defined by a window that slides over the input space. Imagine a small square window sliding over a larger picture where only the pixels visible through the window will be connected to a specific neuron in the next layer. Then, the window slides, and the new set of pixels are connected to a new neuron. <a href="ch10.xhtml#ch10fig13">Figure 10-13</a> illustrates this.</p>
<p class="indent">The structure of these networks encourages localized feature learning. For example, it’s more useful for a network’s lower layers to focus on the relationship between nearby pixels in an image (which form edges, shapes, and so on) than to focus on the relationship between pixels randomly scattered across an image (which are unlikely to mean much). The sliding windows explicitly force this focus, which improves and speeds up learning in areas where local feature extraction is especially important.</p>
<div class="image"><span epub:type="pagebreak" id="page_194"/><a id="ch10fig13"/><img alt="image" src="../images/f0194-01.jpg"/></div>
<p class="figcap"><em>Figure 10-13: Visualization of a 2 × 2 convolutional window sliding over a 3 × 3 input space with a stride (step size) of 1, to yield a 2 × 2 output</em></p>
<p class="indent">Because of their ability to focus on localized sections of the input data, convolutional neural networks are extremely effective at image recognition and classification. They’ve also been shown to be effective for certain types of natural language processing, which has implications for cybersecurity.</p>
<p class="indent">After each convolutional window’s values are fed to specific neurons in a convolutional layer, a sliding window is again slid over <em>these</em> neurons’ outputs, but instead of them being fed to standard neurons (for example, ReLUs) with weights associated with each input, they’re fed to neurons that have no weights (that is, fixed at 1) and a max (or similar) activation function. In other words, a small window is slid over the convolutional layer’s outputs, and the maximum value of each window is taken and passed to the next layer. This is called a <em>pooling layer</em>. The purpose of pooling layers is to “zoom out” on the data (usually, an image), thereby reducing the size of the features for faster computation, while retaining the most important information.</p>
<p class="indent">Convolutional neural networks can have one or multiple sets of convolutional and pooling layers. A standard architecture might include a convolutional layer, a pooling layer, followed by another set of convolutional and pooling layers, and finally a few fully connected layers, like in feed-forward networks. The goal of this architecture is that these final fully connected layers receive fairly high-level features as inputs (think wheels on a unicycle), and as a result are able to accurately classify complex data (such as images).</p>
<h4 class="h4" id="lev179"><strong><em>Autoencoder Neural Network</em></strong></h4>
<p class="noindent">An <em>autoencoder</em> is a type of neural network that tries to compress and then decompress an input with minimal difference between the original training input and the decompressed output. The goal of an autoencoder is to learn <span epub:type="pagebreak" id="page_195"/>an efficient representation for a set of data. In other words, autoencoders act like optimized lossy compression programs, where they compress input data into a smaller representation, then decompress it back to its original input size.</p>
<p class="indent">Instead of the neural network optimizing parameters by minimizing the difference between known labels (<em>y</em>) and predicted labels (<em>ŷ</em> ) for a given input <em>x</em>, the network tries to minimize the difference between the original input <em>x</em> and the reconstructed output <img alt="images" src="../images/xcap.jpg"/>.</p>
<p class="indent">Structurally, autoencoders are usually very similar to standard feed-forward neural networks, except that middle layers contain fewer neurons than early and later stage layers, as shown in <a href="ch10.xhtml#ch10fig14">Figure 10-14</a>.</p>
<div class="image"><a id="ch10fig14"/><img alt="image" src="../images/f0195-01.jpg"/></div>
<p class="figcap"><em>Figure 10-14: Visualization of an autoencoder network</em></p>
<p class="indent">As you can see, the middle layer is much smaller than the leftmost (input) and rightmost (output) layers, which each have the same size. The last layer should always contain the same number of outputs as the original inputs, so each training input <em>x</em><sub><em>i</em></sub> can be compared to its compressed and reconstructed cousin <img alt="images" src="../images/xcap1.jpg"/>.</p>
<p class="indent">After an autoencoder network has been trained, it can be used for different purposes. Autoencoder networks can simply be used as efficient compress/decompress programs. For example, autoencoders trained to compress image files can create images that look far clearer than the same image compressed via JPEG to the same size.</p>
<h4 class="h4" id="lev180"><strong><em>Generative Adversarial Network</em></strong></h4>
<p class="noindent">A <em>generative adversarial network (GAN)</em> is a system of <em>two</em> neural networks competing with each other to improve themselves at their respective tasks. Typically, the <em>generative</em> network tries to create fake samples (for example, some sort of image) from random noise. Then a second <em>discriminator</em> network <span epub:type="pagebreak" id="page_196"/>attempts to tell the difference between real samples and the fake, generated samples (for example, distinguishing between real images of a bedroom and generated images).</p>
<p class="indent">Both neural networks in a GAN are optimized with backpropagation. The generator network optimizes its parameters based on how well it fooled the discriminator network in a given round, while the discriminator network optimizes its parameters based on how accurately it could discriminate between generated and real samples. In other words, their loss functions are direct opposites of one another.</p>
<p class="indent">GANs can be been used to generate real-looking data or enhance low-quality or corrupted data.</p>
<h4 class="h4" id="lev181"><strong><em>Recurrent Neural Network</em></strong></h4>
<p class="noindent"><em>Recurrent networks (RRNs)</em> are a relatively broad class of neural networks in which connections between neurons form directed cycles whose activation functions are dependent on time-steps. This allows the network to develop a memory, which helps it learn patterns in sequences of data. In RNNs, the inputs, the outputs, or both the inputs and outputs are some sort of time series.</p>
<p class="indent">RNNs are great for tasks where data order matters, like connected handwriting recognition, speech recognition, language translation, and time series analysis. In the context of cybersecurity, they’re relevant to problems like network traffic analysis, behavioral detection, and static file analysis. Because program code is similar to natural language in that order matters, it can be treated as a time series.</p>
<p class="indent">One issue with RNNs is that due to the vanishing gradient problem, each time-step introduced in an RNN is similar to an entire extra layer in a feed-forward neural network. During backpropagation, the vanishing gradient problem causes signals in lower-level layers (or in this case, earlier time-steps) to become incredibly faint.</p>
<p class="indent">A <em>long short-term memory (LSTM) network</em> is a special type of RNN designed to address this problem. LSTMs contain <em>memory cells</em> and special neurons that try to decide what information to remember and what information to forget. Tossing out most information greatly limits the vanishing gradient problem because it reduces path explosion.</p>
<h4 class="h4" id="lev182"><strong><em>ResNet</em></strong></h4>
<p class="noindent">A <em>ResNet</em> (short for <em>residual network</em>) is a type of neural network that creates <em>skip connections</em> between neurons in early/shallow layers of the network to deeper layers by skipping one or more intermediate layers. Here the word <em>residual</em> refers to the fact that these networks learn to pass numerical information directly between layers, without that numerical information having to pass through the kinds of activation functions we illustrated in <a href="ch10.xhtml#ch10tab1">Table 10-1</a>.</p>
<p class="indent">This structure helps greatly reduce the vanishing gradient problem, which enables ResNets to be incredibly deep—sometimes more than 100 layers.</p>
<p class="indent"><span epub:type="pagebreak" id="page_197"/>Very deep neural networks excel at modeling extremely complex, odd relationships in input data. Because ResNets are able to have so many layers, they are especially suited to complex problems. Like feed-forward neural networks, ResNets are important more because of their general effectiveness at solving complex problems rather than their expertise in very specific problem areas.</p>
<h3 class="h3" id="lev183"><strong>Summary</strong></h3>
<p class="noindent">In this chapter, you learned about the structure of neurons and how they are connected together to form neural networks. You also explored how these networks are trained via backpropagation, and you discovered some benefits and issues that neural networks have, such as universality, automatic feature generation, and the vanishing gradient problem. Finally, you learned the structures and benefits of a few common types of neural networks.</p>
<p class="indent">In the next chapter, you’ll actually build neural networks to detect malware, using Python’s <code>Keras</code> package.<span epub:type="pagebreak" id="page_198"/></p>
</body></html>