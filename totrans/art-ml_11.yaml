- en: '**8'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**8'
- en: PARAMETRIC METHODS**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**参数化方法**'
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: 'Recall the term *regression function*, first introduced in [Section 1.6](ch01.xhtml#ch01lev6)
    and denoted by *r*(*t*). It’s the mean *Y* in the subpopulation defined by the
    condition *X* = *t*. The example we gave then involved bike ridership data:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下“回归函数”这个术语，它首先出现在[第1.6节](ch01.xhtml#ch01lev6)，并用 *r*(*t*) 表示。它是由条件 *X* =
    *t* 定义的子群体中的 *Y* 的均值。当时我们举的例子是骑行人数数据：
- en: A regression function has as many arguments as we have features. Let’s take
    humidity as a second feature, for instance. To predict ridership for a day with
    temperature 28 and humidity 0.51, we would use the mean ridership in our dataset,
    among days in which temperature and humidity are approximately 28 and 0.51\. In
    regression function notation, that’s *r*(28, 0.51).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 回归函数的参数个数与特征数量相等。举个例子，假设湿度是第二个特征。如果我们要预测一天的骑行人数，已知当天的温度为28度，湿度为0.51，那么我们将使用数据集中温度和湿度接近28和0.51的日子的平均骑行人数。在回归函数表示法中，就是
    *r*(28, 0.51)。
- en: Basically, ML methods all are techniques to estimate the regression function
    from sample data. With k-NN, we would estimate *r*(28, 0.51) in the bike ridership
    example by calculating the mean ridership among the days in the neighborhood of
    (28,0.51). With trees, we would plug (28,0.51) into our tree, follow the proper
    branches, and then calculate the mean ridership in the resulting leaf node, which
    acts like a neighborhood.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，机器学习方法都是从样本数据中估计回归函数的技术。使用 k-NN 方法，我们会通过计算（28, 0.51）附近日期的平均骑行人数来估算 *r*(28,
    0.51)。使用决策树时，我们会将（28, 0.51）输入到树中，沿着适当的分支走，然后计算最终叶节点的平均骑行人数，叶节点就像是一个邻域。
- en: So far, we have not made any assumptions about the shape of the regression function
    graph. In this chapter, we will assume the shape is that of a straight line, or
    planes and so on in higher dimensions.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们并没有对回归函数图形的形状做出任何假设。在本章中，我们将假设回归函数的形状为直线，或者在更高维度下为平面等。
- en: The so-called *linear model* is quite old, a couple of centuries old, actually.
    It can work fairly well in “easy” prediction applications, and even in some “advanced”
    ones. Indeed, we will see in [Section 8.13](ch08.xhtml#ch08lev13) that a variant
    of the linear model can often outperform more sophisticated ML models.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 所谓的*线性模型*实际上已有几个世纪的历史。它在“简单”的预测应用中表现良好，甚至在一些“高级”应用中也能发挥作用。实际上，我们将在[第8.13节](ch08.xhtml#ch08lev13)中看到，线性模型的一个变体往往能超越更复杂的机器学习模型。
- en: The linear model should thus be in every analyst’s toolkit. But an even more
    compelling reason to know the linear model is that it forms the basis of some
    of the most popular and powerful ML algorithms, including the LASSO, support vector
    machines, and neural networks, which we will cover in the succeeding chapters
    of this book.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型应该是每个分析师工具箱中的必备工具。但更有说服力的理由是，线性模型是一些最流行和最强大的机器学习算法的基础，包括 LASSO、支持向量机和神经网络，我们将在本书后续章节中介绍这些内容。
- en: '8.1 Motivating Example: The Baseball Player Data'
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1 动机示例：棒球运动员数据
- en: We’ll soon introduce the `qe*`-series function for linear models, `qeLin()`.
    But to understand what it does, let’s start with a simple setting in which we
    have only one feature and use it to motivate the concept of a linear model.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快将介绍线性模型的 `qe*` 系列函数 `qeLin()`。但是，为了理解它的功能，我们先从一个简单的场景开始，在这个场景中我们只有一个特征，并使用它来激发对线性模型的概念。
- en: 'Recall the dataset `mlb` in [Section 1.8](ch01.xhtml#ch01lev8) that is included
    with `regtools`. Let’s restrict attention to just heights and weights of the players:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下[第1.8节](ch01.xhtml#ch01lev8)中的数据集 `mlb`，它是随 `regtools` 附带的。我们将只关注球员的身高和体重：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, *X* and *Y* will be height and weight, respectively.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*X* 和 *Y* 分别表示身高和体重。
- en: '***8.1.1 A Graph to Guide Our Intuition***'
  id: totrans-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.1.1 一个引导我们直觉的图形***'
- en: So, we are predicting weight from height. In the *r*() notation, that means
    that if we wish to predict the weight of a new player whose height is 71 inches,
    we need to estimate *r*(71). This is the mean weight of all players in the subpopulation
    of players having height 71.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们在预测体重与身高的关系。在 *r*() 表示法中，这意味着如果我们希望预测一个新玩家的体重，而他的身高是 71 英寸，我们需要估算 *r*(71)。这就是所有身高为
    71 的玩家的平均体重。
- en: 'We don’t know population values, as we only have a sample from the population.
    (As noted earlier, we consider our data to be a sample from the population of
    all players, past, present, and future.) How, then, can we estimate *r*(71)? The
    natural estimate is the analogous sample quantity, the mean weight of all height
    71 players in our sample:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不知道总体值，因为我们只有来自总体的一个样本。（如前所述，我们将数据视为来自所有球员的总体样本，包括过去、现在和未来的球员。）那么，我们如何估计 *r*(71)
    呢？自然的估计是类似的样本量，即我们样本中所有身高为 71 的球员的平均体重：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Recalling that the “hat” notation means “estimate of,” we have that ![Image](../images/rcap1.jpg)(71)
    = 190.3596\. With deft usage of R’s `tapply()` function, we can get all the estimated
    *r*() values:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，“帽子”符号表示“估计值”，因此我们有 ![Image](../images/rcap1.jpg)(71) = 190.3596。通过熟练使用
    R 的 `tapply()` 函数，我们可以得到所有估计的 *r*() 值：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This says, “Group the weight values by height, and find the mean weight in
    each group.” By the way, note that the heights are available as the names of the
    weight items:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这表示，“按身高分组体重值，并找到每个组的平均体重。”顺便说一下，注意身高是作为体重项目的名称提供的：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let’s plot the estimated mean weights against height:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制估计的平均体重与身高的关系图：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[Figure 8-1](ch08.xhtml#ch08fig01) shows the result.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-1](ch08.xhtml#ch08fig01) 显示了结果。'
- en: '![Image](../images/ch08fig01.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08fig01.jpg)'
- en: '*Figure 8-1: Estimated regression function, weight vs. height*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 8-1：估计的回归函数，体重与身高的关系*'
- en: Remarkably, the points seem to nearly lie on a straight line. This suggests
    a model for *r*(*t*),
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，这些点似乎几乎都落在一条直线上。这表明可以为 *r*(*t*) 建立一个模型，
- en: '![Image](../images/ch08equ01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ01.jpg)'
- en: for some unknown values of the slope *m* and intercept *b* that we will estimate
    from the data. We are assuming that the graph of *r*(*t*) is *some* straight line,
    though we don’t know which one—that is, we don’t know *b* and *m*. This is the
    linear model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们将从数据中估计的未知的斜率 *m* 和截距 *b*。我们假设 *r*(*t*) 的图形是 *某* 条直线，尽管我们不知道是哪一条——也就是说，我们不知道
    *b* 和 *m*。这就是线性模型。
- en: Keep in mind *r*(*t*) is the *mean Y* for the subpopulation *X* = *t*, so we
    are modeling *mean Y* and not *Y* itself. We are not saying [Equation 8.1](ch08.xhtml#ch08equ01)
    gives us the weight of individual players, though we do use the equation as the
    basis of our predictions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，*r*(*t*) 是子群体 *X* = *t* 的 *平均 Y*，所以我们建模的是 *平均 Y* 而不是 *Y* 本身。我们并不是说 [方程 8.1](ch08.xhtml#ch08equ01)
    给出了单个球员的体重，尽管我们确实使用该方程作为预测的基础。
- en: '***8.1.2 View as Dimension Reduction***'
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.1.2 作为维度约简的视图***'
- en: If [Equation 8.1](ch08.xhtml#ch08equ01) is a valid model, we have greatly simplified
    our problem.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 [方程 8.1](ch08.xhtml#ch08equ01) 是有效的模型，那么我们就大大简化了问题。
- en: Ordinarily, we would need to estimate many different values of *r*(*t*), such
    as those for *t* equal to 68, 69, 70, 71, 72, 73, and so on, say, 15 or 20 of
    them. But with the above model, *we need to estimate only two numbers*, *m* and
    *b*. As such, this is a form of dimension reduction.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们需要估计 *r*(*t*) 的多个不同值，比如 *t* 等于 68、69、70、71、72、73 等等，假设有 15 或 20 个值。但使用上述模型，*我们只需要估计两个数字*，*m*
    和 *b*。因此，这是一种维度约简的形式。
- en: 8.2 The lm() Function
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2 lm() 函数
- en: 'Assuming the linear model (again, we’ll address its validity shortly), we can
    use R’s `lm()` function to estimate *m* and *b*:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 假设线性模型（稍后我们将讨论其有效性），我们可以使用 R 的 `lm()` 函数来估计 *m* 和 *b*：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: So, ![Image](../images/unch08equ01.jpg) and ![Image](../images/unch08equ02.jpg)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 所以， ![Image](../images/unch08equ01.jpg) 和 ![Image](../images/unch08equ02.jpg)
- en: 'Let’s see what this call is saying:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个调用在说什么：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here we are requesting that R fit a linear model to our data frame `hw`, predicting
    weight. The dot (.) means “all other columns,” which, in this case, is just the
    height column.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们要求 R 对我们的数据框 `hw` 拟合一个线性模型，预测体重。点号（.）表示“所有其他列”，在此情况下，仅为身高列。
- en: 'To predict the weight of a new player of height 71, we would compute:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测一个身高为 71 的新球员的体重，我们将计算：
- en: '![Image](../images/ch08equ02.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ02.jpg)'
- en: 'But hey, we should have the computer do this computation rather than do it
    by hand:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，嘿，我们应该让计算机来做这个计算，而不是手工计算：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The slight discrepancy is due to a roundoff error in the computation by hand,
    where our data was given only to a few digits.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 轻微的误差是由于手工计算时的四舍五入误差造成的，我们的数据只提供了几位数字。
- en: '8.3 Wrapper for lm() in the qe*-Series: qeLin()'
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3 lm() 在 qe*-Series 中的封装：qeLin()
- en: The `lm()` function is so basic in R that everyone should see it at least once,
    so we used it in the last section. But for simplicity and uniformity, we will
    use its `qe*`-series wrapper, `qeLin()`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`lm()`函数在R语言中非常基础，每个人至少应该见过一次，因此我们在上一节中使用了它。但为了简化和统一，我们将使用其`qe*`系列封装函数`qeLin()`。'
- en: 'Here’s how to do the above computations in `qeLin()`:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何在`qeLin()`中执行上述计算：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Most applications have more than just one feature. We cover the general case
    next.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数应用程序不仅仅有一个特征。接下来我们将讨论一般情况。
- en: 8.4 Use of Multiple Features
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4 使用多个特征
- en: We can, and typically do, fit the model to more than one feature.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以，并且通常会，拟合多个特征的模型。
- en: '***8.4.1 Example: Baseball Player, Continued***'
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.4.1 示例：棒球运动员，继续***'
- en: 'Say we add in age, so our linear model is:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们加入了年龄，这样我们的线性模型就是：
- en: '![Image](../images/ch08equ03.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ03.jpg)'
- en: For the purpose of terminology (used here and later), let’s write this as
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了术语的统一（这里和后面都使用），我们将其写成：
- en: '![Image](../images/ch08equ04.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ04.jpg)'
- en: where *D* is an artificial variable that is always equal to 1\. Then we say
    that mean weight is a *linear combination* of the variables *D*, *height*, and
    *age*. This is just a term meaning that to get mean weight, we multiply each of
    the three variables *D*, *height*, and *age* by the corresponding coefficients
    *b*, *m*[1], and *m*[2] and sum up the result.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*D*是一个人工变量，总是等于1。然后我们说，平均体重是*D*、*身高*和*年龄*这三个变量的*线性组合*。这只是一个术语，意思是为了得到平均体重，我们将这三个变量*D*、*身高*和*年龄*分别乘以对应的系数*b*、*m*[1]和*m*[2]，然后将结果求和。
- en: 'We now are using columns 4, 5, and 6 of `mlb`, so we fit the model as follows,
    say, for age 28:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用`mlb`的第4、5、6列，因此我们按如下方式拟合模型，例如，对于28岁：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '***8.4.2 Beta Notation***'
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.4.2 β符号***'
- en: 'Since the reader of this book will likely see other discussions, say, on the
    web, it should be mentioned that it’s traditional to use the Greek letter *β*
    for the coefficients. For instance, [Equation 8.3](ch08.xhtml#ch08equ03) would
    be written as:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书的读者可能会在网络上看到其他相关讨论，因此需要提到，通常使用希腊字母*β*表示系数。例如，[公式 8.3](ch08.xhtml#ch08equ03)可以写成如下形式：
- en: '![Image](../images/ch08equ05.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ05.jpg)'
- en: We will estimate *β*[0], *β*[1], and *β*[2] from our sample data, as seen in
    [Section 8.4.4](ch08.xhtml#ch08lev4sec4). And, recalling that we use the hat notation
    for estimates, our estimated coefficients will be denoted by ![Image](../images/unch08equ03.jpg)
    and ![Image](../images/unch08equ04.jpg).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从我们的样本数据中估计*β*[0]、*β*[1]和*β*[2]，如在[第8.4.4节](ch08.xhtml#ch08lev4sec4)中所见。而且，回顾一下，我们使用“帽子符号”表示估计值，因此我们的估计系数将表示为
    ![Image](../images/unch08equ03.jpg) 和 ![Image](../images/unch08equ04.jpg)。
- en: '***8.4.3 Example: Airbnb Data***'
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.4.3 示例：Airbnb 数据***'
- en: The short-term housing firm Airbnb makes available voluminous rental data. Here
    we look at some data from San Francisco.^([1](footnote.xhtml#ch8fn1)) (The dataset
    used here, from February 1, 2019, appears to no longer be available.) It will
    not only provide another example of the linear model, but it also will illustrate
    some data-cleaning issues.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 短期租赁公司Airbnb提供了大量的租赁数据。这里我们查看了来自旧金山的一些数据。^([1](footnote.xhtml#ch8fn1))（这里使用的数据集来自2019年2月1日，似乎现在已经不再可用。）这不仅提供了线性模型的另一个示例，而且还将展示一些数据清理问题。
- en: 8.4.3.1 Data Preparation
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 8.4.3.1 数据准备
- en: After downloading the data and reading it into R (details not shown), we had
    a data frame `Abb`, which still required a lot of attention.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在下载数据并将其读入R后（细节省略），我们得到了一个数据框`Abb`，但它仍然需要很多注意。
- en: 'Many of the features are textual, for example:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 许多特征是文本数据，例如：
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We will treat the topic of text data later in this book but removed it for this
    example.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本书稍后会讨论文本数据的主题，但为了这个示例，我们暂时省略了该部分。
- en: 'Another problem is that prices include dollar signs and commas, for example:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是价格包含美元符号和逗号，例如：
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Dealing with such issues tends to take up a remarkably large portion of a data
    scientist’s job. Here we wrote a function to convert a column `d` of such numbers
    to the proper form, using a couple of R’s character string manipulation facilities:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 处理此类问题往往占据数据科学家工作的大部分时间。这里我们编写了一个函数，将此类数字的列`d`转换为正确的格式，使用了R语言的一些字符字符串操作功能：
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And, not surprisingly, this dataset seems to have its share of erroneous entries:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 而且，毫不奇怪，这个数据集似乎也有一些错误的条目：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: For instance, areas of 1 and 2 square feet are listed, obviously incorrect.
    We will not pursue this further here, but clearly we would have a lot more work
    to do if this were not merely an example for the book.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，列出1和2平方英尺的区域，显然这是不正确的。我们在这里不再深入探讨，但显然，如果这不仅仅是书中的一个示例，我们将需要做更多的工作。
- en: 'After data cleaning, the data frame looks like this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清理后，数据框架如下所示：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We are now ready to perform the analysis.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备进行分析了。
- en: '***8.4.4 Applying the Linear Model***'
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.4.4 应用线性模型***'
- en: 'Here is the call, omitting the square footage and weekly price columns:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这是调用，省略了面积和周价格列：
- en: '[PRE15]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As is common in R, the estimated coefficients are displayed here in *scientific
    notation*, in which, for instance, 1.605326*e* + 03 = 1.605326 × 10³ = 1605.326\.
    So, for instance, ![Image](../images/unch08equ05.jpg) is about −4,486, ![Image](../images/unch08equ06.jpg)
    is about −444, and so on.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在 R 中常见的那样，估计的系数以*科学计数法*显示，例如，1.605326*e* + 03 = 1.605326 × 10³ = 1605.326。比如说，![Image](../images/unch08equ05.jpg)
    大约是 −4,486，![Image](../images/unch08equ06.jpg) 大约是 −444，依此类推。
- en: Note that `lm()` (via its wrapper `qeLin()`) has converted the ZIP code feature,
    an R factor, to dummy variables. Recall that typically we have one fewer dummy
    than the number of categories—in this case, the number of ZIP codes. R leaves
    out the first one here, which is 94102.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`lm()`（通过其封装函数`qeLin()`）已将邮政编码特征，一个 R 因子，转换为虚拟变量。回想一下，通常我们会比类别的数量少一个虚拟变量——在这里是邮政编码的数量。R
    在这里省略了第一个，即94102。
- en: Since our focus in this book is on prediction rather than causal interpretation,
    the estimated coefficients are of lesser interest. Furthermore, one must be very
    careful in interpreting coefficients. Nevertheless, some comments regarding the
    coefficients are in order, next.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书的重点是预测而非因果解释，因此估计的系数并不是特别重要。此外，在解释系数时必须非常小心。然而，关于这些系数，接下来需要做一些说明。
- en: 8.5 Dimension Reduction
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5 降维
- en: Let’s discuss this fundamental ML topic in the context of linear models and
    the Airbnb example in the previous section.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在前一节的线性模型和Airbnb示例的背景下讨论这个基本的机器学习话题。
- en: '***8.5.1 Which Features Are Important?***'
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.5.1 哪些特征是重要的？***'
- en: As noted in [Section 3.1.1](ch03.xhtml#ch03lev1sec1), there are more than 40,000
    ZIP codes in the United States; this is typically far too many to use directly.
    In San Francisco, the number is manageable, but still we may wish to drop the
    ones that seem unimportant to our predictions.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第3.1.1节](ch03.xhtml#ch03lev1sec1)所述，美国有超过40,000个邮政编码；这通常远远超过了可以直接使用的数量。在旧金山，这个数量是可管理的，但我们可能还是希望去掉那些对预测似乎不重要的邮政编码。
- en: On the other hand, as real estate agents say, “Location, location, location.”
    ZIP code should matter a lot, and the estimated coefficients at least seem to
    confirm this. For instance, according to the coefficient estimates given earlier,
    a property in ZIP code 94105, on average, commands a price premium of about $1,012,
    while one in 94107 will, on average, cost about $285 below market, holding all
    other variables fixed. But what are the terms *premium* and *cost less* relative
    to here? Since ZIP code 94102 was omitted, we see that 94105 costs about $1,012
    more on average than 94102—the ZIP code term in ![Image](../images/rcap1.jpg)(*t*)
    would be about 1 · 1012 for a property in that ZIP code, while it would be 0 for
    one in 94102, since there is no dummy variable for that ZIP code. Similarly, 94107
    runs about $444 below 94102, and so on. In other words, 94102 becomes the baseline
    ZIP code.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，正如房地产经纪人所说：“位置，位置，位置。”邮政编码应该非常重要，且估计的系数至少似乎证实了这一点。例如，根据之前给出的系数估计，位于94105邮政编码的房产，平均来说，其价格溢价大约为1,012美元，而位于94107的房产，平均而言，其价格低于市场价大约285美元，假设其他变量保持不变。那么，*溢价*和*低于成本*是相对于什么而言的呢？由于省略了94102邮政编码，我们看到94105的价格平均比94102高出1,012美元——在![Image](../images/rcap1.jpg)(*t*)中的邮政编码项将是1·1012，对于该邮政编码的房产，而94102则为0，因为没有该邮政编码的虚拟变量。类似地，94107的价格比94102低大约444美元，依此类推。换句话说，94102成为基准邮政编码。
- en: 'But . . . note the phrasing above: “the estimated coefficients at least *seem*
    to confirm this.” After all, we are working with *estimates* of finite accuracy.
    This is a vital point to take into account, which we will do next.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 但是……注意上面的措辞：“估计的系数至少*似乎*证实了这一点。”毕竟，我们所做的是*有限准确度*的估计。这是一个必须考虑的关键点，接下来我们将讨论。
- en: On the other hand, the amount of `security_deposit` seems not to matter much
    at all, so we should consider dropping it from our analysis. Recall that having
    more features means less bias but more variance. Since the effect of a security
    deposit in prediction values seems small, dropping this feature should add very
    little bias. The same statement holds for the features `minimum_nights` and `maximum_nights`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`security_deposit` 的数量似乎并没有太大影响，因此我们应该考虑将其从分析中删除。回想一下，更多的特征意味着更少的偏差，但更多的方差。由于保证金在预测值中的影响似乎很小，删除这一特征应当不会增加太多的偏差。对于
    `minimum_nights` 和 `maximum_nights` 特征，情况也是如此。
- en: '***8.5.2 Statistical Significance and Dimension Reduction***'
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.5.2 统计显著性与降维***'
- en: In the previous section, we suggested several features to drop from our analysis.
    But we did so only on the basis of a “feeling.” It is natural to desire some magic
    formula that will determine which features to retain and which to remove. But
    alas, as has been explained in this book, no such magic formula exists. We have
    cited a few methods, such as cross-validation and PCA, that are commonly used,
    but again, these are not magic, foolproof solutions.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们建议从分析中删除几个特征。但我们仅仅是凭借一种“直觉”来做这个决定。人们自然会希望有一个神奇的公式来决定保留哪些特征，删除哪些特征。然而，正如本书所解释的那样，实际上并没有这样的神奇公式。我们列举了一些常用的方法，比如交叉验证和主成分分析（PCA），但这些方法也不是万能的、万无一失的解决方案。
- en: In this section, we look at the use of *statistical significance* for dimension
    reduction in parametric models. *We do not recommend it*, and it is less favored
    than in the past, but it is still popular among many analysts. Thus, it is imperative
    to cover the technique here.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，我们将讨论*统计显著性*在参数模型中用于降维的应用。*我们不推荐使用它*，而且它的受欢迎程度比过去低了，但仍然在许多分析师中流行。因此，有必要在这里介绍这一技术。
- en: First, we will need to introduce a new R generic function ([Section 1.5.1](ch01.xhtml#ch01lev5sec1)).
    In addition to `print()`, `plot()`, and `predict()`, another common generic function
    in R is `summary()`. It does what its name implies; that is, it provides a summary
    of the object.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要介绍一个新的 R 通用函数（[第 1.5.1 节](ch01.xhtml#ch01lev5sec1)）。除了 `print()`、`plot()`
    和 `predict()`，R 中另一个常见的通用函数是 `summary()`。它的功能正如其名字所示；也就是说，它提供了对象的摘要信息。
- en: Recall that a generic function is tailored to the class of the object at hand.
    What is the class of our object here, `linout`?
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，通用函数是根据当前对象的类别量身定制的。我们这里的对象 `linout` 的类别是什么？
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'So, if we make the call `summary(linout)`, the R interpreter will first check
    for a function `summary.qeLin()`. Since the `qeML` package has no such function,
    the interpreter will next look for `summary.lm()`, which does exist. Let’s see
    what the function gives us:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们调用 `summary(linout)`，R 解释器会首先查找 `summary.qeLin()` 函数。由于 `qeML` 包中没有此函数，解释器接着会查找
    `summary.lm()`，它是存在的。我们来看一下这个函数给我们提供的内容：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: One particular type of information computed here is standard errors, discussed
    next.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里计算的一个特定类型的信息是标准误差，接下来会讨论。
- en: 8.5.2.1 Standard Errors
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 8.5.2.1 标准误差
- en: You can see above that a *standard error* is reported for each estimated coefficient
    ![Image](../images/unch08equ07.jpg). It’s the estimated standard deviation of
    ![Image](../images/unch08equ07.jpg) over all possible samples for whatever population
    is being sampled. This gives us an idea as to how accurate ![Image](../images/unch08equ07.jpg)
    is, using the following reasoning.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，上面报告了每个估计系数的*标准误差* ![Image](../images/unch08equ07.jpg)。这是对于所采样的总体，所有可能样本的
    ![Image](../images/unch08equ07.jpg) 的标准偏差估计。这让我们可以通过以下推理来了解 ![Image](../images/unch08equ07.jpg)
    的准确度。
- en: If the standard error is small, it says that if we had had a different set of
    sample data from the given population, ![Image](../images/unch08equ07.jpg) probably
    would have come out to about the same value as what we got. In other words, we
    can treat ![Image](../images/unch08equ07.jpg) as representative.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果标准误差很小，这意味着如果我们使用与给定总体不同的一组样本数据，![Image](../images/unch08equ07.jpg) 可能会得到与我们当前值差不多的结果。换句话说，我们可以将
    ![Image](../images/unch08equ07.jpg) 视为具有代表性。
- en: We can form an approximate 95 percent confidence interval (CI) for *β*[*i*]
    by adding and subtracting 1.96 times the standard error of ![Image](../images/unch08equ07.jpg).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过加减 1.96 倍的标准误差来形成一个大约 95% 的置信区间（CI）来估计 *β*[*i*]。
- en: 'For instance, consider the dummy variable `zipcode94134`. The estimated beta
    coefficient for this variable is −$1,370\. This is relative to whichever ZIP code
    is the base, meaning the one for which there is no dummy variable. (Recall from
    [Section 1.4](ch01.xhtml#ch01lev4) that with a categorical feature, we have one
    fewer dummy than the number of categories.) As noted earlier, the omitted ZIP
    code is 94102\. So, for a given security deposit, guest policy, and so on, this
    neighborhood is estimated to be more than $1,000 cheaper than the baseline. But
    look at the CI:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑虚拟变量`zipcode94134`。该变量的估计beta系数为−$1,370\。这是相对于基准的邮政编码而言，也就是说，指没有虚拟变量的那个邮政编码。（回想一下[第1.4节](ch01.xhtml#ch01lev4)，当我们有一个分类特征时，虚拟变量的数量比类别数少1。）如前所述，被省略的邮政编码是94102\。因此，对于某个特定的安全押金、客人政策等，该地区的价格估计比基准低超过$1,000。但看看置信区间（CI）：
- en: '![Image](../images/ch08equ06.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ06.jpg)'
- en: The CI suggests that this neighborhood actually could be hundreds of dollars
    more *expensive* than the base.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间显示，这个地区实际上可能比基准地区*贵*上几百美元。
- en: 8.5.2.2 Significance Tests
  id: totrans-111
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 8.5.2.2 显著性检验
- en: That last example suggests that the status of `zipcode94134` as a predictor
    of rent is inconclusive. We should thus seriously consider dropping it from our
    model. Remember the notion of the Bias-Variance Trade-off means that if a feature
    is not very helpful, then including it in our model may degrade our predictive
    ability.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的这个例子表明，`zipcode94134`作为租金预测因子的状态尚无定论。因此，我们应该认真考虑将其从模型中去除。记住，偏差-方差权衡的概念意味着，如果某个特征并不特别有用，那么将其纳入模型可能会降低我们的预测能力。
- en: But let’s consider another ZIP code, say, 94132\. Here the CI is
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，让我们考虑另一个邮政编码，比如94132\。这里的置信区间是
- en: '![Image](../images/ch08equ07.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ07.jpg)'
- en: which is entirely in negative territory. For this reason, it is flagged with
    an asterisk.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间完全位于负值范围。因此，它被标记了一个星号。
- en: What do all those asterisks mean? Why are there double asterisks for some coefficients?
    Our focus in this book is not on statistics, but it is important for the reader
    to have at least an overview of the situation since it is common to use the asterisks
    as a guide for dimension reduction.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这些星号到底是什么意思？为什么某些系数有双星号？本书的重点不在统计学上，但对读者来说至少了解这个情况是很重要的，因为通常使用星号作为降维的指南。
- en: Roughly speaking, if the CI does not contain 0, the coefficient is flagged with
    an asterisk. It rates *two* asterisks if 0 is well outside the interval and three
    if the CI is far, far away from 0\. A coefficient with one asterisk is termed
    *significant* (that is, significantly different from 0); one with two asterisks
    is called *highly significant*, and three asterisks wins a coefficient the accolade
    *very highly significant*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 大致来说，如果置信区间不包含0，那么系数就会被标记一个星号。如果0远离区间，则标记两个星号；如果置信区间远离0，则标记三个星号。带一个星号的系数称为*显著*（即，与0显著不同）；带两个星号的称为*高度显著*，三个星号则获得*非常高度显著*的称号。
- en: Well then, what constitutes “well outside the interval” and “far, far away from
    0”? This is determined by the p-value. A p-value under 0.05 is significant, and
    it is highly or very highly significant if it is under 0.01 or 0.001, respectively.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么算是“远远超出区间”和“远远远离0”呢？这是由p值决定的。p值低于0.05是显著的，低于0.01或0.001则分别表示高度显著或非常高度显著。
- en: The p-value is a certain probability whose convoluted definition we will skip.
    (Recall this term from [Section 5.5](ch05.xhtml#ch05lev5).) Suffice it to say,
    under this approach to dimension reduction, one discards any feature with no asterisks,
    such as `zipcode94134`, and retains the others in the model. If one wants to exercise
    a little more caution, one might retain only the coefficients with at least two
    asterisks.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: p值是一个特定的概率，其复杂的定义我们暂时跳过。（回想一下[第5.5节](ch05.xhtml#ch05lev5)中的这个术语。）可以简单地说，在这种降维方法下，任何没有星号的特征，比如`zipcode94134`，都会被舍弃，其他特征则保留在模型中。如果想稍微谨慎一点，也可以只保留那些至少有两个星号的系数。
- en: Today, many analysts, including myself, consider this approach to be flawed.
    Let’s see why. The short answer is that p-values are too dependent on the number
    of data points *n*. Actually, the standard error is inversely proportional to
    ![Image](../images/unch08equ08.jpg). This has quite an implication, as follows.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，包括我自己在内的许多分析师认为这种方法存在缺陷。让我们来看一下为什么。简短的回答是，p值过于依赖数据点的数量*n*。实际上，标准误差与![Image](../images/unch08equ08.jpg)成反比。这有一个相当深远的影响，具体如下。
- en: 'Suppose, hypothetically, that the estimated coefficient for, say, `zipcode94132`
    had been 1.4, with a standard error of 0.9\. That would give us a confidence interval
    of:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 假设，假设`zipcode94132`的估计系数为1.4，标准误差为0.9\。那么我们可以得到一个置信区间：
- en: '![Image](../images/ch08equ08.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ08.jpg)'
- en: 'This contains 0, hence no asterisks. And that’s probably a good thing, since
    this feature seems to have no real predictive power: being in that ZIP code makes
    an estimated difference in rent of only a dollar or so.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这包含0，因此没有星号。这可能是件好事，因为这个特征似乎没有实际的预测能力：在这个邮政编码中，租金的估计差异只有一美元左右。
- en: 'But what if we were fortunate to have 25 times as much data? Then ![Images](../images/unch08equ08.jpg)
    would increase by a factor of 5, so the standard error would shrink by a factor
    of 5, coming out at approximately 0.18\. It would change somewhat, as would the
    coefficient estimate 1.4, but in rough terms our CI would now be something like:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果我们幸运地拥有25倍的数据呢？那么![Images](../images/unch08equ08.jpg)将增加5倍，因此标准误差将缩小5倍，约为0.18\。它会有所变化，系数估计值1.4也会有所变化，但大体上我们的CI现在将是：
- en: '![Image](../images/ch08equ09.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ09.jpg)'
- en: Ah, now it’s significant! Yay! But . . . the estimated coefficient would still
    be something like $1.40—less than $2! That variable can hardly help us predict
    rent. In other words, the so-called significant nature of that feature could really
    lead us astray.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 啊，现在它变得显著了！太好了！但是……估计系数仍然大概是1.40美元——不到2美元！这个变量几乎无法帮助我们预测租金。换句话说，这个特征的所谓显著性可能会误导我们。
- en: Use of significance tests and p-values is frowned upon by many statisticians
    (including this author).^([2](footnote.xhtml#ch8fn2)) The tests are especially
    unreliable in prediction applications. With large datasets, *every* feature will
    be declared “very highly significant” (three asterisks) regardless of whether
    the feature has substantial predictive power. A feature with a very small regression
    coefficient could be declared “significant,” in spite of being essentially useless
    as a predictor.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 许多统计学家（包括本文作者）对使用显著性检验和p值持反对态度。^([2](footnote.xhtml#ch8fn2))这些检验在预测应用中尤其不可靠。对于大数据集，*每个*特征都会被声明为“非常显著”（三个星号），无论该特征是否具有实质性的预测能力。一个回归系数非常小的特征也可能被声明为“显著”，尽管它在预测中几乎没有用处。
- en: '8.5.2.3 Pitfall: NA Values and Impact on n'
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 8.5.2.3 陷阱：NA值及其对n的影响
- en: As shown above, this dataset also includes a number of NA values. We didn’t
    have to deal with this directly, since `lm()`, which `qeLin()` wraps, automatically
    restricts its computations to complete cases. Nevertheless, as noted in [Section
    4.1](ch04.xhtml#ch04lev1), if a dataset contains many NAs, this is yet another
    reason to seek dimension reduction, as doing so may increase the number of complete
    cases. This means less variance, which is very desirable. Some experimentation
    here reveals that removal of the most NA-prone features, beyond the ones we’ve
    already deleted, does not help increase data size in this particular case, but
    it is an important general principle.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，数据集还包括一些NA值。我们不需要直接处理这些NA值，因为`lm()`（`qeLin()`所包装的函数）会自动将计算限制在完整的案例中。然而，正如在[第4.1节](ch04.xhtml#ch04lev1)中所指出的，如果数据集包含许多NA值，这又是另一个需要进行维度减少的原因，因为这样做可能会增加完整案例的数量。这意味着方差较小，这是非常可取的。通过一些实验，我们发现，去除那些NA倾向较大的特征（除了我们已经删除的特征）并不会在这个特定案例中帮助增加数据量，但这是一个重要的普遍原则。
- en: '8.5.2.4 Pitfall: Difficulty of Forming Holdout Sets with Many-Level Categoricals'
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 8.5.2.4 陷阱：具有多级分类变量的保留集形成困难
- en: 'In our earlier Airbnb analysis, problems occur if we form a holdout set:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的Airbnb分析中，如果我们形成一个保留集，就会出现问题：
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Of course, since the holdout set is chosen randomly, there may be a different
    result each time. But we see that in each of our two tries here, we had at least
    one error, “factor zipcode has new levels.” What is happening here?
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，由于保留集是随机选择的，因此每次可能会有不同的结果。但我们看到，在我们这里的两次尝试中，每次至少有一个错误，“因子邮政编码有新水平。”这里发生了什么？
- en: The problem is that certain ZIP codes, such as 94014, appear in only a few data
    points. Apparently there were no 94014 cases in each training set here, so lm()
    *was “surprised” to see one in the holdout set.*
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，某些邮政编码（如94014）仅出现在少数数据点中。显然，在这里的每个训练集中都没有94014的案例，因此`lm()` *对在保留集中看到一个表示“感到惊讶”。*
- en: The only solution would be to remove all cases with 94014 (and possibly others)
    from the data before running `qeLin()`.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的解决办法是在运行`qeLin()`之前从数据中删除所有包含94014（以及可能的其他）案例。
- en: 8.6 Least Squares and Residuals
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6 最小二乘法和残差
- en: Even though the computational details underlying `lm()` are beyond the scope
    of this book, it’s important to have a rough idea of what is involved, as similar
    computations will arise later in the book. This will bring in the notion of *least
    squares*. That, in turn, will lead to the idea of *residuals*, which are important
    in their own right.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管`lm()`背后的计算细节超出了本书的范围，但大致了解所涉及的内容是很重要的，因为类似的计算将在本书后续出现。这将引入*最小二乘法*的概念。接着，这将引导出*残差*的概念，它们本身也很重要。
- en: For simplicity, let’s consider the context of [Section 8.2](ch08.xhtml#ch08lev2)
    here. The quantities ![Image](../images/unch08equ09.jpg) and ![Image](../images/unch08equ10.jpg)
    and so on are computed using the famous *ordinary least squares (OLS)* method,
    which works as follows.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为简便起见，我们这里考虑[第8.2节](ch08.xhtml#ch08lev2)的上下文。数量 ![Image](../images/unch08equ09.jpg)
    和 ![Image](../images/unch08equ10.jpg) 等是使用著名的*普通最小二乘法（OLS）*方法计算得出的，其原理如下。
- en: 'Imagine that after we compute ![Image](../images/unch08equ09.jpg) and ![Image](../images/unch08equ10.jpg),
    we go back and “predict” the weight of the first player in our sample data. As
    implied by the quotation marks, this would be silly; after all, we already know
    the weight of the first player, 180:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，在计算出 ![Image](../images/unch08equ09.jpg) 和 ![Image](../images/unch08equ10.jpg)
    后，我们回过头来“预测”样本数据中第一个玩家的体重。正如引号所示，这样做是愚蠢的；毕竟，我们已经知道第一个玩家的体重是180：
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: But think through this exercise anyway. It will turn out to be the basis for
    how things work, both for linear models and all the ML methods in the remainder
    of the book.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 但无论如何，还是要思考这个练习。最终这将成为事物运作的基础，既适用于线性模型，也适用于本书其余部分的所有机器学习方法。
- en: 'Our predicted value would be ![Image](../images/unch08equ11.jpg). Thus our
    prediction error would be:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预测的值将是 ![Image](../images/unch08equ11.jpg)。因此，我们的预测误差为：
- en: '![Image](../images/unch08equ12.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/unch08equ12.jpg)'
- en: 'This is the *residual* for that row in the dataset. (Recall that this was briefly
    mentioned in [Section 6.3.2](ch06.xhtml#ch06lev3sec2).) We’ll square that error
    rather than using it in its raw form, as we will be summing errors and don’t want
    positive and negative ones to cancel. Now we “predict” all the other data points
    as well, and add up the squared errors:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据集中该行的*残差*。（回想一下，这在[第6.3.2节](ch06.xhtml#ch06lev3sec2)中有简要提到。）我们将对该误差进行平方，而不是直接使用它的原始形式，因为我们将对误差进行求和，而不希望正误差和负误差互相抵消。现在，我们也“预测”所有其他数据点，并将平方误差相加：
- en: '![Image](../images/ch08equ10.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ10.jpg)'
- en: 'Now here is the point: the way `lm()` finds ![Image](../images/unch08equ10.jpg)
    and ![Image](../images/unch08equ09.jpg) is to set them to whatever values minimize
    the sum of squares ([Equation 8.10](ch08.xhtml#ch08equ10)). In other words, think
    of the expression as a function of two variables, ![Image](../images/unch08equ10.jpg)
    and ![Image](../images/unch08equ09.jpg), and then minimize the expression with
    respect to those two variables. (Readers who know calculus may have spotted the
    fact that we set the two derivatives equal to 0 and solve for ![Image](../images/unch08equ10.jpg)
    and ![Image](../images/unch08equ09.jpg).)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在要注意的是：`lm()`找到 ![Image](../images/unch08equ10.jpg) 和 ![Image](../images/unch08equ09.jpg)
    的方式是将它们设置为能够最小化平方和的值（[方程式8.10](ch08.xhtml#ch08equ10)）。换句话说，把这个表达式看作是两个变量 ![Image](../images/unch08equ10.jpg)
    和 ![Image](../images/unch08equ09.jpg) 的函数，然后对这两个变量最小化该表达式。（懂微积分的读者可能已经注意到，我们将这两个导数设为0并解出
    ![Image](../images/unch08equ10.jpg) 和 ![Image](../images/unch08equ09.jpg)。）
- en: Since we are minimizing a sum of squares, the estimated coefficients are said
    to be the *least squares estimates*. (The word *ordinary* is often added, as ordinary
    least squares is distinct from some variants that we will not discuss here.)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们是在最小化平方和，估计的系数被称为*最小二乘估计*。（通常会加上“普通”一词，因为普通最小二乘法与一些我们在这里不讨论的变体不同。）
- en: '8.7 Diagnostics: Is the Linear Model Valid?'
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.7 诊断：线性模型是否有效？
- en: '*All models are wrong, but some are useful.*'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '*所有模型都是错误的，但有些是有用的。*'
- en: —George Box, famous early statistician
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: —乔治·博克斯，著名的早期统计学家
- en: The linearity assumption is pretty strong. When is it appropriate? Let’s take
    a closer look.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 线性假设是相当强的。这何时适用？让我们仔细看看。
- en: '***8.7.1 Exactness?***'
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.7.1 精确性？***'
- en: 'The reader may ask, “How can the linear model in [Equation 8.1](ch08.xhtml#ch08equ01)
    be valid?” Yes, the points in [Figure 8-1](ch08.xhtml#ch08fig01) look like they
    are kind of on a straight line, but not exactly so. There are two important answers:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 读者可能会问：“[方程式8.1](ch08.xhtml#ch08equ01)中的线性模型如何有效？”是的，[图8-1](ch08.xhtml#ch08fig01)中的点看起来似乎大致位于一条直线上，但并不完全如此。这里有两个重要的回答：
- en: As the quote from George Box points out, no model is *exactly* correct. Commonly
    used physics models ignore things like air resistance and friction, and even models
    accounting for such things still don’t reflect all possible factors. A linear
    approximation to the regression function *r*(*t*) may do a fine job in prediction
    even if the model is not perfect.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如乔治·博克斯的名言所指出的，没有模型是*完全*正确的。常用的物理模型忽略了空气阻力和摩擦等因素，即使是考虑了这些因素的模型，也无法反映所有可能的因素。即便线性回归函数*r*（*t*）的模型并不完美，它在预测方面也可能表现得很好。
- en: Even if [Equation 8.1](ch08.xhtml#ch08equ01) were exactly correct, the points
    in [Figure 8-1](ch08.xhtml#ch08fig01) would not lie exactly on the line. Remember,
    *r*(71), for instance, is only the *mean* weight of all players of height 71\.
    Most individual players of that height are heavier or lighter than that value,
    so their data points will not fall exactly on that line and, in fact, may be far
    from it in some cases. And the same point holds for the mean weights that we plotted
    in [Figure 8-1](ch08.xhtml#ch08fig01); each of those means were based on only
    a few players.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使[方程式8.1](ch08.xhtml#ch08equ01)完全正确，[图8-1](ch08.xhtml#ch08fig01)中的点也不会精确地落在直线上。记住，*r*(71)只是所有71身高球员的*平均*体重。大多数该身高的球员体重大于或小于这个值，因此他们的数据点不会完全落在直线上，事实上，在某些情况下可能远离直线。同样，[图8-1](ch08.xhtml#ch08fig01)中我们绘制的平均体重也有类似的问题；每个平均值都是基于少数几个球员的数据。
- en: By the way, classical linear model methodology makes some assumptions beyond
    linearity, such as *Y* having a normal distribution in each subpopulation. But
    these are not relevant to our prediction context. (Actually, even for statistical
    inference, the normality assumption is not important in large samples.)
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，经典的线性模型方法论有一些假设，超出了线性假设的范围，比如假设*Y*在每个子群体中服从正态分布。但这些假设对于我们的预测背景并不相关。（实际上，即使是在统计推断中，正态性假设在大样本中也不是很重要。）
- en: '***8.7.2 Diagnostic Methods***'
  id: totrans-157
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.7.2 诊断方法***'
- en: 'Over the years, analysts have developed a number of methods to check the validity
    of the linear model. Several are described in my book *Statistical Regression
    and Classification: From Linear Models to Machine Learning* (CRC Press, 2017).'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，分析师们已经开发了多种方法来检验线性模型的有效性。我在我的书《*统计回归与分类：从线性模型到机器学习*》（CRC Press, 2017）中描述了几种方法。
- en: Again, since we are interested in prediction rather than causal analysis, we
    will not cover this material here. As long as the outcome variable is an increasing
    or decreasing function of the features—for example, mean human weight is an increasing
    function of height—a linear model should do fairly well in prediction-oriented
    applications. With linear polynomial models (see [Section 8.11](ch08.xhtml#ch08lev11)),
    this can be refined.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，由于我们关注的是预测而非因果分析，这部分内容我们将在此不予讨论。只要结果变量是特征的递增或递减函数——例如，人的平均体重是身高的递增函数——线性模型应该能在以预测为导向的应用中表现得相当好。通过线性多项式模型（参见[第8.11节](ch08.xhtml#ch08lev11)），这一点可以进一步完善。
- en: 8.8 The R-Squared Value(s)
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.8 R平方值
- en: Recall that the estimated coefficients are calculated by minimizing the sum
    of squared differences between actual and predicted *Y* values (see [Section 8.6](ch08.xhtml#ch08lev6)).
    *R*² is the squared correlation between actual and predicted *Y*.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，估计的回归系数是通过最小化实际和预测*Y*值之间的平方差之和来计算的（参见[第8.6节](ch08.xhtml#ch08lev6)）。*R*²是实际和预测*Y*之间的平方相关性。
- en: It can be shown that this can be interpreted as the proportion of variation
    in *Y* due to *X*. (As always, *X* refers collectively to all our features.) As
    such, we have 0 ≤ *R*² ≤ 1, with a value of 1 meaning that *X* perfectly predicts
    *Y*. However, there is a big problem here, as we are predicting the same data
    that we used to estimate our prediction machine, the regression coefficients.
    If we are overfitting, then *R*² will be overly optimistic.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明，这可以被解释为由于*X*引起的*Y*变异的比例。（和往常一样，*X*指的是我们所有的特征。）因此，*R*²的值范围是0 ≤ *R*² ≤ 1，值为1表示*X*能完美预测*Y*。然而，这里存在一个大问题，因为我们正在预测的正是我们用来估计预测模型（回归系数）的数据。如果我们出现过拟合，那么*R*²将显得过于乐观。
- en: This, of course, is the motivation for using holdout data. Thus `qeLin()` reports
    not only the standard *R*² but also the *R*² calculated on the holdout set (stored
    in the `holdoutR2` component of the `qeLin()` return value). The latter is more
    reliable. Furthermore, if there is a large discrepancy between the two, it suggests
    that we are overfitting.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这，当然，就是使用保留数据集的动机。因此，`qeLin()`不仅报告标准的*R*²值，还报告在保留集上计算的*R*²值（存储在`qeLin()`返回值的`holdoutR2`组件中）。后者更可靠。此外，如果这两个值之间有较大差异，表明我们发生了过拟合。
- en: Most linear regression software libraries also report the *adjusted R*² value.
    The word *adjusted* here alludes to the fact that the formula attempts to correct
    for overfitting. The `qeLin()` reports this too, and again a large discrepancy
    between this value and the first *R*² value suggests we are overfitting.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数线性回归软件库也会报告*调整后的 R*²值。这里的*调整*一词暗示着公式试图修正过拟合的情况。`qeLin()`也报告这个值，且如果这个值与第一个*R*²值之间存在较大差异，则表明我们正在发生过拟合。
- en: '8.9 Classification Applications: The Logistic Model'
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.9 分类应用：*logistic*模型
- en: The linear model is designed for regression applications. What about classification?
    A generalization of the linear model, unsurprisingly called the *generalized linear
    model*, handles that. Here we will present one form of the model, the *logistic*
    model.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型是为回归应用设计的。那么分类问题呢？线性模型的一个推广，毫不奇怪地被称为*广义线性模型*，用于处理分类问题。这里我们将介绍该模型的一种形式——*logistic*模型。
- en: Recall the discussion at the beginning of [Chapter 2](ch02.xhtml), which pointed
    out that in classification settings, where *Y* is either 1 or 0, the regression
    function becomes the probability of *Y* = 1 for the given subpopulation. If we
    fit a purely linear model with `lm()`, the estimated regression values may be
    outside the interval [0,1] and thus not represent a probability. We could, of
    course, truncate any value predicted by `lm()` to [0,1], but the *logistic* model
    provides a better approach.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下[第2章](ch02.xhtml)开头的讨论，指出在分类问题中，*Y*的值要么是1，要么是0，回归函数变成了给定子群体中*Y* = 1的概率。如果我们使用`lm()`拟合一个纯线性模型，估算的回归值可能会超出[0,1]区间，因此无法代表概率。当然，我们可以将`lm()`预测的任何值截断到[0,1]区间，但*logistic*模型提供了一个更好的方法。
- en: The model takes its name from the logistic function *l*(*t*) = 1/(1 + *e*^(−*t*)).
    Since that function takes values in (0,1), it is suitable for modeling a probability.
    We still use a linear form but run the form through the logistic function to squeeze
    it into (0,1) for probability modeling.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的名称来源于logistic函数*l*(*t*) = 1/(1 + *e*^(−*t*))。由于该函数的值域在(0,1)之间，因此非常适合用于建模概率。我们仍然使用线性形式，但将该形式通过logistic函数进行转换，将其压缩到(0,1)区间，进行概率建模。
- en: 'Say we wish to predict gender from height. Our model might be:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望根据身高预测性别。我们的模型可能是：
- en: '![Image](../images/unch08equ13.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/unch08equ13.jpg)'
- en: Here *β*[0] and *β*[1] are, again, population values, which we estimate from
    our data.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的*β*[0]和*β*[1]再次是人口参数，我们从数据中进行估算。
- en: 'The logistic and linear models are basically similar: in the linear model,
    *β**[i]* is the impact that the *i**^(th)* feature has on mean *Y*, while in the
    logit case, *β**[i]* is the impact that the *i**^(th)* feature has on the probability
    that *Y* = 1\. (Some analysts view logit in terms of a linear model of the *log-odds
    ratio*, log(*P*(*Y* = 1| *X*) / [1 − *P*(*Y* = 1|*X*)]).)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '*logistic*和线性模型基本相似：在线性模型中，*β**[i]*是第*i*个特征对平均*Y*的影响，而在logit模型中，*β**[i]*是第*i*个特征对*Y*
    = 1的概率的影响。（一些分析师将logit视为*log-odds比率*的线性模型，即log(*P*(*Y* = 1| *X*) / [1 − *P*(*Y*
    = 1| *X*)]）。）'
- en: The logistic model is often called the *logit* model for simplicity.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '*logistic*模型通常被称为*logit*模型，简化时常用这个名字。'
- en: '***8.9.1 The glm() and qeLogit() Functions***'
  id: totrans-174
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.9.1 glm()和qeLogit()函数***'
- en: 'In R, the standard function for the generalized linear model is `glm()`. In
    the logistic case, that function is wrapped by the `qeML` package function `qeLogit()`.
    The call form for the latter is:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，用于广义线性模型的标准函数是`glm()`。在logistic回归的情况下，该函数被`qeML`包中的`qeLogit()`函数所包装。后者的调用形式为：
- en: '[PRE20]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The first three arguments are as in the other `qe*`-series functions. The last
    argument, `yesYVal`, is needed in the 2-class case. It specifies the value of
    *Y* that we wish to be coded as *Y* = 1.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 前三个参数与其他`qe*`系列函数相同。最后一个参数`yesYVal`在二分类情况下是必要的，它指定我们希望被编码为*Y* = 1的*Y*值。
- en: '***8.9.2 Example: Telco Churn Data***'
  id: totrans-178
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.9.2 示例：电信流失数据***'
- en: In [Section 2.2](ch02.xhtml#ch02lev2), we used k-NN to analyze some customer
    retention data. Let’s revisit that data, now using a logistic model. Recall that
    the `Churn` variable has values `'Yes'` and `'No'`.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 2.2 节](ch02.xhtml#ch02lev2)中，我们使用 k-NN 分析了一些客户流失数据。现在，我们用一个逻辑模型重新分析这部分数据。回忆一下，`Churn`
    变量的值为 `'Yes'` 和 `'No'`。
- en: '[PRE21]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Our model is:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型是：
- en: '![Image](../images/unch08equ14.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/unch08equ14.jpg)'
- en: 'Let’s predict a new case that is similar to, say, the 333rd one in our dataset
    but with a different gender:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们要预测一个新案例，它类似于我们数据集中第 333 个案例，但性别不同：
- en: '[PRE22]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We guess that the customer will stay put—that is, not jump to another service
    provider—with a jump probability of only about 23 percent.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们猜测客户会保持原状——即不会跳槽到其他服务提供商——跳槽概率大约只有 23%。
- en: 'We also get a warning message:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还会收到一个警告消息：
- en: '[PRE23]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This is a technical issue, occurring when the features are highly correlated.
    Here `glm()` has actually skipped over some of the features that are in essence
    redundant.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个技术问题，通常发生在特征高度相关时。此时，`glm()` 实际上跳过了一些本质上是冗余的特征。
- en: 'Sometimes `glm()` will give us a warning message like:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 有时 `glm()` 会给我们一个警告消息，例如：
- en: '[PRE24]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Again, this is a technical issue, which we will not pursue here. The reader
    may proceed as usual.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这是一个技术问题，我们在这里不会深入探讨。读者可以照常继续。
- en: On the other hand, a warning that one cannot ignore is “failed to converge.”
    This will not happen with `lm()`, the R function wrapped by our `qeLinear()`,
    but it may occasionally occur with logit. This is usually remedied by performing
    some dimension reduction.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，有一个警告是不容忽视的：“未能收敛”。这在 `lm()` 中不会发生（`lm()` 是我们封装的 `qeLinear()` 使用的 R 函数），但在使用
    logit 时偶尔会发生。这通常可以通过执行一些维度压缩来解决。
- en: '***8.9.3 Multiclass Case***'
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.9.3 多类情况***'
- en: If there are more than two classes, we have two options. For concreteness, consider
    the vertebrae data from [Section 2.3](ch02.xhtml#ch02lev3). There we had three
    classes, DH, NO, and SL. For now, just consider using `glm()` directly rather
    than its wrapper, `qeLogit()`.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如果类别超过两个，我们有两个选择。为了具体说明，考虑 [第 2.3 节](ch02.xhtml#ch02lev3)中的脊柱数据。那里我们有三个类别：DH、NO
    和 SL。现在，暂时考虑直接使用 `glm()`，而不是它的封装函数 `qeLogit()`。
- en: '**One vs. All (OVA) method** Here we run `glm()` once for each class. We first
    run logit with DH playing the role of *Y*. Then we do this with NO serving as
    *Y* and then finally the same for SL. That gives us three sets of coefficients—in
    fact, three return objects from `glm()`, say, `DHout`, `NOout`, and `SLout`. Then
    when predicting a new case `newx`, we run:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**一对多（OVA）方法** 在这里我们对每个类别运行一次 `glm()`。我们首先使用 DH 作为 *Y* 来运行 logit。然后我们使用 NO
    作为 *Y* 运行，再最后对 SL 进行相同的操作。这样，我们就得到了三组系数——实际上是从 `glm()` 返回的三个对象，比如 `DHout`、`NOout`
    和 `SLout`。然后，在预测新案例 `newx` 时，我们运行：'
- en: '[PRE25]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This gives us three probabilities. We take as our prediction whichever class
    has the highest probability.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这会给我们三个概率。我们会选择概率最高的类别作为预测结果。
- en: '**All vs. All (AVA) method** Here we run `glm()` once for each *pair* of classes.
    First, we restrict the data to just DH and NO, putting SL cases aside for the
    moment, and take *Y* as DH. Then we focus on just DH and SL, taking *Y* to be
    DH again. Finally, we put DH aside for the moment, running with NO and SL and
    taking *Y* to be NO. Again, that would give us three objects output from `glm()`.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '**全对全（AVA）方法** 在这里我们对每一对类别运行一次 `glm()`。首先，我们将数据限制在 DH 和 NO 之间，将 SL 类别暂时放在一旁，并将
    *Y* 设为 DH。然后，我们仅关注 DH 和 SL，将 *Y* 设为 DH。最后，我们将 DH 放到一旁，运行 NO 和 SL 并将 *Y* 设为 NO。这样，我们也会得到三个
    `glm()` 输出的对象。'
- en: Then we would call `predict()` three times on `newx`. Say the outcome with the
    first object is less than 0.5\. That means between DH and NO, we would predict
    this new case to be NO—that is, NO “wins.” We do this on all three objects, and
    whichever class wins the most often is our predicted class.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们会对 `newx` 调用 `predict()` 三次。假设第一次得到的结果小于 0.5，这意味着在 DH 和 NO 之间，我们会预测这个新案例为
    NO——也就是说，NO “获胜”。我们在所有三个对象上都这么做，最后，预测的类别是出现频率最多的那个类别。
- en: The `qeLogit()` function uses the OVA approach. Since `qeLogit()` is a wrapper
    for `glm()`, we do not see the actions of the latter, and they are used only as
    intermediate internal computations. However, if desired, the results of the calls
    to `glm()` can be accessed in the `glOuts` component of the object returned by
    `qeLogit()`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`qeLogit()` 函数使用了 OVA 方法。由于 `qeLogit()` 是 `glm()` 的封装函数，我们看不到后者的具体操作，它们仅作为中间内部计算使用。然而，如果需要，可以通过
    `qeLogit()` 返回的对象中的 `glOuts` 组件访问 `glm()` 调用的结果。'
- en: '***8.9.4 Example: Fall Detection Data***'
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.9.4 示例：跌倒检测数据***'
- en: 'This dataset is included in `qeML`, originally from Kaggle.^([3](footnote.xhtml#ch8fn3))
    From the site:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集包含在`qeML`中，最初来自Kaggle。^([3](footnote.xhtml#ch8fn3)) 来自该网站：
- en: Falls are a serious public health problem and possibly life threatening for
    people in fall risk groups. We develop an automated fall detection system with
    wearable motion sensor units fitted to the subjects’ body at six different positions.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 跌倒是一个严重的公共卫生问题，对于跌倒风险群体的人来说，甚至可能是致命的。我们开发了一种自动跌倒检测系统，该系统配备了穿戴式运动传感器单元，传感器被安装在受试者身体的六个不同位置。
- en: 'There are six activity types, thus six classes, coded 0 (Standing), 1 (Walking),
    2 (Sitting), 3 (Falling), 4 (Cramps), and 5 (Running). Let’s see how well we can
    predict the class:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 有六种活动类型，因此有六个类别，分别编码为0（站立）、1（行走）、2（坐着）、3（跌倒）、4（抽筋）和5（跑步）。让我们看看我们能有多准确地预测类别：
- en: '[PRE26]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We are correctly predicting only about 40 percent of the cases with our logit
    model, but that’s better than the 28 percent correct we’d get just guessing every
    case to be of Class 3, the most common class.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的logit模型仅正确预测了大约40%的案例，但这比我们仅仅猜测每个案例为Class 3（最常见类别）时的28%正确率要好。
- en: 'Let’s predict a hypothetical new case, say, like the first row in the data
    but with `BP` equal to 28:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们要预测一个假设的新案例，比如数据中的第一行，但`BP`等于28：
- en: '[PRE27]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Such a case would result in a prediction of Class 2, with a probability of about
    23 percent.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况下，预测结果为Class 2，概率约为23%。
- en: 8.10 Bias and Variance in Linear/Generalized Linear Models
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.10 线性/广义线性模型中的偏差与方差
- en: As discussed in [Chapter 3](ch03.xhtml), the more features we use, the smaller
    the bias but the larger the variance. With parametric models, such as those in
    this chapter, the larger variance comes in the form of less-stable estimates of
    the coefficients, which, in turn, make later predictions less stable.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[第3章](ch03.xhtml)中讨论的那样，我们使用的特征越多，偏差越小，但方差越大。对于像本章中的参数模型来说，较大的方差表现为系数估计的不稳定性，而这反过来又使得后续的预测更加不稳定。
- en: Once again, note that high variance for a coefficient estimate means that the
    value of that estimate will vary a lot from one sample to another. That large
    oscillation, in turn, means that the estimated coefficient vector will be less
    likely to be near the true population value.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，高方差的回归系数估计意味着该估计值在不同样本之间会有很大的波动。大的波动反过来意味着估计的系数向量更可能远离真实的总体值。
- en: Here we present a concrete example illustrating the fact that the variance increases
    with the complexity of the model.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通过一个具体的例子来说明方差是如何随着模型复杂度增加而增加的。
- en: '***8.10.1 Example: Bike Sharing Data***'
  id: totrans-214
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.10.1 示例：共享单车数据***'
- en: We can make that point about instability of predictions more concrete using
    the `regtools` function `stdErrPred()`. This function finds the standard error
    of a predicted value obtained from `lm()`. Recall from [Section 8.5.2.1](ch08.xhtml#ch08lev5sec2sec1)
    that the standard error of an estimator is the estimated standard deviation of
    that estimator. A larger standard error thus means more variability of the estimator
    from one sample to another.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`regtools`函数`stdErrPred()`来更具体地说明预测不稳定性的问题。这个函数计算从`lm()`得到的预测值的标准误差。回顾[第8.5.2.1节](ch08.xhtml#ch08lev5sec2sec1)，估计量的标准误差是该估计量的标准差。因此，较大的标准误差意味着估计量在不同样本之间的波动更大。
- en: We’ll fit two models, one with a smaller feature set and the other with a somewhat
    larger one, and then do the same prediction on each; just as an example, we’ll
    predict the third data point in the dataset. We will print out the two predictions
    and, most important, the standard error of the two predictions.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将拟合两个模型，一个使用较小的特征集，另一个使用稍大的特征集，然后在每个模型上进行相同的预测；作为示例，我们将预测数据集中的第三个数据点。我们将打印出两个预测值，并且最重要的是，打印出这两个预测的标准误差。
- en: '[PRE28]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: So the prediction from the larger feature set has a larger standard error. The
    standard error is the standard deviation of an estimator—in this case, our estimate
    of prediction accuracy. So here we see the Bias-Variance Trade-off in action.
    The larger model, though more detailed and thus less biased, does have a larger
    variance.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用较大特征集的预测具有更大的标准误差。标准误差是估计量的标准差——在这种情况下，是我们对预测准确性的估计。所以在这里我们看到了偏差-方差权衡的实际应用。尽管更大的模型更详细，从而偏差较小，但它确实具有更大的方差。
- en: Does that mean that we should use the smaller feature set? No. In order to see
    if we’ve hit the switchover point, we’d need to use cross-validation. But the
    reader should keep this concrete illustration of the trade-off in mind.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 那是否意味着我们应该使用更小的特征集呢？不。为了判断我们是否达到了切换点，我们需要使用交叉验证。但是，读者应该牢记这个具体的折中示例。
- en: 8.11 Polynomial Models
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.11 多项式模型
- en: Surprisingly, one can use linear regression methods to model nonlinear effects.
    We’ll see how in this section. Why is this important?
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 出人意料的是，我们可以使用线性回归方法来建模非线性效应。我们将在本节中展示如何做到这一点。为什么这很重要？
- en: A polynomial model can often match or even outperform many of the more glamorous
    ML models.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式模型通常能够与许多更华丽的机器学习模型匹敌，甚至超越它们。
- en: Polynomials will play an important role in our chapter on support vector machines
    ([Chapter 10](ch10.xhtml)), and even in our treatment of neural networks ([Chapter
    11](ch11.xhtml)), where there is a surprising connection to polynomials.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式将在我们关于支持向量机的章节（[第10章](ch10.xhtml)）以及我们对神经网络的讨论（[第11章](ch11.xhtml)）中发挥重要作用，甚至在这里，多项式与这些内容之间有着出人意料的联系。
- en: '***8.11.1 Motivation***'
  id: totrans-224
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.11.1 动机***'
- en: We’ve used the example of programmer and engineer wages earlier in this book
    (see [Section 3.2.3](ch03.xhtml#ch03lev2sec3)). Consider the graph of wage income
    against age shown in [Figure 8-2](ch08.xhtml#ch08fig02). There seems to be a steep
    rise in a worker’s 20s, then a long leveling off, with a hint even of a decline
    after age 55 or so. This is definitely not a linear relationship.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本书早些时候使用了程序员和工程师工资的例子（见[第3.2.3节](ch03.xhtml#ch03lev2sec3)）。考虑[图8-2](ch08.xhtml#ch08fig02)中展示的工资收入与年龄的关系图。看起来工人在20多岁时工资急剧上升，然后平稳一段时间，在55岁左右甚至有下降的迹象。这显然不是线性关系。
- en: '![Image](../images/ch08fig02.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08fig02.jpg)'
- en: '*Figure 8-2: Wage income vs. age*'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8-2：工资收入与年龄的关系*'
- en: Or consider [Figure 8-3](ch08.xhtml#ch08fig03), for the bike sharing data, graphing
    total ridership against temperature. The nonlinear relationship is even clearer
    here. (We seem to see two groups here, possibly for the registered and casual
    riders.) No surprise, of course—people don’t want to go bike riding if the weather
    is too cold or too hot—but again, the point is that a linear model would seem
    questionable.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 或者可以参考[图8-3](ch08.xhtml#ch08fig03)，对于共享单车数据，绘制总骑行人数与温度的关系。这里非线性关系更加明显。（我们似乎看到了两组数据，可能是注册用户和临时用户。）这并不奇怪——如果天气太冷或太热，人们自然不愿意去骑车——但重点是，线性模型似乎不太合适。
- en: '![Image](../images/ch08fig03.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08fig03.jpg)'
- en: '*Figure 8-3: Ridership vs. temperature*'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8-3：骑行人数与温度的关系*'
- en: Fortunately, these nonlinear effects actually *can* be accommodated with linear
    models.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这些非线性效应实际上是可以通过线性模型来适应的。
- en: '***8.11.2 Modeling Nonlinearity with a Linear Model***'
  id: totrans-232
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.11.2 使用线性模型建模非线性***'
- en: 'Starting simple, suppose in the bike rental data we wish to predict total ridership
    `tot`, using temperature `temp` as our sole feature, but want a quadratic model:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 从简单开始，假设在共享单车数据中，我们希望预测总骑行人数`tot`，只使用温度`temp`作为唯一特征，但需要一个二次模型：
- en: '![Image](../images/ch08equ11.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ11.jpg)'
- en: 'This is still a linear model! Sure, there is a squared term there for `temp`,
    so we say the model is nonlinear *in terms of* `temp`. But it is still linear
    in `b`, `c`, and `d`. We are modeling mean `tot` as a linear combination of three
    things: 1, `temp`, and `temp`² (thinking of *b* as *b* × 1).'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这仍然是一个线性模型！当然，`temp`有一个平方项，所以我们说模型在`temp`上是非线性的。但它在`b`、`c`和`d`上仍然是线性的。我们正在将平均`tot`建模为三者的线性组合：1、`temp`和`temp`²（可以将*b*看作*b*
    × 1）。
- en: 'Then we could simply add a `temp`² column and call `qeLin()`:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以简单地添加一个`temp`²列，并调用`qeLin()`：
- en: '[PRE29]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We see that ![Image](../images/unch08equ15.jpg) and ![Image](../images/unch08equ16.jpg).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到的是![Image](../images/unch08equ15.jpg)和![Image](../images/unch08equ16.jpg)。
- en: But this is inconvenient. Not only would we need to add that squared column
    manually, but we also would have to remember to add it later to new cases that
    we wish to predict.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 但这也很不方便。我们不仅需要手动添加那个平方列，而且还需要记得在以后预测新案例时添加它。
- en: 'Worse, we would need to add the *cross-product* terms. Say we are predicting
    total ridership from both temperature and humidity. In that case, [Equation 8.11](ch08.xhtml#ch08equ11)
    would include a product of these two features, becoming:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，我们还需要添加*交叉乘积*项。假设我们要根据温度和湿度来预测总骑行人数。在这种情况下，[方程8.11](ch08.xhtml#ch08equ11)将包含这两个特征的乘积，变成：
- en: '![Image](../images/ch08equ12.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch08equ12.jpg)'
- en: If we have a lot of features, adding these terms manually would become a real
    nuisance.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有很多特征，手动添加这些项将变得非常麻烦。
- en: A more subtle problem concerns dummy variables. Since 0² = 0 and 1² = 1, we
    see that the square of any dummy is itself. So adding squared terms to our model
    for dummies would be redundant.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更微妙的问题涉及虚拟变量。因为0² = 0且1² = 1，我们可以看到任何虚拟变量的平方就是其本身。因此，在我们的模型中添加虚拟变量的平方项会是多余的。
- en: 'To avoid such issues, the `qeML` package has the `qePolyLin()` function, which
    takes care of these things for us automatically. Its basic call form is:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种问题，`qeML`包提供了`qePolyLin()`函数，它可以自动处理这些问题。其基本调用形式为：
- en: '[PRE30]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The argument `deg` is the degree of the polynomial, and `maxInteractDeg` is
    the maximum interaction degree term; for instance, *temp* × *hum* is considered
    to be of degree 2 in [Equation 8.12](ch08.xhtml#ch08equ12). Of course, if we have
    just a single feature, there are no interaction terms.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 参数`deg`是多项式的阶数，`maxInteractDeg`是最大交互项的阶数；例如，*temp* × *hum*在[方程式8.12](ch08.xhtml#ch08equ12)中被视为二阶项。当然，如果我们只有一个特征，则没有交互项。
- en: 'It gives the same fit as the one we got above manually (of course). Let’s again
    predict `tot` from `temp`:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 它给出的拟合结果与我们之前手动得到的相同（当然）。我们再次用`temp`来预测`tot`：
- en: '[PRE31]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let’s take a look at the resulting estimated coefficients:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看得到的估计系数：
- en: '[PRE32]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Prediction is as usual, for example, for a 12-degree day:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 预测仍然像往常一样，例如，预测12度天的情况：
- en: '[PRE33]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s see if the quadratic model predicts better:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看二次模型是否能做出更好的预测：
- en: '[PRE34]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Yes, the MAPE value was smaller for the quadratic model, though as always, it
    must be added that we should use `replicMeans()` to be sure (see [Section 3.2.2](ch03.xhtml#ch03lev2sec2)).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，二次模型的MAPE值较小，尽管一如既往，必须补充说明我们应该使用`replicMeans()`来确保（参见[第3.2.2节](ch03.xhtml#ch03lev2sec2)）。
- en: '***8.11.3 Polynomial Logistic Regression***'
  id: totrans-256
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.11.3 多项式逻辑回归***'
- en: Recall that the logit model starts with a linear combination of the features
    and then runs it through the logistic function *l*(*t*) = 1/(1 + *e*^(−*t*)) to
    squeeze it into [0,1]. That means we can add polynomial terms as in the linear
    model. The `regtools` function `qePolyLog()` does this.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆一下，logit模型从特征的线性组合开始，然后通过逻辑函数 *l*(*t*) = 1/(1 + *e*^(−*t*))将其挤压到[0,1]之间。这意味着我们可以像线性模型那样添加多项式项。`regtools`包中的`qePolyLog()`函数可以做到这一点。
- en: '***8.11.4 Example: Programmer and Engineer Wages***'
  id: totrans-258
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.11.4 示例：程序员与工程师薪资***'
- en: 'Let’s predict occupation by applying nonpolynomial logit first:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先应用非多项式logit模型来预测职业：
- en: '[PRE35]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'About 35 percent right, which is not too bad, considering there are 6 classes.
    But maybe a quadratic model—that is, adding terms such as the squares of income
    and age—would improve things. Let’s see:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 约35%的准确率，考虑到有6个类别，这还算不错。但也许二次模型——即添加收入和年龄的平方等项——会有所改善。我们来看看：
- en: '[PRE36]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This is a slight improvement. But is it a sampling accident? We could use the
    `qeCompare()` function to compare different degrees while using many holdout sets
    to address sampling issues (see [Section 8.13](ch08.xhtml#ch08lev13)).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个轻微的改进。但这是否是一个采样意外？我们可以使用`qeCompare()`函数来比较不同的多项式阶数，同时使用多个保留集来解决采样问题（参见[第8.13节](ch08.xhtml#ch08lev13)）。
- en: 8.12 Blending the Linear Model with Other Methods
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.12 将线性模型与其他方法结合
- en: Problems tend to occur with k-NN around the fringes of a dataset. As a simple
    concrete example, let’s again consider predicting human weight from height in
    the Major League Baseball Player data from [Section 1.8](ch01.xhtml#ch01lev8).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 问题往往出现在k-NN模型的训练数据集边缘。作为一个简单的具体例子，我们再考虑一下预测从[第1.8节](ch01.xhtml#ch01lev8)中获取的美国职业棒球大联盟球员数据中身高与体重的关系。
- en: 'Here’s a summary of the data:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据的总结：
- en: '[PRE37]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Suppose we wish to predict the weight of a new player whose height is 68.2 and
    use k-NN. This height is on the low end of our training data, so most of the nearest
    neighbors will be taller than this. Taller people tend to be heavier, and the
    dataset neighbors of our new point will mostly be taller than this new player
    and thus likely heavier. The result will be that our prediction will be biased
    upward; we will tend to predict a larger weight than this player’s true value.
    Similarly, if our new case has height, say, 81.5, our prediction will be biased
    downward.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望预测一个新球员的体重，他的身高为68.2，并且使用k-NN方法。这个身高处于我们训练数据的较低端，所以大多数最近邻的身高会比这个球员高。身高较高的人往往也较重，而我们新点的数据集中的邻居大多会比这个新球员高，因此也很可能更重。结果是我们的预测将会有偏向，通常会预测比这个球员实际体重大。类似地，如果我们新案例的身高是81.5，那么我们的预测将会有向下的偏差。
- en: One remedy is to fit a linear model within the neighborhood. Say we are predicting
    a new case `x` and use *k* = 25 neighbors. Then, instead of averaging the weights
    of those 25 neighboring players, we invoke `lm()` on that neighborhood data. We
    then predict `x` from the output of `lm()`. The linearity of this process will
    result in more realistic predictions at the fringes of the data.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解决方法是在邻域内拟合一个线性模型。假设我们正在预测一个新的数据点 `x`，并使用 *k* = 25 个邻居。然后，我们不是对这25个邻近的玩家的权重取平均值，而是对该邻域数据调用
    `lm()`。然后，我们根据 `lm()` 的输出预测 `x`。这个过程的线性性质将使得在数据边缘的预测更加真实。
- en: The point, then, is that instead of using the mean to smooth the data in a neighborhood,
    we could use `lm()`. Or, if we are worried about the effects of outliers, we might
    try `median()`.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 关键是，代替在邻域内使用均值平滑数据，我们可以使用 `lm()`。或者，如果我们担心异常值的影响，可以尝试使用 `median()`。
- en: There is an argument called `smoothingFtn` in the `regtools` function `kNN()`
    (which is wrapped by `qeKNN()`) that lets us specify some kind of smoothing other
    than the usual mean. The default is `smoothingFtn = mean`; to use median smoothing,
    we would specify `smoothingFtn = median`. For linear smoothing, we would use `smoothingFtn
    = loclin`.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '`regtools` 函数 `kNN()`（由 `qeKNN()` 封装）中有一个名为 `smoothingFtn` 的参数，允许我们指定除常规均值外的某种平滑方法。默认值是
    `smoothingFtn = mean`；若要使用中位数平滑，可以指定 `smoothingFtn = median`。对于线性平滑，我们使用 `smoothingFtn
    = loclin`。'
- en: Recall that decision trees (and thus random forests and tree-based boosting
    as well) form neighborhoods too. They thus are subject to the same problem—that
    is, bias in neighborhoods that are near the edges of the data. Thus the same local-linear
    idea could be applied here. The CRAN package `grf` does this; it is wrapped by
    `qeRFgrf()`.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，决策树（因此也包括随机森林和基于树的提升方法）也会形成邻域。因此，它们也会面临相同的问题——即，在数据边缘附近的邻域存在偏差。因此，可以在这里应用相同的局部线性思想。CRAN
    包 `grf` 就是这么做的；它被 `qeRFgrf()` 封装。
- en: 8.13 The qeCompare() Function
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.13 `qeCompare()` 函数
- en: In our experiment in [Section 8.11.4](ch08.xhtml#ch08lev11sec4), a quadratic
    model did appear to help, with a slightly lower OME than that of the ordinary
    logit. An extensive investigation would involve `fineTuning()`, with cross-validation
    trials, and possibly exploring polynomial degrees other than 1 or 2.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们[8.11.4节](ch08.xhtml#ch08lev11sec4)的实验中，二次模型确实有所帮助，具有略低于普通对数几率模型的 OME 值。一次全面的调查将涉及
    `fineTuning()`，进行交叉验证试验，可能还需要探索其他次数的多项式模型，而不仅限于 1 次或 2 次。
- en: But remember, “qe” stands for “quick and easy.” The `qeML` function `qeCompare()`
    can be used for quick comparisons between models. (Of course, for large datasets,
    it won’t be so quick.)
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 但记住，“qe”代表“快速和简便”。`qeML` 函数 `qeCompare()` 可以用于模型之间的快速比较。（当然，对于大型数据集，它可能不会那么快速。）
- en: Let’s use it to compare ordinary logistic regression with a quadratic version
    for the vertebrae data. While we are at it, let’s compare to the other methods
    we’ve had in the book so far.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用它来比较普通的逻辑回归与二次版本的逻辑回归，使用脊椎数据。顺便比较一下我们到目前为止在书中提到的其他方法。
- en: '[PRE38]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: What happened here?
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生了什么？
- en: Here we generated 100 random holdout sets (of size 73, the default for this
    dataset). The same holdout set is used for all methods. (The `qeCompare()` function
    has an optional random-number `seed` argument, but we’ve taken the default value
    of 9999.)
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这里，我们生成了100个随机的保留集（每个大小为73，这是该数据集的默认值）。所有方法使用相同的保留集。（`qeCompare()` 函数有一个可选的随机数
    `seed` 参数，但我们使用了默认值9999。）
- en: We are using default hyperparameters for each of the functions. The `qeCompare()`
    function has an optional `opts` argument to set non-default values, such as `nTree`
    for `qeRF()`.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在每个函数中都使用了默认的超参数。`qeCompare()` 函数有一个可选的 `opts` 参数，用于设置非默认值，比如 `qeRF()` 的 `nTree`。
- en: We found OME values for each method.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们找到了每种方法的 OME 值。
- en: The quadratic logit not only outperformed the ordinary logit, but it also turned
    out to be the best of the bunch! Yes, it outperformed the fancy ML methods. Of
    course, each method was run with the default hyperparameters, and things could
    change with other values.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 二次对数几率模型不仅优于普通的对数几率模型，而且最终证明它是所有方法中表现最好的！是的，它优于复杂的机器学习方法。当然，每个方法都是使用默认的超参数运行的，使用其他参数值时，结果可能会有所不同。
- en: '***8.13.1 Need for Caution Regarding Polynomial Models***'
  id: totrans-283
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***8.13.1 关于多项式模型的谨慎使用***'
- en: The polynomial degree is a hyperparameter. In our example of predicting occupation
    in [Section 8.11.4](ch08.xhtml#ch08lev11sec4), we might, say, try a cubic (degree-3)
    model
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式的次数是一个超参数。在我们[8.11.4节](ch08.xhtml#ch08lev11sec4)的职业预测示例中，我们可能会尝试一个三次（3次）模型。
- en: '[PRE39]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: or even set degree to 4, 5, and so on.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 或者甚至将次数设置为 4、5 等。
- en: However, with higher and higher degrees, we do need to watch for over-fitting,
    as the number of terms increases very rapidly with degree. Let’s illustrate that
    point by checking the number of *β* coefficients in each model for varying degree,
    as shown in [Table 8-1](ch08.xhtml#ch8tab1). This requires some digging into the
    output objects. It would be a distraction to explain that here, but for the interested
    reader, this is in the component `$glmOuts[[1]]`. One must then exclude the intercept
    term.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着度数的增加，我们确实需要关注过拟合问题，因为随着度数的增加，项数会迅速增加。我们可以通过查看不同度数下每个模型中*β*系数的数量来说明这一点，如[表
    8-1](ch08.xhtml#ch8tab1)所示。这需要深入挖掘输出对象。虽然在此解释会引起分心，但对于有兴趣的读者，可以查看组件`$glmOuts[[1]]`。然后需要排除截距项。
- en: '**Table 8-1:** Complexity of Polynomial Models'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 8-1：** 多项式模型的复杂度'
- en: '| **Degree** | **Coefficients** |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| **度数** | **系数** |'
- en: '| --- | --- |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | 6 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 6 |'
- en: '| 2 | 22 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 22 |'
- en: '| 3 | 50 |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 50 |'
- en: '| 4 | 90 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 90 |'
- en: '| 5 | 143 |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 143 |'
- en: Remember, these are the values of *p*, our number of features, after we add
    in polynomial terms. Our sample size *n* remains at 20,090\. At some point while
    increasing the degree, we will overfit.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这些是添加了多项式项后的*p*值，也就是我们的特征数量。我们的样本大小*n*仍然是20,090。随着度数的增加，在某个点上我们会出现过拟合。
- en: If we follow the rough rule of thumb that we need to have ![Image](../images/prootn.jpg),
    this suggests a limit of something like *p* < 141, corresponding to using at most
    a degree-4 model. But this is, after all, only a rule of thumb. It may be the
    case that, say, OME starts increasing after just a degree-2 model. The reader
    is urged to try polynomials of various degrees, on this dataset and others, noting
    the OME values that result.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们遵循一个大致的经验法则，要求![Image](../images/prootn.jpg)，这就建议度数的限制大约是*p* < 141，对应使用最多度数为4的模型。但毕竟，这只是一个经验法则。也有可能，在某些情况下，比如说，OME在度数为2的模型后就开始增加。建议读者在此数据集及其他数据集上尝试不同度数的多项式，并注意结果中的OME值。
- en: 'We note the following:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到以下几点：
- en: Polynomial models may be able to hold their own against, or even outperform,
    their more esoteric ML counterparts.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式模型可能能够与更深奥的机器学习对手竞争，甚至超越它们。
- en: Use of polynomial models is attractive in that there is only one hyperparameter
    (the degree), and also because the calculation (in the case of `qePolyLin()`)
    is noniterative and thus has no convergence issues.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式模型的使用具有吸引力，因为它只有一个超参数（度数），并且在`qePolyLin()`的情况下，计算是非迭代的，因此不会有收敛问题。
- en: As with any ML method, one must always keep in mind the possibility of overfitting.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 和任何机器学习方法一样，我们必须时刻记住过拟合的可能性。
- en: Unfortunately, many treatments of ML overlook polynomial models. But they can
    be quite powerful and should definitely be in the analyst’s toolkit.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，许多机器学习的研究忽视了多项式模型。但它们可以非常强大，绝对应该成为分析师工具包的一部分。
- en: 8.14 What’s Next
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.14 接下来做什么
- en: The linear model is the oldest form of ML. As we have seen, it still can be
    quite powerful, outperforming “modern” ML methods in some cases. But in some settings,
    it can be made even better by, oddly, “shrinking” ![Image](../images/betacap.jpg)
    This is the topic of the next chapter.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型是最古老的机器学习形式。正如我们所见，它仍然可以非常强大，在某些情况下甚至优于“现代”机器学习方法。但在某些设置下，通过“收缩”来改进它，奇怪的是！[Image](../images/betacap.jpg)。这是下一章的主题。
