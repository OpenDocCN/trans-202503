<html><head></head><body>
<h2 class="h2" id="ch10"><span epub:type="pagebreak" id="page_375"/><strong><span class="big">10</span><br/>RANDOMIZATION</strong></h2>
<div class="image1"><img alt="Image" src="../images/common1.jpg"/></div>
<p class="noindent">Think back to when we learned about binary search in <a href="ch07.xhtml">Chapter 7</a>. Rather than answering the question, “What is the optimal solution?” we instead asked, “Is this specific value the optimal solution?” While we were solving the Feeding Ants problem, you may have thought that my picking values out of thin air was outlandish, wondering how that was going to work at all. But it works great, as we now know.</p>
<p class="indent">You want something that’s even more outlandish than binary search? How about just straight-up guessing a completely random solution. How could that possibly work? What is it about specific problems that makes this random guessing a viable strategy? And could random guessing still help us solve a problem even if we already have a solution? The surprising conclusions await.</p>
<h3 class="h3" id="lev63"><span epub:type="pagebreak" id="page_376"/><strong>Problem 1: Yōkan</strong></h3>
<p class="noindent">Yōkan is a Japanese candy. It’s sweet. It has kind of a jelly or gummy texture. Buy a nice big block and cut it into little pieces and pair it with some fruit and chill it for a nice refreshing . . . oh, sorry. Back to algorithms.</p>
<p class="indent">This is DMOJ problem <code>dmpg15g6</code>.</p>
<h4 class="h4" id="sec157"><em>The Problem</em></h4>
<p class="noindent">Two friends have found a Yōkan consisting of <em>n</em> pieces. The pieces are numbered 1, 2, . . . , <em>n</em>. Each piece of the Yōkan has a specific flavor, and each friend will eat only those pieces that are the same flavor.</p>
<p class="indent">A slab of Yōkan consists of all of the pieces from Piece <em>l</em> to Piece <em>r</em>. A friend is <em>happy</em> with a slab if they can find at least one-third of that slab’s pieces that have the same flavor. For example, if a slab has 9 pieces, then a friend would need to find 9/3 = 3 pieces of the same flavor. For both friends to be happy with the slab, they would each need to find their own one-third of pieces that have the same flavor.</p>
<p class="indent">The friends will query about various slabs; for each, we need to determine whether both of them would be happy with that slab.</p>
<h5 class="h5">Input</h5>
<p class="noindent">The input consists of the following lines:</p>
<ul>
<li class="noindent">A line containing <em>n</em>, the number of pieces in the Yōkan, and <em>m</em>, the number of possible piece flavors. <em>n</em> and <em>m</em> are between 1 and 200,000.</li>
<li class="noindent">A line containing <em>n</em> integers giving the flavors of the Yōkan pieces from Piece 1 to Piece <em>n</em>. Each integer is a flavor between 1 and <em>m</em>.</li>
<li class="noindent">A line containing <em>q</em>, the number of queries that the friends have. <em>q</em> is between 1 and 200,000.</li>
<li class="noindent"><em>q</em> lines, one for each query. Each such line contains the integers <em>l</em> and <em>r</em>, indicating the slab from Piece <em>l</em> to Piece <em>r</em>.</li>
</ul>
<h5 class="h5">Output</h5>
<p class="noindent">The output for each query is on its own line. For each query:</p>
<ul>
<li class="noindent">If both friends are happy with this slab, output <code>YES</code>.</li>
<li class="noindent">Otherwise, output <code>NO</code>.</li>
</ul>
<p class="indent">The time limit for solving the test case is 1.4 seconds.</p>
<h4 class="h4" id="sec158"><em>Randomly Choosing a Piece</em></h4>
<p class="noindent">Let’s start with a test case:</p>
<pre>14 4
1 3 4 2 1 1 2 4 1 2 2 4 1 1
<span epub:type="pagebreak" id="page_377"/>3
3 11
8 11
5 6</pre>
<p class="indent">The Yōkan here has 14 pieces. It looks like this:</p>
<div class="image1"><img alt="Image" src="../images/pg377-01.jpg"/></div>
<p class="indent">There are three queries to process. The first query starts at Piece 3 and ends at Piece 11. We’re therefore interested in this slab of the Yōkan:</p>
<div class="image1"><img alt="Image" src="../images/pg377-02.jpg"/></div>
<p class="indent">This slab has 9 pieces, so we want to determine whether each friend can find 9/3 = 3 pieces of the same flavor. And they can! The first friend could eat 3 pieces of Flavor 1. The second friend could eat 3 pieces of Flavor 2. (There are 4 pieces of Flavor 2 there, but that fourth one is overkill for what we need.) For this query, we would therefore output <code>YES</code>.</p>
<p class="indent">Think about how we might write code to determine whether the friends are happy with this slab. In general, it would be too slow to do this by checking each piece in the slab one by one; after all, a slab can have up to 200,000 pieces in it. This is a familiar roadblock for us by this point in the book; the usual thing to do would be to use some fancy data structure to make the queries fast.</p>
<p class="indent">But we’re going to do something far less usual here. I’d like you to look at that Yōkan slab again and randomly pick one of its pieces. Pieces of Flavor 1 and pieces of Flavor 2 are prevalent here, so you may have ended up picking a piece of one of those two flavors. If you did, then you just found a way to satisfy the first friend. If not, please randomly pick another piece of that Yōkan slab. You may have gotten Flavor 1 or Flavor 2 that time. Still no? Then try a third time. If you’re choosing randomly, you’re bound to pick Flavor 1 or Flavor 2 within a small number of tries.</p>
<p class="indent">Let’s say that you’ve found Flavor 1 for the first friend. Now, do it again, this time for the second friend. It’ll be a little more difficult this time: the three Flavor 1 pieces are gone, so you’ll have to land on Flavor 2. Still, try picking a random piece a few times, and I’m sure you’ll eventually pick one of Flavor 2.</p>
<p class="indent">The program that we’ll write to solve this problem is going to do exactly what you just did: picking pieces randomly, trying to find one whose flavor makes each friend happy.</p>
<p class="indent">Suppose that the two friends are happy with a given Yōkan slab. This means that there’s a single flavor that shows up for 2/3 of the pieces, or two different flavors that each show up for 1/3 of the pieces. Regardless, we have a 2/3 chance of making the first friend happy by just choosing a piece at random. If we succeed, then we’re done with the first friend and we move <span epub:type="pagebreak" id="page_378"/>to the second friend. If we fail, well, we’ll just try again, and we’ll have a new 2/3 chance of success. If we fail that second time, we’ll try a third time, and a fourth time, until we succeed.</p>
<p class="indent">We’ll figure out how many attempts we need later. For now, though, I can promise that it won’t be very many. The intuition for this can come from a coin-tossing experiment.</p>
<p class="indent">Imagine that you were playing a game with a fair coin. If you toss the coin and it comes up heads, you win. If you toss the coin and it comes up tails, you have to try again. Think of the coin coming up heads as making the friend happy, and the coin coming up tails as not making the friend happy and having to try again. How many times do you expect to have to toss the coin before it comes up heads? Not many, right? If there’s a flavor in the slab that makes a friend happy, we’ll toss only so many tails in a row before we find a heads.</p>
<p class="indent">We were in the middle of working through a test case before all of that randomizing and coin-tossing talk, so let’s finish that before continuing.</p>
<p class="indent">The second query starts at Piece 8 and ends at Piece 11. The corresponding slab is:</p>
<div class="image1"><img alt="Image" src="../images/pg378-01.jpg"/></div>
<p class="indent">Unfortunately, the two friends are not happy with this one. Each friend needs to find at least 4/3 = <img alt="Image" src="../images/page_378_1.jpg"/> pieces of the same flavor; as the available number of pieces of each flavor is an integer, what we really need is at least 2 pieces of the same flavor. We can do this for the first friend with Flavor 2, but we’re stuck for the second friend. We need to output <code>NO</code> here.</p>
<p class="indent">The third query starts at Piece 5 and ends at Piece 6. That’s this part of the Yōkan:</p>
<div class="image1"><img alt="Image" src="../images/pg378-02.jpg"/></div>
<p class="indent">Each friend needs just one piece of a given flavor. We can therefore use Flavor 1 to make both friends happy: we can give one piece to the first friend and the other to the second friend! The correct output is therefore <code>YES</code>.</p>
<h4 class="h4" id="sec159"><em>Generating Random Numbers</em></h4>
<p class="noindent">We’ll need a way to generate random numbers in order to randomly pick Yōkan pieces. We’ll use C’s <code>rand</code> function to do this.</p>
<p class="indent">If we call <code>rand</code> with an integer <code>x</code>, we’re asking for <code>rand</code> to give us one of <code>x</code> possibilities. Specifically, we’ll get back a random integer in the range <code>0</code> to <code>x - 1</code>. For example, if we call <code>rand(4)</code>, we’ll get back a <code>0</code>, <code>1</code>, <code>2</code>, or <code>3</code>.</p>
<p class="indent">Now, how can we use <code>rand</code> to pick a random piece of a slab? Let’s use the term <em>width</em> to refer to the number of pieces in a slab. For example, the slab from Piece 8 to Piece 11 has a width of 4. In this case, we’d need <code>rand</code> to give us back <code>8</code>, <code>9</code>, <code>10</code>, or <code>11</code>. We can start by calling <code>rand(4)</code>, because we need <code>rand</code> <span epub:type="pagebreak" id="page_379"/>to give us one of four possibilities. That would give us a <code>0</code>, <code>1</code>, <code>2</code>, or <code>3</code>. This is a good start, but those numbers are not in the right range. To fix that, we can just add 8 to move that value into the 8–11 range that we need.</p>
<p class="indent">In code, generating a random number for a given width <code>width</code> and starting point <code>left</code> can be done as in <a href="ch10.xhtml#ch010ex01">Listing 10-1</a>.</p>
<pre>int random_piece(int left, int width) {
<span class="ent">❶</span> return (rand() % width) + left;
}</pre>
<p class="excap" id="ch010ex01"><em>Listing 10-1: Randomly choosing a piece</em></p>
<p class="indent">The code carries out the plan that we just outlined: it generates a random number from <code>0</code> to <code>width - 1</code>, then adds the starting point <code>left</code> to it <span class="ent">❶</span>.</p>
<h4 class="h4" id="sec160"><em>Determining Number of Pieces</em></h4>
<p class="noindent">Suppose that we’re working on a particular query. We’re going to choose a random piece in that query’s slab. Does the flavor of that piece make one or both of the friends happy? To answer that, we’ll need to be able to quickly determine how many times that flavor shows up in the slab.</p>
<p class="indent">It will therefore be convenient for us to have a sorted array for each flavor that gives us the pieces of that flavor. I’ll call such an array a <em>flavor array</em>.</p>
<p class="indent">Let’s go back to the Yōkan from our test case:</p>
<div class="image1"><img alt="Image" src="../images/pg379-01.jpg"/></div>
<p class="indent">The array for Flavor 1 would be <code>[1, 5, 6, 9, 13, 14]</code>; the array for Flavor 2 would be <code>[4, 7, 10, 11]</code>; and so on. As promised, each of these arrays is sorted: the piece numbers are in order from smallest to largest. We’ll see how to generate these flavor arrays later; for now let’s just assume they exist.</p>
<p class="indent">We can use such an array to determine the number of pieces of a given flavor that lie within a slab. For example, we could use the array <code>[1, 5, 6, 9, 13, 14]</code> to conclude that there are three pieces of Flavor 1 in the 3-11 slab: the pieces 5, 6, and 9.</p>
<p class="indent">Let’s take stock. We have the query that we want to solve. We have a random flavor that we care about checking. We have the flavor array: a sorted array of piece numbers of that flavor. And we need to determine how many of those pieces are in the range of the query.</p>
<p class="indent">We could do this using a linear search through the flavor array. But that would be too slow—a linear amount of work per query.</p>
<p class="indent">If you think back to <a href="ch07.xhtml">Chapter 7</a>, you might wonder whether we can call on a binary search here. We can indeed, because the array is sorted! Well, actually, we’ll need to call binary search twice rather than once, but that won’t change the fact that we’ll be able to find what we need in logarithmic time.</p>
<p class="indent"><span epub:type="pagebreak" id="page_380"/>We’re going to write a binary search function that takes a flavor array <code>pieces</code> and an integer <code>at_least</code> and returns the index of the leftmost value in the array that’s greater than or equal to <code>at_least</code>.</p>
<p class="indent">Before we do, we should make sure that the specification of that function actually does what we need. To that end, let’s use it to figure out how many pieces of Flavor 1 are in the 3-11 slab.</p>
<p class="indent">To figure out where the pieces of Flavor 1 begin in that slab, we can call our function with the array <code>[1, 5, 6, 9, 13, 14]</code> and an <code>at_least</code> value of <code>3</code>. We’ll get a result of <code>1</code>. This tells us that the piece at index 1 is the first piece of this flavor whose number is at least 3. That piece is Piece 5, which is indeed the first piece that we’re looking for.</p>
<p class="indent">Where do the pieces of Flavor 1 end in that slab? We can figure that out, too! Just call our function with the same array, but this time an <code>at_least</code> value of <code>12</code>. Why 12? Because that’s the first piece <em>not</em> in the slab. If we make this call, we’ll get a result of <code>4</code>. This refers to the piece at index 4, which is Piece 13. That’s the first piece of this flavor that’s not in the 3-11 slab. In general, to figure out where a flavor ends, we’ll call our binary search function with an <code>at_least</code> value that’s 1 larger than the right end of the slab.</p>
<p class="indent">Now we know where the relevant pieces start (index 1) and where the relevant pieces end (just to the left of index 4). If we subtract 1 from 4, we get an answer of 3, which is exactly the number of pieces of Flavor 1 in the 3-11 slab.</p>
<p class="indent">Let’s write the code for our binary search function. (Soon, we’ll see the function that calls this function twice.) As you learned in “Searching for a Solution” on <a href="ch07.xhtml#sec107">page 250</a>, the right way to write a binary search function is to first figure out the invariant. Our invariant will have two parts: that all values at indices less than <code>low</code> are <code>&lt; at_least</code>, and that all values at indices <code>high</code> or greater are <code>&gt;= at_least</code>. See <a href="ch10.xhtml#ch010ex02">Listing 10-2</a> for the code. In addition to the aforementioned <code>pieces</code> and <code>at_least</code> parameters, we have a parameter <code>num_pieces</code> that gives the number of pieces in the <code>pieces</code> array.</p>
<pre>int lowest_index(int pieces[], int num_pieces, int at_least) {
  int low, high, mid;
<span class="ent">❶</span> low = 0;
<span class="ent">➋</span> high = num_pieces;
<span class="ent">➌</span> while (high - low &gt;= 1) {
     mid = (low + high) / 2;
     if (pieces[mid] &lt; at_least)
       low = mid + 1;
     else
       high = mid;
  }
<span class="ent">➍</span> return low;
}</pre>
<p class="excap" id="ch010ex02"><em>Listing 10-2: Searching for the first satisfying value</em></p>
<p class="indent">We need to make both parts of the invariant true above the loop. For the first part, notice that the invariant isn’t making any claim about the <span epub:type="pagebreak" id="page_381"/>value at index <code>low</code>; it makes a claim only about the values to the left of index <code>low</code>. For that reason, we can set <code>low</code> to <code>0</code> above the loop <span class="ent">❶</span>; there’s nothing to the left of <code>low</code> now, so this part of the invariant is satisfied.</p>
<p class="indent">For the second part, the invariant claims something about all of the values at indices <code>high</code> or greater. Since we don’t know anything about any value in the array, we need to make this part of the invariant claim nothing. We can do this by setting <code>high</code> to just beyond the right end of the array <span class="ent">➋</span>: now there are no valid indices between <code>high</code> and the end of the array.</p>
<p class="indent">The code inside the <code>while</code> loop maintains the invariant. I encourage you to check this for yourself if you like, but you’ve had a lot of binary search practice already so I don’t blame you if you’d rather not!</p>
<p class="indent">The <code>while</code> loop condition <span class="ent">➌</span> ensures that <code>low</code> and <code>high</code> are equal when the loop terminates. The invariant tells us that all values to the left of <code>low</code> are too small and that <code>low</code> is the first index of the value that’s <code>&gt;= at_least</code>. This is why we return <code>low</code> when the function terminates <span class="ent">➍</span>.</p>
<p class="indent">Next, as promised, we’re going to make two calls of that function to figure out how many pieces of a given flavor are within the range of a given slab. See <a href="ch10.xhtml#ch010ex03">Listing 10-3</a> for the code.</p>
<pre>int num_in_range(int pieces[], int num_pieces, int left, int right) {
<span class="ent">❶</span> int left_index = lowest_index(pieces, num_pieces, left);
<span class="ent">➋</span> int right_index = lowest_index(pieces, num_pieces, right + 1);
<span class="ent">➌</span> return right_index - left_index;
}</pre>
<p class="excap" id="ch010ex03"><em>Listing 10-3: Determining number of pieces of a given flavor that are in range</em></p>
<p class="indent">Here, the <code>pieces</code> parameter is the flavor array, and the <code>left</code> and <code>right</code> parameters indicate the leftmost and rightmost pieces of the slab. The code first finds the index in the slab where the flavor starts <span class="ent">❶</span>. Then it finds the index immediately to the right of where the flavor ends in the slab <span class="ent">➋</span>. Finally, it subtracts the first of these indices from the second to determine the number of pieces of the flavor in the slab <span class="ent">➌</span>.</p>
<h4 class="h4" id="sec161"><em>Guessing Flavors</em></h4>
<p class="noindent">At this point, we know what to do once we’ve guessed a flavor: use binary search to check whether the guessed flavor makes one or both friends happy. Now we need to work on the code that makes the guesses.</p>
<p class="indent">Our overall strategy can be broken down into three steps:</p>
<p class="block"><strong>Step 1</strong>   Figure out the number of pieces that we need to make one friend happy.</p>
<p class="block"><strong>Step 2</strong>   Try to make the first friend happy. Start by guessing a piece. If the flavor of that piece makes the friend happy, then we are done; otherwise, guess again. Keep guessing until we succeed or until we run out of guesses. It’s possible for us to find a flavor that’s so prevalent that it makes not just the first friend happy, but <em>both</em> friends happy. If that happens, we pump out a <code>YES</code> and stop right there, without doing Step 3.</p>
<p class="block"><span epub:type="pagebreak" id="page_382"/><strong>Step 3</strong>   Try to make the second friend happy using the same strategy that we used for the first friend. If we happen to guess the flavor that made the first friend happy, then we need to ignore it and move on to our next attempt because that flavor isn’t prevalent enough to make both friends happy.</p>
<p class="indent">We’ll write the function for the following signature:</p>
<pre>void solve(int yokan[], int *pieces_for_flavor[],
           int num_of_flavor[], int left, int right)</pre>
<p class="indent">Here’s what each parameter is for:</p>
<p class="block"><span class="codestrong">yokan</span>   The array of Yōkan flavors; <code>yokan[1]</code> is the flavor of the first piece, <code>yokan[2]</code> is the flavor of the second piece, and so on. (We start at index 1 rather than 0 because the pieces are numbered from 1 in this problem.) We need this array so that we can choose a random piece.</p>
<p class="block"><span class="codestrong">pieces_for_flavor</span>   The array of flavor arrays. Each flavor array is sorted from smallest piece number to largest piece number. For example, <code>pieces_for_flavor[1]</code> might be the array <code>[1, 5, 6, 9, 13, 14]</code>, telling us all of the pieces that are of Flavor 1. We need these arrays so that we can binary search them.</p>
<p class="block"><span class="codestrong">num_of_flavor</span>   An array giving the number of pieces of each flavor; <code>num_of_flavor[1]</code> is the number of pieces of Flavor 1, <code>num_of_flavor[2]</code> is the number of pieces of Flavor 2, and so on. That is, this array tells us how many elements are in each of the flavor arrays.</p>
<p class="block"><span class="codestrong">left</span>   The beginning index of the current query.</p>
<p class="block"><span class="codestrong">right</span>   The ending index of the current query.</p>
<p class="indent">The code for this function is in <a href="ch10.xhtml#ch010ex04">Listing 10-4</a>. Look out for the three steps—figure out the happy threshold, make the first friend happy, make the second friend happy—as you read through the code.</p>
<pre>void solve(int yokan[], int *pieces_for_flavor[],
           int num_of_flavor[], int left, int right) {
  int attempt, rand_piece, flavor, result;
  int width = right - left + 1;
<span class="ent">❶</span> double threshold = width / 3.0;
   int first_flavor = 0;

<span class="ent">➋</span> for (attempt = 0; attempt &lt; NUM_ATTEMPTS; attempt++) {
  <span class="ent">➌</span> rand_piece = random_piece(left, width);
     flavor = yokan[rand_piece];
  <span class="ent">➍</span> result = num_in_range(pieces_for_flavor[flavor],
                           num_of_flavor[flavor], left, right);
  <span class="ent">➎</span> if (result &gt;= 2 * threshold) {
       printf("YES\n");
       return;
     }
<span epub:type="pagebreak" id="page_383"/>  <span class="ent">➏</span> if (result &gt;= threshold)
    <span class="ent">❼</span> first_flavor = flavor;
  }

  if (first_flavor == 0) {
    printf("NO\n");
    return;
  }

<span class="ent">❽</span> for (attempt = 0; attempt &lt; NUM_ATTEMPTS; attempt++) {
     rand_piece = random_piece(left, width);
     flavor = yokan[rand_piece];
  <span class="ent">❾</span> if (flavor == first_flavor)
       continue;
     result = num_in_range(pieces_for_flavor[flavor],
                           num_of_flavor[flavor], left, right);
     if (result &gt;= threshold) {
       printf("YES\n");
       return;
     }
  }

  printf("NO\n");
}</pre>
<p class="excap" id="ch010ex04"><em>Listing 10-4: Solving the problem</em></p>
<p class="indent">For Step 1, we determine the number of pieces that will make a friend happy <span class="ent">❶</span>.</p>
<p class="indent">For Step 2, we start guessing flavors for the first friend <span class="ent">➋</span>. The <code>for</code> loop uses a <code>NUM_ATTEMPTS</code> constant that we haven’t defined yet. We’ll decide on this number after we finish walking through this function. In the <code>for</code> loop, we choose a random piece from the current slab <span class="ent">➌</span>, then call our <code>num_in_range</code> helper function to get the number of pieces in the slab that have the same flavor as that random piece <span class="ent">➍</span>.</p>
<p class="indent">Did our random flavor make one or both of the friends happy? We first check whether the flavor was so prevalent that it makes both friends happy. Specifically, if the flavor shows up 2/3 of the time (that is, twice the threshold value), it can be used to make both friends happy <span class="ent">➎</span>. In this case, we’re done: we just output <code>YES</code> and return. If the flavor doesn’t make both friends happy, it might still be good enough to make the first friend happy, so we check for that next <span class="ent">➏</span>. We also record the flavor that we found for the first friend <span class="ent">❼</span>.</p>
<p class="indent">If in all our guessing we weren’t able to find a flavor for the first friend, then we output <code>NO</code> and stop.</p>
<p class="indent">If we were able to find a flavor for the first friend, then we proceed to Step 3 <span class="ent">❽</span>, where we try to find a flavor for the second friend. The logic is quite similar to what we did for the first friend. The only addition is to <span epub:type="pagebreak" id="page_384"/>ensure that we don’t inadvertently use the flavor that we already used for the first friend <span class="ent">❾</span>.</p>
<p class="indent">If we get to the bottom of the function, it means that we weren’t able to find a flavor for the second friend. We output <code>NO</code> in this case.</p>
<h4 class="h4" id="sec162"><em>How Many Attempts Do We Need?</em></h4>
<p class="noindent">Let’s finally answer the question of how many attempts we need to ensure a ridiculously high probability of success.</p>
<p class="indent">We’ll assume that each query asks about a slab of the Yōkan where exactly one third of the pieces are of some flavor <em>x</em>, exactly one third are of some other flavor <em>y</em>, and the rest of the pieces are distributed among a bunch of other flavors. That will be the hardest type of query of all for us. We may get lucky and run into a query where one flavor shows up 50 percent or 70 percent or 85 percent of the time, and for those we’ll have an easier time with our guessing. But we’re focusing on the hardest type of query because if we can nail that one, then we know that we can nail any others.</p>
<p class="indent">Don’t worry if you haven’t worked with probability before. A <em>probability</em> is just a value in the range 0 to 1. If something has a probability of 0 then it never occurs; if something has a probability of 1 then it occurs every time. You can multiply a probability value by 100 to turn it into a percentage. For example, when tossing a coin there is a 0.5 probability that it comes up heads; multiplied by 100, we see it equivalently has a 0.5 × 100 = 50 percent chance of coming up heads. We need a couple of other rules of probability as well, but I’ll explain those as we go along.</p>
<p class="indent">Let’s just pick a number of guesses out of nowhere and see how well we do. How about 10? We’ll first figure out the probability that we make the first friend happy. On our first guess, we have a 2/3 probability of success. That’s because 2/3 of the pieces in the slab are of one of the two flavors that each show up 1/3 of the time. What’s our probability of failure? There are only two outcomes here: success and failure. They have to add up to 1, because there’s a 100 percent chance that one of these two outcomes happens. So we can find the probability of failure by subtracting the probability of success from 1. That gives us a 1 – 2/3 = 1/3 probability of failure.</p>
<p class="indent">What’s the probability of failure on all 10 guesses? For that to happen, we need to have failed on each guess independently. There’s a 1/3 probability that we fail on the first guess, a 1/3 probability that we fail on the second guess, a 1/3 probability that we fail on the third guess, and so on. There’s a rule that we can use here to figure out the probability that we fail on all of these 10 independent guesses: just multiply all of the probabilities together. We see that the probability of failing on all 10 guesses is (1/3)<sup>10</sup>, which is about 0.000017.</p>
<p class="indent">Now we are able to calculate our probability of success for this friend: 1 – 0.000017 = 0.999983.</p>
<p class="indent">This is a better-than-99.99 percent probability of success. We’re doing great!</p>
<p class="indent">What’s the probability that we make the second friend happy given that we made the first friend happy? For this one, the probability of success on <span epub:type="pagebreak" id="page_385"/>each attempt is 1/3, not 2/3, because the pieces of the first friend’s flavor are gone. If you run through the calculation starting with 1/3 rather than 2/3, you should find a probability of success for the second friend of about 0.982658. That’s over 98.2 percent! We’re still looking good.</p>
<p class="indent">It’s nice that we now have both the probability of success for the first friend and the probability of success for the second friend given success on the first friend. But what we care about more is the probability of success for both friends. To find that, we can multiply our two success probabilities together. Doing so, we find that the overall probability of making both friends happy is 0.999983 × 0.982658 = 0.982641.</p>
<p class="indent">This probability is more than 98.2 percent. Pretty good, right? Unfortunately, no. If we had to process one query, then this probability would be just fine. But we may need to process a massive 200,000 queries. And we need to get every single one of them right. If we get even one wrong, then we fail the test case.</p>
<p class="indent">Suppose you’re throwing a ball into a basket and you have a 98.2 percent probability of success on each throw. You throw one ball. That one’s probably going in. Now imagine that you throw 100 balls. You’re probably going to botch at least a couple of those throws. And if you threw 200,000 balls? Your probability of getting every single one into the basket is near 0.</p>
<p class="indent">While 10 attempts was a good try, it isn’t enough. We need more. Through some trial and error, I’ve settled on using 60 attempts for each friend. If you run through the calculations using 60 guesses instead of 10, you should find a success probability for each query of about 0.99999999997.</p>
<p class="indent">That’s a lot of 9s! But we need them all because otherwise we’d take a massive probability hit when going from 1 query to 200,000. To find our probability of success for 200,000 queries, we can raise our per-query probability of success to the power of 200,000: 0.99999999997<sup>200,000</sup> = 0.999994.</p>
<p class="indent">It looks like we’ve lost a few 9s. Still, this is a staggeringly high probability, and this time it is for the probability that we get every single query right, not just one.</p>
<p class="indent">We’re finally ready to set our <code>NUM_ATTEMPTS</code> constant. Let’s use <code>60</code>:</p>
<pre>#define NUM_ATTEMPTS 60</pre>
<h4 class="h4" id="sec163"><em>Filling the Flavor Arrays</em></h4>
<p class="noindent">We’re almost ready for the <code>main</code> function; we just need one more little helper function first.</p>
<p class="indent">That helper function will take <code>yokan</code> (the Yōkan array) and <code>num_pieces</code> (the number of pieces in the Yōkan) and produce the <code>pieces_for_flavor</code> flavor arrays that we used in the <code>solve</code> function. See <a href="ch10.xhtml#ch010ex05">Listing 10-5</a> for the code.</p>
<pre>#define MAX_FLAVORS 200000

void init_flavor_arrays(int yokan[], int num_pieces,
                        int *pieces_for_flavor[]) {
<span class="ent">❶</span> static int cur_of_flavor[MAX_FLAVORS + 1];
   int i, flavor, j;
   for (i = 1; i &lt;= num_pieces; i++) {
     flavor = yokan[i];
  <span class="ent">➋</span> j = cur_of_flavor[flavor];
     pieces_for_flavor[flavor][j] = i;
     cur_of_flavor[flavor]++;
   }
}</pre>
<p class="excap" id="ch010ex05"><span epub:type="pagebreak" id="page_386"/><em>Listing 10-5: Filling in the flavor arrays</em></p>
<p class="indent">The function assumes that each array in <code>pieces_for_flavor</code> already has memory assigned to it; that’s a responsibility of the <code>main</code> function that’s coming up next.</p>
<p class="indent">We use a local <code>cur_of_flavor</code> array <span class="ent">❶</span> to track the number of pieces we’ve found so far of each flavor. Inside the <code>for</code> loop, we use this array to determine the index in which to store the current piece number <span class="ent">➋</span>.</p>
<h4 class="h4" id="sec164"><em>The main Function</em></h4>
<p class="noindent">We’ve made it to the <code>main</code> function! Check it out in <a href="ch10.xhtml#ch010ex06">Listing 10-6</a>.</p>
<pre>#define MAX_PIECES 200000

int main(void) {
  static int yokan[MAX_PIECES + 1];
  static int num_of_flavor[MAX_FLAVORS + 1];
  static int *pieces_for_flavor[MAX_FLAVORS + 1];
  int num_pieces, num_flavors, i, num_queries, l, r;
<span class="ent">❶</span> srand((unsigned) time(NULL));
   scanf("%d%d", &amp;num_pieces, &amp;num_flavors);

<span class="ent">➋</span> for (i = 1; i &lt;= num_pieces; i++) {
     scanf("%d", &amp;yokan[i]);
     num_of_flavor[yokan[i]]++;
   }

<span class="ent">➌</span> for (i = 1; i &lt;= num_flavors; i++) {
  <span class="ent">➍</span> pieces_for_flavor[i] = malloc(num_of_flavor[i] * sizeof(int));
     if (pieces_for_flavor[i] == NULL) {
       fprintf(stderr, "malloc error\n");
       exit(1);
     }
  }

<span class="ent">➎</span> init_flavor_arrays(yokan, num_pieces, pieces_for_flavor);

  scanf("%d", &amp;num_queries);
<span epub:type="pagebreak" id="page_387"/>  for (i = 0; i &lt; num_queries; i++) {
    scanf("%d%d", &amp;l, &amp;r);
  <span class="ent">➏</span> solve(yokan, pieces_for_flavor, num_of_flavor, l, r);
  }

  return 0;
}</pre>
<p class="excap" id="ch010ex06"><em>Listing 10-6: The</em> <span class="codeitalic1">main</span> <em>function</em></p>
<p class="indent">Before we can use C’s <code>rand</code> function, we need to use the <code>srand</code> function to initialize the random number generator with a seed. The seed determines the sequence of random numbers that are generated. We don’t want to use the same seed every time, otherwise we’ll generate the same sequence of numbers each time. What works well is to use the current time as the seed so that the random numbers change each time we run the program. We do that using C’s <code>time</code> function <span class="ent">❶</span>. To use that function, you’ll need to add <code>#include &lt;time.h&gt;</code> at the top of your program.</p>
<p class="indent">There are two important <code>for</code> loops here. The first one <span class="ent">➋</span> fills in the <code>yokan</code> array and also uses the <code>num_of_flavor</code> array to keep track of the number of pieces of each flavor. Why do we need to know the number of pieces of each flavor? It’s because, without knowing that, we wouldn’t know how big to make each flavor array. The second <code>for</code> loop <span class="ent">➌</span> is responsible for allocating memory for the flavor arrays. It uses <code>num_of_flavor</code> to determine exactly how big each flavor array should be <span class="ent">➍</span>.</p>
<p class="indent">Following these <code>for</code> loops, we call our helper function to fill in the flavor arrays whose memory we just allocated <span class="ent">➎</span>.</p>
<p class="indent">And then we’re off to the queries! For each one, we call our <code>solve</code> function <span class="ent">➏</span> to print <code>YES</code> or <code>NO</code> as needed.</p>
<p class="indent">If you submit our code to the judge, you should find that it passes all test cases within the time limit. If your code is correct and you somehow fail a test case, take a screenshot: you’ll probably never see that again.</p>
<h3 class="h3" id="lev64">Randomization</h3>
<p class="noindent">There are two main types of randomized algorithms. We just learned about one of them. Let’s expand on that one here and preview the other.</p>
<h4 class="h4" id="sec165"><em>Monte Carlo Algorithms</em></h4>
<p class="noindent">The type of algorithm that we used to solve Yōkan, where there’s a chance that we get the answer wrong, is called a <em>Monte Carlo Algorithm</em>. The key question when using such an algorithm is: How many attempts should we use? There’s a tradeoff between the number of attempts and the probability of success: as we crank up the number of attempts, we increase the probability of success but slow down the algorithm. We generally want to find a sweet spot where the probability of success is high enough but our algorithm is still fast. Of course, what counts as a “high enough” probability <span epub:type="pagebreak" id="page_388"/>of success depends on what we’re using the algorithm for. Solving a programming competition problem? Ninety-nine percent probability of success is fine. (If the algorithm fails, who cares: just run it again.) For algorithms that impact the health and safety of people, though, 99 percent is not okay.</p>
<p class="indent">In our solution to Yōkan, if we answer <code>YES</code>, then we’re guaranteed to be correct. We only answer <code>YES</code> when we’re staring at the very flavors that show why the friends are happy with the slab. By contrast, if we answer <code>NO</code>, then we might be wrong. It might be the case that the friends aren’t happy with the slab—but it could also be that we just got unlucky and kept picking bad flavors. Because only one of the two types of answers can be wrong, we say that our algorithm has <em>one-sided errors</em>. There are Monte Carlo algorithms that can be wrong in both the “yes” and “no” cases; those are said to have <em>two-sided errors</em>.</p>
<p class="indent">A Monte Carlo algorithm helped us solve Yōkan because the probability of randomly finding a useful flavor is so high. It might not seem that a 1/3 or 2/3 probability of success is that great, and indeed an algorithm that worked only one-third or two-thirds of the time wouldn’t cut it. But remember that these probabilities are only our starting point. By the time we’re done with our repeated attempts, we’ll have converted that wonderful per-attempt probability to a wonderful per-answer probability.</p>
<p class="indent">Monte Carlo algorithms are useful for other problems as well. Consider a graph with <em>n</em> nodes and imagine dividing the nodes into two groups. There are about 2<em><sup>n</sup></em> ways to make this division, because for each of the <em>n</em> nodes we have two options for where to put it. Such a division of nodes into two groups is called a <em>cut</em>. The <em>minimum cut problem</em> asks which of these 2<em><sup>n</sup></em> divisions has the fewest edges that cross from one group to the other. Now, if we just randomly chose a cut, we’d have a per-attempt probability of success of 1/2<em><sup>n</sup></em>, which is terrible and not a promising start to a Monte Carlo algorithm. There <em>is</em> a Monte Carlo algorithm for this problem, though, and it hinges on the surprising fact that the per-attempt probability of success can be driven up to 1/<em>n</em><sup>2</sup>. Relative to 1/2<em><sup>n</sup></em>, a probability of success of 1/<em>n</em><sup>2</sup> is high indeed.</p>
<p class="indent">If you can find a way to come up with a “surprisingly high” per-attempt probability of success, then you’re well on your way to developing a useful Monte Carlo algorithm. Just crank up the number of attempts until you get the overall probability of success that you want.</p>
<h4 class="h4" id="sec166"><em>Las Vegas Algorithms</em></h4>
<p class="noindent">A Monte Carlo algorithm is always fast and almost always correct. A <em>Las Vegas Algorithm</em>, by contrast, is always correct and almost always fast. (These algorithms were given casino-related names to evoke the idea of gambling: with a Monte Carlo algorithm we’re gambling with correctness, and with a Las Vegas algorithm we’re gambling with speed.)</p>
<p class="indent">Suppose we had an algorithm that was quite fast for the vast majority of test cases but quite slow for the few remaining test cases. We might be okay to deploy this algorithm; we just have to hope that the Achilles’ heel test cases don’t happen very often.</p>
<p class="indent"><span epub:type="pagebreak" id="page_389"/>But we can do better than that, and one way is through the use of a Las Vegas algorithm. In such an algorithm, we randomize the decisions that the algorithm makes as it runs. Because the algorithm has no fixed sequence of steps, no one can craft a test case that’ll reliably slow it down because no one knows what decisions the algorithm will make on that test case!</p>
<p class="indent">Why can Las Vegas algorithms be effective? I like Ethan Epperly’s article “Why Randomized Algorithms?” (see <em><a href="https://www.ethanepperly.com/index.php/2021/08/11/why-randomized-algorithms/">https://www.ethanepperly.com/index.php/2021/08/11/why-randomized-algorithms/</a></em>). Suppose you were playing many rounds of Rock Paper Scissors against your friend. One approach would be to use a fixed pattern, like rock, paper, scissors, rock, paper, scissors, rock, paper . . . This might work for a little while—but eventually your friend will figure out what you’re doing, and then you’ll never win a round again. They’ll just keep picking the option that beats you. A better approach is to randomly decide what to do on each round. If you do that, you’re using a Las Vegas algorithm. Your friend will have no clue what’s coming next! In our code for such an algorithm, we’ll randomize the choices that we make so that no fixed test case can force us into poor performance.</p>
<p class="indent">Way back in <a href="ch01.xhtml">Chapter 1</a>, we solved two problems using hash tables. In each one, we chose one specific hash function and just went for it. A malicious actor could bring those solutions to a crawl by intentionally causing a huge number of hash collisions. It’s possible to address that through a Las Vegas algorithm: rather than committing to a single hash function for all of time, sitting there waiting for someone to figure out what we’re doing, we let our program randomly choose which hash function to use each time it runs. Doing so is called <em>random hashing</em>.</p>
<p class="indent">Random hashing is a frequently used Las Vegas algorithm. But there’s one Las Vegas algorithm used even more frequently than that. We’re going to see that one in Problem 2. First, let’s talk about whether we really do need randomization in the first place.</p>
<h4 class="h4" id="sec167"><em>Deterministic vs. Randomized Algorithms</em></h4>
<p class="noindent">A <em>deterministic algorithm</em> is an algorithm that doesn’t use randomness. Every algorithm we looked at in the first nine chapters of this book is a deterministic algorithm, and wow did we get a lot of mileage from those. Why not just forget about randomized algorithms and stick with deterministic ones, then? Why play around with guessing stuff and getting a 99.9999 percent probability of success when we can just have 100 percent success with a deterministic algorithm?</p>
<p class="indent">The reason is that a fast randomized algorithm can be easier to develop than a fast deterministic algorithm. If you’re interested, you might try solving Yōkan without using randomization. It’s certainly possible but requires additional ideas not needed in the randomized algorithm.</p>
<p class="indent">There are problems where the efficiency gulf between the currently best randomized algorithm and the currently best deterministic algorithm is huge. For example, to determine whether a number is prime, there’s a randomized algorithm that runs in <em>O</em>(<em>n</em><sup>2</sup>) time, but the best we’ve been able to do in terms of deterministic algorithms is <em>O</em>(<em>n</em><sup>6</sup>).</p>
<p class="indent"><span epub:type="pagebreak" id="page_390"/>Likewise, it’s difficult to find a way to quickly solve our next problem with a deterministic algorithm. Good thing we don’t have to. Let’s do some more randomization!</p>
<h3 class="h3" id="lev65">Problem 2: Caps and Bottles</h3>
<p class="noindent">This is DMOJ problem <code>cco09p4</code>.</p>
<h4 class="h4" id="sec168"><em>The Problem</em></h4>
<p class="noindent">We have <em>n</em> caps and <em>n</em> bottles. Each cap and bottle has a unique size, and there is exactly one cap that perfectly fits each bottle.</p>
<p class="indent">Our goal is to match the caps to their corresponding bottles. (I’ve seen this problem alternately phrased as matching nuts and bolts, keys and locks, hats and people’s heads, you name it. Feel free to use one of these if it works as a better visual for you.)</p>
<p class="indent">The caps and bottles have very similar sizes, so we cannot make comparisons between two caps or between two bottles. The only thing we can do is try to put a cap on a bottle to learn whether the cap is too small, the right size, or too big for the bottle.</p>
<p class="indent">To solve the problem, we interact with the judge by making queries and progressively reporting our answer until we are done. (It’s kind of like how we interacted with the judge when solving Cave Doors in <a href="ch07.xhtml">Chapter 7</a>, but here we communicate with the judge by using input and output rather than by calling functions.)</p>
<h5 class="h5">Input and Output</h5>
<p class="noindent">Because input and output are interleaved in this problem, we’ll look at them together.</p>
<p class="indent">To start, we read the integer <em>n</em>, which tells us the number of caps and bottles that we must match. <em>n</em> is between 1 and 10,000. The caps are numbered from 1 to <em>n</em>, as are the bottles.</p>
<p class="indent">After reading <em>n</em>, we can interact with the judge in two ways.</p>
<p class="block"><strong>Query</strong>   We can make a query by outputting <code>0 cap_num bottle_num</code>. This asks the judge to tell us about the relationship between the cap numbered <code>cap_num</code> and the bottle numbered <code>bottle_num</code>. We need to read from the input to get the answer to our query. We’ll get a –1 if the cap is too small for the bottle, a 0 if it matches the bottle, or a 1 if it’s too big for the bottle.</p>
<p class="block"><strong>Report</strong>   We can tell the judge part of our answer by outputting <code>1 cap_num bottle_num</code>, which means that we are matching the cap numbered <code>cap_num</code> with the bottle numbered <code>bottle_num</code>. The judge doesn’t produce anything for us to read in response.</p>
<p class="indent">We need to eventually make <em>n</em> reports to the judge in order to match each of the <em>n</em> caps with some distinct bottle. We can mix and match queries <span epub:type="pagebreak" id="page_391"/>and reports as we prefer; that is, there’s no requirement to make all queries before all reports or anything like that.</p>
<p class="indent">We are allowed to make at most 500,000 queries.</p>
<h4 class="h4" id="sec169"><em>Solving a Subtask</em></h4>
<p class="noindent">For most problems in this book, we read from standard input, do what the problem asks, and output the answer on standard output. Oftentimes, such as for each problem in the previous chapter, what we read from standard input are operations that tell us what to do next. The interaction for this Caps and Bottles problem is a little different. Rather than being asked to respond to queries, we are the ones making the queries to the judge.</p>
<p class="indent">The last time we had a nonstandard interaction with the judge was when we solved Cave Doors in <a href="ch07.xhtml">Chapter 7</a>. There, we first solved a small subtask, rather than the whole problem, to give us confidence that we were interacting correctly. Let’s start that way here.</p>
<p class="indent">The first subtask for this problem guarantees that <em>n</em> will be at most 700. The first algorithm that we come up with might make a lot of queries; the hope is that with only 700 caps and bottles we’ll be able to pass at least those test cases.</p>
<p class="indent">We need to figure out which bottle goes with each cap. Well, why not go through the caps one by one, and just ask about each bottle for each cap? If we do that, we get the code in <a href="ch10.xhtml#ch010ex07">Listing 10-7</a>.</p>
<pre>int main(void) {
  int n, cap_num, bottle_num, result;
<span class="ent">❶</span> scanf("%d", &amp;n);
  for (cap_num = 1; cap_num &lt;= n; cap_num++)
    for (bottle_num = 1; bottle_num &lt;= n; bottle_num++) {
   <span class="ent">➋</span> printf("0 %d %d\n", cap_num, bottle_num);
   <span class="ent">➌</span> scanf("%d", &amp;result);
      if (result == 0) {
     <span class="ent">➍</span> printf("1 %d %d\n", cap_num, bottle_num);
        break;
      }
   }
   return 0;
}</pre>
<p class="excap" id="ch010ex07"><em>Listing 10-7: Solving subtask 1</em></p>
<p class="indent">Let’s make sure we’ve got the interaction right. We start by reading the value of <code>n</code> <span class="ent">❶</span>, which tells us how many caps and bottles we’re dealing with. Then we have a double <code>for</code> loop that considers matching each cap with each bottle. For each such cap-bottle pair, we query the judge <span class="ent">➋</span>. We know that the judge will then produce a response, so we read that next <span class="ent">➌</span>. If we’ve found a match, we tell the judge about it <span class="ent">➍</span>.</p>
<p class="indent"><span epub:type="pagebreak" id="page_392"/>It’s a bit of a mind-bend to test this program locally, but let’s do it anyway. We need to play the role of the judge, responding consistently to the queries that the program makes.</p>
<p class="indent">We’ll work through a test case with three caps and bottles. To “play judge,” we need to settle on some sizes for the caps and bottles so that we can respond consistently to the queries. The program will never know what these sizes are, but as the judge we need them so that we know whether a cap is too small or too large. Let’s agree that the cap sizes are as follows:</p>
<div class="image1"><img alt="Image" src="../images/pg392-01.jpg"/></div>
<p class="indent">and that the bottle sizes are as follows:</p>
<div class="image1"><img alt="Image" src="../images/pg392-02.jpg"/></div>
<p class="indent">If the program handles this test case correctly, it will match Cap 1 with Bottle 2, Cap 2 with Bottle 1, and Cap 3 with Bottle 3.</p>
<p class="indent">Run our program. Type <code>3</code> from the keyboard to indicate that <code>n</code> is <code>3</code>.</p>
<p class="indent">Now the program starts making queries. You’ll see those show up as part of the program’s output. The first one is <code>0 1 1</code>, which is asking us for the relationship between Cap 1 and Bottle 1. Cap 1 (size 23) is smaller than Bottle 1 (size 85), so we need to type <code>-1</code> here. Go ahead—and once you do, we’ll be asked another query.</p>
<p class="indent">The next query we get is <code>0 1 2</code>, which asks us about Cap 1 and Bottle 2. This cap and bottle match, so type <code>0</code>. The program correctly reports that Cap 1 and Bottle 2 are matched.</p>
<p class="indent">Now that our program has figured out how to match Cap 1, it should move on to Cap 2. That’s exactly what it does, as we can see from the next query: <code>0 2 1</code>. Cap 2 and Bottle 1 match, so we need to type <code>0</code> in response. The program now correctly reports a match between Cap 2 and Bottle 1.</p>
<p class="indent">All the program has to figure out now is what to do with Cap 3. It asks the query <code>0 3 1</code>, to which we must type <code>-1</code> because Cap 3 is smaller than Bottle 1. Then it asks <code>0 3 2</code>, and again we type <code>-1</code>. Finally, we get the query <code>0 3 3</code>; as Cap 3 and Bottle 3 match, we type <code>0</code>. When we do so, the program should correctly report that Cap 3 is matched with Bottle 3 . . . and we’re done! The program has successfully matched the caps and bottles.</p>
<p class="indent">If you submit our code to the judge, you should pass a few test cases.</p>
<p class="indent">The reason we don’t pass more is because of the requirement that we make at most 500,000 queries. We can tell from our nested <code>for</code> loops that we have an <em>O</em>(<em>n</em><sup>2</sup>) algorithm here. With 10,000 caps and bottles, we might make up to 10, 000<sup>2</sup> = 100,000,000 queries. That’s way too many! We’ll need new ideas to complete the remaining subtasks.</p>
<h4 class="h4" id="sec170"><span epub:type="pagebreak" id="page_393"/><em>Solution 1: Recursion</em></h4>
<p class="noindent">If we stay with our idea of choosing a cap and then figuring out which bottle matches it, we need to make better use of the information that the judge gives us.</p>
<h5 class="h5">Piles of Caps and Bottles</h5>
<p class="noindent">In the algorithm that we used to solve the subtask, we ask the judge about the relationship between Cap 1 and Bottle 1, Cap 1 and Bottle 2, Cap 1 and Bottle 3, and so on, until we find the bottle that matches Cap 1. Maybe we finally find the match with bottle 5,000. That was a lot of work! For the cost of 5,000 queries, we match one cap and one bottle, and that’s all we get. We’re back to square one for the next cap.</p>
<p class="indent">We’re throwing away a lot of information on our way to matching that first cap, though, and that’s information we can use to make it easier for us to match other caps later. In particular, so far we’re not doing anything with the “too small” and “too big” information that the judge gives us.</p>
<p class="indent">If you were doing this by hand, how could you use this information from the judge? One thing you might do is form two piles of bottles: one of small bottles and one of big bottles. suppose we find that Cap 1 is too small for Bottle 1. Throw that bottle into the big pile. Then maybe we find that Cap 1 is too big for Bottle 2. That bottle goes into the small pile. Cap 1 is too big for Bottle 3? That bottle goes into the small pile, as well. Do this for every bottle.</p>
<p class="indent">Now what we have are two piles of bottles. Maybe these are subproblems? The hope is that we could solve each subproblem and thereby solve the original problem.</p>
<p class="indent">This may feel like the setup to a dynamic-programming solution. But it’s not, because the two subproblems are not overlapping. Solving one of them doesn’t help us at all with the other one. Recursion, then? Can we use that?</p>
<p class="indent">For recursion to work, we need each subproblem to be a smaller version of the original problem. Our original problem had a bunch of caps and bottles. But, so far, our subproblems have only bottles. Where are the caps to go with those bottles? We need to find a way to split the caps into small caps and large caps, too. Once we do that, we’ll truly have our two subproblems: one for the small caps and bottles and one for the big caps and bottles.</p>
<p class="indent">Here are the overall steps that we’ll use.</p>
<p class="block"><strong>Step 1</strong>   Choose a cap for our subproblem.</p>
<p class="block"><strong>Step 2</strong>   Go through the bottles. If the cap is smaller than the bottle, put the bottle in the pile of big bottles; if the cap is bigger than the bottle, put the bottle in the pile of small bottles. At some point during this step, we’re going to find the bottle that matches the cap. Call this the <em>matching bottle</em>. Report the match between the cap and the matching bottle.</p>
<p class="indent">At the end of Step 2, we’ll have the two piles of bottles that we need. Now for the caps . . .</p>
<p class="block"><span epub:type="pagebreak" id="page_394"/><strong>Step 3</strong>   Go through the caps. If the current cap is smaller than the matching bottle, put the cap in the pile of small caps; if the current cap is bigger than the matching bottle, put the cap in the pile of big caps. At the end of this step, we’ll have the two piles of caps that we need.</p>
<p class="block"><strong>Step 4</strong>   Recursively solve the subproblem on the small caps and small bottles.</p>
<p class="block"><strong>Step 5</strong>   Recursively solve the subproblem on the big caps and big bottles.</p>
<p class="indent">Like binary search, this is an example of a divide and conquer algorithm. We’re dividing the caps and bottles into smaller, independent subproblems and then conquering each of those subproblems recursively.</p>
<h5 class="h5">The main Function</h5>
<p class="noindent">There’s a bit of setup we need to do before we can implement our algorithm; let’s get that out of the way first. See <a href="ch10.xhtml#ch010ex08">Listing 10-8</a> for our <code>main</code> function.</p>
<pre>#define MAX_N 10000

int main(void) {
  int n, i;
<span class="ent">❶</span> int cap_nums[MAX_N], bottle_nums[MAX_N];
  scanf("%d", &amp;n);
  for (i = 0; i &lt; n; i++) {
 <span class="ent">➋</span> cap_nums[i] = i + 1;
 <span class="ent">➌</span> bottle_nums[i] = i + 1;
  }
  solve(cap_nums, bottle_nums, n);
  return 0;
}</pre>
<p class="excap" id="ch010ex08"><em>Listing 10-8: The</em> <span class="codeitalic1">main</span> <em>function</em></p>
<p class="indent">There are two important arrays here: <code>cap_nums</code> and <code>bottle_nums</code> <span class="ent">❶</span>. We will initialize these arrays so that they contain all cap numbers <span class="ent">➋</span> and all bottle numbers <span class="ent">➌</span>, respectively. This is our starting point for the caps and bottles that we’re working with. In the code that we’ll see next, we’ll be making recursive calls on smaller subsets of those caps and bottles.</p>
<h5 class="h5">Implementing Our Algorithm</h5>
<p class="noindent">Now let’s turn our five-step algorithm into code. See <a href="ch10.xhtml#ch010ex09">Listing 10-9</a>.</p>
<pre>void *malloc_safe(int size) {
  char *mem = malloc(size);
  if (mem == NULL) {
    fprintf(stderr, "malloc error\n");
    exit(1);
<span epub:type="pagebreak" id="page_395"/>  }
  return mem;
}

void solve(int cap_nums[], int bottle_nums[], int n) {
  int small_count, big_count, cap_num, i, result, matching_bottle;
  int *small_caps = malloc_safe(n * sizeof(int));
  int *small_bottles = malloc_safe(n * sizeof(int));
  int *big_caps = malloc_safe(n * sizeof(int));
  int *big_bottles = malloc_safe(n * sizeof(int));
  if (n == 0)
    return;

  small_count = 0;
  big_count = 0;

<span class="ent">❶</span> cap_num = cap_nums[0];

<span class="ent">➋</span> for (i = 0; i &lt; n; i++) {
    printf("0 %d %d\n", cap_num, bottle_nums[i]);
    scanf("%d", &amp;result);
  <span class="ent">➌</span> if (result == 0) {
      printf("1 %d %d\n", cap_num, bottle_nums[i]);
      matching_bottle = bottle_nums[i];
    } else if (result == -1) {
      big_bottles[big_count] = bottle_nums[i];
      big_count++;
    } else {
      small_bottles[small_count] = bottle_nums[i];
      small_count++;
    }
  }

  small_count = 0;
  big_count = 0;
<span class="ent">➍</span> for (i = 0; i &lt; n; i++) {
    printf("0 %d %d\n", cap_nums[i], matching_bottle);
    scanf("%d", &amp;result);
    if (result == -1) {
      small_caps[small_count] = cap_nums[i];
      small_count++;
    } else if (result == 1) {
      big_caps[big_count] = cap_nums[i];
      big_count++;
    }
  }
<span epub:type="pagebreak" id="page_396"/><span class="ent">➎</span> solve(small_caps, small_bottles, small_count);
<span class="ent">➏</span> solve(big_caps, big_bottles, big_count);
}</pre>
<p class="excap" id="ch010ex09"><em>Listing 10-9: Solution 1</em></p>
<p class="indent">Prior to our code that implements our five steps, we have some <code>malloc</code> calls. We need those so that we have memory for the piles of caps and bottles that we’ll form.</p>
<p class="indent">For Step 1, we must choose a cap. We can make that easy if we just choose the first cap. Yeah, let’s just do that <span class="ent">❶</span> and move on. Nothing to see here.</p>
<p class="indent">For Step 2, we use a <code>for</code> loop to go through all of the bottles <span class="ent">➋</span>. For each cap, there are three possibilities for the if statement inside this loop. In the first, we find a match <span class="ent">➌</span>, so we tell the judge about the match and remember the matching bottle for later. In the second, the cap is too small for the bottle, so we throw the bottle into the pile of big bottles. In the third, the cap is too big for the bottle, so we throw the bottle into the pile of small bottles.</p>
<p class="indent">Step 3 is similar to Step 2, but this time we go through all of the caps <span class="ent">➍</span> rather than all of the bottles. If the cap is too small for the bottle, we throw the cap into the pile of small caps. If the cap is too big for the bottle, we throw the cap into the pile of big caps. Be careful not to mix these up! It’s easy to mess up a <code>-1</code> or a <code>1</code> and throw caps or bottles in the wrong piles.</p>
<p class="indent">For Step 4, we solve the “small caps and small bottles” subproblem with a recursive call <span class="ent">➎</span>.</p>
<p class="indent">And finally, for Step 5, we solve the “big caps and big bottles” subproblem through another recursive call <span class="ent">➏</span>.</p>
<p class="indent">And that’s it! Get the small stuff in one subproblem, get the big stuff in another subproblem, and solve both subproblems recursively. Pretty slick, right? . . . Right?</p>
<p class="indent">Unfortunately it isn’t quite slick enough. If you submit our code to the judge, you will find that it times out before passing all test cases.</p>
<p class="indent">We are very close to nailing this problem, though. All we need to add is randomization. Why is our current solution not quite there? And how will randomization fix it? Those answers are next.</p>
<h4 class="h4" id="sec171"><em>Solution 2: Adding Randomization</em></h4>
<p class="noindent">Before we see how to add randomization, let’s understand exactly the kind of test case that defeats Solution 1.</p>
<h5 class="h5">Why Solution 1 Is Slow</h5>
<p class="noindent">Each call of our <code>solve</code> function operates on some caps and some bottles. Our choice of cap splits the caps and bottles into two groups: the group with the small caps and bottles and the group with the big caps and bottles. No matter which cap we choose, we get this correct behavior.</p>
<p class="indent">That said, the cap we choose does have a major impact on the number of queries that we’ll need to solve the problem. The algorithm that we used to solve the subtask (<a href="ch10.xhtml#ch010ex07">Listing 10-7</a>) was an <em>O</em>(<em>n</em><sup>2</sup>) algorithm, and it was too <span epub:type="pagebreak" id="page_397"/>slow. So to offer an explanation for why Solution 1 is too slow, what we can do is demonstrate that it, too, has test cases on which it takes <em>O</em>(<em>n</em><sup>2</sup>) time.</p>
<p class="indent">The test case we’ll use may intuitively feel like it should be an easy one. But that intuition is wrong.</p>
<p class="indent">As always for this problem, we’ll have <em>n</em> caps and <em>n</em> bottles. The sizes of the caps will increase from Cap 1 to Cap <em>n</em>. For example, we can say that Cap 1 has size 1, Cap 2 has size 2, Cap 3 has size 3, and so on. Let’s do similarly for the bottles: Bottle 1 has size 1, Bottle 2 has size 2, Bottle 3 has size 3, and so on.</p>
<p class="indent">Now, what will our Solution 1 algorithm do? On the first call of <code>solve</code>, it will choose Cap 1 on which to split the caps and bottles. It’ll loop through the caps, which costs <em>n</em> queries, and then it’ll loop through the bottles, which costs another <em>n</em> queries. So that’s 2<em>n</em> queries so far. And what of our subproblems? Do they have similar sizes or are they very lopsided?</p>
<p class="indent">They are lopsided! There are no caps or bottles that are smaller than the chosen cap. So the “smaller caps and bottles” subproblem is empty. The “bigger caps and bottles” subproblem, then, has everything—all remaining <em>n</em> – 1 caps and bottles.</p>
<p class="indent">What happens on that subproblem with <em>n</em> – 1 caps and bottles? Again, we’re going to pick the first cap, which is Cap 2 this time. We’ll make <em>n</em> – 1 queries as we make our way through the first <code>for</code> loop and then another <em>n</em> – 1 queries as we make our way through the second loop. That’s 2(<em>n</em> – 1) queries for this subproblem. And, again, the two subproblems stemming from this one are as lopsided as can be: an empty subproblem and a subproblem with <em>n</em> – 2 caps and bottles.</p>
<p class="indent">The situation here is very similar to the one on <a href="ch08.xhtml#sec129">page 307</a> that clobbered us when we were solving Building Treaps. In each case, we were hoping for a nice, even split of our problem into two subproblems. When we don’t get that, we end up doing a quadratic amount of work. Here, we’ll make 2<em>n</em> queries, then 2(<em>n</em> – 1) queries, then 2(<em>n</em> – 2) queries, and so on. The total number of queries we’ll make is 2(1 + 2 + 3 + . . . + <em>n</em>), which is <em>O</em>(<em>n</em><sup>2</sup>).</p>
<p class="indent">Darn! All of that fancy splitting and recursing, and yet we’re still stuck at <em>O</em>(<em>n</em><sup>2</sup>).</p>
<h5 class="h5">What We Will Randomize</h5>
<p class="noindent">In Solution 1, we chose the first cap and split our problem around it. That first cap determines what counts as “small” and “big.” As we just saw, if that cap does a poor job of splitting, then our algorithm can be quadratic.</p>
<p class="indent">You might wonder whether we can avoid that poor behavior by making a “smarter” choice of cap. Maybe we should have chosen the rightmost cap? Unfortunately not: the test case from the prior subsection would wreck that, too. Maybe we should have chosen the cap in the middle? Sure, but then someone could craft a test case where the middle caps are always the smallest caps. Then we’d be back to quadratic land again.</p>
<p class="indent">The best thing to do here is to choose our caps randomly! Each time we need a cap, we’ll call <code>rand</code> to get it. If we do that, no test case can reliably cause poor performance because on each run we’ll make different choices <span epub:type="pagebreak" id="page_398"/>for how the algorithm executes. This converts our deterministic algorithm into a Las Vegas algorithm.</p>
<p class="indent">Contrast this use of randomization with the kind of randomization that we used when solving Yōkan. In Yōkan, the randomization determined whether we got the right answer. In Caps and Bottles, we always get the right answer; the randomization determines how fast we get it.</p>
<h5 class="h5">Adding the Randomization</h5>
<p class="noindent">We need just two changes to Solution 1. First, we need to add the call of <code>srand</code> to the <code>main</code> function in <a href="ch10.xhtml#ch010ex08">Listing 10-8</a>, just as we did when solving Yōkan.</p>
<p class="indent">Second, we need to choose a random cap in <a href="ch10.xhtml#ch010ex09">Listing 10-9</a>. Rather than choosing the first cap:</p>
<pre>cap_num = cap_nums[0];</pre>
<p class="noindent">we choose a random one:</p>
<pre>cap_num = cap_nums[rand() % n];</pre>
<p class="indent">If you make those two changes and submit the updated code to the judge, you should find that it passes all test cases. Randomization has done it again!</p>
<p class="indent">Believe it or not, in solving this problem we’ve also managed to secretly learn one of the most famous algorithms in computer science. Let’s go there next.</p>
<h3 class="h3" id="lev66">Quicksort</h3>
<p class="noindent">The key idea in our solution to Caps and Bottles is to choose a cap and then use that cap to split the problem into two subproblems: one subproblem with the small stuff and the other with the big stuff. This idea most famously powers a sorting algorithm called <em>Quicksort</em>.</p>
<h4 class="h4" id="sec172"><em>Implementing Quicksort</em></h4>
<p class="noindent">Quicksort is one of many algorithms that can be used to sort an array; in practice, it’s one of the . . . quickest. In Caps and Bottles, the item that’s used to split the problem is a cap; in Quicksort, the value that’s used to split the array is called the <em>pivot</em>.</p>
<p class="indent">The code for Quicksort is similar to the code we used to solve Caps and Bottles. Check it out in <a href="ch10.xhtml#ch010ex010">Listing 10-10</a>.</p>
<pre>#define N 10

void *malloc_safe(int size) {
  char *mem = malloc(size);
  if (mem == NULL) {
    fprintf(stderr, "malloc error\n");
    exit(1);
<span epub:type="pagebreak" id="page_399"/>  }
  return mem;
}

void swap(int *x, int *y) {
  int temp = *x;
  *x = *y;
  *y = temp;
}

void quicksort(int values[], int n) {
  int i, small_count, big_count, pivot_index, pivot;
  int *small_values = malloc_safe(n * sizeof(int));
  int *big_values = malloc_safe(n * sizeof(int));
  if (n == 0)
    return;

  small_count = 0;
  big_count = 0;

<span class="ent">❶</span> pivot_index = rand() % n;
<span class="ent">➋</span> swap(&amp;values[0], &amp;values[pivot_index]);
   pivot = values[0];

<span class="ent">➌</span> for (i = 1; i &lt; n; i++) {
     if (values[i] &gt; pivot) {
       big_values[big_count] = values[i];
       big_count++;
     } else {
       small_values[small_count] = values[i];
       small_count++;
     }
  }

  quicksort(small_values, small_count);
  quicksort(big_values, big_count);

<span class="ent">➍</span> for (i = 0; i &lt; small_count; i++)
    values[i] = small_values[i];
<span class="ent">➎</span> values[small_count] = pivot;
<span class="ent">➏</span> for (i = 0; i &lt; big_count; i++)
    values[small_count + 1 + i] = big_values[i];
}

int main(void) {
  static int values[N] = {96, 61, 36, 74, 45, 60, 47, 6, 95, 93};
  int i;
<span epub:type="pagebreak" id="page_400"/>  srand((unsigned) time(NULL));

  quicksort(values, N);

  for (i = 0; i &lt; N; i++)
    printf("%d ", values[i]);
  printf("\n");
  return 0;
}</pre>
<p class="excap" id="ch010ex010"><em>Listing 10-10: Quicksort</em></p>
<p class="indent">We choose a random pivot index <span class="ent">❶</span> and move the pivot to the left end of the array <span class="ent">➋</span>. We want the pivot out of the way like that so that we don’t lose track of it—we’ll need to put it in the correct place later.</p>
<p class="indent">Next, we go through all of the other values in the array <span class="ent">➌</span>, adding each to <code>big_values</code> or <code>small_values</code> as appropriate. Once that’s done, we make our two recursive calls to sort the small values and sort the big values.</p>
<p class="indent">What we want to do next is paste everything together: first the small values, then the pivot, then the big values. We copy the small values to the beginning of the <code>values</code> array <span class="ent">➍</span>, then copy the pivot <span class="ent">➎</span>, then copy the big values <span class="ent">➏</span>.</p>
<p class="indent">Next, we’ll see why our solution to Caps and Bottles is so fast. While we’ll couch our discussion in terms of Caps and Bottles, what we learn about its runtime directly applies to the runtime of Quicksort as well.</p>
<h4 class="h4" id="sec173"><em>Worst-Case and Expected Runtime</em></h4>
<p class="noindent">Our solution to Caps and Bottles is a Las Vegas algorithm. The runtime depends on how well each of our randomly chosen caps splits the problem into the two subproblems. If we choose terrible cap after terrible cap, we get <em>O</em>(<em>n</em><sup>2</sup>) runtime. But that’s the worst-case behavior; the whole reason we introduced randomization was to make it extremely unlikely that this would actually happen. Rather than focusing on the worst-case runtime of such an algorithm, then, algorithm designers tend to focus on the <em>expected runtime</em>, which tells us what we can expect to happen in practice.</p>
<p class="indent">What can we expect in practice for our randomized solution to Caps and Bottles? We already know what happens if we’re shockingly unlucky: we get <em>O</em>(<em>n</em><sup>2</sup>) performance. What happens if we’re shockingly lucky, picking caps that perfectly split each problem in half?</p>
<p class="indent">To begin, we’ll choose our cap and make our 2<em>n</em> queries, as we always do. If that cap perfectly splits the problem in half, then we’ll need to work on two subproblems each with <em>n</em>/2 caps and bottles. Each of those two subproblems will generate 2<em>n</em>/2 = <em>n</em> queries of their own before they in turn recurse. So those two subproblems with <em>n</em>/2 caps and bottles will generate 2<em>n</em> queries, just like our original problem did.</p>
<p class="indent">Now, if each subproblem with <em>n</em>/2 caps and bottles is split perfectly, then we get four problems of size <em>n</em>/4. Each of those four will generate 2<em>n</em>/4 = <em>n</em>/2 queries before they recurse, for a total of 2<em>n</em> queries.</p>
<p class="indent"><span epub:type="pagebreak" id="page_401"/>To summarize, we make 2<em>n</em> queries for our original problem of size <em>n</em>, 2<em>n</em> queries in total for our subproblems of size <em>n</em>/2, 2<em>n</em> queries in total for our subproblems of size <em>n</em>/4, and so on. We can only do this about log <em>n</em> times before we reach base case subproblems. So, we do 2<em>n</em> queries a total of log <em>n</em> times, for a total of <em>O</em>(<em>n</em> log <em>n</em>) queries.</p>
<p class="indent">Another way to see this <em>O</em>(<em>n</em> log <em>n</em>) bound is through a <em>recursion tree</em>. Such a tree characterizes how much work is done in each call of a recursive function. When we have perfect splits all the way down, our recursion tree looks like the one in <a href="ch10.xhtml#ch010fig01">Figure 10-1</a>.</p>
<div class="image"><img alt="image" id="ch010fig01" src="../images/ch10fig01.jpg"/></div>
<p class="figcap"><em>Figure 10-1: A recursion tree with perfect splits</em></p>
<p class="indent">Notice that each node splits into two nodes below, representing the fact that each problem splits into two. The quantity in each node indicates the number of queries that are directly made to solve that subproblem. The 2<em>n</em> at the top, for example, means that the initial call makes 2<em>n</em> queries. It’s not saying that the total number of queries made in the entire algorithm is 2<em>n</em>, only that the initial call makes 2<em>n</em> queries of its own prior to recursing. Notice that each level in this tree—the node at the top, the two nodes below that, and the four nodes below those—make a total of 2<em>n</em> queries. If we drew the entire tree, it would have about log <em>n</em> levels in it. In all, then, we have <em>O</em>(<em>n</em> log <em>n</em>) queries.</p>
<p class="indent">Now, <em>O</em>(<em>n</em> log <em>n</em>) is a wonderful thing, but all I’ve argued so far is that this is what happens when the algorithm gets super lucky with perfect splits. The algorithm is generally not going to get this lucky, though, just as it’s generally not going to get super unlucky with horrible cap choices.</p>
<p class="indent"><span epub:type="pagebreak" id="page_402"/>It turns out that the expected runtime is very close to what is predicted by the super lucky case rather than the super unlucky case. For example, let’s imagine that each time we choose a cap, one subproblem will end up with 90 percent of the caps and bottles and the other subproblem will end up with the remaining 10 percent of the caps and bottles. You might consider that pretty unlucky. But even in this case, our algorithm is <em>O</em>(<em>n</em> log <em>n</em>)! Our biggest subproblem would go from size <em>n</em>, to size <em>n</em>/(10/9), to size <em>n</em>/(10/9)<sup>2</sup>, and so on. That is, rather than dividing by 2 each time, we’re dividing by 10/9. How many times do we need to do this to get down to a base case? It’s still logarithmic! The base of the log changes—it goes from log<sub>2</sub> to log<sub>10/9</sub>—but it’s still log. Yes: even if we get <em>this</em> unlucky, we’re still not going to hit <em>O</em>(<em>n</em><sup>2</sup>).</p>
<h3 class="h3" id="lev67">Summary</h3>
<p class="noindent">When I teach randomization in my algorithms classes, I often have at least a few flummoxed students. “Really, Dan? Picking random numbers? This feels like the kind of thing I would have tried <em>before</em> learning about real algorithms.” But as I hoped I’ve demonstrated in this chapter, randomization is no rookie move. Compared to deterministic algorithms, randomized algorithms can be faster and easier to design.</p>
<p class="indent">In <a href="ch07.xhtml">Chapter 7</a>, I gave this advice: if you see an opportunity to use binary search to solve a problem, just do it. Who cares if there’s a slightly more efficient solution that doesn’t use binary search. I offer similar advice here: if you see an opportunity to use randomization, and you can tolerate the randomness in correctness or runtime, just do it. Who cares if there’s a deterministic algorithm: even if you can come up with one (which may not be easy!), it’ll probably be slower in practice anyway.</p>
<h3 class="h3" id="lev68">Notes</h3>
<p class="noindent">Yōkan is originally from the 2015 Don Mills Programming Gala programming competition, Gold Division. Caps and Bottles is originally from the 2009 Canadian Computing Olympiad.</p>
<p class="indent">There’s a way to cut down the amount of memory needed by our solution to Caps and Bottles. It’s a neat trick that applies to implementations of Quicksort as well. Check it out in “Caps and Bottles: In-Place Sorting” in <a href="app02.xhtml">Appendix B</a>.</p>
<p class="indent">For a deep dive into sorting algorithms, I recommend <em>Compared to What?: An Introduction to the Analysis of Algorithms</em> by Gregory J.E. Rawlins (1991). It’s an oldie but a goodie. There are many sorting algorithms: some of them are slow, some of them are fast; some of them merge sorted pieces, some of them split and sort the pieces. The book compares and contrasts many sorting algorithms. This is also the book that originally introduced me to the Caps and Bottles problem.</p>
</body></html>