<html><head></head><body>
<h2 class="h2" id="ch10"><span epub:type="pagebreak" id="page_117"/><span class="big">10</span><br/>PARSING STRUCTURED DATA</h2>&#13;
<div class="image1"><img class="inline" src="../images/common.jpg" alt="Images"/></div>&#13;
<p class="noindent"><span class="bign">With ingrained support for any .NET object, and just about every shell method you can think of, PowerShell is able to read, update, and remove data from numerous sources. If you’re lucky enough to have your data stored in some kind of structured way, working with that data is even easier.</span></p>&#13;
<p class="indent">In this chapter, we’ll focus on a few common forms of structured data including CSV, Microsoft Excel spreadsheets, and JSON. You’ll learn how to manage each kind of data by using both native PowerShell cmdlets and .NET objects. By the end of the chapter, you should be a data-wrangling pro, able to use PowerShell to manage all sorts of structured data.</p>&#13;
<h3 class="h3" id="ch10lev1"><span epub:type="pagebreak" id="page_118"/>CSV Files</h3>&#13;
<p class="noindent">One of the easiest, most common ways to store data is to use a CSV file. A <em>CSV file</em> is a simple text file representing a table. Each item in the table is separated by a shared, predetermined symbol known as a <em>delimiter</em> (commas are the most common delimiter). Every CSV file shares the same basic structure: the first row in the CSV is the header row, containing all the headers for the table’s columns; the following rows contain all of the table’s contents.</p>&#13;
<p class="indent">In this section, you’ll primarily be working with a couple of CSV cmdlets: <code>Import-Csv</code> and <code>Export-Csv</code>.</p>&#13;
<h4 class="h4" id="ch10lev1sec1">Reading CSV Files</h4>&#13;
<p class="noindent">Of all the CSV processing tasks PowerShell is equipped to do, the most common is almost certainly reading. Given how simple and effective the CSV structure is, it should be no surprise that CSV files are used by companies and applications throughout the tech world—hence the popularity of the <code>Import-Csv</code> PowerShell command.</p>&#13;
<p class="indent">But what exactly does it mean to <em>read</em> a CSV file? Though a CSV has all the information you want, you can’t just import it directly into your program; usually, you have to read through the file and convert it into usable data. This process is known as <em>parsing</em>. The <code>Import-Csv</code> command parses the CSV file: reading it in, and then transforming the data into PowerShell objects. I will go into the uses of <code>Import-Csv</code> in a moment, but first, it’s worth taking a dive under the hood to see what <code>Import-Csv</code> is doing.</p>&#13;
<p class="indent">Let’s start with a simple spreadsheet containing a few employees at a fictional company, shown in <a href="ch10.xhtml#ch10fig1">Figure 10-1</a>.</p>&#13;
<div class="image"><img src="../images/10fig01.jpg" alt="Image"/></div>&#13;
<p class="figcap" id="ch10fig1"><em>Figure 10-1: Employee CSV file</em></p>&#13;
<p class="indent"><a href="ch10.xhtml#ch10fig1">Figure 10-1</a> is an Excel screenshot, but you can easily see what the data looks like as a plaintext CSV file. For our sample CSV file, you’ll be working with <em>Employees.csv</em>, which can be found in this chapter’s resources; see <a href="ch10.xhtml#ch10list1">Listing 10-1</a>.</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-Content -Path ./Employees.csv –Raw</span>&#13;
&#13;
First Name,Last Name,Department,Manager&#13;
Adam,Bertram,IT,Miranda Bertram&#13;
Barack,Obama,Executive Office,Michelle Obama&#13;
Miranda,Bertram,Executive Office&#13;
Michelle,Obama,Executive Office</pre>&#13;
<p class="caption" id="ch10list1"><em>Listing 10-1: Reading a CSV file with <span class="codeitalic">Get-Content</span></em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_119"/>Here, you’re using the <code>Get-Content</code> command to query our text file (CSV). <code>Get-Content</code> is the PowerShell command to use for reading plaintext files of any kind.</p>&#13;
<p class="indent">You can see that this is a typical CSV file with a header row and multiple data rows separated into columns by a comma delimiter. Notice that you can read the file by using the <code>Get-Content</code> cmdlet. Since a CSV file is a text file, <code>Get-Content</code> works just fine for reading it (this is actually the first step that happens with <code>Import-Csv</code>).</p>&#13;
<p class="indent">But also notice how <code>Get-Content</code> returns the information: as a simple string. This is what happens when you use the <code>Raw</code> parameter. Otherwise, <code>Get-Content</code> returns an array of strings, with each element representing a row in the CSV file:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-Content ./Employees.csv -Raw | Get-Member</span>&#13;
&#13;
   TypeName: System.String&#13;
   <span class="codeitalic1">--snip--</span></pre>&#13;
<p class="indent">Though the <code>Get-Content</code> command can read in the data, the command doesn’t <em>understand</em> a CSV file’s schema. <code>Get-Content</code> has no idea that the table has a header row or data rows, and it doesn’t know what to do with the delimiter. It just takes in the content and spits it back out. That’s why we have <code>Import-Csv</code>.</p>&#13;
<h5 class="h5">Using Import-Csv to Process Data</h5>&#13;
<p class="noindent">To see how <code>Import-Csv</code> works, compare the output in <a href="ch10.xhtml#ch10list1">Listing 10-1</a> with the output from <code>Import-Csv</code> in <a href="ch10.xhtml#ch10list2">Listing 10-2</a>.</p>&#13;
<pre>PS&gt; <span class="codestrong1">Import-Csv -Path ./Employees.csv</span>&#13;
&#13;
First Name Last Name  Department        Manager&#13;
---------- ---------  ----------        -------&#13;
Adam       Bertram    IT                Miranda Bertram&#13;
Barack     Obama      Executive Office  Michelle Obama&#13;
Miranda    Bertram    Executive Office&#13;
Michelle   Obama      Executive Office&#13;
&#13;
PS&gt; <span class="codestrong1">Import-Csv -Path ./Employees.csv | Get-Member</span>&#13;
&#13;
   TypeName: System.Management.Automation.PSCustomObject&#13;
&#13;
PS&gt; <span class="codestrong1">$firstCsvRow = Import-Csv -Path ./Employees.csv | Select-Object –First</span>&#13;
1 &#13;
PS&gt;<span class="codestrong1"> $firstCsvRow | Select-Object -ExpandProperty 'First Name'</span>&#13;
Adam</pre>&#13;
<p class="caption" id="ch10list2"><em>Listing 10-2: Using <span class="codeitalic">Import-Csv</span></em></p>&#13;
<p class="indent">The first thing you’ll probably notice is that the headers are now separated from the data entries by a line. This means that <code>Import-Csv</code> reads the file, treats the top row as a header row, and knows to separate it from <span epub:type="pagebreak" id="page_120"/>the rest of the file. You also may notice that there are no more commas—when a command reads and <em>understands</em> a CSV file, it knows that the delimiter is used to separate items in the table and shouldn’t show up in the table itself.</p>&#13;
<p class="indent">But what happens if the code has a stray delimiter? Try putting a comma in the middle of <em>Adam</em> in <em>Employees.csv</em> and run the code. What happens? Now everything in the Adam row is shifted over: <em>am</em> is the new Last Name, <em>Bertram</em> the new Department, and <em>IT</em> the new Manager. <code>Import-Csv</code> is smart enough to understand a CSV’s format, but not smart enough to understand its content—that’s where you come in.</p>&#13;
<h5 class="h5">Turning Raw Data into Objects</h5>&#13;
<p class="noindent"><code>Import-Csv</code> doesn’t just read in the CSV and print it out with fancy formatting. The content of the file is put into an array of <code>PSCustomObject</code>s. Here, each <code>PSCustomObject</code> is an object that holds the data for one row. Each object has properties that correspond to the headers in the header row, and if you want the data for that header’s column, all you have to do is access that property. Just by knowing which form of data to expect, <code>Import-Csv</code> can take a string of data it has never seen before and turn it into easy-to-use objects. Pretty cool!</p>&#13;
<p class="indent">Having the data as an array of <code>PSCustomObject</code>s allows you to use that data much more effectively. Let’s say you want to find only the employees with the last name of <em>Bertram</em>. Since each data row in the CSV is a <code>PSCustomObject</code>, you can do this by using <code>Where-Object</code>:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Import-Csv -Path ./Employees.csv | Where-Object { $_.'Last Name' -eq 'Bertram' }</span>&#13;
&#13;
First Name Last Name Department       Manager&#13;
---------- --------- ----------       -------&#13;
Adam       Bertram   IT               Miranda Bertram&#13;
Miranda    Bertram   Executive Office</pre>&#13;
<p class="indent">If, instead, you want to return only rows in the CSV that have a department of Executive Office, you can do so easily! You use the same technique and change the property name from Last Name to Department, and the value from Bertram to Executive Office:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Import-Csv -Path ./Employees.csv |</span> <span class="codestrong1">Where-Object {$_.Department -eq 'Executive Office' }</span>&#13;
&#13;
First Name Last Name Department       Manager&#13;
---------- --------- ---------        --------&#13;
Barack     Obama     Executive Office Michelle Obama&#13;
Miranda    Bertram   Executive Office&#13;
Michelle   Obama     Executive Office</pre>&#13;
<p class="indent">What happens if you use semicolons for your delimiter instead of commas? Try changing the CSV file and see what happens. Not good, right? You don’t have to use a comma as a delimiter, but commas are the delimiter <span epub:type="pagebreak" id="page_121"/>that <code>Import-Csv</code> natively understands. If you want to use a different delimiter, you have to specify the new delimiter in your <code>Import-Csv</code> command.</p>&#13;
<p class="indent">To demonstrate, replace all the commas in our <em>Employees.csv</em> file with tabs:</p>&#13;
<pre>PS&gt; <span class="codestrong1">(Get-Content ./Employees.csv -Raw).replace(',',"`t") | Set-Content ./Employees.csv</span>&#13;
PS&gt; <span class="codestrong1">Get-Content ./Employees.csv –Raw</span>&#13;
First Name  Last Name   Department  Manager&#13;
Adam    Bertram IT  Miranda Bertram&#13;
Barack  Obama   Executive Office    Michelle Obama&#13;
Miranda Bertram Executive Office&#13;
Michelle    Obama   Executive Office</pre>&#13;
<p class="indent">Once you have a tab-separated file, you can then specify the tab character (represented by a backtick and the <code>t</code> character) as the new delimiter by using the <code>Delimiter</code> parameter (<a href="ch10.xhtml#ch10list3">Listing 10-3</a>).</p>&#13;
<pre>PS&gt; <span class="codestrong1">Import-Csv -Path ./Employees.csv -Delimiter "`t"</span>&#13;
&#13;
First Name Last Name Department       Manager&#13;
---------- --------- ----------       -------&#13;
Adam       Bertram   IT               Miranda Bertram&#13;
Barack     Obama     Executive Office Michelle Obama&#13;
Miranda    Bertram   Executive Office&#13;
Michelle   Obama     Executive Office</pre>&#13;
<p class="caption" id="ch10list3"><em>Listing 10-3: Using the <span class="codeitalic">Delimiter</span> parameter of <span class="codeitalic">Import-Csv</span></em></p>&#13;
<p class="indent">Notice that the output is the same as it was in <a href="ch10.xhtml#ch10list2">Listing 10-2</a>.</p>&#13;
<h5 class="h5">Defining Your Own Header</h5>&#13;
<p class="noindent">What if you have a table of data, but you want to change the header row to be more user-friendly? <code>Import-Csv</code> can do this too. As with the new delimiter, you want to pass a parameter in to <code>Import-Csv</code>. <a href="ch10.xhtml#ch10list4">Listing 10-4</a> uses the <code>Header</code> parameter to pass in a series of strings separated by commas (the new headers).</p>&#13;
<pre>PS&gt; <span class="codestrong1">Import-Csv -Path ./Employees.csv -Delimiter "`t"</span> &#13;
<span class="codestrong1">-Header 'Employee FName','Employee LName','Dept','Manager'</span>&#13;
&#13;
Employee FName Employee LName Dept             Manager&#13;
-------------- -------------- ----             -------&#13;
First Name     Last Name      Department       Manager&#13;
Adam           Bertram        IT               Miranda Bertram&#13;
Barack         Obama          Executive Office Michelle Obama&#13;
Miranda        Bertram        Executive Office&#13;
Michelle       Obama          Executive Office</pre>&#13;
<p class="caption" id="ch10list4"><em>Listing 10-4: Using the <span class="codeitalic">Header</span> parameter of <span class="codeitalic">Import-Csv</span></em></p>&#13;
<p class="indent">As you can see, after the command runs, each object in the data row will have the new labels as property names.</p>&#13;
<h4 class="h4" id="ch10lev1sec2"><span epub:type="pagebreak" id="page_122"/>Creating CSV Files</h4>&#13;
<p class="noindent">So much for reading CSV files. What if you want to make your own? You could type one out by hand, but that would take time and energy, especially if you’re dealing with thousands of rows. Luckily, PowerShell also has a native cmdlet for creating CSV files: <code>Export-Csv</code>. You can use this cmdlet to create CSV files from any existing PowerShell object; you simply have to tell PowerShell which objects to use as rows, and where it should create the file.</p>&#13;
<p class="indent">Let’s deal with the second requirement first. Say you run some PowerShell commands, and then you want to save the output in the console to a file somehow. You could use <code>Out-File</code>, but that would send the unstructured text directly to a new file. You want a nice structured file instead, complete with header rows and delimiters. Enter <code>Export-Csv</code>.</p>&#13;
<p class="indent">As an example, let’s say you want to pull all the running processes from your computer and record the process name, company, and description of each one. You can use <code>Get-Process</code> to do this and <code>Select-Object</code> to narrow down the properties you want to see, as shown here:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-Process | Select-Object -Property Name,Company,Description</span>&#13;
&#13;
Name                 Company                      Description&#13;
----                 -------                      -----------&#13;
ApplicationFrameHost Microsoft Corporation        Application Frame Host&#13;
coherence            Parallels International GmbH Parallels Coherence service&#13;
coherence            Parallels International GmbH Parallels Coherence service&#13;
coherence            Parallels International GmbH Parallels Coherence service&#13;
com.docker.proxy&#13;
com.docker.service   Docker Inc.                 &#13;
Docker.Service&#13;
<span class="codeitalic1">--snip--</span></pre>&#13;
<p class="indent">In <a href="ch10.xhtml#ch10list5">Listing 10-5</a>, you can see what happens when you commit this output to the filesystem in a structured manner by using <code>Export-Csv</code>.</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-Process | Select-Object -Property Name,Company,Description |</span> &#13;
<span class="codestrong1">Export-Csv -Path C:\Processes.csv –NoTypeInformation</span>&#13;
PS&gt; <span class="codestrong1">Get-Content -Path C:\Processes.csv</span>&#13;
"Name","Company","Description"&#13;
"ApplicationFrameHost","Microsoft Corporation","Application Frame Host"&#13;
"coherence","Parallels International GmbH","Parallels Coherence service"&#13;
"coherence","Parallels International GmbH","Parallels Coherence service"&#13;
"coherence","Parallels International GmbH","Parallels Coherence service"&#13;
"com.docker.proxy",,&#13;
"com.docker.service","Docker Inc.","Docker.Service"</pre>&#13;
<p class="caption" id="ch10list5"><em>Listing 10-5: Using <span class="codeitalic">Export-Csv</span></em></p>&#13;
<p class="indent">By piping the output directly to <code>Export-Csv</code>, specifying the path to the CSV you’d like to create (using the <code>Path</code> parameter), and using the <code>NoTypeInformation</code> parameter, you’ve created a CSV file with the expected header row and data rows.</p>&#13;
<div class="note">&#13;
<p class="notet"><span epub:type="pagebreak" id="page_123"/><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>The <span class="codeitalic">NoTypeInformation</span> parameter is not required, but if you don’t use it, you will get a line at the top of your CSV file specifying the type of object it came from. Unless you’re reimporting the CSV file directly back into PowerShell, this usually isn’t desired. An example line looks like <span class="codeitalic">#TYPE Selected.System.Diagnostics.Process</span>.</em></p>&#13;
</div>&#13;
<h4 class="h4" id="ch10lev1sec3">Project 1: Building a Computer Inventory Report</h4>&#13;
<p class="noindent">To bring together everything you’ve learned so far, let’s work on a mini-project, something you may run into in your daily life.</p>&#13;
<p class="indent">Imagine for a moment that your company has acquired another company that has no idea what servers and PCs it has on its network. All it has is a CSV file of IP addresses and the department where each device is located. You’ve been brought in to figure out what these devices are and to provide a new CSV file to management with the results.</p>&#13;
<p class="indent">What do you have to do? At a high level, this is a two-step process: read in their CSV and write your own. Your CSV file will need the following information: each IP address you process, the department it’s supposed to be in, whether or not the IP address responds to a ping, and the DNS name of that device.</p>&#13;
<p class="indent">You’ll start with a CSV file that looks just like that looks like the following snippet. The IP addresses are part of a full 255.255.255.0 network, so they go all the way up to 192.168.0.254:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-Content -Path ./IPAddresses.csv</span>&#13;
"192.168.0.1","IT"&#13;
"192.168.0.2","Accounting"&#13;
"192.168.0.3","HR"&#13;
"192.168.0.4","IT"&#13;
"192.168.0.5","Accounting"&#13;
<span class="codeitalic1">--snip--</span></pre>&#13;
<p class="indent">I’ve created a script called <em>Discover-Computer.ps1</em> that’s available in this chapter’s resources. As you move through this experiment, start adding code to it.</p>&#13;
<p class="indent">First, you need to read each row in the CSV file. You do this with <code>Import-Csv</code>, which will capture each row of the CSV into a variable for further processing:</p>&#13;
<pre>$rows = Import-Csv -Path C:\IPAddresses.csv</pre>&#13;
<p class="indent">Now that you have the data, you need to use it. You’ll perform two actions on each IP address: pinging it and finding its hostname. Let’s go ahead and test these actions on a row of our CSV to ensure that you have the syntax right.</p>&#13;
<p class="indent">In the following listing, you use the <code>Test-Connection</code> command, which sends a single ICMP packet to the IP address you specify (here the IP address in the first row of our CSV file). The <code>Quiet</code> parameter tells the command to return either a <code>True</code> or <code>False</code> value.</p>&#13;
<pre><span epub:type="pagebreak" id="page_124"/>PS&gt; <span class="codestrong1">Test-Connection -ComputerName $row[0].IPAddress -Count 1 –Quiet</span>&#13;
PS&gt; <span class="codestrong1">(Resolve-DnsName -Name $row[0].IPAddress -ErrorAction Stop).Name</span></pre>&#13;
<p class="indent">In the second line of this code, you’re obtaining the hostname by using the <code>Resolve-DnsName</code> command on the same IP address. The <code>Resolve-DnsName</code> command returns multiple properties. Here, because you’re concerned with only the name, you enclose the entire command in parentheses and use dot notation to return the <code>Name</code> property.</p>&#13;
<p class="indent">Once you’re comfortable with the syntax for each action, you need to do this for every row in the CSV. The easiest way to do this is with a <code>foreach</code> loop:</p>&#13;
<pre>foreach ($row in $rows) {&#13;
    Test-Connection -ComputerName $row.IPAddress -Count 1 –Quiet&#13;
    (Resolve-DnsName -Name $row.IPAddress -ErrorAction Stop).Name&#13;
}</pre>&#13;
<p class="indent">Run the code yourself. What happens? You get a bunch of <code>True</code>/<code>False</code> lines with hostnames, but no way to know which IP address the output is associated with. You’ll have to create a <em>hashtable</em> for each row and assign your own elements to it. You also need to account for if or when <code>Test-Connection</code> or <code>Resolve-DnsName</code> returns an error. <a href="ch10.xhtml#ch10list6">Listing 10-6</a> shows an example of how to do all this.</p>&#13;
<pre>$rows = Import-Csv -Path C:\IPAddresses.csv&#13;
foreach ($row in $rows) {&#13;
    try { <span class="ent">❶</span>&#13;
        $output = @{ <span class="ent">❷</span>&#13;
            IPAddress  = $row.IPAddress&#13;
            Department = $row.Department&#13;
            IsOnline   = $false&#13;
            HostName   = $null&#13;
            Error      = $null&#13;
        }&#13;
        if (Test-Connection -ComputerName $row.IPAddress -Count 1 -Quiet) { <span class="ent">❸</span>&#13;
            $output.IsOnline = $true&#13;
        }&#13;
        if ($hostname = (Resolve-DnsName -Name $row.IPAddress -ErrorAction Stop).Name) { <span class="ent">❹</span>&#13;
            $output.HostName = $hostName&#13;
        }&#13;
    } catch {&#13;
        $output.Error = $_.Exception.Message <span class="ent">❺</span>&#13;
    } finally {&#13;
        [pscustomobject]$output <span class="ent">❻</span>&#13;
    }&#13;
}</pre>&#13;
<p class="caption" id="ch10list6"><em>Listing 10-6: Mini-project—CSV file discovery</em></p>&#13;
<p class="indent">Let’s walk through what’s happening. First, you create a hashtable with values corresponding to the row’s columns and the extra information you want <span class="ent">❷</span>. Next, test whether the computer is connected by pinging the IP address <span class="ent">❸</span>. If the computer is connected, set <code>IsOnline</code> to <code>True</code>. Then do the same with the <code>HostName</code>, testing whether it’s found <span class="ent">❹</span> and updating the <span epub:type="pagebreak" id="page_125"/>hashtable’s value if it is. If any errors occur, record that in the hashtable’s <code>Error</code> value <span class="ent">❺</span>. Lastly, turn your hashtable into a <code>PSCustomObject</code> and return it (regardless of whether an error is thrown) <span class="ent">❻</span>. Note that you’ve wrapped this whole function in a <code>try/catch</code> block <span class="ent">❶</span>, which will execute the code in the <code>catch</code> block if the code in the <code>try</code> block throws an error. Because you’re using the <code>ErrorAction</code> parameter, <code>Resolve-DnsName</code> will throw an exception (an error) if something unexpected happens.</p>&#13;
<p class="indent">Run this, and you should see output that looks like the following:</p>&#13;
<pre>HostName   :&#13;
Error      : 1.0.168.192.in-addr.arpa : DNS name does not exist&#13;
IsOnline   : True&#13;
IPAddress  : 192.168.0.1&#13;
Department : HR&#13;
&#13;
HostName   :&#13;
Error      : 2.0.168.192.in-addr.arpa : DNS name does not exist&#13;
IsOnline   : True&#13;
IPAddress  : 192.168.0.2&#13;
Department : Accounting&#13;
<span class="codeitalic1">--snip--</span></pre>&#13;
<p class="indent">Congrats! You’ve done most of the hard work, and now you can tell which IP address is associated with which output. All that’s left is to record the output to a CSV. As you learned earlier, you can do this with <code>Export-Csv</code>. You’ll simply pipe the <code>PSCustomObject</code> you created into <code>Export-Csv</code>, and the output will go directly into a CSV file rather than being output to the console.</p>&#13;
<p class="indent">Notice that next, you’ll use the <code>Append</code> parameter. By default, <code>Export-Csv</code> overwrites the CSV file. Using the <code>Append</code> parameter adds a row to the end of an existing CSV file rather than overwriting it:</p>&#13;
<pre>PS&gt; <span class="codestrong1">[pscustomobject]$output |</span> &#13;
<span class="codestrong1">Export-Csv -Path C:\DeviceDiscovery.csv -Append</span> &#13;
<span class="codestrong1">-NoTypeInformation</span></pre>&#13;
<p class="indent">Once the script runs, you’ll see that the CSV file will be the exact same as the output you saw in your PowerShell console:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Import-Csv -Path C:\DeviceDiscovery.csv</span>&#13;
&#13;
HostName   :&#13;
Error      : 1.0.168.192.in-addr.arpa : DNS name does not exist&#13;
IsOnline   : True&#13;
IPAddress  : 192.168.0.1&#13;
Department : HR&#13;
&#13;
HostName   :&#13;
Error      :&#13;
IsOnline   : True&#13;
IPAddress  : 192.168.0.2&#13;
Department : Accounting</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_126"/>You should now have a CSV file called <em>DeviceDiscovery.csv</em> (or whatever you named it) that has rows for each IP address in the original CSV, along with values for all of the original CSV file values and the values that you discovered with <code>Test-Connection</code> and <code>Resolve-DnsName</code>.</p>&#13;
<h3 class="h3" id="ch10lev2">Excel Spreadsheets</h3>&#13;
<p class="noindent">It’s hard to imagine a business that doesn’t use Excel spreadsheets. Chances are, if you get a scripting project, it will involve an Excel spreadsheet. But before we dive deep into the world of Excel, it’s worth stating something clearly: if possible, don’t use it at all!</p>&#13;
<p class="indent">A CSV file can store data as effectively as a simple Excel spreadsheet, and CSV files are much easier to manage with PowerShell. Excel spreadsheets come in a proprietary format, and you can’t even read them by using PowerShell unless you’re using an external library. If you have an Excel workbook with a single worksheet, do yourself a favor and save it as a CSV file. Of course, this isn’t always possible, but if it is, you’ll thank yourself later. Trust me.</p>&#13;
<p class="indent">But what if it isn’t possible to save it as a CSV? In that case, you need to use a community module. Once upon a time, reading <em>.xls</em> or <em>.xlsx</em> Excel spreadsheets with PowerShell required a software developer’s delicate touch. You had to have Excel installed, and you had to access <em>COM objects</em>, complex programming components that take all the fun out of working in PowerShell. Luckily, other people have done the hard work for you, so rather than focus on learning how to use COM, in this section, you’ll rely on Doug Finke’s wonderful <code>ImportExcel</code> module. This freely available community module does not require Excel to be installed, and it’s much simpler than COM objects.</p>&#13;
<p class="indent">First, you need to install the module. The <code>ImportExcel</code> module is available via the PowerShell Gallery and can be installed by running <code>Install-Module ImportExcel</code>. Once you’ve installed the <code>ImportExcel</code> module, it’s time to see what it can do.</p>&#13;
<h4 class="h4" id="ch10lev2sec4">Creating Excel Spreadsheets</h4>&#13;
<p class="noindent">To start, you need to create an Excel spreadsheet. Now, sure, you could create one the usual way by opening Excel and going through all that jazz—but where’s the fun in that? Let’s use PowerShell to create a simple spreadsheet with a single worksheet (you have to crawl before you can walk). To do this, you’ll use the <code>Export-Excel</code> command. Just like <code>Export-Csv</code>, <code>Export</code><code>-Excel</code> will read the property names of each object it receives, create a header row from them, and then create the data rows right below.</p>&#13;
<p class="indent">The easiest way to use <code>Export-Excel</code> is to pipe one or more objects into it just as you would with <code>Export-Csv</code>. As an example, let’s create an Excel workbook with a single worksheet that contains all the running processes on my computer.</p>&#13;
<p class="indent">The input <span class="codestrong">Get-Process | Export-Excel .\Processes.xlsx</span> gives us a spreadsheet that looks like <a href="ch10.xhtml#ch10fig2">Figure 10-2</a>.</p>&#13;
<div class="image"><img src="../images/10fig02.jpg" alt="Image"/></div>&#13;
<p class="figcap" id="ch10fig2"><span epub:type="pagebreak" id="page_127"/><em>Figure 10-2: The Excel spreadsheet</em></p>&#13;
<p class="indent">If you haven’t converted to CSVs yet, you’re probably working with something more complicated than just a single worksheet. Let’s add a couple more worksheets to our existing workbook. To do that, use the <code>WorksheetName</code> parameter, as shown in <a href="ch10.xhtml#ch10list7">Listing 10-7</a>. This will create additional worksheets by using the objects that are sent to <code>Export-Excel</code>.</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-Process | Export-Excel .\Processes.xlsx -WorksheetName 'Worksheet2'</span>&#13;
PS&gt; <span class="codestrong1">Get-Process | Export-Excel .\Processes.xlsx -WorksheetName 'Worksheet3'</span></pre>&#13;
<p class="caption" id="ch10list7"><em>Listing 10-7: Adding worksheets to an Excel workbook</em></p>&#13;
<p class="indent">Creating a spreadsheet by using <code>Export-Excel</code> can be a <em>whole</em> lot more complicated, but to save us time (and the Earth a couple of trees), we don’t go into it here. If you’re curious, check out the help documentation on <code>Export-Excel</code> and you’ll see the dozens of parameters you can use!</p>&#13;
<h4 class="h4" id="ch10lev2sec5">Reading Excel Spreadsheets</h4>&#13;
<p class="noindent">Now that you have a spreadsheet you can work with, let’s focus on reading the rows inside. To read a spreadsheet, you use the <code>Import-Excel</code> command. This command reads a worksheet in a workbook and returns one or more <code>PSCustomObject</code> objects representing each row. The simplest way to use this command is to specify the workbook path by using the <code>Path</code> parameter. You’ll see in <a href="ch10.xhtml#ch10list8">Listing 10-8</a> that <code>Import-Excel</code> returns an object that uses the column names as properties.</p>&#13;
<pre>PS&gt; <span class="codestrong1">Import-Excel -Path .\Processes.xlsx</span>&#13;
&#13;
Name                       : ApplicationFrameHost&#13;
SI                         : 1&#13;
Handles                    : 315&#13;
VM                         : 2199189057536&#13;
WS                         : 26300416&#13;
PM                         : 7204864&#13;
NPM                        : 17672&#13;
Path                       : C:\WINDOWS\system32\ApplicationFrameHost.exe&#13;
Company                    : Microsoft Corporation&#13;
CPU                        : 0.140625&#13;
<span class="codeitalic1">--snip--</span></pre>&#13;
<p class="caption" id="ch10list8"><em>Listing 10-8: Using <span class="codeitalic">Import-Excel</span></em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_128"/>By default, <code>Import-Excel</code> will return only the first worksheet. Our example workbook has multiple worksheets, so you need to figure out a way to go through each sheet. But imagine it’s been a while since you last created that spreadsheet, and you can’t remember the worksheet names. No problem. You’ll use <code>Get-ExcelSheetInfo</code> to find all the worksheets in the workbook, as shown in <a href="ch10.xhtml#ch10list9">Listing 10-9</a>.</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-ExcelSheetInfo -Path .\Processes.xlsx</span>&#13;
&#13;
Name       Index  Hidden  Path&#13;
----       -----  ------  ----&#13;
Sheet1         1  Visible C:\Users\adam\Processes.xlsx&#13;
Worksheet2     2  Visible C:\Users\adam\Processes.xlsx&#13;
Worksheet3     3  Visible C:\Users\adam\Processes.xlsx</pre>&#13;
<p class="caption" id="ch10list9"><em>Listing 10-9: Using <span class="codeitalic">Get-ExcelSheetInfo</span></em></p>&#13;
<p class="indent">You’ll use this output to pull data from all our worksheets. Make a <code>foreach</code> loop and call <code>Import-Excel</code> for every worksheet inside the workbook, just as in <a href="ch10.xhtml#ch10list10">Listing 10-10</a>.</p>&#13;
<pre>$excelSheets <span class="codestrong1">=</span> <span class="codestrong1">Get-ExcelSheetInfo -Path .\Processes.xlsx</span>&#13;
<span class="codestrong1">Foreach ($sheet in $excelSheets) {</span>&#13;
<span class="codestrong1">    $workSheetName = $sheet.Name</span>&#13;
<span class="codestrong1">    $sheetRows = Import-Excel -Path .\Processes.xlsx -WorkSheetName</span>&#13;
<span class="codestrong1">    $workSheetName</span> &#13;
  <span class="ent">❶</span> <span class="codestrong1">$sheetRows | Select-Object -Property *,@{'Name'='Worksheet';'Expression'={ $workSheetName }</span>&#13;
<span class="codestrong1">}</span></pre>&#13;
<p class="caption" id="ch10list10"><em>Listing 10-10: Getting all rows from all worksheets</em></p>&#13;
<p class="indent">Notice that you use a calculated property with <code>Select-Object</code> <span class="ent">❶</span>. Typically, when using the <code>Property</code> parameter of <code>Select-Object</code>, a simple string is used, specifying the property you want returned. When you use a calculated property, however, you provide <code>Select-Object</code> with a hashtable containing the name of the property to return and an expression that runs when <code>Select-Object</code> receives input. The result of the expression will be the value of the new, calculated property.</p>&#13;
<p class="indent">By default, <code>Import-Excel</code> doesn’t add the worksheet name as a property to each object—meaning you won’t know which worksheet the row comes from. To account for this, you need to create a property called <code>Worksheet</code> on each row object so you have something to reference later.</p>&#13;
<h4 class="h4" id="ch10lev2sec6">Adding to Excel Spreadsheets</h4>&#13;
<p class="noindent">In the previous section, you created a workbook from scratch. There will inevitably come a time when you need to add rows to a worksheet. Luckily, this is easy enough with the <code>ImportExcel</code> module; you just need to use the <code>Append</code> parameter on the <code>Export-Excel</code> command.</p>&#13;
<p class="indent">As an example, let’s say you want to track process execution history on your computer. You’d like to export all the processes running on your <span epub:type="pagebreak" id="page_129"/>computer over a period of time and then compare results in Excel later. To do so, you need to export all the running processes and make sure to include a timestamp on each row to indicate when the process information was gathered.</p>&#13;
<p class="indent">Let’s add another worksheet to our demo workbook and call it <strong>ProcessesOverTime</strong>. You’ll use a calculated property to add a timestamp property to each process row, like so:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-Process |</span> &#13;
<span class="codestrong1">Select-Object -Property *,@{Name = 'Timestamp';Expression = { Get-Date -Format&#13;
'MM-dd-yy hh:mm:ss' }} |</span> &#13;
<span class="codestrong1">Export-Excel .\Processes.xlsx -WorksheetName 'ProcessesOverTime'</span></pre>&#13;
<p class="indent">Run this command, and then open the Processes workbook. You should see a worksheet called ProcessesOverTime with a list of all running processes on your computer, and an additional timestamp column indicating when the process information was queried.</p>&#13;
<p class="indent">At this point, you’ll append additional rows to the worksheet by using the same command you just used, but this time with the <code>Append</code> parameter. This command can be run as many times as you like. It will just keep appending rows to the worksheet:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-Process |</span> &#13;
<span class="codestrong1">Select-Object -Property *,@{Name = 'Timestamp';Expression = { Get-Date -Format&#13;
'MM-dd-yy hh:mm:ss' }} |</span> &#13;
<span class="codestrong1">Export-Excel .\Processes.xlsx -WorksheetName 'ProcessesOverTime' -Append</span></pre>&#13;
<p class="indent">Once you collect your data, you can review your Excel workbook and all the process information you collected.</p>&#13;
<h4 class="h4" id="ch10lev2sec7">Project 2: Creating a Windows Service Monitoring Tool</h4>&#13;
<p class="noindent">Let’s put together the skills you learned in this section and work on another mini-project. This time, you’ll build a process to track Windows service states over time and record them to an Excel worksheet. Then, you’ll build a report showing when various services have changed state—basically, you’re making a lo-fi monitoring tool.</p>&#13;
<p class="indent">The first thing you want to do is figure out how to pull all Windows services, returning only their name and state. You can do this easily enough by running <code>Get-Service | Select-Object -Property Name,Status</code>. Next, you need to get a timestamp on each row in the Excel worksheet. Just as you did in the lesson, you’ll use a calculated property to do this; see <a href="ch10.xhtml#ch10list11">Listing 10-11</a>.</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-Service |</span> &#13;
<span class="codestrong1">Select-Object -Property Name,Status,@{Name = 'Timestamp';Expression = { Get-Date -Format 'MM-dd-yy hh:mm:ss' }} |</span> &#13;
<span class="codestrong1">Export-Excel .\ServiceStates.xlsx -WorksheetName 'Services'</span></pre>&#13;
<p class="caption" id="ch10list11"><em>Listing 10-11: Exporting service states</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_130"/>You should now have an Excel workbook created called <em>ServiceStates.xlsx</em> with a single worksheet called Services that’ll look something like <a href="ch10.xhtml#ch10fig3">Figure 10-3</a>.</p>&#13;
<div class="image"><img src="../images/10fig03.jpg" alt="Image"/></div>&#13;
<p class="figcap" id="ch10fig3"><em>Figure 10-3: The Excel workbook</em></p>&#13;
<p class="indent">Before running the same command again, let’s change the state of various Windows services. This will allow you to track changes over time. Stop and start a few services to change their states. Then run the same command as in <a href="ch10.xhtml#ch10list11">Listing 10-11</a>, although this time using the <code>Append</code> parameter to <code>Export-Excel</code>. This will get you some data to work with. (Don’t forget to use the <code>Append</code> parameter, or the command will overwrite the existing worksheet!)</p>&#13;
<p class="indent">Once you have the data, it’s time to summarize it. Excel provides multiple ways to do this, but for now, you’ll stick with a pivot table. A <em>pivot table</em> is a way to summarize data by grouping one or more properties together and then performing an action on those properties’ corresponding values (counting, adding, and so on). Using a pivot table, you can easily spot which services changed states and when they did so.</p>&#13;
<p class="indent">You’ll use the <code>IncludePivotTable</code>, <code>PivotRows</code>, <code>PivotColumns</code>, and <code>PivotData</code> parameters to create a summary pivot table (<a href="ch10.xhtml#ch10fig4">Figure 10-4</a>).</p>&#13;
<div class="image"><img src="../images/10fig04.jpg" alt="Image"/></div>&#13;
<p class="figcap" id="ch10fig4"><em>Figure 10-4: Service state pivot table</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_131"/>As you can see in <a href="ch10.xhtml#ch10list12">Listing 10-12</a>, you’re reading the data in the Services worksheet and using that data to create a pivot table.</p>&#13;
<pre>PS&gt;<span class="codestrong1"> Import-Excel .\ServiceStates.xlsx -WorksheetName 'Services' |</span> &#13;
<span class="codestrong1">Export-Excel -Path .\ServiceStates.xlsx -Show -IncludePivotTable -PivotRows Name,Timestamp&#13;
-PivotData @{Timestamp = 'count'} -PivotColumns Status</span></pre>&#13;
<p class="caption" id="ch10list12"><em>Listing 10-12: Creating an Excel pivot table with PowerShell</em></p>&#13;
<p class="indent">The <code>ImportExcel</code> PowerShell module has a suite of options you can use here. If you want to keep working with this dataset, play around with it and see what you can do. Take a look at the ImportExcel GitHub repository (<a href="https://github.com/dfinke/ImportExcel"><em>https://github.com/dfinke/ImportExcel</em></a>), or if you want to use different data, give that a go. As long as you have the data, PowerShell can manipulate and represent it just about any way you like!</p>&#13;
<h3 class="h3" id="ch10lev3">JSON Data</h3>&#13;
<p class="noindent">If you’ve been working in tech for the last five years, you’ve probably read some JSON. Created in the early 2000s, <em>JavaScript Object Notation (JSON)</em> is a machine-readable, human-understandable language that represents hierarchical sets of data. As its name might suggest, it’s heavily used in JavaScript applications, meaning it has a strong presence in web development.</p>&#13;
<p class="indent">A recent surge in the number of online services that use a <em>REST API</em>—a technology used to send data between client and server—has led to a similar surge in the use of JSON. If you’re doing anything with the web, JSON is a good format to know, and it’s one you can easily manage in PowerShell.</p>&#13;
<h4 class="h4" id="ch10lev3sec8">Reading JSON</h4>&#13;
<p class="noindent">Similar to reading the CSVs, you can read JSON a couple of ways in PowerShell: with parsing or no parsing. Since JSON is just plaintext, PowerShell treats it as a string by default. As an example, look at the JSON file <em>Employees.json</em> found in this chapter’s resources, reproduced here:</p>&#13;
<pre>{&#13;
    "Employees": [&#13;
        {&#13;
            "FirstName": "Adam",&#13;
            "LastName": "Bertram",&#13;
            "Department": "IT",&#13;
            "Title": "Awesome IT Professional"&#13;
        },&#13;
        {&#13;
            "FirstName": "Bob",&#13;
            "LastName": "Smith",&#13;
            "Department": "HR",&#13;
            "Title": "Crotchety HR guy"&#13;
        }&#13;
    ]&#13;
}</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_132"/>If you want only the string output, you can use <code>Get-Content -Path Employees</code><code>.json -Raw</code> to read the file and return a string. But there’s not much you can do with a string. You need structure. To get that, you need something that understands the JSON schema (the way individual nodes and arrays of nodes are represented in JSON) and can parse the file accordingly. You need the <code>ConvertFrom-Json</code> cmdlet.</p>&#13;
<p class="indent">The <code>ConvertFrom-Json</code> cmdlet is a native cmdlet in PowerShell that takes raw JSON as input and converts it into PowerShell objects. You can see in <a href="ch10.xhtml#ch10list13">Listing 10-13</a> that PowerShell knows <code>Employees</code> is a property now.</p>&#13;
<pre>PS&gt; <span class="codestrong1">Get-Content -Path .\Employees.json -Raw | ConvertFrom-Json</span>&#13;
&#13;
Employees&#13;
---------&#13;
{@{FirstName=Adam; LastName=Bertram; Department=IT;&#13;
Title=Awesome IT Professional}, @{FirstName=Bob;&#13;
LastName=Smith; Department=HR; Title=Crotchety H...</pre>&#13;
<p class="caption" id="ch10list13"><em>Listing 10-13: Converting JSON to objects</em></p>&#13;
<p class="indent">If you take a look at the <code>Employees</code> property, you’ll see that all the employee nodes have been parsed out, with each key representing a column header, and each value representing the row value:</p>&#13;
<pre>PS&gt; <span class="codestrong1">(Get-Content -Path .\Employees.json -Raw | ConvertFrom-Json).Employees</span>&#13;
&#13;
FirstName LastName Department Title&#13;
--------- -------- ---------- -----&#13;
Adam      Bertram  IT         Awesome IT Professional&#13;
Bob       Smith    HR         Crotchety HR guy</pre>&#13;
<p class="indent">The <code>Employees</code> property is now an array of objects that you can query and manipulate just as you would any other array.</p>&#13;
<h4 class="h4" id="ch10lev3sec9">Creating JSON Strings</h4>&#13;
<p class="noindent">Let’s say you have a whole bunch of data from a whole bunch of sources and you want to convert it all to JSON. What do you do? This is the magic of the <code>ConvertTo-Json</code> cmdlet: it can convert any object in PowerShell to JSON.</p>&#13;
<p class="indent">As an example, let’s convert the CSV file you built earlier in the chapter into <em>Employees.json</em>. First, you need to import our CSV:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Import-Csv -Path .\Employees.csv -Delimiter "`t"</span>&#13;
&#13;
First Name Last Name Department       Manager&#13;
---------- --------- ----------       -------&#13;
Adam       Bertram   IT               Miranda Bertram&#13;
Barack     Obama     Executive Office Michelle Obama&#13;
Miranda    Bertram   Executive Office&#13;
Michelle   Obama     Executive Office</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_133"/>To do the conversion, you need to pipe the output to <code>ConvertTo-Json</code>, as in <a href="ch10.xhtml#ch10list14">Listing 10-14</a>.</p>&#13;
<pre>PS&gt; <span class="codestrong1">Import-Csv -Path .\Employees.csv -Delimiter "`t" | ConvertTo-Json</span>&#13;
[&#13;
    {&#13;
        "First Name":  "Adam",&#13;
        "Last Name":  "Bertram",&#13;
        "Department":  "IT",&#13;
        "Manager":  "Miranda Bertram"&#13;
    },&#13;
    {&#13;
        "First Name":  "Barack",&#13;
        "Last Name":  "Obama",&#13;
        "Department":  "Executive Office",&#13;
        "Manager":  "Michelle Obama"&#13;
    },&#13;
    {&#13;
        "First Name":  "Miranda",&#13;
        "Last Name":  "Bertram",&#13;
        "Department":  "Executive Office",&#13;
        "Manager":  null&#13;
    },&#13;
    {&#13;
        "First Name":  "Michelle",&#13;
        "Last Name":  "Obama",&#13;
        "Department":  "Executive Office",&#13;
        "Manager":  null&#13;
    }&#13;
]</pre>&#13;
<p class="caption" id="ch10list14"><em>Listing 10-14: Converting objects to JSON</em></p>&#13;
<p class="indent">As you might expect by now, there are a couple parameters you can pass in to modify the conversion. A nice one is the <code>Compress</code> parameter, which minifies the output by removing all the potentially unwanted line breaks:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Import-Csv -Path .\Employees.csv -Delimiter "`t" | ConvertTo-Json –Compress</span>&#13;
[{"First Name":"Adam","Last&#13;
Name":"Bertram","Department":"IT","Manager":"Miranda&#13;
Bertram"},{"First Name":"Barack","Last&#13;
Name":"Obama","Department":"Executive Office","Manager":"Michelle Obama"},{"First&#13;
Name":"Miranda","Last Name":"Bertram","Department":"Executive&#13;
Office","Manager":null},{"First Name":"Michelle",&#13;
"Last Name":"Obama","Department":"Executive&#13;
Office","Manager":null}]</pre>&#13;
<p class="indent">If it has a property and a property value, <code>ConvertTo-Json</code> can do its job. The property will always be the node key, and the property value will always be the node value.</p>&#13;
<h4 class="h4" id="ch10lev3sec10"><span epub:type="pagebreak" id="page_134"/>Project 3: Querying and Parsing a REST API</h4>&#13;
<p class="noindent">Now that you know how to parse JSON, let’s do something a little fancier: let’s use PowerShell to query a REST API and parse the results. You could use just about any REST API, but some require authentication, and it’ll be easier to do this without the extra steps. Let’s use one that doesn’t require authentication. I’ve found a REST API at <em>postcodes.io</em>, a service that allows you to query UK postal codes from various criteria.</p>&#13;
<p class="indent">The URI you’ll use is <em><a href="http://api.postcodes.io/random/postcodes">http://api.postcodes.io/random/postcodes</a></em>. When you access this URI, it will query the <em>postcodes.io</em> API service and return a random postcode in JSON form. To query this URI, you’ll use PowerShell’s <code>Invoke-WebRequest</code> cmdlet:</p>&#13;
<pre>PS&gt; <span class="codestrong1">$result =</span> <span class="codestrong1">Invoke-WebRequest -Uri 'http://api.postcodes.io/random/postcodes'</span>&#13;
PS&gt; <span class="codestrong1">$result.Content</span>&#13;
{"status":200,"result":{"postcode":"IP12&#13;
2FE","quality":1,"eastings":641878,"northings":250383,"country&#13;
:"England","nhs_ha":"East of England","longitude":&#13;
1.53013518866685,"latitude":52.0988661618569,"european_elector&#13;
al_region":"Eastern","primary_care_trust":"Suffolk","region":"&#13;
East of England","lsoa":"Suffo&#13;
lk Coastal 007C","msoa":"Suffolk Coastal&#13;
007","incode":"2FE","outcode":"IP12","parliamentary_constituen&#13;
cy":"Suffolk Coastal","admin_district":"Suffolk Coa&#13;
stal","parish":"Orford","admin_county":"Suffolk","admin_ward":&#13;
"Orford &amp; Eyke","ccg":"NHS Ipswich and East&#13;
Suffolk","nuts":"Suffolk","codes":{"admin_distri&#13;
ct":"E07000205","admin_county":"E10000029","admin_ward":"E0501&#13;
449","parish":"E04009440","parliamentary_constituency":"E14000&#13;
81","ccg":"E38000086","nuts"&#13;
:"UKH14"}}}</pre>&#13;
<p class="indent">In Windows PowerShell, <code>Invoke-WebRequest</code> relies on Internet Explorer. If you don't have Internet Explorer on your computer, you may have to use the <code>-UseBasicParsing</code> parameter to remove the dependency. “Advanced” parsing breaks down the resulting HTML output a bit more but it's not needed in all cases.</p>&#13;
<p class="indent">Now, let’s see if you can convert the result into a PowerShell object:</p>&#13;
<pre>PS&gt; <span class="codestrong1">$result = Invoke-WebRequest -Uri 'http://api.postcodes.io/random/postcodes'</span>&#13;
PS&gt; <span class="codestrong1">$result.Content | ConvertFrom-Json</span>&#13;
&#13;
status result&#13;
------ ------&#13;
   200 @{postcode=DE7 9HY; quality=1; eastings=445564;&#13;
       northings=343166; country=England; nhs_ha=East Midlands;&#13;
       longitude=-1.32277519314161; latitude=...&#13;
&#13;
PS&gt; <span class="codestrong1">$result = Invoke-WebRequest -Uri 'http://api.postcodes.io/random/postcodes'</span>&#13;
PS&gt;<span class="codestrong1"> $contentObject = $result.Content | ConvertFrom-Json</span>&#13;
PS&gt;<span class="codestrong1"> $contentObject.result</span>&#13;
&#13;
postcode                   : HA7 2SR&#13;
quality                    : 1&#13;
eastings                   : 516924&#13;
northings                  : 191681&#13;
country                    : England&#13;
nhs_ha                     : London&#13;
<span epub:type="pagebreak" id="page_135"/>longitude                  : -0.312779792807334&#13;
latitude                   : 51.6118279308721&#13;
european_electoral_region  : London&#13;
primary_care_trust         : Harrow&#13;
region                     : London&#13;
lsoa                       : Harrow 003C&#13;
msoa                       : Harrow 003&#13;
incode                     : 2SR&#13;
outcode                    : HA7&#13;
parliamentary_constituency : Harrow East&#13;
admin_district             : Harrow&#13;
parish                     : Harrow, unparished area&#13;
admin_county               :&#13;
admin_ward                 : Stanmore Park&#13;
ccg                        : NHS Harrow&#13;
nuts                       : Harrow and Hillingdon&#13;
codes                      : @{admin_district=E09000015;&#13;
                             admin_county=E99999999; admin_ward=E05000303;&#13;
                             parish=E43000205;</pre>&#13;
<p class="indent">You can convert the response to JSON without a problem. But you have to use two commands, <code>Invoke-WebRequest</code> and <code>ConvertFrom-Json</code>. Wouldn’t life be great if you could use only one? It turns out that PowerShell has a command that will do everything for you: <code>Invoke-RestMethod</code>.</p>&#13;
<p class="indent">The <code>Invoke-RestMethod</code> cmdlet is similar to <code>Invoke-WebRequest</code>; it sends various HTTP verbs to web services and returns the response. Because the <em>postcodes.io</em> API service does not require any authentication, you can simply use the <code>Uri</code> parameter on <code>Invoke-RestMethod</code> to get the API response:</p>&#13;
<pre>PS&gt; <span class="codestrong1">Invoke-RestMethod –Uri 'http://api.postcodes.io/random/postcodes'</span>&#13;
&#13;
status result&#13;
------ ------&#13;
   200 @{postcode=NE23 6AA; quality=1; eastings=426492;&#13;
       northings=576264; country=England; nhs_ha=North East;&#13;
       longitude=-1.5865793029774; latitude=55...</pre>&#13;
<p class="indent">You can see that <code>Invoke-RestMethod</code> returns an HTTP status code and the response from the API in the <code>result</code> property. So where’s the JSON? Well, just as you wanted, it’s already been converted to an object for you. There’s no need to manually convert the JSON to an object, as you can use the <code>result</code> property:</p>&#13;
<pre>PS&gt; <span class="codestrong1">(Invoke-RestMethod –Uri 'http://api.postcodes.io/random/postcodes').result</span>&#13;
&#13;
postcode                   : SY11 4BL&#13;
quality                    : 1&#13;
eastings                   : 332201&#13;
northings                  : 331090&#13;
country                    : England&#13;
nhs_ha                     : West Midlands&#13;
longitude                  : -3.00873643515338&#13;
<span epub:type="pagebreak" id="page_136"/>latitude                   : 52.8729967314029&#13;
european_electoral_region  : West Midlands&#13;
primary_care_trust         : Shropshire County&#13;
region                     : West Midlands&#13;
lsoa                       : Shropshire 011E&#13;
msoa                       : Shropshire 011&#13;
incode                     : 4BL&#13;
outcode                    : SY11&#13;
parliamentary_constituency : North Shropshire&#13;
admin_district             : Shropshire&#13;
parish                     : Whittington&#13;
admin_county               :&#13;
admin_ward                 : Whittington&#13;
ccg                        : NHS Shropshire&#13;
nuts                       : Shropshire CC&#13;
codes                      : @{admin_district=E06000051;&#13;
                             admin_county=E99999999; admin_ward=E05009287;&#13;
                             parish=E04012256;</pre>&#13;
<p class="indent">Working with JSON in PowerShell is a straightforward process. With PowerShell’s easy-to-use cmdlets, you’re usually spared any complicated string parsing—simply pass in JSON, or a soon-to-be-JSONified object, into the pipeline and watch the magic happen!</p>&#13;
<h3 class="h3" id="ch10lev4">Summary</h3>&#13;
<p class="noindent">This chapter covered a few ways to structure data, as well as how to work with those structures in PowerShell. PowerShell’s native cmdlets make this process a breeze, abstracting away a lot of complicated code and leaving the user with easy-to-use commands. But don’t let its simplicity fool you: PowerShell can parse and manipulate nearly any kind of data. Even if it doesn’t have a native command to handle the data type, because of its .NET foundation, it’s able to dig into any .NET classes for any advanced concepts.</p>&#13;
<p class="indent">In the next chapter, we’ll work with Microsoft’s Active Directory (AD). Full of repetitive tasks, AD is a common place to start when learning to use PowerShell; we’ll spend a lot of time on this great resource throughout the rest of this book.</p>&#13;
</body></html>