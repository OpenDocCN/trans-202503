- en: '**4**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**EXAMINING STORAGE**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00015.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Over the next several chapters, we dive into specific Azure services and the
    pentest techniques and tools unique to each. We’ll begin with Azure Storage accounts,
    which are used by several Azure services to store everything from logs to virtual
    machine “hard disk” images. Customers also use storage accounts for document sharing
    and backups—essentially a cloud-based replacement for on-premises file servers.
    Of course, centralizing all of this data in one place makes for a tempting target
    for attackers.
  prefs: []
  type: TYPE_NORMAL
- en: Aside from the potential value of its data, a storage account is an ideal target
    for several reasons; the most important is that every storage account has two
    keys that grant full control to its data. These keys are shared by all services
    using the storage account and all account administrators. To make matters worse,
    most customers never change them.
  prefs: []
  type: TYPE_NORMAL
- en: 'These practices cause problems with repudiation, authorization, and remediation
    (if an attack does occur). Storage account keys also might have a user-inflicted
    weakness: because so many applications require storage access, developers often
    embed storage keys in their code or configuration files without considering the
    possible security ramifications.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we first discuss the different authentication methods available
    in Azure Storage. We then look at how to find these credentials in source code,
    followed by a look at each of the popular tools used to access and manage Azure
    Storage and how credentials can be stolen from them. This is important, because
    you won’t know ahead of time what utilities you’ll encounter on developer systems.
    Finally, we look at how to retrieve different forms of data from storage accounts.
    This serves two purposes: first, it demonstrates to clients that improperly secured
    cloud storage poses a significant risk of a data breach; second, the data in the
    accounts can sometimes be used to obtain additional access to an environment.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Best Practices: Storage Security**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Improperly configured cloud storage has been mentioned in over two dozen publicly
    disclosed data breaches between 2016 and 2018\. Generally, issues arise when developers
    write code that programmatically accesses a cloud storage container, and the developer
    embeds the access key in their source code and checks it in to source control.
    Since many companies use services like GitHub to host their code, the developer
    might not realize that the repository they checked the password into was publicly
    accessible. Occasionally, breaches also occur when storage accounts are configured
    to be readable by anyone, without requiring a password. Since malicious actors
    routinely scan public repositories looking for passwords and storage account URLs,
    trying to gain access, the time between a mistake and a breach can be very short.
    But even when access to a repository is limited, the number of people with access
    to the code is usually higher than the number of people who are authorized to
    have access keys. In addition, secrets and keys should never be stored in cleartext,
    even temporarily.
  prefs: []
  type: TYPE_NORMAL
- en: As an administrator, you can take several steps to protect against these issues.
    First, regularly practice “rolling” or resetting the access keys for your storage
    accounts and document any places where the keys need to be updated. This way,
    if a real incident does occur, you can begin remediation without worrying about
    breaking dependent services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, enable encryption of data in transit and at rest for your cloud storage
    whenever possible. As of late 2017, Azure defaults to encrypting all data at rest
    in Azure Storage, using a key that is managed automatically. If desired, administrators
    can provide their own encryption key using the storage account settings in the
    Azure portal. However, although this setting protects the data on its storage
    medium, it doesn’t protect the data as it is uploaded or downloaded from the storage
    account. For this, the storage account must be configured to allow connections
    only over the HTTPS protocol. This can be done in the storage account configuration
    settings in Azure portal by enabling the “Secure transfer required” option. It
    can also be enabled via PowerShell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: To ensure that storage accounts can’t be accessed by more people than intended,
    regularly check the Access Type setting for your storage containers. It should
    be set to Private unless you intend to allow anonymous access. Additionally, you
    can use Shared Access Signature (SAS) access tokens to specify more granular permissions
    within storage accounts, including limiting access to specific time spans and
    IP ranges. For more information about these permissions, see *[https://docs.microsoft.com/en-us/azure/storage/blobs/storage-manage-access-to-resources/](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-manage-access-to-resources/)*.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, perform regular code reviews to look for instances of developers checking
    secrets into source code. You might even consider using a code analysis tool to
    automatically check for the presence of passwords whenever new code is checked
    in. This can be helpful not only for finding storage account keys but other credentials
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: '**Accessing Storage Accounts**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure Storage can be accessed through storage account keys, user credentials,
    and *Shared Access Signature (SAS)* tokens, which are URLs with embedded access
    keys that usually provide access to a limited subset of files and may have other
    restrictions. Each type of credential has a different purpose, and some are more
    useful to a penetration tester than others. Let’s examine each of them.
  prefs: []
  type: TYPE_NORMAL
- en: '***Storage Account Keys***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Using storage account keys, paired with the name of a storage account, is the
    most desired and frequently used method of attack because they grant full access
    to the entire storage account without the need for 2FA. Storage accounts have
    only two keys—a primary and secondary—and all storage account users share these
    keys. These keys don’t expire on their own, but they can be rolled. Unlike passwords,
    which can be chosen by a user, storage keys are automatically generated 64-byte
    values represented in base64 encoding, which makes them easy to identify in source
    code or configuration files.
  prefs: []
  type: TYPE_NORMAL
- en: Storage keys are also supported by every Azure Storage utility and storage-related
    API, making them highly versatile. Additionally, they are the most common credential
    used by developers and are changed infrequently, so the chances of obtaining valid
    keys are good.
  prefs: []
  type: TYPE_NORMAL
- en: '***User Credentials***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Obtaining user credentials is the next-best way in. Although role-based permissions
    could limit a user account’s ability to perform certain actions against a storage
    account, in practice, permissions this granular are rarely implemented. The biggest
    downside to relying on these credentials is the potential for encountering 2FA.
    If a user’s account has 2FA enabled, it’s impossible to impersonate them without
    using one of the methods discussed in “[Encountering Two-Factor Authentication](part0011.html#lev38)”
    on [page 26](part0011.html#page_26). Those methods add additional complexity to
    an attack and decrease the odds of success. An additional hurdle when employing
    user credentials is the lack of tool support. Many of the Azure Storage utilities
    we’ll look at later in this chapter only accept storage keys, so you may have
    to log in to the Azure portal with the user credentials and copy the storage keys
    to use them.
  prefs: []
  type: TYPE_NORMAL
- en: '***SAS Tokens***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SAS tokens are keys that grant only certain rights to a subset of objects in
    a storage account. For example, SAS tokens are used to enable the “share a file”
    options in OneDrive, SharePoint Online, Office 365, Dropbox, and similar services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure SAS tokens are formatted as URLs that point to Azure Storage and contain
    a long string of parameters and a unique SHA256-hashed, base64-encoded key that
    looks something like this: *[https://storagerm.blob.core.windows.net/container/file.txt?st=2017-04-09T01%3A00%3A00Z&se=2017-04-20T01%3A00%3A00Z&sp=r&sip=127.0.0.1-127.0.0.100&sig=7%2BwycBOdzx8IS4zhMcKNw7AHvnZlYwk8wXIqNtLEu4s%3D](https://storagerm.blob.core.windows.net/container/file.txt?st=2017-04-09T01%3A00%3A00Z&se=2017-04-20T01%3A00%3A00Z&sp=r&sip=127.0.0.1-127.0.0.100&sig=7%2BwycBOdzx8IS4zhMcKNw7AHvnZlYwk8wXIqNtLEu4s%3D)*.'
  prefs: []
  type: TYPE_NORMAL
- en: Penetration testers may find SAS tokens not particularly useful, not only because
    they are usually scoped to a subset of files but also because they may have assigned
    permissions (via the SP parameter) such as read-only. SAS tokens can also be designated
    to work only from a specific IP address or range (via the SIP parameter), so even
    if you get a SAS token, it might only work from the machine for which it was originally
    created. SAS tokens might also have designated start and end times (via the ST
    and SE parameters, respectively) that limit a token’s lifetime to that period.
  prefs: []
  type: TYPE_NORMAL
- en: As if all this wasn’t discouraging enough, most Azure tools don’t support SAS
    tokens. This means you’ll likely be limited to using them through a web browser.
    What’s more, if you somehow find a cache of these tokens, it will take some time
    to go through them sequentially, thus using up valuable testing hours. That said,
    if the prior two credential types aren’t available, a usable SAS token is better
    than no access at all.
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFENDER’S TIP**'
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft provides detailed guidance on choosing the correct storage authentication
    options, common pitfalls, possible mitigations, and ways to recover from a compromised
    credential at *[https://docs.microsoft.com/en-us/azure/storage/storage-security-guide](https://docs.microsoft.com/en-us/azure/storage/storage-security-guide)*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Where to Find Storage Credentials**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that you know the types of credentials to look for, let’s examine the most
    common places where they can be found: source code and storage management utilities.
    For source code sleuthing, you’ll need access to either a developer’s machine
    or their source code control system. To get keys out of storage utilities, you’ll
    need to find where these tools are installed; typically, this is on developer
    workstations. With access to these systems, you can begin hunting for keys.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Finding Keys in Source Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The most straightforward way to find storage keys is in the source code of applications
    that use Azure Storage—usually in configuration files used to build everything
    from an Azure website to custom business applications that use the cloud to store
    data. You have several ways to quickly locate storage keys in source code, but
    the method you should choose depends on the type of code you find.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft provides libraries for .NET (C# and Visual Basic) and Java to make
    it easier to access storage and other Azure features. Fortunately, the name of
    functions used to authenticate to Azure Storage are consistent across these libraries.
    Search for instances of the *StorageCredentials* class, and you’ll likely find
    where any application uses storage keys. If that doesn’t work, try searching for
    the library’s full name, such as *Microsoft.WindowsAzure.Storage.Auth* in .NET
    or *com.microsoft.azure.storage.StorageCredentials* in Java.
  prefs: []
  type: TYPE_NORMAL
- en: If you suspect that a certain storage instance may use SAS tokens, search code
    repositories for *.core.windows.net*, the domain used in all SAS token URLs. (The
    base64 signature in SAS tokens should make them easy to distinguish from any other
    *windows.net* domain references.)
  prefs: []
  type: TYPE_NORMAL
- en: Many code bases place storage account keys into configuration files, especially
    when coupled with ASP.NET and Azure websites. ASP.NET and Azure websites use files
    named *web.config*, whereas other websites often use *app.config* files. Storage
    account keys in config files are often labeled *StorageAccountKey*, *StorageServiceKeys*,
    or *StorageConnectionString* (the name used in some Microsoft documentation sample
    code).
  prefs: []
  type: TYPE_NORMAL
- en: You can identify Azure Storage use within JavaScript files by scanning for *azure-storage.common.js*.
    If you find this script reference in code, also look for *AzureStorage.createBlobService*;
    you’ll need it in order to authenticate to Azure. (The JavaScript library allows
    the use of both storage keys and SAS tokens, but greatly encourages the use of
    highly restricted SAS tokens because users can view JavaScript code.)
  prefs: []
  type: TYPE_NORMAL
- en: '***Obtaining Keys from a Developer’s Storage Utilities***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you can’t find storage keys in source code, you may be able to recover them
    from tools that the developers used to transfer files to Azure. To find these
    keys, you first need to access a developer’s workstation and then look for Azure
    Storage management applications. Once you have access, check the application to
    see if it exposes saved keys in its user interface or if it saves the keys in
    an insecure manner.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we look at the tools most commonly used to manage storage accounts
    to see if they’re susceptible to this attack.
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFENDER’S TIP**'
  prefs: []
  type: TYPE_NORMAL
- en: Notice in the following discussion that only Microsoft Azure Storage Explorer
    makes key recovery difficult for an attacker. If you must use a tool to manage
    Azure Storage and if you have cached credentials on your system, Microsoft Azure
    Storage Explorer is the safest choice.
  prefs: []
  type: TYPE_NORMAL
- en: '**Getting Keys from Microsoft Azure Storage Explorer**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Azure Storage Explorer is well designed, with storage key protection as an obvious
    goal. It offers no option to show a key once it’s saved in the interface, and
    the encrypted keys are stored in Windows Credential Manager, which makes recovering
    them directly impractical.
  prefs: []
  type: TYPE_NORMAL
- en: Despite these security features, all is not lost. Because Azure Storage Explorer
    needs to decrypt the keys in order to provide them to Azure’s API when transferring
    data, you can set a breakpoint in Storage Explorer’s code on the line just after
    the keys are decrypted and then view them directly in memory with the built-in
    debugger.
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform this test, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Launch Azure Storage Explorer on the target engineer’s workstation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose **Help** ▸ **Toggle Developer Tools**. You should see the debugger interface.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the debugging window, click the **Sources** tab at the top of the screen
    and then click the vertical ellipse menu and choose **Go to file**, as shown in
    [Figure 4-1](part0013.html#ch04fig1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![image](../images/00021.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '*Figure 4-1: The Sources view in Azure Storage Explorer*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the file list dialog that appears, enter AzureStorageUtilities.js and click
    the first entry to load the *AzureStorageUtilities.js* file, which contains the
    logic to load the storage account keys.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand the debugger window so you can read the source code; then find the function
    `loadStorageAccounts(host, key)`, which is shown in [Listing 4-1](part0013.html#ch04list1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*Listing 4-1: Code snippet from Microsoft Azure Storage Explorer’s* loadStorageAccounts()
    *function*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Set a breakpoint in this function just before the account information is returned
    to the application by clicking the line number for the line `return account;`
    on the left side of the window, as shown in [Figure 4-2](part0013.html#ch04fig2).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, to trigger the application to reload the account information so that the
    breakpoint will be hit, click **Refresh All** above the list of accounts. The
    debugger should break in and pause the application. Look for the account: Object
    variable on the right side of the window (as shown in [Figure 4-2](part0013.html#ch04fig2))
    and click the arrow next to `account` to expand it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![image](../images/00022.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-2: Account object expanded in the debugger*'
  prefs: []
  type: TYPE_NORMAL
- en: The `account` object should list the `accountKey` as well as the `accountName`
    of the first storage account registered in Azure Storage Explorer. To see if there
    are multiple accounts, press F8 to continue execution. If there are more storage
    accounts, the debugger should immediately break in again and update the account
    object with the next account details. Keep pressing F8 until you have recovered
    the connection information for each storage account.
  prefs: []
  type: TYPE_NORMAL
- en: Once the last storage account’s details are shown, press F8 again to return
    the application to normal operation. Then remove your breakpoint by right-clicking
    in the Breakpoints list in the pane on the right and choosing **Remove All Breakpoints**.
    Finally, click **Help** ▸ **Toggle Developer Tools** to close the debugging tools
    and then exit the application.
  prefs: []
  type: TYPE_NORMAL
- en: '**Getting Keys from Redgate’s Azure Explorer**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Redgate’s Azure Explorer gives you two ways to access the keys it contains:
    a connection editor dialog and a Copy option in each account’s context menu. To
    view account keys, launch Redgate’s Azure Explorer, open the account, and then
    right-click the account to dig into its details, as shown in [Figure 4-3](part0013.html#ch04fig3).'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00023.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-3: Redgate’s storage account menu*'
  prefs: []
  type: TYPE_NORMAL
- en: The Edit Connection Details option opens a dialog like the one shown in [Figure
    4-4](part0013.html#ch04fig4), where you can update the key associated with a storage
    account. The dialog conveniently displays the current key in plaintext.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00024.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-4: Storage account key in Redgate’s Azure Explorer*'
  prefs: []
  type: TYPE_NORMAL
- en: The Copy Connection String option is also interesting. You can use it to copy
    the key to the clipboard in SQL Connection String format, which contains the key
    itself and the account name, and also indicates whether the storage account should
    be accessed using SSL or an unencrypted connection. Use this option to grab all
    required connection information for an account and then paste it into a small
    document. Repeat this for each listed account.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Because Redgate encrypts storage keys in Azure Explorer’s settings file* %UserProfile%\AppData\Local\Red
    Gate\Azure Explorer\Settings.xml*, you will need to be able to run Azure Explorer
    to recover the keys; you can’t simply take the XML file.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Getting Keys from ClumsyLeaf’s CloudXplorer**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'ClumsyLeaf Software makes three products for interacting with cloud-based storage:
    CloudXplorer, TableXplorer, and AzureXplorer. All of these tools allow you to
    manage not just Azure Storage but also storage offerings from other providers,
    such as Amazon and Google.'
  prefs: []
  type: TYPE_NORMAL
- en: CloudXplorer interacts with files and blob storage, whereas TableXplorer provides
    a SQL-like interface for tabular cloud storage. AzureXplorer is a Visual Studio
    plug-in to make interacting with cloud content easier during development.
  prefs: []
  type: TYPE_NORMAL
- en: You can view and edit stored keys in CloudXplorer by right-clicking a storage
    account in the left pane and choosing **Properties**, as shown in [Figure 4-5](part0013.html#ch04fig5).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00025.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-5: Storage account context menu in CloudXplorer*'
  prefs: []
  type: TYPE_NORMAL
- en: The Account window (see [Figure 4-6](part0013.html#ch04fig6)) shows which Azure
    instance is being used and whether SSL is enabled, and should allow you to copy
    both the name and key of the storage account.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00026.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-6: Account information in CloudXplorer*'
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*CloudXplorer’s Configuration* ▸ *Export option exports all of the storage
    account connection details, but they’re encrypted. You’re not likely to find that
    very useful.*'
  prefs: []
  type: TYPE_NORMAL
- en: Like Redgate, ClumsyLeaf also encrypts its account information within an XML
    file. You’ll find it at *%AppData%\ClumsyLeaf Software\CloudXplorer\accounts.xml*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Getting Keys from ClumsyLeaf’s TableXplorer**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: To use TableXplorer to view storage accounts, click **Manage Accounts**, as
    shown in [Figure 4-7](part0013.html#ch04fig7), to open the Manage Accounts window.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00027.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-7: The Manage Accounts button in TableXplorer*'
  prefs: []
  type: TYPE_NORMAL
- en: The Manage Accounts window should display each account, as shown in [Figure
    4-8](part0013.html#ch04fig8). Azure Storage accounts are marked with a Windows
    logo and Amazon accounts with an orange cube. Click the name of an account and
    choose **Edit**.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00028.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-8: Account list in TableXplorer*'
  prefs: []
  type: TYPE_NORMAL
- en: The Edit window will look just like the CloudXplorer window shown earlier in
    [Figure 4-6](part0013.html#ch04fig6). Also, like CloudXplorer, TableXplorer encrypts
    the keys in its configuration file, which is located at *%AppData%\ClumsyLeaf
    Software\TableXplorer\accounts.xml*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Getting Keys from Azure Storage Explorer 6**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Azure Storage Explorer 6 is probably the oldest tool on this list. Although
    it’s no longer maintained, it was the standard for years, and you’ll probably
    find it on many developer systems for years to come.
  prefs: []
  type: TYPE_NORMAL
- en: 'To view storage account settings through Azure Storage Explorer 6, follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Launch the application and choose an account from the drop-down list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the account and then choose **Storage Account** ▸ **View Connection String**,
    as shown in [Figure 4-9](part0013.html#ch04fig9).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![image](../images/00029.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '*Figure 4-9: The Storage Account menu in Azure Storage Explorer 6*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You should see a pop-up message box appear, displaying the SQL Connection String–formatted
    account key, as shown in [Figure 4-10](part0013.html#ch04fig10). Click **OK**
    to copy the value to the clipboard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![image](../images/00030.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '*Figure 4-10: Storage account connection string in Azure Storage Explorer 6*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Prior to version 6 of Azure Storage Explorer, unencrypted credentials were stored
    in *%AppData%\AzureStorageExplorer\AzureStorageExplorer.config*, making this a
    valuable file to look for any time you suspect a machine has been used to manage
    storage accounts. Beginning with version 6, these settings were encrypted and
    moved to *%AppData%\Neudesic\AzureStorageExplorer\<Version>\AzureStorageExplorer6.dt1*.
    However, because Azure Storage Explorer is open source and because the same encryption
    key is used in every installation, it’s very easy to find the encryption key it
    uses to “protect” these files online, as well as the encryption and decryption
    code. Of course, it’s easier to recover storage keys from the GUI, but it’s helpful
    to have another option if you can’t launch applications on the system you’re targeting.
  prefs: []
  type: TYPE_NORMAL
- en: '**Accessing Storage Types**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once you have access to a storage account, it’s time to find out what kind of
    data you can obtain. First, you’ll need to determine which storage mechanisms
    each account uses (blob, table, queue, and/or file), bearing in mind that a single
    account can use more than one mechanism. Be sure to check each account for each
    storage type.
  prefs: []
  type: TYPE_NORMAL
- en: '***Identifying the Storage Mechanisms in Use***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although you can check for storage account content using the Azure portal, a
    penetration tester could face a couple of challenges with that method. First,
    an account may have only a management certificate, which won’t provide direct
    portal access. Second, the Azure portal doesn’t display a summary of each storage
    type in one view; you have to click each account, click to view any blobs in that
    account, and then click the button for files, and so on. This process takes a
    while when subscriptions contain numerous storage accounts.
  prefs: []
  type: TYPE_NORMAL
- en: The best way to identify the storage types in use is with PowerShell. For example,
    the PowerShell script shown in [Listing 4-2](part0013.html#ch04list2) will enumerate
    all storage accounts in a subscription, check each storage mechanism for content,
    and then display a summary of anything it finds.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 4-2: Listing storage account usage via PowerShell*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This script is split into two parts: the first part searches ASM storage accounts,
    and the second searches ARM.'
  prefs: []
  type: TYPE_NORMAL
- en: We begin by getting a list of all ASM storage accounts in the subscription ➊.
    For each account, we obtain the key ➋ and then create a *context* for that storage
    account ➌—a PowerShell object that contains both the name and key of the storage
    account. We can use this context when accessing a storage account in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the script begins examining the different storage types, as discussed
    in the following sections, before repeating the process for ARM storage accounts.
  prefs: []
  type: TYPE_NORMAL
- en: '***Accessing Blobs***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A blob is the most basic form of storage in Azure: it’s an unstructured collection
    of bits that applications can use without restriction. Blobs are most commonly
    used to store virtual hard disk files for Azure virtual machines.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll find three kinds of blobs in Azure: *page*, *append*, and *block*. As
    a pentester, it can be helpful to know the primary usage for each blob type so
    you can make an educated guess about the contents of a given blob without necessarily
    having to download it. In my assessments, I’ve found it can be enormously frustrating
    to download a multi-gigabyte file over several hours, only to discover it isn’t
    what I expected.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Page blobs* are made up of sets of bytes, referred to as *pages*. Each page
    is 512 bytes, and a page blob itself can be up to 1TB in size. The total size
    must be set when the blob is created, which means there is a strong chance a page
    blob file will be quite large, but only a small fraction of it will be data—the
    rest will likely be empty. Because page blobs are very efficient at random reads/writes,
    they are the blob type used for hard disk images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Append blobs* are optimized for adding new data, but changes are prohibited
    to existing data within the blob. They can be up to 195GB in size and are ideal
    for log files. Log files may be interesting if you are trying to identify additional
    user accounts, IP addresses, or servers that could be related to your assessment;
    however, if you are just hoping to modify logs to erase your tracks, append blobs
    won’t let you do so.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Block blobs* are the default type. They consist of one or more blocks of bytes
    that can vary in size up to 100MB. Up to 50,000 blocks can be placed in a single
    blob, and block blobs can grow as needed. This is used for all other types of
    unstructured data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure requires users to place all blobs in a *container*, which is like a file
    directory, except that it can’t be nested. In other words, a container can hold
    blobs, but not other containers. Each storage account can have an unlimited number
    of containers, and each container can have any number of blobs within it.
  prefs: []
  type: TYPE_NORMAL
- en: The script in [Listing 4-2](part0013.html#ch04list2) obtains a list of all blob
    containers at ➍ with the `Get-AzureStorageContainer` cmdlet and then prints a
    table for each container using `Get-AzureStorageBlob`, with one line per blob
    ➎. The table includes the blob’s name, size, data type, and the date it was last
    changed, as shown in [Listing 4-3](part0013.html#ch04list3). Look through this
    list for files that sound useful, ignoring any *.status* files and most logs,
    and focusing instead on documents, source code, and configuration files. Once
    you have a list of interesting files, use one of the Azure Storage management
    tools to begin collecting the files.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00031.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Listing 4-3: Output from blob commands*'
  prefs: []
  type: TYPE_NORMAL
- en: 'To view a blob’s content, Microsoft Azure Storage Explorer is probably the
    best option for a penetration tester. It’s free, properly exposes all types of
    blobs, and supports opening both ASM and ARM storage. Perhaps most importantly,
    it allows access to storage accounts using a variety of sign-in options, including
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Shared Access Signature token
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storage account key in SQL Connection String format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storage account name and key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Username and password of a user with access to the subscription
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The username and password login feature is especially nice because it will populate
    the application with the storage accounts for every subscription the user can
    access. You can also add more than one user account so that you can view files
    for every compromised account simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: With all the storage accounts added to Microsoft Azure Storage Explorer, expand
    the blob storage section under the desired storage accounts; then browse the list
    of containers, select a file of interest, and click the **Download** button to
    pull down a copy, as shown in [Figure 4-11](part0013.html#ch04fig11).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00032.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-11: Downloading blobs from Microsoft Azure Storage Explorer*'
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve retrieved the files, be sure to check them for additional credentials.
    I’ve found a surprising number of secrets stored in Azure Storage. This makes
    it a fantastic place to gain access to additional systems or services, moving
    deeper into the target’s environment.
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFENDER’S TIP**'
  prefs: []
  type: TYPE_NORMAL
- en: Azure Storage blobs aren’t an ideal place to store unencrypted secrets. Because
    of the broad access and repudiation that access keys provide, secrets should be
    kept elsewhere—or at the very least encrypted with a key not kept in a storage
    account. Azure Key Vault, although not completely immune from attack, as I’ll
    discuss in [Chapter 7](part0016.html#ch07), is a far better choice for secret
    storage.
  prefs: []
  type: TYPE_NORMAL
- en: '***Accessing Tables***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Tables provide storage of tabular data in Azure. They are great for keeping
    semi-structured data like web service logs or website content databases, and they
    are good alternatives to a resource-intensive, costlier database solution like
    SQL Server.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 4-2](part0013.html#ch04list2) calls the `Get-AzureStorageTable` cmdlet
    ➏, which will return all the table names in the provided storage context, as shown
    in [Listing 4-4](part0013.html#ch04list4). You can also use the only other cmdlet
    for Azure tables, `Get-AzureStorageTableStoredAccessPolicy`, which displays any
    special permissions for a table. I rarely find access policies in use, so I typically
    skip it. With such limited PowerShell options, you need to use a stand-alone tool
    to access a table’s data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 4-4: Output from* Get-AzureStorageTable *command*'
  prefs: []
  type: TYPE_NORMAL
- en: Selecting the right tool is easy because there aren’t many options. The primary
    ones are Microsoft Azure Storage Explorer and ClumsyLeaf’s TableXplorer. In this
    case, I prefer TableXplorer, even though it’s not freeware, because it’s very
    quick, has options for exporting data, and provides a query option, shown in [Figure
    4-12](part0013.html#ch04fig12), that uses normal SQL syntax. This last feature
    makes identifying data incredibly easy for anyone with a SQL background. Microsoft
    Azure Storage Explorer also has a query capability, but it doesn’t work with SQL
    syntax and is slower than TableXplorer.
  prefs: []
  type: TYPE_NORMAL
- en: In TableXplorer, you might find a number of tables, with names starting with
    `$Metrics`, that don’t appear when using PowerShell. Azure automatically generates
    and uses these tables to store details about the storage account in which they
    reside. The dollar sign (`$`) at the beginning of the name marks them as hidden,
    so PowerShell doesn’t enumerate them.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00033.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-12: Using TableXplorer to query Azure Storage tables with SQL syntax*'
  prefs: []
  type: TYPE_NORMAL
- en: Data in these metrics tables track things like the total number of blobs being
    stored and any transactions that have billing implications, such as the addition
    or removal of data. These files typically have little value to an attacker, unless
    they want to look for log entries that show activity they performed against the
    storage account. Unfortunately, you can’t remove these entries because the metrics
    tables are read-only.
  prefs: []
  type: TYPE_NORMAL
- en: '***Accessing Queues***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Azure Storage queues provide a place to line up transactions and process them
    sequentially as resources become available. Mainly software developers use queues;
    after all, few people other than developers need to worry about processing data
    in order.
  prefs: []
  type: TYPE_NORMAL
- en: 'From a penetration testing perspective, I used to find queues boring. They
    usually sit empty, waiting for a flood of work to come in, and are drained shortly
    thereafter when the tasks are all handled. I changed my opinion, though, when
    I saw the most beautiful, yet horrifying use of queues imaginable: a queue to
    send unsigned commands to a server for execution. Many security researchers will
    spend weeks or even months trying to find vulnerable software and develop *remote
    code execution* exploits—getting a process on a different computer to run code
    under the attacker’s control. Here, it wasn’t a vulnerability but rather an intentional
    feature!'
  prefs: []
  type: TYPE_NORMAL
- en: Although that particular instance is an extreme case, queues actually lend themselves
    to this kind of behavior if a developer isn’t careful. Developers generally use
    them as an input into some custom application, like an order fulfillment system.
    The application’s developer might expect that the queue only contains work items
    from another trusted system they own, such as the order page on their website,
    so the developer neglects to put in proper validation on the work item’s fields.
    That means an attacker can inject their own custom messages into the queue, and
    the service that processes them might not confirm that the data in those messages
    makes sense. If these fields happen to contain the price of items for sale, the
    bank account where payments should be sent, or what system commands the computer
    processing the request should run, then the attacker has found a very high-priority
    bug.
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFENDER’S TIP**'
  prefs: []
  type: TYPE_NORMAL
- en: If you use a queue to transport confidential data or to send commands that must
    come from a verified source, you should use asymmetric cryptography to encrypt
    or sign the messages before they are placed in the queue. Then, the receiver can
    decrypt the message or validate its signature to ensure it is authentic and hasn’t
    been tampered with.
  prefs: []
  type: TYPE_NORMAL
- en: Queues are often used as a backend service that developers typically use to
    facilitate communication between applications, so they have good API support and
    interacting with them is limited without writing custom applications. PowerShell
    only has two relevant cmdlets to display queue information. One is `Get-AzureStorageQueue`,
    which I use in the script in [Listing 4-2](part0013.html#ch04list2) ➐ to enumerate
    the queues and their current message count, as shown in [Listing 4-5](part0013.html#ch04list5).
    The second is `Get-AzureStorageQueueStoredAccessPolicy`, which is used for viewing
    SAS token permissions and restrictions, which are rarely used. Note that there
    are no cmdlets to create or view items in the queue.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 4-5: Output from* Get-AzureStorageQueue *command*'
  prefs: []
  type: TYPE_NORMAL
- en: To actually see and insert messages into a queue, you must, once again, turn
    to Microsoft Azure Storage Explorer. From its interface, select a storage account,
    expand the Queues list below that account, and then select a queue. This will
    open a view that shows all currently queued messages, and it allows you to view
    the contents of a message or insert a new message. I suggest examining any existing
    messages to get a sense of what valid messages look like before trying to insert
    your own. If the queue is empty, try to find the source code for the application
    that processes the messages to see what it’s expecting.
  prefs: []
  type: TYPE_NORMAL
- en: '**WARNING**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Azure queues, like queue data structures in other programming languages, have
    two functions related to viewing a message. You can use* PeekMessage *to view
    the next message in the queue without changing or removing it. On the other hand,*
    GetMessage *actually takes the item from the queue and hides it from any other
    program that’s using the queue. If you’re just using Microsoft Azure Storage Explorer,
    you don’t have to worry about this, but if you develop a custom application to
    snoop on queues, calling* GetMessage *might prevent Azure from processing a legitimate
    request (from the queue). So be sure you fully understand these APIs before using
    them!*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Accessing Files***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The latest addition to Azure Storage’s offerings, called Azure Files, is a cloud-based
    SMB file share service. It allows users to create shared directories and fill
    them with files, just like in an on-premises file server. This is useful for migrating
    legacy applications that depend on SMB shares to Azure. Azure Files allows connections
    from clients that support the SMB 2.1 or SMB 3.0 protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 'While Azure Files is designed to be a drop-in replacement for an existing enterprise
    file server, it does have some limitations. First, any clients connecting to it
    must be able to reach the service on the native SMB port: TCP 445\. This might
    not sound like a big deal, but some corporate networks block TCP 445 traffic in
    both directions, because file shares are normally considered an internal resource.
    However, the biggest difference from a traditional Windows file server is the
    lack of user accounts and permissions.'
  prefs: []
  type: TYPE_NORMAL
- en: On a normal SMB share, a user can assign Read, Change, and Full Control permissions
    to any number of users or groups. Additionally, a user can specify file system–level
    permissions on files within these shares to further restrict access.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure Files is different. By design, its shares have only one user and it isn’t
    configurable. The share’s user is `AZURE\`Name_of_Storage_Account, and the password
    is the primary key for that storage account, once again highlighting the importance
    of protecting storage account keys from unauthorized access. So to get full access
    to an Azure Files share named myshare within a storage account named mysa, you
    would run the following from a Windows command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Connections from remote machines to Azure Files is limited to Windows hosts
    that support SMB 3.0 because Linux, and Windows versions prior to Windows 8, don’t
    support encrypted SMB connections. Linux and older Windows versions can connect
    to Azure Files, but only if they are virtual machines running within Azure and
    are in the same Azure region.*'
  prefs: []
  type: TYPE_NORMAL
- en: To enumerate the shares, use the `Get-AzureStorageShare` cmdlet shown in [Listing
    4-2](part0013.html#ch04list2) at ➑. For each share, you can use the cmdlet `Get-AzureStorageFile`
    to see a list of files within that share. At ➒ in [Listing 4-2](part0013.html#ch04list2),
    I piped the output of `Get-AzureStorageFile` to the format-table command—with
    some rather ugly parameters—to display each file on one line and to include the
    name of the file with its size in bytes. Because the file size is buried in the
    properties of each file object (and is called “Length”), you need to display it
    using PowerShell’s hash table syntax. The `-auto` switch adjusts the column widths
    of the table automatically. The resulting output is shown in [Listing 4-6](part0013.html#ch04list6).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 4-6: Output from file commands*'
  prefs: []
  type: TYPE_NORMAL
- en: Aside from using PowerShell and the built-in SMB connectivity of Windows, you
    can also view Azure Files through Microsoft Azure Storage Explorer (see [Figure
    4-13](part0013.html#ch04fig13)).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/00034.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-13: Accessing Azure Files using Microsoft Azure Storage Explorer*'
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Azure Storage Explorer doesn’t provide any more functionality than
    PowerShell and the Windows SMB client in tandem, but it does get around the TCP
    445 firewall issue by using Azure’s APIs for access instead of connecting directly
    through SMB. It also has a handy button labeled **Connect VM** that will automatically
    create and display the properly formatted `net use` SMB command so you can connect
    to the share using Windows.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this chapter, we discussed some design limitations in the authentication
    design of Azure Storage as well as the different types of credentials an attacker
    can use to access Azure Storage: storage account keys, usernames and passwords,
    and Shared Access Signatures. Next, we examined places where attackers often find
    credentials, such as source code, configuration files, and stored within a number
    of storage management tools. Then, we discussed the different types of storage
    available in Azure, including blobs, tables, queues, and files, and how an attacker
    can access each of them. Using this information, you can retrieve all of the data
    from a target’s storage account, which often includes documents, log files, hard
    disk images, and source code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we’ll take a look at the biggest user of Azure Storage:
    Azure Virtual Machines.'
  prefs: []
  type: TYPE_NORMAL
