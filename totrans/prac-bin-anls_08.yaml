- en: '6'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '6'
- en: DISASSEMBLY AND BINARY ANALYSIS FUNDAMENTALS
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 拆解与二进制分析基础
- en: Now that you know how binaries are structured and are familiar with basic binary
    analysis tools, it’s time to start disassembling some binaries! In this chapter,
    you’ll learn about the advantages and disadvantages of some of the major disassembly
    approaches and tools. I’ll also discuss some more advanced analysis techniques
    to analyze the control- and data-flow properties of disassembled code.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了二进制文件的结构，并且熟悉了基本的二进制分析工具，接下来是时候开始拆解一些二进制文件了！在本章中，你将学习一些主要的拆解方法和工具的优缺点。我还将讨论一些更高级的分析技巧，用于分析拆解代码的控制流和数据流特性。
- en: Note that this chapter is not a guide to reverse engineering; for that, I recommend
    Chris Eagle’s *The IDA Pro Book* (No Starch Press, 2011). The goal is to get familiar
    with the main algorithms behind disassembly and learn what disassemblers can and
    cannot do. This knowledge will help you better understand the more advanced techniques
    discussed in later chapters, as these techniques invariably rely on disassembly
    at their core. Throughout this chapter, I’ll use `objdump` and IDA Pro for most
    of the examples. In some of the examples, I’ll use pseudocode to simplify the
    discussion. [Appendix C](appc.xhtml) contains a list of well-known disassemblers
    you can try if you want to use a disassembler other than IDA Pro or `objdump`.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，本章并不是反向工程的指南；如果你需要反向工程的指导，我推荐 Chris Eagle 的 *《IDA Pro 书籍》*（No Starch Press，2011）。本章的目标是帮助你熟悉拆解背后的主要算法，了解拆解器能够和不能做什么。这些知识将帮助你更好地理解后续章节中讨论的更高级的技术，因为这些技术本质上依赖于拆解作为核心。整个章节中，我将使用
    `objdump` 和 IDA Pro 来进行大部分示例。在一些示例中，我将使用伪代码来简化讨论。[附录 C](appc.xhtml)包含了你可以尝试的其他知名拆解器，如果你想使用除了
    IDA Pro 或 `objdump` 之外的拆解工具。
- en: 6.1 Static Disassembly
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 静态拆解
- en: You can classify all binary analysis as either static analysis, dynamic analysis,
    or a combination of both. When people say “disassembly,” they usually mean *static
    disassembly*, which involves extracting the instructions from a binary without
    executing it. In contrast, *dynamic disassembly*, more commonly known as *execution
    tracing*, logs each executed instruction as the binary runs.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将所有二进制分析分为静态分析、动态分析，或者两者的结合。当人们提到“拆解”时，他们通常指的是 *静态拆解*，它涉及从二进制文件中提取指令，而不需要执行它。与此相对，*动态拆解*，更常见的称呼是
    *执行跟踪*，它在二进制文件运行时记录每个已执行的指令。
- en: 'The goal of every static disassembler is to translate *all* code in a binary
    into a form that a human can read or a machine can process (for further analysis).
    To achieve this goal, static disassemblers need to perform the following steps:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 每个静态拆解器的目标是将二进制文件中的 *所有* 代码转换成一个人类可以阅读或机器可以处理（以便进一步分析）的形式。为了实现这一目标，静态拆解器需要执行以下步骤：
- en: Load a binary for processing, using a binary loader like the one implemented
    in [Chapter 4](ch04.xhtml#ch04).
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用二进制加载器（如[第4章](ch04.xhtml#ch04)中实现的加载器）加载二进制文件进行处理。
- en: Find all the machine instructions in the binary.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到二进制文件中的所有机器指令。
- en: Disassemble these instructions into a human- or machine-readable form.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些指令拆解成人类或机器可读的形式。
- en: 'Unfortunately, step 2 is often very difficult in practice, resulting in disassembly
    errors. There are two major approaches to static disassembly, each of which tries
    to avoid disassembly errors in its own way: *linear disassembly* and *recursive
    disassembly*. Unfortunately, neither approach is perfect in every case. Let’s
    discuss the trade-offs of these two static disassembly techniques. I’ll return
    to dynamic disassembly later in this chapter.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，步骤 2 在实际操作中常常非常困难，导致拆解错误。静态拆解有两种主要方法，每种方法都以不同的方式尝试避免拆解错误：*线性拆解*和*递归拆解*。不幸的是，在每种情况下，这两种方法都不是完美的。我们来讨论一下这两种静态拆解技术的权衡。我将在本章稍后部分回到动态拆解的讨论。
- en: '[Figure 6-1](ch06.xhtml#ch06fig1) illustrates the basic principles of linear
    and recursive disassembly. It also highlights some types of disassembly errors
    that may occur with each approach.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 6-1](ch06.xhtml#ch06fig1)展示了线性和递归拆解的基本原理。它还突出了每种方法可能出现的一些拆解错误类型。'
- en: '![image](Images/f116-01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f116-01.jpg)'
- en: '*Figure 6-1: Linear versus recursive disassembly. Arrows show the disassembly
    flow. Gray blocks show missed or corrupted code.*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6-1：线性拆解与递归拆解。箭头表示拆解流程，灰色块表示丢失或损坏的代码。*'
- en: '*6.1.1 Linear Disassembly*'
  id: totrans-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.1.1 线性拆解*'
- en: Let’s begin with linear disassembly, which is conceptually the simplest approach.
    It iterates through all code segments in a binary, decoding all bytes consecutively
    and parsing them into a list of instructions. Many simple disassemblers, including
    `objdump` from [Chapter 1](ch01.xhtml#ch01), use this approach.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从线性反汇编开始，这种方法在概念上是最简单的。它遍历二进制文件中的所有代码段，按顺序解码所有字节，并将它们解析为指令列表。许多简单的反汇编器，包括[第1章](ch01.xhtml#ch01)中的`objdump`，都采用这种方法。
- en: The risk of using linear disassembly is that not all bytes may be instructions.
    For example, some compilers, such as Visual Studio, intersperse data such as jump
    tables with the code, without leaving any clues as to where exactly that data
    is. If disassemblers accidentally parse this *inline data* as code, they may encounter
    invalid opcodes. Even worse, the data bytes may coincidentally correspond to valid
    opcodes, leading the disassembler to output bogus instructions. This is especially
    likely on dense ISAs like x86, where most byte values represent a valid opcode.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线性反汇编的风险在于，并非所有字节都是指令。例如，一些编译器，如Visual Studio，会将跳转表等数据与代码交织在一起，而没有留下任何关于数据所在位置的提示。如果反汇编器错误地将这些*内联数据*解析为代码，它们可能会遇到无效的操作码。更糟糕的是，这些数据字节可能巧合地对应于有效的操作码，导致反汇编器输出虚假的指令。在像x86这样密集的ISA上，这种情况尤为可能，因为大多数字节值都代表有效的操作码。
- en: In addition, on ISAs with variable-length opcodes, such as x86, inline data
    may even cause the disassembler to become desynchronized with respect to the true
    instruction stream. Though the disassembler will typically self-resynchronize,
    desynchronization can cause the first few real instructions following inline data
    to be missed, as shown in [Figure 6-2](ch06.xhtml#ch06fig2).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于具有可变长度操作码的指令集架构（ISA），例如x86，内联数据甚至可能导致反汇编器与真实指令流不同步。尽管反汇编器通常会自我重新同步，但不同步可能导致内联数据后的前几条真实指令被遗漏，如[图6-2](ch06.xhtml#ch06fig2)所示。
- en: '![image](Images/f117-01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f117-01.jpg)'
- en: '*Figure 6-2: Disassembly desynchronization due to inline data interpreted as
    code. The instruction where the disassembly resynchronizes is shaded gray.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6-2：由于将内联数据误解为代码，导致的反汇编不同步。反汇编重新同步的指令用灰色标示。*'
- en: The figure illustrates *disassembler desynchronization* in part of a binary’s
    code section. You can see a number of inline data bytes (`0x8e 0x20 0x5c 0x00`),
    followed by some instructions (`push rbp`, `mov rbp,rsp`, and so on). The correct
    decoding of all the bytes, as would be found by a perfectly synchronized disassembler,
    is shown on the left of the figure under “synchronized.” But a naive linear disassembler
    instead interprets the inline data as code, thus decoding the bytes as shown under
    “−4 bytes off.” As you can see, the inline data is decoded as a `mov fs,[rax]`
    instruction, followed by a `pop rsp` and an `add [rbp+0x48],dl`. This last instruction
    is especially nasty because it stretches beyond the inline data region and into
    the real instructions! In doing so, the `add` instruction “eats up” some of the
    real instruction bytes, causing the disassembler to miss the first two real instructions
    altogether. The disassembler encounters similar problems if it starts 3 bytes
    too early (“−3 bytes off”), which may happen if the disassembler tries to skip
    the inline data but fails to recognize all of it.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 该图示例展示了二进制代码段中的*反汇编不同步*问题。你可以看到一些内联数据字节（`0x8e 0x20 0x5c 0x00`），后面跟着一些指令（`push
    rbp`、`mov rbp,rsp`等）。正确解码所有字节的结果，假设是通过一个完全同步的反汇编器进行解码，显示在图的左侧，标注为“synchronized”。但是，一个简单的线性反汇编器会将内联数据错误地解释为代码，从而解码出图中显示的“−4
    bytes off”字节。正如你所看到的，内联数据被解码为`mov fs,[rax]`指令，接着是`pop rsp`和`add [rbp+0x48],dl`指令。最后这一条指令尤其恶劣，因为它超出了内联数据区域，进入了实际的指令区！这样，`add`指令“吃掉”了一些真正的指令字节，导致反汇编器完全错过了前两条实际指令。如果反汇编器提早3个字节开始（“−3
    bytes off”），它也会遇到类似的问题，这可能发生在反汇编器尝试跳过内联数据却没能识别出所有内联数据时。
- en: Fortunately, on x86, the disassembled instruction stream tends to automatically
    resynchronize itself after just a few instructions. But missing even a few instructions
    can still be bad news if you’re doing any kind of automated analysis or you want
    to modify the binary based on the disassembled code. As you’ll see in [Chapter
    8](ch08.xhtml#ch08), malicious programs sometimes intentionally contain bytes
    designed to desynchronize disassemblers to hide the program’s true behavior.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，在x86架构上，反汇编后的指令流通常会在几条指令后自动重新同步。但是，如果你进行任何自动化分析，或者基于反汇编的代码修改二进制文件，哪怕遗漏了几条指令也可能是个坏消息。正如你在[第8章](ch08.xhtml#ch08)中看到的，恶意程序有时故意包含一些字节，旨在使反汇编器不同步，从而隐藏程序的真实行为。
- en: In practice, linear disassemblers such as `objdump` are safe to use for disassembling
    ELF binaries compiled with recent versions of compilers such as `gcc` or LLVM’s
    `clang`. The x86 versions of these compilers don’t typically emit inline data.
    On the other hand, Visual Studio *does*, so it’s good to keep an eye out for disassembly
    errors when using `objdump` to look at PE binaries. The same is true when analyzing
    ELF binaries for architectures other than x86, such as ARM. And if you’re analyzing
    malicious code with a linear disassembler, well, all bets are off, as it may include
    obfuscations far worse than inline data!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，像`objdump`这样的线性反汇编器在反汇编使用最近版本编译器（如`gcc`或LLVM的`clang`）编译的ELF二进制文件时是安全的。这些编译器的x86版本通常不会生成内联数据。另一方面，Visual
    Studio *会*生成内联数据，因此在使用`objdump`查看PE二进制文件时，最好留意反汇编错误。在分析其他架构（如ARM）上的ELF二进制文件时也是如此。如果你使用线性反汇编器分析恶意代码，那就完全无法预料了，因为它可能包含比内联数据更复杂的混淆技术！
- en: '*6.1.2 Recursive Disassembly*'
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.1.2 递归反汇编*'
- en: Unlike linear disassembly, recursive disassembly is sensitive to control flow.
    It starts from known entry points into the binary (such as the main entry point
    and exported function symbols) and from there recursively follows control flow
    (such as jumps and calls) to discover code. This allows recursive disassembly
    to work around data bytes in all but a handful of corner cases.^([1](footnote.xhtml#ch06fn_1))
    The downside of this approach is that not all control flow is so easy to follow.
    For instance, it’s often difficult, if not impossible, to statically figure out
    the possible targets of indirect jumps or calls. As a result, the disassembler
    may miss blocks of code (or even entire functions, such as *f*[1] and *f*[2] in
    [Figure 6-1](ch06.xhtml#ch06fig1)) targeted by indirect jumps or calls, unless
    it uses special (compiler-specific and error-prone) heuristics to resolve the
    control flow.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性反汇编不同，递归反汇编对控制流非常敏感。它从已知的二进制入口点（如主入口点和导出函数符号）开始，然后递归地跟踪控制流（如跳转和调用）以发现代码。这使得递归反汇编能够绕过几乎所有数据字节，除了极少数的特殊情况。^([1](footnote.xhtml#ch06fn_1))
    这种方法的缺点是，并非所有的控制流都容易跟踪。例如，静态地判断间接跳转或调用的目标往往是困难的，甚至是不可能的。因此，反汇编器可能会遗漏代码块（甚至整个函数，例如[图6-1](ch06.xhtml#ch06fig1)中的*f*[1]和*f*[2]），这些代码块可能是间接跳转或调用的目标，除非它使用特殊的（特定于编译器且容易出错的）启发式方法来解析控制流。
- en: 'Recursive disassembly is the de facto standard in many reverse-engineering
    applications, such as malware analysis. IDA Pro (shown in [Figure 6-3](ch06.xhtml#ch06fig3))
    is one of the most advanced and widely used recursive disassemblers. Short for
    *Interactive DisAssembler*, IDA Pro is meant to be used interactively and offers
    many features for code visualization, code exploration, scripting (in Python),
    and even decompilation^([2](footnote.xhtml#ch06fn_2)) that aren’t available in
    simple tools like `objdump`. Of course, there’s a price tag to match: at the time
    of writing, licenses for IDA Starter (a simplified edition of IDA Pro) start at
    $739, while full-fledged IDA Professional licenses go for $1,409 and up. But don’t
    worry—you don’t need to buy IDA Pro to use this book. This book focuses not on
    interactive reverse engineering but on creating your own automated binary analysis
    tools based on free frameworks.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 递归反汇编是许多逆向工程应用中的事实标准，例如恶意软件分析。IDA Pro（如[图6-3](ch06.xhtml#ch06fig3)所示）是最先进且广泛使用的递归反汇编工具之一。IDA
    Pro 是 *Interactive DisAssembler*（交互式反汇编器）的缩写，旨在交互使用，并提供许多用于代码可视化、代码探索、脚本编写（使用
    Python）甚至反编译^([2](footnote.xhtml#ch06fn_2))的功能，这些功能在简单的工具如`objdump`中是无法实现的。当然，它的价格也不便宜：在撰写时，IDA
    Starter（IDA Pro的简化版）的许可证起价为$739，而完整的IDA Professional许可证则从$1,409起。但不用担心——你不需要购买IDA
    Pro来使用本书。本书关注的不是交互式逆向工程，而是基于免费的框架创建你自己的自动化二进制分析工具。
- en: '![image](Images/f119-01.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f119-01.jpg)'
- en: '*Figure 6-3: IDA Pro’s graph view*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6-3：IDA Pro 的图形视图*'
- en: '[Figure 6-4](ch06.xhtml#ch06fig4) illustrates some of the challenges that recursive
    disassemblers like IDA Pro face in practice. Specifically, the figure shows how
    a simple function from `opensshd` v7.1p2 is compiled by `gcc` v5.1.1 from C to
    x64 code.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 6-4](ch06.xhtml#ch06fig4)展示了像 IDA Pro 这样的递归反汇编工具在实际应用中面临的一些挑战。具体来说，图中显示了如何将
    `opensshd` v7.1p2 版本的一个简单函数通过 `gcc` v5.1.1 从 C 代码编译成 x64 代码。'
- en: '![image](Images/f120-01.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f120-01.jpg)'
- en: '*Figure 6-4: Example of a disassembled switch statement (from* `opensshd` *v7.1p2
    compiled with* `gcc` *5.1.1 for x64, source edited for brevity). Interesting lines
    are shaded.*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6-4：反汇编后的 switch 语句示例（来自* `opensshd` *v7.1p2，使用* `gcc` *5.1.1 为 x64 编译，源代码经过编辑以简化）。有趣的行被阴影标出。*'
- en: 'As you can see on the left side of the figure, which shows the C representation
    of the function, the function does nothing special. It uses a `for` loop to iterate
    over an array, applying a `switch` statement in each iteration to determine what
    to do with the current array element: skip uninteresting elements, return the
    index of an element that meets some criteria, or print an error and exit if something
    unexpected happens. Despite the simplicity of the C code, the compiled version
    of this function (shown on the right side of the figure) is far from trivial to
    disassemble correctly.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如图左侧所示，展示了该函数的 C 语言表示，函数本身没有做什么特别的事情。它使用一个 `for` 循环遍历数组，在每次迭代中应用一个 `switch`
    语句来确定如何处理当前的数组元素：跳过不感兴趣的元素，返回满足某些条件的元素的索引，或者如果发生了意外错误则打印错误并退出。尽管 C 语言代码很简单，但该函数的编译版本（图右侧所示）要正确反汇编并不简单。
- en: As you can see in [Figure 6-4](ch06.xhtml#ch06fig4), the x64 implementation
    of the switch statement is based on a *jump table*, a construct commonly emitted
    by modern compilers. This jump table implementation avoids the need for a complicated
    tangle of conditional jumps. Instead, the instruction at address `0x4438f9` uses
    the switch input value to compute (in `rax`) an index into a table, which stores
    at that index the address of the appropriate case block. This way, only the single
    indirect jump at address `0x443901` is required to transfer control to any case
    address the jump table defines.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图 6-4](ch06.xhtml#ch06fig4)所示，switch 语句的 x64 实现基于一个 *跳转表*，这是现代编译器常见的构造。该跳转表实现避免了复杂的条件跳转链。相反，位于地址
    `0x4438f9` 的指令利用 switch 输入值计算（存储在 `rax` 寄存器中）一个表的索引，表中存储着对应的 case 块的地址。通过这种方式，只有位于地址
    `0x443901` 的单一间接跳转指令，才能将控制流传递到跳转表定义的任何 case 地址。
- en: While efficient, jump tables make recursive disassembly more difficult because
    they use *indirect control flow*. The lack of an explicit target address in the
    indirect jump makes it difficult for the disassembler to track the flow of instructions
    past this point. As a result, any instructions that the indirect jump may target
    remain undiscovered unless the disassembler implements specific (compiler-dependent)
    heuristics to discover and parse jump tables.^([3](footnote.xhtml#ch06fn_3)) For
    this example, this means a recursive disassembler that doesn’t implement switch-detection
    heuristics won’t discover the instructions at addresses `0x443903`–`0x443925`
    at all.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管跳转表高效，但它们使得递归反汇编变得更加困难，因为它们使用了 *间接控制流*。间接跳转指令中缺乏明确的目标地址，这使得反汇编器很难追踪到指令流的走向。因此，间接跳转可能会指向的任何指令都不会被发现，除非反汇编器实现了特定的（依赖于编译器的）启发式方法来发现和解析跳转表。^([3](footnote.xhtml#ch06fn_3))
    对于这个例子来说，这意味着一个没有实现 switch 检测启发式方法的递归反汇编工具根本无法发现地址 `0x443903`–`0x443925` 之间的指令。
- en: Things get even more complicated because there are multiple `ret` instructions
    in the switch, as well as calls to the `fatal` function, which throws an error
    and never returns. In general, it is not safe to assume that there are instructions
    following a `ret` instruction or nonreturning `call`; instead, these instructions
    may be followed by data or padding bytes not intended to be parsed as code. However,
    the converse assumption that these instructions are *not* followed by more code
    may lead the disassembler to miss instructions, leading to an incomplete disassembly.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 情况变得更加复杂，因为 switch 中有多个 `ret` 指令，并且还调用了 `fatal` 函数，该函数抛出错误并且永远不返回。一般来说，不能假设
    `ret` 指令或非返回的 `call` 后面一定有指令；实际上，这些指令后面可能跟着的是数据或填充字节，而这些内容并不打算被当作代码解析。然而，相反的假设（即这些指令后面没有更多的代码）可能会导致反汇编器遗漏指令，导致反汇编结果不完整。
- en: 'These are just some of the challenges faced by recursive disassemblers; many
    more complex cases exist, especially in more complicated functions than the one
    shown in the example. As you can see, neither linear nor recursive disassembly
    is perfect. For benign x86 ELF binaries, linear disassembly is a good choice because
    it will yield both a complete and accurate disassembly: such binaries typically
    don’t contain inline data that will throw the disassembler off, and the linear
    approach won’t miss code because of unresolved indirect control flow. On the other
    hand, if inline data or malicious code is involved, it’s probably a better idea
    to use a recursive disassembler that’s not as easily fooled into producing bogus
    output as a linear disassembler is.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是递归反汇编器面临的一些挑战；更复杂的情况还很多，特别是在比示例中更复杂的函数中。正如你所看到的，线性反汇编和递归反汇编都不是完美的。对于良性x86
    ELF二进制文件，线性反汇编是一个不错的选择，因为它能够提供既完整又准确的反汇编：这类二进制文件通常不包含会让反汇编器出错的内联数据，并且线性方法不会因为无法解析的间接控制流而漏掉代码。另一方面，如果涉及到内联数据或恶意代码，使用递归反汇编器可能是更好的选择，因为它不容易像线性反汇编器那样产生虚假的输出。
- en: In cases where disassembly correctness is paramount, even at the expense of
    completeness, you can use *dynamic disassembly*. Let’s look at how this approach
    differs from the static disassembly methods just discussed.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要确保反汇编正确性的情况下，即使以牺牲完整性为代价，也可以使用*动态反汇编*。让我们来看一下这种方法与刚才讨论的静态反汇编方法有何不同。
- en: 6.2 Dynamic Disassembly
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 动态反汇编
- en: 'In the previous sections, you saw the challenges that static disassemblers
    face, such as distinguishing data from code, resolving indirect calls, and so
    on. Dynamic analysis solves many of these problems because it has a rich set of
    runtime information at its disposal, such as concrete register and memory contents.
    When execution reaches a particular address, you can be absolutely sure there’s
    an instruction there, so dynamic disassembly doesn’t suffer from the inaccuracy
    problems involved in static disassembly. This allows dynamic disassemblers, also
    known as *execution tracers* or *instruction tracers*, to simply dump instructions
    (and possibly memory/register contents) as the program executes. The main downside
    of this approach is the *code coverage problem*: the fact that dynamic disassemblers
    don’t see all instructions but only those they execute. I’ll get back to the code
    coverage problem later in this section. First, let’s take a look at a concrete
    execution trace.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，你看到了静态反汇编器所面临的挑战，如区分数据和代码、解析间接调用等。动态分析解决了许多这些问题，因为它拥有丰富的运行时信息，例如具体的寄存器和内存内容。当执行到达特定地址时，你可以完全确信那里有一条指令，因此动态反汇编不会遇到静态反汇编中常见的不准确问题。这使得动态反汇编器，也叫做*执行追踪器*或*指令追踪器*，可以在程序执行时直接输出指令（以及可能的内存/寄存器内容）。这种方法的主要缺点是*代码覆盖问题*：即动态反汇编器只能看到它们执行的指令，而不是所有指令。我将在本节后面再讨论代码覆盖问题。首先，让我们来看一个具体的执行追踪示例。
- en: '*6.2.1 Example: Tracing a Binary Execution with gdb*'
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.2.1 示例：使用 gdb 追踪二进制执行*'
- en: Surprisingly enough, there’s no widely accepted standard tool on Linux to do
    “fire-and-forget” execution tracing (unlike on Windows, where excellent tools
    such as OllyDbg are available^([4](footnote.xhtml#ch06fn_4))). The easiest way
    using only standard tools is with a few `gdb` commands, as shown in [Listing 6-1](ch06.xhtml#ch06list1).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，Linux上没有广泛接受的标准工具用于“即刻执行并忘记”追踪（与Windows不同，Windows上有像OllyDbg这样优秀的工具^([4](footnote.xhtml#ch06fn_4))）。使用仅标准工具的最简单方法是通过一些`gdb`命令，如[清单6-1](ch06.xhtml#ch06list1)所示。
- en: '*Listing 6-1: Dynamic disassembly with* gdb'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单6-1：使用* gdb 进行动态反汇编'
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This example loads */bin/ls* into `gdb` and produces a trace of all instructions
    executed when listing the contents of the current directory. After starting `gdb`,
    you can list information on the files loaded into `gdb` (in this case, it’s just
    the executable */bin/ls*) ➊. This tells you the binary’s entry point address ➋
    so that you can set a breakpoint there that will halt execution as soon as the
    binary starts running ➌. You then disable pagination ➍ and configure `gdb` such
    that it logs to file instead of standard output ➎. By default, the log file is
    called *gdb.txt*. Pagination means that `gdb` pauses after outputting a certain
    number of lines, allowing the user to read all the output on the screen before
    moving on. It’s enabled by default. Since you’re logging to file, you don’t want
    these pauses, as you would have to constantly press a key to continue, which gets
    annoying quickly.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 本例将 */bin/ls* 加载到 `gdb` 中，并生成一个跟踪，记录在列出当前目录内容时执行的所有指令。启动 `gdb` 后，你可以列出加载到 `gdb`
    中的文件信息（在本例中，只有可执行文件 */bin/ls*） ➊。这会告诉你该二进制文件的入口点地址 ➋，以便你可以在程序开始运行时设置一个断点来暂停执行
    ➌。接着，你禁用分页 ➍ 并配置 `gdb` 将日志记录到文件中，而不是标准输出 ➎。默认情况下，日志文件名为 *gdb.txt*。分页意味着 `gdb`
    在输出一定行数后会暂停，允许用户在继续之前阅读屏幕上的所有输出，默认情况下启用。由于你正在将日志记录到文件，因此不希望出现这些暂停，否则你会不得不不断按键才能继续，快速变得很烦人。
- en: After setting everything up, you run the binary ➏. It pauses immediately, as
    soon as the entry point is hit. This gives you a chance to tell `gdb` to log this
    first instruction to file ➐ and then enter a `while` loop ➑ that continuously
    executes a single instruction at a time ➒ (this is called *single stepping* )
    until there are no more instructions left to execute. Each single-stepped instruction
    is automatically printed to the log file in the same format as before. Once the
    execution is complete, you get a log file containing all the executed instructions.
    As you might expect, the output is quite lengthy; even a simple run of a small
    program traverses tens or hundreds of thousands of instructions, as shown in [Listing
    6-2](ch06.xhtml#ch06list2).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 设置好一切后，你运行二进制文件 ➏。它会立即暂停，一旦入口点被触及。此时你可以告诉 `gdb` 将这条第一条指令记录到文件中 ➐，然后进入一个 `while`
    循环 ➑，不断执行单条指令 ➒（这称为 *单步执行*），直到没有更多的指令可以执行为止。每一条单步执行的指令都会自动以与之前相同的格式打印到日志文件中。执行完成后，你将得到一个包含所有执行指令的日志文件。正如你所料，输出相当冗长；即使是简单运行一个小程序，也会遍历数十万甚至更多的指令，如
    [清单 6-2](ch06.xhtml#ch06list2) 所示。
- en: '*Listing 6-2: Output of dynamic disassembly with* gdb'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 6-2：使用* gdb *进行动态反汇编后的输出*'
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using `wc` to count the lines in the log file, you can see that the file contains
    614,390 lines, far too many to list here ➊. To give you an idea of what the output
    looks like, you can use `head` to take a look at the first 20 lines in the log
    ➋. The actual execution trace starts at ➌. For each executed instruction, `gdb`
    prints the command used to log the instruction, then the instruction itself, and
    finally some context on the instruction’s location (which is unknown since the
    binary is stripped). Using a `grep`, you can filter out everything but the lines
    showing the executed instructions, since they’re all you’re interested in, yielding
    output as shown in [Listing 6-3](ch06.xhtml#ch06list3).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `wc` 来计算日志文件中的行数，你会发现该文件包含 614,390 行，远远超过这里能列出的数量 ➊。为了给你一个输出的概念，你可以使用 `head`
    查看日志文件的前 20 行 ➋。实际的执行跟踪从 ➌ 开始。对于每条执行的指令，`gdb` 会打印用于记录该指令的命令，然后是指令本身，最后是指令位置的相关信息（由于二进制文件已被剥离，因此位置未知）。使用
    `grep`，你可以过滤掉除显示已执行指令的行外的所有内容，因为它们才是你关心的，从而得到如下所示的输出，详见 [清单 6-3](ch06.xhtml#ch06list3)。
- en: '*Listing 6-3: Filtered output of dynamic disassembly with* gdb'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 6-3：使用* gdb *进行动态反汇编后的过滤输出*'
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As you can see, this is a lot more readable than the unfiltered `gdb` log.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这比未经过滤的 `gdb` 日志要更易读。
- en: '*6.2.2 Code Coverage Strategies*'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.2.2 代码覆盖策略*'
- en: 'The main disadvantage of all dynamic analysis, not just dynamic disassembly,
    is the code coverage problem: the analysis only ever sees the instructions that
    are actually executed during the analysis run. Thus, if any crucial information
    is hidden in other instructions, the analysis will never know about it. For instance,
    if you’re dynamically analyzing a program that contains a logic bomb (for instance,
    triggering malicious behavior at a certain time in the future), you’ll never find
    out until it’s too late. In contrast, a close inspection using static analysis
    might have revealed this. As another example, when dynamically testing software
    for bugs, you’ll never be sure that there isn’t a bug in some rarely executed
    code path that you failed to cover in your tests.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 所有动态分析的主要缺点（不仅仅是动态反汇编）是代码覆盖率问题：分析只会看到分析过程中实际执行的指令。因此，如果任何关键的信息隐藏在其他指令中，分析将永远无法得知。例如，如果你正在动态分析一个包含逻辑炸弹的程序（例如，在未来某个时间触发恶意行为），你永远不会发现，直到为时已晚。相反，通过静态分析的仔细检查可能会揭示这一点。再举一个例子，在动态测试软件时，如果有一个代码路径很少执行，你无法保证自己是否遗漏了在测试中未覆盖的
    bug。
- en: Many malware samples even try to actively hide from dynamic analysis tools or
    debuggers like `gdb`. Virtually all such tools produce some kind of detectable
    artifact in the environment; if nothing else, the analysis inevitably slows down
    execution, typically enough to be detectable. Malware detects these artifacts
    and hides its true behavior if it knows it’s being analyzed. To enable dynamic
    analysis on these samples, you must reverse engineer and then disable the malware’s
    anti-analysis checks (for instance, by overwriting those code bytes with patched
    values). These anti-analysis tricks are the reason why, if possible, it’s usually
    a good idea to at least augment your dynamic malware analysis with static analysis
    methods.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 许多恶意软件样本甚至会主动躲避动态分析工具或调试器，如 `gdb`。几乎所有这类工具都会在环境中产生某种可检测的痕迹；即使没有其他表现，分析过程通常会导致执行速度变慢，通常慢到足以被检测到。恶意软件会检测到这些痕迹，并在知道自己正在被分析时隐藏其真实行为。为了在这些样本上启用动态分析，你必须对恶意软件进行逆向工程，然后禁用其反分析检查（例如，通过用修补后的值覆盖那些代码字节）。这些反分析技巧就是为什么，如果可能的话，通常建议至少用静态分析方法来增强你的动态恶意软件分析的原因。
- en: Because it’s difficult and time-consuming to find the correct inputs to cover
    every possible program path, dynamic disassembly will almost never reveal all
    possible program behavior. There are several methods you can use to improve the
    coverage of dynamic analysis tools, though in general none of them achieves the
    level of completeness provided by static analysis. Let’s take a look at some of
    the methods used most often.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于找到正确的输入以覆盖每一个可能的程序路径是困难且耗时的，动态反汇编几乎永远无法揭示所有可能的程序行为。你可以使用几种方法来提高动态分析工具的覆盖率，尽管通常这些方法都无法达到静态分析所提供的完整性。让我们来看看一些最常用的方法。
- en: Test Suites
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试套件
- en: One of the easiest and most popular methods to increase code coverage is running
    the analyzed binary with known test inputs. Software developers often manually
    develop test suites for their programs, crafting inputs designed to cover as much
    of the program’s functionality as possible. Such test suites are perfect for dynamic
    analysis. To achieve good code coverage, simply run an analysis pass on the program
    with each of the test inputs. Of course, the downside of this approach is that
    a ready-made test suite isn’t always available, for instance, for proprietary
    software or malware.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 提高代码覆盖率最简单且最常见的方法之一是使用已知的测试输入运行被分析的二进制文件。软件开发人员通常会手动为他们的程序开发测试套件，设计输入来覆盖尽可能多的程序功能。这类测试套件非常适合动态分析。为了实现良好的代码覆盖率，只需使用每个测试输入对程序进行分析。当然，这种方法的缺点是，并非总能获得现成的测试套件，例如专有软件或恶意软件就可能没有现成的测试套件。
- en: The exact way to use test suites for code coverage differs per application,
    depending on how the application’s test suite is structured. Typically, there’s
    a special Makefile `test` target, which you can use to run the test suite by entering
    `make test` on the command line. Inside the Makefile, the `test` target is often
    structured something like [Listing 6-4](ch06.xhtml#ch06list4).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用测试套件来实现代码覆盖率的具体方式因应用程序而异，这取决于应用程序的测试套件结构。通常，有一个特殊的 Makefile `test` 目标，你可以通过在命令行输入
    `make test` 来运行测试套件。在 Makefile 内，`test` 目标通常是像[清单 6-4](ch06.xhtml#ch06list4)那样结构化的。
- en: '*Listing 6-4: Structure of a Makefile* test *target*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 6-4：Makefile* 测试 *目标* 结构'
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `PROGRAM` variable contains the name of the application that’s being tested,
    in this case `foo`. The `test` target depends on a number of test cases (`test1`,
    `test2`, and so on), each of which gets called when you run `make test`. Each
    test case consists of running `PROGRAM` on some input, recording the output, and
    then checking it against a correct output using `diff`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`PROGRAM`变量包含正在测试的应用程序的名称，在本例中为`foo`。`test`目标依赖于多个测试用例（`test1`、`test2`等），每个测试用例在你运行`make
    test`时都会被调用。每个测试用例包括在某些输入上运行`PROGRAM`、记录输出，然后使用`diff`与正确输出进行比较。'
- en: 'There are many different (and more concise) ways of implementing this type
    of testing framework, but the key point is that you can run your dynamic analysis
    tool on each of the test cases by simply overriding the `PROGRAM` variable. For
    instance, say you want to run each of `foo`’s test cases with `gdb`. (In reality,
    instead of `gdb`, you’d more likely use a fully automated dynamic analysis, which
    you’ll learn how to build in [Chapter 9](ch09.xhtml#ch09).) You could do this
    as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这种类型的测试框架有许多不同（且更简洁）的方法，但关键点是你可以通过简单地覆盖`PROGRAM`变量，在每个测试用例上运行动态分析工具。例如，假设你想用`gdb`运行每个`foo`的测试用例。（实际上，你可能不会用`gdb`，而是使用完全自动化的动态分析工具，如何构建这种工具你将在[第9章](ch09.xhtml#ch09)中学习。）你可以按照如下方式进行：
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Essentially, this redefines `PROGRAM` so that instead of just running `foo`
    with each test, you now run `foo` *inside* *gdb*. This way, `gdb` or whatever
    dynamic analysis tool you’re using runs `foo` with each of its test cases, allowing
    the dynamic analysis to cover all of `foo`’s code that’s covered by the test cases.
    In cases where there isn’t a `PROGRAM` variable to override, you’ll have to do
    a search and replace, but the idea remains the same.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，这重新定义了`PROGRAM`，使得你不再只是对每个测试运行`foo`，而是将`foo`*在* *gdb*中运行。这样，`gdb`或你正在使用的任何动态分析工具会在每个测试用例上运行`foo`，允许动态分析覆盖所有测试用例所涵盖的`foo`代码。在没有`PROGRAM`变量可供覆盖的情况下，你需要进行搜索和替换，但思想保持不变。
- en: Fuzzing
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模糊测试
- en: There are also tools, called *fuzzers*, that try to automatically generate inputs
    to cover new code paths in a given binary. Well-known fuzzers include AFL, Microsoft’s
    Project Springfield, and Google’s OSS-Fuzz. Broadly speaking, fuzzers fall into
    two categories based on the way they generate inputs.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些被称为*模糊测试器*的工具，它们试图自动生成输入，以覆盖给定二进制文件中的新代码路径。著名的模糊测试器包括AFL、微软的Project Springfield和谷歌的OSS-Fuzz。广义上讲，模糊测试器根据生成输入的方式可分为两类。
- en: 'Generation-based fuzzers: These generate inputs from scratch (possibly with
    knowledge of the expected input format).'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于生成的模糊测试器：这些模糊测试器从头开始生成输入（可能了解预期的输入格式）。
- en: 'Mutation-based fuzzers: These fuzzers generate new inputs by mutating known
    valid inputs in some way, for instance, starting from an existing test suite.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于变异的模糊测试器：这些模糊测试器通过某种方式变异已知的有效输入来生成新的输入，例如，从现有的测试套件开始。
- en: The success and performance of fuzzers depend greatly on the information available
    to the fuzzer. For instance, it helps if source information is available or if
    the program’s expected input format is known. If none of these things is known
    (and even if they all are known), fuzzing can require a lot of compute time and
    may not reach code hidden behind complex sequences of `if`/`else` conditions that
    the fuzzer fails to “guess.” Fuzzers are typically used to search programs for
    bugs, permuting inputs until a crash is detected.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊测试器的成功与性能在很大程度上依赖于可用的信息。例如，如果有源代码信息可用，或者已知程序的预期输入格式，那会非常有帮助。如果这些都不知道（即使知道了），模糊测试可能需要大量的计算时间，且可能无法覆盖被复杂`if`/`else`条件所隐藏的代码路径，而这些条件是模糊测试器无法“猜测”的。模糊测试器通常用于搜索程序中的漏洞，改变输入直到检测到崩溃。
- en: Although I won’t go into details on fuzzing in this book, I encourage you to
    play around with one of the free tools available. Each fuzzer has its own usage
    method. A great choice for experimentation is AFL, which is free and comes with
    good online documentation.^([5](footnote.xhtml#ch06fn_5)) Additionally, in [Chapter
    10](ch10.xhtml#ch10) I’ll discuss how dynamic taint analysis can be used to augment
    fuzzing.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我在本书中不会详细讲解模糊测试，但我鼓励你尝试使用一些免费的工具。每个模糊测试器都有其独特的使用方法。一个很好的实验选择是AFL，它是免费的，并且有很好的在线文档。^([5](footnote.xhtml#ch06fn_5))
    此外，在[第10章](ch10.xhtml#ch10)中，我将讨论如何使用动态污点分析来增强模糊测试。
- en: Symbolic Execution
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 符号执行
- en: Symbolic execution is an advanced technique that I discuss in detail in [Chapters
    12](ch12.xhtml#ch12) and [13](ch13.xhtml#ch13). It’s a broad technique with a
    multitude of applications, not just code coverage. Here, I’ll just give you a
    rough idea of how symbolic execution applies to code coverage, glossing over many
    details, so don’t worry if you can’t follow all of it yet.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 符号执行是一种高级技术，我将在[第12章](ch12.xhtml#ch12)和[第13章](ch13.xhtml#ch13)中详细讨论。这是一项广泛的技术，具有多种应用，而不仅仅是代码覆盖。在这里，我只是大致介绍符号执行如何应用于代码覆盖，省略了许多细节，所以如果你暂时跟不上，也不用担心。
- en: Normally, when you execute an application, you do so using concrete values for
    all variables. At each point in the execution, every CPU register and memory area
    contains some particular value, and these values change over time as the application’s
    computation proceeds. Symbolic execution is different.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当你执行一个应用程序时，你会使用所有变量的具体值。在执行的每个时刻，每个CPU寄存器和内存区域都包含某个特定值，并且这些值会随着应用程序的计算过程而不断变化。而符号执行则不同。
- en: In a nutshell, symbolic execution allows you to execute an application not with
    *concrete values* but with *symbolic values*. You can think of symbolic values
    as mathematical symbols. A symbolic execution is essentially an emulation of a
    program, where all or some of the variables (or register and memory states) are
    represented using such symbols.^([6](footnote.xhtml#ch06fn_6)) To get a clearer
    idea of what this means, consider the pseudocode program shown in [Listing 6-5](ch06.xhtml#ch06list5).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，符号执行允许你用*符号值*而不是*具体值*来执行一个应用程序。你可以将符号值视为数学符号。符号执行本质上是对程序的模拟，其中所有或部分变量（或寄存器和内存状态）都通过这些符号来表示。^([6](footnote.xhtml#ch06fn_6))为了更清楚地理解这意味着什么，请考虑[Listing
    6-5](ch06.xhtml#ch06list5)中显示的伪代码程序。
- en: '*Listing 6-5: Pseudocode example to illustrate symbolic execution*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 6-5：伪代码示例，用于说明符号执行*'
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The program starts by taking two command line arguments, converting them to
    numbers, and storing them in two variables called `x` and `y` ➊. At the start
    of a symbolic execution, you might define the `x` variable to contain the symbolic
    value *α*[1], while `y` may be initialized to *α*[2]. Both *α*[1] and *α*[2] are
    symbols that could represent any possible numerical value. Then, as the emulation
    proceeds, the program essentially computes formulas over these symbols. For instance,
    the operation `z = x + y` causes `z` to assume the symbolic expression *α*[1]
    + *α*[2] ➋.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 程序从接受两个命令行参数开始，将它们转换为数字，并存储在两个变量`x`和`y`中 ➊。在符号执行的开始，你可能会将`x`变量定义为包含符号值*α*[1]，而`y`可能初始化为*α*[2]。*α*[1]和*α*[2]*都是可以表示任何可能数值的符号。然后，随着模拟的进行，程序实际上会计算这些符号的公式。例如，操作`z
    = x + y`使得`z`的符号表达式变为*α*[1] + *α*[2] ➋。
- en: At the same time, the symbolic execution also computes *path constraints*, which
    are just restrictions on the concrete values that the symbols could take, given
    the branches that have been traversed so far. For instance, if the branch `if(x
    < 5)` is taken, the symbolic execution adds a path constraint saying that *α*[1]
    < 5 ➌. This constraint expresses the fact that if the `if` branch is taken, then
    *α*[1] (the symbolic value in `x`) must always be less than 5\. Otherwise, the
    branch wouldn’t have been taken. For each branch, the symbolic execution extends
    the list of path constraints accordingly.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，符号执行还计算了*路径约束*，这只是对符号可能取值的限制，考虑到到目前为止已遍历的分支。例如，如果分支`if(x < 5)`被执行，则符号执行会添加一个路径约束，表示*α*[1]
    < 5 ➌。这个约束表示，如果执行了`if`分支，那么*α*[1]（`x`中的符号值）必须始终小于5，否则该分支就不会被执行。对于每个分支，符号执行会相应地扩展路径约束列表。
- en: How does all this apply to code coverage? The key point is that *given the list
    of path constraints, you can check whether there’s any concrete input that would
    satisfy all these constraints.* There are special programs, called *constraint
    solvers*, that check, given a list of constraints, whether there’s any way to
    satisfy these constraints. For instance, if the only constraint is *α*[1] < 5,
    the solver may yield the solution *α*[1] = 4 ^ *α*[2] = 0\. Note that the path
    constraints don’t say anything about *α*[2], so it can take any value. This means
    that, at the start of a concrete execution of the program, you can (via user input)
    set the value 4 for `x` and the value 0 for `y`, and the execution will then take
    the same series of branches taken in the symbolic execution. If there’s no solution,
    the solver will inform you.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切如何与代码覆盖率相关？关键点是，*给定路径约束列表，你可以检查是否存在任何具体输入能够满足所有这些约束。*有一些特殊的程序，叫做 *约束求解器*，它们可以在给定约束列表的情况下检查是否有办法满足这些约束。例如，如果唯一的约束是
    *α*[1] < 5，求解器可能会给出解 *α*[1] = 4 ^ *α*[2] = 0。请注意，路径约束并未提及 *α*[2]，因此它可以取任何值。这意味着，在程序的具体执行开始时，你可以（通过用户输入）将
    `x` 的值设置为 4，将 `y` 的值设置为 0，然后执行将走在符号执行中走过的相同分支。如果没有解，求解器会通知你。
- en: Now, to increase code coverage, you can change the path constraints and ask
    the solver if there’s any way to satisfy the changed constraints. For instance,
    you could “flip” the constraint *α*[1] < 5 to instead say *α*[1] ≥ *α*[5] and
    ask the solver for a solution. The solver will then inform you of a possible solution,
    such as *α*[1] = 5 ^ *α*[2] = 0, which you can feed as input to a concrete execution
    of the program, thereby forcing that execution to take the `else` branch and thus
    increasing code coverage ➍. If the solver informs you that there’s no possible
    solution, you know that there’s no way to “flip” the branch, and you should continue
    looking for new paths by changing other path constraints.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了增加代码覆盖率，你可以更改路径约束，并询问求解器是否有任何方法满足更改后的约束。例如，你可以将约束 *α*[1] < 5 改为 *α*[1]
    ≥ *α*[5]，并询问求解器是否有解。求解器会告知你一个可能的解，如 *α*[1] = 5 ^ *α*[2] = 0，你可以将这个解作为输入用于程序的具体执行，从而强制该执行走
    `else` 分支，进而增加代码覆盖率 ➍。如果求解器告知你没有可能的解，那就意味着无法“翻转”该分支，你应继续通过更改其他路径约束来寻找新路径。
- en: As you may have gathered from this discussion, symbolic execution (or even just
    its application to code coverage) is a complex subject. Even given the ability
    to “flip” path constraints, it’s still infeasible to cover all program paths since
    the number of possible paths increases exponentially with the number of branch
    instructions in a program. Moreover, solving a set of path constraints is computationally
    intensive; if you don’t take care, your symbolic execution approach can easily
    become unscalable. In practice, it takes a lot of care to apply symbolic execution
    in a scalable and effective way. I’ve only covered the gist of the ideas behind
    symbolic execution so far, but ideally it’s given you a taste of what to expect
    in [Chapters 12](ch12.xhtml#ch12) and [13](ch13.xhtml#ch13).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从前面的讨论中可能已经了解到的，符号执行（甚至仅仅是其在代码覆盖率中的应用）是一个复杂的主题。即便具备了“翻转”路径约束的能力，仍然无法覆盖所有程序路径，因为可能的路径数量随着程序中的分支指令数量的增加而呈指数级增长。此外，求解路径约束集合在计算上是非常密集的；如果不小心，符号执行方法很容易变得不可扩展。实际上，应用符号执行时需要非常小心，以确保其可扩展性和有效性。到目前为止，我仅概述了符号执行背后的核心思想，但理想情况下，它已经让你对[第12章](ch12.xhtml#ch12)和[第13章](ch13.xhtml#ch13)有所了解。
- en: 6.3 Structuring Disassembled Code and Data
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 结构化反汇编代码和数据
- en: So far, I’ve shown you how static and dynamic disassemblers find instructions
    in a binary, but disassembly doesn’t end there. Large unstructured heaps of disassembled
    instructions are nearly impossible to analyze, so most disassemblers structure
    the disassembled code in some way that’s easier to analyze. In this section, I’ll
    discuss the common code and data structures that disassemblers recover and how
    they help binary analysis.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我已经向你展示了静态和动态反汇编器如何在二进制文件中找到指令，但反汇编并不止于此。大量没有结构的反汇编指令几乎无法进行分析，因此大多数反汇编器会以某种方式将反汇编的代码结构化，使其更容易分析。在本节中，我将讨论反汇编器恢复的常见代码和数据结构，以及它们如何帮助二进制分析。
- en: '*6.3.1 Structuring Code*'
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.3.1 结构化代码*'
- en: First, let’s take a look at the various ways of structuring disassembled code.
    Broadly speaking, the code structures I’ll show you make code easier to analyze
    in two ways.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们来看看反汇编代码的各种结构方式。广义上讲，我将展示的代码结构可以通过两种方式让代码分析变得更加容易。
- en: 'Compartmentalizing: By breaking the code into logically connected chunks, it
    becomes easier to analyze what each chunk does and how chunks of code relate to
    each other.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 划分功能区：通过将代码划分为逻辑上连接的块，分析每个块的功能以及代码块之间的关系变得更加容易。
- en: 'Revealing control flow: Some of the code structures I’ll discuss next explicitly
    represent not only the code itself but also the control transfers between blocks
    of code. These structures can be represented visually, making it much easier to
    quickly see how control flows through the code and to get a quick idea of what
    the code does.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示控制流：我接下来要讨论的一些代码结构不仅显式地表示代码本身，还表示代码块之间的控制转移。这些结构可以以可视化的方式呈现，使得更容易快速看出控制如何在代码中流动，并快速了解代码的功能。
- en: The following code structures are useful in both automated and manual analysis.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码结构在自动化和手动分析中都非常有用。
- en: Functions
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 函数
- en: In most high-level programming languages (including C, C++, Java, Python, and
    so on), functions are the fundamental building blocks used to group logically
    connected pieces of code. As any programmer knows, programs that are well structured
    and properly divided into functions are much easier to understand than poorly
    structured programs with “spaghetti code.” For this reason, most disassemblers
    make some effort to recover the original program’s function structure and use
    it to group disassembled instructions by function. This is known as *function
    detection*. Not only does function detection make the code much easier to understand
    for human reverse engineers, but it also helps in automated analysis. For instance,
    in automated binary analysis, you may want to search for bugs at a per-function
    level or modify the code so that a particular security check happens at the start
    and end of each function.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数高级编程语言（包括C、C++、Java、Python等）中，函数是将逻辑上相关的代码块组织在一起的基本构建块。正如任何程序员都知道的那样，结构良好并正确划分为函数的程序，比那些结构不良、充满“意大利面条代码”的程序更容易理解。因此，大多数反汇编工具会尽力恢复原始程序的函数结构，并利用它将反汇编指令按函数分组。这被称为*函数检测*。函数检测不仅使得代码对人工逆向工程师更易于理解，而且对自动化分析也很有帮助。例如，在自动化二进制分析中，你可能希望按函数级别搜索漏洞，或修改代码，使得每个函数的开始和结束处进行特定的安全检查。
- en: For binaries with symbolic information, function detection is trivial; the symbol
    table specifies the set of functions, along with their names, start addresses,
    and sizes. Unfortunately, as you may recall from [Chapter 1](ch01.xhtml#ch01),
    many binaries are stripped of this information, which makes function detection
    far more challenging. Source-level functions have no real meaning at the binary
    level, so their boundaries may become blurred during compilation. The code belonging
    to a particular function might not even be arranged contiguously in the binary.
    Bits and pieces of the function might be scattered throughout the code section,
    and chunks of code may even be shared between functions (known as *overlapping
    code blocks*). In practice, most disassemblers make the assumption that functions
    are contiguous and don’t share code, which holds true in many but not all cases.
    This is especially not true if you’re analyzing things such as firmware or code
    for embedded systems.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于包含符号信息的二进制文件，函数检测非常简单；符号表指定了函数集合，并列出了它们的名称、起始地址和大小。不幸的是，正如你在[第1章](ch01.xhtml#ch01)中可能记得的那样，许多二进制文件会去除这些信息，这使得函数检测变得更加具有挑战性。源代码级别的函数在二进制级别没有实际意义，因此它们的边界在编译过程中可能会变得模糊。属于某个特定函数的代码甚至可能在二进制文件中不按顺序排列。函数的各个部分可能分散在代码区段中，甚至有些代码块可能会在多个函数之间共享（这称为*重叠代码块*）。实际上，大多数反汇编工具假设函数是连续的，并且代码不会共享，这在许多情况下是成立的，但并非所有情况都如此。如果你分析的是固件或嵌入式系统代码，这种假设尤其不成立。
- en: The predominant strategy that disassemblers use for function detection is based
    on *function signatures*, which are patterns of instructions often used at the
    start or end of a function. This strategy is used in all well-known recursive
    disassemblers, including IDA Pro. Linear disassemblers like `objdump` typically
    don’t do function detection, except when symbols are available.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 反汇编器用于函数检测的主要策略是基于*函数签名*，即在函数的开始或结束时常用的指令模式。这一策略在所有知名的递归反汇编器中都有使用，包括IDA Pro。像`objdump`这样的线性反汇编器通常不进行函数检测，除非有符号可用。
- en: Typically, signature-based function detection algorithms start with a pass over
    the disassembled binary to locate functions that are directly addressed by a `call`
    instruction. These cases are easy for the disassembler to find; functions that
    are called only indirectly or tail-called are more of a challenge.^([7](footnote.xhtml#ch06fn_7))
    To locate these challenging cases, signature-based function detectors consult
    a database of known function signatures.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，基于签名的函数检测算法从通过反汇编的二进制文件开始，定位由`call`指令直接调用的函数。这些情况对于反汇编器来说比较容易找到；而仅通过间接调用或尾调用的函数则更具挑战性。^([7](footnote.xhtml#ch06fn_7))
    为了找到这些具有挑战性的情况，基于签名的函数检测器会查询已知函数签名的数据库。
- en: Function signature patterns include well-known *function prologues* (instructions
    used to set up the function’s stack frame) and *function epilogues* (used to tear
    down the stack frame). For instance, a typical pattern that many x86 compilers
    emit for unoptimized functions starts with the prologue `push ebp; mov ebp,esp`
    and ends with the epilogue `leave; ret`. Many function detectors scan the binary
    for such signatures and use them to recognize where functions start and end.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 函数签名模式包括众所周知的*函数序言*（用于设置函数堆栈帧的指令）和*函数尾声*（用于拆除堆栈帧的指令）。例如，许多x86编译器生成的未优化函数的典型模式以序言`push
    ebp; mov ebp,esp`开始，并以尾声`leave; ret`结束。许多函数检测器扫描二进制文件，寻找这样的签名，并用它们来识别函数的起始和结束位置。
- en: Although functions are an essential and useful way to structure disassembled
    code, you should always be wary of errors. In practice, function patterns vary
    depending on the platform, compiler, and optimization level used to create the
    binary. Optimized functions may not have well-known function prologues or epilogues
    at all, making them impossible to recognize using a signature-based approach.
    As a result, errors in function detection occur quite regularly. For example,
    it’s not rare for disassemblers to get 20 percent or more of the function start
    addresses wrong or even to report a function where there is none.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管函数是构建反汇编代码的一个重要且有用的方式，但你应该始终警惕错误。在实践中，函数模式会根据平台、编译器和用来创建二进制文件的优化级别而有所不同。经过优化的函数可能完全没有众所周知的函数序言或尾声，因此无法通过基于签名的方法进行识别。因此，函数检测错误相当常见。例如，反汇编器将函数起始地址错误标记20％或更多，甚至报告一个根本不存在的函数也并不罕见。
- en: Recent research explores different methods for function detection, based not
    on signatures but on the structure of the code.^([8](footnote.xhtml#ch06fn_8))
    While this approach is potentially more accurate than signature-based approaches,
    detection errors are still a fact of life. The approach has been integrated into
    Binary Ninja, and the research prototype tool can interoperate with IDA Pro, so
    you can give it a go if you want.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究探索了不同的函数检测方法，这些方法不依赖于签名，而是基于代码的结构。^([8](footnote.xhtml#ch06fn_8)) 尽管这种方法可能比基于签名的方法更准确，但检测错误依然是不可避免的。这一方法已被集成到Binary
    Ninja中，研究原型工具也可以与IDA Pro互操作，如果你有兴趣，可以尝试一下。
- en: Function Detection Using the .eh_frame Section
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用.eh_frame节进行函数检测
- en: An interesting alternative approach to function detection for ELF binaries is
    based on the `.eh_frame` section, which you can use to circumvent the function
    detection problem entirely. The `.eh_frame` section contains information related
    to DWARF-based debugging features such as stack unwinding. This includes function
    boundary information that identifies all functions in the binary. The information
    is present even in stripped binaries, unless the binary was compiled with `gcc`’s
    `-fno-asynchronous-unwind-tables` flag. It’s used primarily for C++ exception
    handling but also for various other applications such as `backtrace()` and `gcc`
    intrinsics such as `__attribute__((__cleanup__(f)))` and `__builtin_return_address(n)`.
    Because of its many uses, `.eh_frame` is present by default not only in C++ binaries
    that use exception handling but in all binaries produced by `gcc`, including plain
    C binaries.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一种有趣的替代方法是基于`.eh_frame`部分进行函数检测，这可以完全绕过函数检测问题。`.eh_frame`部分包含与基于DWARF的调试功能（如栈展开）相关的信息。这包括标识二进制文件中所有函数的函数边界信息。即使是剥离的二进制文件也会包含这些信息，除非该二进制文件是使用`gcc`的`-fno-asynchronous-unwind-tables`标志编译的。它主要用于C++异常处理，但也用于其他各种应用，如`backtrace()`以及`gcc`的内建函数，如`__attribute__((__cleanup__(f)))`和`__builtin_return_address(n)`。由于它的多种用途，`.eh_frame`默认存在于所有由`gcc`生成的二进制文件中，不仅仅是使用异常处理的C++二进制文件，还包括普通的C二进制文件。
- en: As far as I know, this method was first described by Ryan O’Neill (aka ElfMaster).
    On his website, he provides code to parse the `.eh_frame` section into a set of
    function addresses and sizes.^([a](#ch06foot_a1))
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 据我所知，这种方法最早是由Ryan O’Neill（别名ElfMaster）描述的。在他的网站上，他提供了将`.eh_frame`部分解析为一组函数地址和大小的代码。^([a](#ch06foot_a1))
- en: '[a](#ch06foot-a1). [http://www.bitlackeys.org/projects/eh_frame.tgz](http://www.bitlackeys.org/projects/eh_frame.tgz)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[a](#ch06foot-a1). [http://www.bitlackeys.org/projects/eh_frame.tgz](http://www.bitlackeys.org/projects/eh_frame.tgz)'
- en: Control-Flow Graphs
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 控制流图（CFG）
- en: Breaking the disassembled code into functions is one thing, but some functions
    are quite large, which means analyzing even one function can be a complex task.
    To organize the internals of each function, disassemblers and binary analysis
    frameworks use another code structure, called a *control-flow graph (CFG)*. CFGs
    are useful for automated analysis, as well as manual analysis. They also offer
    a convenient graphical representation of the code structure, which makes it easy
    to get a feel for a function’s structure at a glance. [Figure 6-5](ch06.xhtml#ch06fig5)
    shows an example of the CFG of a function disassembled with IDA Pro.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 将反汇编的代码拆分为函数是一回事，但有些函数相当庞大，这意味着分析一个函数可能是一个复杂的任务。为了组织每个函数的内部结构，反汇编器和二进制分析框架使用另一种代码结构，称为*控制流图（CFG）*。控制流图对于自动化分析以及手动分析都非常有用。它们还提供了一种便捷的图形化表示代码结构的方式，可以让你一眼就能了解函数的结构。[图
    6-5](ch06.xhtml#ch06fig5)展示了一个通过IDA Pro反汇编的函数的CFG示例。
- en: '![image](Images/f132-01.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f132-01.jpg)'
- en: '*Figure 6-5: A CFG as seen in IDA Pro*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6-5：在IDA Pro中看到的CFG*'
- en: As you can see in the figure, CFGs represent the code inside a function as a
    set of code blocks, called *basic blocks*, connected by *branch edges*, shown
    here as arrows. A basic block is a sequence of instructions, where the first instruction
    is the only entry point (the only instruction targeted by any jump in the binary),
    and the last instruction is the only exit point (the only instruction in the sequence
    that may jump to another basic block). In other words, you’ll never see a basic
    block with an arrow connected to any instruction other than the first or last.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，控制流图（CFG）将函数内的代码表示为一组代码块，称为*基本块*，通过*分支边*连接，这里用箭头表示。基本块是一系列指令，其中第一条指令是唯一的入口点（即任何跳转指令所指向的指令），而最后一条指令是唯一的出口点（即该序列中唯一可能跳转到另一个基本块的指令）。换句话说，你永远不会看到一个基本块有箭头连接到第一条或最后一条以外的指令。
- en: An edge in the CFG from a basic block *B* to another basic block *C* means that
    the last instruction in *B* may jump to the start of *C*. If *B* has only one
    outbound edge, that means it will definitely transfer control to the target of
    that edge. For instance, this is what you’ll see for an indirect jump or call
    instruction. On the other hand, if *B* ends in a conditional jump, then it will
    have two outbound edges, and which edge is taken at runtime depends on the outcome
    of the jump condition.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在CFG中，从基本块*B*到另一个基本块*C*的边，表示*B*中的最后一条指令可能跳转到*C*的起始位置。如果*B*只有一条出边，那么这意味着它一定会将控制转移到该边的目标。例如，这就是间接跳转或调用指令的情况。另一方面，如果*B*以条件跳转结束，那么它会有两条出边，运行时选择哪条边取决于跳转条件的结果。
- en: Call edges are not part of a CFG because they target code outside of the function.
    Instead, the CFG shows only the “fallthrough” edge that points to the instruction
    where control will return after the function call completes. There is another
    code structure, called a *call graph*, that is designed to represent the edges
    between call instructions and functions. I’ll discuss call graphs next.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 调用边不属于CFG的一部分，因为它们指向函数外的代码。相反，CFG仅显示指向函数调用完成后控制将返回的指令的“顺序执行”边。还有一种代码结构，称为*调用图*，它专门用于表示调用指令和函数之间的边。我将在接下来的内容中讨论调用图。
- en: In practice, disassemblers often omit indirect edges from the CFG because it’s
    difficult to resolve the potential targets of such edges statically. Disassemblers
    also sometimes define a global CFG rather than per-function CFGs. Such a global
    CFG is called an *interprocedural CFG (ICFG)* since it’s essentially the union
    of all per-function CFGs (*procedure* is another word for function). ICFGs avoid
    the need for error-prone function detection but don’t offer the compartmentalization
    benefits that per-function CFGs have.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，反汇编工具通常会省略CFG中的间接边，因为静态分析时很难解析这些边的潜在目标。反汇编工具有时还会定义一个全局的CFG，而不是每个函数的CFG。这样的全局CFG被称为*过程间CFG（ICFG）*，因为它本质上是所有每个函数的CFG的并集（*过程*是函数的另一种说法）。ICFG避免了易出错的函数检测，但没有每个函数CFG的封装性优势。
- en: Call Graphs
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调用图
- en: '*Call graphs* are similar to CFGs, except they show the relationship between
    call sites and functions rather than basic blocks. In other words, CFGs show you
    how control may flow within a function, while call graphs show you which functions
    may call each other. Just as with CFGs, call graphs often omit indirect call edges
    because it’s infeasible to accurately figure out which functions may be called
    by a given indirect call site.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*调用图*与控制流图（CFG）类似，区别在于它显示的是调用位置和函数之间的关系，而不是基本块之间的关系。换句话说，CFG展示的是函数内部控制流的走向，而调用图则展示哪些函数可能相互调用。与CFG一样，调用图通常会省略间接调用边，因为准确判断某个间接调用位置可能会调用哪些函数是不可行的。'
- en: The left side of [Figure 6-6](ch06.xhtml#ch06fig6) shows a set of functions
    (labeled *f*[1] through *f*[4]) and the call relationships between them. Each
    function consists of some basic blocks (the gray circles) and branch edges (the
    arrows). The corresponding call graph is on the right side of the figure. As you
    can see, the call graph contains a node for each function and has edges showing
    that function *f*[1] can call both *f*[2] and *f*[3], as well as an edge representing
    the call from *f*[3] to *f*[1]. Tail calls, which are really implemented as jump
    instructions, are shown as a regular call in the call graph. However, notice that
    the indirect call from *f*[2] to *f*[4] is *not* shown in the call graph.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-6](ch06.xhtml#ch06fig6)的左侧展示了一组函数（标记为*f*[1]到*f*[4]）及它们之间的调用关系。每个函数由若干个基本块（灰色圆圈）和分支边（箭头）组成。对应的调用图位于图的右侧。如图所示，调用图包含了每个函数的节点，并且有边显示函数*f*[1]可以调用*f*[2]*和*f*[3]*，还有一条表示从*f*[3]到*f*[1]*的调用边。尾调用实际上是作为跳转指令实现的，在调用图中显示为常规调用。然而，请注意，从*f*[2]到*f*[4]*的间接调用在调用图中*没有*显示。'
- en: '![image](Images/f134-01.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f134-01.jpg)'
- en: '*Figure 6-6: CFGs and connections between functions (left) and the corresponding
    call graph (right)*'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6-6：控制流图（左）和函数间连接（右）以及相应的调用图*'
- en: IDA Pro can also display partial call graphs, which show only the potential
    callers of a particular function of your choice. For manual analysis, these are
    often more useful than complete call graphs because complete call graphs often
    contain too much information. [Figure 6-7](ch06.xhtml#ch06fig7) shows an example
    of a partial call graph in IDA Pro that reveals the references to function `sub_404610`.
    As you can see, the graph shows from where the function is called; for instance,
    `sub_404610` is called by `sub_4e1bd0`, which is itself called by `sub_4e2fa0`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: IDA Pro 还可以显示部分调用图，显示你选择的特定函数的潜在调用者。对于手动分析而言，这些通常比完整的调用图更有用，因为完整的调用图通常包含过多的信息。[图
    6-7](ch06.xhtml#ch06fig7) 显示了 IDA Pro 中一个部分调用图的示例，揭示了对函数 `sub_404610` 的引用。正如你所看到的，图中显示了函数的调用位置；例如，`sub_404610`
    被 `sub_4e1bd0` 调用，而 `sub_4e1bd0` 又被 `sub_4e2fa0` 调用。
- en: In addition, the call graphs produced by IDA Pro show instructions that store
    the address of a function somewhere. For instance, at address `0x4e072c` in the
    `.text` section, there’s an instruction that stores the address of function `sub_4e2fa0`
    in memory. This is called “taking the address” of function `sub_4e2fa0`. Functions
    that have their address taken anywhere in the code are called *address-taken functions*.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，IDA Pro 生成的调用图还显示了存储函数地址的指令。例如，在 `.text` 段的地址 `0x4e072c` 处，有一条指令将函数 `sub_4e2fa0`
    的地址存储到内存中。这称为“获取函数” `sub_4e2fa0` 的地址。任何在代码中被引用地址的函数都称为 *地址引用函数*。
- en: It’s nice to know which functions are address-taken because this tells you they
    might be called indirectly, even if you don’t know exactly by which call site.
    If a function’s address is never taken and doesn’t appear in any data sections,
    you know it will never be called indirectly.^([9](footnote.xhtml#ch06fn_9)) That’s
    useful for some kinds of binary analysis or security applications, such as if
    you’re trying to secure the binary by restricting indirect calls to only legal
    targets.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 了解哪些函数的地址被引用是很有用的，因为这表明它们可能会被间接调用，即使你不确切知道是通过哪个调用位置。如果一个函数的地址从未被引用，也没有出现在任何数据段中，你就知道它永远不会被间接调用。^([9](footnote.xhtml#ch06fn_9))
    这对于某些类型的二进制分析或安全应用很有帮助，例如，当你试图通过限制间接调用只允许合法目标来保护二进制文件时。
- en: '![image](Images/f135-01.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f135-01.jpg)'
- en: '*Figure 6-7: A call graph of calls targeting function* `sub_404610`*, as seen
    in IDA Pro*'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6-7：一个调用图，显示了指向函数* `sub_404610`* 的调用，来自 IDA Pro*'
- en: Object-Oriented Code
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面向对象代码
- en: You’ll find that many binary analysis tools, including fully featured disassemblers
    like IDA Pro, are targeted at programs written in *procedural languages* like
    C. Because code is structured mainly through the use of functions in these languages,
    binary analysis tools and disassemblers provide features such as function detection
    to recover programs’ function structure, and they call graphs to examine the relationship
    between functions.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现许多二进制分析工具，包括像 IDA Pro 这样的全功能反汇编器，主要面向用 *过程语言*（如 C）编写的程序。因为这些语言中的代码主要通过使用函数来结构化，二进制分析工具和反汇编器提供了如函数检测等功能，用于恢复程序的函数结构，并通过调用图来检查函数之间的关系。
- en: Object-oriented languages like C++ structure code using *classes* that group
    logically connected functions and data. They typically also offer complex exception-handling
    features that allow any instruction to throw an exception, which is then caught
    by a special block of code that handles the exception. Unfortunately, current
    binary analysis tools lack the ability to recover class hierarchies and exception-handling
    structures.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 面向对象语言，如 C++，通过使用 *类* 来构造代码，这些类将逻辑上相关的函数和数据组织在一起。它们通常还提供复杂的异常处理功能，允许任何指令抛出异常，之后会被一个特殊的代码块捕获并处理。不幸的是，当前的二进制分析工具缺乏恢复类层次结构和异常处理结构的能力。
- en: To make matters worse, C++ programs often contain lots of function pointers
    because of the way virtual methods are typically implemented. *Virtual methods*
    are class methods (functions) that are allowed to be overridden in a derived class.
    In a classic example, you might define a class called `Shape` that has a derived
    class called `Circle`. `Shape` defines a virtual method called `area` that computes
    the area of the shape, and `Circle` overrides that method with its own implementation
    appropriate to circles.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，C++ 程序通常包含大量的函数指针，因为虚拟方法的实现方式。*虚拟方法* 是允许在派生类中重写的类方法（函数）。在一个经典示例中，你可能会定义一个名为
    `Shape` 的类，它有一个名为 `Circle` 的派生类。`Shape` 定义了一个虚拟方法 `area`，用于计算形状的面积，而 `Circle`
    则重写了这个方法，提供适用于圆形的实现。
- en: When compiling a C++ program, the compiler may not know whether a pointer will
    point to a base `Shape` object or a derived `Circle` object at runtime, so it
    cannot statically determine which implementation of the `area` method should be
    used at runtime. To solve this issue, compilers emit tables of function pointers,
    called *vtables*, that contain pointers to all the virtual functions of a particular
    class. Vtables are usually kept in read-only memory, and each polymorphic object
    has a pointer (called a *vptr*) to the vtable for the object’s type. To invoke
    a virtual method, the compiler emits code that follows the object’s vptr at runtime
    and indirectly calls the correct entry in its vtable. Unfortunately, all these
    indirect calls make the program’s control flow even more difficult to follow.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在编译 C++ 程序时，编译器可能不知道指针在运行时会指向一个基类`Shape`对象还是一个派生类`Circle`对象，因此无法静态地确定运行时应该使用哪个`area`方法的实现。为了解决这个问题，编译器会生成一个包含函数指针的表，称为*vtables*，其中包含指向特定类的所有虚函数的指针。Vtables
    通常保存在只读内存中，每个多态对象都有一个指向其类型 vtable 的指针（称为*vptr*）。要调用虚方法，编译器会生成代码，在运行时跟踪对象的 vptr，并间接调用
    vtable 中的正确条目。不幸的是，所有这些间接调用使得程序的控制流更加难以追踪。
- en: 'The lack of support for object-oriented programs in binary analysis tools and
    disassemblers means that if you want to structure your analysis around the class
    hierarchy, you’re on your own. When reverse engineering a C**++** program manually,
    you can often piece together the functions and data structures belonging to different
    classes, but this requires significant effort. I won’t go into details on this
    subject here in order to keep our focus on (semi)automated binary analysis techniques.
    If you’re interested in learning how to manually reverse C++ code, I recommend
    Eldad Eilam’s book *Reversing: Secrets of Reverse Engineering* (Wiley, 2005).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '二进制分析工具和反汇编工具不支持面向对象程序意味着，如果你想围绕类层次结构来组织分析，你就只能依靠自己了。在手动反向工程 C**++** 程序时，你通常可以将属于不同类的函数和数据结构拼凑在一起，但这需要大量的工作。为了保持我们对（半）自动化二进制分析技术的关注，我在这里不会详细讨论这个主题。如果你有兴趣学习如何手动反向工程
    C++ 代码，我推荐 Eldad Eilam 的书《Reversing: Secrets of Reverse Engineering》（Wiley，2005年）。'
- en: In case of automated analysis, you can (as most binary analysis tools do) simply
    pretend classes don’t exist and treat object-oriented programs the same as procedural
    programs. In fact, this “solution” works adequately for many kinds of analysis
    and saves you from the pain of having to implement special C++ support unless
    really necessary.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动化分析的情况下，你可以（就像大多数二进制分析工具一样）简单地假装类不存在，将面向对象程序与过程化程序一样对待。事实上，这种“解决方案”对于许多分析工作来说足够有效，并且可以让你避免实现特殊的
    C++ 支持，除非真的需要。
- en: '*6.3.2 Structuring Data*'
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.3.2 数据结构化*'
- en: As you saw, disassemblers automatically identify various types of code structures
    to help your binary analysis efforts. Unfortunately, the same cannot be said for
    data structures. Automatic data structure detection in stripped binaries is a
    notoriously difficult problem, and aside from some research work,^([10](footnote.xhtml#ch06fn_10))
    disassemblers generally don’t even attempt it.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，反汇编工具可以自动识别各种代码结构，以帮助你进行二进制分析。不幸的是，数据结构就不能这么简单了。在精简的二进制文件中自动检测数据结构是一个公认的难题，除了某些研究工作^([10](footnote.xhtml#ch06fn_10))，反汇编工具通常甚至不尝试处理。
- en: But there are some exceptions. For example, if a reference to a data object
    is passed to a well-known function, such as a library function, disassemblers
    like IDA Pro can automatically infer the data type based on the specification
    of the library function. [Figure 6-8](ch06.xhtml#ch06fig8) shows an example.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 但也有一些例外。例如，如果将数据对象的引用传递给一个著名的函数，如库函数，像 IDA Pro 这样的反汇编工具可以根据库函数的规范自动推断数据类型。[图
    6-8](ch06.xhtml#ch06fig8)展示了一个例子。
- en: Near the bottom of the basic block, there’s a call to the well-known `send`
    function used to send a message over a network. Since IDA Pro knows the parameters
    of the `send` function, it can label the parameter names (`flags`, `len`, `buf`,
    `s`) and infer the data types of the registers and memory objects used to load
    the parameters.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在基本块的底部，调用了著名的`send`函数，用于通过网络发送消息。由于 IDA Pro 知道`send`函数的参数，它可以标记参数名称（`flags`、`len`、`buf`、`s`），并推断出用于加载参数的寄存器和内存对象的数据类型。
- en: Additionally, primitive types can sometimes be inferred by the registers they’re
    kept in or the instructions used to manipulate the data. For instance, if you
    see a floating-point register or instruction being used, you know the data in
    question is a floating-point number. If you see a `lodsb` (*load string byte*)
    or `stosb` (*store string byte*) instruction, it’s likely manipulating a string.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，原始类型有时可以通过它们存储的寄存器或用于操作数据的指令来推断。例如，如果你看到使用浮点寄存器或浮点指令，你就知道相关数据是浮点数。如果你看到`lodsb`（*加载字符串字节*）或`stosb`（*存储字符串字节*）指令，很可能是在操作字符串。
- en: 'For composite types such as `struct` types or arrays, all bets are off, and
    you’ll have to rely on your own analysis. As an example of why automatic identification
    of composite types is hard, take a look at how the following line of C code is
    compiled into machine code:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对于复合类型，如`struct`类型或数组，所有的推测都不再适用，你必须依赖自己的分析。为了说明为什么自动识别复合类型困难，看看以下C代码如何编译成机器码：
- en: '[PRE6]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![image](Images/f137-01.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f137-01.jpg)'
- en: '*Figure 6-8: IDA Pro automatically infers data types based on the use of the*
    `send` *function.*'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6-8：IDA Pro根据使用的*`send`*函数自动推断数据类型。*'
- en: 'This is a line from the `nginx` v1.8.0 source, where an integer field from
    one `struct` is assigned to a field in another `struct`. When compiled with `gcc`
    v5.1 at optimization level `-O2`, this results in the following machine code:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`nginx` v1.8.0源代码中的一行，其中一个`struct`中的整数字段被赋值到另一个`struct`中的字段。当使用`gcc` v5.1并在优化级别`-O2`下编译时，生成以下机器码：
- en: '[PRE7]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now let’s take a look at the following line of C code, which copies an integer
    from a heap-allocated array called `b` into another array `a`:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看以下C代码，它将一个整数从一个名为`b`的堆分配数组复制到另一个数组`a`中：
- en: '[PRE8]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here’s the result of compiling that with `gcc` v5.1, again at optimization
    level `-O2`:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用`gcc` v5.1并在优化级别`-O2`下编译的结果：
- en: '[PRE9]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As you can see, the code pattern is exactly the same as for the `struct` assignment!
    This shows that there’s no way for any automated analysis to tell from a series
    of instructions like this whether they represent an array lookup, a `struct` access,
    or something else entirely. Problems like this make accurate detection of composite
    data types difficult, if not impossible in the general case. Keep in mind that
    this example is quite simple; imagine reversing a program that contains an array
    of `struct` types, or nested `struct`s, and trying to figure out which instructions
    index which data structure! Clearly, that’s a complex task that requires an in-depth
    analysis of the code. Given the complexity of accurately recognizing nontrivial
    data types, you can see why disassemblers make no attempt at automated data structure
    detection.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，代码模式与`struct`赋值完全相同！这表明，没有任何自动化分析方法能够从这样的指令序列中判断它们是表示数组查找、`struct`访问，还是完全不同的操作。像这样的问题使得准确检测复合数据类型变得困难，在一般情况下甚至是不可能的。请记住，这个例子非常简单；想象一下，反向工程一个包含`struct`类型数组或嵌套`struct`的程序，并试图弄清楚哪些指令是对哪个数据结构进行索引！显然，这是一个复杂的任务，需要对代码进行深入分析。鉴于准确识别复杂数据类型的复杂性，你可以理解为什么反汇编工具不会尝试自动检测数据结构。
- en: To facilitate structuring data manually, IDA Pro allows you to define your own
    composite types (which you have to infer by reversing the code) and assign these
    to data items. Chris Eagle’s *The IDA Pro Book* (No Starch Press, 2011) is a great
    resource on manually reversing data structures with IDA Pro.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便手动构造数据，IDA Pro允许你定义自己的复合类型（你必须通过反向工程代码来推断这些类型），并将它们分配给数据项。Chris Eagle的*《IDA
    Pro书》*（No Starch Press, 2011）是一本非常好的手动反向工程数据结构的资源。
- en: '*6.3.3 Decompilation*'
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.3.3 反编译*'
- en: As the name implies, *decompilers* are tools that attempt to “reverse the compilation
    process.” They typically start from disassembled code and translate it into a
    higher-level language, usually a form of C-like pseudocode. Decompilers are useful
    when reversing large programs because decompiled code is easier to read than lots
    of assembly instructions. But decompilers are limited to manual reversing because
    the decompilation process is too error-prone to serve as a reliable basis for
    any automated analysis. Although you won’t use decompilation in this book, let’s
    take a look at [Listing 6-6](ch06.xhtml#ch06list6) to give you an idea of what
    decompiled code looks like.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 正如名称所示，*反编译器*是尝试“逆向编译过程”的工具。它们通常从反汇编代码开始，并将其翻译成更高层次的语言，通常是一种类似 C 的伪代码形式。在逆向大型程序时，反编译器非常有用，因为反编译的代码比大量的汇编指令更易于阅读。但由于反编译过程容易出错，反编译器只能用于手动逆向，无法作为任何自动化分析的可靠基础。尽管在本书中你不会使用反编译，但我们还是来看看[清单
    6-6](ch06.xhtml#ch06list6)，让你对反编译的代码有个大致的了解。
- en: The most widely used decompiler is Hex-Rays, a plugin that ships with IDA Pro.^([11](footnote.xhtml#ch06fn_11))
    [Listing 6-6](ch06.xhtml#ch06list6) shows the Hex-Rays output for the function
    shown earlier in [Figure 6-5](ch06.xhtml#ch06fig5).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最广泛使用的反编译器是 Hex-Rays，它是 IDA Pro 的一个插件。^([11](footnote.xhtml#ch06fn_11)) [清单
    6-6](ch06.xhtml#ch06list6) 显示了 Hex-Rays 输出的函数，展示了前面[图 6-5](ch06.xhtml#ch06fig5)中显示的内容。
- en: '*Listing 6-6: A function decompiled with Hex-Rays*'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 6-6：使用 Hex-Rays 反编译的函数*'
- en: '[PRE10]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As you can see in the listing, the decompiled code is a lot easier to read than
    raw assembly. The decompiler guesses the function’s signature ➊ and local variables
    ➋. Moreover, instead of assembly mnemonics, arithmetic and logical operations
    are expressed more intuitively, using C’s normal operators ➌. The decompiler also
    attempts to reconstruct control-flow constructs, such as `if`/`else` branches
    ➍, loops ➎, and function calls ➏. There’s also a C-style return statement, making
    it easier to see what the end result of the function is ➐.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在清单中看到的，反编译的代码比原始汇编代码更易于阅读。反编译器推测了函数的签名 ➊ 和局部变量 ➋。此外，算术和逻辑运算使用 C 的常规运算符 ➌
    表达，而不是汇编助记符。反编译器还尝试重建控制流结构，例如 `if`/`else` 分支 ➍，循环 ➎ 和函数调用 ➏。还有一个 C 风格的返回语句，使得更容易看到函数的最终结果
    ➐。
- en: Useful as all this is, keep in mind that decompilation is nothing more than
    a tool to help you understand what the program is doing. The decompiled code is
    nowhere close to the original C source, may fail explicitly, and suffers from
    any inaccuracies in the underlying disassembly as well as inaccuracies in the
    decompilation process itself. That’s why it’s generally not a good idea to layer
    more advanced analyses on top of decompilation.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些工具非常有用，但请记住，反编译不过是帮助你理解程序正在做什么的工具。反编译的代码与原始的 C 源代码差距很大，可能会显式地失败，并且会受到底层反汇编和反编译过程本身不准确的影响。这就是为什么通常不建议在反编译的基础上进行更高级的分析。
- en: '*6.3.4 Intermediate Representations*'
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.3.4 中间表示*'
- en: Instruction sets like x86 and ARM contain many different instructions with complex
    semantics. For instance, on x86, even seemingly simple instructions like `add`
    have side effects, such as setting status flags in the `eflags` register. The
    sheer number of instructions and side effects makes it difficult to reason about
    binary programs in an automated way. For example, as you’ll see in [Chapters 10](ch10.xhtml#ch10)
    through [13](ch13.xhtml#ch13), dynamic taint analysis and symbolic execution engines
    must implement explicit handlers that capture the data-flow semantics of all the
    instructions they analyze. Accurately implementing all these handlers is a daunting
    task.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 像 x86 和 ARM 这样的指令集包含了许多具有复杂语义的不同指令。例如，在 x86 上，即使是看似简单的指令，如 `add`，也会产生副作用，例如设置
    `eflags` 寄存器中的状态标志。指令和副作用的数量庞大，使得自动推理二进制程序变得困难。例如，正如你将在[第 10 章](ch10.xhtml#ch10)到[第
    13 章](ch13.xhtml#ch13)中看到的那样，动态污点分析和符号执行引擎必须实现显式的处理程序，以捕捉它们分析的所有指令的数据流语义。准确实现这些处理程序是一个艰巨的任务。
- en: '*Intermediate representations (IR)*, also known as *intermediate languages*,
    are designed to remove this burden. An IR is a simple language that serves as
    an abstraction from low-level machine languages like x86 and ARM. Popular IRs
    include *Reverse Engineering Intermediate Language (REIL)* and *VEX IR* (the IR
    used in the *valgrind* instrumentation framework^([12](footnote.xhtml#ch06fn_12))).
    There’s even a tool called *McSema* that translates binaries into *LLVM bitcode*
    (also known as *LLVM IR*).^([13](footnote.xhtml#ch06fn_13))'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '*中间表示（IR）*，也称为*中间语言*，旨在消除这一负担。IR是一种简单的语言，作为x86和ARM等低级机器语言的抽象。常见的IR包括*逆向工程中间语言（REIL）*和*VEX
    IR*（用于*valgrind*插桩框架的IR^([12](footnote.xhtml#ch06fn_12)))。甚至有一个叫做*McSema*的工具，它将二进制文件转换为*LLVM位代码*（也称为*LLVM
    IR*）。^([13](footnote.xhtml#ch06fn_13))'
- en: The idea of IR languages is to automatically translate real machine code, such
    as x86 code, into an IR that captures all of the machine code’s semantics but
    is much simpler to analyze. For comparison, REIL contains only 17 different instructions,
    as opposed to x86’s hundreds of instructions. Moreover, languages like REIL, VEX
    and LLVM IR explicitly express all operations, with no obscure instruction side
    effects.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: IR语言的概念是自动将实际的机器代码（如x86代码）转换为IR，这个IR捕获了所有机器代码的语义，但更易于分析。作为对比，REIL只有17条不同的指令，而x86有数百条指令。此外，像REIL、VEX和LLVM
    IR这样的语言明确表达所有操作，没有模糊的指令副作用。
- en: It’s still a lot of work to implement the translation step from low-level machine
    code to IR code, but once that work is done, it’s much easier to implement new
    binary analyses on top of the translated code. Instead of having to write instruction-specific
    handlers for every binary analysis, with IRs you only have to do that once to
    implement the translation step. Moreover, you can write translators for many ISAs,
    such as x86, ARM, and MIPS, and map them all onto the same IR. That way, any binary
    analysis tool that works on that IR automatically inherits support for all of
    the ISAs that the IR supports.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 从低级机器代码到IR代码的转换步骤仍然是一个繁重的工作，但一旦完成这项工作，就更容易在转换后的代码上实现新的二进制分析。与其为每个二进制分析编写特定的指令处理程序，使用IR时，你只需进行一次翻译步骤的实现即可。此外，你还可以为多个ISA（如x86、ARM和MIPS）编写翻译器，并将它们全部映射到相同的IR。这样，任何支持该IR的二进制分析工具将自动继承IR支持的所有ISA。
- en: The trade-off of translating a complex instruction set like x86 into a simple
    language like REIL, VEX, or LLVM IR is that IR languages are far less concise.
    That’s an inherent result of expressing complex operations, including all side
    effects, with a limited number of simple instructions. This is generally not an
    issue for automated analyses, but it does tend to make intermediate representations
    hard to read for humans. To give you an idea of what an IR looks like, take a
    look at [Listing 6-7](ch06.xhtml#ch06list7), which shows how the x86-64 instruction
    `add rax,rdx` translates into VEX IR.^([14](footnote.xhtml#ch06fn_14))
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 将像x86这样复杂的指令集转换为像REIL、VEX或LLVM IR这样简单语言的权衡是，IR语言远不如原始指令集简洁。这是因为在用有限数量的简单指令表达复杂操作（包括所有副作用）时，必然的结果。这通常对于自动化分析没有问题，但却往往使得中间表示对于人类来说难以阅读。为了让你了解IR是什么样子的，可以看看[Listing
    6-7](ch06.xhtml#ch06list7)，它展示了x86-64指令`add rax,rdx`如何转换为VEX IR。^([14](footnote.xhtml#ch06fn_14))
- en: '*Listing 6-7: Translation of the x86-64 instruction* add rax,rdx *into VEX
    IR*'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 6-7: 将x86-64指令* add rax,rdx *转换为VEX IR*'
- en: '[PRE11]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see, the single `add` instruction results in 10 VEX instructions,
    plus some metadata. First, there’s some metadata that says this is an *IR super
    block (IRSB)* ➊ corresponding to one machine instruction. The IRSB contains four
    temporary values labeled `t0`–`t3`, all of type `Ity_I64` (64-bit integer) ➋.
    Then there’s an *IMark* ➌, which is metadata stating the machine instruction’s
    address and length, among other things.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，单个`add`指令会生成10个VEX指令，以及一些元数据。首先，有一些元数据说明这是一个*IR超级块（IRSB）* ➊，对应于一个机器指令。IRSB包含四个临时值，分别标记为`t0`–`t3`，类型为`Ity_I64`（64位整数）
    ➋。接下来是一个*IMark* ➌，它是元数据，指出了机器指令的地址和长度等信息。
- en: Next come the actual IR instructions modeling the `add`. First, there are two
    `GET` instructions that fetch 64-bit values from `rax` and `rdx` into temporary
    stores `t2` and `t1`, respectively ➍. Note that, here, `rax` and `rdx` are just
    symbolic names for the parts of VEX’s state used to model these registers—the
    VEX instructions don’t fetch from the real `rax` or `rdx` registers but rather
    from VEX’s mirror state of those registers. To perform the actual addition, the
    IR uses VEX’s `Add64` instruction, adding the two 64-bit integers `t2` and `t1`
    and storing the result in `t0` ➎.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是实际的IR指令，用于建模`add`。首先，有两条`GET`指令，它们分别将64位值从`rax`和`rdx`取出并存储到临时寄存器`t2`和`t1`中
    ➍。请注意，`rax`和`rdx`只是VEX状态中用于建模这些寄存器的符号名称——VEX指令并不会从真实的`rax`或`rdx`寄存器中获取数据，而是从VEX的镜像状态中获取这些寄存器的数据。为了执行实际的加法，IR使用VEX的`Add64`指令，将两个64位整数`t2`和`t1`相加，并将结果存储到`t0`中
    ➎。
- en: After the addition, there are some `PUT` instructions that model the `add` instruction’s
    side effects, such as updating the x86 status flags ➏. Then, another `PUT` stores
    the result of the addition into VEX’s state representing `rax` ➐. Finally, the
    VEX IR models updating the program counter to the next instruction ➑. The `Ijk_Boring`
    (*Jump Kind Boring* ) ➒ is a control-flow hint that says the `add` instruction
    doesn’t affect the control flow in any interesting way; since the `add` isn’t
    a branch of any kind, control just “falls through” to the next instruction in
    memory. In contrast, branch instructions can be marked with hints like `Ijk_Call`
    or `Ijk_Ret` to inform the analysis that a call or return is taking place, for
    example.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在加法操作之后，有一些`PUT`指令，用来建模`add`指令的副作用，例如更新x86状态标志 ➏。然后，另一条`PUT`指令将加法结果存储到VEX的状态中，表示`rax`
    ➐。最后，VEX IR建模了将程序计数器更新到下一个指令 ➑。`Ijk_Boring`（*Jump Kind Boring*） ➒ 是一个控制流提示，表示`add`指令不会以任何有趣的方式影响控制流；由于`add`不是任何形式的跳转指令，控制只是“自然”地流向内存中的下一条指令。相反，分支指令可以使用像`Ijk_Call`或`Ijk_Ret`这样的提示来通知分析发生了调用或返回。
- en: When implementing tools on top of an existing binary analysis framework, you
    typically won’t have to deal with IR. The framework will handle all IR-related
    stuff internally. However, it’s useful to know about IRs if you ever plan to implement
    your own binary analysis framework or modify an existing one.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在现有的二进制分析框架上实现工具时，通常不需要处理中间表示（IR）。框架会在内部处理所有与IR相关的事务。然而，如果你计划实现自己的二进制分析框架或修改现有框架，了解IR还是很有用的。
- en: 6.4 Fundamental Analysis Methods
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 基本分析方法
- en: The disassembly techniques you’ve learned so far in this chapter are the foundation
    of binary analysis. Many of the advanced techniques discussed in later chapters,
    such as binary instrumentation and symbolic execution, are based on these basic
    disassembly methods. But before moving on to those techniques, there are a few
    “standard” analyses I’d like to cover because they’re widely applicable. Note
    that these aren’t stand-alone binary analysis techniques, but you can use them
    as ingredients of more advanced binary analyses. Unless I note otherwise, these
    are all normally implemented as static analyses, though you can also modify them
    to work for dynamic execution traces.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你在本章中学习的反汇编技术是二进制分析的基础。许多后续章节中讨论的高级技术，如二进制插桩和符号执行，都基于这些基本的反汇编方法。但在继续讨论这些技术之前，还有一些“标准”分析方法我想要介绍，因为它们具有广泛的应用性。请注意，这些方法并不是独立的二进制分析技术，但你可以将它们作为更高级二进制分析的组成部分来使用。除非另有说明，这些通常作为静态分析来实现，尽管你也可以修改它们以适应动态执行轨迹。
- en: '*6.4.1 Binary Analysis Properties*'
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.4.1 二进制分析属性*'
- en: First, let’s go over some of the different properties that any binary analysis
    approach can have. This will help to classify the different techniques I’ll cover
    here and in later chapters and help you understand their trade-offs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们回顾一下任何二进制分析方法可能具备的不同属性。这将有助于分类我将在这里以及后续章节中介绍的不同技术，并帮助你理解它们的权衡。
- en: Interprocedural and Intraprocedural Analysis
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跨过程和过程内分析
- en: 'Recall that functions are one of the fundamental code structures that disassemblers
    attempt to recover because it’s more intuitive to analyze code at the function
    level. Another reason for using functions is scalability: some analyses are simply
    infeasible when applied to a complete program.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，函数是反汇编器尝试恢复的基本代码结构之一，因为在函数级别分析代码更加直观。使用函数的另一个原因是可扩展性：当应用于完整程序时，某些分析是不可行的。
- en: The number of possible paths through a program increases exponentially with
    the number of control transfers (such as jumps and calls) in the program. In a
    program with just 10 `if`/`else` branches, there are up to 2^(10) = 1,024 possible
    paths through the code. In a program with a hundred such branches, there are up
    to 1.27 × 10^(30) possible paths, and a thousand branches yield up to 1.07 × 10^(301)
    paths! Many programs have far more branches than that, so it’s not computationally
    feasible to analyze every possible path through a nontrivial program.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 程序中可能的路径数会随着控制转移（如跳转和调用）的数量呈指数增长。在一个仅有10个`if`/`else`分支的程序中，最多有2^(10) = 1,024条可能的路径。如果程序有一百个这样的分支，最多有1.27
    × 10^(30)条可能路径，而一千个分支则最多有1.07 × 10^(301)条路径！许多程序的分支数远超过这个数量，因此在非平凡的程序中分析每一条可能的路径在计算上是不可行的。
- en: 'That’s why computationally expensive binary analyses are often *intraprocedural*:
    they consider the code only within a single function at a time. Typically, an
    intraprocedural analysis will analyze the CFG of each function in turn. This is
    in contrast to *interprocedural* analysis, which considers an entire program as
    a whole, typically by linking all the function CFGs together via the call graph.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么计算量大的二进制分析通常是*内程序*的原因：它们只考虑每次一个函数内部的代码。通常，内程序分析会依次分析每个函数的控制流图（CFG）。这与*跨程序*分析形成对比，后者会将整个程序作为一个整体来考虑，通常通过调用图将所有函数的控制流图连接在一起。
- en: Because most functions contain only a few dozen control transfer instructions,
    complex analyses are computationally feasible at the function level. If you individually
    analyze 10 functions with 1,024 possible paths each, you analyze a total of 10
    × 1,024 = 10,240 paths; that’s a lot better than the 1,024^(10) ≈ 1.27 × 10^(30)
    paths you’d have to analyze if you considered the whole program at once.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 因为大多数函数只包含几十条控制转移指令，所以在函数级别进行复杂分析是计算上可行的。如果你单独分析10个函数，每个函数有1,024条可能的路径，你将分析总共10
    × 1,024 = 10,240条路径；这比考虑整个程序时必须分析的1,024^(10) ≈ 1.27 × 10^(30)条路径要好得多。
- en: The downside of intraprocedural analysis is that it’s not complete. For instance,
    if your program contains a bug that’s triggered only after a very specific combination
    of function calls, an intraprocedural bug detection tool won’t find the bug. It
    will simply consider each function on its own and conclude there’s nothing wrong.
    In contrast, an interprocedural tool would find the bug but might take so long
    to do so that the results won’t matter anymore.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 内程序分析的缺点是它并不完整。例如，如果你的程序包含一个只有在非常特定的函数调用组合下才会触发的bug，内程序bug检测工具就无法找到该bug。它只会独立地考虑每个函数，并得出没有问题的结论。相比之下，跨程序工具能够找到这个bug，但可能需要花费太长时间，导致结果已不再有意义。
- en: As another example, let’s consider how a compiler might decide to optimize the
    code shown in [Listing 6-8](ch06.xhtml#ch06list8), depending on whether it’s using
    intraprocedural or interprocedural optimization.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是，考虑编译器如何决定优化[清单 6-8](ch06.xhtml#ch06list8)中显示的代码，具体取决于它是使用内程序优化还是跨程序优化。
- en: '*Listing 6-8: A program containing a dead function*'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 6-8：包含死代码的程序*'
- en: '[PRE12]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this example, there’s a function called `dead` that takes a single integer
    parameter `x` and returns nothing ➊. Inside the function, there is a branch that
    will print a message only if `x` is equal to 5 ➋. As it happens, `dead` is invoked
    from only one location, with the constant value 4 as its argument ➌. Thus, the
    branch at ➋ is never taken, and no message is ever printed.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，有一个名为`dead`的函数，它接受一个整数参数`x`并不返回任何值➊。在函数内部，有一个分支，只有在`x`等于5时才会打印一条信息➋。实际上，`dead`只在一个位置被调用，并且其参数是常量值4➌。因此，➋处的分支永远不会被执行，也不会打印任何信息。
- en: Compilers use an optimization called *dead code elimination* to find instances
    of code that can never be reached in practice so that they can omit such useless
    code in the compiled binary. In this case, though, a purely intraprocedural dead
    code elimination pass would fail to eliminate the useless branch at ➋. This is
    because when the pass is optimizing `dead`, it doesn’t know about any of the code
    in other functions, so it doesn’t know where and how `dead` is invoked. Similarly,
    when it’s optimizing `main`, it cannot look inside `dead` to notice that the specific
    argument passed to `dead` at ➌ results in `dead` doing nothing.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器使用一种优化技术，叫做*死代码消除*，来找出在实际运行中永远无法到达的代码实例，以便它们可以在编译后的二进制文件中省略这些无用的代码。然而，在这种情况下，纯粹的过程内死代码消除会失败，无法消除➋处的无用分支。这是因为当进行`dead`的优化时，它并不知道其他函数中的任何代码，因此不知道`dead`是如何以及在何处被调用的。同样，在优化`main`时，它也无法深入`dead`函数，注意到在➌处传递给`dead`的特定参数导致`dead`什么也不做。
- en: It takes an interprocedural analysis to conclude that `dead` is only ever called
    from `main` with the value 4 and that this means the branch at ➋ will never be
    taken. Thus, an intraprocedural dead code elimination pass will output the entire
    `dead` function (and its invocations) in the compiled binary, even though it serves
    no purpose, while an interprocedural pass will omit the entire useless function.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 需要进行跨过程分析，才能得出结论：`dead`仅在`main`中被调用，且传入的值为4，这意味着➋处的分支永远不会被执行。因此，过程内死代码消除将会在编译后的二进制文件中输出整个`dead`函数（及其调用），尽管它没有任何用途，而跨过程分析则会省略整个无用的函数。
- en: Flow-Sensitivity
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流敏感性
- en: A binary analysis can be either *flow-sensitive* or *flow-insensitive*.^([15](footnote.xhtml#ch06fn_15))
    Flow-sensitivity means that the analysis takes the order of the instructions into
    account. To make this clearer, take a look at the following example in pseudocode.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制分析可以是*流敏感*或*流不敏感*的。^([15](footnote.xhtml#ch06fn_15)) 流敏感性意味着分析会考虑指令的执行顺序。为了更清楚地说明这一点，看看下面这个伪代码的示例。
- en: '[PRE13]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The code takes an unsigned integer from user input and then performs some computation
    on it. For this example, let’s assume you’re interested in doing an analysis that
    tries to determine the potential values each variable can assume; this is called
    *value set analysis*. A flow-insensitive version of this analysis would simply
    determine that `x` may contain any value since it gets its value from user input.
    While it’s true in general that `x` could take on any value at some point in the
    program, this isn’t true for *all* points in the program. So, the information
    provided by the flow-insensitive analysis is not very precise, but the analysis
    is relatively cheap in terms of computational complexity.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码从用户输入中获取一个无符号整数，然后对其进行一些计算。假设你对进行一种分析感兴趣，旨在确定每个变量可能的值，这被称为*值集分析*。该分析的无流分析版本会简单地确定`x`可能包含任何值，因为它的值来自用户输入。虽然从程序的角度来看，`x`在某些时刻可能取任何值，但并不是程序中的*所有*点都如此。因此，无流分析提供的信息并不是非常精确，但从计算复杂度的角度来看，该分析相对便宜。
- en: 'A flow-sensitive version of the analysis would yield more precise results.
    In contrast to the flow-insensitive variant, it provides an estimate of `x`’s
    possible value set *at each point in the program*, taking into account the previous
    instructions. At ➊, the analysis concludes that `x` can have any unsigned value
    since it’s taken from user input and there haven’t yet been any instructions to
    constrain the value of `x`. However, at ➋, you can refine the estimate: since
    the value 5 is added to `x`, you know that from this point on, `x` can only have
    a value of at least 5\. Similarly, after the instruction at ➌, you know that `x`
    is at least equal to 15.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 流敏感版本的分析会提供更精确的结果。与无流版本相比，它提供了在程序中*每个点*的`x`可能值集的估计，同时考虑到之前的指令。在➊处，分析得出结论，`x`可以是任何无符号值，因为它是从用户输入中获取的，而且此时还没有任何指令来限制`x`的值。然而，在➋处，你可以细化这个估计：由于`x`增加了5，你知道从此时开始，`x`的值至少是5。同样，在➌处的指令之后，你知道`x`的值至少是15。
- en: Of course, things aren’t quite so simple in real life, where you must deal with
    more complex constructs such as branches, loops, and (recursive) function calls
    instead of simple straight-line code. As a result, flow-sensitive analyses tend
    to be much more complex and also more computationally intensive than flow-insensitive
    analyses.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，现实生活中情况并不像那么简单，你必须处理更复杂的结构，例如分支、循环和（递归）函数调用，而不是简单的直线代码。因此，流敏感分析往往比流不敏感分析更加复杂，并且计算开销更大。
- en: Context-Sensitivity
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 上下文敏感性
- en: While flow-sensitivity considers the order of instructions, *context-sensitivity*
    takes the order of function invocations into account. Context-sensitivity is meaningful
    only for interprocedural analyses. A *context-insensitive* interprocedural analysis
    computes a single, global result. On the other hand, a *context-sensitive* analysis
    computes a separate result for each possible path through the call graph (in other
    words, for each possible order in which functions may appear on the call stack).
    Note that this implies that the accuracy of a context-sensitive analysis is bounded
    by the accuracy of the call graph. The *context* of the analysis is the state
    accrued while traversing the call graph. I’ll represent this state as a list of
    previously traversed functions, denoted as < *f*[1], *f*[2], . . . , *f*[n] >.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 流敏感分析考虑的是指令的顺序，*上下文敏感性*则考虑函数调用的顺序。上下文敏感性仅对跨过程分析有意义。*上下文不敏感*的跨过程分析会计算一个全局的结果。另一方面，*上下文敏感*的分析会针对通过调用图的每一条可能路径（换句话说，针对函数可能出现在调用栈中的每一种顺序）计算一个单独的结果。请注意，这意味着上下文敏感分析的准确性受限于调用图的准确性。分析的*上下文*是遍历调用图时积累的状态。我将把这个状态表示为一个之前遍历过的函数列表，记作
    < *f*[1], *f*[2], . . . , *f*[n] >。
- en: In practice, the context is usually limited, because very large contexts make
    flow-sensitive analysis too computationally expensive. For instance, the analysis
    may only compute results for contexts of five (or any arbitrary number of) consecutive
    functions, instead of for complete paths of indefinite length. As an example of
    the benefits of context-sensitive analysis, take a look at [Figure 6-9](ch06.xhtml#ch06fig9).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，分析的上下文通常是有限制的，因为非常大的上下文会使得流敏感分析变得计算量过大。例如，分析可能只计算连续五个（或任何任意数量的）函数的上下文结果，而不是计算任意长度路径的完整结果。作为上下文敏感分析优势的一个例子，请看[图
    6-9](ch06.xhtml#ch06fig9)。
- en: '![image](Images/f145-01.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f145-01.jpg)'
- en: '*Figure 6-9: Context-sensitive versus context-insensitive indirect call analysis
    in* `opensshd`'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6-9：`opensshd`中上下文敏感与上下文不敏感的间接调用分析*'
- en: 'The figure shows how context-sensitivity affects the outcome of an indirect
    call analysis in `opensshd` v3.5\. The goal of the analysis is to figure out the
    possible targets of an indirect call site in the `channel_handler` function (the
    line that reads `(*ftab[c->type])(c, readset, writeset);`). The indirect call
    site takes its target from a table of function pointers, which is passed in as
    an argument called `ftab` to `channel_handler`. The `channel_handler` function
    is called from two other functions: `channel_prepare_select` and `channel_after_select`.
    Each of these passes its own function pointer table as the `ftab` argument.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 该图展示了上下文敏感性如何影响`opensshd` v3.5中间接调用分析的结果。分析的目标是找出`channel_handler`函数中间接调用位置的可能目标（即执行`(*ftab[c->type])(c,
    readset, writeset);`的那一行）。间接调用位置从一个函数指针表中获取其目标，这个表作为参数`ftab`传递给`channel_handler`。`channel_handler`函数由两个其他函数调用：`channel_prepare_select`和`channel_after_select`。这两个函数各自将自己的函数指针表作为`ftab`参数传递。
- en: A context-insensitive indirect call analysis concludes that the indirect call
    in `channel_handler` could target any function pointer in either the `channel_pre`
    table (passed in from `channel_prepare_select`) or the `channel_post` table (passed
    in from `channel_after_select`). Effectively, it concludes that the set of possible
    targets is the union of all the possible sets in any path through the program
    ➊.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有上下文敏感分析的情况下，间接调用分析得出的结论是`channel_handler`中的间接调用可能指向`channel_pre`表中的任何函数指针（从`channel_prepare_select`传入）或`channel_post`表中的任何函数指针（从`channel_after_select`传入）。实际上，它得出结论，所有可能的目标集合是程序中任何路径上所有可能集合的并集
    ➊。
- en: In contrast, the context-sensitive analysis determines a different target set
    for each possible context of preceding calls. If `channel_handler` was invoked
    by `channel_prepare_select`, then the only valid targets are those in the `channel_pre`
    table that it passes to `channel_handler` ➋. On the other hand, if `channel_handler`
    was called from `channel_after_select`, then only the targets in `channel_post`
    are possible ➌. In this example, I’ve discussed only a context of length 1, but
    in general the context could be arbitrarily long (as long as the longest possible
    path through the call graph).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，上下文敏感分析为每个可能的前置调用上下文确定一个不同的目标集合。如果`channel_handler`是由`channel_prepare_select`调用的，那么只有在它传递给`channel_handler`的`channel_pre`表中的目标才是有效的➋。另一方面，如果`channel_handler`是从`channel_after_select`调用的，那么只有`channel_post`中的目标是可能的➌。在这个例子中，我只讨论了长度为1的上下文，但一般来说，上下文可以是任意长的（只要是通过调用图的最长路径）。
- en: As with flow-sensitivity, the upside of context-sensitivity is increased precision,
    while the downside is the greater computational complexity. In addition, context-sensitive
    analyses must deal with the large amount of state that must be kept to track all
    the different contexts. Moreover, if there are any recursive functions, the number
    of possible contexts is infinite, so special measures are needed to deal with
    these cases.^([16](footnote.xhtml#ch06fn_16)) Often, it may not be feasible to
    create a scalable context-sensitive version of an analysis without resorting to
    cost and benefit trade-offs such as limiting the context size.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 与流敏感性类似，上下文敏感性的优点是提高了精度，而缺点则是更高的计算复杂性。此外，上下文敏感分析必须处理大量的状态信息，用以追踪所有不同的上下文。而且，如果存在递归函数，可能的上下文数量是无限的，因此需要采取特别措施来处理这些情况^([16](footnote.xhtml#ch06fn_16))。通常，若不通过诸如限制上下文大小等成本与收益的权衡，创建一个可扩展的上下文敏感分析版本可能是不可行的。
- en: '*6.4.2 Control-Flow Analysis*'
  id: totrans-192
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.4.2 控制流分析*'
- en: The purpose of any binary analysis is to figure out information about a program’s
    control-flow properties, its data-flow properties, or both. A binary analysis
    that looks at control-flow properties is aptly called a *control-flow analysis*,
    while a data flow–oriented analysis is called a *data-flow analysis*. The distinction
    is based purely on whether the analysis focuses on control or data flow; it doesn’t
    say anything about whether the analysis is intraprocedural or interprocedural,
    flow-sensitive or insensitive, or context-sensitive or insensitive. Let’s start
    by looking at a common type of control-flow analysis, called *loop detection*.
    In the next section, you’ll see some common data-flow analyses.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 任何二进制分析的目的是找出程序的控制流属性、数据流属性或两者。专注于控制流属性的二进制分析被称为*控制流分析*，而专注于数据流的分析被称为*数据流分析*。这种区分仅仅是基于分析是否专注于控制流或数据流；它并没有说明分析是过程内分析还是跨过程分析，是流敏感还是流不敏感，或者是上下文敏感还是上下文不敏感。让我们先来看一种常见的控制流分析类型，叫做*循环检测*。在下一节中，你将看到一些常见的数据流分析。
- en: Loop Detection
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 循环检测
- en: As the name implies, the purpose of loop detection is to find loops in the code.
    At the source level, keywords like `while` or `for` give you an easy way to spot
    loops. At the binary level, it’s a little harder, because loops are implemented
    using the same (conditional or unconditional) jump instructions used to implement
    `if`/`else` branches and switches.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，循环检测的目的是在代码中查找循环。在源代码级别，像`while`或`for`这样的关键字可以轻松地帮助你找到循环。在二进制级别，这就更难一些，因为循环通常使用与实现`if`/`else`分支和开关语句相同的（有条件或无条件的）跳转指令来实现。
- en: The ability to find loops is useful for many reasons. For instance, from the
    compiler perspective, loops are interesting because much of a program’s execution
    time is spent inside loops (an often quoted number is 90 percent). That means
    that loops are an interesting target for optimization. From a security perspective,
    analyzing loops is useful because vulnerabilities such as buffer overflows tend
    to occur in loops.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 查找循环的能力有很多用途。例如，从编译器的角度来看，循环很重要，因为程序的大部分执行时间都花费在循环中（一个常被引用的数字是90%）。这意味着循环是优化的一个重要目标。从安全角度来看，分析循环也很有用，因为像缓冲区溢出这样的漏洞往往发生在循环中。
- en: Loop detection algorithms used in compilers use a different definition of a
    loop than what you might intuitively expect. These algorithms look for *natural
    loops*, which are loops that have certain well-formedness properties that make
    them easier to analyze and optimize. There are also algorithms that detect any
    *cycle* in a CFG, even those that don’t conform to the stricter definition of
    a natural loop. [Figure 6-10](ch06.xhtml#ch06fig10) shows an example of a CFG
    containing a natural loop, as well as a cycle that isn’t a natural loop.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器中使用的循环检测算法采用了不同于直觉的循环定义。这些算法寻找*自然循环*，这些循环具有某些良好的结构属性，使得它们更易于分析和优化。也有一些算法可以检测CFG中的任何*循环*，即使这些循环不符合自然循环的严格定义。[图6-10](ch06.xhtml#ch06fig10)展示了一个包含自然循环的CFG示例，以及一个不是自然循环的循环。
- en: First, I’ll show you the typical algorithm used to detect natural loops. After
    that, it will be clearer to you why not every cycle fits that definition. To understand
    what a natural loop is, you’ll need to learn what a *dominance tree* is. The right
    side of [Figure 6-10](ch06.xhtml#ch06fig10) shows an example of a dominance tree,
    which corresponds to the CFG shown on the left side of the figure.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我将向您展示用于检测自然循环的典型算法。之后，您会更清楚为什么并非每个循环都符合该定义。要理解什么是自然循环，您需要了解什么是*支配树*。[图6-10](ch06.xhtml#ch06fig10)的右侧展示了一个支配树的示例，它对应于图左侧展示的CFG。
- en: '![image](Images/f147-01.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f147-01.jpg)'
- en: '*Figure 6-10: A CFG and the corresponding dominance tree*'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6-10：一个CFG及其对应的支配树*'
- en: A basic block *A* is said to *dominate* another basic block *B* if the only
    way to get to *B* from the entry point of the CFG is to go through *A* first.
    For instance, in [Figure 6-10](ch06.xhtml#ch06fig10), *BB*[3] dominates *BB*[5]
    but not *BB*[6], since *BB*[6] can also be reached via *BB*[4]. Instead, *BB*[6]
    is dominated by *BB*[1], which is the last node that any path from the entry point
    to *BB*[6] must flow through. The dominance tree encodes all the dominance relationships
    in the CFG.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基本块*A*被认为是*支配*另一个基本块*B*，如果从控制流图（CFG）的入口点到达*B*的唯一方式是先经过*A*。例如，在[图6-10](ch06.xhtml#ch06fig10)中，*BB*[3]支配*BB*[5]，但不支配*BB*[6]，因为*BB*[6]也可以通过*BB*[4]到达。相反，*BB*[6]由*BB*[1]支配，*BB*[1]*是从入口点到*BB*[6]*的所有路径必须经过的最后一个节点。支配树编码了CFG中的所有支配关系。
- en: Now, a natural loop is induced by a *back edge* from a basic block *B* to *A*,
    where *A* dominates *B*. The loop resulting from this back edge contains all basic
    blocks dominated by *A* from which there is a path to *B*. Conventionally, *B*
    itself is excluded from this set. Intuitively, this definition means that natural
    loops cannot be entered somewhere in the middle but only at a well-defined *header
    node*. This simplifies the analysis of natural loops.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一个自然循环是由一个从基本块*B*到*A*的*回边*诱发的，其中*A*支配*B*。由这个回边产生的循环包含所有由*A*支配的、从中有路径通向*B*的基本块。通常，*B*本身被排除在这个集合之外。直观地说，这一定义意味着自然循环不能在中途被进入，只能在一个明确的*头节点*处进入。这简化了自然循环的分析。
- en: For instance, in [Figure 6-10](ch06.xhtml#ch06fig10), there’s a natural loop
    spanning basic blocks *BB*[3] and *BB*[5] since there’s a back edge from *BB*[5]
    to *BB*[3] and *BB*[3] dominates *BB*[5]. In this case, *BB*[3] is the header
    node of the loop, *BB*[5] is the “loopback” node, and the loop “body” (which by
    definition doesn’t include the header and loopback nodes) doesn’t contain any
    nodes.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在[图6-10](ch06.xhtml#ch06fig10)中，存在一个自然循环，横跨基本块*BB*[3]和*BB*[5]，因为从*BB*[5]到*BB*[3]有回边，且*BB*[3]支配*BB*[5]。在这种情况下，*BB*[3]是循环的头节点，*BB*[5]是“回环”节点，而循环的“主体”（根据定义不包括头节点和回环节点）不包含任何节点。
- en: Cycle Detection
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 循环检测
- en: You may have noticed another back edge in the graph, leading from *BB*[7] to
    *BB*[4]. This back edge induces a cycle, but *not* a natural loop, since the loop
    can be entered “in the middle” at *BB*[6] or *BB*[7]. Because of this, *BB*[4]
    doesn’t dominate *BB*[7], so the cycle does not meet the definition of a natural
    loop.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到图中有另一个回边，从*BB*[7]到*BB*[4]。这个回边诱发了一个循环，但*不是*自然循环，因为循环可以在*BB*[6]或*BB*[7]“中途”进入。由于这个原因，*BB*[4]没有支配*BB*[7]，因此该循环不符合自然循环的定义。
- en: To find cycles like this, including any natural loops, you only need the CFG,
    not the dominance tree. Simply start a depth-first search (DFS) from the entry
    node of the CFG, then keep a stack where you push any basic block that the DFS
    traverses and “pop” it back off when the DFS backtracks. If the DFS ever hits
    a basic block that’s already on the stack, then you’ve found a cycle.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到像这样的循环，包括任何自然循环，你只需要控制流图（CFG），而不需要支配树。只需从 CFG 的入口节点开始深度优先搜索（DFS），然后保持一个栈，每当
    DFS 遍历一个基本块时，就将其推入栈中，并在 DFS 回溯时将其弹出。如果 DFS 遇到一个已经在栈中的基本块，那么你就找到了一个循环。
- en: For instance, let’s assume you’re doing a DFS on the CFG shown in [Figure 6-10](ch06.xhtml#ch06fig10).
    The DFS starts at the entry point, *BB*[1]. [Listing 6-9](ch06.xhtml#ch06list9)
    shows how the DFS state evolves and how the DFS detects both cycles in the CFG
    (for brevity, I don’t show how the DFS continues after finding both cycles).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你正在对 [图 6-10](ch06.xhtml#ch06fig10) 中显示的控制流图（CFG）进行 DFS。DFS 从入口点 *BB*[1]
    开始。[列表 6-9](ch06.xhtml#ch06list9) 显示了 DFS 状态的演变以及 DFS 如何在 CFG 中检测到两个循环（为了简洁起见，我没有展示
    DFS 在找到两个循环之后的继续过程）。
- en: '*Listing 6-9: Cycle detection using DFS*'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 6-9：使用 DFS 检测循环*'
- en: '[PRE14]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: First, the DFS explores the leftmost branch of *BB*[1] but quickly backtracks
    as it hits a dead end. It then enters the middle branch, leading from *BB*[1]
    to *BB*[3], and continues its search through *BB*[5], after which it hits *BB*[3]
    again, thereby finding the cycle encompassing *BB*[3] and *BB*[5] ➊. It then backtracks
    to *BB*[5] and continues its search down the path leading to *BB*[7], then *BB*[4],
    *BB*[6], until finally hitting *BB*[7] again, finding the second cycle ➋.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，DFS 探索 *BB*[1] 的最左分支，但在遇到死胡同时迅速回溯。然后进入中间分支，从 *BB*[1] 到 *BB*[3]，继续沿着 *BB*[5]
    搜索，在此之后再次遇到 *BB*[3]，从而找到包含 *BB*[3] 和 *BB*[5] 的循环 ➊。接着回溯到 *BB*[5]，继续沿着通往 *BB*[7]
    的路径搜索，然后是 *BB*[4]、*BB*[6]，直到最终再次遇到 *BB*[7]，找到第二个循环 ➋。
- en: '*6.4.3 Data-Flow Analysis*'
  id: totrans-211
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*6.4.3 数据流分析*'
- en: 'Now let’s take a look at some common data-flow analysis techniques: reaching
    definitions analysis, use-def chains, and program slicing.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看一些常见的数据流分析技术：到达定义分析、使用-定义链和程序切片。
- en: Reaching Definitions Analysis
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 到达定义分析
- en: '*Reaching definitions analysis* answers the question, “Which data definitions
    can reach this point in the program?” When I say a data definition can “reach”
    a point in the program, I mean that a value assigned to a variable (or, at a lower
    level, a register or memory location) can reach that point without the value being
    overwritten by another assignment in the meantime. Reaching definitions analysis
    is usually applied at the CFG level, though it can also be used interprocedurally.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '*到达定义分析* 解答了“哪些数据定义可以到达程序中的这一点？”当我说一个数据定义可以“到达”程序中的某个点时，我的意思是，分配给一个变量（或者在更低级别上，分配给一个寄存器或内存位置）的值可以到达该点，而不会在此过程中被其他赋值覆盖。到达定义分析通常应用于控制流图（CFG）级别，尽管它也可以在过程间使用。'
- en: The analysis starts by considering for each individual basic block which definitions
    the block *generates* and which it *kills*. This is usually expressed by computing
    a *gen* and *kill* set for each basic block. [Figure 6-11](ch06.xhtml#ch06fig11)
    shows an example of a basic block’s *gen* and *kill* sets.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 分析首先通过考虑每个基本块生成哪些定义并杀死哪些定义来开始。通常通过计算每个基本块的 *gen* 和 *kill* 集合来表达这一点。[图 6-11](ch06.xhtml#ch06fig11)
    显示了基本块的 *gen* 和 *kill* 集合示例。
- en: The *gen* set for *BB*[3] contains the statements numbered 6 and 8 since those
    are data definitions in *BB*[3] that survive until the end of the basic block.
    Statement 7 doesn’t survive since `z` is overwritten by statement 8\. The *kill*
    set contains statements 1, 3, and 4 from *BB*[1] and *BB*[2] since those assignments
    are overwritten by other assignments in *BB*[3].
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '*BB*[3] 的 *gen* 集合包含语句 6 和 8，因为这些是 *BB*[3] 中的定义，直到基本块结束时仍然有效。语句 7 不再有效，因为 `z`
    被语句 8 覆盖。*kill* 集合包含来自 *BB*[1] 和 *BB*[2] 的语句 1、3 和 4，因为这些赋值被 *BB*[3] 中的其他赋值覆盖。'
- en: '![image](Images/f149-01.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f149-01.jpg)'
- en: '*Figure 6-11: Example of* gen *and* kill *sets for a basic block*'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6-11：基本块的* gen *和* kill *集合示例*'
- en: 'After computing each basic block’s *gen* and *kill* sets, you have a *local*
    solution that tells you which data definitions each basic block generates and
    kills. From that, you can compute a *global* solution that tells you which definitions
    (from anywhere in the CFG) can reach the start of a basic block and which can
    still be alive after the basic block. The global set of definitions that can reach
    a basic block *B* is expressed as a set *in*[*B*], defined as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 计算每个基本块的*gen*和*kill*集合之后，你就得到了一个*局部*解，告诉你每个基本块生成和消除的数据定义。从这些信息中，你可以计算出一个*全局*解，告诉你哪些定义（来自控制流图中的任何地方）可以到达一个基本块的开始，哪些定义在基本块执行完后仍然存活。可以到达基本块*B*的全局定义集合表示为一个集合*out*[*B*]，定义如下：
- en: '![image](Images/f149-02.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f149-02.jpg)'
- en: 'Intuitively, this means the set of definitions reaching *B* is the union of
    all sets of definitions leaving other basic blocks that precede *B*. The set of
    definitions leaving a basic block *B* is denoted as *out*[*B*] and defined as
    follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，这意味着到达*B*的定义集合是所有离开其他前驱基本块的定义集合的并集。离开基本块*B*的定义集合表示为*out*[*B*]，定义如下：
- en: '![image](Images/f149-03.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f149-03.jpg)'
- en: 'In other words, the definitions that leave *B* are those *B* either generates
    itself or that *B* receives from its predecessors (as part of its *in* set) and
    doesn’t kill. Note that there’s a mutual dependency between the definitions of
    the *in* and *out* sets: *in* is defined in terms of *out*, and vice versa. This
    means that in practice, it’s not enough for a reaching definitions analysis to
    compute the *in* and *out* sets for each basic block just once. Instead, the analysis
    must be iterative: in each iteration, it computes the sets for every basic block,
    and it continues iterating until there are no more changes in the sets. Once all
    of the *in* and *out* sets have reached a stable state, the analysis is complete.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，离开*B*的定义是*B*自己生成的或从其前驱接收的（作为其*in*集合的一部分）且没有被杀死的定义。注意，*in*集合和*out*集合之间存在相互依赖关系：*in*是通过*out*定义的，反之亦然。这意味着实际上，进行到达定义分析时，仅仅计算每个基本块的*in*和*out*集合一次是不够的。相反，分析必须是迭代的：每次迭代时，它都会计算每个基本块的集合，并继续迭代，直到集合没有再发生变化为止。一旦所有的*in*和*out*集合都达到稳定状态，分析就完成了。
- en: Reaching definitions analysis forms the basis of many data-flow analyses. This
    includes *use-def analysis*, which I’ll discuss next.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 到达定义分析构成了许多数据流分析的基础。这包括*使用-定义分析*，我接下来将讨论这一点。
- en: Use-Def Chains
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用-定义链
- en: '*Use-def chains* tell you, at each point in the program where a variable is
    used, where that variable may have been defined. For instance, in [Figure 6-12](ch06.xhtml#ch06fig12),
    the use-def chain for `y` in *B*[2] contains statements 2 and 7\. This is because
    at that point in the CFG, `y` could have gotten its value from the original assignment
    at statement 2 or (after one iteration of the loop) at statement 7\. Note that
    there’s no use-def chain for `z` in *B*[2], as `z` is only assigned in that basic
    block, not used.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用-定义链*告诉你，在程序中的每个变量使用点，那个变量可能被定义的位置。例如，在[图6-12](ch06.xhtml#ch06fig12)中，*B*[2]中`y`的使用-定义链包含语句2和语句7。这是因为在该控制流图（CFG）中的这一点，`y`可能是通过语句2的原始赋值或（经过一次循环迭代后）语句7获得的。注意，*B*[2]中没有`z`的使用-定义链，因为`z`仅在该基本块中被赋值，而未被使用。'
- en: '![image](Images/f150-01.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/f150-01.jpg)'
- en: '*Figure 6-12: Example of use-def chains*'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6-12：使用-定义链的示例*'
- en: 'One instance where use-def chains come in handy is decompilation: they allow
    the decompiler to track where a value used in a conditional jump was compared.
    This way, the decompiler can take a `cmp x,5` and `je` (jump if equal) instruction
    and merge them into a higher-level expression like `if(x == 5)`. Use-def chains
    are also used in compiler optimizations such as *constant propagation*, which
    replaces a variable by a constant if that’s the only possible value at that point
    in the program. They’re also useful in a myriad of other binary analysis scenarios.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 使用-定义链的一个应用场景是反编译：它们使反编译器能够追踪在条件跳转中使用的值被比较的位置。通过这种方式，反编译器可以将`cmp x,5`和`je`（相等时跳转）指令合并为一个更高层次的表达式，如`if(x
    == 5)`。使用-定义链也用于编译器优化，例如*常量传播*，当某个变量在程序中的某个点唯一的可能值为常量时，替换该变量为常量。它们在许多其他二进制分析场景中也很有用。
- en: At first glance, computing use-def chains may seem complex. But given a reaching
    definitions analysis of the CFG, it’s quite straightforward to compute the use-def
    chain for a variable in a basic block using the *in* set to find the definitions
    of that variable that may reach the basic block. In addition to use-def chains,
    it’s also possible to compute def-use chains. In contrast to use-def chains, def-use
    chains tell you where in the program a given data definition may be used.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，计算使用-定义链（use-def chain）可能会显得复杂。但在有了控制流图（CFG）的达成定义分析之后，利用*in*集来查找可能到达基本块的该变量的定义，计算基本块中变量的使用-定义链就变得相当简单。除了使用-定义链，还可以计算定义-使用链。与使用-定义链相反，定义-使用链告诉你程序中某个数据定义可能在哪些地方被使用。
- en: Program Slicing
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 程序切片
- en: '*Slicing* is a data-flow analysis that aims to extract all instructions (or,
    for source-based analysis, lines of code) that contribute to the values of a chosen
    set of variables at a certain point in the program (called the *slicing criterion*).
    This is useful for debugging when you want to find out which parts of the code
    may be responsible for a bug, as well as when reverse engineering. Computing slices
    can get pretty complicated, and it’s still more of an active research topic than
    a production-ready technique. Still, it’s an interesting technique, so it’s worth
    learning about. Here, I’ll just give you the general idea, but if you want to
    play around with slicing, I suggest taking a look at the angr reverse-engineering
    framework,^([17](footnote.xhtml#ch06fn_17)) which offers built-in slicing functionality.
    You’ll also see how to implement a practical slicing tool with symbolic execution
    in [Chapter 13](ch13.xhtml#ch13).'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '*切片*是一种数据流分析方法，旨在提取在程序某一特定点（称为*切片标准*）对一组选定变量的值有贡献的所有指令（或者，对于基于源代码的分析，是指源代码的所有行）。这在调试时非常有用，尤其是当你想找出哪些代码部分可能是导致bug的原因，也适用于逆向工程。计算切片可能非常复杂，它仍然是一个活跃的研究课题，而不是生产就绪的技术。尽管如此，它仍然是一个有趣的技术，值得了解。在这里，我将简单介绍它的基本思想，如果你想深入体验切片，我建议你查看
    angr 逆向工程框架，^([17](footnote.xhtml#ch06fn_17))，它提供了内置的切片功能。你还可以在[第13章](ch13.xhtml#ch13)中看到如何通过符号执行实现一个实用的切片工具。'
- en: Slices are computed by tracking control and data flows to figure out which parts
    of the code are irrelevant to the slice and then deleting those parts. The final
    slice is whatever remains after deleting all the irrelevant code. As an example,
    let’s say you want to know which lines in [Listing 6-10](ch06.xhtml#ch06list10)
    contribute to the value of `y` on line 14.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 切片是通过跟踪控制流和数据流来计算的，以找出哪些代码部分与切片无关，然后删除这些部分。最终的切片是删除所有无关代码后剩下的部分。例如，假设你想知道[示例6-10](ch06.xhtml#ch06list10)中哪些行对第14行的`y`值有贡献。
- en: '*Listing 6-10: Using slicing to find the lines contributing to* y *on line
    14*'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例6-10：使用切片来查找对* y *在第14行的贡献行*'
- en: '[PRE15]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The slice contains the lines shaded gray in this code. Note that all the assignments
    to `z` are completely irrelevant to the slice because they make no difference
    to the eventual value of `y`. What happens with `x` *is* relevant since it determines
    how often the loop on line 5 iterates, which in turn affects the value of `y`.
    If you compile a program with just the lines included in the slice, it will yield
    exactly the same output for the `print(y)` statement as the full program would.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 该切片包含代码中阴影灰色的行。请注意，所有对`z`的赋值与切片完全无关，因为它们对`y`的最终值没有影响。`x`的变化是相关的，因为它决定了第5行的循环迭代次数，这反过来又影响了`y`的值。如果你只编译切片中包含的行，`print(y)`语句的输出将与完整程序的输出完全相同。
- en: Originally, slicing was proposed as a static analysis, but nowadays it’s often
    applied to dynamic execution traces instead. Dynamic slicing has the advantage
    that it tends to produce smaller (and therefore more readable) slices than static
    slicing does.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，切片是作为静态分析提出的，但现在它通常应用于动态执行跟踪。动态切片的优势在于，它通常比静态切片产生更小（因此更易读）的切片。
- en: What you just saw is known as *backward slicing* since it searches backward
    for lines that affect the chosen slicing criterion. But there’s also *forward
    slicing*, which starts from a point in the program and then searches forward to
    determine which other parts of the code are somehow affected by the instruction
    and variable in the chosen slicing criterion. Among other things, this can predict
    which parts of the code will be impacted by a change to the code at the chosen
    point.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '你刚才看到的被称为 *反向切片*，因为它是从后向前搜索影响所选切片标准的行。但也有 *正向切片*，它从程序中的某个点开始，向前搜索以确定其他哪些代码部分会受到所选切片标准中的指令和变量的影响。除此之外，它还可以预测代码中的哪些部分会受到所选点上代码更改的影响。  '
- en: 6.5 Effects of Compiler Settings on Disassembly
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.5 编译器设置对反汇编的影响  '
- en: Compilers optimize code to minimize its size or execution time. Unfortunately,
    optimized code is usually significantly harder to accurately disassemble (and
    therefore analyze) than unoptimized code.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '编译器优化代码以最小化其大小或执行时间。不幸的是，优化后的代码通常比未优化的代码更难以精确反汇编（因此也更难分析）。  '
- en: Optimized code corresponds less closely to the original source, making it less
    intuitive to a human. For instance, when optimizing arithmetic code, compilers
    will go out of their way to avoid the very slow `mul` and `div` instructions and
    instead implement multiplications and divisions using a series of bitshift and
    add operations. These can be challenging to decipher when reverse engineering
    the code.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '优化后的代码与原始源代码的对应关系较少，这使得它对人类的直观性降低。例如，在优化算术代码时，编译器会尽量避免非常慢的 `mul` 和 `div` 指令，而是通过一系列位移和加法操作来实现乘法和除法。逆向工程时，这些操作可能会很难解读。  '
- en: Also, compilers often merge small functions into the larger functions calling
    them, to avoid the cost of the `call` instruction; this merging is called *inlining*.
    Thus, not all functions you see in the source code are necessarily there in the
    binary, at least not as a separate function. In addition, common function optimizations
    such as tail calls and optimized calling conventions make function detection significantly
    less accurate.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，编译器经常将小函数合并到调用它们的较大函数中，以避免 `call` 指令的开销；这种合并被称为 *内联*。因此，你在源代码中看到的并不一定都是二进制文件中存在的函数，至少它们不会作为单独的函数存在。此外，常见的函数优化，例如尾调用和优化的调用约定，会使得函数检测的准确性大大降低。  '
- en: At higher optimization levels, compilers often emit padding bytes between functions
    and basic blocks to align them at memory addresses where they can be most efficiently
    accessed. Interpreting these padding bytes as code can cause disassembly errors
    if the padding bytes aren’t valid instructions. Moreover, compilers may “unroll”
    loops to avoid the overhead of jumping to the next iteration. This hinders loop
    detection algorithms and decompilers, which try to find high-level constructs
    like `while` and `for` loops in the code.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '在较高的优化级别下，编译器通常会在函数和基本块之间插入填充字节，以便将它们对齐到可以最有效访问的内存地址。将这些填充字节误解释为代码可能会导致反汇编错误，尤其是当这些填充字节不是有效指令时。此外，编译器可能会“展开”循环，以避免跳转到下一次迭代的开销。这会妨碍循环检测算法和反编译器，后者试图在代码中找到类似
    `while` 和 `for` 循环的高级结构。  '
- en: Optimizations may also hinder data structure detection, not just code discovery.
    For instance, optimized code may use the same base register to index different
    arrays at the same time, making it difficult to recognize them as separate data
    structures.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 优化还可能妨碍数据结构检测，而不仅仅是代码发现。例如，优化后的代码可能同时使用相同的基址寄存器来索引不同的数组，这使得很难将它们识别为独立的数据结构。
- en: Nowadays, *link-time optimization (LTO)* is gaining in popularity, which means
    that optimizations that were traditionally applied on a per-module basis can now
    be used on the whole program. This increases the optimization surface for many
    optimizations, making the effects even more profound.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '如今，*链接时优化 (LTO)* 越来越受到欢迎，这意味着传统上在每个模块基础上应用的优化现在可以用于整个程序。这增加了许多优化的优化面，使得效果更加深远。  '
- en: When writing and testing your own binary analysis tools, always keep in mind
    that their accuracy may suffer from optimized binaries.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '在编写和测试自己的二进制分析工具时，务必记住，优化后的二进制文件可能会影响工具的准确性。  '
- en: In addition to the previous optimizations, binaries are increasingly often compiled
    as *position-independent code (PIC)* to accommodate security features like *address-space
    layout randomization (ASLR)*, which need to be able to move code and data around
    without this breaking the binary.^([18](footnote.xhtml#ch06fn_18)) Binaries compiled
    with PIC are called *position-independent executables (PIEs)*. In contrast to
    position-dependent binaries, PIE binaries don’t use absolute addresses to reference
    code and data. Instead, they use references relative to the program counter. This
    also means that some common constructs, such as the PLT in ELF binaries, look
    different in PIE binaries than in non-PIE binaries. Thus, binary analysis tools
    that aren’t built with PIC in mind may not work properly for such binaries.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 除了之前提到的优化方法之外，二进制文件越来越多地被编译为*位置无关代码（PIC）*，以适应像*地址空间布局随机化（ASLR）*这样的安全功能，这些功能需要能够在不破坏二进制文件的情况下移动代码和数据。^([18](footnote.xhtml#ch06fn_18))
    使用PIC编译的二进制文件称为*位置无关可执行文件（PIE）*。与位置依赖的二进制文件相比，PIE二进制文件不会使用绝对地址来引用代码和数据。相反，它们使用相对于程序计数器的引用。这也意味着一些常见的结构，比如ELF二进制文件中的PLT，在PIE二进制文件中与非PIE二进制文件中的表现不同。因此，那些没有考虑到PIC的二进制分析工具，可能无法正确处理这种二进制文件。
- en: 6.6 Summary
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6 总结
- en: You’re now familiar with the inner workings of disassemblers as well as the
    essential binary analysis techniques you’ll need to understand the rest of this
    book. Now you’re ready to move on to techniques that will allow you to not only
    disassemble binaries but also modify them. Let’s start with basic binary modification
    techniques in [Chapter 7](ch07.xhtml#ch07)!
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经了解了反汇编器的内部工作原理，以及理解本书其余部分所需的基本二进制分析技术。现在你已经准备好继续学习一些技术，不仅能够反汇编二进制文件，还能修改它们。让我们从[第七章](ch07.xhtml#ch07)开始，学习基本的二进制修改技术！
- en: Exercises
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 练习
- en: 1\. Confusing objdump
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 欺骗objdump
- en: Write a program that confuses `objdump` such that it interprets data as code,
    or vice versa. You’ll probably need to use some inline disassembly to achieve
    this (for instance, using `gcc`’s `asm` keyword).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个程序，欺骗`objdump`，使其将数据解读为代码，或者将代码解读为数据。你可能需要使用一些内联反汇编来实现这一点（例如，使用`gcc`的`asm`关键字）。
- en: 2\. Confusing a Recursive Disassembler
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 欺骗递归反汇编器
- en: Write another program, this time so that it tricks your favorite recursive disassembler’s
    function detection algorithm. There are various ways to do this. For instance,
    you could create a tail-called function or a function that has a `switch` with
    multiple return cases. See how far you can go with confusing the disassembler!
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 编写另一个程序，这次让它欺骗你最喜欢的递归反汇编器的函数检测算法。实现这一点有多种方法。例如，你可以创建一个尾调用函数，或者一个带有多个返回情况的`switch`函数。看看你能让反汇编器困惑到什么程度！
- en: 3\. Improving Function Detection
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 改进函数检测
- en: Write a plugin for your recursive disassembler of choice so that it can better
    detect functions such as those the disassembler missed in the previous exercise.
    You’ll need a recursive disassembler that you can write plugins for, such as IDA
    Pro, Hopper, or Medusa.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 为你选择的递归反汇编器编写一个插件，使其能够更好地检测诸如在之前练习中未能检测到的函数。你需要一个可以为其编写插件的递归反汇编器，例如IDA Pro、Hopper或Medusa。
