- en: '**13**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**DESKTOP ARCHITECTURES**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Image](../images/f0301-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: “A computer on every desk” was Bill Gates’s ambition during the 32-bit era of
    the 1990s, and while the current trend is toward the Internet of Things and the
    cloud, a personal computer (PC) can still be found on many desks and laps today.
    The PC isn’t a single computer design; rather, it’s a set of loose conventions
    for combining many different components from different manufacturers into computers,
    based around the x86 family of CPUs.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to a business-led focus on backward compatibility, modern PCs retain
    many features from earlier stages of their evolution, so in this chapter we’ll
    study how these conventions came into being and how they’ve affected x86 architecture
    and PC computer design. We’ll examine x86’s CISC philosophy and its Silicon Valley
    history and instruction set, then look at some computer design elements used to
    build modern PCs around it.
  prefs: []
  type: TYPE_NORMAL
- en: CISC Design Philosophy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most desktop computers use CPUs from the x86 family, which are usually described
    as CISC architectures. We’ve seen CISC architectures a few times, but let’s take
    a closer look at some of the CISC principles that appear in x86.
  prefs: []
  type: TYPE_NORMAL
- en: In a CISC architecture, you try to do as many big and clever things as you can
    on a large, complex chip with lots of silicon. You design many different small
    machines that all do different specialized things; you also provide dedicated
    instructions for each of them. As you can imagine, this is very hard to design,
    and you end up having to pay your architects a lot of money—especially when all
    the new complex features need to be made to play nicely with other innovations,
    such as pipelining and out-of-order execution (OOOE). Using lots of silicon typically
    consumes lots of power, so CISC processors often have to be plugged into the wall,
    with heavy power transformers and large cooling systems such as fans. These requirements
    are easier to meet in a desktop setting than in embedded and smart-type environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'A classic aspect of CISC philosophy is having lots of instructions that combine
    memory access with arithmetic logic unit (ALU) instructions, such as “multiply
    the contents of a first address by the contents of a second address and store
    the result in a third address,” where the addresses are in RAM. This is, in fact,
    a compound instruction involving many steps: we need to load both addresses, multiply
    their values, put the resulting value in a register, and store it in memory again.'
  prefs: []
  type: TYPE_NORMAL
- en: CISC also emphasizes implementing new instructions in hardware essentially saying,
    “Throw more silicon at the problem.” For example, if users demand lots of video
    codec streaming, you can create special instructions that perform the specific
    mathematical operations used in video codecs, and build lots of new simple machines
    in digital logic to implement each of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'A “decode my video” instruction is going to take more than one clock cycle,
    and accommodating different instructions that take differing amounts of time is
    a major challenge that arises in CISC architectures. In particular, pipelining
    and OOOE are harder to get right when instructions have different durations. This
    problem can be fixed by throwing even more silicon at it: you can create even
    more complex digital logic in the control unit (CU) to identify these durations
    and schedule around them.'
  prefs: []
  type: TYPE_NORMAL
- en: One supposed advantage of CISC architectures is that the compiler has to do
    very little work to translate common high-level language statements into assembly;
    this is because the instruction set architecture (ISA) has dedicated instructions
    for commands such as “decode my video,” which then have a simple one-to-one translation.
    But these instructions make life harder for compiler writers, who now need to
    wade through a five-volume set of instructions for *every* backend CPU they target;
    they’re also now expected to make some attempt to optimize their compiler for
    each particular ISA. It would be much easier for compiler writers to just use
    one volume of instructions and ignore all the advanced ones. In practice, this
    means that CISC architectures are more likely to come with compilers written by
    the same people who built the CPU, because no one else wants to work to optimize
    for one particular CPU. These compilers tend to be proprietary and to run faster
    than the open source versions due to the complexity involved; only those who built
    the system fully understand all the features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another upside is that assembly programs can be short, as every instruction
    does a lot of work. In the 1980s, this was important: RAM was limited, so shorter
    programs freed up more RAM for data. It’s not so important today.'
  prefs: []
  type: TYPE_NORMAL
- en: CISC was invented by an Englishman, Maurice Wilkes, seen previously in [Figure
    1-19](ch01.xhtml#ch01fig19), but was commercialized by Americans. Stereotypical
    CISC architects and users are business-driven, and CISC is dominant in real-world
    desktop computing. You’re probably using a CISC architecture on your desktop today.
    If a CISC client asks for a new instruction to speed up their particular multimedia
    application, then the CISC business will often design and add it for them—for
    a cost. New features are often bolted on in this way, without necessarily being
    designed to beautifully fit together with what was there before. The older features
    will usually be retained, however, in order to avoid breaking other customers’
    existing systems.
  prefs: []
  type: TYPE_NORMAL
- en: Microprogramming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Building new CPUs in hardware is hard and expensive. A chip mask set costs around
    $5 million to make, and if you get it wrong anywhere, new masks will be needed.
    This problem is acute for CISC due to its complex designs. *Microprogramming*
    is a solution to this problem in which the architecture consists of many simple
    machines that can be connected and disconnected through basic switches. Instructions
    are then defined as sequences of connections and disconnections. For example,
    to add two registers, you first connect one of them to an ALU input, then connect
    the other register to the other ALU input. Then you connect the ALU to a signal
    asking it to add, and finally you connect the result in the ALU output to a register.
  prefs: []
  type: TYPE_NORMAL
- en: This idea is reminiscent of the rotating barrel CU in Babbage’s Analytical Engine.
    The barrel has pins that are placed to trigger sequences of the simple machines.
    If the pins are moved around, different instructions and architectures can be
    easily created. Modern electronic microprogramming—and hence CISC—is credited
    to Wilkes, who studied and taught the history of computing and was very open about
    having picked up the idea from Babbage’s mechanical barrel. This is a paradigmatic
    example of how studying the arc of history can enable major, Turing Award–winning
    advances in modern architecture.
  prefs: []
  type: TYPE_NORMAL
- en: The electronic version of Babbage’s barrel pins is usually firmware, known as
    *microcode*, inside the CPU, containing a list of connections to make and break
    in sequence for each instruction. (This isn’t ROM in the CPU’s address space,
    it’s a non-addressable, separate region inside the CPU itself.) As firmware, it
    can be electronically reprogrammed at any time. This massively reduces the cost
    of fixing hardware bugs in the CPU, as they can be corrected with a firmware update
    rather than having to return and remanufacture the chip itself.
  prefs: []
  type: TYPE_NORMAL
- en: Microprograms aren’t machine code programs; they exist at a lower level, defining
    the machine that the machine code runs on. The actions of microprograms can be
    notated using register transfer language (RTL), as in [Chapter 7](ch07.xhtml).
    Modern CISC chips may have many thousands of complex instructions all defined
    in microcode. You can re-microprogram your CPU to implement a completely different
    instruction set if you like, such as turning an x86 into a retro 6502! There’s
    now so much reconfigurability that microprograms can behave almost like FPGAs.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve seen some of the design concepts, let’s turn to the history of
    x86\. Doing so will help you make sense of features still present in modern x86s
    that have accumulated through this history.
  prefs: []
  type: TYPE_NORMAL
- en: x86 History
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The x86 architecture has been the most commercially successful and resilient
    CPU architecture to date, reaching its 45th anniversary in 2023\. x86 is a family
    of CISC architectures whose designs and names derive from the model numbers of
    the first few generations of Intel processors: 8086, 80286, 80386, and 80486\.
    x86 has persisted across three generations of word lengths: 16-, 32-, and 64-bit
    architectures. As a commercial product, it has strongly emphasized rigorous backward
    compatibility with all previous generations, at the cost of adding complexity
    to the design, including digital logic to ensure historical bugs are kept in order
    to allow old games that exploit them as features to continue to run. You can still
    take your executable machine code from the 1970s and run it on a modern x86 and
    it will “just work.” (This is a similar approach to software design in commercial
    operating systems, which similarly grow to huge, bloated sizes to maintain compatibility
    for customers at the expense of performance and beauty.) As a result of continually
    adding new CISC instructions and keeping all the old ones, the latest version
    of x86—the *amd64* ISA—now includes over 3,000 instructions, documented in a five-volume
    set of reference books.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Prehistory*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The history of x86 design is one of Silicon Valley architecture and politics,
    and specifically of the companies Intel and AMD. Both companies make processors
    using the same proprietary instruction set, and they’re constantly locked in legal
    battles with each other, which have now spanned decades.
  prefs: []
  type: TYPE_NORMAL
- en: William Shockley, John Bardeen, and Walter Brattain were awarded the Nobel Prize
    in Physics in 1956 for their invention of the transistor at Bell Labs, New Jersey.
    Shockley’s family was from Palo Alto, California, though he was born in London.
    After winning a Nobel Prize, you can live and work wherever you like, so Shockley
    decided to relocate from New Jersey to Mountain View, California, because he wanted
    to be near his mother in Palo Alto. He set up Shockley Semiconductor there to
    continue his transistor research and commercialization.
  prefs: []
  type: TYPE_NORMAL
- en: By 1957, Shockley had become a difficult person to work with due to a mixture
    of Nobel laureate hubris and obsession with topics considered fringe by his staff.
    A group of employees, the so-called “traitorous eight”—including Gordon Moore
    and Robert Noyce—walked out on Shockley to set a rival firm, Fairchild Semiconductor.
    This was considered almost blasphemous by the commercial culture of the time,
    in which it was assumed people would join a big company and be loyal company servants
    for their whole careers. It has since become the blueprint for Silicon Valley’s
    startup culture, in which it’s assumed employees will and should leave big companies
    to start their own.
  prefs: []
  type: TYPE_NORMAL
- en: Fairchild created the first commercial version of the integrated circuit (chip).
    Demand for computing at this time was almost entirely from the American military,
    which used taxpayer money to subsidize research and buy the products of chipmakers
    to power missiles and planes for the Cold War. These government funds fed the
    silicon industry, accelerating the growth of Fairchild and also many rival upstarts
    as Fairchild staff copied the Fairchild model and left to start their own competing
    chip companies, giving rise to modern Silicon Valley.
  prefs: []
  type: TYPE_NORMAL
- en: In 1968, Fairchild politics led Gordon Moore and Robert Noyce to quit again—this
    time leaving Fairchild to set up Intel (short for Integrated Electronics). AMD
    (Advanced Micro Devices) was founded the following year by Jerry Sanders. AMD’s
    early goal was to copy Intel’s products and produce them more cheaply as a second
    source. Before the x86 series proper, Intel produced the 4-bit 4004 in 1971\.
    AMD cloned it shortly afterward in 1975 as the Am9080\. Intel preempted this in
    1974 with an 8-bit version, the 8080 (3 MHz), which was then also copied by AMD.
  prefs: []
  type: TYPE_NORMAL
- en: '*16-Bit Classical Era*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The first member of the x86 family proper—defined by modern backward compatibility—was
    Intel’s 16-bit, 5 MHz 8086 chip, made in 1978\. This was a CISC chip that used
    microprogramming. x86 is named after its last two digits.
  prefs: []
  type: TYPE_NORMAL
- en: Competition between Intel and AMD became formalized in 1982 by a three-way contract
    between Intel, AMD, and IBM, whose business at the time was building computers.
    IBM wanted to buy CPUs for its computers but didn’t want to be locked into using
    a proprietary design from a single company, because such a company could then
    hold IBM to ransom via the lock-in and increase its prices. As a huge company,
    IBM had enough buying power to play suppliers against one another to get what
    it really wanted, which was for more than one company to compete to produce the
    same chips as generic commodities; this would push down the prices and enable
    IBM to get them cheap in perpetuity. IBM said to Intel, “We want to buy your chips,
    but we’ll buy them only if you sign this contract saying you’ll let AMD copy them.
    If you don’t sign, then we won’t buy from either of you.” The three companies
    agreed and thus created the famous Intel-AMD cross-license for both chipmakers
    to design and sell chips implementing the same x86 ISA.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*This is a general lesson about computer economics: after a sale, the seller
    of a hardware or software platform can wield extreme power over the buyer via
    lock-in. Platform sellers should thus try to initially give away their platforms
    for free or at large discounts, to get users locked into them, before ramping
    up their sales terms once they have the buyer over a barrel. But before the buyer
    selects a platform, it’s the buyer who holds all the power and calls the shots.
    Thus, buyers should negotiate hard to formalize a contract that mitigates the
    seller’s power over them later. Once you hand over the money, you have no power
    except what was agreed in that contract.*'
  prefs: []
  type: TYPE_NORMAL
- en: The IBM deal propelled both chipmakers into the business computing market, enabling
    them to scale rapidly. After the deal, Intel updated the 8086 with its 80186 (1982;
    6 MHz), followed soon after by the 80286 (1982; 8 MHz), which added protected
    mode for OS support for the first time. AMD then quickly cloned the 80286 as its
    Am286 (1982; 8 MHz). These 16-bit devices were appearing in the early 1980s as
    high-end business machines, at the same time that the 8-bit golden age was arriving
    in homes.
  prefs: []
  type: TYPE_NORMAL
- en: '*32-Bit Clone Wars Era*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The 32-bit era began with Intel’s 386 (1985; 16 MHz), which introduced the 32-bit
    instruction set x86 IA-32\. Throughout this era, we saw continual antagonism and
    legal action between the two big chipmakers; this was made more entertaining by
    the entry of additional competitors Cyrix and Via, who also made x86 clones. [Table
    13-1](ch13.xhtml#ch13tab1) summarizes these developments.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 13-1:** 32-Bit Era x86 Developments'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Year** | **Maker** | **Architecture** | **Features** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1985 | Intel | 386 | 16 MHz |'
  prefs: []
  type: TYPE_TB
- en: '| 1989 | Intel | 486 | 50 MHz, pipelined, FPU |'
  prefs: []
  type: TYPE_TB
- en: '| 1991 | AMD | Am386 | Clone of 386 |'
  prefs: []
  type: TYPE_TB
- en: '| 1993 | Intel | Pentium | 75 MHz, superscalar |'
  prefs: []
  type: TYPE_TB
- en: '| 1993 | AMD | Am486 | Clone of 486 (last clone) |'
  prefs: []
  type: TYPE_TB
- en: '| 1995 | Intel | P5 | 150 MHz, MMX SIMD “Pentium MMX” |'
  prefs: []
  type: TYPE_TB
- en: '| 1995 | Intel | P6 (i686) | 200 MHz, SSE SIMD, OOOE, “Pentium Pro” |'
  prefs: []
  type: TYPE_TB
- en: '| 1996 | AMD | K5 | 133 MHz, Pentium-like |'
  prefs: []
  type: TYPE_TB
- en: '| 1995 | Cyrix | Cx5x86 | 140 MHz, Pentium-like |'
  prefs: []
  type: TYPE_TB
- en: '| 1996 | Cyrix | 6x86 | 140 MHz, Pentium-like |'
  prefs: []
  type: TYPE_TB
- en: '| 1997 | AMD | K6 | 300 MHz, 3D-NOW, rival SIMD |'
  prefs: []
  type: TYPE_TB
- en: '| 2001 | VIA | C3 | 500 MHz, Pentium-like |'
  prefs: []
  type: TYPE_TB
- en: '| 2001 | AMD | Athlon | 2 GHz |'
  prefs: []
  type: TYPE_TB
- en: Intel was usually the technical leader, creating new technologies such as pipelined
    designs and extension instructions, with the others copying a year or two later
    to bring the price down. At every step, clock speeds reliably got faster, following
    Moore’s law for clock speed. This was the “bland 1990s,” where customers assumed
    they would need to buy a new beige desktop computer every 18 months to keep up
    with doubling clock speeds.
  prefs: []
  type: TYPE_NORMAL
- en: After the 486, Intel got sick of competitors copying the untrademarkable 86
    name, so they switched to the trademarkable brand name “Pentium.” This was the
    dominant chip for some time, but then AMD took the lead by becoming the first
    to reach 1 GHz speed with its Athlon in 2001.
  prefs: []
  type: TYPE_NORMAL
- en: '*64-Bit Branding Era*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The 64-bit era of x86 arrived in 2000 when AMD formally defined the amd64 ISA,
    which was adopted by most CISC processors following it. This was a coup: the x86
    ISA family had previously always been defined by Intel, with others pegging their
    own products to them.'
  prefs: []
  type: TYPE_NORMAL
- en: Intel attempted to define its own failed 64-bit competitor ISA, called IA-64,
    but this was released after amd64 and never caught on; today, everyone uses amd64\.
    Intel, however, refuses to acknowledge the name amd64, instead referring to the
    same ISA as x86_64\. Confusingly, you’ll see both names used to describe executable
    software downloads for this ISA, such as in the names of Linux distribution packages.
  prefs: []
  type: TYPE_NORMAL
- en: The 64-bit era is characterized by a separation of marketing terms from the
    underlying technologies, with the same marketing brand often used to label completely
    different architectures. Unlike the previous 32-bit Pentium, the branding is no
    longer attached to specific designs. You’re probably used to seeing 64-bit products
    with brands like Pentium, Celeron, and Xeon. You may also see the numbers 3, 5,
    7, and 9 in brand names, as in Core i3, Core i5, and so on. For Intel, these numbers
    don’t mean anything other than suggesting an ordering of which products are better;
    AMD uses the same numbers to suggest which products are similar to Intel’s.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 13-2](ch13.xhtml#ch13tab2) shows examples of Intel and AMD releases
    and some of their notable features during the 64-bit era.'
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines have varied between around 14 and 20 stages during this period, and
    OOOE has been used throughout. AMD Piledriver was the first to introduce neural
    network–based branch prediction hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Clock speeds hit 3.5 GHz around the start of the 64-bit era and have been stuck
    there ever since, due to the end of Moore’s law for clock speed. However, Moore’s
    law for transistor size continued to hold, and it became common to define machines
    by their transistor scale, in nanometers (nm) per transistor, rather than their
    clock speed, to show the continued progress. Between 2006 and 2016, Intel used
    a “tick-tock” cycle, in which their new products alternated between new digital
    logic designs (tock) and the use of new transistor technologies to make the same
    design smaller and faster (tick). *Boosts* are a feature first added in Nehalem,
    which *temporarily* increase the clock speed beyond the usual 3.5 GHz heat limit
    for short periods of time at the bottlenecks of intensive computations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 13-2:** 64-Bit Era x86 Developments'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Year** | **Maker** | **Architecture** | **Transistor size (nm)** | **Branding**
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2003 | AMD | Hammer (K8) | 130 | Opteron |'
  prefs: []
  type: TYPE_TB
- en: '| 2005 | AMD | Hammer (K8) | 90 | Athlon 64 X2 |'
  prefs: []
  type: TYPE_TB
- en: '| 2006 | Intel | Core | 65 | Celeron/Pentium/Xeon |'
  prefs: []
  type: TYPE_TB
- en: '| 2007 | AMD | 10h (K10) | 65 | Opteron |'
  prefs: []
  type: TYPE_TB
- en: '| 2008 | Intel | Nehalem | 45 | Pentium, Xeon, Core (1st generation) |'
  prefs: []
  type: TYPE_TB
- en: '| 2011 | Intel | Sandy Bridge | 32 | 2nd-generation Core i3/i5/i9; Xeon |'
  prefs: []
  type: TYPE_TB
- en: '| 2012 | AMD | Piledriver | 32 | Opteron |'
  prefs: []
  type: TYPE_TB
- en: '| 2013 | Intel | Haswell | 22 | 4th-generation Core i3/5/7; Celeron/Pentium/Xeon
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2015 | Intel | Skylake | 14 | 6th-generation Core i3/5/7; Celeron/Pentium/Xeon;
    CoreM |'
  prefs: []
  type: TYPE_TB
- en: '| 2017 | Intel | Coffee Lake | 14 | 8th-generation Core i3/5/7; Celeron/Pentium
    Gold/Xeon |'
  prefs: []
  type: TYPE_TB
- en: '| 2017 | AMD | Zen | 14 | Ryzen 3/5/7 1000 series |'
  prefs: []
  type: TYPE_TB
- en: '| 2018 | AMD | Zen+ | 12 | Ryzen 3/5/7 2000 series |'
  prefs: []
  type: TYPE_TB
- en: '| 2019 | AMD | Zen2 | 7 | Ryzen 3/5/7 3000 series |'
  prefs: []
  type: TYPE_TB
- en: '| 2020 | AMD | Zen3 | 7 | Ryzen 5/7/9 5000 series |'
  prefs: []
  type: TYPE_TB
- en: '| 2021 | Intel | Cypress Cove | 14 | 11th-generation Core i5/7/9; Xeon |'
  prefs: []
  type: TYPE_TB
- en: '| 2021 | Intel | Golden Cove | 7 | 12th-generation Core i5/7/9; Xeon |'
  prefs: []
  type: TYPE_TB
- en: '| 2022 | AMD | Zen4 | 5 | Ryzen 5/7/9 7000 series |'
  prefs: []
  type: TYPE_TB
- en: Now that we’ve seen how x86 evolved, let’s look at its instruction set and learn
    how to program it. This will be a messier experience than for the other architectures
    we’ve studied, but hopefully, by understanding the history, you can at least understand
    why things ended up this way.
  prefs: []
  type: TYPE_NORMAL
- en: Programming x86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: x86 is big and ugly; its code is usually generated by compilers rather than
    written by hand. Still, it’s worth your time to study it if you want to better
    understand what your compiler and computer are doing, or if you want to write
    compilers or other system software such as operating systems and bootloaders.
    Because x86 is such a widely used architecture, understanding it is also useful
    in security applications, such as cracking and defending code, including cheat
    and anti-cheat systems for games.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a CISC architecture, x86 often has many variations of each instruction,
    taking different types of operand, such as constants, registers, and memory locations.
    Groups of instructions have been added at different points in the architecture’s
    history, and they don’t always use the same conventions: for example, integer
    addition, integer multiplication, and floating-point operations all present very
    different interfaces to the programmer. You wouldn’t design a new CPU from scratch
    using such different interfaces; this mess is simply how the architecture has
    grown over time.'
  prefs: []
  type: TYPE_NORMAL
- en: This won’t be an exhaustive tour of x86 features. Rather, we’ll look at a couple
    of examples to give a flavor of how CISC extensions are created and how they operate.
  prefs: []
  type: TYPE_NORMAL
- en: '*Registers*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Because of the way x86 has evolved over time and its requirement for backward
    compatibility, its register set has grown into a particular form. There are two
    general types of register; let’s look at each.
  prefs: []
  type: TYPE_NORMAL
- en: '**General-Purpose Registers**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are eight general-purpose user registers in x86 architecture. Their names
    reflect their traditional uses. [Table 13-3](ch13.xhtml#ch13tab3) shows them.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 13-3:** x86 General-Purpose Registers'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Register** | **Meaning** | **Use** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AX | Accumulator register | Arithmetic operations |'
  prefs: []
  type: TYPE_TB
- en: '| BX | Base register | A pointer to data |'
  prefs: []
  type: TYPE_TB
- en: '| CX | Counter register | Shift, rotate, and loop instructions |'
  prefs: []
  type: TYPE_TB
- en: '| DX | Data register | Arithmetic and I/O operations |'
  prefs: []
  type: TYPE_TB
- en: '| SP | Stack pointer register | A pointer to the top of the stack |'
  prefs: []
  type: TYPE_TB
- en: '| BP | Stack base pointer register | A pointer to the base of the stack |'
  prefs: []
  type: TYPE_TB
- en: '| SI | Source index register | A pointer to a source for data copies |'
  prefs: []
  type: TYPE_TB
- en: '| DI | Destination index register | A pointer to a destination for data copies
    |'
  prefs: []
  type: TYPE_TB
- en: In the original 16-bit 8086, the general-purpose registers all had 16 bits.
    To retain partial backward compatibility with the previous 8-bit 8080, the first
    four—AX, BX, CX, and DX—can also be split into two 8-bit registers, named with
    H and L for high and low bytes, which can be accessed independently.
  prefs: []
  type: TYPE_NORMAL
- en: 'IA-32 extended the eight registers to have 32-bits. They can still be accessed
    as 16- or 8-bit registers as before, to maintain compatibility. To access them
    in their full 32-bit mode, we add the prefix E (for *extended*) to their names:
    EAX, EBX, ECX, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'amd64 extended the eight registers again, to 64 bits. As before, the 32-, 16-,
    and 8-bit versions are left intact for compatibility. To access them in 64-bit
    mode, we add the prefix R to their names: RAX, RBX, RCX, and so on. amd64 also
    added eight more 64-bit general-purpose registers, named R8 through R15.'
  prefs: []
  type: TYPE_NORMAL
- en: As x86 is defined as the family based on the 16-bit system, and has to retain
    backward compatibility, a *word* in x86 speak still means 16 bits of data, rather
    than the full size of the modern registers. *Doubleword* or *dword* means 32 bits,
    and *quadword* or *qword* means 64 bits.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 13-1](ch13.xhtml#ch13fig1) summarizes the evolution of the general-purpose
    x86 registers.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0310-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-1: The x86 registers. Register names are shown to the left of each
    register, apart from 8-bit register names, which are shown in the center of the
    register.*'
  prefs: []
  type: TYPE_NORMAL
- en: For compatibility with these different word sizes, memory addressing is always
    done *per byte*, even on a modern amd64\. This is in contrast to addressing, say,
    non-overlapping 64-bit *words* of memory. Words are stored in memory as little-endian
    bytes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Internal Registers**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The program counter is called the *instruction pointer* in x86 speak, identified
    as IP, EIP, or RIP when used in its 16-, 32-, or 64-bit form, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: The status register is called FLAGS, EFLAGS, or RFLAGS, again when used in 16-,
    32-, or 64-bit form. Its structure is shown in [Figure 13-2](ch13.xhtml#ch13fig2).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0310-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-2: The x86 status register (compare with [Figure 11-6](ch11.xhtml#ch11fig6))*'
  prefs: []
  type: TYPE_NORMAL
- en: This is very like the 6502’s status register, with similar mnemonics. As with
    the 6502, these flags are set with comparison instructions, then consulted with
    separate branch instructions. There are also instructions to clear flags. Two
    important flags, as in other architectures, are the zero flag (ZF) and sign flag
    (SF).
  prefs: []
  type: TYPE_NORMAL
- en: '*Netwide Assembler Syntax*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Because of its long history, x86 has acquired several different assembly languages
    with different syntaxes, which all assemble into the same machine code. Here we’ll
    use the *Netwide Assembler (NASM)* style, which is the least worst of them.
  prefs: []
  type: TYPE_NORMAL
- en: x86 instructions usually have two operands. In NASM syntax, the first is usually
    the destination and sometimes also an input that gets updated to store the result,
    like an accumulator; the second operand is an input.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like most assemblers, NASM enables us to label lines of a program with text
    labels by inserting the label as text, followed by a colon, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If a label is inserted on line 5, we can jump to or load from line 5 by using
    its label name rather than the number 5.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Movement**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To copy constants or register contents between registers and RAM, you can use
    the same `mov` (move) instruction. This generalizes all of loading, storing, and
    moving. Several different addressing modes are provided.
  prefs: []
  type: TYPE_NORMAL
- en: '*Immediate addressing* places constants into registers. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*Register addressing* copies data from one register to another inside the CPU,
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*Direct addressing* loads from and stores to memory through a specified address.
    Labels can be used in place of numerical addresses, in which context they’re known
    as *variables*. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Register indirect addressing* is notated using square brackets, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In these two instructions, RDI is assumed to contain an address that in turn
    is used to load or store the value from RAX.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Creation**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Data locations in RAM can be given names, and can be initialized or uninitialized.
    To initialize a location with a value and create a name for it, we use commands
    beginning with `d`, for *define*. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'To name an uninitialized location, we use commands beginning with `r`, for
    *reserve*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note that these aren’t x86 instructions, but rather just labeled regions of
    data, with the directives telling NASM to treat them as such.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create arrays, we simply allocate a set of consecutive addresses. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'NASM also provides macro directives, which enable you to define numeric `(equ)`
    and string `(%define)` constants:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: NASM substitutes for these constants’ values before doing the assembly. These
    macro directives aren’t part of the x86 instructions set, but NASM provides them
    for convenience.
  prefs: []
  type: TYPE_NORMAL
- en: '**Arithmetic and Logic**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As x86 instructions are usually designed to take two arguments, most arithmetic
    is done accumulator-style. There isn’t a single accumulator register, but any
    register can act like one. For example, here we place the value 1 into RBX and
    add 2 into it, so it ends up storing the result, 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'As a CISC architecture, variations of arithmetic instructions usually exist
    that combine loading data from memory with the arithmetic. For example, here’s
    how to add two numbers from addresses 1000h and 2000h and put the result in RBX:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note that x86 *doesn’t* include the most extreme CISC style of addition, such
    as `[3000h] := [1000h]+[2000h]`, which combines two loads, one addition, and one
    store in a single instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Subtraction works similarly to addition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Incrementing and decrementing 8-, 16-, or 32-bit operands can be done using
    the `inc` and `dec` instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To multiply or divide integer operands, x86 provides `mul` and `div` instructions.
    Unlike addition and subtraction, these always use the A register as the accumulator
    (hence its name) and act on it with the operand given to the instruction. For
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the last of the above examples, the prefix `i` is added to the `div` instruction
    to indicate that signed integers are used. The `cwd` instruction converts a word
    to a double by allowing the DX register to be used as an extension of AX in order
    to accommodate the sign information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bitwise logic instructions include `and, or, not`, and `xor`. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As with addition, the first operand acts as an accumulator so gets overwritten
    with the result.
  prefs: []
  type: TYPE_NORMAL
- en: '**Flow Control**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'NASM provides two types of labels, symbolic and numeric, that can both be used
    for jumps and branches. Symbolic labels consist of an identifier followed by a
    colon (:). They must be defined only once, as they have global scope. If the label
    identifier begins with a period (.), it’s considered local and can be used only
    in the current file. Here’s an infinite loop using a symbolic label and a jump:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Numeric labels consist of a single digit in the range 0 to 9 followed by a
    colon. Numeric labels are considered local. They also have limited scope so can
    be redefined repeatedly. When a numeric label is used as a reference (as an instruction
    operand, for example), the suffixes `b` (for backward) or `f` (for forward) should
    be added to the numeric label. For numeric label `1`, the reference `1b` refers
    to the nearest label `1` defined before the reference, and the reference `1f`
    refers to the nearest label `1` defined after the reference. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Conditional jumps are performed using pairs of instructions. First, we use the
    `cmp` instruction to compare two values. It takes two operands to compare and
    raises appropriate flags in the status register. Next, a conditional jump instruction
    consults the status register to determine whether or not to make the jump. Some
    of the available conditional jump types are listed in [Table 13-4](ch13.xhtml#ch13tab4).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 13-4:** x86 Conditional Jump Instructions'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Instruction** | **Condition** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `je` | Jump if `cmp` is equal |'
  prefs: []
  type: TYPE_TB
- en: '| `jne` | Jump if `cmp` is not equal |'
  prefs: []
  type: TYPE_TB
- en: '| `jg` | Signed > (greater) |'
  prefs: []
  type: TYPE_TB
- en: '| `jge` | Signed >= |'
  prefs: []
  type: TYPE_TB
- en: '| `jl` | Signed < (less than) |'
  prefs: []
  type: TYPE_TB
- en: '| `jle` | Signed <= |'
  prefs: []
  type: TYPE_TB
- en: '| `ja` | Unsigned > (above) |'
  prefs: []
  type: TYPE_TB
- en: '| `jae` | Unsigned >= |'
  prefs: []
  type: TYPE_TB
- en: '| `jb` | Unsigned < (below) |'
  prefs: []
  type: TYPE_TB
- en: '| `jbe` | Unsigned <= |'
  prefs: []
  type: TYPE_TB
- en: '| `jc` | Jump if carry (used for unsigned overflow or multi-precision add)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `jo` | Jump if there was signed overflow |'
  prefs: []
  type: TYPE_TB
- en: 'To illustrate, this program uses the `cmp` and `je` instructions to make a
    jump if the compared values are equal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Subroutines are called and returned from as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The `call` instruction jumps to the subroutine with the given label, and `ret`
    returns from the subroutine to the calling location.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Stack**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Subroutine calls and returns are implemented internally using a stack. If you’re
    just writing simple calls and returns, as in the example we just looked at, you
    don’t need to see or think about the stack yourself. However, x86 also allows
    you to access the stack directly to pass arguments or for other purposes. Specifically,
    registers SS and ESP (or SP) are provided and used for implementing the stack.
    The stack is limited to storing only words and doublewords. Here’s how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Here, the contents of registers AX and BX are pushed to the stack, meaning these
    registers can then be overwritten and used for other purposes, before being restored
    by the pop instructions.
  prefs: []
  type: TYPE_NORMAL
- en: '**X86 CALLING CONVENTIONS**'
  prefs: []
  type: TYPE_NORMAL
- en: The x86 architecture has been used with many different calling conventions during
    its history. Due to the small number of architectural registers, and a historical
    focus on simplicity and small code size, many x86 calling conventions pass arguments
    on the stack. The return value (or a pointer to it) is returned in a register.
    Some conventions use registers for the first few parameters, which may improve
    performance, especially for short and simple *leaf routines* that are very frequently
    invoked (these are routines that don’t call other routines).
  prefs: []
  type: TYPE_NORMAL
- en: For amd64, there are two current conventions in widespread use, one suggested
    by System V UNIX designers and the other by Microsoft. They agree that the caller
    rather than callee should clean up the stack. They both require the first few
    arguments to be passed in registers, with the later arguments on the stack, right
    to left, though they disagree on how many and which registers to use. They disagree
    on which registers are *temporary*—that is, which can be overwritten by the callee
    during a function call. This is in contrast to those that are *safe*, guaranteed
    to not be changed by function calls.
  prefs: []
  type: TYPE_NORMAL
- en: '**BIOS I/O**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We can call BIOS routines from ROM to communicate with the screen and keyboard,
    as on a retro computer. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This sets a screen mode, prints an ASCII character to a location on the screen,
    reads an ASCII character from the keyboard, and sets a pixel color. These are
    all the basic ingredients you need to make 8 bit–style video games. The `int`
    instructions here generate interrupt requests, which pass control to the BIOS,
    and their operands tell the BIOS which of its subroutines is to be run. These
    subroutines each assume that their arguments have been placed into particular
    registers such as AH and AL before the interrupt is made.
  prefs: []
  type: TYPE_NORMAL
- en: '**Floating Point**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The x86 floating-point architecture derives from the 8086’s old coprocessor,
    the 8087\. This was a separate, optional chip for accelerating numerical computation.
    Since the 486, the FPU moved into the main x86 architecture, where it has become
    known as the *x87 extension*.
  prefs: []
  type: TYPE_NORMAL
- en: The x87 extension adds dedicated floating-point registers called ST0 to ST7,
    which are used as a stack (hence the prefix *ST*); the stack has a maximum of
    eight elements, with ST0 being the top. New floating-point instructions start
    with the letter `F` and move data to and from this stack; they instruct the FPU
    to perform arithmetic using the top items of the stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can push floats to the x87 stack, call arithmetic on them, and pop the
    result back, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Here, when you give an ASCII representation of a float to NASM for any of the
    word lengths used, NASM knows to convert it to IEEE binary representation for
    you.
  prefs: []
  type: TYPE_NORMAL
- en: '*Segmentation*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: x86 programs can be written as collections of *segments*, which are separate
    chunks of a program that can be stored in different locations in memory. For example,
    if you wish to keep your instructions apart from your data (as in a Harvard architecture),
    you can do this by using a separate code segment and data segment. A stack segment
    can also be used to keep the hardware stack data separate from both. Segments
    all live in the same global address space, but by storing the start address of
    each segment in a dedicated register, addresses within them can afterward be referred
    to by just their offset from the segment start. This system was intended as a
    way for 16-bit CPUs to work with more than 64 k[2]B of RAM. It still exists but
    isn’t used much in modern 64-bit x86, because the 64-bit address space is so large
    anyway. Six *segment registers*, called CS, SS, DS, ES, FS, and GS, are specified
    to hold the segment start addresses.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re using the segment system, the NASM directive `section` specifies code
    and data segments. In some settings, some assemblers will still look for sections
    and assume that `section .text` is read-only and that `section .data` is read-write,
    even though the concepts are no longer used at the amd64 hardware level. A *segmentation
    fault* will occur if you try to access a segment that the assembler doesn’t want
    you to access.
  prefs: []
  type: TYPE_NORMAL
- en: '*Backward-Compatible Modes*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Part of the x86 standard is that all CPUs have to be backward-compatible with
    the original 16-bit 8086\. This means that when they first power on, they have
    to start in 16-bit mode and behave exactly like an 8086.
  prefs: []
  type: TYPE_NORMAL
- en: From there, 32-bit x86s have instructions that switch them into 32-bit mode,
    and 64-bit x86s have further instructions to switch from 32-bit to 64-bit mode.
    To boot an amd64, you therefore progressively switch up into 32- and then 64-bit
    mode, replaying the history of its architecture in a fraction of a second.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an understanding of the x86 architecture, let’s zoom out to
    consider the PC computer design that uses it as the CPU component.
  prefs: []
  type: TYPE_NORMAL
- en: PC Computer Design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The desktop PC is a different concept from the other computers we’ve studied:
    rather than specifying one particular computer design, it’s a loose collection
    of formal and informal standards. The first PCs were designed and defined as such
    by IBM, beginning in 1981 with the IBM 5150, seen in [Figure 11-1](ch11.xhtml#ch11fig1);
    they were then copied by other manufacturers using similar compatible components.'
  prefs: []
  type: TYPE_NORMAL
- en: In the 1990s, any computer with an x86 CPU capable of running a Microsoft DOS
    or Windows operating system was generally considered to be a PC. Microsoft chose
    what computer design features to support in this software, so it effectively set
    the standard definition. Other operating systems could also run on many of these
    machines while making different support choices. Often there are multiple competing
    standards for computer design features, and it becomes a political as well as
    technical question which ones get taken up by the PC community.
  prefs: []
  type: TYPE_NORMAL
- en: Programming and using PCs thus feels different than more standardized platforms.
    For example, games created for a particular machine, such as a Commodore 64, can
    assume a precise hardware feature set and will run exactly the same on any Commodore
    64\. This enables the game designer to work as an artist, making the game look
    and feel exactly as they intend. But a game made for PCs will run differently
    on different PCs with different features, requiring game designers to create what
    is really a whole set of similar games, some of which they’ll never see themselves
    and can only guess at how to implement. Similarly, game players may have to get
    more involved in configuring their hardware and software to customize which version
    of the game they want to play.
  prefs: []
  type: TYPE_NORMAL
- en: Here we’ll look at some specific examples of buses, I/O modules, and devices
    used in today’s desktop PCs. These can often form the bottlenecks in modern PCS—there’s
    little use in having a highly optimized CPU if it has to spend its time waiting
    on other parts of the system. When you buy a computer, don’t just look at CPU
    speed—think about these supporting structures, too.
  prefs: []
  type: TYPE_NORMAL
- en: '*The Bus Hierarchy*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Like CPUs, buses are continually being improved and replaced, so the PC architecture
    has used various standard bus hierarchies over time. Buses can be found in a desktop
    PC at several layers; each layer has different uses and different bandwidths,
    and is optimized for different purposes. [Table 13-5](ch13.xhtml#ch13tab5) shows
    some recent standards with their speeds and typical uses.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 13-5:** PC Bus Speeds and Uses'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Standard** | **Bandwidth (GBps)** | **Uses** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Gigabit Ethernet | 1 | Network |'
  prefs: []
  type: TYPE_TB
- en: '| USB3 | 5 | Peripherals |'
  prefs: []
  type: TYPE_TB
- en: '| SATA3 | 6 | Secondary storage |'
  prefs: []
  type: TYPE_TB
- en: '| NVMe | 32 | Secondary storage |'
  prefs: []
  type: TYPE_TB
- en: '| PCI express 5.0 x16 | 63 | Graphics cards |'
  prefs: []
  type: TYPE_TB
- en: You can see that communication with the outside world via Ethernet is at the
    slower end, local peripherals and secondary storage are in the middle, and graphics
    cards have had a lot of work done to make them communicate quickly.
  prefs: []
  type: TYPE_NORMAL
- en: The classic PC hierarchy used two structures called Northbridge and Southbridge—known
    together as the *chipset*—as the main skeleton of the bus hierarchy. This is shown
    in [Figure 13-3](ch13.xhtml#ch13fig3).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0320-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-3: The Northbridge-Southbridge bus architecture*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Northbridge* connects directly to the CPU’s FSB (front-side bus) and links
    it to RAM and to fast I/O modules using the same address space via PCIe bus. It
    also connects to Southbridge. Northbridge is fast and powerful. It was traditionally
    constructed on a separate chip from the CPU that also hosted some memory cache
    levels. More recently, Northbridge has moved onto CPU silicon in many systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Southbridge* bridges a second time, from Northbridge to slower I/O bus hierarchies.
    It’s still usually located in its own dedicated silicon chip (which is sometimes
    also called “the chipset” even when Northbridge is located on the CPU chip). Southbridge
    contains many different standard I/O modules, all printed on the same silicon.
    Here you’ll see structures such as USB controllers, hard disk controllers, and
    the older PCI (not PCIe) bus.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 2](fm03.xhtml#fig2) in the introduction shows the physical layout of
    this design on a 2010s PC mainboard. In the figure, both Northbridge and Southbridge
    are covered by large heatsinks, showing that they’re major consumers of power
    and producers of heat, just like the CPU. Compared to retro computers, there are
    few other chips remaining on the mainboard, because most of their functionality
    has migrated to either Southbridge, Northbridge, or the CPU. The rest of the mainboard
    is taken up mostly by physical connectors and analog components used in power
    management.'
  prefs: []
  type: TYPE_NORMAL
- en: With Northbridge now migrated onto the same silicon as the CPU in many cases,
    it’s become harder to identify it on more modern mainboards.
  prefs: []
  type: TYPE_NORMAL
- en: '**Standardized I/O**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A current desktop PC trend is toward standardized I/O. In the bad old days,
    every device would have its own I/O module, a physical component sitting on the
    bus. That meant that each device had its own IRQ (interrupt request) line into
    the processor. You would need a specific I/O-level driver to look after that module,
    which could be painful to configure.
  prefs: []
  type: TYPE_NORMAL
- en: Bus hierarchies such as USB have now largely solved this problem for PCs. These
    use a single I/O module, such as a USB controller, which has to be configured
    only once and uses only a single IRQ. All the devices then connect to this controller
    using a lower-level bus with its own protocol, which can include communications
    that inform the controller what the device is. They can easily share the single
    IRQ allocated to the controller.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fast Serial Buses**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the golden age, a bus meant a whole load of parallel wires, often in the
    form of a ribbon cable, as in the left of [Figure 13-4](ch13.xhtml#ch13fig4).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0321-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-4: A 1980s parallel bus ribbon cable with lots of wires (left) versus
    a fast serial 2020s connector with fewer wires*'
  prefs: []
  type: TYPE_NORMAL
- en: It’s rare to see ribbon cables nowadays, as most buses are serial, having just
    one wire for communication plus a few control and power wires, as on the right
    of [Figure 13-4](ch13.xhtml#ch13fig4). For example, SATA, SSA-SCSI, USB, and CAN
    are all serial buses.
  prefs: []
  type: TYPE_NORMAL
- en: This change was prompted by technical problems with parallel buses that arrived
    once speeds exceeded around 1Gbps. Small differences in delays on out-of-box parallel
    wires can put signals on different wires out of sync, and resynchronizing their
    data is very hard. Serial buses, on the other hand, can be made faster and faster
    as there’s no need to sync multiple wires.
  prefs: []
  type: TYPE_NORMAL
- en: '**Migration Up the Hierarchy**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As I/O modules get faster they want to move up the bus hierarchy to be closer
    to the CPU. Devices that used to hang off standardized buses, such as USB, want
    to connect directly to Southbridge; devices that used to hang off Southbridge
    want to get promoted to Northbridge; and devices that used to hang off Northbridge
    want to get promoted up into system-on-chip (SoC) silicon. At the same time, Northbridge,
    Southbridge, and standardized buses all want to increase their own speeds, meaning
    a device wanting to move from Southbridge to Northbridge, for example, might get
    overtaken by a new, faster Southbridge that makes its migration unnecessary. Since
    Moore’s law stopped the central CPU clock from getting faster, there’s been a
    big push to move innovation to all of these levels, which perhaps is making it
    a little more glamorous for the non-CPU architects who work on them.
  prefs: []
  type: TYPE_NORMAL
- en: Migration up the bus hierarchy and onto silicon makes the economics and legal
    structures of computer design harder to understand. In 8-bit times, different
    companies could make separate physical chips, such as CPU and I/O modules. Computer
    manufacturers would buy these chips, then design and build PCBs to integrate them.
    Nowadays, as more of these structures need to be fabricated together on the same
    piece of silicon, the CPU and I/O module companies need to share their designs
    with the computer manufacturer, using software files similar to LogiSim designs.
    The manufacturer then adds designs to these files to link them together, then
    sends them to a fabrication company. The units of digital logic design provided
    by each company are known as *IP (intellectual property) cores* and need to be
    closely guarded by lawyers and patent agents rather than just bought and sold
    as physical chips in plastic packages.
  prefs: []
  type: TYPE_NORMAL
- en: '*Common Buses*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most of the space on mainboards is now taken up by connectors rather than chips,
    as you saw in [Figure 2](fm03.xhtml#fig2) of the introduction. The connectors
    seen in that figure are typical of other parts of the bus hierarchy. We’ll examine
    some of the main ones next.
  prefs: []
  type: TYPE_NORMAL
- en: '**Peripheral Component Interconnect Express Bus**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: PCIe (not to be confused with the older PCI) stands for Peripheral Component
    Interconnect Express and is a general-purpose bus for connecting graphics and
    other cards. PCIe comes in several flavors, as shown in [Figure 13-5](ch13.xhtml#ch13fig5);
    the connectors have physically different widths because they have different numbers
    of lanes.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0322-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-5: Some PCIe bus connectors*'
  prefs: []
  type: TYPE_NORMAL
- en: You can get various powers of 2 between 1 and 32 lanes, depending on how much
    data you want to transfer. PCIe also comes in different generations, with speeds
    going from 250MBps to 2GBps per lane.
  prefs: []
  type: TYPE_NORMAL
- en: Like many modern “buses,” PCIe began as an actual bus—in which many nodes share
    the same set of wires, each with its own address—but has evolved into a mesh network,
    with nodes now performing some routing to avoid congestion on the bus.
  prefs: []
  type: TYPE_NORMAL
- en: '**SCSI and SATA Buses**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SCSI and SATA are competing buses for mass storage devices (for example, hard
    disks). The Small Computer System Interface (SCSI, pronounced “scuzzy”) is a very
    ancient, classic, well-tested, reliable, and expensive standard, dating from the
    1980s. It pioneered moving compute work for I/O control from CPU into digital
    logic in the I/O module, freeing up the CPU to work on other tasks more quickly.
    It’s used today in servers. SCSI has been through many versions; the latest update
    is Serial Storage Architecture (SSA), a serial bus version.
  prefs: []
  type: TYPE_NORMAL
- en: Serial Advanced Technology Attachment (SATA) is cheaper and simpler than SCSI.
    For these reasons, it’s used in most consumer systems rather than SCSI.
  prefs: []
  type: TYPE_NORMAL
- en: '**Universal Serial Bus**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *Universal Serial “Bus” (USB)* is the one you’re probably most familiar
    with. However, USB isn’t a bus at all—it’s not even a mesh network. It’s actually
    a point-to-point connector, intended to upgrade the older serial port.
  prefs: []
  type: TYPE_NORMAL
- en: Before USB was invented, whenever you got a new piece of hardware you would
    spend a day trying to get the device driver working and configuring the IRQ lines.
    USB now makes all of this instant so you can “plug and play” many devices. USB
    is designed so that devices can be connected and disconnected while the computer
    is turned on, and part of its standard defines a generic method for devices to
    state their type and model over the basic USB protocol itself rather than requiring
    a device driver. This enables computer software to automatically see what’s been
    plugged in, and in many cases to download and run the appropriate drivers for
    it without intervention.
  prefs: []
  type: TYPE_NORMAL
- en: USB also defines standards for requesting and sending power down the wires.
    A USB cable has four wires, two for sending a serial signal and two for power.
    There are 5 V and a ground in there, so, for example, you can use the same USB
    cable to charge your mobile phone and exchange data with it.
  prefs: []
  type: TYPE_NORMAL
- en: All of this is done through a centralized USB controller, which is a single
    I/O module, so you don’t have to worry about IRQs anymore. The USB controller
    itself has an IRQ, but then everything else is hanging off a USB network. There
    have been different versions of USB, including USB 1 running at 12Mbps and USB
    3 running at 5Gbps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike some point-to-point networks, USB connections have a manager end and
    a worker end, with the manager in charge of the communications protocol. If you
    plug a USB memory stick into your computer, your computer is the manager. As the
    worker, your USB stick can’t take over and start sending its own requests to copy
    data from your computer. This is why USB wires have different endings: one end
    plugs into the manager that controls it and the other end goes into the worker,
    and you can’t connect them the other way around.'
  prefs: []
  type: TYPE_NORMAL
- en: '*On-the-go (OTG)* is part of the USB protocol that allows a worker device to
    act as a manager via a physical adapter. Sometimes you do want to connect them
    the wrong way around. For example, when you connect your smartphone to your computer,
    you usually want it to be the worker, like a USB stick, with your computer as
    the manager. But other times you want the phone to be the manager, such as when
    connecting a memory stick or sound card to it.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ethernet**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Ethernet*, in its oldest and simplest form, is a true bus, with multiple PCs
    in a local area network all writing and reading on public wires. Each message
    is packaged as a “frame,” containing the address (Media Access Control, or MAC,
    address) of the recipient. Senders must take care to avoid collisions—that is,
    people talking at the same time—by watching the bus and waiting for a suitable
    time to transmit. Everyone can see everything on the bus, so it’s easy to “sniff”
    the bus and spy on other users.'
  prefs: []
  type: TYPE_NORMAL
- en: Modern networks build non-bus features on top of the basic Ethernet bus structure.
    For example, rather than connecting all computers in a building to a single shared
    Ethernet bus, it’s now common for each to connect only to a central *switch* using
    a dedicated Ethernet cable. The switch receives all messages that are sent, but
    rather than forwarding them, bus-style, to all machines on the network, it forwards
    them only to the intended destination.
  prefs: []
  type: TYPE_NORMAL
- en: '*Standard Devices*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Your desktop PC wouldn’t be complete without some other standard devices. To
    complete our study of PCs, let’s take a quick look at how these have evolved.
  prefs: []
  type: TYPE_NORMAL
- en: '**Flat-Screen Displays**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Modern flat-screen displays are used in mobile phone screens and large-screen
    TVs and monitors. They’re made from transistors and capacitors, laid down like
    chips by photolithography masks and gas processes. Many rare elements are used
    to produce the specific red, green, and blue light-emitting pixels, including
    yttrium, lanthanum, terbium, praseodymium, europium, dysprosium, and gadolinium.
    Some of these are so rare that they can be mined only in one or two places. Many
    specific combinations of electronics and elements have been used as display “technologies,”
    including TFT. The latest at the time of writing is organic LED (OLED).
  prefs: []
  type: TYPE_NORMAL
- en: '**Graphics Cards**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the 1980s, graphics was simple. An area of memory was allocated to represent
    the array of pixels on the screen. User programs would write to it like any other
    part of memory. Then a graphics chip would read from it and turn the data into
    CRT scanning commands to send to the monitor. Now things are more complicated,
    as programmers expect graphics hardware to provide commands for complex rendering
    of 2D and 3D shapes without taking up CPU time.
  prefs: []
  type: TYPE_NORMAL
- en: To respond to this demand, the modern graphics processing unit (GPU) evolved
    from 1980s visual display units (VDUs). Rather than taking commands to light up
    pixels, GPUs typically take commands to render 3D triangles with sprite-like textures,
    and to shade them using complex lighting models.
  prefs: []
  type: TYPE_NORMAL
- en: If you’ve been playing video games over the last couple of decades, you’ll have
    seen the visual abilities of GPUs evolve with Moore’s law, doubling in quality
    and getting closer to photorealistic, real-time rendering.
  prefs: []
  type: TYPE_NORMAL
- en: The GPU traditionally sits on one of the buses of the mainboard, such as PCI,
    AGP, or PCIe. GPUs have been the one part of computer architecture that’s been
    getting physically bigger rather than shrinking over the years, starting off as
    a small chip and now most likely a full card ([Figure 13-6](ch13.xhtml#ch13fig6)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0325-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-6: A 2022 Nvidia RTX 3080 GPU*'
  prefs: []
  type: TYPE_NORMAL
- en: There has, however, also been a recent trend to shrink GPUs back to put on a
    single chip on the mainboard, or onto the same silicon as the CPU. This is particularly
    the case in machines where the GPU isn’t the main focus, such as generic business
    PCs where the graphics requirements don’t extend much beyond displaying the desktop.
  prefs: []
  type: TYPE_NORMAL
- en: Graphics cards sit on the system bus as I/O modules. Importantly, they can use
    direct memory access (DMA). For example, an image can be placed in regular RAM,
    then a single command can be given to the GPU to load it from main RAM into the
    GPU. This DMA action doesn’t go through the CPU, so from the CPU’s point of view
    it’s almost instant. (It will, however, slow down if the bus is needed for other
    things, such as additional DMAs from a webcam into the main RAM.)
  prefs: []
  type: TYPE_NORMAL
- en: Early GPUs were designed to accelerate rendering of the popular OpenGL 3D graphics
    API by implementing its commands directly in hardware, beginning with a memory-mapped
    area and a chip that read that area and figured out how to display that memory
    block on the screen. In the 2000s, in addition to or instead of memory-mapped
    graphics, optional plug-in graphics cards sat on the system bus as I/O modules
    and drew graphics in response to compiled and assembled commands of graphics languages
    such as OpenGL or DirectX, sent to them via the system bus. Graphics cards were
    labeled and sold as implementing one or more of these language interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: A 3D graphics language usually assumes that 3D objects are composed of many
    small triangles. Triangles are chosen because their three points always lie in
    a plane, making the math easier. Their implementations, in hardware and/or software,
    usually split into two main parts, known as *shaders*. First, vertex calculations
    convert the 3D coordinates of each vertex into 2D pixel coordinates. Second, pixel
    calculations compute the color (shade) of each display pixel.
  prefs: []
  type: TYPE_NORMAL
- en: The latter can be done in many different ways according to different mathematical
    models of how surfaces and lights interact. Most shaders allow triangles to be
    translucent (partly transparent), modeled via an alpha channel in their RGBA color,
    as discussed on [page 68](ch02.xhtml#page_68). Some shaders allow normal (orthogonal)
    vectors to be described for each triangle as a hint that they’re part of smooth,
    continuous surfaces.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 13-7](ch13.xhtml#ch13fig7) shows the results of three traditional shaders
    built into early OpenGL implementations, rendering the same triangle mesh approximation
    to a sphere.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0326-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-7: Traditional OpenGL shaders: flat (left), Gouraud (center), and
    Phong (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: Graphics users demanded more flexibility in shaders. New shading models are
    often proposed in graphics research, and users wanted them to be quickly available
    in their own systems. The graphics languages rapidly gained many extension commands
    in their later versions, to enable particular additional shaders, and graphics
    card architects struggled to keep up with designing new hardware to implement
    them and make them compatible with one another. These architects instead began
    to open up new and simpler shader languages (such as GLSL) to enable these and
    other arbitrary shaders to be implemented in user programs, and executed on the
    graphics card—now known as a GPU—via their own ISAs. This allowed programmers—especially
    game designers and movie studios—to create their own custom shaders to give their
    creations a more individual feel, as in the examples in [Figure 13-8](ch13.xhtml#ch13fig8).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0326-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-8: Custom shaders: water effects from* 0 A.D. *(left), “toon” shading
    (center), and retro CRT emulation (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: Today’s graphics systems have continued this architectural trend, with GPUs
    now functioning as highly general parallel processors of their own instruction
    sets, and the graphics-specific shaders moved into software. Former hardware interfaces
    including OpenGL and DirectX are now implemented in software, written in the GPU’s
    own assembly and machine code. Such code can now also be generated directly by
    other graphics tools, such as Wayland compositors and the Vulkan SPIR-V language.
    The resulting GPU machine code is sent over the bus to the graphics card, where
    it runs on the GPU. We’ll study this code in more detail in [Chapter 15](ch15.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: '**Sound Cards**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Unlike retro sound chips, such as the SID, modern sound cards don’t generate
    signals at all. Instead, they manage the flow of quantized, digital sound wave
    signals. As a result, computers have lost their characteristic sound effects and
    musical culture: modern game music can consist of ordinary recordings of orchestras
    or rock bands rather than any particular “computer music.” Like graphics cards,
    sound cards are always now under OS control, so user programmers are unlikely
    to see much of their architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: A modern sound card is really just a group of digital-to-analog converters (DACs),
    and indeed it’s possible to make your own from any DAC, such as the one found
    on a Labjack, a software-defined radio, or an Arduino Due. Typically, professional
    sound cards are optimized for low latency, sound quality, and many channels, while
    consumer cards are optimized for lower cost. Human hearing has a maximum frequency
    of around 20 kHz, which requires a 40 kHz sampling rate to be represented accurately.
    It’s common to use 48 kHz to allow some wiggle room and because it’s almost a
    power of 2\. Professional systems may use higher rates to reduce the buildup of
    audible errors from repeated processing.
  prefs: []
  type: TYPE_NORMAL
- en: Sound card hardware typically consists of a ring buffer for each channel, as
    well as DAC hardware, which reads or writes to and from it. A ring buffer maintains
    a pointer to the next location to write, and wraps the storage around the ring
    so space doesn’t run out. The buffer size provides a trade-off between latency
    and dropouts. A small buffer means low latency but risks dropouts. We can also
    choose the bit depth of the audio.
  prefs: []
  type: TYPE_NORMAL
- en: Sound cards, like graphics cards, connect to the system bus. They’re less bandwidth-hungry
    than video, so they’re usually found on a bus hanging off of Southbridge, such
    as PCI for internal cards or USB or Firewire for external cards.
  prefs: []
  type: TYPE_NORMAL
- en: Sound card I/O protocols vary by manufacturer, and like GPUs, their details
    may be proprietary and known only to the driver writers inside the company, who
    then make a software API available. As with GPUs, the hardware or software interfaces
    are then reverse engineered by open source driver writers, who wrap them in generic
    software APIs such as *ALSA*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Keyboards and Mice**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Modern keyboards are nothing like the memory-mapped keyboards of the 1980s.
    They now contain small, embedded computers (see [Figure 13-9](ch13.xhtml#ch13fig9)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0328-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-9: The key pressure sensors and embedded system inside a modern
    keyboard*'
  prefs: []
  type: TYPE_NORMAL
- en: The keyboard’s embedded computer is actually doing a lot of work, similar to
    a typical Arduino application. It takes the matrix of key presses, converts them
    to a keycode data representation scheme, and transmits them over a virtual serial
    port wrapped in USB protocol.
  prefs: []
  type: TYPE_NORMAL
- en: Something similar has happened with mice. A modern optical mouse performs some
    extremely complicated real-time machine vision processing known as *optic flow*
    on a dedicated internal embedded system. If you try to implement optic flow in
    software, you’ll find it’s hard to do fast. It’s still a research area, with recent
    implementations in software libraries such as OpenCV. In a mouse, however, it’s
    implemented directly as low-level digital electronics, as in [Figure 13-10](ch13.xhtml#ch13fig10).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0328-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-10: The inside of an optical mouse*'
  prefs: []
  type: TYPE_NORMAL
- en: This digital logic is just about simple enough for you to still be able to see
    the connections. You can see from the overall, fairly homogeneous structure that
    it’s processing a region of 2D space—the image underneath the mouse. It tracks
    how light and dark areas of this image are moving around and from that infers
    the movement of the mouse.
  prefs: []
  type: TYPE_NORMAL
- en: There’s also usually a USB controller attached to the device. This is actually
    a complex embedded system—possibly a computer in its own right—and the fact that
    it’s now available for a few dollars in every mouse is very impressive.
  prefs: []
  type: TYPE_NORMAL
- en: '**THE PC BOOT PROCESS**'
  prefs: []
  type: TYPE_NORMAL
- en: The term *booting* comes from the paradoxical expression “pulling yourself up
    by your bootstraps.” It means starting with nothing and getting into a complex
    computer system by having small programs execute that load slightly larger and
    more powerful programs, in a sequence. On both retro systems and modern PCs, this
    begins by the CPU fetching an instruction from a hardwired ROM address.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike retro computers, modern PCs aren’t made from standard components; instead,
    they are assembled from many different optional components, such as RAM modules
    of various types, caches, and I/O extension cards. It’s not initially obvious
    where all these things are, how they should be initialized, or how they should
    be mounted in the address space. To address this, the modern PC boot process is
    split into two parts.
  prefs: []
  type: TYPE_NORMAL
- en: First, a *bootloader* such as *coreboot* is burned into ROM firmware, at the
    address of the CPU’s initial program counter. For x86, this is ffff,fff0[16].
    This is a 16-bit address, because x86 processors always power on in “legacy mode”
    (Intel calls it “real mode”), which makes them behave like 1980s 16-bit chips
    for backward compatibility. In this mode, only 1 M[2]B of combined ROM and RAM
    memory is addressable, and the initial program counter address is near the top
    of it. The bootloader runs from here and is responsible for inspecting, initializing,
    and assigning addresses to the available hardware. The boot-loader doesn’t display
    anything onscreen because there aren’t yet any routines available for doing I/O.
    Because it’s invisible, it can be hard to understand all the hard work the bootloader
    is doing.
  prefs: []
  type: TYPE_NORMAL
- en: Second, after this initialization, the bootloader performs a jump to code in
    the BIOS. The BIOS, as in a retro computer, contains subroutines for basic I/O
    such as ASCII character display, keyboard reading, and hard disk access. At this
    stage, your PC can look and feel much like a retro computer.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, the BIOS code jumped to from the bootloader will print a few strings
    on the screen, such as the name and logo of the BIOS. A PC BIOS ROM and an example
    of BIOS display I/O capabilities are shown here.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0330-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A BIOS will usually first offer the user the chance to “go into the BIOS” by
    pressing a key, which will call graphical routines for setting configuration options.
    One of these options is usually to give the name of a storage device whose first
    data contains the next program to be loaded and jumped to, usually at address
    7c00[16]. What this program does is up to you—a common first move is to switch
    the x86 up into 32-, then 64-bit modes.
  prefs: []
  type: TYPE_NORMAL
- en: There was a time when different x86 BIOS manufacturers all made different and
    incompatible libraries of routines, but they’ve now converged on two standards.
    One, PCBIOS, was defined by IBM (who just call it “BIOS”) in early x86 PCs. It
    was cloned by other manufacturers and is still used by many x86 machines today.
    SeaBIOS is an open source implementation. The other standard, UEFI, is more recent.
    It assumes more advanced graphics and I/O are available, so its library of routines
    includes higher resolution and more colorful graphics, and access to additional
    devices such as USB. TianoCore is an open source implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: No one would design a modern desktop PC to have its current form if they were
    able to start from scratch. Like many successful commercial, real-world systems,
    the PC has evolved over time as new features have been requested and bolted on,
    while existing customers demand backward compatibility. As a result, both the
    x86 architecture and PC computer design have accumulated layers of legacy features.
    The CISC philosophy is a good fit for this environment. It’s common for multiple
    competing standards to be supported within single designs, even including multiple
    choices for x86 assemblers including but not limited to NASM. Recent x86 has extended
    beyond the features seen in this chapter by adding parallelization, which we’ll
    examine in [Chapter 15](ch15.xhtml). But before this, we’ll take a breather by
    looking at developments in the cleaner, more beautiful world of RISC in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Creating a Bootable ISO Image**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Here you’ll create a simple 16-bit “Hello, world!” program, assemble it with
    NASM into executable machine code, then store this machine code in an ISO file,
    an image of the contents of a physical secondary storage device that you can use
    to boot a real PC or a virtual machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the following *hello16bit.asm* file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you’re using Microsoft Windows, these commands can be run by installing
    and using the Windows Subsystem for Linux. If you don’t already have NASM, install
    it from* [https://nasm.us](https://nasm.us). *You may also need to install mkisofs
    for your system.*'
  prefs: []
  type: TYPE_NORMAL
- en: If everything worked, you’ll now have a *cd.iso* file for booting a physical
    or virtual x86 machine. This will allow you to run on “bare metal” x86, without
    an operating system getting in the way.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We’ll discuss how to boot into your ISO file in the next exercises. When you
    do, you should see something like [Figure 13-11](ch13.xhtml#ch13fig11) on the
    screen.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0332-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-11: The result of booting into a bare metal test program*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before going any further, let’s look at what *hello16bit.asm* actually does.
    In addition to actual x86 instruction mnemonics, a NASM program usually also includes
    some directives, which are lines that aren’t assembled themselves but instead
    tell NASM to change its behaviors in various ways. The `section` directive tells
    NASM to change which segment of the output file to write the next assembled instructions
    to. In some file formats, the number and names of sections are fixed; in others,
    the user may make up as many as they wish. The Unix object and bin formats all
    support the standardized section names `.text` (contains executable instructions),
    `.data` (contains initialized variables), and `.bss` (contains uninitialized variables).
    The ASCII string includes special ASCII codes 13, 10, and 0 after the human readable
    letters. What are these? (Hint: See [Chapter 2](ch02.xhtml).)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Booting on a Virtual x86**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The ISO can be booted on a virtual machine as if it were a physical disk. Follow
    these steps to try it out using the VirtualBox virtual machine. (Open source Linux
    users may prefer to use virt-manager at *[https://virt-manager.org](https://virt-manager.org)*.)
  prefs: []
  type: TYPE_NORMAL
- en: Visit *[https://www.virtualbox.org](https://www.virtualbox.org)* for instructions
    on how to install VirtualBox on your system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once installed, create a new virtual machine by clicking the **New** icon; use
    the default settings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start your virtual machine and “insert” your bootable virtual CD by selecting
    your *cd.iso* file when asked.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Booting on a Physical x86**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The ISO can also be booted on a physical x86 machine if you first “burn” it
    onto a physical USB stick. Here’s how:'
  prefs: []
  type: TYPE_NORMAL
- en: Use a program such as Etcher (*[https://www.balena.io](https://www.balena.io)*)
    for your current operating system to burn the ISO to a USB stick.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you have a bootable USB stick, you need to tell your PC to boot from it.
    Your PC is probably currently configured to boot from a hard disk, but it will
    have some method—which varies by manufacturer—to change to booting from USB as
    part of its BIOS configuration tools. Editing these settings is called “going
    into the BIOS.” On most machines it’s done by holding down a particular key for
    a few seconds as you turn on the machine. This is often ESC, DEL, F1, F2, F8,
    F10, or F11, depending on the manufacturer (if it doesn’t say which, try running
    a finger over the whole top row of the keyboard to hit them all). You’ll usually
    see some low-resolution BIOS menus: if you hunt around, there will be some way
    to specify the boot order and bring USB to the top of it. Some machines may have
    additional security features that need to be disabled before you can boot from
    a new device.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Booting to and Programming in 64-Bit Mode**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Switching a modern x86 into 32- and 64-bit modes isn’t trivial. Due to historical
    baggage, it requires a couple of screens of instructions and data. How these work
    is fairly obscure, but luckily it’s a standard process that can now be done using
    the boilerplate code shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'If you save this, assemble it, and put it into an ISO as for the 16-bit version,
    it will boot your real or virtual x86 into 64-bit mode and print another “Hello,
    world!” message. You can then use the “Hello, world!” program as a starting point,
    modifying it into your own bootable programs for the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Write a subroutine that reads integers and converts them into ASCII strings.
    Extend it to floating point. Use it to print out some numbers along with “Hello,
    world!”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try porting previous programs from the Analytical Engine and Manchester Baby
    to run on x86\. What’s gotten easier or harder to do in modern x86 compared to
    those systems?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Call the BIOS routine to light up pixels on the screen several times to draw
    a simple shape.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**More Challenging**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Write a simple game such as *Space Invaders* using the above BIOS calls, on
    bare metal x86.
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For the official NASM manual, see “NASM: The Netwide Assembler,” *[https://www.nasm.us/xdoc/2.13.03/html/nasmdoc0.html](https://www.nasm.us/xdoc/2.13.03/html/nasmdoc0.html)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For an overview of x86 history, see P. Lilly, “A Brief History of CPUs: 31
    Awesome Years of x86,” *Maximum PC*, April 2009, *[https://www.pcgamer.com/a-brief-history-of-cpus-31-awesome-years-of-x86](https://www.pcgamer.com/a-brief-history-of-cpus-31-awesome-years-of-x86)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the full five-volume amd64 reference set, see AMD Technology, *AMD64 Architecture
    Programmer’s Manual Volumes 1–5* (Santa Clara: AMD Technology, 2023), *[https://www.amd.com/en/support/tech-docs/amd64-architecture-programmers-manual-volumes-1-5](https://www.amd.com/en/support/tech-docs/amd64-architecture-programmers-manual-volumes-1-5)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For information on 3D graphics programming, see Graham Sellars, *Vulkan Programming
    Guide* (Boston: Addison-Wesley, 2017).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For details of how the x86 boot assembly code works, see Gregor Brunmar, “The
    World of Protected Mode” (*[http://www.osdever.net/tutorials/view/the-world-of-protected-mode](http://www.osdever.net/tutorials/view/the-world-of-protected-mode)*),
    the lame_bootloader GitHub repository (*[https://github.com/sedflix/lame_bootloader](https://github.com/sedflix/lame_bootloader)*),
    and “Setting Up Long Mode” (*[https://wiki.osdev.org/Setting_Up_Long_Mode](https://wiki.osdev.org/Setting_Up_Long_Mode)*).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
