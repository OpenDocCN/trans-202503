<html><head></head><body>
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="105" id="Page_105"/>3</span><br/>
<span class="ChapterTitle">Memory Access and Organization</span></h1>
</header>
<figure class="opener">
<img src="image_fi/book_art/chapterart.png" alt=""/>
</figure>
<p class="ChapterIntro"><span class="xref" itemid="xref_target_Chapters 1 and 2">Chapters 1 and 2</span> showed you how to declare and access simple variables in an assembly language program. This chapter fully explains x86-64 memory access. In this chapter, you will learn how to efficiently organize your variable declarations to speed up access to their data. You’ll also learn about the x86-64 stack and how to manipulate data on it.</p>
<p>This chapter discusses several important concepts, including the following:</p>
<ul>
<li>Memory organization</li>
<li>Memory allocation by program</li>
<li>x86-64 memory addressing modes</li>
<li><span epub:type="pagebreak" title="106" id="Page_106"/>Indirect and scaled-indexed addressing modes</li>
<li>Data type coercion</li>
<li>The x86-64 stack</li>
</ul>
<p>This chapter will teach to you make efficient use of your computer’s memory resources.</p>
<h2 id="h1-501089c03-0001">	3.1	Runtime Memory Organization</h2>
<p class="BodyFirst">A running program uses memory in many ways, depending on the data’s type. Here are some common data classifications you’ll find in an assembly language program:</p>
<p class="ListHead"><b>Code</b></p>
<ol class="none">
<li>Memory values that encode machine instructions.</li>
</ol>
<p class="ListHead"><b>Uninitialized static data</b></p>
<ol class="none">
<li>An area in memory that the program sets aside for uninitialized variables that exist the whole time the program runs; Windows will initialize this storage area to 0s when it loads the program into memory.</li>
</ol>
<p class="ListHead"><b>Initialized static data</b></p>
<ol class="none">
<li>A section of memory that also exists the whole time the program runs. However, Windows loads values for all the variables appearing in this section from the program’s executable file so they have an initial value when the program first begins execution.</li>
</ol>
<p class="ListHead"><b>Read-only data</b></p>
<ol class="none">
<li>Similar to initialized static data insofar as Windows loads initial data for this section of memory from the executable file. However, this section of memory is marked <em>read-only</em> to prevent inadvertent modification of the data. Programs typically store constants and other unchanging data in this section of memory (by the way, note that the code section is also marked read-only by the operating system).</li>
</ol>
<p class="ListHead"><b>Heap</b></p>
<ol class="none">
<li>This special section of memory is designated to hold dynamically allocated storage. Functions such as C’s <code>malloc()</code> and <code>free()</code> are responsible for allocating and deallocating storage in the heap area. <span class="xref" itemid="xref_target_“Pointer Variables and Dynamic Memory Allocation” in Chapter 4">“Pointer Variables and Dynamic Memory Allocation” in Chapter 4</span> discusses dynamic storage allocation in greater detail.</li>
</ol>
<p class="ListHead"><b>Stack</b></p>
<ol class="none">
<li>In this special section in memory, the program maintains local variables for procedures and functions, program state information, and other transient data. See <span class="xref" itemid="xref_target_“The Stack Segment and the push and pop Instructions” on page 134">“The Stack Segment and the push and pop Instructions” on page 134</span> for more information about the stack section.</li>
</ol>
<p><span epub:type="pagebreak" title="107" id="Page_107"/>These are the typical sections you will find in common programs (assembly language or otherwise). Smaller programs won’t use all of these sections (code, stack, and data sections are a good minimum number). Complex programs may create additional sections in memory for their own purposes. Some programs may combine several of these sections together. For example, many programs will combine the code and read-only sections into the same section in memory (as the data in both sections gets marked as read-only). Some programs combine the uninitialized and initialized data sections together (<em>initializing</em> the uninitialized variables to 0). Combining sections is generally handled by the linker program. See the Microsoft linker documentation for more details on combining sections.<sup class="FootnoteReference"><a id="c03-footnoteref-1" href="#c03-footnote-1">1</a></sup></p>
<p>Windows tends to put different types of data into different sections (or <em>segments</em>) of memory. Although it is possible to reconfigure memory as you choose by running the linker and specifying various parameters, by default Windows loads a MASM program into memory by using an organization similar to that in <a href="#figure3-1" id="figureanchor3-1">Figure 3-1</a>.<sup class="FootnoteReference"><a id="c03-footnoteref-2" href="#c03-footnote-2">2</a></sup></p>
<figure>
<img src="image_fi/501089c03/f03001.png" alt="f03001" class=""/>
<figcaption><p><a id="figure3-1">Figure 3-1</a>: MASM typical runtime memory organization</p></figcaption>
</figure>
<p>Windows reserves the lowest memory addresses. Generally, your application cannot access data (or execute instructions) at these low addresses. One reason the operating system reserves this space is to help trap NULL pointer references: if you attempt to access memory location 0 (NULL), the operating system will generate a <em>general protection fault</em> (also known as a <em>segmentation fault</em>), meaning you’ve accessed a memory location that doesn’t contain valid data.</p>
<p>The remaining six areas in the memory map hold different types of data associated with your program. These sections of memory include the stack section, the heap section, the <code>.code</code> section, the <code>.data</code> (static) section, <span epub:type="pagebreak" title="108" id="Page_108"/>the <code>.const</code> section, and the <code>.data?</code> (storage) section. Each corresponds to a type of data you can create in your MASM programs. The <code>.code</code>, <code>.data</code>, <code>.const</code>, and <code>.data?</code> sections are described next in detail.<sup class="FootnoteReference"><a id="c03-footnoteref-3" href="#c03-footnote-3">3</a></sup></p>
<h3 id="h2-501089c03-0001">3.1.1	The .code Section</h3>
<p class="BodyFirst">The <code>.code</code> section contains the machine instructions that appear in a MASM program. MASM translates each machine instruction you write into a sequence of one or more byte values. The CPU interprets these byte values as machine instructions during program execution.</p>
<p>By default, when MASM links your program, it tells the system that your program can execute instructions and read data from the code segment but cannot write data to the code segment. The operating system will generate a general protection fault if you attempt to store any data into the code segment.</p>
<h3 id="h2-501089c03-0002">3.1.2	The .data Section</h3>
<p class="BodyFirst">The <code>.data</code> section is where you will typically put your variables. In addition to declaring static variables, you can also embed lists of data into the <code>.data</code> declaration section. You use the same technique to embed data into your <code>.data</code> section that you use to embed data into the <code>.code</code> section: you use the <code>byte</code>, <code>word</code>, <code>dword</code>, <code>qword</code>, and so on, directives. Consider the following example:</p>
<pre><code>    .data
b   byte    0
    byte    1,2,3

u   dword   1
    dword   5,2,10;

c   byte   ?
    byte   'a', 'b', 'c', 'd', 'e', 'f';

bn  byte   ?
    byte   true  ; Assumes true is defined as "1"</code></pre>
<p>Values that MASM places in the <code>.data</code> memory segment by using these directives are written to the segment after the preceding variables. For example, the byte values <code>1</code>, <code>2</code>, and <code>3</code> are emitted to the <code>.data</code> section after <code>b</code>’s <code>0</code> byte. Because there aren’t any labels associated with these values, you do not have direct access to them in your program. You can use the indexed addressing modes to access these extra values.</p>
<p>In the preceding examples, note that the <code>c</code> and <code>bn</code> variables do not have an (explicit) initial value. However, if you don’t provide an initial <span epub:type="pagebreak" title="109" id="Page_109"/>value, MASM will initialize the variables in the <code>.data</code> section to 0, so MASM assigns the NULL character (ASCII code 0) to <code>c</code> as its initial value. Likewise, MASM assigns false as the initial value for <code>bn</code> (assuming false is defined as <code>0</code>). Variable declarations in the <code>.data</code> section always consume memory, even if you haven’t assigned them an initial value. </p>
<h3 id="h2-501089c03-0003">3.1.3	The .const Section</h3>
<p class="BodyFirst">The <code>.const</code> data section holds constants, tables, and other data that your program cannot change during execution. You create read-only objects by declaring them in the <code>.const</code> declaration section. The <code>.const</code> section is similar to the <code>.data</code> section, with three differences:</p>
<ul>
<li>The <code>.const</code> section begins with the reserved word <code>.const</code> rather than <code>.data</code>.</li>
<li>All declarations in the <code>.const</code> section have an initializer.</li>
<li>The system does not allow you to write data to variables in a <code>.const</code> object while the program is running.</li>
</ul>
<p>Here’s an example:</p>
<pre><code>        .const
pi      real4     3.14159
e       real4     2.71
MaxU16  word      65535
MaxI16  sword     32767</code></pre>
<p>All <code>.const</code> object declarations must have an initializer because you cannot initialize the value under program control. For many purposes, you can treat <code>.const</code> objects as literal constants. However, because they are actually memory objects, they behave like (read-only) <code>.data</code> objects. You cannot use a <code>.const</code> object anywhere a literal constant is allowed; for example, you cannot use them as displacements in addressing modes (see <span class="xref" itemid="xref_target_“The x86-64 Addressing Modes” on page 122">“The x86-64 Addressing Modes” on page 122</span>), and you cannot use them in constant expressions. In practice, you can use them anywhere that reading a <code>.data</code> variable is legal.</p>
<p>As with the <code>.data</code> section, you may embed data values in the <code>.const</code> section by using the <code>byte</code>, <code>word</code>, <code>dword</code>, and so on, data declarations, though all declarations must be initialized. For example:</p>
<pre><code>        .const
roArray byte     0
        byte     1, 2, 3, 4, 5
qwVal   qword    1
        qword    0</code></pre>
<p>Note that you can also declare constant values in the <code>.code</code> section. Data values you declare in this section are also read-only objects, as Windows write-protects the <code>.code</code> section. If you do place constant declarations in the <code>.code</code> section, you should take care to place them in a location that the program will not attempt to execute as code (such as after a <code>jmp</code> or <code>ret</code> <span epub:type="pagebreak" title="110" id="Page_110"/>instruction). Unless you’re manually encoding x86 machine instructions using data declarations (which would be rare, and done only by expert programmers), you don’t want your program to attempt to execute data as machine instructions; the result is usually undefined.<sup class="FootnoteReference"><a id="c03-footnoteref-4" href="#c03-footnote-4">4</a></sup></p>
<h3 id="h2-501089c03-0004">3.1.4	The .data? Section</h3>
<p class="BodyFirst">The <code>.const</code> section requires that you initialize all objects you declare. The <code>.data</code> section lets you optionally initialize objects (or leave them uninitialized, in which case they have the default initial value of <code>0</code>). The <code>.data?</code> section lets you declare variables that are always uninitialized when the program begins running. The <code>.data?</code> section begins with the <code>.data?</code> reserved word and contains variable declarations without initializers. Here is an example:</p>
<pre><code>            .data?
UninitUns32 dword  ?
i           sdword ?
character   byte   ?
b           byte   ?</code></pre>
<p>Windows will initialize all <code>.data?</code> objects to 0 when it loads your program into memory. However, it’s probably not a good idea to depend on this implicit initialization. If you need an object initialized with 0, declare it in a <code>.data</code> section and explicitly set it to 0.</p>
<p>Variables you declare in the <code>.data?</code> section may consume less disk space in the executable file for the program. This is because MASM writes out initial values for <code>.const</code> and <code>.data</code> objects to the executable file, but it may use a compact representation for uninitialized variables you declare in the <code>.data?</code> section; note, however, that this behavior is dependent on the OS version and object-module format.</p>
<h3 id="h2-501089c03-0005">3.1.5	Organization of Declaration Sections Within Your Programs</h3>
<p class="BodyFirst">The <code>.data</code>, <code>.const</code>, <code>.data?</code>, and <code>.code</code> sections may appear zero or more times in your program. The declaration sections may appear in any order, as the following example demonstrates:</p>
<pre><code>           .data
i_static   sdword    0

           .data?
i_uninit   sdword    ?

           .const
i_readonly dword     5

<span epub:type="pagebreak" title="111" id="Page_111"/>           .data
j          dword     ?

           .const
i2         dword     9

           .data?
c          byte      ?

           .data?
d          dword     ?

           .code

      <var>Code goes here</var>

            end</code></pre>
<p>The sections may appear in an arbitrary order, and a given declaration section may appear more than once in your program. As noted previously, when multiple declaration sections of the same type (for example, the three <code>.data?</code> sections in the preceding example) appear in a declaration section of your program, MASM combines them into a single group (in any order it pleases).</p>
<h3 id="h2-501089c03-0006">3.1.6	Memory Access and 4K Memory Management Unit Pages</h3>
<p class="BodyFirst">The x86-64’s <em>memory </em><em>management unit (</em><em>MMU)</em> divides memory into blocks known as <em>pages</em>.<sup class="FootnoteReference"><a id="c03-footnoteref-5" href="#c03-footnote-5">5</a></sup> The operating system is responsible for managing pages in memory, so application programs don’t typically worry about page organization. However, you should be aware of a couple of issues when working with pages in memory: specifically, whether the CPU even allows access to a given memory location and whether it is read/write or read-only (write-protected).</p>
<p>Each program section appears in memory in contiguous MMU pages. That is, the <code>.const</code> section begins at offset 0 in an MMU page and sequentially consumes pages in memory for all the data appearing in that section. The next section in memory (perhaps <code>.data</code>) begins at offset 0 in the next MMU page following the last page of the previous section. If that previous section (for example, <code>.const</code>) did not consume an integral multiple of 4096 bytes, padding space will be present between the end of that section’s data to the end of its last page (to guarantee that the next section begins on an MMU page boundary).</p>
<p>Each new section starts in its own MMU page because the MMU controls access to memory by using page <em>granularity</em>. For example, the MMU controls whether a page in memory is readable/writable or read-only. For <code/><span epub:type="pagebreak" title="112" id="Page_112"/>.const sections, you want the memory to be read-only. For the <code>.data</code> section, you want to allow reads and writes. Because the MMU can enforce these attributes only on a page-by-page basis, you cannot have <code>.data</code> section information in the same MMU page as a <code>.const</code> section.</p>
<p>Normally, all of this is completely transparent to your code. Data you declare in a <code>.data</code> (or <code>.data?</code>) section is readable and writable, and data in a <code>.const</code> section (and <code>.code</code> section) is read-only (<code>.code</code> sections are also <em>executable</em>). Beyond placing data in a particular section, you don’t have to worry too much about the page attributes.</p>
<p>You do have to worry about MMU page organization in memory in one situation. Sometimes it is convenient to access (read) data beyond the end of a data structure in memory (for legitimate reasons—see <span class="xref" itemid="xref_target_Chapter 11">Chapter 11</span> on SIMD instructions and <span class="xref" itemid="xref_target_Chapter 14">Chapter 14</span> on string instructions). However, if that data structure is aligned with the end of an MMU page, accessing the next page in memory could be problematic. Some pages in memory are <em>inaccessible</em>; the MMU does not allow reading, writing, or execution to occur on that page. </p>
<p>Attempting to do so will generate an x86-64 <em>general protection (segmentation) fault</em> and abort the normal execution of your program.<sup class="FootnoteReference"><a id="c03-footnoteref-6" href="#c03-footnote-6">6</a></sup> If you have a data access that crosses a page boundary, and the next page in memory is inaccessible, this will crash your program. For example, consider a word access to a byte object at the very end of an MMU page, as shown in <a href="#figure3-2" id="figureanchor3-2">Figure 3-2</a>.</p>
<figure>
<img src="image_fi/501089c03/f03002.png" alt="f03002" class=""/>
<figcaption><p><a id="figure3-2">Figure 3-2</a>: Word access at the end of an MMU page</p></figcaption>
</figure>
<p>As a general rule, you should never read data beyond the end of a data structure.<sup class="FootnoteReference"><a id="c03-footnoteref-7" href="#c03-footnote-7">7</a></sup> If for some reason you need to do so, you should ensure that it is legal to access the next page in memory (alas, there is no instruction on modern x86-64 CPUs to allow this; the only way to be sure that access is legal is to make sure there is valid data after the data structure you are accessing).</p>
<h2 id="h1-501089c03-0002"><span epub:type="pagebreak" title="113" id="Page_113"/>	3.2	How MASM Allocates Memory for Variables</h2>
<p class="BodyFirst">MASM associates a current <em>location counter</em> with each of the four declaration sections (<code>.code</code>, <code>.data</code>, <code>.const</code>, and <code>.data?</code>). These location counters initially contain <code>0</code>, and whenever you declare a variable in one of these sections (or write code in a code section), MASM associates the current value of that section’s location counter with the variable; MASM also bumps up the value of that location counter by the size of the object you’re declaring. As an example, assume that the following is the only <code>.data</code> declaration section in a program:</p>
<pre><code>    .data
b   byte   ?        ; Location counter = 0,  size = 1
w   word   ?        ; Location counter = 1,  size = 2
d   dword  ?        ; Location counter = 3,  size = 4
q   qword  ?        ; Location counter = 7,  size = 8
o   oword  ?        ; Location counter = 15, size = 16
                    ; Location counter is now 31</code></pre>
<p>As you can see, the variable declarations appearing in a (single) <code>.data</code> section have contiguous offsets (location counter values) into the <code>.data</code> section. Given the preceding declaration, <code>w</code> will immediately follow <code>b</code> in memory, <code>d</code> will immediately follow <code>w</code> in memory, <code>q</code> will immediately follow <code>d</code>, and so on. These offsets aren’t the actual runtime address of the variables. At runtime, the system loads each section to a (base) address in memory. The linker and Windows add the base address of the memory section to each of these location counter values (which we call <em>displacements</em>, or <em>offsets</em>) to produce the actual memory address of the variables.</p>
<p>Keep in mind that you may link other modules with your program (for example, from the C Standard Library) or even additional <code>.data</code> sections in the same source file, and the linker has to merge the <code>.data</code> sections together. Each section has its own location counter that also starts from zero when allocating storage for the variables in the section. Hence, the offset of an individual variable may have little bearing on its final memory address. </p>
<p>Remember that MASM allocates memory objects you declare in <code>.const</code>, <code>.data</code>, and <code>.data?</code> sections in completely different regions of memory. Therefore, you cannot assume that the following three memory objects appear in adjacent memory locations (indeed, they probably will not):</p>
<pre><code>    .data
b   byte   ?

    .const
w   word    1234h

    .data?
d   dword   ?</code></pre>
<p><span epub:type="pagebreak" title="114" id="Page_114"/>In fact, MASM will not even guarantee that variables you declare in separate <code>.data</code> (or whatever) sections are adjacent in memory, even if there is nothing between the declarations in your code. For example, you cannot assume that <code>b</code>, <code>w</code>, and <code>d</code> are in adjacent memory locations in the following declarations, nor can you assume that they <em>won’t</em> be adjacent in memory:</p>
<pre><code>    .data
b   byte   ?

    .data
w   word   1234h

    .data
d   dword  ?</code></pre>
<p>If your code requires these variables to consume adjacent memory locations, you must declare them in the same <code>.data</code> section.</p>
<h2 id="h1-501089c03-0003">	3.3	The Label Declaration</h2>
<p class="BodyFirst">The <code>label</code> declaration lets you declare variables in a section (<code>.code</code>, <code>.data</code>, <code>.const</code>, and <code>.data?</code>) without allocating memory for the variable. The <code>label</code> directive tells MASM to assign the current address in a declaration section to a variable but not to allocate any storage for the object. That variable shares the same memory address as the next object appearing in the variable declaration section. Here is the syntax for the <code>label</code> declaration:</p>
<pre><code><var>variable_name</var> label <var>type</var></code></pre>
<p>The following code sequence provides an example of using the <code>label</code> declaration in the <code>.const</code> section:</p>
<pre><code>        .const
abcd    label   dword
        byte 'a', 'b', 'c', 'd'</code></pre>
<p>In this example, <code>abcd</code> is a double word whose LO byte contains 97 (the ASCII code for <code>a</code>), byte 1 contains 98 (<code>b</code>), byte 2 contains 99 (<code>c</code>), and the HO byte contains 100 (<code>d</code>). MASM does not reserve storage for the <code>abcd</code> variable, so MASM associates the following 4 bytes in memory (allocated by the <code>byte</code> directive) with <code>abcd</code>.</p>
<h2 id="h1-501089c03-0004">	3.4	Little-Endian and Big-Endian Data Organization</h2>
<p class="BodyFirst">Back in <span class="xref" itemid="xref_target_“The Memory Subsystem” in Chapter 1">“The Memory Subsystem” in Chapter 1</span>, this book pointed out that the x86-64 stores multi-byte data types in memory with the LO byte at the lowest address in memory and the HO byte at the highest address in memory (see <a href="c01.xhtml#figure1-5">Figure 1-5</a> in Chapter 1). This type of data organization in memory is known as <em>little endian</em>. Little-endian data organization (in which the LO <span epub:type="pagebreak" title="115" id="Page_115"/>byte comes first and the HO byte comes last) is a common memory organization shared by many modern CPUs. It is not, however, the only possible data organization.</p>
<p>The <em>big-endian</em> data organization reverses the order of the bytes in memory. The HO byte of the data structure appears first (in the lowest memory address), and the LO byte appears in the highest memory address. Tables 3-1, 3-2, and 3-3 describe the memory organization for words, double words, and quad words, respectively.</p>
<figure>
<figcaption class="TableTitle"><p><a id="table3-1">Table 3-1</a>: Word Object Little- and Big-Endian Data Organizations</p></figcaption>
<table id="table-501089c03-0001" border="1">
<thead>
<tr>
<td><b>Data byte</b></td>
<td><b>Memory organization for little endian</b></td>
<td><b>Memory organization for big endian</b></td>
</tr>
</thead>
<tbody>
<tr>
<td>0 (LO byte)</td>
<td>base + 0</td>
<td>base + 1</td>
</tr>
<tr>
<td>1 (HO byte)</td>
<td>base + 1</td>
<td>base + 0</td>
</tr>
</tbody>
</table>
</figure>
<figure>
<figcaption class="TableTitle"><p><a id="table3-2">Table 3-2</a>: Double-Word Object Little- and Big-Endian Data Organizations</p></figcaption>
<table id="table-501089c03-0002" border="1">
<thead>
<tr>
<td><b>Data byte</b></td>
<td><b>Memory organization for little endian</b></td>
<td><b>Memory organization for big endian</b></td>
</tr>
</thead>
<tbody>
<tr>
<td>0 (LO byte)</td>
<td>base + 0</td>
<td>base + 3</td>
</tr>
<tr>
<td>1 </td>
<td>base + 1</td>
<td>base + 2</td>
</tr>
<tr>
<td>2</td>
<td>base + 2</td>
<td>base + 1</td>
</tr>
<tr>
<td>3 (HO byte)</td>
<td>base + 3</td>
<td>base + 0</td>
</tr>
</tbody>
</table>
</figure>
<figure>
<figcaption class="TableTitle"><p><a id="table3-3">Table 3-3</a>: Quad-Word Object Little- and Big-Endian Data Organizations</p></figcaption>
<table id="table-501089c03-0003" border="1">
<thead>
<tr>
<td><b>Data byte</b></td>
<td><b>Memory organization for little endian</b></td>
<td><b>Memory organization for big endian</b></td>
</tr>
</thead>
<tbody>
<tr>
<td>0 (LO byte)</td>
<td>base + 0</td>
<td>base + 7</td>
</tr>
<tr>
<td>1 </td>
<td>base + 1</td>
<td>base + 6</td>
</tr>
<tr>
<td>2</td>
<td>base + 2</td>
<td>base + 5</td>
</tr>
<tr>
<td>3 </td>
<td>base + 3</td>
<td>base + 4</td>
</tr>
<tr>
<td>4</td>
<td>base + 4</td>
<td>base + 3</td>
</tr>
<tr>
<td>5</td>
<td>base + 5</td>
<td>base + 2</td>
</tr>
<tr>
<td>6</td>
<td>base + 6</td>
<td>base + 1</td>
</tr>
<tr>
<td>7 (HO byte)</td>
<td>base + 7</td>
<td>base + 0</td>
</tr>
</tbody>
</table>
</figure>
<p>Normally, you wouldn’t be too concerned with big-endian memory organization on an x86-64 CPU. However, on occasion you may need to deal with data produced by a different CPU (or by a protocol, such as TCP/IP, that uses big-endian organization as its canonical integer format). If you were to load a big-endian value in memory into a CPU register, your calculations would be incorrect.</p>
<p><span epub:type="pagebreak" title="116" id="Page_116"/>If you have a 16-bit big-endian value in memory and you load it into a 16-bit register, it will have its bytes swapped. For 16-bit values, you can correct this issue by using the <code>xchg</code> instruction. It has the syntax</p>
<pre><code>xchg <var>reg</var>, <var>reg</var>
xchg <var>reg</var>, <var>mem</var></code></pre>
<p class="BodyContinued">where <var>reg</var> is any 8-, 16-, 32-, or 64-bit general-purpose register, and <var>mem</var> is any appropriate memory location. The <var>reg</var> operands in the first instruction, or the <var>reg</var> and <var>mem</var> operands in the second instruction, must both be the same size.</p>
<p>Though you can use the <code>xchg</code> instruction to exchange the values between any two arbitrary (like-sized) registers, or a register and a memory location, it is also useful for converting between (16-bit) little- and big-endian formats. For example, if AX contains a big-endian value that you would like to convert to little-endian form prior to some calculations, you can use the following instruction to swap the bytes in the AX register to convert the value to little-endian form:</p>
<pre><code>xchg al, ah</code></pre>
<p>You can use the <code>xchg</code> instruction to convert between little- and big-endian form for any of the 16-bit registers AX, BX, CX, and DX by using the low/high register designations (AL/AH, BL/BH, CL/CH, and DL/DH).</p>
<p>Unfortunately, the <code>xchg</code> trick doesn’t work for registers other than AX, BX, CX, and DX. To handle larger values, Intel introduced the <code>bswap</code> (<em>byte swap</em>) instruction. As its name suggests, this instruction swaps the bytes in a 32- or 64-bit register. It swaps the HO and LO bytes, and the (HO – 1) and (LO + 1) bytes (plus all the other bytes, in opposing pairs, for 64-bit registers). The <code>bswap</code> instruction works for all general-purpose 32-bit and 64-bit registers.</p>
<h2 id="h1-501089c03-0005">	3.5	Memory Access</h2>
<p class="BodyFirst">As you saw in <span class="xref" itemid="xref_target_“The Memory Subsystem” in Chapter 1">“The Memory Subsystem” in Chapter 1</span>, the x86-64 CPU fetches data from memory on the data bus. In an idealized CPU, the data bus is the size of the standard integer registers on the CPU; therefore, you would expect the x86-64 CPUs to have a 64-bit data bus. In practice, modern CPUs often make the physical data bus connection to main memory much larger in order to improve system performance. The bus brings in large chunks of data from memory in a single operation and places that data in the CPU’s <em>cache</em>, which acts as a buffer between the CPU and physical memory. </p>
<p>From the CPU’s point of view, the cache <em>is</em> memory. Therefore, when the remainder of this section discusses memory, it’s generally talking about data sitting in the cache. As the system transparently maps memory accesses into the cache, we can discuss memory as though the cache were not present and discuss the advantages of the cache as necessary.</p>
<p><span epub:type="pagebreak" title="117" id="Page_117"/>On early x86 processors, memory was arranged as an array of bytes (8-bit machines such as the 8088), words (16-bit machines such as the 8086 and 80286), or double words (on 32-bit machines such as the 80386). On a 16-bit machine, the LO bit of the address did not physically appear on the address bus. So the addresses 126 and 127 put the same bit pattern on the address bus (126, with an implicit <code>0</code> in bit position 0), as shown in <a href="#figure3-3" id="figureanchor3-3">Figure 3-3</a>.<sup class="FootnoteReference"><a id="c03-footnoteref-8" href="#c03-footnote-8">8</a></sup> </p>
<figure>
<img src="image_fi/501089c03/f03003.png" alt="f03003" class=""/>
<figcaption><p><a id="figure3-3">Figure 3-3</a>: Address and data bus for 16-bit processors</p></figcaption>
</figure>
<p>When reading a byte, the CPU uses the LO bit of the address to select the LO byte or HO byte on the data bus. <a href="#figure3-4" id="figureanchor3-4">Figure 3-4</a> shows the process when accessing a byte at an even address (126 in this figure). <a href="#figure3-5" id="figureanchor3-5">Figure 3-5</a> shows the same operation when reading a byte from an odd address (127 in this figure). Note that in both Figures 3-4 and 3-5, the address appearing on the address bus is 126.</p>
<figure>
<img src="image_fi/501089c03/f03004.png" alt="f03004" class=""/>
<figcaption><p><a id="figure3-4">Figure 3-4</a>: Reading a byte from an even address on a 16-bit CPU</p></figcaption>
</figure>
<span epub:type="pagebreak" title="118" id="Page_118"/><figure>
<img src="image_fi/501089c03/f03005.png" alt="f03005" class=""/>
<figcaption><p><a id="figure3-5">Figure 3-5</a>: Reading a byte from an odd address on a 16-bit CPU</p></figcaption>
</figure>
<p>So, what happens when this 16-bit CPU wants to access 16 bits of data at an odd address? For example, suppose in these figures the CPU reads the word at address 125. When the CPU puts address 125 on the address bus, the LO bit doesn’t physically appear. Therefore, the actual address on the bus is 124. If the CPU were to read the LO 8 bits off the data bus at this point, it would get the data at address 124, not address 125.</p>
<p>Fortunately, the CPU is smart enough to figure out what is going on here, and extracts the data from the HO 8 bits on the address bus and uses this as the LO 8 bits of the data operand. However, the HO 8 bits that the CPU needs are not found on the data bus. The CPU has to initiate a second read operation, placing address 126 on the address bus, to get the HO 8 bits (which will be sitting in the LO 8 bits of the data bus, but the CPU can figure that out). The bottom line is that it takes two memory cycles for this read operation to complete. Therefore, the instruction reading the data from memory will take longer to execute than had the data been read from an address that was an integral multiple of two.</p>
<p>The same problem exists on 32-bit processors, except the 32-bit data bus allows the CPU to read 4 bytes at a time. Reading a 32-bit value at an address that is not an integral multiple of four incurs the same performance penalty. Note, however, that accessing a 16-bit operand at an odd address doesn’t always guarantee an extra memory cycle—only addresses whose remainder when divided by four is 3 incur the penalty. In particular, if you access a 16-bit value (on a 32-bit bus) at an address where the LO 2 bits contain 01b, the CPU can read the word in a single memory cycle, as shown in <a href="#figure3-6" id="figureanchor3-6">Figure 3-6</a>.</p>
<p>Modern x86-64 CPUs, with cache systems, have largely eliminated this problem. As long as the data (1, 2, 4, 8, or 10 bytes in size) is fully within a cache line, there is no memory cycle penalty for an unaligned access. If the access does cross a cache line boundary, the CPU will run a bit slower while it executes two memory operations to get (or store) the data.</p>
<span epub:type="pagebreak" title="119" id="Page_119"/><figure>
<img src="image_fi/501089c03/f03006.png" alt="f03006" class=""/>
<figcaption><p><a id="figure3-6">Figure 3-6</a>: Accessing a word on a 32-bit data bus</p></figcaption>
</figure>
<h2 id="h1-501089c03-0006">	3.6	MASM Support for Data Alignment</h2>
<p class="BodyFirst">To write fast programs, you need to ensure that you properly align data objects in memory. Proper <em>alignment</em> means that the starting address for an object is a multiple of a certain size, usually the size of an object if the object’s size is a power of 2 for values up to 32 bytes in length. For objects greater than 32 bytes, aligning the object on an 8-, 16-, or 32-byte address boundary is probably sufficient. For objects fewer than 16 bytes, aligning the object at an address that is the next power of 2 greater than the object’s size is usually fine. Accessing data that is not aligned at an appropriate address may require extra time (as noted in the previous section); so, if you want to ensure that your program runs as rapidly as possible, you should try to align data objects according to their size.</p>
<p>Data becomes misaligned whenever you allocate storage for different-sized objects in adjacent memory locations. For example, if you declare a byte variable, it will consume 1 byte of storage, and the next variable you declare in that declaration section will have the address of that byte object plus 1. If the byte variable’s address happens to be an even address, the variable following that byte will start at an odd address. If that following variable is a word or double-word object, its starting address will not be optimal. In this section, we’ll explore ways to ensure that a variable is aligned at an appropriate starting address based on that object’s size.</p>
<p>Consider the following MASM variable declarations:</p>
<pre><code>    .data
dw  dword  ?
b   byte   ?
w   word   ?
dw2 dword  ?
w2  word   ?
b2  byte   ?
dw3 dword  ?</code></pre>
<p><span epub:type="pagebreak" title="120" id="Page_120"/>The first <code>.data</code> declaration in a program (running under Windows) places its variables at an address that is an even multiple of 4096 bytes. Whatever variable first appears in that <code>.data</code> declaration is guaranteed to be aligned on a reasonable address. Each successive variable is allocated at an address that is the sum of the sizes of all the preceding variables plus the starting address of that <code>.data</code> section. Therefore, assuming MASM allocates the variables in the previous example at a starting address of <code>4096</code>, MASM will allocate them at the following addresses:</p>
<pre><code>                    ; Start Adrs       Length
dw    dword  ?      ;     4096           4
b     byte   ?      ;     4100           1
w     word   ?      ;     4101           2
dw2   dword  ?      ;     4103           4
w2    word   ?      ;     4107           2
b2    byte   ?      ;     4109           1
dw3   dword  ?      ;     4110           4</code></pre>
<p>With the exception of the first variable (which is aligned on a 4KB boundary) and the byte variables (whose alignment doesn’t matter), all of these variables are misaligned. The <code>w</code>, <code>w2</code>, and <code>dw2</code> variables start at odd addresses, and the <code>dw3</code> variable is aligned on an even address that is not a multiple of four.</p>
<p>An easy way to guarantee that your variables are aligned properly is to put all the double-word variables first, the word variables second, and the byte variables last in the declaration, as shown here:</p>
<pre><code>      .data
dw    dword  ?
dw2   dword  ?
dw3   dword  ?
w     word   ?
w2    word   ?
b     byte   ?
b2    byte   ?</code></pre>
<p>This organization produces the following addresses in memory:</p>
<pre><code>                  ; Start Adrs          Length
dw    dword   ?   ;     4096              4
dw2   dword   ?   ;     4100              4
dw3   dword   ?   ;     4104              4
w     word    ?   ;     4108              2
w2    word    ?   ;     4110              2
b     byte    ?   ;     4112              1
b2    byte    ?   ;     4113              1</code></pre>
<p>As you can see, these variables are all aligned at reasonable addresses. Unfortunately, it is rarely possible for you to arrange your variables in this <span epub:type="pagebreak" title="121" id="Page_121"/>manner. While many technical reasons make this alignment impossible, a good practical reason for not doing this is that it doesn’t let you organize your variable declarations by logical function (that is, you probably want to keep related variables next to one another regardless of their size).</p>
<p>To resolve this problem, MASM provides the <code>align</code> directive, which uses the following syntax:</p>
<pre><code>align <var>integer_constant</var></code></pre>
<p>The integer constant must be one of the following small unsigned integer values: 1, 2, 4, 8, or 16. If MASM encounters the <code>align</code> directive in a <code>.data</code> section, it will align the very next variable on an address that is an even multiple of the specified alignment constant. The previous example could be rewritten, using the <code>align</code> directive, as follows:</p>
<pre><code>     .data
     align  4
dw   dword  ?
b    byte   ?
     align  2
w    word   ?
     align  4
dw2  dword  ?
w2   word   ?
b2   byte   ?
     align  4
dw3  dword  ?</code></pre>
<p>If MASM determines that the current address (location counter value) of an <code>align</code> directive is not an integral multiple of the specified value, MASM will quietly emit extra bytes of padding after the previous variable declaration until the current address in the <code>.data</code> section is a multiple of the specified value. This makes your program slightly larger (by a few bytes) in exchange for faster access to your data. Given that your program will grow by only a few bytes when you use this feature, this is probably a good trade-off.</p>
<p>As a general rule, if you want the fastest possible access, you should choose an alignment value that is equal to the size of the object you want to align. That is, you should align words to even boundaries by using an <code>align 2</code> statement, double words to 4-byte boundaries by using <code>align 4</code>, quad words to 8-byte boundaries by using <code>align 8</code>, and so on. If the object’s size is not a power of 2, align it to the next higher power of 2 (up to a maximum of 16 bytes). Note, however, that you need only align <code>real80</code> (and <code>tbyte</code>) objects on an 8-byte boundary.</p>
<p>Note that data alignment isn’t always necessary. The cache architecture of modern x86-64 CPUs actually handles most misaligned data. Therefore, you should use the alignment directives only with variables for which speedy access is absolutely critical. This is a reasonable space/speed trade-off.</p>
<h2 id="h1-501089c03-0007"><span epub:type="pagebreak" title="122" id="Page_122"/>	3.7	The x86-64 Addressing Modes</h2>
<p class="BodyFirst">Until now, you’ve seen only a single way to access a variable: the <em>PC-relative</em> addressing mode. In this section, you’ll see additional ways your programs can access memory by using x86-64 memory addressing modes. An <em>addressing mode</em> is a mechanism the CPU uses to determine the address of a memory location an instruction will access.</p>
<p>The x86-64 memory addressing modes provide flexible access to memory, allowing you to easily access variables, arrays, records, pointers, and other complex data types. Mastery of the x86-64 addressing modes is the first step toward mastering x86-64 assembly language.</p>
<p>The x86-64 provides several addressing modes:</p>
<ul>
<li>Register addressing modes</li>
<li>PC-relative memory addressing modes</li>
<li>Register-indirect addressing modes: <code>[</code><var>reg</var><span class="SubscriptLiteral">64</span><code>]</code></li>
<li>Indirect-plus-offset addressing modes: <code>[</code><var>reg</var><span class="SubscriptLiteral">64 </span><code>+ </code><var>expression</var><code>]</code></li>
<li>Scaled-indexed addressing modes: <code>[</code><var>reg</var><span class="SubscriptLiteral">64 </span><code>+ </code><var>reg</var><span class="SubscriptLiteral">64 </span><code>* </code><var>scale</var><code>]</code> and <code>[</code><var>reg</var><span class="SubscriptLiteral">64 </span><code>+ </code><var>expression </var><code>+ </code><var>reg</var><span class="SubscriptLiteral">64 </span><code>* </code><var>scale</var><code>]</code></li>
</ul>
<p>The following sections describe each of these modes.</p>
<h3 id="h2-501089c03-0007">3.7.1	x86-64 Register Addressing Modes</h3>
<p class="BodyFirst">The <em>register addressing modes</em> provide access to the x86-64’s general-purpose register set. By specifying the name of the register as an operand to the instruction, you can access the contents of that register. This section uses the x86-64 <code>mov</code> (<em>move</em>) instruction to demonstrate the register addressing mode. The generic syntax for the <code>mov</code> instruction is shown here:</p>
<pre><code>mov <var>destination</var>, <var>source</var></code></pre>
<p>The <code>mov</code> instruction copies the data from the <var>source</var> operand to the <var>destination</var> operand. The 8-, 16-, 32-, and 64-bit registers are all valid operands for this instruction. The only restriction is that both operands must be the same size. The following <code>mov</code> instructions demonstrate the use of various registers:</p>
<pre><code>mov ax, bx          ; Copies the value from BX into AX
mov dl, al          ; Copies the value from AL into DL
mov esi, edx        ; Copies the value from EDX into ESI
mov rsp, rbp        ; Copies the value from RBP into RSP
mov ch, cl          ; Copies the value from CL into DH
mov ax, ax          ; Yes, this is legal! (Though not very useful)</code></pre>
<p>The registers are the best place to keep variables. Instructions using the registers are shorter and faster than those that access memory. Because most computations require at least one register operand, the register addressing mode is popular in x86-64 assembly code.</p>
<h3 id="h2-501089c03-0008"><span epub:type="pagebreak" title="123" id="Page_123"/>3.7.2	x86-64 64-Bit Memory Addressing Modes</h3>
<p class="BodyFirst">The addressing modes provided by the x86-64 family include PC-relative, register-indirect, indirect-plus-offset, and scaled-indexed. Variations on these four forms provide all the addressing modes on the x86-64.</p>
<h4 id="h3-501089c03-0001">3.7.2.1	The PC-Relative Addressing Mode</h4>
<p class="BodyFirst">The most common addressing mode, and the one that’s easiest to understand, is the <em>PC-relative</em> (or <em>RIP-relative</em>) addressing mode. This mode consists of a 32-bit constant that the CPU adds with the current value of the RIP (instruction pointer) register to specify the address of the target location. </p>
<p>The syntax for the PC-relative addressing mode is to use the name of a symbol you declare in one of the many MASM sections (<code>.data</code>, <code>.data?</code>, <code>.const</code>, <code>.code</code>, etc.), as this book has been doing all along:</p>
<pre><code>mov al, symbol  ; PC-relative addressing mode automatically provides [RIP]</code></pre>
<p>Assuming that variable <code>j</code> is an <code>int8</code> variable appearing at offset 8088h from RIP, the instruction <code>mov al, j</code> loads the AL register with a copy of the byte at memory location RIP + 8088h. Likewise, if <code>int8</code> variable <code>K</code> is at address RIP + 1234h in memory, then the instruction <code>mov K, dl</code> stores the value in the DL register to memory location RIP + 1234h (see <a href="#figure3-7" id="figureanchor3-7">Figure 3-7</a>).</p>
<figure>
<img src="image_fi/501089c03/f03007.png" alt="f03007" class=""/>
<figcaption><p><a id="figure3-7">Figure 3-7</a>: PC-relative addressing mode</p></figcaption>
</figure>
<p>MASM does not directly encode the address of <code>j</code> or <code>K</code> into the instruction’s <em>operation code</em> (or <em>opcode</em>, the numeric machine encoding of the instruction). Instead, it encodes a signed displacement from the end of the current instruction’s address to the variable’s address in memory. For example, if the next instruction’s opcode is sitting in memory at location 8000h (the end of the current instruction), then MASM will encode the value 88h as a 32-bit signed constant for <code>j</code> in the instruction opcode.</p>
<p>You can also access words and double words on the x86-64 processors by specifying the address of their first byte (see <a href="#figure3-8" id="figureanchor3-8">Figure 3-8</a>).</p>
<span epub:type="pagebreak" title="124" id="Page_124"/><figure>
<img src="image_fi/501089c03/f03008.png" alt="f03008" class=""/>
<figcaption><p><a id="figure3-8">Figure 3-8</a>: Accessing a word or dword by using the PC-relative addressing mode</p></figcaption>
</figure>
<h4 id="h3-501089c03-0002">3.7.2.2	The Register-Indirect Addressing Modes</h4>
<p class="BodyFirst">The x86-64 CPUs let you access memory indirectly through a register by using the <em>register-indirect</em> addressing modes. The term <em>indirect</em> means that the operand is not the actual address, but the operand’s value specifies the memory address to use. In the case of the register-indirect addressing modes, the value held in the register is the address of the memory location to access. For example, the instruction <code>mov [rbx], eax</code> tells the CPU to store EAX’s value at the location whose address is currently in RBX (the square brackets around RBX tell MASM to use the register-indirect addressing mode).</p>
<p>The x86-64 has 16 forms of this addressing mode. The following instructions provide examples of these 16 forms:</p>
<pre><code>mov [<var>reg</var><sub>64</sub>], al </code></pre>
<p class="BodyContinued">where <var>reg</var><span class="SubscriptLiteral">64</span> is one of the 64-bit general-purpose registers: RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP, R8, R9, R10, R11, R12, R13, R14, or R15. This addressing mode references the memory location at the offset found in the register enclosed by brackets.</p>
<p>The register-indirect addressing modes require a 64-bit register. You cannot specify a 32-, 16-, or 8-bit register in the square brackets when using an indirect addressing mode. Technically, you could load a 64-bit register with an arbitrary numeric value and access that location indirectly using the register-indirect addressing mode:</p>
<pre><code>mov rbx, 12345678
mov [rbx], al   ; Attempts to access location 12345678</code></pre>
<p>Unfortunately (or fortunately, depending on how you look at it), this will probably cause the operating system to generate a protection fault because it’s not always legal to access arbitrary memory locations. As it turns out, there are better ways to load the address of an object into a register, and you’ll see those shortly.</p>
<p><span epub:type="pagebreak" title="125" id="Page_125"/>You can use the register-indirect addressing modes to access data referenced by a pointer, you can use them to step through array data, and, in general, you can use them whenever you need to modify the address of a variable while your program is running.</p>
<p>The register-indirect addressing mode provides an example of an <em>anonymous</em> variable; when using a register-indirect addressing mode, you refer to the value of a variable by its numeric memory address (the value you load into a register) rather than by the name of the variable.</p>
<p>MASM provides a simple instruction that you can use to take the address of a variable and put it into a 64-bit register, the <code>lea</code> (<em>load effective address</em>) instruction:</p>
<pre><code>lea rbx, j</code></pre>
<p>After executing this <code>lea</code> instruction, you can use the <code>[rbx]</code> register-indirect addressing mode to indirectly access the value of <code>j</code>.</p>
<h4 id="h3-501089c03-0003">3.7.2.3	Indirect-Plus-Offset Addressing Mode</h4>
<p class="BodyFirst">The indirect-plus-offset addressing modes compute an <em>effective address</em> by adding a 32-bit signed constant to the value of a 64-bit register.<sup class="FootnoteReference"><a id="c03-footnoteref-9" href="#c03-footnote-9">9</a></sup> The instruction then uses the data at this effective address in memory.</p>
<p>The indirect-plus-offset addressing modes use the following syntax:</p>
<pre><code>mov [<var>reg</var><sub>64</sub> + <var>constant</var>], <var>source</var>
mov [<var>reg</var><sub>64</sub> - <var>constant</var>], <var>source</var></code></pre>
<p class="BodyContinued">where<var> reg</var><span class="SubscriptLiteral">64</span> is a 64-bit general-purpose register, <var>constant</var> is a 4-byte constant (±2 billion), and <var>source</var> is a register or constant value.</p>
<p>If <var>constant</var> is 1100h and RBX contains 12345678h, then</p>
<pre><code>mov [rbx + 1100h], al</code></pre>
<p class="BodyContinued">stores AL into the byte at address 12346778h in memory (see <a href="#figure3-9" id="figureanchor3-9">Figure 3-9</a>).</p>
<figure>
<img src="image_fi/501089c03/f03009.png" alt="f03009" class=""/>
<figcaption><p><a id="figure3-9">Figure 3-9</a>: Indirect-plus-offset addressing mode</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="126" id="Page_126"/>The indirect-plus-offset addressing modes are really handy for accessing fields of classes and records/structures. You will see how to use these addressing modes for that purpose in <span class="xref" itemid="xref_target_Chapter 4">Chapter 4</span>.</p>
<h4 id="h3-501089c03-0004">3.7.2.4	Scaled-Indexed Addressing Modes</h4>
<p class="BodyFirst">The <em>scaled-indexed addressing modes</em> are similar to the indexed addressing modes, except the scaled-indexed addressing modes allow you to combine two registers plus a displacement, and multiply the index register by a (scaling) factor of 1, 2, 4, or 8 to compute the effective address by adding in the value of the second register multiplied by the scaling factor. (<a href="#figure3-10" id="figureanchor3-10">Figure 3-10</a> shows an example involving RBX as the base register and RSI as the index register.)</p>
<p>The syntax for the scaled-indexed addressing modes is shown here:</p>
<pre><code>[<var>base_reg</var><sub>64</sub> + <var>index_reg</var><sub>64</sub>*<var>scale</var>]
[<var>base_reg</var><sub>64</sub> + <var>index_reg</var><sub>64</sub>*<var>scale</var> + <var>displacement</var>]
[<var>base_reg</var><sub>64</sub> + <var>index_reg</var><sub>64</sub>*<var>scale</var> - <var>displacement</var>]</code></pre>
<p><var>base_reg</var><span class="SubscriptLiteral">64</span> represents any general-purpose 64-bit register, <var>index_reg</var><span class="SubscriptLiteral">64</span> represents any general-purpose 64-bit register except RSP, and <var>scale</var> must be one of the constants 1, 2, 4, or 8.</p>
<figure>
<img src="image_fi/501089c03/f03010.png" alt="f03010" class=""/>
<figcaption><p><a id="figure3-10">Figure 3-10</a>: Scaled-indexed addressing mode</p></figcaption>
</figure>
<p>In <a href="#figure3-10">Figure 3-10</a>, suppose that RBX contains 1000FF00h, RSI contains 20h, and <var>const</var> is 2000h; then the instruction</p>
<pre><code>mov al, [rbx + rsi*4 + 2000h]</code></pre>
<p class="BodyContinued">will move the byte at address 10011F80h—1000FF00h + (20h × 4) + 2000—into the AL register.</p>
<p><span epub:type="pagebreak" title="127" id="Page_127"/>The scaled-indexed addressing modes are useful for accessing array elements that are 2, 4, or 8 bytes each. These addressing modes are also useful for accessing elements of an array when you have a pointer to the beginning of the array.</p>
<h3 id="h2-501089c03-0009">3.7.3	Large Address Unaware Applications</h3>
<p class="BodyFirst">One advantage of 64-bit addresses is that they can access a frightfully large amount of memory (something like 8TB under Windows). By default, the Microsoft linker (when it links together the C++ and assembly language code) sets a flag named <code>LARGEADDRESSAWARE</code> to true (<code>yes</code>). This makes it possible for your programs to access a huge amount of memory. However, there is a price to be paid for operating in <code>LARGEADDRESSAWARE</code> mode: the <var>const</var> component of the [<var>reg</var><span class="SubscriptLiteral">64 </span>+ <var>const</var>] addressing mode is limited to 32 bits and cannot span the entire address space.</p>
<p>Because of instruction-encoding limitations, the <var>const</var> value is limited to a signed value in the range ±2GB. This is probably far more than enough when the register contains a 64-bit base address and you want to access a memory location at a fixed offset (less than ±2GB) around that base address. A typical way you would use this addressing mode is as follows:</p>
<pre><code>lea rcx, someStructure
mov al, [rcx+fieldOffset]</code></pre>
<p>Prior to the introduction of 64-bit addresses, the <var>const</var> offset appearing in the (32-bit) indirect-plus-offset addressing mode could span the entire (32-bit) address space. So if you had an array declaration such as</p>
<pre><code>    .data
buf byte   256 dup (?)</code></pre>
<p class="BodyContinued">you could access elements of this array by using the following addressing mode form:</p>
<pre><code>mov al, buf[ebx]  ; EBX was used on 32-bit processors</code></pre>
<p>If you were to attempt to assemble the instruction <code>mov al, buf[rbx]</code> in a 64-bit program (or any other addressing mode involving <code>buf</code> other than PC-relative), MASM would assemble the code properly, but the linker would report an error:</p>
<pre><code>error LNK2017: 'ADDR32' relocation to 'buf' invalid without /LARGEADDRESSAWARE:NO</code></pre>
<p>The linker is complaining that in an address space exceeding 32 bits, it is impossible to encode the offset to the <code>buf</code> buffer because the machine instruction opcodes provide only a 32-bit offset to hold the address of <code>buf</code>.</p>
<p><span epub:type="pagebreak" title="128" id="Page_128"/>However, if we were to artificially limit the amount of memory that our application uses to 2GB, then MASM can encode the 32-bit offset to <code>buf</code> into the machine instruction. As long as we kept our promise and never used any more memory than 2GB, several new variations on the indirect-plus-offset and scaled-indexed addressing modes become possible.</p>
<p>To turn off the large address–aware flag, you need to add an extra command line option to the <code>ml64</code> command. This is easily done in the <em>build.bat</em> file; let’s create a new <em>build.bat</em> file and call it <em>sbuild.bat. </em>This file will have the following lines:</p>
<pre><code>echo off
ml64 /nologo /c /Zi /Cp %1.asm 
cl /nologo /O2 /Zi /utf-8 /EHa /Fe%1.exe c.cpp %1.obj /link /largeaddressaware:no </code></pre>
<p>This set of commands (<em>sbuild.bat</em> for <em>small build</em>) tells MASM to pass a command to the linker that turns off the large address–aware file. MASM, MSVC, and the Microsoft linker will construct an executable file that requires only 32-bit addresses (ignoring the 32 HO bits in the 64-bit registers appearing in addressing modes).</p>
<p>Once you’ve disabled <code>LARGEADDRESSAWARE</code>, several new variants of the indirect-plus-offset and scaled-indexed addressing modes become available to your programs:</p>
<pre><code><var>variable</var>[<var>reg</var><sub>64</sub>]
<var>variable</var>[<var>reg</var><sub>64</sub> + <var>const</var>]
<var>variable</var>[<var>reg</var><sub>64</sub> - <var>const</var>]
<var>variable</var>[<var>reg</var><sub>64</sub> * <var>scale</var>]
<var>variable</var>[<var>reg</var><sub>64</sub> * <var>scale</var> + <var>const</var>]
<var>variable</var>[<var>reg</var><sub>64</sub> * <var>scale</var> - <var>const</var>]
<var>variable</var>[<var>reg</var><sub>64</sub> + <var>reg_not_RSP</var><sub>64 </sub>* <var>scale</var>]
<var>variable</var>[<var>reg</var><sub>64</sub> + <var>reg_not_RSP</var><sub>64 </sub>* <var>scale</var> + <var>const</var>]
<var>variable</var>[<var>reg</var><sub>64</sub> + <var>reg_not_RSP</var><sub>64 </sub>* <var>scale</var> - <var>const</var>]</code></pre>
<p class="BodyContinued">where <var>variable</var> is the name of an object you’ve declared in your source file by using directives like <code>byte</code>, <code>word</code>, <code>dword</code>, and so on; <var>const</var> is a (maximum 32-bit) constant expression; and <var>scale</var> is 1, 2, 4, or 8. These addressing mode forms use the address of <var>variable</var> as the base address and add in the current value of the 64-bit registers (see Figures 3-11 through 3-16 for examples).</p>
<figure>
<img src="image_fi/501089c03/f03011.png" alt="f03011" class=""/>
<figcaption><p><a id="figure3-11">Figure 3-11</a>: Base address form of indirect-plus-offset addressing mode</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="129" id="Page_129"/>Although the small address forms (<code>LARGEADDRESSAWARE:NO</code>) are convenient and efficient, they can fail spectacularly if your program ever uses more than 2GB of memory. Should your programs ever grow beyond that point, you will have to completely rewrite every instruction that uses one of these addresses (that uses a global data object as the base address rather than loading the base address into a register). This can be very painful and error prone. Think twice before ever using the <code>LARGEADDRESSAWARE:NO</code> option.</p>
<figure>
<img src="image_fi/501089c03/f03012.png" alt="f03012" class=""/>
<figcaption><p><a id="figure3-12">Figure 3-12</a>: Small address plus constant form of indirect-plus-offset addressing mode</p></figcaption>
</figure>
<figure>
<img src="image_fi/501089c03/f03013.png" alt="f03013" class=""/>
<figcaption><p><a id="figure3-13">Figure 3-13</a>: Small address form of base-plus-scaled-indexed addressing mode</p></figcaption>
</figure>
<figure>
<img src="image_fi/501089c03/f03014.png" alt="f03014" class=""/>
<figcaption><p><a id="figure3-14">Figure 3-14</a>: Small address form of base-plus-scaled-indexed-plus-constant addressing mode</p></figcaption>
</figure>
<span epub:type="pagebreak" title="130" id="Page_130"/><figure>
<img src="image_fi/501089c03/f03015.png" alt="f03015" class=""/>
<figcaption><p><a id="figure3-15">Figure 3-15</a>: Small address form of scaled-indexed addressing mode</p></figcaption>
</figure>
<figure>
<img src="image_fi/501089c03/f03016.png" alt="f03016" class=""/>
<figcaption><p><a id="figure3-16">Figure 3-16</a>: Small address form of scaled-indexed-plus-constant addressing mode</p></figcaption>
</figure>
<h2 id="h1-501089c03-0008">	3.8	Address Expressions</h2>
<p class="BodyFirst">Often, when accessing variables and other objects in memory, we need to access memory locations immediately before or after a variable rather than the memory at the address specified by the variable. For example, when accessing an element of an array or a field of a structure/record, the exact element or field is probably not at the address of the variable itself. Address expressions provide a mechanism to attach an arithmetic expression to an address to access memory around a variable’s address.</p>
<p>This book considers an <em>address expression</em> to be any legal x86-64 addressing mode that includes a displacement (that is, variable name) or an offset. For example, the following are legal address expressions:</p>
<pre><code>[<var>reg</var><sub>64</sub> + <var>offset</var>]
[<var>reg</var><sub>64</sub> + <var>reg_not_RSP</var><sub>64 </sub>* <var>scale</var> + <var>offset</var>]</code></pre>
<p><span epub:type="pagebreak" title="131" id="Page_131"/>Consider the following legal MASM syntax for a memory address, which isn’t actually a new addressing mode but simply an extension of the PC-relative addressing mode:</p>
<pre><code><var>variable_name</var>[<var>offset</var>]</code></pre>
<p>This extended form computes its effective address by adding the constant offset within the brackets to the variable’s address. For example, the instruction <code>mov al, Address[3]</code> loads the AL register with the byte in memory that is 3 bytes beyond the <code>Address</code> object (see <a href="#figure3-17" id="figureanchor3-17">Figure 3-17</a>).</p>
<p>The <var>offset</var> value in these examples must be a constant. If <var>index</var> is an <code>int32</code> variable, then <var>variable</var><code>[</code><var>index</var><code>]</code> is not a legal address expression. If you wish to specify an index that varies at runtime, you must use one of the indirect or scaled-indexed addressing modes.</p>
<p>Another important thing to remember is that the offset in <var>Address</var><code>[</code><var>offset</var><code>]</code> is a byte address. Although this syntax is reminiscent of array indexing in a high-level language like C/C++ or Java, this does not properly index into an array of objects unless <var>Address</var> is an array of bytes.</p>
<figure>
<img src="image_fi/501089c03/f03017.png" alt="f03017" class=""/>
<figcaption><p><a id="figure3-17">Figure 3-17</a>: Using an address expression to access data beyond a variable</p></figcaption>
</figure>
<p>Until this point, the offset in all the addressing mode examples has always been a single numeric constant. However, MASM also allows a <em>constant expression</em> anywhere an offset is legal. A constant expression consists of one or more constant terms manipulated by operators such as addition, subtraction, multiplication, division, modulo, and a wide variety of others. Most address expressions, however, will involve only addition, subtraction, multiplication, and sometimes division. Consider the following example:</p>
<pre><code>mov al, X[2*4 + 1]</code></pre>
<p>This instruction will move the byte at address <code>X + 9</code> into the AL register.</p>
<p>The value of an address expression is always computed at compile time, never while the program is running. When MASM encounters the <span epub:type="pagebreak" title="132" id="Page_132"/>preceding instruction, it calculates 2 × 4 + 1 on the spot and adds this result to the base address of <code>X</code> in memory. MASM encodes this single sum (base address of <code>X</code> plus 9) as part of the instruction; MASM does not emit extra instructions to compute this sum for you at runtime (which is good, because doing so would be less efficient). Because MASM computes the value of address expressions at compile time, all components of the expression must be constants because MASM cannot know the runtime value of a variable while it is compiling the program.</p>
<p>Address expressions are useful for accessing the data in memory beyond a variable, particularly when you’ve used the <code>byte</code>, <code>word</code>, <code>dword</code>, and so on, statements in a <code>.data</code> or <code>.const</code> section to tack on additional bytes after a data declaration. For example, consider the program in <a href="#listing3-1" id="listinganchor3-1">Listing 3-1</a> that uses address expressions to access the four consecutive bytes associated with variable <code>i</code>.</p>
<pre><code>; Listing 3-1
 
; Demonstrate address expressions.

        option  casemap:none

nl      =       10  ; ASCII code for newline

                .const
ttlStr          byte    'Listing 3-1', 0
fmtStr1         byte    'i[0]=%d ', 0
fmtStr2         byte    'i[1]=%d ', 0
fmtStr3         byte    'i[2]=%d ', 0
fmtStr4         byte    'i[3]=%d',nl, 0

        .data
i       byte    0, 1, 2, 3

        .code
        externdef printf:proc

; Return program title to C++ program:

         public getTitle
getTitle proc
         lea rax, ttlStr
         ret
getTitle endp

; Here is the "asmMain" function.

        public  asmMain
asmMain proc
        push    rbx
                           
<span epub:type="pagebreak" title="133" id="Page_133"/>; "Magic" instruction offered without
; explanation at this point:

        sub     rsp, 48

        lea     rcx, fmtStr1
        movzx   rdx, i[0]
        call    printf

        lea     rcx, fmtStr2
        movzx   rdx, i[1]
        call    printf

        lea     rcx, fmtStr3
        movzx   rdx, i[2]
        call    printf

        lea     rcx, fmtStr4
        movzx   rdx, i[3]
        call    printf

        add     rsp, 48
        pop     rbx
        ret     ; Returns to caller
asmMain endp
        end</code></pre>
<p class="CodeListingCaption"><a id="listing3-1">Listing 3-1</a>: Demonstration of address expressions</p>
<p>Here’s the output from the program:</p>
<pre><code>C:\&gt;<b>build listing3-1</b>

C:\&gt;<b>echo off</b>
 Assembling: listing3-1.asm
c.cpp

C:\&gt;<b>listing3-1</b>
Calling Listing 3-1:
i[0]=0 i[1]=1 i[2]=2 i[3]=3
Listing 3-1 terminated</code></pre>
<p>The program in <a href="#listing3-1">Listing 3-1</a> displays the four values <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code> as though they were array elements. This is because the value at the address of <code>i</code> is <code>0</code>. The address expression <code>i[1]</code> tells MASM to fetch the byte appearing at <code>i</code>’s address plus 1. This is the value <code>1</code>, because the <code>byte</code> statement in this program emits the value <code>1</code> to the <code>.data</code> segment immediately after the value <code>0</code>. Likewise for <code>i[2]</code> and <code>i[3]</code>, this program displays the values <code>2</code> and <code>3</code>.</p>
<p>Note that MASM also provides a special operator, <code>this</code>, that returns the current location counter (current position) within a section. You can use the <code>this</code> operator to represent the address of the current instruction in an address expression. See <span class="xref" itemid="xref_target_“Constant Expressions” in Chapter 4">“Constant Expressions” in Chapter 4</span> for more details.</p>
<h2 id="h1-501089c03-0009"><span epub:type="pagebreak" title="134" id="Page_134"/>	3.9	The Stack Segment and the push and pop Instructions</h2>
<p class="BodyFirst">The x86-64 maintains the stack in the <code>stack</code> segment of memory. The <em>stack</em> is a dynamic data structure that grows and shrinks according to certain needs of the program. The stack also stores important information about the program, including local variables, subroutine information, and temporary data. </p>
<p>The x86-64 controls its stack via the RSP (stack pointer) register. When your program begins execution, the operating system initializes RSP with the address of the last memory location in the <code>stack</code> memory segment. Data is written to the <code>stack</code> segment by “pushing” data onto the stack and “popping” data off the stack.</p>
<h3 id="h2-501089c03-0010">3.9.1	The Basic push Instruction</h3>
<p class="BodyFirst">Here’s the syntax for the x86-64 <code>push</code> instruction:</p>
<pre><code>push  <var>reg</var><sub>16</sub>
push  <var>reg</var><sub>64</sub>
push  <var>memory</var><sub>16</sub>
push  <var>memory</var><sub>64</sub>
pushw <var>constant</var><sub>16</sub>
push  <var>constant</var><sub>32</sub>  ; Sign extends <var>constant</var><sub>32</sub> to 64 bits</code></pre>
<p>These six forms allow you to push 16-bit or 64-bit registers, 16-bit or 64-bit memory locations, and 16-bit or 64-bit constants, but not 32-bit registers, memory locations, or constants.</p>
<p>The <code>push</code> instruction does the following:</p>
<pre><code>RSP   := RSP - <var>size_of_register_or_memory_operand</var> (2 or 8)
[RSP] := <var>operand's_value</var></code></pre>
<p>For example, assuming that RSP contains 00FF_FFFCh, the instruction <code>push rax</code> will set RSP to 00FF_FFE4h and store the current value of RAX into memory location 00FF_FFE04, as Figures 3-18 and 3-19 show.</p>
<figure>
<img src="image_fi/501089c03/f03018.png" alt="f03018" class=""/>
<figcaption><p><a id="figure3-18">Figure 3-18</a>: Stack segment before the <span class="LiteralInCaption"><code>push rax</code></span> operation</p></figcaption>
</figure>
<span epub:type="pagebreak" title="135" id="Page_135"/><figure>
<img src="image_fi/501089c03/f03019.png" alt="f03019" class=""/>
<figcaption><p><a id="figure3-19">Figure 3-19</a>: Stack segment after the <span class="LiteralInCaption"><code>push rax</code></span> operation</p></figcaption>
</figure>
<p>Although the x86-64 supports 16-bit push operations, their primary use is in 16-bit environments such as Microsoft Disk Operating System (MS-DOS). For maximum performance, the stack pointer’s value should always be a multiple of eight; indeed, your program may malfunction under a 64-bit OS if RSP contains a value that is not a multiple of eight. The only practical reason for pushing fewer than 8 bytes at a time on the stack is to build up a quad word via four successive word pushes.</p>
<h3 id="h2-501089c03-0011">3.9.2	The Basic pop Instruction</h3>
<p class="BodyFirst">To retrieve data you’ve pushed onto the stack, you use the <code>pop</code> instruction. The basic <code>pop</code> instruction allows the following forms:</p>
<pre><code>pop <var>reg</var><sub>16</sub>
pop <var>reg</var><sub>64</sub>
pop <var>memory</var><sub>16</sub>
pop <var>memory</var><sub>64</sub></code></pre>
<p>Like the <code>push</code> instruction, the <code>pop</code> instruction supports only 16-bit and 64-bit operands; you cannot pop an 8-bit or 32-bit value from the stack. As with the <code>push</code> instruction, you should avoid popping 16-bit values (unless you do four 16-bit pops in a row) because 16-bit pops may leave the RSP register containing a value that is not a multiple of eight. One major difference between <code>push</code> and <code>pop</code> is that you cannot pop a constant value (which makes sense, because the operand for <code>push</code> is a source operand, while the operand for <code>pop</code> is a destination operand).</p>
<p>Formally, here’s what the <code>pop</code> instruction does:</p>
<pre><code><var>operand</var> := [RSP]
RSP     := RSP + <var>size_of_operand</var> (2 or 8)</code></pre>
<p><span epub:type="pagebreak" title="136" id="Page_136"/>As you can see, the <code>pop</code> operation is the converse of the <code>push</code> operation. Note that the <code>pop</code> instruction copies the data from memory location <code>[RSP]</code> before adjusting the value in RSP. See Figures 3-20 and 3-21 for details on this operation.</p>
<figure>
<img src="image_fi/501089c03/f03020.png" alt="f03020" class=""/>
<figcaption><p><a id="figure3-20">Figure 3-20</a>: Memory before a <span class="LiteralInCaption"><code>pop rax</code></span> operation</p></figcaption>
</figure>
<figure>
<img src="image_fi/501089c03/f03021.png" alt="f03021" class=""/>
<figcaption><p><a id="figure3-21">Figure 3-21</a>: Memory after the <span class="LiteralInCaption"><code>pop rax</code></span> operation</p></figcaption>
</figure>
<p>The value popped from the stack is still present in memory. Popping a value does not erase the value in memory; it just adjusts the stack pointer so that it points at the next value above the popped value. However, you should never attempt to access a value you’ve popped off the stack. The next time something is pushed onto the stack, the popped value will be obliterated. Because your code isn’t the only thing that uses the stack (for example, the operating system uses the stack, as do subroutines), you cannot rely on data remaining in stack memory once you’ve popped it off the stack.</p>
<h3 id="h2-501089c03-0012"><span epub:type="pagebreak" title="137" id="Page_137"/>3.9.3	Preserving Registers with the push and pop Instructions</h3>
<p class="BodyFirst">Perhaps the most common use of the <code>push</code> and <code>pop</code> instructions is to save register values during intermediate calculations. Because registers are the best place to hold temporary values, and registers are also needed for the various addressing modes, it is easy to run out of registers when writing code that performs complex calculations. The <code>push</code> and <code>pop</code> instructions can come to your rescue when this happens.</p>
<p>Consider the following program outline:</p>
<pre><code><var>  Some instructions that use the RAX register</var>

<var>  Some instructions that need to use RAX, for a</var>
<var>  different purpose than the above instructions</var>

<var>  Some instructions that need the original value in RAX</var></code></pre>
<p>The <code>push</code> and <code>pop</code> instructions are perfect for this situation. By inserting a <code>push</code> instruction before the middle sequence and a <code>pop</code> instruction after the middle sequence, you can preserve the value in RAX across those calculations:</p>
<pre><code><var>  Some instructions that use the RAX register</var>

     push rax

<var>  Some instructions that need to use RAX, for a</var>
<var>  different purpose than the above instructions</var>

     pop rax

<var>  Some instructions that need the original value in RAX</var></code></pre>
<p>This <code>push</code> instruction copies the data computed in the first sequence of instructions onto the stack. Now the middle sequence of instructions can use RAX for any purpose it chooses. After the middle sequence of instructions finishes, the <code>pop</code> instruction restores the value in RAX so the last sequence of instructions can use the original value in RAX.</p>
<h2 id="h1-501089c03-0010">	3.10	The Stack Is a LIFO Data Structure</h2>
<p class="BodyFirst">You can push more than one value onto the stack without first popping previous values off the stack. However, the stack is a <em>last-in, first-out (</em><em>LIFO)</em> data structure, so you must be careful how you push and pop multiple values. For example, suppose you want to preserve RAX and RBX across a <span epub:type="pagebreak" title="138" id="Page_138"/>block of instructions; the following code demonstrates the obvious way to handle this:</p>
<pre><code>push rax
push rbx
<var>  Code that uses RAX and RBX goes here</var>
pop rax
pop rbx</code></pre>
<p>Unfortunately, this code will not work properly! Figures 3-22 through 3-25 show the problem. Because this code pushes RAX first and RBX second, the stack pointer is left pointing at RBX’s value on the stack. When the <code>pop rax</code> instruction comes along, it removes the value that was originally in RBX from the stack and places it in RAX! Likewise, the <code>pop rbx</code> instruction pops the value that was originally in RAX into the RBX register. The result is that this code manages to swap the values in the registers by popping them in the same order that it pushes them.</p>
<figure>
<img src="image_fi/501089c03/f03022.png" alt="f03022" class=""/>
<figcaption><p><a id="figure3-22">Figure 3-22</a>: Stack after pushing RAX</p></figcaption>
</figure>
<p>To rectify this problem, you must note that the stack is a LIFO data structure, so the first thing you must pop is the last thing you push onto the stack. Therefore, you must always observe the following maxim: <em>always pop values in the reverse order that you push them.</em></p>
<p>The correction to the previous code is shown here:</p>
<pre><code>push rax
push rbx
<var>  Code that uses RAX and RBX goes here</var>
pop rbx
pop rax</code></pre>
<span epub:type="pagebreak" title="139" id="Page_139"/><figure>
<img src="image_fi/501089c03/f03023.png" alt="f03023" class=""/>
<figcaption><p><a id="figure3-23">Figure 3-23</a>: Stack after pushing RBX</p></figcaption>
</figure>
<figure>
<img src="image_fi/501089c03/f03024.png" alt="f03024" class=""/>
<figcaption><p><a id="figure3-24">Figure 3-24</a>: Stack after popping RAX</p></figcaption>
</figure>
<p>Another important maxim to remember is this: <em>always pop exactly the same number of bytes that you push. </em>This generally means that the number of pushes and pops must exactly agree. If you have too few pops, you will leave data on the stack, which may confuse the running program. If you have too many pops, you will accidentally remove previously pushed data, often with disastrous results.</p>
<p>A corollary to the preceding maxim is <em>be careful when pushing and popping data within a loop.</em> Often it is quite easy to put the pushes in a loop and leave the pops outside the loop (or vice versa), creating an inconsistent stack. Remember, it is the execution of the <code>push</code> and <code>pop</code> instructions that matters, not the number of <code>push</code> and <code>pop</code> instructions that appear in your program. At runtime, the number (and order) of the <code>push</code> instructions the program executes must match the number (and reverse order) of the <code>pop</code> instructions.</p>
<span epub:type="pagebreak" title="140" id="Page_140"/><figure>
<img src="image_fi/501089c03/f03025.png" alt="f03025" class=""/>
<figcaption><p><a id="figure3-25">Figure 3-25</a>: Stack after popping RBX</p></figcaption>
</figure>
<p>One final thing to note: <em>the Microsoft ABI requires the stack to be aligned on a 16-byte boundary. </em>If you push and pop items on the stack, make sure that the stack is aligned on a 16-byte boundary before calling any functions or procedures that adhere to the Microsoft ABI (and require the stack to be aligned on a 16-byte boundary).</p>
<h2 id="h1-501089c03-0011">	3.11	Other push and pop Instructions</h2>
<p class="BodyFirst">The x86-64 provides four additional <code>push</code> and <code>pop</code> instructions in addition to the basic ones:</p>
<ol class="none">
<li><code>pushf</code>      <code>popf</code></li>
<li><code>pushfq</code>     <code>popfq</code></li>
</ol>
<p>The <code>pushf</code>, <code>pushfq</code>, <code>popf</code>, and <code>popfq</code> instructions push and pop the RFLAGS register. These instructions allow you to preserve condition code and other flag settings across the execution of a sequence of instructions. Unfortunately, unless you go to a lot of trouble, it is difficult to preserve individual flags. When using the <code>pushf(q)</code> and <code>popf(q)</code> instructions, it’s an all-or-nothing proposition: you preserve all the flags when you push them; you restore all the flags when you pop them.</p>
<p>You should really use the <code>pushfq</code> and <code>popfq</code> instructions to push the full 64-bit version of the RFLAGS register (rather than pushing only the 16-bit FLAGs portion). Although the extra 48 bits you push and pop are essentially ignored when writing applications, you still want to keep the stack aligned by pushing and popping only quad words.</p>
<h2 id="h1-501089c03-0012">	3.12	Removing Data from the Stack Without Popping It</h2>
<p class="BodyFirst">Quite often you may discover that you’ve pushed data onto the stack that you no longer need. Although you could pop the data into an unused <span epub:type="pagebreak" title="141" id="Page_141"/>register or memory location, there is an easier way to remove unwanted data from the stack—simply adjust the value in the RSP register to skip over the unwanted data on the stack.</p>
<p>Consider the following dilemma (in pseudocode, not actual assembly language):</p>
<pre><code>push rax
push rbx

<var>  Some code that winds up computing some values we want to keep</var>
<var>  in RAX and RBX</var>

if(<var>Calculation_was_performed</var>) then

    ; Whoops, we don't want to pop RAX and RBX!
    ; What to do here?

else

    ; No calculation, so restore RAX, RBX.

    pop rbx
    pop rax

endif;</code></pre>
<p>Within the <code>then</code> section of the <code>if</code> statement, this code wants to remove the old values of RAX and RBX without otherwise affecting any registers or memory locations. How can we do this?</p>
<p>Because the RSP register contains the memory address of the item on the top of the stack, we can remove the item from the top of the stack by adding the size of that item to the RSP register. In the preceding example, we wanted to remove two quad-word items from the top of the stack. We can easily accomplish this by adding 16 to the stack pointer (see Figures 3-26 and 3-27 for the details):</p>
<pre><code>push rax
push rbx

<var>  Some code that winds up computing some values we want to keep</var>
<var>  in RAX and RBX</var>

if(<var>Calculation_was_performed</var>) then

    ; Remove unneeded RAX/RBX values
    ; from the stack.

    add rsp, 16

else

<span epub:type="pagebreak" title="142" id="Page_142"/>    ; No calculation, so restore RAX, RBX.

    pop rbx
    pop rax

endif;</code></pre>
<figure>
<img src="image_fi/501089c03/f03026.png" alt="f03026" class=""/>
<figcaption><p><a id="figure3-26">Figure 3-26</a>: Removing data from the stack, before <span class="LiteralInCaption"><code>add rsp, 16</code></span></p></figcaption>
</figure>
<figure>
<img src="image_fi/501089c03/f03027.png" alt="f03027" class=""/>
<figcaption><p><a id="figure3-27">Figure 3-27</a>: Removing data from the stack, after <span class="LiteralInCaption"><code>add rsp, 16</code></span></p></figcaption>
</figure>
<p>Effectively, this code pops the data off the stack without moving it anywhere. Also note that this code is faster than two dummy <code>pop</code> instructions because it can remove any number of bytes from the stack with a single <code>add</code> instruction.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Remember to keep the stack aligned on a quad-word boundary. Therefore, you should always add a constant that is a multiple of eight to RSP when removing data from the stack.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h2 id="h1-501089c03-0013">	3.13	Accessing Data You’ve Pushed onto the Stack Without Popping It</h2>
<p class="BodyFirst">Once in a while, you will push data onto the stack and will want to get a copy of that data’s value, or perhaps you will want to change that data’s value without actually popping the data off the stack (that is, you wish to pop the data off the stack at a later time). The x86-64 <code>[</code><var>reg</var><span class="SubscriptLiteral">64</span><code> ± </code><var>offset</var><code>]</code> addressing mode provides the mechanism for this.</p>
<p><span epub:type="pagebreak" title="143" id="Page_143"/>Consider the stack after the execution of the following two instructions (see <a href="#figure3-28" id="figureanchor3-28">Figure 3-28</a>):</p>
<pre><code>push rax
push rbx</code></pre>
<figure>
<img src="image_fi/501089c03/f03028.png" alt="f03028" class=""/>
<figcaption><p><a id="figure3-28">Figure 3-28</a>: Stack after pushing RAX and RBX</p></figcaption>
</figure>
<p>If you wanted to access the original RBX value without removing it from the stack, you could cheat and pop the value and then immediately push it again. Suppose, however, that you wish to access RAX’s old value or another value even further up the stack. Popping all the intermediate values and then pushing them back onto the stack is problematic at best, impossible at worst. However, as you will notice from <a href="#figure3-28">Figure 3-28</a>, each value pushed on the stack is at a certain offset from the RSP register in memory. Therefore, we can use the <code>[rsp ± </code><var>offset</var><code>]</code> addressing mode to gain direct access to the value we are interested in. In the preceding example, you can reload RAX with its original value by using this single instruction:</p>
<pre><code>mov rax, [rsp + 8]</code></pre>
<p>This code copies the 8 bytes starting at memory address <code>rsp + 8</code> into the RAX register. This value just happens to be the previous value of RAX that was pushed onto the stack. You can use this same technique to access other data values you’ve pushed onto the stack.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Don’t forget that the offsets of values from RSP into the stack change every time you push or pop data. Abusing this feature can create code that is hard to modify; if you use this feature throughout your code, it will make it difficult to push and pop other data items between the point where you first push data onto the stack and the point where you decide to access that data again using the <code>[rsp + </code><var>offset</var><code>]</code> memory addressing mode.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>The previous section pointed out how to remove data from the stack by adding a constant to the RSP register. That pseudocode example could probably be written more safely as this:</p>
<pre><code>push rax
push rbx

<span epub:type="pagebreak" title="144" id="Page_144"/><var>  Some code that winds up computing some values we want to keep</var>
<var>  in RAX and RBX</var>

if(<var>Calculation_was_performed</var>) then

  <var>Overwrite saved values on stack with</var>
<var>  new RAX/RBX values (so the pops that</var>
<var>  follow won't change the values in RAX/RBX)</var>

     mov [rsp + 8], rax
     mov [rsp], rbx

endif
pop rbx
pop rax</code></pre>
<p>In this code sequence, the calculated result was stored over the top of the values saved on the stack. Later, when the program pops the values, it loads these calculated values into RAX and RBX.</p>
<h2 id="h1-501089c03-0014">	3.14	Microsoft ABI Notes</h2>
<p class="BodyFirst">About the only feature this chapter introduces that affects the Microsoft ABI is data alignment. As a general rule, the Microsoft ABI requires all data to be aligned on a natural boundary for that data object. A <em>natural boundary</em> is an address that is a multiple of the object’s size (up to 16 bytes). Therefore, if you intend to pass a word/sword, dword/sdword, or qword/sqword value to a C++ procedure, you should attempt to align that object on a 2-, 4-, or 8-byte boundary, respectively.</p>
<p>When calling code written in a Microsoft ABI–aware language, you must ensure that the stack is aligned on a 16-byte boundary before issuing a <code>call</code> instruction. This can severely limit the usefulness of the <code>push</code> and <code>pop</code> instructions. If you use the <code>push</code> instructions to save a register’s value prior to a call, you must make sure you push two (64-bit) values, or otherwise make sure the RSP address is a multiple of 16 bytes, prior to making the call. <span class="xref" itemid="xref_target_Chapter 5">Chapter 5</span> explores this issue in greater detail.</p>
<h2 id="h1-501089c03-0015">	3.15	For More Information</h2>
<p class="BodyFirst">An older, 16-bit version of my book <em>The Art of Assembly Language Programming</em> can be found at <a href="https://artofasm.randallhyde.com/" class="LinkURL">https://artofasm.randallhyde.com/</a>. In that text, you will find information about the 8086 16-bit addressing modes and segmentation. The published edition of that book (No Starch Press, 2010) covers the 32-bit addressing modes. Of course, the Intel x86 documentation (found at <a href="http://www.intel.com/" class="LinkURL">http://www.intel.com/</a>) provides complete information on x86-64 address modes and machine instruction encoding.</p>
<h2 id="h1-501089c03-0016"><span epub:type="pagebreak" title="145" id="Page_145"/>	3.16	Test Yourself</h2>
<ol class="decimal">
<li value="1">The PC-relative addressing mode indexes off which 64-bit register?</li>
<li value="2">What does <em>opcode</em> stand for?</li>
<li value="3">What type of data is the PC-relative addressing mode typically used for?</li>
<li value="4">What is the address range of the PC-relative addressing mode?</li>
<li value="5">In a register-indirect addressing mode, what does the register contain?</li>
<li value="6">Which of the following registers is valid for use with the register-indirect addressing mode?
<ol class="lower-alpha">
<li value="1">AL</li>
<li value="2">AX</li>
<li value="3">EAX</li>
<li value="4">RAX</li>
</ol></li>
<li value="7">What instruction would you normally use to load the address of a memory object into a register?</li>
<li value="8">What is an effective address?</li>
<li value="9">What scaling values are legal with the scaled-indexed addressing mode?</li>
<li value="10">What is the memory limitation on a <code>LARGEADDRESSAWARE:NO</code> application?</li>
<li value="11">What is the advantage of using the <code>LARGEADDRESSAWARE:NO</code> option when compiling a program?</li>
<li value="12">What is the difference between the <code>.data</code> section and the <code>.data?</code> section?</li>
<li value="13">Which (standard MASM) memory sections are read-only?</li>
<li value="14">Which (standard MASM) memory sections are readable and writable?</li>
<li value="15">What is the location counter?</li>
<li value="16">Explain how to use the <code>label</code> directive to coerce data to a different type.</li>
<li value="17">Explain what happens if two (or more) <code>.data</code> sections appear in a MASM source file.</li>
<li value="18">How would you align a variable in the <code>.data</code> section to an 8-byte boundary?</li>
<li value="19">What does <em>MMU</em> stand for?</li>
<li value="20">If <code>b</code> is a byte variable in read/write memory, explain how a <code>mov ax, b</code> instruction could cause a general protection fault.</li>
<li value="21">What is an address expression?</li>
<li value="22">What is the purpose of the MASM PTR operator?</li>
<li value="23">What is the difference between a big-endian value and a little-endian value?</li>
<li value="24">If AX contains a big-endian value, what instruction could you use to convert it to a little-endian value?</li>
<li value="25"><span epub:type="pagebreak" title="146" id="Page_146"/>If EAX contains a little-endian value, what instruction could you use to convert it to a big-endian value?</li>
<li value="26">If RAX contains a big-endian value, what instruction could you use to convert it to a little-endian value?</li>
<li value="27">Explain, step by step, what the <code>push rax</code> instruction does.</li>
<li value="28">Explain, step by step, what the <code>pop rax</code> instruction does.</li>
<li value="29">When using the <code>push</code> and <code>pop</code> instructions to preserve registers, you must always pop the registers in the <span class="Underline">                         </span> order that you pushed them.</li>
<li value="30">What does <em>LIFO</em> stand for?</li>
<li value="31">How do you access data on the stack without using the <code>push</code> and <code>pop</code> instructions?</li>
<li value="32">How can pushing RAX onto the stack before calling a Windows ABI–compatible function create problems?</li>
</ol>
<section class="footnotes">
<aside class="FootnoteEntry"><p><sup class="FootnoteReference"><a id="c03-footnote-1" href="#c03-footnoteref-1">1.</a></sup> The Microsoft linker documentation can be accessed at <a href="https://docs.microsoft.com/en-us/cpp/build/reference/linking?view=msvc-160/" class="LinkURL">https://docs.microsoft.com/en-us/cpp/build/reference/linking?view=msvc-160/</a>. </p></aside>
<aside class="FootnoteEntry"><p><sup class="FootnoteReference"><a id="c03-footnote-2" href="#c03-footnoteref-2">2</a></sup>. This is, of course, subject to change over time at the whims of Microsoft.</p></aside>
<aside class="FootnoteEntry"><p><sup class="FootnoteReference"><a id="c03-footnote-3" href="#c03-footnoteref-3">3.</a></sup> The OS provides the stack and heap sections; you don’t normally declare these two in an assembly language program. Therefore, there isn’t anything more to discuss about them here.</p></aside>
<aside class="FootnoteEntry"><p><sup class="FootnoteReference"><a id="c03-footnote-4" href="#c03-footnoteref-4">4.</a></sup> Technically, it is well defined: the machine will decode whatever bit pattern you place in memory as a machine instruction. However, few people will be able to look at a piece of data and interpret its meaning as a machine instruction.</p></aside>
<aside class="FootnoteEntry"><p><sup class="FootnoteReference"><a id="c03-footnote-5" href="#c03-footnoteref-5">5.</a></sup> Unfortunately, early Intel documentation called 256-byte blocks <em>pages</em>, and some early MMUs used 512-byte pages, so this term elicits a lot of confusion. In memory, however, pages are always 4096-byte blocks on the x86-64.</p></aside>
<aside class="FootnoteEntry"><p><sup class="FootnoteReference"><a id="c03-footnote-6" href="#c03-footnoteref-6">6.</a></sup> This will typically crash your program unless you have an exception handler in place to handle general protection faults.</p></aside>
<aside class="FootnoteEntry"><p><sup class="FootnoteReference"><a id="c03-footnote-7" href="#c03-footnoteref-7">7</a></sup>. It goes without saying that you should never write data beyond the end of a given data structure; this is always incorrect and can create far more problems than just crashing your program (including severe security issues).</p></aside>
<aside class="FootnoteEntry"><p><sup class="FootnoteReference"><a id="c03-footnote-8" href="#c03-footnoteref-8">8.</a></sup> 32-bit processors did not put the LO 2 bits onto the address bus, so addresses 124, 125, 126, and 127 would all have the value 124 on the address bus.</p></aside>
<aside class="FootnoteEntry"><p><sup class="FootnoteReference"><a id="c03-footnote-9" href="#c03-footnoteref-9">9.</a></sup> The <em>effective address</em> is the ultimate address in memory that an instruction will access, once all the address calculations are complete.</p></aside>
</section>
</section>
</body></html>