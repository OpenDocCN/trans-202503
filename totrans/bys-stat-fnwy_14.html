<html><head></head><body>
<h2 class="h2" id="ch11"><span epub:type="pagebreak" id="page_103"/><strong><span class="big">11</span><br/>MEASURING THE SPREAD OF OUR DATA</strong></h2>&#13;
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>&#13;
<p class="noindent">In this chapter, you’ll learn three different methods—mean absolute deviation, variance, and standard deviation—for quantifying the <em>spread</em>, or the different extremes, of your observations.</p>&#13;
<p class="indent">In the previous chapter, you learned that the mean is the best way to guess the value of an unknown measurement, and that the more spread out our observations, the more uncertain we are about our estimate of the mean. As an example, if we’re trying to figure out the location of a collision between two cars based only on the spread of the remaining debris after the cars have been towed away, then the more spread out the debris, the less sure we’d be of where precisely the two cars collided.</p>&#13;
<p class="indent">Because the spread of our observations is related to the uncertainty in the measurement, we need to be able to quantify it so we can make probabilistic statements about our estimates (which you’ll learn how to do in the next chapter).</p>&#13;
<h3 class="h3" id="ch11lev1sec1"><span epub:type="pagebreak" id="page_104"/><strong>Dropping Coins in a Well</strong></h3>&#13;
<p class="noindent">Say you and a friend are wandering around the woods and stumble across a strange-looking old well. You peer inside and see that it seems to have no bottom. To test it, you pull a coin from your pocket and drop it in, and sure enough, after a few seconds you hear a splash. From this, you conclude that the well is deep, but not bottomless.</p>&#13;
<p class="indent">With the supernatural discounted, you and your friend are now equally curious as to how deep the well actually is. To gather more data, you grab five more coins from your pocket and drop them in, getting the following measurements in seconds:</p>&#13;
<p class="equ">3.02, 2.95, 2.98, 3.08, 2.97</p>&#13;
<p class="indent">As expected, you find some variation in your results; this is primarily due to the challenge of making sure you drop the coin from the same height and time then record the splash correctly.</p>&#13;
<p class="indent">Next, your friend wants to try his hand at getting some measurements. Rather than picking five similarly sized coins, he grabs a wider assortment of objects, from small pebbles to twigs. Dropping them in the well, your friend gets the following measurements:</p>&#13;
<p class="equ">3.31, 2.16, 3.02, 3.71, 2.80</p>&#13;
<p class="indent">Both of these samples have a mean (μ) of about 3 seconds, but your measurements and your friend’s measurements are spread to different degrees. Our aim in this chapter is to come up with a way to quantify the difference between the spread of your measurements and the spread of your friend’s. We’ll use this result in the next chapter to determine the probability of certain ranges of values for our estimate.</p>&#13;
<p class="indent">For the rest of this chapter we’ll indicate when we’re talking about the first group of values (your observations) with the variable <em>a</em> and the second group (your friend’s observations) with the variable <em>b</em>. For each group, each observation is denoted with a subscript; for example, <em>a</em><sub>2</sub> is the second observation from group <em>a</em>.</p>&#13;
<h3 class="h3" id="ch11lev1sec2"><strong>Finding the Mean Absolute Deviation</strong></h3>&#13;
<p class="noindent">We’ll begin by measuring the spread of each observation from the mean (μ). The mean for both <em>a</em> and <em>b</em> is 3. Since μ is our best estimate for the true value, it makes sense to start quantifying the difference in the two spreads by measuring the distance between the mean and each of the values. <a href="ch11.xhtml#ch11tab01">Table 11-1</a> displays each observation and its distance from the mean.</p>&#13;
<p class="tabcap" id="ch11tab01"><span epub:type="pagebreak" id="page_105"/><strong>Table 11-1:</strong> Your and Your Friend’s Observations and Their Distances from the Mean</p>&#13;
<table class="topbot-d">&#13;
<colgroup>&#13;
<col style="width:50%"/>&#13;
<col style="width:50%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Observation</strong></p></td>&#13;
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Difference from mean</strong></p></td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba"><strong>Group <em>a</em></strong></p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba"> </p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">3.02</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.02</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">2.95</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">–0.05</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">2.98</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">–0.02</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">3.08</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.08</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">2.97</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">–0.03</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba"><strong>Group <em>b</em></strong></p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba"> </p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">3.31</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.31</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">2.16</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">–0.84</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">3.02</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.02</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">3.71</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.71</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-ba" style="vertical-align: top;"><p class="taba">2.80</p></td>&#13;
<td class="table-ba" style="vertical-align: top;"><p class="taba">–0.16</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>The distance from the mean is different than the error value, which is the distance from the true value and is unknown in this case.</em></p>&#13;
</div>&#13;
<p class="indent">A first guess at how to quantify the difference between the two spreads might be to just sum up their differences from the mean. However, when we try this out, we find that the sum of the differences for both sets of observations is exactly the same, which is odd given the notable difference in the spread of the two data sets:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0105-01.jpg"/></div>&#13;
<p class="indent">The reason we can’t simply sum the differences from the mean is related to why the mean works in the first place: as we know from <a href="ch10.xhtml#ch10">Chapter 10</a>, the errors tend to cancel each other out. What we need is a mathematical method that makes sure our differences don’t cancel out without affecting the validity of our measurements.</p>&#13;
<p class="indent">The reason the differences cancel out is that some are negative and some are positive. So, if we convert all the differences to positives, we can eliminate this problem without invalidating the values.</p>&#13;
<p class="indent">The most obvious way to do this is to take the <em>absolute value</em> of the differences; this is the number’s distance from 0, so the absolute value of 4 is 4, and the absolute value of –4 is also 4. This gives us the positive version of our negative numbers without actually changing them. To represent an absolute value, we enclose the value in vertical lines, as in | –6 | = | 6 | = 6.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_106"/>If we take the absolute value of the differences in <a href="ch11.xhtml#ch11tab01">Table 11-1</a> and use those in our calculation instead, we get a result we can work with:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0106-01.jpg"/></div>&#13;
<p class="indent">Try working this out by hand, and you should get the same results. This is a more useful approach for our particular situation, but it applies only when the two sample groups are the same size.</p>&#13;
<p class="indent">Imagine we had 40 more observations for group <em>a</em>—let’s say 20 observations of 2.9 and 20 of 3.1. Even with these additional observations, the data in group <em>a</em> seems less spread out than the data in group <em>b</em>, but the absolute sum of group <em>a</em> is now 85.19 simply because it has more observations!</p>&#13;
<p class="indent">To correct for this, we can normalize our values by dividing by the total number of observations. Rather than dividing, though, we’ll just multiply by 1 over the total, which is known as <em>multiplying the reciprocal</em> and looks like this:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0106-02.jpg"/></div>&#13;
<p class="indent">Now we have a measurement of the spread that isn’t dependent on the sample size! The generalization of this approach is as follows:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0106-03.jpg"/></div>&#13;
<p class="indent">Here we’ve calculated the mean of the absolute differences between our observations and the mean. This means that for group <em>a</em> the average observation is 0.04 from the mean, and for group <em>b</em> it’s about 0.416 seconds from the mean. We call the result of this formula the <em>mean absolute deviation (MAD)</em>. The MAD is a very useful and intuitive measure of how spread out your observations are. Given that group <em>a</em> has a MAD of 0.04 and group <em>b</em> around 0.4, we can now say that group <em>b</em> is about 10 times as spread out as group <em>a</em>.</p>&#13;
<h3 class="h3" id="ch11lev1sec3"><strong>Finding the Variance</strong></h3>&#13;
<p class="noindent">Another way to mathematically make all of our differences positive without invalidating the data is to square them: (<em>x<sub>i</sub></em> – μ)<sup>2</sup>. This method has at least two benefits over using MAD.</p>&#13;
<p class="indent">The first benefit is a bit academic: squaring values is much easier to work with mathematically than taking their absolute value. In this book, we won’t take advantage of this directly, but for mathematicians, the absolute value function can be a bit annoying in practice.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_107"/>The second, and more practical, reason is that squaring results in having an <em>exponential penalty</em>, meaning measurements very far away from the mean are penalized much more. In other words, small differences aren’t nearly as important as big ones, as we would feel intuitively. If someone scheduled your meeting in the wrong room, for example, you wouldn’t be too upset if you ended up next door to the right room, but you’d almost certainly be upset if you were sent to an office on the other side of the country.</p>&#13;
<p class="indent">If we substitute the absolute value for the squared difference, we get the following:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0107-01.jpg"/></div>&#13;
<p class="indent">This formula, which has a very special place in the study of probability, is called the <em>variance</em>. Notice that the equation for variance is exactly the same as MAD except that the absolute value function in MAD has been replaced with squaring. Because it has nicer mathematical properties, variance is used much more frequently in the study of probability than MAD. We can see how different our results look when we calculate their variance:</p>&#13;
<p class="equ">Var(group <em>a</em>) = 0.002, Var(group <em>b</em>) = 0.269</p>&#13;
<p class="indent">Because we’re squaring, however, we no longer have an intuitive understanding of what the results of variance mean. MAD gave us an intuitive definition: this is the average distance from the mean. Variance, on the other hand, says: this is the average squared difference. Recall that when we used MAD, group <em>b</em> was about 10 times more spread out than group <em>a</em>, but in the case of variance, group <em>b</em> is now 100 times more spread out!</p>&#13;
<h3 class="h3" id="ch11lev1sec4"><strong>Finding the Standard Deviation</strong></h3>&#13;
<p class="noindent">While in theory variance has many properties that make it useful, in practice it can be hard to interpret the results. It’s difficult for humans to think about what a difference of 0.002 seconds squared means. As we’ve mentioned, the great thing about MAD is that the result maps quite well to our intuition. If the MAD of group <em>b</em> is 0.4, that means that the average distance between any given observation and the mean is literally 0.4 seconds. But averaging over squared differences doesn’t allow us to reason about a result as nicely.</p>&#13;
<p class="indent">To fix this, we can take the square root of the variance in order to scale it back into a number that works with our intuition a bit better. The square root of a variance is called the <em>standard deviation</em> and is represented by the lowercase Greek letter sigma (σ). It is defined as follows:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0107-02.jpg"/></div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_108"/>The formula for standard deviation isn’t as scary as it might seem at first. Looking at all of the different parts, given that our goal is to numerically represent how spread out our data is, we can see that:</p>&#13;
<ol>&#13;
<li class="noindent">We want the difference between our data and the mean, <em>x<sub>i</sub></em> – μ.</li>&#13;
<li class="noindent">We need to convert negative numbers to positives, so we take the square, (<em>x<sub>i</sub></em> – μ)<sup>2</sup>.</li>&#13;
<li class="noindent">We need to add up all the differences:&#13;
<div class="equ-image"><img alt="Image" src="../images/f0108-01.jpg"/></div></li>&#13;
<li class="noindent">We don’t want the sum to be affected by the number of observations, so we normalize it with 1/<em>n</em>.</li>&#13;
<li class="noindent">Finally, we take the square root of everything so that the numbers are closer to what they would be if we used the more intuitive absolute distance.</li>&#13;
</ol>&#13;
<p class="indent">If we look at the standard deviation for our two groups, we can see that it’s very similar to the MAD:</p>&#13;
<p class="equ">σ(group <em>a</em>) = 0.046, σ(group <em>b</em>) = 0.519</p>&#13;
<p class="indent">The standard deviation is a happy medium between the intuitiveness of MAD and the mathematical ease of variance. Notice that, just like with MAD, the difference in the spread between <em>b</em> and <em>a</em> is a factor of 10. The standard deviation is so useful and ubiquitous that, in most of the literature on probability and statistics, variance is defined simply as σ<sup>2</sup>, or sigma squared!</p>&#13;
<p class="indent">So we now have three different ways of measuring the spread of our data. We can see the results in <a href="ch11.xhtml#ch11tab02">Table 11-2</a>.</p>&#13;
<p class="tabcap" id="ch11tab02"><strong>Table 11-2:</strong> Measurements of Spread by Method</p>&#13;
<table class="topbot-d">&#13;
<colgroup>&#13;
<col style="width:55%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:15%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Method of measuring spread</strong></p></td>&#13;
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Group <em>a</em></strong></p></td>&#13;
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Group <em>b</em></strong></p></td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">Mean absolute deviations</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.040</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.416</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">Variance</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.002</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.269</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-ba" style="vertical-align: top;"><p class="taba">Standard deviation</p></td>&#13;
<td class="table-ba" style="vertical-align: top;"><p class="taba">0.046</p></td>&#13;
<td class="table-ba" style="vertical-align: top;"><p class="taba">0.519</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">None of these methods for measuring spread is more correct than any other. By far the most commonly used value is the standard deviation, because we can use it, together with the mean, to define a normal distribution, which in turn allows us to define explicit probabilities to possible true values of our measurements. In the next chapter, we’ll take a look at the normal distribution and see how it can help us understand our level of confidence in our measurements.</p>&#13;
<h3 class="h3" id="ch11lev1sec5"><span epub:type="pagebreak" id="page_109"/><strong>Wrapping Up</strong></h3>&#13;
<p class="noindent">In this chapter, you learned three methods for quantifying the spread of a group of observations. The most intuitive measurement of the spread of values is the mean absolute deviation (MAD), which is the average distance of each observation from the mean. While intuitive, MAD isn’t as useful mathematically as the other options.</p>&#13;
<p class="indent">The mathematically preferred method is the variance, which is the squared difference of our observations. But when we calculate the variance, we lose the intuitive feel for what our calculation means.</p>&#13;
<p class="indent">Our third option is to use the standard deviation, which is the square root of the variance. The standard deviation is mathematically useful and also gives us results that are reasonably intuitive.</p>&#13;
<h3 class="h3" id="ch11lev1sec6"><strong>Exercises</strong></h3>&#13;
<p class="noindent">Try answering the following questions to see how well you understand these different methods of measuring the spread of data. The solutions can be found at <em><a href="https://nostarch.com/learnbayes/">https://nostarch.com/learnbayes/</a></em>.</p>&#13;
<ol>&#13;
<li class="noindent">One of the benefits of variance is that squaring the differences makes the penalties exponential. Give some examples of when this would be a useful property.</li>&#13;
<li class="noindent">Calculate the mean, variance, and standard deviation for the following values: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10.<span epub:type="pagebreak" id="page_110"/></li>&#13;
</ol>&#13;
</body></html>