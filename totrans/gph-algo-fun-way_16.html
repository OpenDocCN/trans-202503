<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><section epub:type="chapter" role="doc-chapter" aria-labelledby="ch13">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_207" aria-label="207"/>&#13;
<hgroup>&#13;
&#13;
<h2 class="CHAPTER" id="ch13">&#13;
<span class="CN"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">13</samp></span>&#13;
<span class="CT"><samp class="SANS_Dogma_OT_Bold_B_11">RANDOM WALKS</samp></span>&#13;
</h2>&#13;
</hgroup>&#13;
<figure class="opener"><img class="opener" src="../images/opener.jpg" role="presentation" alt="" width="386" height="386"/>&#13;
</figure>&#13;
<p class="ChapterIntro">So far, this book has introduced a variety of algorithms focused on achieving specific goals. This chapter considers algorithms that seek to do something a bit different: inducing <i>random behavior</i> on graphs. Analyzing random movement through a graph allows us to model and study systems with nondeterministic behavior such as randomized network routing or real-world social interactions.</p>&#13;
<p class="TX">Random walks on graphs have a rich mathematical history that extends well beyond the scope of this book. This chapter provides an overview of random walks, an introduction of how to analyze them with Markov chains, and code for implementing a random walk over a graph. We consider the types of questions we can investigate and systems we can model with random walks, such as gambling and luck-based board games. Finally, we consider how we can reconstruct underlying graphs from sample observations.</p>&#13;
<section epub:type="division" aria-labelledby="sec1">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_208" aria-label="208"/>&#13;
<h3 class="H1" id="sec1"><span id="h-162"/><samp class="SANS_Futura_Std_Bold_B_11">Introducing Random Walks</samp></h3>&#13;
<p class="TNI1">A <i>random walk</i> on a graph is a sequence of nodes where the next node in the sequence is chosen randomly based on some probability distribution. We denote the <i>transition probability</i> from node <i>u</i> to node <i>v</i> as:</p>&#13;
<p class="EQ"><i>p</i>(<i>u</i> <span class="symbol">→</span> <i>v</i>) where 0 ≤ <i>p</i>(<i>u</i> <span class="symbol">→</span> <i>v</i>) ≤ 1</p>&#13;
<p class="BodyContinued">This means that whenever we are at a node <i>u</i>, we select the next node from <i>u</i>’s neighbors using the given probability distribution.</p>&#13;
<p class="TX">We can visualize a random walk as a tourist who absolutely refuses to plan ahead. Convinced that serendipity produces the best vacations, they set out to explore the city with neither a map nor a clue as to where they are going. When they reach an intersection, they consider possible routes and choose one at random. The tourist makes each decision in isolation, without thought to past or future transitions.</p>&#13;
<p class="TX">We use the graph structure to restrict probabilities in a few ways. First, we limit movement to nodes that are connected to the current node by an edge. In the case of directed graphs, this must be an edge in the correct direction:</p>&#13;
<p class="EQ"><i>p</i>(<i>u</i> <span class="symbol">→</span> <i>v</i>) = 0 if (<i>u</i>, <i>v</i>) <span class="symbol">∉</span> <i>E</i></p>&#13;
<p class="BodyContinued">In other words, our tourist has no chance of traversing from point <i>u</i> to point <i>v</i> unless there is a road connecting them. For the sake of clarity, in this chapter we also require the probability to be greater than zero if the edge exists:</p>&#13;
<p class="EQ"><i>p</i>(<i>u</i> <span class="symbol">→</span> <i>v</i>) &gt; 0 if (<i>u</i>, <i>v</i>) <span class="symbol">∈</span> <i>E</i></p>&#13;
<p class="BodyContinued">This means that our tourist can, in theory, traverse all the roads in the city.</p>&#13;
<p class="TX">Second, transition probabilities must sum to 1.0 over all outgoing adjacent edges:</p>&#13;
<p class="EQ">∑<span class="ePub-I-SUB">v</span> <i>p</i>(<i>u</i> <span class="symbol">→</span> <i>v</i>) = 1 for every <i>u</i> <span class="symbol">∈</span> <i>V</i></p>&#13;
<p class="BodyContinued">This restricts the probabilities to form a valid distribution. Every node must include at least one outgoing edge. In directed graphs, we can use self-loops <i>p</i>(<i>u</i> <span class="symbol">→</span> <i>u</i>) &gt; 0 to model cases where the walk does not proceed to a new node. This constraint corresponds to the tourist always having at least one path along which to proceed, even if that path loops back to the current location.</p>&#13;
<section epub:type="division" aria-labelledby="sec2">&#13;
&#13;
<h4 class="H2" id="sec2"><span id="h-163"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Probabilities in Random Walks</samp></h4>&#13;
<p class="TNI1">The simplest random walk is one where we choose among the outgoing edges with equal probability. In this case, our hypothetical tourist chooses from the current intersection’s streets completely at random. If the intersection has two outgoing edges, the tourist chooses either with a 50 percent probability. If the intersection has four outgoing edges, they each get a probability of 25 percent. <a href="#fig13-1">Figure 13-1</a> shows an undirected and unweighted graph (a) and the corresponding transition probabilities out of each node (b).</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_209" aria-label="209"/>&#13;
<figure class="IMG"><img id="fig13-1" class="img80" src="../images/f13001.jpg" alt="(A) shows an undirected graph with 4 nodes and 5 edges. Node 0 is adjacent to two edges (0, 1) and (0, 2). (B) shows a directed graph with 4 nodes and 10 edges. Each edge is labeled with a fraction. Node 0 has outgoing edges (0, 1) and (0, 2) with labels of a half." width="1107" height="579"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-1: An undirected graph (a) and its random walk probabilities (b)</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">While we discuss random walks on both directed and undirected graphs, we always model these systems as directed graphs because, in many cases, the transition probabilities between two nodes will not be symmetric. In formal terms:</p>&#13;
<p class="EQ"><i>p</i>(<i>u</i> <span class="symbol">→</span> <i>v</i>) ≠ <i>p</i>(<i>v</i> <span class="symbol">→</span> <i>u</i>)</p>&#13;
<p class="BodyContinued">In <a href="#fig13-1">Figure 13-1(b)</a>, for example, the probability of moving from node 0 to node 1 is 1/2, while the probability of moving in the reverse direction is only 1/3. For our wandering tourist, the probability of traveling between two intersections depends on how many roads branch out from the current intersection.</p>&#13;
<p class="TX">We can use weighted graphs to model more realistic scenarios by assigning different probabilities to each edge and storing them in the edge weights. We constrain these probabilities (the edge weights) such that the sum of probabilities over all outgoing edges equals 1.0. <a href="#fig13-2">Figure 13-2</a> shows an example as a directed, weighted graph. A random walk at node 3 has three possible next states: it can move to node 1 with a probability of 0.2 or to node 2 with a probability of 0.6, or it can stay at node 3 (via a self-loop) with a probability of 0.2.</p>&#13;
<figure class="IMG"><img id="fig13-2" class="img40" src="../images/f13002.jpg" alt="a directed graph with 4 nodes and 10 edges. Each edge is labeled with a number between 0 and 1." width="664" height="554"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-2: A directed graph with transition probabilities</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_210" aria-label="210"/>These more general graphs correspond to a tourist who is probabilistically influenced by factors beyond the number of roads. They tend to head toward areas with more interesting architecture or follow the smell of coffee. When arriving at a particular four-way intersection, they have a surprising 90 percent chance of taking a left toward a street of caf<span class="accent">é</span>s.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec3">&#13;
&#13;
<h4 class="H2" id="sec3"><span id="h-164"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Random Walks as Markov Chains</samp></h4>&#13;
<p class="TNI1">Random walks over a graph’s edges are one example of a <i>Markov chain</i> or <i>Markov model</i>, a system for which the probability of the next state depends solely on the current state. Each step is taken without consideration to the previous path, a property known as <i>time invariance</i>. We draw the connection to Markov chains to allow us to tap into the vast amount of related analysis. The full breadth of research into analyzing different types of Markov chains far exceeds the scope of this book. In this chapter, we will only briefly touch upon a few concepts and terminology that help analyze random walks and demonstrate their modeling power.</p>&#13;
<p class="TX">The time invariance property corresponds to our wandering tourist’s habit of considering only the paths open in front of them. They do not consider pesky details such as where they have already been, how many steps they have taken, or even what time of day it is. While this is not optimal for conventionally regular activities such as eating and sleeping, the tourist resolutely adheres to their randomized vacationing principles.</p>&#13;
<p class="TX">In probability and statistics references, these transition probabilities are often written as <i>p</i>(<i>X</i><span class="ePub-I-SUB">t</span> | <i>X</i><span class="ePub-I-SUB">t</span> <sub>– 1</sub>) to indicate the probability of being in state <i>X</i><span class="ePub-I-SUB">t</span> at timestep <i>t</i> given that the system was in state <i>X</i><span class="ePub-I-SUB">t</span> <sub>– 1</sub> at time <i>t</i> – 1. Combining this shorthand with the graph-based notation, we get the following equation:</p>&#13;
<p class="EQ"><i>p</i>(<i>u</i> <span class="symbol">→</span> <i>v</i>) = <i>p</i>(<i>X</i><span class="ePub-I-SUB">t</span> = <i>v</i> | <i>X</i><span class="ePub-I-SUB">t</span> <sub>– 1</sub> = <i>u</i>)</p>&#13;
<p class="TX">Given the independence of each transition, we can compute the probability of an entire path [<i>v</i><sub>0</sub>, <i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>, . . . , <i>v</i><span class="ePub-I-SUB">k]</span> from a fixed starting node <i>v</i><sub>0</sub> by multiplying the probability of each transition:</p>&#13;
<p class="EQ"><i>p</i>([<i>v</i><sub>0</sub>, <i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>, . . . , <i>v</i><span class="ePub-I-SUB">k</span>]) = ∏<span class="ePub-I-SUB">i</span> <sub>= 1 to</sub> <span class="ePub-I-SUB">k</span> <i>p</i>(<i>X</i><span class="ePub-I-SUB">t</span> = <i>v</i><span class="ePub-I-SUB">i</span> | <i>X</i><span class="ePub-I-SUB">t</span> <sub>– 1</sub> = <i>v</i><span class="ePub-I-SUB">i</span> <sub>– 1</sub>)</p>&#13;
<p class="TX">Markov chains are useful for a wide variety of tasks for which transitions are independent of previous paths. Artificial intelligence uses a variety of (more powerful) Markov models to simulate or reason about a range of real phenomena, from understanding speech to decision-making with autonomous agents. For example, the <i>hidden Markov model</i> is a staple of machine learning that uses random transitions over unseen states, where each state produces noisy output. Efficient algorithms exist for estimating the underlying states from the output or even learning both the transition probabilities and output distributions from sample data.</p>&#13;
<p class="TX">In contrast, the random walks we consider in this chapter represent a particularly simple Markov model. The current state (node) is visible at each state and the decisions are fully random. As we will see, however, even <span role="doc-pagebreak" epub:type="pagebreak" id="pg_211" aria-label="211"/>these seemingly simple models can provide a wealth of simulative and analytical power.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec4">&#13;
&#13;
<h4 class="H2" id="sec4"><span id="h-165"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Transition Probabilities</samp></h4>&#13;
<p class="TNI1">When modeling a random walk on a graph using the edge weights, we require the weights out of each node to form a valid probability distribution. We can test whether the edge weights of our <samp class="SANS_TheSansMonoCd_W5Regular_11">Graph</samp> data structure form a valid probability distribution by iterating over each node and checking that the sum of outgoing edge weights is 1.0, as shown in <a href="#list13-1">Listing 13-1</a>.</p>&#13;
<span id="list13-1"/>&#13;
<pre><code>def is_valid_probability_graph(g: Graph) -&gt; bool: &#13;
    for node in g.nodes:&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> edge_list: list = node.get_edge_list()&#13;
        if len(edge_list) == 0:&#13;
            return False&#13;
&#13;
        total: float = 0.0&#13;
        for edge in edge_list:&#13;
          <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> if edge.weight &lt; 0.0 or edge.weight &gt; 1.0:&#13;
                return False&#13;
            total += edge.weight&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation3">❸</span> if abs(total - 1.0) &gt; 1e-10:&#13;
            return False&#13;
&#13;
    return True&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 13-1: Checking the validity of probabilities stored in the edge weights</samp></p>&#13;
<p class="TX">The code uses a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop to iterate over each node and check that the weights of its outgoing edges form a valid probability distribution. First, it extracts the node’s edge list and checks whether it is empty <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. If so, there is nowhere to go from that node and the code returns <samp class="SANS_TheSansMonoCd_W5Regular_11">False</samp>. The constraint that the sum probabilities out of a node equal 1 requires that every node must have at least one outgoing edge with a nonzero weight, even if it is a self-loop.</p>&#13;
<p class="TX">The code uses a second <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop to iterate over the outgoing edges. It checks that each edge has a valid probability between 0.0 and 1.0, immediately returning <samp class="SANS_TheSansMonoCd_W5Regular_11">False</samp> if not <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>, then adds the current the edge weight to the total. After reviewing all edges, the code checks if the total weight is 1.0, allowing for a small accumulation of floating-point errors <span class="CodeAnnotationCode" aria-label="annotation3">❸</span>. It returns <samp class="SANS_TheSansMonoCd_W5Regular_11">True</samp> only if all these conditions pass for all nodes and edges.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec5">&#13;
&#13;
<h4 class="H2" id="sec5"><span id="h-166"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Matrix Formulation</samp></h4>&#13;
<p class="TNI1">The matrix representation of a graph is useful when analyzing properties of a random walk on the graph and is commonly used in statistics and machine learning texts to describe random walks. In the matrix representation, transition probabilities are often specified using a <i>transition matrix</i> (<i>M</i>) where the value in row <i>i</i> and column <i>j</i> of the matrix corresponds to the probability of moving to node <i>j</i> given that the walk is at node <i>i</i>:</p>&#13;
<p class="EQ">M[<i>i</i>][<i>j</i>] = <i>p</i>(<i>i</i> <span class="symbol">→</span> <i>j</i>)</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_212" aria-label="212"/>We can even reuse the <samp class="SANS_TheSansMonoCd_W5Regular_11">GraphMatrix</samp> data structure from <span class="Xref"><a href="chapter1.xhtml">Chapter 1</a></span> to store these values. Because we restrict the entries to be probabilities, we impose additional restrictions to the values in <samp class="SANS_TheSansMonoCd_W5Regular_11">GraphMatrix</samp>’s <samp class="SANS_TheSansMonoCd_W5Regular_11">connection</samp> list:</p>&#13;
<ul class="BL">&#13;
<li class="BL">0 ≤ <samp class="SANS_TheSansMonoCd_W5Regular_11">connections[i][j]</samp> ≤ 1 for all <samp class="SANS_TheSansMonoCd_W5Regular_11">i</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">j</samp></li>&#13;
<li class="BL">∑<span class="ePub-I-SUB">j</span> <samp class="SANS_TheSansMonoCd_W5Regular_11">connections[i][j]</samp> = 1 for all <samp class="SANS_TheSansMonoCd_W5Regular_11">i</samp></li>&#13;
</ul>&#13;
<p class="BodyContinued">These constraints mirror the restrictions placed on edge weights earlier.</p>&#13;
<p class="TX">We can use matrix math to model the effect of taking a random step. We let <i>V</i><span class="ePub-I-SUB">t</span> be a vector of probabilities such that <i>V</i><span class="ePub-I-SUB">t</span> [<i>u</i>] is the probability that our random walk is at node <i>u</i> (so 0 ≤ <i>V</i><span class="ePub-I-SUB">t</span> [<i>u</i>] ≤ 1 for each <i>u</i> and ∑<span class="ePub-I-SUB">u</span> <i>V</i><span class="ePub-I-SUB">t</span> [<i>u</i>] = 1) at time step <i>t</i>. For example, we would use <i>V</i><span class="ePub-I-SUB">t</span> = [0.5, 0.4, 0.0, 0.1] to represent the probability that our walk is at each of the four nodes in <a href="#fig13-2">Figure 13-2</a>. The vector indicates there is a 50 percent chance of being at node 0, a 40 percent chance of being at node 1, a 0 percent chance of being at node 2, and a 10 percent chance of being at node 4.</p>&#13;
<p class="TX">The vector <i>V</i><sub>0</sub> gives the probability of starting the walk at each of the nodes. For example, <i>V</i><sub>0</sub> = [1.0, 0.0, 0.0, 0.0] indicates a deterministic start at node 0, while <i>V</i><sub>0</sub> = [0.5, 0.5, 0.0, 0.0] indicates an equal chance of starting from either node 0 or node 1. The vector <i>V</i><sub>1</sub> then gives the probability of being at each node after randomly starting the walk according to <i>V</i><sub>0</sub> and taking a single additional random step. <i>V</i><sub>2</sub> indicates the probability after two steps of the random walk and so forth.</p>&#13;
<p class="TX">We can use matrix algebra with the transition matrix <i>M</i> to compute subsequent probability distributions:</p>&#13;
<p class="EQ"><i>V</i><span class="ePub-I-SUB">t</span> <sub>+ 1</sub> = <i>V</i><span class="ePub-I-SUB">t</span> <i>M</i></p>&#13;
<p class="BodyContinued">Each entry <i>V</i><span class="ePub-I-SUB">t</span> <sub>+ 1</sub> [<i>u</i>] gives us the probability that our random walk is at node <i>u</i> at the following time step <i>t</i> + 1. We can even add a method to the <samp class="SANS_TheSansMonoCd_W5Regular_11">GraphMatrix</samp> class that performs this computation, as shown in <a href="#list13-2">Listing 13-2</a>.</p>&#13;
<span id="list13-2"/>&#13;
<pre><code>def simulate_random_step(self, Vt: list) -&gt; list: &#13;
    if len(Vt) != self.num_nodes:&#13;
        raise ValueError("Incorrect length of probability dist")&#13;
&#13;
    Vnext: list = [0.0] * self.num_nodes&#13;
    for i in range(self.num_nodes):&#13;
        for j in range(self.num_nodes):&#13;
            Vnext[j] += Vt[i] * self.connections[i][j]&#13;
    return Vnext&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 13-2: Simulating a single step of a random walk on a graph</samp></p>&#13;
<p class="TX">The code starts by checking that the incoming vector <samp class="SANS_TheSansMonoCd_W5Regular_11">Vt</samp> has the correct length and, if not, raising an error. It then creates a result vector <samp class="SANS_TheSansMonoCd_W5Regular_11">Vnext</samp> and uses a pair of nested <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loops to perform the computation. It returns the new vector of probabilities.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_213" aria-label="213"/>&#13;
<blockquote>&#13;
<p class="Note"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_15">NOTE</samp></span></p>&#13;
</blockquote>&#13;
<p class="Note-TXT"><i>As mentioned in <a href="chapter1.xhtml">Chapter 1</a>, the code in this book uses a list of lists to represent matrices for the purposes of illustration. For the sake of efficiency, production code for this computation should use a library that supports efficient matrix operations, such as</i> <samp class="SANS_TheSansMonoCd_W7Italic">numpy</samp><i>.</i></p>&#13;
<p class="TX">The computation for simulating a random step also works from a deterministic state: <i>V</i>[<i>u</i>] = 1 for exactly one node <i>u</i>. By then multiplying <i>V</i><span class="ePub-I-SUB">t</span> <sub>+ 1</sub> = <i>V</i><span class="ePub-I-SUB">t</span> <i>M</i>, we get the probability distribution of where our random walk will be after exactly one step away from <i>u</i>. We can repeat this process by multiplying by <i>M</i> again as follows:</p>&#13;
<p class="EQ"><i>V</i><span class="ePub-I-SUB">t</span> <sub>+ 2</sub> = <i>V</i><span class="ePub-I-SUB">t</span> <i>M M</i></p>&#13;
<p class="BodyContinued">This gives us the probability distribution of nodes that are reached in exactly two steps.</p>&#13;
<p class="TX">Alternatively, we can extend our matrix notation such that <i>M</i><span class="ePub-I-SUB">t</span> is the transition matrix for a random walk of exactly <i>t</i> steps, so <i>M</i><span class="ePub-I-SUB">t</span> [<i>u</i>][<i>v</i>] is the probability of transitioning from node <i>u</i> to node <i>v</i> in exactly <i>t</i> steps. We can compute this matrix directly using matrix multiplication:</p>&#13;
<p class="EQ"><i>M</i><span class="ePub-I-SUB">t</span> = ∏<span class="ePub-I-SUB">I</span> <sub>= 1 to</sub> <span class="ePub-I-SUB">t</span> <i>M</i></p>&#13;
<p class="TX">While the matrix formulation is useful for describing and analyzing the properties of a random walk, the code in the remainder of the chapter uses the adjacency list representation of our <samp class="SANS_TheSansMonoCd_W5Regular_11">Graph</samp> class for consistency with the other chapters. All the functions can be adapted to work with the <samp class="SANS_TheSansMonoCd_W5Regular_11">GraphMatrix</samp> class.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec6">&#13;
&#13;
<h3 class="H1" id="sec6"><span id="h-167"/><samp class="SANS_Futura_Std_Bold_B_11">Use Cases</samp></h3>&#13;
<p class="TNI1">Random walks are used to model and analyze problems that involve non-deterministic behavior. Random behavior shows up in a wide range of real-world systems, from human interaction to the explicit randomness in some computer algorithms. In this section, we look at three example use cases: social networks, randomized explorations, and games of chance.</p>&#13;
<section epub:type="division" aria-labelledby="sec7">&#13;
&#13;
<h4 class="H2" id="sec7"><span id="h-168"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Information Chains in Social Networks</samp></h4>&#13;
<p class="TNI1">We can use random walks to model how a rumor spreads through a social network where the interactions have a random component. Determined not to gossip excessively, each person in the network resolves to pass information to only a single other person when they hear a rumor. However, they are bursting to share the latest gossip as soon as they hear it, so they share the news with the first person they come across. This is inherently a probabilistic selection, as they don’t know which friend they’ll run into first. After sharing their news, they are temporarily satisfied and hold off on discussing the rumor until it is shared with them again.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_214" aria-label="214"/>We could model the social network as a graph where the edges represent the probability that each neighbor is the person with whom the rumor is shared. The rumor itself randomly walks the graph, getting passed from person to person.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec8">&#13;
&#13;
<h4 class="H2" id="sec8"><span id="h-169"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Exploration</samp></h4>&#13;
<p class="TNI1">Previous chapters discussed numerous algorithms for deterministically exploring graphs, such as depth-first search or A* search. However, many real-world explorations involve a randomized element, such as weather-based path closures. Random walks allow us to model systems with such constraints.</p>&#13;
<p class="TX">Consider the explorer from <span class="Xref"><a href="chapter8.xhtml">Chapter 8</a></span> searching for a best path to an archeological site. The current conditions might add a random element to their exploration. When faced with a fork in the path, the northern route might have a 50 percent chance of being flooded out, while the southern route has a 10 percent chance of being blocked by an angry swarm of hornets. Taking these probabilities into account, we could model their unpleasant journey through the jungle as a random walk.</p>&#13;
<p class="TX">We can use a similar approach to analyze robot path planning in dynamic environments. A search-and-rescue robot exploring a damaged building may run into different obstacles at different times, such as fires or flooded passages, and need to reroute.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec9">&#13;
&#13;
<h4 class="H2" id="sec9"><span id="h-170"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Games of Chance</samp></h4>&#13;
<p class="TNI1">We can also use a random walk to simulate the outcomes of games of chance. Graph nodes represent different game states, and the edges indicate the possible (probabilistic) changes in those states. For example, we can use the Markov chain shown in <a href="#fig13-3">Figure 13-3</a> to represent a gambler playing a one-dollar slot machine.</p>&#13;
<figure class="IMG"><img id="fig13-3" class="img100" src="../images/f13003.jpg" alt="A linear chain of nodes. Each node has a directed edge to the left with probability 0.99 and an edge 9 nodes to the right with a probability of 0.01." width="1364" height="317"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-3: A subset of nodes for a gambler’s graph</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Each state represents the number of dollars in the gambler’s possession. Each pull of the slot machine decides the next state without regard to previous pulls or the gambler’s current financial situation. Maybe the machine has a 1 in 100 chance of paying out 10 dollars, moving the gambler from state <i>k</i> to state <i>k</i> + 9, and a 99 in 100 of chance of paying out nothing, moving the gambler from state <i>k</i> to <i>k</i> – 1.</p>&#13;
<p class="TX">As we model more complex games of chance, we need correspondingly more complex graphs. Later in this chapter we show how to use graphs to <span role="doc-pagebreak" epub:type="pagebreak" id="pg_215" aria-label="215"/>model luck-based board games. We discuss nodes that simultaneously represent multiple players’ states and the transitions among them.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec10">&#13;
&#13;
<h3 class="H1" id="sec10"><span id="h-171"/><samp class="SANS_Futura_Std_Bold_B_11">Simulating Random Walks</samp></h3>&#13;
<p class="TNI1">One powerful approach to understanding random walks and their underlying graph is to <i>repeatedly simulate</i> a random walk over the graph and analyze the paths taken. We simulate a random walk on a graph by repeatedly selecting the next state based on the probability distribution over the neighbors of the current state. As a prerequisite, we need a function to sample from a finite set of options with pre-specified probabilities.</p>&#13;
<p class="TX">We provide a simple algorithm for illustration purposes that draws a random number uniformly within [0, 1) and checks to which neighbor it corresponds by iterating over each outgoing edge and accumulating the cumulative probability of the previous nodes. We are effectively breaking the range [0, 1) into regions for each option where the size of the region corresponds to the probability of that option. <a href="#fig13-4">Figure 13-4</a> shows an example where 50 percent of the range leads to node 0, 20 percent leads to node 1, and 30 percent leads to node 3.</p>&#13;
<p class="TX">By tracking the cumulative probability seen so far while iterating over the options, we are tracking the start and end of each region and comparing it to the selected value. We want to find the bin whose region brackets our randomly selected value. As soon as we cross the bin edge where the cumulative value exceeds the randomly selected value, we know we have gone too far.</p>&#13;
<figure class="IMG"><img id="fig13-4" class="img70" src="../images/f13004.jpg" alt="A bar from 0.0 to 1.0 divided into three sections. The first section spans 0.0 to 0.5 and is labeled node 0." width="1087" height="182"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-4: The transition probability to three nodes and the corresponding cumulative probability</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The code for a random walk on a graph consists of a random number generation followed by a single <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop that iterates over the outgoing edges, as shown in <a href="#list13-3">Listing 13-3</a>.</p>&#13;
<span id="list13-3"/>&#13;
<pre><code>def choose_next_node(current: Node) -&gt; int: &#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> prob: float = random.random()&#13;
    cumulative: float = 0.0&#13;
    edge_list: list = current.get_edge_list()&#13;
&#13;
    for edge in edge_list:&#13;
        cumulative += edge.weight&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> if cumulative &gt;= prob:&#13;
            return edge.to_node&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation3">❸</span> return edge_list[-1].to_node&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 13-3: Choosing the next node in a random walk</samp></p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_216" aria-label="216"/>The code starts by drawing a random number from [0, 1) using Python’s <samp class="SANS_TheSansMonoCd_W5Regular_11">random</samp> library <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. It then uses a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop over each outgoing edge to compute the total (cumulative) probability seen so far. The selected edge is the first one whose weight causes this cumulative probability to exceed the selected random number <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>. If the code makes it to the end of the list (due to imprecisions in how floating-point numbers are stored), the code simply returns the last edge <span class="CodeAnnotationCode" aria-label="annotation3">❸</span>.</p>&#13;
<p class="TX">The <samp class="SANS_TheSansMonoCd_W5Regular_11">choose_next_node()</samp> function in <a href="#list13-3">Listing 13-3</a> does not perform any validity checks on the probability distribution leaving each node. This is intentional so as not to pay the cost of performing the check each time the function is called. Instead, I recommend checking the distributions for all nodes once using the <samp class="SANS_TheSansMonoCd_W5Regular_11">is_valid_probability_graph()</samp> function from <a href="#list13-1">Listing 13-1</a>.</p>&#13;
<p class="TX">Given this helper function, the code to perform the random walk from a given starting node (<samp class="SANS_TheSansMonoCd_W5Regular_11">start</samp>) is relatively short:</p>&#13;
<pre><code>def random_walk(g: Graph, start: int, steps: int) -&gt; list: &#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> if not is_valid_probability_graph(g):&#13;
        raise ValueError("Graph weights are not probabilities.")&#13;
&#13;
    walk: list = [-1] * steps&#13;
    current: int = start&#13;
    walk[0] = current&#13;
    for i in range(1, steps):&#13;
      <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> current = choose_next_node(g.nodes[current])&#13;
        walk[i] = current&#13;
&#13;
    return walk&#13;
</code></pre>&#13;
<p class="TX">The function starts by confirming that the graph’s weights represent a valid probability distribution and raising an error if not <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. It then allocates a list <samp class="SANS_TheSansMonoCd_W5Regular_11">walk</samp> to store the results, sets the current node to the start node, and sets the first step in the walk to the start node. The code uses a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop to iterate through each step, using the <samp class="SANS_TheSansMonoCd_W5Regular_11">choose_next_node()</samp> function from <a href="#list13-3">Listing 13-3</a> to continually select the next node from the current one <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>. The code adds the new node to the <samp class="SANS_TheSansMonoCd_W5Regular_11">walk</samp> list, which it returns after taking all the steps.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec11">&#13;
&#13;
<h3 class="H1" id="sec11"><span id="h-172"/><samp class="SANS_Futura_Std_Bold_B_11">Statistical Measures</samp></h3>&#13;
<p class="TNI1">Random walks are a powerful tool for understanding randomized systems and computing a variety of practical statistics measures. For example, we might want to find the probability of reaching a particular node or determine how many steps it will take to get there. These measures are useful in answering questions such as “What is the probability a gambler will lose all their money?” or “How long (on average) will it take a rumor to reach me?” or “If a tourist randomly wanders the city for years, how long will they spend at each location?”</p>&#13;
<p class="TX">In this section, we briefly consider how such questions apply to the case of our wandering tourist and outline how to compute the answers. After <span role="doc-pagebreak" epub:type="pagebreak" id="pg_217" aria-label="217"/>considering the probability of reaching specific nodes and the average number of steps to do so, we analyze the long-term behavior of random walks.</p>&#13;
<section epub:type="division" aria-labelledby="sec12">&#13;
&#13;
<h4 class="H2" id="sec12"><span id="h-173"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Hitting and Absorption Time</samp></h4>&#13;
<p class="TNI1">The <i>hitting time</i> of a set of nodes <i>A</i> <span class="symbol">⊂</span> <i>V</i> is the average number of steps a random walk must take before it first hits a node in <i>A</i> from a given starting node. For example, if <i>A</i> is the set of all intersections with caf<span class="accent">é</span>s in the town our tourist is exploring, they might want to calculate the hitting time of that set to find out when they are likely to get their next cup of coffee.</p>&#13;
<p class="TX">If a random walk cannot leave the nodes in <i>A</i>, we refer to these hitting times as <i>absorption times</i> because the walk is absorbed into <i>A</i>. For example, in <a href="#fig13-5">Figure 13-5</a>, node <i>k</i> forms an absorbing set. Once a walk arrives at node <i>k</i>, it stays there forever.</p>&#13;
<figure class="IMG"><img id="fig13-5" class="img30" src="../images/f13005.jpg" alt="A node with multiple incoming edges and a single outgoing edge labeled 1.0 that forms a self-loop." width="335" height="293"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-5: An absorbing set consisting of a single node in a graph</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Absorbing nodes can also be used to represent the termination of a random walk. As a concrete example, the tourist could decide to stop their random walk when they hit their hotel.</p>&#13;
<p class="TX">When analyzing random walks on graphs, we often consider two statistical quantities related to hitting times: the probability the walk will reach the subset and the expected time to do so.</p>&#13;
<section epub:type="division" aria-labelledby="sec13">&#13;
&#13;
<h5 class="H3" id="sec13"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">Hitting Probability and Absorption Probability</samp></h5>&#13;
<p class="TNI1">The <i>hitting probability</i> for a subset of nodes <i>A</i> <span class="symbol">⊆</span> <i>V</i> is the probability that a random walk from node <i>u</i> will hit a node <i>v</i> <span class="symbol">∈</span> <i>A</i> in that subset. We can use this measure to answer questions like “What is the probability that our tourist will encounter a coffee shop?” Similarly, the <i>absorption probability</i> for a subset of nodes <i>A</i> is the probability that a random walk from node <i>u</i> will be absorbed by that subset. This allows us to ask questions like “What is the probability the tourist will return to the hotel and stop their random walk?”</p>&#13;
<p class="TX">Absorbing subsets of nodes can impact the hitting probability of non-absorbing nodes. For example, consider the weighted graph in <a href="#fig13-6">Figure 13-6</a>, which shows a graph with three nodes and an absorbing subset of {0, 1}.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_218" aria-label="218"/>&#13;
<figure class="IMG"><img id="fig13-6" class="img70" src="../images/f13006.jpg" alt="A graph with three nodes. Node 0 has a self-loop with weight 0.25 and an edge to node 1 with weight 0.75. Node 1 has a single edge to node 0 with a weight of 1.0. Node 2 has a self-loop with weight 0.5 and an edge to node 1 with weight 0.5." width="913" height="177"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-6: A graph with three nodes and transition probabilities</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The probability that a walk starting from node 2 will hit node 0 is 1.0 given a potentially infinite number of steps. In contrast, once the walk hits the nodes <i>A</i> = {0, 1}, it can never travel to node 2, as it will be stuck in an endless set of steps connected to nodes 0 and 1.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec14">&#13;
&#13;
<h5 class="H3" id="sec14"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">Expected Hitting Time</samp></h5>&#13;
<p class="TNI1">The <i>expected hitting time</i> is the expected number of steps a random walk takes (on average) before it first hits a node in <i>A</i>. This allows us to determine how long on average it will take our tourist to get their next coffee. The <i>absorption time</i> is similar, quantifying the expected time until the random walk reaches the absorbing set. For our tourist, this would be how long their walk will be on average (before they reach their hotel and stop for the day).</p>&#13;
<p class="TX">For example, the expected hitting time of node 1 from node 0 (denoted <i>h</i><sub>01</sub>) in <a href="#fig13-6">Figure 13-6</a> is as follows:</p>&#13;
<p class="ListPlain"><i>h</i><sub>01</sub> = 1 × <i>p</i>(first hit node 1 after 1 step)</p>&#13;
<p class="ListPlain">+ 2 × <i>p</i>(first hit node 1 after 2 steps)</p>&#13;
<p class="ListPlain">+ 3 × <i>p</i>(first hit node 1 after 3 steps) + . . .</p>&#13;
<p class="ListPlain"><i>h</i><sub>01</sub> = 1 × ¾ + 2 × ¼ × ¾ + 3 × (¼)<sup>2</sup> × ¾ + 4 × (¼)<sup>3</sup> × ¾ + . . .</p>&#13;
<p class="ListPlain"><i>h</i><sub>01</sub> = 4/3</p>&#13;
<p class="TX">This is because the possible walks from node 0 include walks that start [0, 1], [0, 0, 1], [0, 0, 0, 1], and so forth. If we have the full transition matrix, we can use a set of equations to solve for the expected hitting times.</p>&#13;
<p class="TX">The expected hitting time may be infinite, like that from node 0 to node 2 (<i>h</i><sub>02</sub>) in <a href="#fig13-6">Figure 13-6</a>. No matter how long of a walk we consider, we can never hit node 2 from node 0.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec15">&#13;
&#13;
<h4 class="H2" id="sec15"><span id="h-174"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Stationary Distribution</samp></h4>&#13;
<p class="TNI1"><i>Stationary distribution</i> represents the distribution of visits to each state if we keep wandering a strongly connected graph forever. This distribution provides insight into how likely we are to spend time at each node. For example, we could ask, “After our tourist has been wandering for days, what is the probability that they are currently at the caf<span class="accent">é</span> on Fifth Street?” We can also use stationary distribution to predict the probable locations of millions of wandering tourists all following the same randomized rules as they traverse a city.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_219" aria-label="219"/>Returning to the matrix notation introduced earlier in the chapter (where <i>M</i> is the transition matrix and <i>V</i><span class="ePub-I-SUB">t</span> is a vector of probabilities such that <i>V</i><span class="ePub-I-SUB">t</span> [<i>u</i>] is the probability that our random walk is at node <i>u</i> at time step <i>t</i>), the stationary distribution is a vector <i>V</i><sup>*</sup> where:</p>&#13;
<p class="EQ"><i>V</i><sup>*</sup> = <i>V</i> <sup>*</sup><i>M</i></p>&#13;
<p class="BodyContinued">In other words, adding one more step to the random walk will not change the distribution of the possible locations.</p>&#13;
<p class="TX">We can derive stationary distributions from the structure of the graph. Consider the two-node graph in <a href="#fig13-7">Figure 13-7</a>, where <i>M</i> = [[0.25, 0.75], [0.5, 0.5]].</p>&#13;
<figure class="IMG"><img id="fig13-7" class="img40" src="../images/f13007.jpg" alt="The graph has two nodes. Node 0 has a self-loop with weight 0.25 and an edge to node 1 with weight 0.75. Node 1 has a self-loop with weight 0.5 and an edge to node 0 with a weight of 0.5." width="642" height="177"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-7: A graph with two nodes and four transition probabilities</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The structure of the graph in <a href="#fig13-7">Figure 13-7</a> indicates that over the long term, random walks will tend to spend more time at node 1 than at node 0. The probability of staying at node 0, due to a self-loop, is only 0.25, while the probability of staying at node 1 is 0.5. We can quantify that difference in time spent at each node by using the stationary distribution, which for this graph is <i>V</i><sup>*</sup> = [0.4, 0.6].</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec16">&#13;
&#13;
<h3 class="H1" id="sec16"><span id="h-175"/><samp class="SANS_Futura_Std_Bold_B_11">Luck-Based Board Games</samp></h3>&#13;
<p class="TNI1">We can bring together the topics in this section to consider one of the most entertaining applications of random walks: analyzing luck-based board games for children. These games involve no actual choices, but instead rely on random numbers generated by spinners or dice to decide the moves. After hours spent spinning dials that determine whether a plastic piece moves ahead one, two, or three spaces, even non-statistically minded people might inquire about the expected absorption time of the goal state by asking, “How much longer do I have to play this game?” We can answer such questions by modeling the game as a random walk on a graph.</p>&#13;
<p class="TX">Consider the simple example of a game where the goal is to be the first player to complete a circuit of the board. During their turn, each player uses a small spinner labeled with 1, 2, and 3 that indicates how many steps to take. <a href="#fig13-8">Figure 13-8</a> shows a graphical representation of several states in this game. The nodes’ numbers correspond to the squares on the board, where the player is currently at square <i>k</i>. Based on the random spinner, they could move to squares <i>k</i> + 1, <i>k</i> + 2, or <i>k</i> + 3, each with a 1/3 probability.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_220" aria-label="220"/>&#13;
<figure class="IMG"><img id="fig13-8" class="img100" src="../images/f13008.jpg" alt="A line of graph nodes. Each node k has three outgoing edges, to node k + 1, k + 2, and k + 3." width="1301" height="573"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-8: A graph representing sample states of a spinner-based game</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">In an attempt to make the game more exciting (or possibly to cause more children to cry in frustration), the creators label some of the squares “Go back X spaces.” These represent traps that should be avoided at all costs. We can incorporate this behavior directly into our graph.</p>&#13;
<p class="TX"><a href="#fig13-9">Figure 13-9</a> shows the state graph where square <i>k</i> + 2 contains the instructions “Move back one space.” This effectively removes node <i>k</i> + 2 from the graph (represented in the figure by graying out the node). It is not possible to finish a turn in that state. The transition probabilities of the neighboring nodes change correspondingly. The probability of going from node <i>k</i> to <i>k</i> + 1 increases from 1/3 to 2/3, because now spins of both 1 and 2 will end on square <i>k</i> + 1. Similarly, a spin of 1 from node <i>k</i> + 1 will land the player back on node <i>k</i> + 1. We model this as a self-loop with probability 1/3.</p>&#13;
<figure class="IMG"><img id="fig13-9" class="img100" src="../images/f13009.jpg" alt="A line of graph nodes. Nodes have edges to themselves and to nodes further right." width="1301" height="574"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-9: A graph representing the movements from state</samp> <samp class="SANS_Futura_Std_Book_11">k</samp> <samp class="SANS_Futura_Std_Book_Oblique_I_11">in a spinner-based game</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">While we can add more edges to capture square-based and spinner-based transitions, significantly more complexity is required to capture aspects such as player-player interactions. The graph model presented so far in this section captures only the dynamics of a single random walk through the board game. This works fine if all players are independent. However, if the game provides the ability to knock a player back two squares when <span role="doc-pagebreak" epub:type="pagebreak" id="pg_221" aria-label="221"/>someone lands on their square, we need a model that incorporates both players’ positions.</p>&#13;
<p class="TX">We can create such models by increasing the number of nodes to match the available states of the board game. Instead of <i>N</i> nodes for <i>N</i> squares, we could use 2<i>N</i><sup>2</sup> nodes by modeling the game state as a tuple of Alice’s location (player 1’s state), Bob’s location (player 2’s state), and a Boolean indicating whether it is Alice’s turn. For example, the tuple <samp class="SANS_TheSansMonoCd_W5Regular_11">(5, 4, False)</samp> indicates that Alice is on square 5, Bob is on square 4, and it is Bob’s turn. If we combine the three-option spinner with the new “knock-back” rule, there is a 1/3 probability that Bob will spin a 1, move forward a square, and knock Alice back two squares. More formally, <i>p</i>(<samp class="SANS_TheSansMonoCd_W5Regular_11">(5, 4, False)</samp> <span class="symbol">→</span> <samp class="SANS_TheSansMonoCd_W5Regular_11">(3, 5, True)</samp>) = 1/3.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec17">&#13;
&#13;
<h3 class="H1"><span id="sec17"/><span id="h-176"/><samp class="SANS_Futura_Std_Bold_B_11">Transition Probabilities</samp></h3>&#13;
<p class="TNI1">Beyond analyzing given graphs, we can extend the concepts in this chapter to <i>estimating</i> the graphs themselves from observed data. Imagine that we’ve found the logbook of a tourist who spent the last year randomly wandering the streets of an unknown city. Each entry lists at least a location and a time. Eager to understand their journey, we consider their long sequence of visited locations.</p>&#13;
<p class="TX">We can easily reconstruct individual nodes from the location names, such as Integer Square and Floating Point Harbor. With a little reasoning, we can also identify the existence of edges; for example, the transition from Integer Square to If-Then Intersection implies an edge connects them. After hours of studying the tourist’s agonizingly looping path, we step back and try to reconstruct their transition matrix.</p>&#13;
<section epub:type="division" aria-labelledby="sec18">&#13;
&#13;
<h4 class="H2"><span id="sec18"/><span id="h-177"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Maximum Likelihood Estimations</samp></h4>&#13;
<p class="TNI1">We can estimate a transition matrix using a sequence of observations that result from one or more walks to statistically estimate transition probabilities. A <i>maximum likelihood estimation</i> allows us to find the model parameters (transition probabilities) that maximize the chance that we will see the sampled data given those parameters. We won’t discuss the mathematical details of this approach here, but in short, a maximum likelihood estimation uses the independence of each step to compute the transition probability from node <i>u</i> to node <i>v</i> by counting the following two quantities:</p>&#13;
<p class="RunInPara"><b><i>N</i></b><span class="ePub-BI-SUB">u</span><b> </b>The number of times node <i>u</i> appears in the data at the start of a move (not the last node in the path)</p>&#13;
<p class="RunInPara"><b><i>N</i></b><span class="ePub-BI-SUB">u</span> <sub>→</sub> <span class="ePub-BI-SUB">v</span><b> </b>The number of times node <i>v</i> appears immediately after node <i>u</i> in the data</p>&#13;
<p class="TX">Given this information, we compute the probability of a transition as follows:</p>&#13;
<p class="EQ"><i>p</i>(<i>u</i> <span class="symbol">→</span> <i>v</i>) ≈ <i>N</i><span class="ePub-I-SUB">u</span> <sub>→</sub> <span class="ePub-I-SUB">v</span> / <i>N</i><span class="ePub-I-SUB">u</span></p>&#13;
<p class="BodyContinued"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_222" aria-label="222"/>If we have departed 100 times from node 1, and 30 of those times we moved directly to node 3, we estimate <i>p</i>(1 <span class="symbol">→</span> 3) = 30 / 100 = 0.3.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec19">&#13;
&#13;
<h4 class="H2" id="sec19"><span id="h-178"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">A Transition Matrix Estimation Algorithm</samp></h4>&#13;
<p class="TNI1">The algorithm to estimate an underlying graph from observational data consists of three phrases. In the first phase, we use the nodes visited along the walks to compute the number of nodes for the graph. This corresponds to scanning through the tourist’s logbook and determining how many intersections we will need to track. Second, we construct the count array for the number of times the tourist visited each node (<i>N</i><span class="ePub-I-SUB">u)</span> and the count matrix for the node-to-node transitions (<i>N</i><span class="ePub-I-SUB">u</span> <sub>→</sub> <span class="ePub-I-SUB">v)</span>. We compute the counts by iterating over the steps in the walk, effectively retracing the tourist’s journey. Finally, we build the graph by inserting edges for all nonzero node-to-node transitions.</p>&#13;
<p class="TX">Because we are constructing the graph from nodes in the walk, we include only those nodes that the algorithm visits at least once. This means that, given a disconnected graph, we would capture only the graph that is reachable from the initial starting node(s). If the tourist is frightened of water and refuses to cross bridges, we might miss all of the locations on the other side of the river.</p>&#13;
<p class="TX"><a href="#list13-4">Listing 13-4</a> reflects these three phases.</p>&#13;
<span id="list13-4"/>&#13;
<pre><code>def estimate_graph_from_random_walks(walks: list) -&gt; Graph: &#13;
    num_nodes: int = 0&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> for path in walks:&#13;
        for node in path:&#13;
            if node &gt;= num_nodes:&#13;
                num_nodes = node + 1&#13;
&#13;
    counts: list = [0.0] * num_nodes&#13;
    move_counts: list = [[0.0] * num_nodes for _ in range(num_nodes)]&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> for path in walks:&#13;
        for i in range(0, len(path) - 1):&#13;
            counts[path[i]] += 1.0&#13;
            move_counts[path[i]][path[i + 1]] += 1.0&#13;
&#13;
    g: Graph = Graph(num_nodes)&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation3">❸</span> for i in range(num_nodes):&#13;
        if counts[i] &gt; 0.0:&#13;
            for j in range(num_nodes):&#13;
              <span class="CodeAnnotationCode-1" aria-label="annotation4">❹</span> if move_counts[i][j] &gt; 0.0:&#13;
                    g.insert_edge(i, j, move_counts[i][j] / counts[i])&#13;
    return g&#13;
</code></pre>&#13;
<p class="CodeListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 13-4: Estimating a transition matrix from observed data</samp></p>&#13;
<p class="TX">The function takes in a list of lists (<samp class="SANS_TheSansMonoCd_W5Regular_11">walks</samp>) that contain the nodes visited on multiple random walks. The code starts by using a pair of nested <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loops to iterate over each walk and each node in that walk and records the highest index seen <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. It then allocates data structures for the two sets of counts (<samp class="SANS_TheSansMonoCd_W5Regular_11">counts</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">move_counts</samp>) and fills these using a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop to iterate over <span role="doc-pagebreak" epub:type="pagebreak" id="pg_223" aria-label="223"/>each step in the path <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>. Once it has completed the counts, the code creates a graph (<samp class="SANS_TheSansMonoCd_W5Regular_11">g</samp>) and iterates over each pair of nodes with two nested <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loops <span class="CodeAnnotationCode" aria-label="annotation3">❸</span>. If the transition count between the two nodes is nonzero <span class="CodeAnnotationCode" aria-label="annotation4">❹</span>, it computes the probability and inserts the corresponding edge into the graph.</p>&#13;
<p class="TX">Keep in mind that using the highest index seen has the downside that if the underlying graph consists of multiple disconnected components, the re-created graph will include indices that we will never visit. Since these indices have a count of zero, they will not be given any outgoing edges, and the resulting graph will fail the <samp class="SANS_TheSansMonoCd_W5Regular_11">is_valid_probability_graph()</samp> check. We use the maximum index approach in <a href="#list13-4">Listing 13-4</a> for simplicity and consistency with previous chapters, but a more robust approach is to use a <i>node name</i> to index mapping, as described in <span class="Xref"><a href="appendix_A.xhtml">Appendix A</a></span>.</p>&#13;
<p class="TX">As an example of estimating the graph, consider a travel journal that consists of two paths and contains visits to numbered buildings:</p>&#13;
<pre><code>path1 = [0, 1, 0, 0, 1, 0, 0]&#13;
path2 = [0, 1, 0, 1, 0, 0, 0]&#13;
</code></pre>&#13;
<p class="TX">We can feed these paths into our estimation function to learn about our tourist’s vacation behavior:</p>&#13;
<pre><code>g = estimate_graph_from_random_walks([path1, path2])&#13;
</code></pre>&#13;
<p class="TX">A few points immediately jump out when looking at the paths. First, the tourist always started from node 0. Second, they visited only two buildings, 0 and 1. In this case, building 0 is the hotel with a caf<span class="accent">é</span> in the lobby, while building 1 is the coffee shop across the street.</p>&#13;
<p class="TX">As we compute the maximum likelihood estimate, we accumulate the following values:</p>&#13;
<p class="EQ"><i>N</i><sub>0</sub> = 8, <i>N</i><sub>1</sub> = 4</p>&#13;
<p class="EQ"><i>N</i><sub>0 → 0</sub> = 4, <i>N</i><sub>0 → 1</sub> = 4, <i>N</i><sub>1 → 0</sub> = 4, <i>N</i><sub>1 → 1</sub> = 0</p>&#13;
<p class="BodyContinued">The tourist started a move from node 0 eight times (<i>N</i><sub>0</sub> = 8). Four of those times they stayed at node 0 (<i>N</i><sub>0 → 0</sub> = 4), and four times they went to node 1 (<i>N</i><sub>0 → 1</sub> = 4). They started moves from node 1 four times, always going to node 0 (<i>N</i><sub>1 → 0</sub> = 4) and never to node 1 (<i>N</i><sub>1 → 1</sub> = 0).</p>&#13;
<p class="TX">We use these statistics to estimate the pairwise transition probabilities:</p>&#13;
<p class="ListPlain"><i>p</i>(0 <span class="symbol">→</span> 0) = 4 / 8 = 0.5</p>&#13;
<p class="ListPlain"><i>p</i>(0 <span class="symbol">→</span> 1) = 4 / 8 = 0.5</p>&#13;
<p class="ListPlain"><i>p</i>(1 <span class="symbol">→</span> 0) = 4 / 4 = 1.0</p>&#13;
<p class="ListPlain"><i>p</i>(1 <span class="symbol">→</span> 1) = 0 / 4 = 0.0</p>&#13;
<p class="BodyContinued">These probabilities provide the edge weights for the estimated graph, as shown in <a href="#fig13-10">Figure 13-10</a>. Note that we do not include the edge (1, 1) because it has a weight of 0.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_224" aria-label="224"/>&#13;
<figure class="IMG"><img id="fig13-10" class="img40" src="../images/f13010.jpg" alt="A graph with two nodes and three edges. Node 0 has a self-loop with a weight 0.5 and an edge to node 1 with a weight 0.5. Node 1 has a single edge back to node 0 with a weight 1.0." width="607" height="177"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-10: A graph with edge transition probabilities estimated from data</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">When at the hotel, the tourist has a 50 percent chance of staying at the hotel and a 50 percent chance of going across the street to the coffee shop. However, when at the coffee shop, they always return directly to the hotel.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec20">&#13;
&#13;
<h4 class="H2" id="sec20"><span id="h-179"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Limitations of Working with Finite Data</samp></h4>&#13;
<p class="TNI1">Of course, our estimates of transition probability are likely to be very noisy until we accumulate significant observations. If we have a big enough graph, we might never have a chance to observe certain nodes or low-probability edges. This is a fundamental problem of working with random data. If our tourist has a 5 percent chance of turning down a narrow alley, they might reasonably skip it each of the 10 times we see them at its entrance.</p>&#13;
<p class="TX">Using statistics, we can analyze not only the maximum likelihood values but also their error bars and our confidence levels. These analyses are outside the scope of this book. For now, we just give a word of caution against trying to draw rigorous conclusions from a small amount of random data.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec21">&#13;
&#13;
<h3 class="H1" id="sec21"><span id="h-180"/><samp class="SANS_Futura_Std_Bold_B_11">Random Starting Nodes</samp></h3>&#13;
<p class="TNI1">We can extend both our model and its estimation to account for cases where the random walk starts at different nodes. The idea of a <i>random starting node</i> may not seem intuitive since physical walks start at a single location such as the tourist’s hotel. However, randomized starts can represent a variety of real-world phenomena, such as the tourist randomly leaving one of many hotels or a rumor starting at a random point in a social network.</p>&#13;
<p class="TX">Let’s label the vector of starting probabilities <i>S</i> where <i>S</i>[<i>u</i>] indicates the probability that we start our random walk at node <i>u</i>. Since <i>S</i> contains probabilities, we restrict 0 ≤ <i>S</i>[<i>u</i>] ≤ 1 and ∑<span class="ePub-I-SUB">u</span> <i>S</i>[<i>u</i>] = 1.</p>&#13;
<section epub:type="division" aria-labelledby="sec22">&#13;
&#13;
<h4 class="H2" id="sec22"><span id="h-181"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Choosing a Random Starting Node</samp></h4>&#13;
<p class="TNI1">We can directly sample the starting node with the same approach we used for <samp class="SANS_TheSansMonoCd_W5Regular_11">choose_next_node()</samp> in <a href="#list13-3">Listing 13-3</a>:</p>&#13;
<pre><code>def choose_start(S: list) -&gt; int: &#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> prob: float = random.random()&#13;
    cumulative: float = 0.0&#13;
&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> for i in range(len(S)):&#13;
        cumulative += S[i]<span role="doc-pagebreak" epub:type="pagebreak" id="pg_225" aria-label="225"/>&#13;
        if cumulative &gt;= prob:&#13;
            return i&#13;
    return len(S) - 1&#13;
</code></pre>&#13;
<p class="TX">The <samp class="SANS_TheSansMonoCd_W5Regular_11">choose_start()</samp> function draws a random number from [0, 1) using Python’s <samp class="SANS_TheSansMonoCd_W5Regular_11">random</samp> library <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. Instead of iterating over a node’s edges as in <samp class="SANS_TheSansMonoCd_W5Regular_11">choose_next_node()</samp>, the function iterates over the values in <i>S</i> until it finds the correct one <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>.</p>&#13;
<p class="TX">As a more detailed example, imagine an evil wizard who creates dungeons that use randomized entryways to prevent former adventurers from writing strategy guides (thereby messing with the adventurers’ retirement plans). The wizard teleports each new arrival to a random location using a carefully chosen distribution <i>S</i>. They restrict adventurers from ever starting their quest in the treasure room by setting that room’s starting probability to zero, <i>S</i>[<i>treasure</i>] = 0. To reduce the ability for adventurers to share information, the wizard also enforces <i>S</i>[<i>room</i>] &lt; 0.1 for all rooms, meaning that there is less than a 10 percent chance the adventurers will start in any particular room.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec23">&#13;
&#13;
<h4 class="H2" id="sec23"><span id="h-182"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Estimating the Probability Distribution for Starting Nodes</samp></h4>&#13;
<p class="TNI1">If we run many random walks, we might be interested in estimating the distribution over starting states. We can use a similar approach to that of the transition probabilities to estimate the starting probabilities. If <i>N</i><sub>0</sub>[<i>u</i>] is the number of walks that start at node <i>u</i>, then we define the probability of starting at node <i>u</i> as the fraction of times a walk started from that node:</p>&#13;
<p class="EQ">S[<i>u</i>] = <i>N</i><sub>0</sub>[<i>u</i>] / ∑<span class="ePub-I-SUB">v</span> <i>N</i><sub>0</sub>[<i>v</i>]</p>&#13;
<p class="BodyContinued">We can implement this estimation in the following code:</p>&#13;
<pre><code>def estimate_start_from_random_walks(walks: list) -&gt; list: &#13;
    num_nodes: int = 0&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> for path in walks:&#13;
        for node in path:&#13;
            if node &gt;= num_nodes:&#13;
                num_nodes = node + 1&#13;
    counts: list = [0.0] * num_nodes&#13;
&#13;
  <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> for path in walks:&#13;
        counts[path[0]] += 1.0&#13;
&#13;
    for i in range(num_nodes):&#13;
        counts[i] = counts[i] / len(walks)&#13;
    return counts&#13;
</code></pre>&#13;
<p class="TX">Like the code for estimating the transition probabilities, the code to estimate the starting probabilities starts by computing the maximum node index and creating a data structure to track occurrences <span class="CodeAnnotationCode" aria-label="annotation1">❶</span>. In this case, however, the code looks only at the first node in the walk. It uses a single <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop over the different walks to count how many of the walks start at <span role="doc-pagebreak" epub:type="pagebreak" id="pg_226" aria-label="226"/>each node <span class="CodeAnnotationCode" aria-label="annotation2">❷</span>. It then computes the empirical probability of starting at each node.</p>&#13;
<p class="TX">Our adventurer could theoretically use this approach to gather information for their upcoming strategy guide. They enter the dungeon a few hundred times, carefully tracking where they land each time. It is up to them to decide whether the payoff of writing a comprehensive guide to this dungeon is worth the hassle of navigating through the same dungeon over and over again.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec24">&#13;
&#13;
<h3 class="H1" id="sec24"><span id="h-183"/><samp class="SANS_Futura_Std_Bold_B_11">Why This Matters</samp></h3>&#13;
<p class="TNI1">Analyzing random walks on graphs is useful for both understanding the structure of a graph and analyzing its underlying system. More importantly, however, the concept of random walks extends the range of real-world problems we can model with graph algorithms. We can move beyond deterministic questions, such as how to find the shortest path between two nodes, to account for more realistic behaviors. For example, to model path planning with occasional wrong turns, we could use a random walk that takes the optimal path most of the time but makes a random error at some intersections.</p>&#13;
<p class="TX">In the next chapter, we switch topics and consider the graphs from a perspective of overall capacity, finding the maximum flow through a network to model systems from plumbing to transportation.</p>&#13;
</section>&#13;
</section>&#13;
</div>
</div>
</body></html>