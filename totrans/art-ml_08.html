<html><head></head><body>
<div id="sbo-rt-content" class="calibre1"><h2 class="h1" id="ch06"><span epub:type="pagebreak" id="page_95" class="calibre2"/><strong class="calibre3"><span class="big">6</span><br class="calibre18"/>TWEAKING THE TREES</strong></h2>
<p class="centera"><em class="calibre13">AdaBoost is the best off-the-shelf classifier in the world.</em></p>
<p class="centerb">—CART co-inventor Leo Breiman, 1996</p>
<p class="centera"><em class="calibre13">XGBoost is the algorithm of choice for many winning teams of machine learning competitions.</em></p>
<p class="centerb">—Wikipedia entry, 2022</p>
<div class="imagec"><img alt="Image" src="../images/common.jpg" class="calibre14"/></div>
<p class="noindent">Here we talk about two general techniques in ML, <em class="calibre13">bagging</em> and <em class="calibre13">boosting</em>, and apply them to form extensions of decision tree analysis. The extensions, <em class="calibre13">random forests</em> and <em class="calibre13">tree-based gradient boosting</em>, are widely used—in fact, even more so than individual tree methods.<span epub:type="pagebreak" id="page_96"/></p>
<h3 class="h2" id="ch06lev1">6.1 Bias vs. Variance, Bagging, and Boosting</h3>
<p class="blockquotea"><em class="calibre13">For want of a nail the shoe was lost;</em></p>
<p class="blockquotea"><em class="calibre13">for want of a shoe the horse was lost;</em></p>
<p class="blockquotea"><em class="calibre13">and for want of a horse the man was lost.</em></p>
<p class="blockquoter">—Old proverb</p>
<p class="noindenta1">We must always bear in mind that we are dealing with sample data. Sometimes the “population” being sampled is largely conceptual; for example, in the taxi data in <a href="ch05.xhtml#ch05lev3" class="calibre12">Section 5.3</a>, we are considering the data a sample from the ridership in all days, past, present, and future. But in any case, there is sampling variation.</p>
<p class="indent">In the bike rental data, say, what if the data collection period had continued one more day? Even this slight change might affect the exact split at the top of the tree, Node 1. And that effect could then change the splits (or possibly non-splits) at Nodes 2 and 3 and so on, with the those changes cascading down to the lowest levels of the resulting tree. Note that not only might the split points in the nodes change, but the membership of the nodes could also change. A training set data point that had been in Node 2 may now be in Node 3. In other words:</p>
<p class="blockquote">Decision trees can be very sensitive to slight changes in the inputs. That means they are very sensitive to sampling variation—that is, <strong class="calibre5">decision trees have a high variance.</strong></p>
<p class="noindent">Recall that splitting a node reduces bias and that, typically, reducing bias also increases variance. But for the reason given above, variance may be especially problematic in DT settings.</p>
<p class="indent">In this chapter, we treat two major methods for handling this problem, <em class="calibre13">bagging/random forests</em> and <em class="calibre13">boosting</em>. Both take this point of view: “Variance too high? Well, that means the sample size is too small, so let’s generate more trees!” But how?</p>
<h3 class="h2" id="ch06lev2">6.2 Bagging: Generating New Trees by Resampling</h3>
<p class="noindent">The term <em class="calibre13">bagging</em> refers to an ML version of a handy tool from modern statistics known as the <em class="calibre13">bootstrap</em>. This consists of drawing many random subsamples from our data, applying our given estimator to each subsample, and then averaging (or otherwise combining) the results. Here we apply the bootstrap to decision trees.</p>
<p class="indent">Starting with our original data, once again considered a sample from some population, we’ll generate <em class="calibre13">s</em> new samples from the original dataset. We generate a new sample by randomly sampling <em class="calibre13">m</em> of our <em class="calibre13">n</em> data points—<em class="calibre13">with</em>  replacement. (We may get a few duplicates.) We’ll fit a tree to each new sample, thus achieving the above goal of generating more trees, and combine the results in a manner to be presented shortly. The quantities <em class="calibre13">s</em> and <em class="calibre13">m</em> here are—you guessed it—hyperparameters.<span epub:type="pagebreak" id="page_97"/></p>
<h4 class="h3" id="ch06lev2sec1"><em class="calibre22"><strong class="calibre3">6.2.1 Random Forests</strong></em></h4>
<p class="noindent">Say we have a new case to be predicted. We will then <em class="calibre13">aggregate</em> the <em class="calibre13">s</em> trees by forming a prediction for each tree and then combining all those predicted values to form our final prediction as follows:</p>
<ul class="calibre15">
<li class="noindent3">In a numeric-<em class="calibre13">Y</em> setting, the combining would take the form of averaging all the predictions. In the taxi data, for example (see <a href="ch05.xhtml#ch05lev3" class="calibre12">Section 5.3</a>), each tree would give us a predicted trip time, and our final predicted trip time would be the average of all those individual predictions.</li>
<li class="noindent3">In a classification setting, such as the vertebrae example we covered in <a href="ch02.xhtml#ch02lev3" class="calibre12">Section 2.3</a>, we could combine by using a <em class="calibre13">voting</em> process. For each tree, we would find the predicted class, NO, DH, or SL, and then see what class received the most “votes” among the various trees. That would be our predicted class. Or, we could find the estimated class probabilities for this new case, for each tree, and then average the probabilities. Our predicted class would be whichever one has the largest average.</li>
</ul>
<p class="indent">So, we do a bootstrap and then aggregation, hence the short name <em class="calibre13">bagging</em>. It is also commonly known as <em class="calibre13">random forests</em>, a specific implementation by Leo Breiman. (The earliest proposal along these lines seems to be that of Tin Kam Ho. She called the method <em class="calibre13">random decision forests</em>.) That approach places a limit on the number of features under consideration for splitting at any given node, with a different candidate set at each step.</p>
<p class="indent">Why might this strategy, which is using a different candidate set of features each time, work? Ordinary bagging can result in substantially correlated trees because it tends to choose the same features every time. It can be shown that the average of positively correlated numbers has a higher variance than the average of independent numbers. Thus the approach in which we limit the candidate feature set at each step hopefully reduces variance.</p>
<h4 class="h3" id="ch06lev2sec2"><em class="calibre22"><strong class="calibre3">6.2.2 The qeRF() Function</strong></em></h4>
<p class="noindent">The <span class="literal">qe*-</span> series of functions actually includes several for random forests. For a given application, one may be more accurate or faster than others, but they all use the general random forest paradigm described previously. We’ll use <span class="literal">qeRF()</span> here.</p>
<p class="indent">Recall that the <span class="literal">qe*</span> functions all have the following arguments:</p>
<p class="block"><span class="codestrong1">data</span>   A data frame containing our training data.</p>
<p class="block1"><span class="codestrong1">yName</span>   The name of the column in <span class="literal">data</span> containing <em class="calibre13">Y</em>, the outcome variable to be predicted. The user distinguishes between numeric-<em class="calibre13">Y</em> and classification settings by having this column be numeric or an R factor, respectively.<span epub:type="pagebreak" id="page_98"/></p>
<p class="block1"><span class="codestrong1">holdout</span>   The size of the optional holdout set.</p>
<p class="block1"><strong class="calibre5">Application-specific arguments</strong> For example, as the number <em class="calibre13">k</em> of nearest neighbors in the case of <span class="literal">qeKNN()</span>.</p>
<p class="indenta">Each <span class="literal">qe*</span> function is a wrapper interface to a function in a standard R ML package. In the case of random forests, <span class="literal">qeRF()</span> is a wrapper for <span class="literal">randomForest</span> in the package of the same name. The call form is:</p>
<pre class="calibre16">qeRF(data, yName, nTree = 500, minNodeSize = 10,
   holdout = floor(min(1000,0.1 * nrow(data))))</pre>
<p class="noindent">The application-specific arguments are <span class="literal">nTree</span>, which is the number of bootstrapped trees to generate, and <span class="literal">minNodeSize</span>, which is similar to <span class="literal">minsplit</span> in <span class="literal">ctree()</span>.</p>
<h4 class="h3" id="ch06lev2sec3"><em class="calibre22"><strong class="calibre3">6.2.3 Example: Vertebrae Data</strong></em></h4>
<p class="noindent">Let’s look again at the vertebrae dataset from <a href="ch02.xhtml#ch02lev3" class="calibre12">Section 2.3</a>, now applying random forests instead of k-NN. We’ll predict the same hypothetical new case as in that earlier example:</p>
<pre class="calibre16"># fit RF model
&gt; <span class="codestrong">rfout &lt;- qeRF(vert,'V7',holdout=NULL)</span>
# new case to predict
&gt; <span class="codestrong">z &lt;- vert[1,-7]</span>
&gt; <span class="codestrong">z$V2 &lt;- 18</span>
# predict
&gt; <span class="codestrong">predict(rfout,z)</span>
$predClasses
[1] "DH"
<br class="calibre1"/>
$probs
     DH    NO   SL
2 0.532 0.378 0.09
attr(,"class")
[1] "matrix" "array"  "votes"</pre>
<p class="noindent">With k-NN, we had predicted the same class, DH, but with slightly different class probabilities:</p>
<pre class="calibre16">&gt; <span class="codestrong">predict(kout,z)</span>
$predClasses
[1] "DH"
<br class="calibre1"/>
$probs
      DH  NO  SL
[1,] 0.6 0.2 0.2</pre>
<p class="noindent"><span epub:type="pagebreak" id="page_99"/>The difference between the two sets of probabilities is due both to the fact that we used two different ML algorithms and to the small <em class="calibre13">n</em> in this dataset (310), which caused large sample variability.</p>
<p class="indent">We used the default values here for <span class="literal">nTree</span> and <span class="literal">minNodeSize</span>. We could explore a few other pairs of these hyperparameters and then compare the performance of random forests and k-NN on this dataset.</p>
<h4 class="h3" id="ch06lev2sec4"><em class="calibre22"><strong class="calibre3">6.2.4 Example: Remote-Sensing Soil Analysis</strong></em></h4>
<p class="noindent">Here we will analyze the African Soil Property dataset from Kaggle.<sup class="calibre11"><a id="ch6fn1b" class="calibre12"/><a href="footnote.xhtml#ch6fn1" class="calibre12">1</a></sup> From the data site:</p>
<p class="block">Advances in rapid, low cost analysis of soil samples using infrared spectroscopy, georeferencing of soil samples, and greater availability of earth remote sensing data provide new opportunities for predicting soil functional properties at unsampled locations. . . . Digital mapping of soil functional properties, especially in data sparse regions such as Africa, is important for planning sustainable agricultural intensification and natural resources management.</p>
<p class="noindent">We wish to predict various soil properties without directly testing the soil.</p>
<p class="indent">One important property of this dataset that we have not encountered before is that it has <em class="calibre13">p</em> &gt; <em class="calibre13">n</em> (that is, more columns than rows). The original first column, an ID variable, has been removed.</p>
<pre class="calibre16">&gt; <span class="codestrong">dim(afrsoil)</span>
[1] 1157 3599</pre>
<p class="indent">Traditionally, the statistics field has been wary of this kind of setting, as linear models (<a href="ch08.xhtml" class="calibre12">Chapter 8</a>) do not work there. One must first do dimension reduction. Tree-based methods do this as an integral aspect of their operation, so let’s give it a try using <span class="literal">qeRF()</span>.</p>
<p class="indent">Here are the names of the columns:</p>
<pre class="calibre16">&gt; <span class="codestrong">names(afrsoil)</span>
...
[3547] "m659.543" "m657.615" "m655.686" "m653.758" "m651.829" "m649.901"
[3553] "m647.972" "m646.044" "m644.115" "m642.187" "m640.258" "m638.33"
[3559] "m636.401" "m634.473" "m632.544" "m630.616" "m628.687" "m626.759"
[3565] "m624.83"  "m622.902" "m620.973" "m619.045" "m617.116" "m615.188"
[3571] "m613.259" "m611.331" "m609.402" "m607.474" "m605.545" "m603.617"
[3577] "m601.688" "m599.76"  "BSAN"     "BSAS"     "BSAV"     "CTI"
[3583] "ELEV"     "EVI"      "LSTD"     "LSTN"     "REF1"     "REF2"
[3589] "REF3"     "REF7"     "RELI"     "TMAP"     "TMFI"     "Depth"
[3595] "Ca"       "P"        "pH"       "SOC"      "Sand"</pre>
<p class="indent"><span epub:type="pagebreak" id="page_100"/>Columns 1 through 3594 are the <em class="calibre13">X</em> variables, with cryptic code names. The remaining columns are <em class="calibre13">Y</em>, some with more easily guessable names. We’ll predict pH, the soil acidity.</p>
<p class="indent">This kind of setting is considered tough. There is a major potential for overfitting since, with so many features, one or more of them may accidentally look to be a strong predictor due to p-hacking (<a href="ch01.xhtml#ch01lev13" class="calibre12">Section 1.13</a>). Let’s see how well <span class="literal">qeRF()</span> does here.</p>
<pre class="calibre16">&gt; <span class="codestrong">set.seed(9999)</span>
&gt; <span class="codestrong">rfo &lt;- qeRF(afrsoil[,c(1:3578,3597)],'pH',holdout=500)</span>
&gt; <span class="codestrong">rfo$testAcc</span>
[1] 0.3894484
&gt; <span class="codestrong">rfo$baseAcc</span>
[1] 0.6858574</pre>
<p class="noindent">Use of the features has cut MAPE almost in half. Note the range under the pH scale used here:</p>
<pre class="calibre16">&gt; <span class="codestrong">range(afrsoil$pH)</span>
[1] -1.886946  3.416117</pre>
<p class="indent">We are now ready to predict, say, on a hypothetical new case like that of row 88 in the training data:</p>
<pre class="calibre16">&gt; <span class="codestrong">predict(rfo,afrsoil[88,1:3594])</span>
       88
0.6068828</pre>
<p class="indent">We would predict a pH level of about 0.61.</p>
<h3 class="h2" id="ch06lev3">6.3 Boosting: Repeatedly Tweaking a Tree</h3>
<p class="noindent">Imagine a classification problem with just two classes, so <em class="calibre13">Y</em> = 1 or 0, and just one feature, <em class="calibre13">X</em>, say, age. We fit a tree with just one level. Suppose our rule is to guess <em class="calibre13">Y</em> = 1 if <em class="calibre13">X</em> &gt; 12.5 and guess <em class="calibre13">Y</em> = 0 if <em class="calibre13">X</em> ≤ 12.5. <em class="calibre13">Boosting</em> would involve exploring the effect of small changes to the 12.5 threshold on our overall rate of correct classification.</p>
<p class="indent">Consider a data point for which <em class="calibre13">X</em> = 5.2. In the original analysis, we’d guess <em class="calibre13">Y</em> to be 0. And, here is the point, if we were to move the threshold to, say, 11.9, we would <em class="calibre13">still</em> guess <em class="calibre13">Y</em> = 0. But the move may turn some misclassified data points near 12.5 to correctly classified ones. If more formerly misclassified points become correctly classified than vice versa, it’s a win.</p>
<p class="indent">So the idea of boosting is to tweak the original tree, thus forming a new tree, then in turn tweaking that new tree, forming a second new tree, and so on. After generating <em class="calibre13">s</em> trees (<em class="calibre13">s</em> is a hyperparameter), we predict a new case by plugging it into all those trees and somehow combining the resulting predicted values.<span epub:type="pagebreak" id="page_101"/></p>
<h4 class="h3" id="ch06lev3sec1"><em class="calibre22"><strong class="calibre3">6.3.1 Implementation: AdaBoost</strong></em></h4>
<p class="noindent">The first proposal made for boosting was <em class="calibre13">AdaBoost</em>. The tweaking involves assigning weights to the points in our training set, which change with each tree. Each time we form a new tree, we fit a tree according to the latest set of weights, updating them with each new tree.</p>
<p class="indent">In a numeric-<em class="calibre13">Y</em> situation, to predict a new case with a certain <em class="calibre13">X</em> value, we plug that value into all the trees, yielding <em class="calibre13">s</em> predicted values. Our final predicted value in a numeric- <em class="calibre13">Y</em> setting is a weighted average of the individual predictions. In a classification setting, we would take a weighted average of the estimated probabilities of <em class="calibre13">Y</em> = 1 to get the final probability estimate, or use weighted voting.</p>
<p class="indent">To make this idea concrete, below is an outline of how the process could be implemented with <span class="literal">ctree()</span>. It relies on the fact that one of the arguments in <span class="literal">ctree()</span>, named <span class="literal">weights</span>, is a vector of nonnegative numbers, one for each data point. Say our response is named <span class="literal">y</span>, with features <em class="calibre13">x</em>. Denote the portion of the data frame <span class="literal">d</span> for <em class="calibre13">x</em> by <span class="literal">dx</span>.</p>
<p class="indent">In the pseudocode below, we will maintain two vectors of weights:</p>
<ol class="calibre17">
<li class="noindent3"><span class="literal">wts</span> will store the current weightings of the various rows in the training data. Recall that as the boosting process evolves, we will weight some rows more heavily than others according to their current impact on misclassification.</li>
<li class="noindent3"><span class="literal">alpha</span> will store the current weights of our various trees. Recall that in the end, when we do prediction, we will place more weight on some trees than others.</li>
</ol>
<p class="indent">Here is an outline of the algorithm:</p>
<pre class="calibre16">ctboost &lt;- function(d,s) {
   # uniform weights to begin
   wts &lt;- rep(1/n,n)
   trees &lt;- list()
   alpha &lt;- vector(length=s)  # alpha[i] = coefficient for tree i
   for(treeNum in 1:s) {
      trees[[i]] &lt;- ctree(y ~ x,data=d,weights=wts)
      preds &lt;- predict(trees[[i]],dx)
      # update wts, placing larger weight on data points on which
      # we had the largest errors (regression case) or which we
      # misclassified (classification case)
      wts &lt;- (computation not shown)
      # find latest tree weight
      alpha[i] &lt;- (computation not shown)
   }
   l &lt;- list(trees=trees,treeWts=alpha)
   class(l) &lt;- 'ctboost'
   return(l)
}</pre>
<p class="noindent"><span epub:type="pagebreak" id="page_102"/>And to predict a new case, <span class="literal">newx</span>:</p>
<pre class="calibre16">predict.ctboost &lt;- function(ctbObject,newx)
{
   trees &lt;- ctbObject$trees
   alpha &lt;- ctbObject$alpha
   pred &lt;- 0.0
   for (i in 1:s) {
      pred &lt;- pred + alpha[i] * predict(trees[[i]],newx)
   }
   return(pred)
}</pre>
<p class="indent">Since this book is aimed to be nonmathematical, we omit the formulas for <span class="literal">wts</span> and <span class="literal">alpha</span>. It should be noted, though, that <span class="literal">alpha</span> is an increasing sequence, so when we predict new cases, the later trees play a larger role.</p>
<p class="indent">The <span class="literal">qeML</span> package has a function for AdaBoost, <span class="literal">qeAdaBoost()</span>. But it is applicable to classification settings only, so let’s go right to the next form of boosting.</p>
<h4 class="h3" id="ch06lev3sec2"><em class="calibre22"><strong class="calibre3">6.3.2 Gradient Boosting</strong></em></h4>
<p class="noindent">In statistics/ML, there is the notion of a <em class="calibre13">residual</em>—that is, the difference between a predicted value and an actual value. <em class="calibre13">Gradient boosting</em> works by fitting trees to residuals. Given our dataset, a rough description of the process is as follows:</p>
<ol class="calibre17">
<li class="noindent3">Start with some initial tree. Set <em class="calibre13">CurrentTree</em> to it.</li>
<li class="noindent3">For each of our data points, calculate the residuals for <em class="calibre13">CurrentTree</em>.</li>
<li class="noindent3">Fit a tree <em class="calibre13">to the residuals</em>—that is, take our residuals as the “data” and fit a tree T on it. Set <em class="calibre13">CurrentTree</em> = <em class="calibre13">T</em>.</li>
<li class="noindent3">Go to Step 2.</li>
</ol>
<p class="noindent">These steps are iterated for the number of trees specified by the user. Then, to predict a new case, we plug it into all the trees. The predicted value is simply the sum of the predicted values from the individual trees.</p>
<p class="indent">At any given step, we are saying, “Good, we’ve got a certain predictive ability so far, so let’s work on what is left over—that is, our current errors.” Hence our predicted value for any new case is the sum of what each tree predicts for that case.</p>
<h5 class="h4" id="ch06lev3sec2sec1">6.3.2.1 The qeGBoost() Function</h5>
<p class="noindent">The <span class="literal">qe*</span> function for gradient boosting is <span class="literal">qeGBoost()</span>, a wrapper for <span class="literal">gbm()</span> in the package of the same name. Its call form is:</p>
<pre class="calibre16">qeGBoost(data, yName, nTree = 100, minNodeSize = 10, learnRate = 0.1,
    holdout = floor(min(1000, 0.1 * nrow(data))))</pre>
<p class="noindent"><span epub:type="pagebreak" id="page_103"/>This is similar to <span class="literal">qeRF()</span> but with a new argument, the <em class="calibre13">learning rate</em>. That rate is a common notion in ML and will be explained shortly.</p>
<div class="note">
<p class="notet"><strong class="calibre3"><span class="notes">NOTE</span></strong></p>
<p class="notep"><em class="calibre13">A number of gradient boosting packages are available for R. We chose the</em><span class="codeitalic1">gbm</span> <em class="calibre13">package for its simplicity. Just as was the case above for random forests, other packages may be faster or more accurate on some datasets, notably</em><span class="codeitalic1">qeXGBoost</span><em class="calibre13">. Here,</em><span class="codeitalic1">qeGBoost()</span> <em class="calibre13">sticks to the “quick and easy” philosophy of the</em><span class="codeitalic1">qe*</span><em class="calibre13">-series, but the reader is encouraged to explore other packages as an advanced topic.</em></p>
</div>
<h4 class="h3" id="ch06lev3sec3"><em class="calibre22"><strong class="calibre3">6.3.3 Example: Call Network Monitoring</strong></em></h4>
<p class="noindent">Let’s first apply boosting to a dataset titled Call Test Measurements for Mobile Network Monitoring and Optimization,<sup class="calibre11"><a id="ch6fn2b" class="calibre12"/><a href="footnote.xhtml#ch6fn2" class="calibre12">2</a></sup> which rates quality of service on mobile calls. The aim is to predict the quality rating.</p>
<h5 class="h4" id="ch06lev3sec3sec1">6.3.3.1 The Data</h5>
<p class="noindent">Here is an introduction to the data:</p>
<pre class="calibre16">&gt; <span class="codestrong">ds &lt;- read.csv('dataset.csv',stringsAsFactors=TRUE)</span>
&gt; <span class="codestrong">names(ds)</span>
[1] "Date.Of.Test"             "Signal..dBm."
[3] "Speed..m.s."              "Distance.from.site..m."
[5] "Call.Test.Duration..s."   "Call.Test.Result"
[7] "Call.Test.Technology"     "Call.Test.Setup.Time..s."
[9] "MOS"
&gt; <span class="codestrong">ds &lt;- ds[,-1]</span>
&gt; <span class="codestrong">head(ds)</span>
  Signal..dBm. Speed..m.s. Distance.from.site..m. Call.Test.Duration..s.
1          -61       68.80                1048.60                     90
2          -61       68.77                1855.54                     90
3          -71       69.17                1685.62                     90
4          -65       69.28                1770.92                     90
5         -103        0.82                 256.07                     60
6          -61       68.86                 452.50                     90
  Call.Test.Result Call.Test.Technology Call.Test.Setup.Time..s. MOS
1          SUCCESS                 UMTS                     0.56 2.1
2          SUCCESS                 UMTS                     0.45 3.2
3          SUCCESS                 UMTS                     0.51 2.1
4          SUCCESS                 UMTS                     0.00 1.0
5          SUCCESS                 UMTS                     3.35 3.6
6          SUCCESS                 UMTS                     0.00 1.0
...</pre>
<p class="noindent">Here <em class="calibre13">Y</em> is <span class="literal">MOS</span>, the quality of service.<span epub:type="pagebreak" id="page_104"/></p>
<p class="indent">How big is it?</p>
<pre class="calibre16">&gt; <span class="codestrong">dim(ds)</span>
[1] 105828      8</pre>
<p class="indent">Now, let’s fit the model.</p>
<h5 class="h4" id="ch06lev3sec3sec2">6.3.3.2 Fitting the Model</h5>
<p class="noindent">With over 100,000 data points and just 8 features, overfitting should not be an issue in this dataset. It easily satisfies our rough rule of thumb, <em class="calibre13">p</em> &lt; <img alt="Images" class="middle4" src="../images/unch08equ08.jpg"/> (<a href="ch03.xhtml#ch03lev1sec3" class="calibre12">Section 3.1.3</a>). So, let’s not bother with a holdout set. There is still some randomness in the algorithm, though, so for consistency, let’s set the random seed.</p>
<pre class="calibre16">&gt; <span class="codestrong">set.seed(9999)</span>
&gt; <span class="codestrong">gbout &lt;- qeGBoost(ds,'MOS',nTree=750,holdout=NULL)</span></pre>
<p class="noindent">The default value for <span class="literal">nTree</span> is only 100, but we tried a much larger number, 750, for reasons that will become clear below.</p>
<p class="indent">Let’s do a prediction. Say we have a case like <span class="literal">ds[3,]</span> but with distance being 1,500 and duration 62:</p>
<pre class="calibre16">&gt; <span class="codestrong">ds3 &lt;- ds[3,-8]</span>
&gt; <span class="codestrong">ds3[,3] &lt;- 1500</span>
&gt; <span class="codestrong">ds3[,4] &lt;- 62</span>
&gt; <span class="codestrong">predict(gbout,ds3)</span>
[1] 2.462538</pre>
<h5 class="h4" id="ch06lev3sec3sec3">6.3.3.3 Hyperparameter: Number of Trees</h5>
<p class="noindent">But should we have used so many trees? After all, 750 may be overfitting. Maybe the later trees were doing “noise fitting.” The package has a couple of ways of addressing that issue, one of which is to use the auxiliary function <span class="literal">gbm.perf()</span>. Applied to the output of <span class="literal">gbm()</span>, it estimates the optimal number of trees.</p>
<p class="indent">As noted, <span class="literal">qeGBoost()</span> calls <span class="literal">gbm()</span> and places the output of the latter in the <span class="literal">gbmOuts</span> component of its own output. So, we are able to call <span class="literal">gbm.perf()</span>:</p>
<pre class="calibre16">&gt; <span class="codestrong">gbm.perf(gbout$gbmOuts)</span></pre>
<p class="noindent">See the output graph in <a href="ch06.xhtml#ch06fig01" class="calibre12">Figure 6-1</a>. The dashed vertical line shows the estimated “sweet spot”—that is, the best number of trees, 382 in this case. (This value is also printed to the R console.)<span epub:type="pagebreak" id="page_105"/></p>
<div class="image"><img alt="Image" id="ch06fig01" src="../images/ch06fig01.jpg" class="calibre35"/></div>
<p class="figcap"><em class="calibre13">Figure 6-1: Output from</em> <span class="codeitalic">gbm.perf</span></p>
<p class="indent">But we need not refit the model. We can change the number of trees in the prediction:</p>
<pre class="calibre16">&gt; <span class="codestrong">predict(gbout,ds3,newNTree=382)</span>
[1] 2.45214</pre>
<p class="indent">Since we did not form a holdout set, we’ll need to calculate MAPE manually:</p>
<pre class="calibre16">&gt; <span class="codestrong">mean(abs(preds - ds[,8]))</span>
[1] 0.6142699</pre>
<p class="indent">Details on other features of the <span class="literal">gbm</span> package are in its documentation.</p>
<h4 class="h3" id="ch06lev3sec4"><em class="calibre22"><strong class="calibre3">6.3.4 Example: Vertebrae Data</strong></em></h4>
<p class="noindent">Boosting can be used in classification settings as well as numeric-<em class="calibre13">Y</em> cases. (And its usage is probably much more common on the classification side.) Here is <span class="literal">qeGBoost()</span> applied to the the vertebrae data (see <a href="ch02.xhtml#ch02lev3" class="calibre12">Section 2.3</a>).</p>
<pre class="calibre16">&gt; <span class="codestrong">set.seed(9999)</span>
&gt; <span class="codestrong">gbout &lt;- qeGBoost(vert,'V7')</span></pre>
<p class="noindent">And, say we were to predict a new case like that of row 12 in the training set:</p>
<pre class="calibre16">&gt; <span class="codestrong">predict(gbout,vert[12,-7])</span>
$predClasses
[1] "DH"
<br class="calibre1"/>
$probs
            DH        NO          SL
[1,] 0.6283904 0.3694108 0.002198735
<br class="calibre1"/>
attr(,"class")
[1] "qeGBoost"</pre>
<p class="indent"><span epub:type="pagebreak" id="page_106"/>We predict DH, with an estimated probability of about 0.63. (Unfortunately, <span class="literal">gbm.perf()</span> is not available for the multiclass case.)</p>
<h4 class="h3" id="ch06lev3sec5"><em class="calibre22"><strong class="calibre3">6.3.5 Bias vs. Variance in Boosting</strong></em></h4>
<p class="noindent">Boosting is “tweaking” a tree, potentially making it more stable, especially since we are averaging many trees, thus smoothing out “For want of a nail . . .” problems. So, it may reduce variance. By making small adjustments to a tree, we are potentially developing a more detailed analysis, thus reducing bias.</p>
<p class="indent">But all of that is true only “potentially.” Though the tweaking process has some theoretical basis, it still can lead us astray, actually <em class="calibre13">increasing</em> bias and possibly increasing variance too. If the hyperparameter <em class="calibre13">s</em> is set too large, producing too many trees, we may overfit.</p>
<h4 class="h3" id="ch06lev3sec6"><em class="calibre22"><strong class="calibre3">6.3.6 Computational Speed</strong></em></h4>
<p class="noindent">Boosting can take up tons of CPU cycles, so we may need something to speed things up. The <span class="literal">n.cores</span> argument in <span class="literal">gbm()</span> tries to offload computation to different cores in your machine. If you have a quad core system, you may try setting this argument to 4 or even 8 (and then call <span class="literal">gbm()</span> directly rather than through <span class="literal">qeGBoost()</span>).</p>
<h4 class="h3" id="ch06lev3sec7"><em class="calibre22"><strong class="calibre3">6.3.7 Further Hyperparameters</strong></em></h4>
<p class="noindent">Boosting algorithms typically have a number of hyperparameters. We have already mentioned <span class="literal">nTree</span> (<span class="literal">n.trees</span> in <span class="literal">gbm()</span>), which is the number of trees to be generated.</p>
<p class="indent">Another hyperparameter is <span class="literal">minNodeSize</span> (<span class="literal">n.minobsinnode</span> in <span class="literal">gbm()</span>), which is the minimum number of data points we are willing to have in one tree node. As we saw in <a href="ch05.xhtml" class="calibre12">Chapter 5</a>, reducing this value will reduce bias but increase variance.</p>
<p class="indent">The <span class="literal">shrinkage</span> hyperparameter is so important in the general ML context that we’ll cover it in a separate subsection, next.</p>
<h4 class="h3" id="ch06lev3sec8"><em class="calibre22"><strong class="calibre3">6.3.8 The Learning Rate</strong></em></h4>
<p class="noindent">The notion of a learning rate comes up often in ML. We’ll describe it here in general and then explain how it works for gradient boosting. We’ll see it again in our material on support vector machines (<a href="ch10.xhtml" class="calibre12">Chapter 10</a>) and neural networks (<a href="ch11.xhtml" class="calibre12">Chapter 11</a>).</p>
<p class="indent"><span epub:type="pagebreak" id="page_107"/>This section has a bit of math in it, in the form of curves and lines tangent to them, which is an exception to the avowedly nonmathematical nature of this book. But there are still no equations, and even math-averse readers should be able to follow the discussion.</p>
<h5 class="h4" id="ch06lev3sec8sec1">6.3.8.1 General Concepts</h5>
<p class="noindent">Recall that in ML methods we are usually trying to minimize some loss function, such as MAPE, or the overall misclassification error OME. Computationally, this minimization can be a challenge.</p>
<p class="indent">Consider the function graphed in <a href="ch06.xhtml#ch06fig02" class="calibre12">Figure 6-2</a>. It is a function of a one-dimensional variable <em class="calibre13">x</em>, whereas typically our <em class="calibre13">x</em> is high-dimensional, but it will make our point.</p>
<div class="image"><img alt="Image" id="ch06fig02" src="../images/ch06fig02.jpg" class="calibre36"/></div>
<p class="figcap"><em class="calibre13">Figure 6-2: A function to be minimized</em></p>
<p class="indent">There is an overall minimum at approximately <em class="calibre13">x</em> = 2.2. This is termed the <em class="calibre13">global minimum</em>. But there is also a <em class="calibre13">local minimum</em>, at about <em class="calibre13">x</em> = 0.4; that term means that this is the minimum value of the function only for points near—“local to”—0.4. Let’s give the name <em class="calibre13">x</em><sub class="calibre27">0</sub> to the value of <em class="calibre13">x</em> at the global minimum.</p>
<p class="indent">To us humans looking at the graph, it’s clear where <em class="calibre13">x</em><sub class="calibre27">0</sub> is, but we need our software to be able to find it. That may be problematic. Here’s why.</p>
<p class="indent">Most ML algorithms use an <em class="calibre13">iterative</em> approach to finding the desired minimum point <em class="calibre13">x</em><sub class="calibre27">0</sub>. This involves a series of guesses for <em class="calibre13">x</em><sub class="calibre27">0</sub> . The code starts with an initial guess, <em class="calibre13">g</em><sub class="calibre27">0</sub>, say, randomly chosen, then evaluates <em class="calibre13">f</em>(<em class="calibre13">g</em><sub class="calibre27">0</sub>). Based on the result, the algorithm then somehow (see below) updates the guess to <em class="calibre13">g</em><sub class="calibre27">1</sub> . It then evaluates <em class="calibre13">f</em>(<em class="calibre13">g</em><sub class="calibre27">1</sub>), producing the next guess, <em class="calibre13">g</em><sub class="calibre27">2</sub>, and so on.</p>
<p class="indent">The algorithm keeps generating guesses until they don’t change much, say, until | <em class="calibre13">g</em><em class="calibre13"><sub class="calibre27">i</sub></em><sub class="calibre27">+1</sub> − <em class="calibre13">g</em><em class="calibre13"><sub class="calibre27">i</sub></em> | &lt; 0.00000001 for Step <em class="calibre13">i</em>. We say that the algorithm has <span epub:type="pagebreak" id="page_108"/><em class="calibre13">converged</em> to this point. Let’s give the name <em class="calibre13">c</em> to that value of <em class="calibre13">i</em>. It then reports <em class="calibre13">x</em><sub class="calibre27">0</sub>, the global minimum point, to be the latest guess, <em class="calibre13">g</em><em class="calibre13"><sub class="calibre27">c</sub></em>.</p>
<p class="indent">So, what about that “somehow” alluded to above? How does the algorithm generate the next guess from the present one? The answer lies in the <em class="calibre13">gradient</em>. In our simple example here with <em class="calibre13">x</em> being one-dimensional, the gradient is the slope of the function at the given point—that is, the slope of the tangent line to the curve.</p>
<p class="indent">Say our initial guess <em class="calibre13">g</em><sub class="calibre27">0</sub> = 1.1. The tangent line is shown in <a href="ch06.xhtml#ch06fig03" class="calibre12">Figure 6-3</a>. The line is pointing upward to the right—that is, it has a positive slope—so it tells us that by going to the left we will go to smaller values of the function. We want to find the point at which <em class="calibre13">f</em>() is smallest, and the tangent line is saying, “Oh, you want a smaller value than <em class="calibre13">f</em> (1.1)? Move to the left!” But actually we should be moving to the right, toward 2.2, where the global minimum is.</p>
<div class="image"><img alt="Image" id="ch06fig03" src="../images/ch06fig03.jpg" class="calibre37"/></div>
<p class="figcap"><em class="calibre13">Figure 6-3: A function to be minimized, plus the tangent</em></p>
<p class="indent">So, the reader can already see that iterative algorithms are fraught with danger. Worse, it also adds yet another hyperparameter: we must decide not only <em class="calibre13">in which direction</em> to move for our next guess but also <em class="calibre13">how far</em> to move in that direction. The learning rate addresses the latter point.</p>
<p class="indent">As noted, we should be moving to the right from 1.1, not to the left. The function <em class="calibre13">f</em>(<em class="calibre13">x</em>) is fooling the algorithm here. Actually, in this scenario, our algorithm may converge to the wrong point. Or it may not even converge at all and just wander aimlessly.</p>
<p class="indent">This is why typical ML packages allow the user to set the learning rate. Small values may be preferable, as large ones may result in our guesses lurching back and forth, always missing the target. On the other hand, if it is too small, we will just inch along, taking a long time to get there. Or worse, we converge to a local minimum.</p>
<p class="indent"><span epub:type="pagebreak" id="page_109"/>Once again, we have a hyperparameter that we need to be at a “Goldilocks” level—not too large and not too small—and may have to experiment with various values.</p>
<h5 class="h4" id="ch06lev3sec8sec2">6.3.8.2 The Learning Rate in gbm</h5>
<p class="noindent">This is the <span class="literal">shrinkage</span> argument in <span class="literal">gbm()</span>, called <span class="literal">learnRate</span> in <span class="literal">qeGBoost()</span>. Say we set it to 0.2. Recall the pseudocode describing gradient boosting in <a href="ch06.xhtml#ch06lev3sec2" class="calibre12">Section 6.3.2</a>. The revised version is this:</p>
<ol class="calibre17">
<li class="noindent3">Start with an initial tree. Set <em class="calibre13">CurrentTree</em> to it.</li>
<li class="noindent3">For each of our data points, calculate the residuals for <em class="calibre13">CurrentTree</em>.</li>
<li class="noindent3">Fit a tree <em class="calibre13">to the residuals</em>—that is, take our residuals as the “data” and fit a tree T on it. Set <em class="calibre13">CurrentTree</em> to the old <em class="calibre13">CurrentTree</em>, plus <span class="literal">shrinkage * T</span>.</li>
<li class="noindent3">Go to Step 2.</li>
</ol>
<p class="noindent">Here, <span class="literal">shrinkage * T</span> means multiplying all the values in the terminal nodes of the tree by the factor <span class="literal">shrinkage</span>. In the end, we still add up all our trees to produce the “supertree” used in the prediction of new cases.</p>
<p class="indent">Again, a small value of <span class="literal">shrinkage</span> is more cautious and slower, and it may cause us to need more trees in order to get good predictive power. But it may help prevent overfitting.</p>
<h3 class="h2" id="ch06lev4">6.4 Pitfall: No Free Lunch</h3>
<p class="blockquotea"><em class="calibre13">There is no such thing as a free lunch.</em></p>
<p class="blockquoter1">—Old economics saying</p>
<p class="noindenta1">Though Leo Breiman had a point on the considerable value of AdaBoost (especially in saying “off the shelf,” meaning usable with just default values of hyperparameters), that old saying about no free lunch applies as well. As always, applying cross-validation and so on is indispensable to developing good models.</p>
<p class="indent">Similar advice concerns another famous Breiman statement: that it is impossible to overfit using random forests. The reader who has come this far in this book will immediately realize that Breiman did not mean his statement in the way some have interpreted it. Any ML method may overfit. What Breiman meant was that it is impossible to set the value of <em class="calibre13">s</em>, the number of trees, too high. But the trees themselves still can overfit, for example, by having too small a minimum value for the number of data points in a node or, for that matter, by including too many features.<span epub:type="pagebreak" id="page_110"/></p>
</div></body></html>