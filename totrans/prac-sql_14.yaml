- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mining Text to Find Meaningful Data
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, you’ll learn how to use SQL to transform, search, and analyze text. You’ll
    start with simple text wrangling using string formatting and pattern matching
    before moving on to more advanced analysis. We’ll use two data-sets: a small collection
    of crime reports from a sheriff’s department near Washington, DC, and a set of
    speeches delivered by US presidents.'
  prefs: []
  type: TYPE_NORMAL
- en: Text offers plenty of possibilities for analysis. You can extract meaning from
    *unstructured* *data*—paragraphs of text in speeches, reports, press releases,
    and other documents—by transforming it into *structured data*, in rows and columns
    in a table. Or you can use advanced text analysis features, such as PostgreSQL’s
    full-text search. With these techniques, ordinary text can reveal facts or trends
    that might otherwise remain hidden.
  prefs: []
  type: TYPE_NORMAL
- en: Formatting Text Using String Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PostgreSQL has more than 50 built-in string functions that handle routine but
    necessary tasks, such as capitalizing letters, combining strings, and removing
    unwanted spaces. Some are part of the ANSI SQL standard, and others are specific
    to PostgreSQL. You’ll find a complete list of string functions at [https://www.postgresql.org/docs/current/functions-string.html](https://www.postgresql.org/docs/current/functions-string.html),
    but in this section we’ll examine several you might use often.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can try each of these in a simple query that places a function after `SELECT`,
    like this: `SELECT upper(''hello'');`. Examples of each function plus code for
    all the listings in this chapter are available at [https://nostarch.com/practical-sql-2nd-edition/](https://nostarch.com/practical-sql-2nd-edition/).'
  prefs: []
  type: TYPE_NORMAL
- en: Case Formatting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The capitalization functions format the text’s case. The `upper(``string``)`
    function capitalizes all alphabetical characters of a string passed to it. Nonalphabetic
    characters, such as numbers, remain unchanged. For example, `upper('Neal7')` returns
    `NEAL7`. The `lower(``string``)` function lowercases all alphabetical characters
    while keeping nonalphabetic characters unchanged. For example, `lower('Randy')`
    returns `randy`.
  prefs: []
  type: TYPE_NORMAL
- en: The `initcap(``string``)` function capitalizes the first letter of each word.
    For example, `initcap('at the end of the day')` returns `At The End Of The Day`.
    This function can be handy for formatting titles of books or movies, but because
    it doesn’t recognize acronyms, it’s not always the perfect solution. For example,
    `initcap('Practical SQL')` returns `Practical Sql`, because it doesn’t recognize
    SQL as an acronym.
  prefs: []
  type: TYPE_NORMAL
- en: The `upper()` and `lower()` functions are ANSI SQL standard commands, but `initcap()`
    is PostgreSQL-specific. These three functions give you enough options to rework
    a column of text into the case you prefer. Note that capitalization does not work
    with all locales or languages.
  prefs: []
  type: TYPE_NORMAL
- en: Character Information
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Several functions return data about the string and are helpful on their own
    or combined with other functions. The `char_length(``string``)` function returns
    the number of characters in a string, including any spaces. For example, `char_length('
    Pat ')` returns a value of `5`, because the three letters in `Pat` and the spaces
    on either end total five characters. You can also use the non-ANSI SQL function
    `length(``string``)` to count strings, which has a variant that lets you count
    the length of binary strings.
  prefs: []
  type: TYPE_NORMAL
- en: The `position(``substring` `in` `string``)` function returns the location of
    the substring characters in the string. For example, `position(', ' in 'Tan, Bella')`
    returns `4`, because the comma and space characters (`,` ) specified in the substring
    passed as the first parameter starting at the fourth index position in the main
    string `Tan, Bella`.
  prefs: []
  type: TYPE_NORMAL
- en: Both `char_length()` and `position()` are in the ANSI SQL standard.
  prefs: []
  type: TYPE_NORMAL
- en: Removing Characters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `trim(``characters` `from` `string``)` function removes characters from
    the beginning and end of a string. To declare one or more characters to remove,
    add them to the function followed by the keyword `from` and the string you want
    to change. Options to remove `leading` characters (at the front of the string),
    `trailing` characters (at the end of the string), or `both` make this function
    super flexible.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, `trim(''s'' from ''socks'')` removes `s` characters at the beginning
    and end, returning `ock`. To remove only the `s` at the end of the string, add
    the `trailing` keyword before the character to trim: `trim(trailing ''s'' from
    ''socks'')` returns `sock`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you don’t specify any characters to remove, `trim()` removes spaces at either
    end of the string by default. For example, `trim('' Pat '')` returns `Pat` without
    the leading or trailing spaces. To confirm the length of the trimmed string, we
    can nest `trim()` inside `char_length()` like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This query should return `3`, the number of letters in `Pat`, which is the result
    of `trim(' Pat ')`.
  prefs: []
  type: TYPE_NORMAL
- en: The `ltrim(``string``,` `characters``)` and `rtrim(``string``,` `characters``)`
    functions are PostgreSQL-specific variations of the `trim()` function. They remove
    characters from the left or right ends of a string. For example, `rtrim('socks',
    's')` returns `sock` by removing only the `s` on the right end of the string.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting and Replacing Characters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `left(``string``,` `number``)` and `right(``string``,` `number``)` functions,
    both ANSI SQL standard, extract and return selected characters from a string.
    For example, to get just the `703` area code from the phone number `703-555-1212`,
    use `left(''703-555-1212'', 3)` to specify that you want the first three characters
    of the string starting from the left. Likewise, `right(''703-555-1212'', 8)` returns
    eight characters from the right: `555-1212`.'
  prefs: []
  type: TYPE_NORMAL
- en: To substitute characters in a string, use the `replace(``string``,` `from``,`
    `to``)` function. To change `bat` to `cat`, for example, you would use `replace('bat',
    'b', 'c')` to specify that you want to replace the `b` in `bat` with a `c`.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know basic functions for manipulating strings, let’s look at how
    to match more complex patterns in text and turn those patterns into data we can
    analyze.
  prefs: []
  type: TYPE_NORMAL
- en: Matching Text Patterns with Regular Expressions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Regular expressions* (or *regex*) are a type of notational language that describes
    text patterns. If you have a string with a noticeable pattern (say, four digits
    followed by a hyphen and then two more digits), you can write a regular expression
    that matches the pattern. You can then use the notation in a `WHERE` clause to
    filter rows by the pattern or use regular expression functions to extract and
    wrangle text that contains the same pattern.'
  prefs: []
  type: TYPE_NORMAL
- en: Regular expressions can seem inscrutable to beginning programmers; they take
    practice to comprehend because they use single-character symbols that aren’t intuitive.
    Getting an expression to match a pattern can involve trial and error, and each
    programming language has subtle differences in the way it handles regular expressions.
    Still, learning regular expressions is a good investment because you gain superpower-like
    abilities to search text using many programming languages, text editors, and other
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, I’ll provide enough regular expression basics to work through
    the exercises. To learn more, I recommend interactive online code testers, such
    as [https://regexr.com/](https://regexr.com/) or [https://www.regexpal.com/](https://www.regexpal.com/),
    which have notation references.
  prefs: []
  type: TYPE_NORMAL
- en: Regular Expression Notation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Matching letters and numbers using regular expression notation is straightforward
    because letters and numbers (and certain symbols) are literals that indicate the
    same characters. For example, `Al` matches the first two characters in `Alicia`.
  prefs: []
  type: TYPE_NORMAL
- en: For more complex patterns, you’ll use combinations of the regular expression
    elements in [Table 14-1](#table14-1).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 14-1: Regular Expression Notation Basics'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Expression** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `.` | A dot is a wildcard that finds any character except a newline. |'
  prefs: []
  type: TYPE_TB
- en: '| `[FGz]` | Any character in the square brackets. Here, *F*, *G*, or *z*. |'
  prefs: []
  type: TYPE_TB
- en: '| `[a-z]` | A range of characters. Here, lowercase *a* to *z*. |'
  prefs: []
  type: TYPE_TB
- en: '| `[^a-z]` | The caret negates the match. Here, not lowercase *a* to *z*. |'
  prefs: []
  type: TYPE_TB
- en: '| `\w` | Any word character or underscore. Same as `[A-Za-z0-9_]`. |'
  prefs: []
  type: TYPE_TB
- en: '| `\d` | Any digit. |'
  prefs: []
  type: TYPE_TB
- en: '| `\s` | A space. |'
  prefs: []
  type: TYPE_TB
- en: '| `\t` | Tab character. |'
  prefs: []
  type: TYPE_TB
- en: '| `\n` | Newline character. |'
  prefs: []
  type: TYPE_TB
- en: '| `\r` | Carriage return character. |'
  prefs: []
  type: TYPE_TB
- en: '| `^` | Match at the start of a string. |'
  prefs: []
  type: TYPE_TB
- en: '| `$` | Match at the end of a string. |'
  prefs: []
  type: TYPE_TB
- en: '| `?` | Get the preceding match zero or one time. |'
  prefs: []
  type: TYPE_TB
- en: '| `*` | Get the preceding match zero or more times. |'
  prefs: []
  type: TYPE_TB
- en: '| `+` | Get the preceding match one or more times. |'
  prefs: []
  type: TYPE_TB
- en: '| `{``m``}` | Get the preceding match exactly `m` times. |'
  prefs: []
  type: TYPE_TB
- en: '| `{``m``,``n``}` | Get the preceding match between `m` and `n` times. |'
  prefs: []
  type: TYPE_TB
- en: '| `a``&#124;``b` | The pipe denotes alternation. Find either `a` or `b`. |'
  prefs: []
  type: TYPE_TB
- en: '| `( )` | Create and report a capture group or set precedence. |'
  prefs: []
  type: TYPE_TB
- en: '| `(?: )` | Negate the reporting of a capture group. |'
  prefs: []
  type: TYPE_TB
- en: Using these regular expressions, you can match various characters and indicate
    how many times and where to match them. For example, placing characters inside
    square brackets (`[]`) lets you match any single character or a range. So, `[FGz]`
    matches a single `F`, `G`, or `z`, whereas `[A-Za-z]` will match any uppercase
    or lowercase letter.
  prefs: []
  type: TYPE_NORMAL
- en: The backslash (`\`) precedes a designator for special characters, such as a
    tab (`\t`), digit (`\d`), or newline (`\n`), which is a line ending character
    in text files.
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to indicate how many times to match a character. Placing
    a number inside curly brackets indicates you want to match it that many times.
    For example, `\d{4}` matches four digits in a row, and `\d{1,4}` matches one to
    four digits.
  prefs: []
  type: TYPE_NORMAL
- en: The `?`, `*`, and `+` characters provide a useful shorthand notation for the
    number of matches you want. The plus sign (`+`) after a character indicates to
    match it one or more times, for example. So, the expression `a+` would find the
    `aa` characters in the string `aardvark`.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, parentheses indicate a *capture group*, which you can use to identify
    a portion of the entire matched expression. For example, if you were hunting for
    an `HH``:``MM``:``SS` time format in text and wanted to report only the hour,
    you could use an expression such as `(\d{2}):\d{2}:\d{2}`. This looks for two
    digits (`\d{2}`) of the hour followed by a colon, another two digits for the minutes
    and a colon, and then the two-digit seconds. By placing the first `\d{2}` inside
    parentheses, you can extract only those two digits, even though the entire expression
    matches the full time.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 14-2](#table14-2) shows examples of combining regular expressions to
    capture different portions of the sentence “The game starts at 7 p.m. on May 2,
    2024.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 14-2: Regular Expression Matching Examples'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Expression** | **What it matches** | **Result** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `.+` | Any character one or more times | `The game starts at 7 p.m. on May
    2, 2024.` |'
  prefs: []
  type: TYPE_TB
- en: '| `\d{1,2} (?:a.m.&#124;p.m.)` | One or two digits followed by a space and
    *a.m.* or *p.m.* in a noncapture group | `7 p.m.` |'
  prefs: []
  type: TYPE_TB
- en: '| `^\w+` | One or more word characters at the start | `The` |'
  prefs: []
  type: TYPE_TB
- en: '| `\w+.$` | One or more word characters followed by any character at the end
    | `2024.` |'
  prefs: []
  type: TYPE_TB
- en: '| `May&#124;June` | Either of the words *May* or *June* | `May` |'
  prefs: []
  type: TYPE_TB
- en: '| `\d{4}` | Four digits | `2024` |'
  prefs: []
  type: TYPE_TB
- en: '| `May \d, \d{4}` | *May* followed by a space, digit, comma, space, and four
    digits | `May 2, 2024` |'
  prefs: []
  type: TYPE_TB
- en: These results show the usefulness of regular expressions for matching the parts
    of the string that interest us. For example, to find the time, we use the expression
    `\d{1,2} (?:a.m.|p.m.)` to look for either one or two digits because the time
    could be a single or double digit followed by a space. Then we look for either
    `a.m.` or `p.m.`; the pipe symbol separating the terms indicates the either-or
    condition, and placing them in parentheses separates the logic from the rest of
    the expression. We need the `?:` symbol to indicate that we don’t want to treat
    the terms inside the parentheses as a capture group, which would report `a.m.`
    or `p.m.` only. The `?:` ensures that the full match will be returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use any of these regular expressions by placing the text and regular
    expression inside the `substring(``string` `from` `pattern``)` function to return
    the matched text. For example, to find the four-digit year, use the following
    query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This query should return `2024`, because we specified that the pattern should
    look for four digits in a row, and 2024 is the only portion of this string that
    matches these criteria. You can check out sample `substring()` queries for all
    the examples in [Table 14-2](#table14-2) in the book’s code resources at [https://nostarch.com/practical-sql-2nd-edition/](https://nostarch.com/practical-sql-2nd-edition/).
  prefs: []
  type: TYPE_NORMAL
- en: Using Regular Expressions with WHERE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’ve filtered queries using `LIKE` and `ILIKE` in `WHERE` clauses. In this
    section, you’ll learn to use regular expressions in `WHERE` clauses so you can
    perform more complex matches.
  prefs: []
  type: TYPE_NORMAL
- en: We use a tilde (`~`) to make a case-sensitive match on a regular expression
    and a tilde-asterisk (`~*`) to perform a case-insensitive match. You can negate
    either expression by adding an exclamation point in front. For example, `!~*`
    indicates to *not* match a regular expression that is case-insensitive. [Listing
    14-1](#listing14-1) shows how this works using the 2019 US Census estimates `us_counties_pop_est_2019`
    table from previous exercises.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-1: Using regular expressions in a `WHERE` clause'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first `WHERE` clause 1 uses the tilde-asterisk (`~*`) to perform a case-insensitive
    match on the regular expression `(lade|lare)` to find any county names that contain
    either the letters `lade` or `lare`. The results should show eight rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, each county name includes the letters `lade` or `lare`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second `WHERE` clause 2 uses the tilde-asterisk (`~*`) as well as a negated
    tilde (`!~`) to find county names containing the letters `ash` but excluding those
    that include `Wash`. This query should return the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: All nine counties in this output have names that contain the letters `ash`,
    but none have `Wash`.
  prefs: []
  type: TYPE_NORMAL
- en: These are fairly simple examples, but you can do more complex matches using
    regular expressions that you wouldn’t be able to perform with the wildcards available
    with just `LIKE` and `ILIKE`.
  prefs: []
  type: TYPE_NORMAL
- en: Regular Expression Functions to Replace or Split Text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Listing 14-2](#listing14-2) shows three regular expression functions that
    replace and split text.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-2: Regular expression functions to replace and split text'
  prefs: []
  type: TYPE_NORMAL
- en: The `regexp_replace(``string``,` `pattern``,` `replacement text``)` function
    lets you substitute a matched pattern with replacement text. In the example at
    1, we’re searching the date string `05/12/2024` for any set of four digits in
    a row using `\d{4}`. When found, we replace them with the replacement text `2023`.
    The result of that query is `05/12/2023` returned as text.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `regexp_split_to_table(``string``,` `pattern``)` function splits delimited
    text into rows. [Listing 14-2](#listing14-2) uses this function to split the string
    `''Four,score,and,seven,years,ago''` on commas 2, resulting in a set of rows that
    has one word in each row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Keep this function in mind as you tackle the “Try It Yourself” exercises at
    the end of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `regexp_split_to_array(``string``,` `pattern``)` function splits delimited
    text into an array. The example splits the string `Phil Mike Tony Steve` on spaces
    3, returning a text array that should look like this in pgAdmin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `text[]` notation in pgAdmin’s column header along with curly brackets around
    the results confirms that this is indeed an array type, which provides another
    means of analysis. For example, you could then use a function such as `array_length()`
    to count the number of words, as shown in [Listing 14-3](#listing14-3).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-3: Finding an array length'
  prefs: []
  type: TYPE_NORMAL
- en: The array that `regexp_split_to_array()` produces is one-dimensional; that is,
    the result contains one list of names. Arrays can have additional dimensions—for
    example, a two-dimensional array can represent a matrix with rows and columns.
    Thus, here we pass `1` as a second argument 1 to `array_length()`, indicating
    we want the length of the first (and only) dimension of the array. The query should
    return `4` because the array has four elements. You can read more about `array_length()`
    and other array functions at [https://www.postgresql.org/docs/current/functions-array.html](https://www.postgresql.org/docs/current/functions-array.html).
  prefs: []
  type: TYPE_NORMAL
- en: If you can identify a pattern in the text, you can use a combination of regular
    expression symbols to locate it. This technique is particularly useful when you
    have repeating patterns in text that you want to turn into a set of data to analyze.
    Let’s practice how to use regular expression functions using a real-world example.
  prefs: []
  type: TYPE_NORMAL
- en: Turning Text to Data with Regular Expression Functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A sheriff’s department in one of the Washington, DC, suburbs publishes daily
    reports that detail the date, time, location, and description of incidents the
    department investigates. These reports would be great to analyze, except they
    post the information in Microsoft Word documents saved as PDF files, which is
    not the friendliest format for importing into a database.
  prefs: []
  type: TYPE_NORMAL
- en: If I copy and paste incidents from the PDF into a text editor, the result is
    blocks of text that look something like [Listing 14-4](#listing14-4).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-4: Crime reports text'
  prefs: []
  type: TYPE_NORMAL
- en: Each block of text includes dates 1, times 2, a street address 3, city or town
    4, the type of crime 5, and a description of the incident 6. The last piece of
    information is a code 7 that might be a unique ID for the incident, although we’d
    have to check with the sheriff’s department to be sure. There are slight inconsistencies.
    For example, the first block of text has two dates (`4/16/17-4/17/17`) and two
    times (`2100-0900 hrs.`), meaning the exact time of the incident is unknown and
    likely occurred within that time span. The second block has one date and time.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you compile these reports regularly, you can expect to find some good insights
    that could answer important questions: Where do crimes tend to occur? Which crime
    types occur most frequently? Do they happen more often on weekends or weekdays?
    Before you can start answering these questions, you’ll need to extract the text
    into table columns using regular expressions.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Table for Crime Reports
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: I’ve collected five of the crime incidents into a file named *crime_reports.csv*
    that you can download via the link to the book’s resources at [https://nostarch.com/practical-sql-2nd-edition/](https://nostarch.com/practical-sql-2nd-edition/).
    Download the file and save it on your computer. Then use the code in [Listing
    14-5](#listing14-5) to build a table that has a column for each data element you
    can parse from the text using a regular expression.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-5: Creating and loading the `crime_reports` table'
  prefs: []
  type: TYPE_NORMAL
- en: Run the `CREATE TABLE` statement in [Listing 14-5](#listing14-5) and then use
    `COPY` to load the text into the column `original_text`. The rest of the columns
    will be `NULL` until we fill them.
  prefs: []
  type: TYPE_NORMAL
- en: When you run `SELECT original_text FROM crime_reports;` in pgAdmin, the results
    grid should display five rows and the first several words of each report. When
    you double-click any cell, pgAdmin shows all the text in that row, as shown in
    [Figure 14-1](#figure14-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![f14001](Images/f14001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14-1: Displaying additional text in the pgAdmin results grid'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you’ve loaded the text you’ll be parsing, let’s explore this data using
    PostgreSQL regular expression functions.
  prefs: []
  type: TYPE_NORMAL
- en: Matching Crime Report Date Patterns
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The first piece of data we want to extract from `original_text` is the date
    or dates of the crime. Most reports have one date, although one has two. The reports
    also have associated times, and we’ll combine the extracted date and time into
    a timestamp. We’ll fill `date_1` with each report’s first (or only) date and time.
    If a second date or second time exists, we’ll add it to `date_2`.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use the `regexp_match(``string``,` `pattern``)` function, which is similar
    to `substring()` with a few exceptions. One is that it returns each match as text
    in an array. Also, if there are no matches, it returns `NULL`. As you might recall
    from Chapter 6, you use an array to pass a list of values into the `percentile_cont()`
    function to calculate quartiles. I’ll show you how to work with results that come
    back as an array when we parse the crime reports.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, let’s use `regexp_match()` to find dates in each of the five incidents.
    The general pattern to match is `MM``/``DD``/``YY`, although there may be one
    or two digits for both the month and date. Here’s a regular expression that matches
    the pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In this expression, the first `\d{1,2}` indicates the month. The numbers inside
    the curly brackets specify that you want at least one digit and at most two digits.
    Next, you want to look for a forward slash (`/`), but because a forward slash
    can have special meaning in regular expressions, you must *escape* that character
    by placing a backslash (`\`) in front of it, like this `\/`. Escaping a character
    in this context simply means we want to treat it as a literal rather than letting
    it take on special meaning. So, the combination of the backslash and forward slash
    (`\/`) indicates you want a forward slash.
  prefs: []
  type: TYPE_NORMAL
- en: Another `\d{1,2}` follows for a single- or double-digit day of the month. The
    expression ends with a second escaped forward slash and `\d{2}` to indicate the
    two-digit year. Let’s pass the expression `\d{1,2}\/\d{1,2}\/\d{2}` to `regexp_match()`,
    as shown in [Listing 14-6](#listing14-6).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-6: Using `regexp_match()` to find the first date'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run that code in pgAdmin, and the results should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that each row shows the first date listed for the incident, because `regexp_match()`
    returns the first match it finds by default. Also note that each date is enclosed
    in curly brackets. That’s PostgreSQL indicating that `regexp_match()` returns
    each result as an array type, or list of elements. Later, in the “Extracting Text
    from the regexp_match() Result” section, I’ll show you how to access elements
    in the array. You also can read more about arrays in PostgreSQL at [https://www.postgresql.org/docs/current/arrays.html](https://www.postgresql.org/docs/current/arrays.html).
  prefs: []
  type: TYPE_NORMAL
- en: Matching the Second Date When Present
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We’ve successfully matched the first date from each report. But recall that
    one of the five incidents has a second date. To find and display all the dates
    in the text, you must use the related `regexp_matches()` function and pass in
    an option in the form of the flag `g`, as shown in [Listing 14-7](#listing14-7).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-7: Using the `regexp_matches()` function with the `g` flag'
  prefs: []
  type: TYPE_NORMAL
- en: The `regexp_matches()` function, when supplied the `g` flag 1, differs from
    `regexp_match()` by returning each match the expression finds as a row in the
    results rather than returning just the first match.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the code again with this revision; you should now see two dates for the
    incident that has a `crime_id` of `1`, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Any time a crime report has a second date, we want to load it and the associated
    time into the `date_2` column. Although adding the `g` flag shows us all the dates,
    to extract just the second date in a report, we can use the pattern we always
    see when two dates exist. In [Listing 14-4](#listing14-4), the first block of
    text showed the two dates separated by a hyphen, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This means you can switch back to `regexp_match()` and write a regular expression
    to look for a hyphen followed by a date, as shown in [Listing 14-8](#listing14-8).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-8: Using `regexp_match()` to find the second date'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although this query finds the second date in the first item (and returns a
    `NULL` for the rest), there’s an unintended consequence: it displays the hyphen
    along with it.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'You don’t want to include the hyphen, because it’s an invalid format for the
    `timestamp` data type. Fortunately, you can specify the exact part of the regular
    expression you want to return by placing parentheses around it to create a capture
    group, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This notation returns only the part of the regular expression you want. Run
    the modified query in [Listing 14-9](#listing14-9) to report only the data in
    parentheses.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-9: Using a capture group to return only the date'
  prefs: []
  type: TYPE_NORMAL
- en: 'The query in [Listing 14-9](#listing14-9) should return just the second date
    without the leading hyphen, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The process you’ve just completed is typical. You start with text to analyze
    and then write and refine the regular expression until it finds the data you want.
    So far, we’ve created regular expressions to match the first date and a second
    date, if it exists. Now, let’s use regular expressions to extract additional data
    elements.
  prefs: []
  type: TYPE_NORMAL
- en: Matching Additional Crime Report Elements
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we’ll capture times, addresses, crime type, description, and
    case number from the crime reports. Here are the expressions for capturing this
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**First hour `\/\d{2}\n(\d{4})`**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first hour, which is the hour the crime was committed or the start of the
    time range, always follows the date in each crime report, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: To find the first hour, we start with an escaped forward slash and `\d{2}`,
    which represents the two-digit year preceding the first date (`17`). The `\n`
    character indicates the newline because the hour always starts on a new line,
    and `\d{4}` represents the four-digit hour (`2100`). Because we just want to return
    the four digits, we put `\d{4}` inside parentheses as a capture group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Second hour `\/\d{2}\n\d{4}-(\d{4})`**'
  prefs: []
  type: TYPE_NORMAL
- en: If the second hour exists, it will follow a hyphen, so we add a hyphen and another
    `\d{4}` to the expression we just created for the first hour. Again, the second
    `\d{4}` goes inside a capture group, because `0900` is the only hour we want to
    return.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Street `hrs.\n(\d+ .+(?:Sq.|Plz.|Dr.|Ter.|Rd.))`**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this data, the street always follows the time’s `hrs.` designation and a
    newline (`\n`), like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The street address always starts with some number that varies in length and
    ends with an abbreviated suffix of some kind. To describe this pattern, we use
    `\d+` to match any digit that appears one or more times. Then we specify a space
    and look for any character one or more times using the dot wildcard and plus sign
    (`.+`) notation. The expression ends with a series of terms separated by the alternation
    pipe symbol that looks like this: `(?:Sq.|Plz.|Dr.|Ter.|Rd.)`. The terms are inside
    parentheses, so the expression will match one or another of those terms. When
    we group terms like this, if we don’t want the parentheses to act as a capture
    group, we need to add `?:` to negate that effect.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**City `(?:Sq.|Plz.|Dr.|Ter.|Rd.)\n(\w+ \w+|\w+)\n`**'
  prefs: []
  type: TYPE_NORMAL
- en: Because the city always follows the street suffix, we reuse the terms separated
    by the alternation symbol we just created for the street. We follow that with
    a newline (`\n`) and then use a capture group to look for two words or one word
    `(\w+ \w+|\w+)` before a final newline, because a town or city name can be more
    than a single word.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Crime type `\n(?:\w+ \w+|\w+)\n(.*):`**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The type of crime always precedes a colon (the only time a colon is used in
    each report) and might consist of one or more words, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: To create an expression that matches this pattern, we follow a newline with
    a nonreporting capture group that looks for the one- or two-word city. Then we
    add another newline and match any character that occurs zero or more times before
    a colon using `(.*):`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Description `:\s(.+)(?:C0|SO)`**'
  prefs: []
  type: TYPE_NORMAL
- en: The crime description always comes between the colon after the crime type and
    the case number. The expression starts with the colon, a space character (`\s`),
    and then a capture group to find any character that appears one or more times
    using the `.+` notation. The nonreporting capture group `(?:C0|SO)` tells the
    program to stop looking when it encounters either `C0` or `SO`, the two character
    pairs that start each case number (a *C* followed by a zero, and an *S* followed
    by a capital *O*). We have to do this because the description might have one or
    more line breaks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Case number `(?:C0|SO)[0-9]+`**'
  prefs: []
  type: TYPE_NORMAL
- en: The case number starts with either `C0` or `SO`, followed by a set of digits.
    To match this pattern, the expression looks for either `C0` or `SO` in a nonreporting
    capture group followed by any digit from 0 to 9 that occurs one or more times
    using the `[0-9]` range notation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now let’s pass some of these regular expressions to `regexp_match()` to see
    them in action. [Listing 14-10](#listing14-10) shows a sample `regexp_match()`
    query that retrieves the case number, first date, crime type, and city.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-10: Matching case number, date, crime type, and city'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the code, and the results should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: After all that wrangling, we’ve transformed the text into a structure that is
    more suitable for analysis. Of course, you would have to include many more incidents
    to count the frequency of crime type by city or by the number of crimes per month
    to identify any trends.
  prefs: []
  type: TYPE_NORMAL
- en: To load each parsed element into the table’s columns, we’ll create an `UPDATE`
    query. But before you can insert the text into a column, you’ll need to learn
    how to extract the text from the array that `regexp_match()` returns.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting Text from the regexp_match() Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In “Matching Crime Report Date Patterns,” I mentioned that `regexp_match()`
    returns data in an array type containing text. Two clues reveal that these are
    array types. The first is that the data type designation in the column header
    shows `text[]` instead of `text`. The second is that each result is surrounded
    by curly brackets. [Figure 14-2](#figure14-2) shows how pgAdmin displays the results
    of the query in [Listing 14-10](#listing14-10).
  prefs: []
  type: TYPE_NORMAL
- en: '![f14002](Images/f14002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14-2: Array values in the pgAdmin results grid'
  prefs: []
  type: TYPE_NORMAL
- en: The `crime_reports` columns we want to update are not array types, so rather
    than passing in the array values returned by `regexp_match()`, we need to extract
    the values from the array first. We do this by using array notation, as shown
    in [Listing 14-11](#listing14-11).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-11: Retrieving a value from within an array'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we wrap the `regexp_match()` function 1 in parentheses. Then, at the
    end, we provide a value of `1`, which represents the first element in the array,
    enclosed in square brackets 2. The query should produce the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Now the data type designation in the pgAdmin column header should show `text`
    instead of `text[]`, and the values are no longer enclosed in curly brackets.
    We can now insert these values into `crime_reports` using an `UPDATE` query.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the crime_reports Table with Extracted Data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To start updating columns in `crime_reports`, [Listing 14-12](#listing14-12)
    combines the extracted first date and time into a single `timestamp` value for
    the column `date_1`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-12: Updating the `crime_reports` `date_1` column'
  prefs: []
  type: TYPE_NORMAL
- en: Because the `date_1` column is of type `timestamp`, we must provide an input
    in that data type. To do that, we’ll use the PostgreSQL double-pipe (`||`) concatenation
    operator to combine the extracted date and time in a format that’s acceptable
    for `timestamp with time zone` input. In the `SET` clause 1, we start with the
    regex pattern that matches the first date 2. Next, we concatenate the date with
    a space using two single quotes 3 and repeat the concatenation operator. This
    step combines the date with a space before connecting it to the regex pattern
    that matches the time 4. Then we include the time zone for the Washington, DC,
    area by concatenating that at the end of the string 5 using the `US/Eastern` designation.
    Concatenating these elements creates a string in the pattern of `MM``/``DD``/``YY``HH:MM``TIMEZONE`,
    which is acceptable as a `timestamp` input. We cast the string to a `timestamp
    with time zone` data type 6 using the PostgreSQL double-colon shorthand and the
    `timestamptz` abbreviation.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you run the `UPDATE`, the `RETURNING` clause will display the columns
    we specify from the updated rows, including the now-filled `date_1` column alongside
    a portion of the `original_text` column, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: At a glance, you can see that `date_1` accurately captures the first date and
    time that appears in the original text and puts it into a format that we can analyze—quantifying,
    for example, which times of day crimes most often occur. Note that if you’re not
    in the Eastern time zone, the timestamps will instead reflect your pgAdmin client’s
    time zone. Also, in pgAdmin, you may need to double-click a cell in the `original_text`
    column to see the full text.
  prefs: []
  type: TYPE_NORMAL
- en: Using CASE to Handle Special Instances
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You could write an `UPDATE` statement for each remaining data element, but combining
    those statements into one would be more efficient. [Listing 14-13](#listing14-13)
    updates all the `crime_reports` columns using a single statement while handling
    inconsistent values in the data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-13: Updating all `crime_reports` columns'
  prefs: []
  type: TYPE_NORMAL
- en: 'This `UPDATE` statement might look intimidating, but it’s not if we break it
    down by column. First, we use the same code from [Listing 14-9](#listing14-9)
    to update the `date_1` column 1. But to update `date_2` 2, we need to account
    for the inconsistent presence of a second date and time. In our limited dataset,
    there are three possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: A second hour exists but not a second date. This occurs when a report covers
    a range of hours on one date.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A second date and second hour exist. This occurs when a report covers more than
    one date.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Neither a second date nor a second hour exists.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To insert the correct value in `date_2` for each scenario, we use a `CASE` statement
    to test for each possibility. After the `CASE` keyword 3, we use a series of `WHEN
    ... THEN` statements to check for the first two conditions and provide the value
    to insert; if neither condition exists, the `CASE` statement will by default return
    a `NULL`.
  prefs: []
  type: TYPE_NORMAL
- en: The first `WHEN` statement 4 checks whether `regexp_match()` returns a `NULL`
    5 for the second date and a value for the second hour (using `IS NOT NULL` 6).
    If that condition evaluates as `true`, the `THEN` statement 7 concatenates the
    first date with the second hour to create a timestamp for the update.
  prefs: []
  type: TYPE_NORMAL
- en: The second `WHEN` statement 8 checks that `regexp_match()` returns a value for
    the second hour and second date. If `true`, the `THEN` statement concatenates
    the second date with the second hour to create a timestamp.
  prefs: []
  type: TYPE_NORMAL
- en: If neither of the two `WHEN` statements returns `true`, the `CASE` statement
    will return a `NULL` because there is only a first date and first time.
  prefs: []
  type: TYPE_NORMAL
- en: When we run the full query in [Listing 14-13](#listing14-13), PostgreSQL should
    report `UPDATE 5`. Success! Now that we’ve updated all the columns with the appropriate
    data while accounting for elements that have additional data, we can examine all
    the columns of the table and find the parsed elements from `original_text`. [Listing
    14-14](#listing14-14) queries four of the columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-14: Viewing selected crime data'
  prefs: []
  type: TYPE_NORMAL
- en: 'The results of the query should show a nicely organized set of data that looks
    something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: You’ve successfully transformed raw text into a table that can answer questions
    and reveal storylines about crime in this area.
  prefs: []
  type: TYPE_NORMAL
- en: The Value of the Process
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Writing regular expressions and coding a query to update a table can take time,
    but there is value to identifying and collecting data this way. In fact, some
    of the best datasets you’ll encounter are those you build yourself. Everyone can
    download the same datasets, but the ones you build are yours alone. You get to
    be first person to find and tell the story behind the data.
  prefs: []
  type: TYPE_NORMAL
- en: Also, after you set up your database and queries, you can use them again and
    again. In this example, you could collect crime reports every day (either by hand
    or by automating downloads using a programming language such as Python) for an
    ongoing dataset that you can mine continually for trends.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll continue our exploration of text by implementing
    a search engine using PostgreSQL.
  prefs: []
  type: TYPE_NORMAL
- en: Full-Text Search in PostgreSQL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PostgreSQL comes with a powerful full-text search engine that adds capabilities
    for searching large amounts of text, similar to online search tools and technology
    that powers search on research databases, such as Factiva. Let’s walk through
    a simple example of setting up a table for text search and associated search functions.
  prefs: []
  type: TYPE_NORMAL
- en: For this example, I assembled 79 speeches by US presidents since World War II.
    Consisting mostly of State of the Union addresses, these public texts are available
    through the Internet Archive at [https://archive.org/](https://archive.org/) and
    the University of California’s American Presidency Project at [https://www.presidency.ucsb.edu/](https://www.presidency.ucsb.edu/).
    You can find the data in the *president_speeches.csv* file along with the book’s
    resources at [https://nostarch.com/practical-sql-2nd-edition/](https://nostarch.com/practical-sql-2nd-edition/).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with the data types unique to full-text search.
  prefs: []
  type: TYPE_NORMAL
- en: Text Search Data Types
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PostgreSQL’s implementation of text search includes two data types. The `tsvector`
    data type represents the text to be searched and to be stored in a normalized
    form. The `tsquery` data type represents the search query terms and operators.
    Let’s look at the details of both.
  prefs: []
  type: TYPE_NORMAL
- en: Storing Text as Lexemes with tsvector
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The `tsvector` data type reduces text to a sorted list of *lexemes*, which are
    linguistic units in a given language. It’s helpful to think of lexemes as word
    roots without the variations created by suffixes. For example, a `tsvector` type
    column would store the words *washes*, *washed*, and *washing* as the lexeme *wash*
    while noting each word’s position in the original text. Converting text to `tsvector`
    also removes small *stop words* that usually don’t play a role in search, such
    as *the* or *it*.
  prefs: []
  type: TYPE_NORMAL
- en: To see how this data type works, let’s convert a string to `tsvector` format.
    [Listing 14-15](#listing14-15) uses the PostgreSQL search function `to_tsvector()`,
    which normalizes the text “I am walking across the sitting room to sit with you”
    to lexemes using the `english` language search configuration.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-15: Converting text to `tsvector` data'
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the code, and it should return the following output in the `tsvector`
    data type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The `to_tsvector()` function reduces the number of words from eleven to four,
    eliminating words such as *I*, *am*, and *the*, which are not helpful search terms.
    The function removes suffixes, changing *walking* to *walk* and *sitting* to *sit*.
    It orders the words alphabetically, and the number following each colon indicates
    its position in the original string, taking stop words into account. Note that
    *sit* is recognized as being in two positions, one for *sitting* and one for *sit*.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Search Terms with tsquery
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The `tsquery` data type represents the full-text search query, again optimized
    as lexemes. It also provides operators for controlling the search. Examples of
    operators include the ampersand (`&`) for AND, the pipe symbol (`|`) for OR, and
    the exclamation point (`!`) for NOT. The `<->` followed by operator lets you search
    for adjacent words or words a certain distance apart.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 14-16](#listing14-16) shows how the `to_tsquery()` function converts
    search terms to the `tsquery` data type.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-16: Converting search terms to `tsquery` data'
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the code, you should see that the resulting `tsquery` data type
    has normalized the terms into lexemes, which match the format of the data to search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Now you can use terms stored as `tsquery` to search text optimized as `tsvector`.
  prefs: []
  type: TYPE_NORMAL
- en: Using the @@ Match Operator for Searching
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: With the text and search terms converted to the full-text search data types,
    you can use the double at sign (`@@`) match operator to check whether a query
    matches text. The first query in [Listing 14-17](#listing14-17) uses `to_tsquery()`
    to evaluate whether the text contains both *walking* and *sitting*, which we combine
    with the `&` operator. It returns a Boolean value of `true` because the lexemes
    of both *walking* and *sitting* are present in the text converted by `to_tsvector()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-17: Querying a `tsvector` type with a `tsquery`'
  prefs: []
  type: TYPE_NORMAL
- en: However, the second query returns `false` because both *walking* and *running*
    are not present in the text. Now let’s build a table for searching the speeches.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Table for Full-Text Search
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The code in [Listing 14-18](#listing14-18) creates and fills `president_speeches`
    with a column for the original text as well as a column of type `tsvector`. After
    the import, we’ll convert the speech text to the `tsvector` data type. Note that
    to accommodate how I set up the CSV file, the `WITH` clause in `COPY` has a different
    set of parameters than what we’ve generally used. It’s pipe-delimited and uses
    an ampersand for quoting.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-18: Creating and filling the `president_speeches` table'
  prefs: []
  type: TYPE_NORMAL
- en: After executing the query, run `SELECT * FROM president_speeches;` to see the
    data. In pgAdmin, double-click any cell to see extra words not visible in the
    results grid. You should see a sizable amount of text in each row of the `speech_text`
    column.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we use the `UPDATE` query in [Listing 14-19](#listing14-19) to copy the
    contents of `speech_text` to the `tsvector` column `search_speech_text` and transform
    it to that data type at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-19: Converting speeches to `tsvector` in the `search_speech_text`
    column'
  prefs: []
  type: TYPE_NORMAL
- en: The `SET` clause 1 fills `search_speech_text` with the output of `to_tsvector()`.
    The first argument in the function specifies the language for parsing the lexemes.
    We’re using `english` here, but you can substitute `spanish`, `german`, `french`,
    and other languages (some languages may require you to find and install additional
    dictionaries). Using `simple` for the language will remove stop words but not
    reduce words to lexemes. The second argument is the name of the input column.
    Run the code to fill the column.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we want to index the `search_speech_text` column to speed up searches.
    You learned about indexing in Chapter 8, which focused on PostgreSQL’s default
    index type, B-tree. For full-text search, the PostgreSQL documentation recommends
    using the *generalized inverted index* (*GIN*). A GIN index, according to the
    documentation, contains “an index entry for each word (lexeme), with a compressed
    list of matching locations.” See [https://www.postgresql.org/docs/current/textsearch-indexes.html](https://www.postgresql.org/docs/current/textsearch-indexes.html)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: You can add a GIN index using `CREATE INDEX` in [Listing 14-20](#listing14-20).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-20: Creating a GIN index for text search'
  prefs: []
  type: TYPE_NORMAL
- en: Now you’re ready to use search functions.
  prefs: []
  type: TYPE_NORMAL
- en: Searching Speech Text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Nearly 80 years’ worth of presidential speeches is fertile ground for exploring
    history. For example, the query in [Listing 14-21](#listing14-21) lists the speeches
    in which the president discussed Vietnam.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-21: Finding speeches containing the word *Vietnam*'
  prefs: []
  type: TYPE_NORMAL
- en: In the `WHERE` clause, the query uses the double at sign (`@@`) match operator
    1 between the `search_speech_text` column (of data type `tsvector`) and the query
    term *Vietnam*, which `to_tsquery()` transforms into `tsquery` data. The results
    should list 19 speeches, showing that the first mention of Vietnam came up in
    a 1961 special message to Congress by John F. Kennedy and became a recurring topic
    starting in 1966 as America’s involvement in the Vietnam War escalated.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Before we try more searches, let’s add a method for showing the location of
    our search term in the text.
  prefs: []
  type: TYPE_NORMAL
- en: Showing Search Result Locations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To see where our search terms appear in text, we can use the `ts_headline()`
    function. It displays one or more highlighted search terms surrounded by adjacent
    words with options to format the display, the number of words to show around the
    matched search term, and how many matched results to show from each row of text.
    [Listing 14-22](#listing14-22) highlights how to display a search for a specific
    instance of the word *tax* using `ts_headline()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-22: Displaying search results with `ts_headline()`'
  prefs: []
  type: TYPE_NORMAL
- en: To declare `ts_headline()` 1, we pass the original `speech_text` column rather
    than the `tsvector` column we used in the search function as the first argument.
    Then, as the second argument, we pass a `to_tsquery()` function that specifies
    the word to highlight. We follow this with a third argument that lists optional
    formatting parameters 2 separated by commas. Here, we specify characters that
    will identify the start and end of the matched search term or terms (`StartSel`
    and `StopSel`). We also set the minimum and maximum number of total words to display,
    including the matched terms (`MinWords` and `MaxWords`), plus the maximum number
    of fragments (or instances of a match) to show using `MaxFragments`. These settings
    are optional, and you can adjust them according to your needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The results of this query should show at most seven words per speech, highlighting
    words in which *tax* is the root:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can quickly see the context of the term we searched. You might also
    use this function to provide flexible display options for a search feature on
    a web application. And notice that we didn’t just find exact matches. The search
    engine identified `tax` along with `taxes`, `Tax`, and `Taxes`—words with *tax*
    as the root and regardless of case.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s continue trying forms of searches.
  prefs: []
  type: TYPE_NORMAL
- en: Using Multiple Search Terms
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As another example, we could look for speeches in which a president mentioned
    the word *transportation* but didn’t discuss *roads*. We might want to do this
    to find speeches that focused on broader policy rather than a specific roads program.
    To do this, we use the syntax in [Listing 14-23](#listing14-23).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-23: Finding speeches with the word *transportation* but not *roads*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we use `ts_headline()` 1 to highlight the terms our search finds. In
    the `to_tsquery()` function in the `WHERE` clause 2, we pass `transportation`
    and `roads`, combining them with the ampersand (`&`) operator. We use the exclamation
    point (`!`) in front of `roads` to indicate that we want speeches that do not
    contain this word. This query should find 15 speeches that fit the criteria. Here
    are the first four rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the highlighted words in the `ts_headline` column include `transportation`
    and `transport`. Again, `to_tsquery()` converted `transportation` to the lexeme
    `transport` for the search term. This database behavior is extremely useful in
    helping to find relevant related words.
  prefs: []
  type: TYPE_NORMAL
- en: Searching for Adjacent Words
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Finally, we’ll use the distance (`<->`) operator, which consists of a hyphen
    between the less-than and greater-than signs, to find adjacent words. Alternatively,
    you can place a number between the signs to find terms that many words apart.
    For example, [Listing 14-24](#listing14-24) searches for any speeches that include
    the word *military* immediately followed by *defense*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-24: Finding speeches where *defense* follows *military*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This query should find five speeches, and because `to_tsquery()` converts the
    search terms to lexemes, the words identified in the speeches should include plurals,
    such as *military defenses*. The following shows the speeches that have the adjacent
    terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: If you changed the query terms to `military <2> defense`, the database would
    return matches where the terms are exactly two words apart, as in the phrase “our
    military and defense commitments.”
  prefs: []
  type: TYPE_NORMAL
- en: Ranking Query Matches by Relevance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also rank search results by relevance using two of PostgreSQL’s full-text
    search functions. These functions are helpful when you’re trying to understand
    which piece of text, or speech in this case, is most relevant to your particular
    search terms.
  prefs: []
  type: TYPE_NORMAL
- en: One function, `ts_rank()`, generates a rank value (returned as a variable-precision
    `real` data type) based on how often the lexemes you’re searching for appear in
    the text. The other function, `ts_rank_cd()`, considers how close the lexemes
    searched are to each other. Both functions can take optional arguments to consider
    document length and other factors. The rank value they generate is an arbitrary
    decimal that’s useful for sorting but doesn’t have any inherent meaning. For example,
    a value of `0.375` generated during one query isn’t directly comparable to the
    same value generated during a different query.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, [Listing 14-25](#listing14-25) uses `ts_rank()` to rank speeches
    containing all the words *war*, *security*, *threat*, and *enemy*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-25: Scoring relevance with `ts_rank()`'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this query, the `ts_rank()` function 1 takes two arguments: the `search_speech_text`
    column and the output of a `to_tsquery()` function containing the search terms.
    The output of the function receives the alias `score`. In the `WHERE` clause 2
    we filter the results to only those speeches that contain the search terms specified.
    Then we order the results in `score` in descending order and return just five
    of the highest-ranking speeches. The results should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Bill Clinton’s 1997 State of the Union message contains the words *war*, *security*,
    *threat*, and *enemy* more often than the other speeches, as he discussed the
    Cold War and other topics. However, it also happens to be one of the longer speeches
    in the table (which you can determine by using `char_length()`, as you learned
    earlier in the chapter). The lengths of speeches influences these rankings because
    `ts_rank()` factors in the number of matching terms in a given text. Two speeches
    by George W. Bush, delivered in the years before and after the start of the Iraq
    War, rank next.
  prefs: []
  type: TYPE_NORMAL
- en: It would be ideal to compare frequencies between speeches of identical lengths
    to get a more accurate ranking, but this isn’t always possible. However, we can
    factor in the length of each speech by adding a normalization code as a third
    parameter of the `ts_rank()` function, as shown in [Listing 14-26](#listing14-26).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 14-26: Normalizing `ts_rank()` by speech length'
  prefs: []
  type: TYPE_NORMAL
- en: Adding the optional code `2` 1 instructs the function to divide the `score`
    by the length of the data in the `search_speech_text` column. This quotient then
    represents a score normalized by the document length, giving an apples-to-apples
    comparison among the speeches. The PostgreSQL documentation at [https://www.postgresql.org/docs/current/textsearch-controls.html](https://www.postgresql.org/docs/current/textsearch-controls.html)
    lists all the options available for text search, including using the document
    length and dividing by the number of unique words.
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the code in [Listing 14-26](#listing14-26), the rankings should
    change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: In contrast to the ranking results in [Listing 14-25](#listing14-25), George
    W. Bush’s 2004 speech now tops the rankings, and Truman’s 1946 message falls out
    of the top five. This might be a more meaningful ranking than the first sample
    output, because we normalized it by length. But three of the five top-ranked speeches
    are the same between the two sets, and you can be reasonably certain that each
    of these three is worthy of closer examination to understand more about presidential
    speeches that include wartime terminology.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Far from being boring, text offers abundant opportunities for data analysis.
    In this chapter, you’ve learned techniques for turning ordinary text into data
    you can extract, quantify, search, and rank. In your work or studies, keep an
    eye out for routine reports that have facts buried inside chunks of text. You
    can use regular expressions to dig them out, turn them into structured data, and
    analyze them to find trends. You can also use search functions to analyze the
    text.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you’ll learn how PostgreSQL can help you analyze geographic
    information.
  prefs: []
  type: TYPE_NORMAL
