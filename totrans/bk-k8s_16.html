<html><head></head><body>
<h2 class="h2" id="ch14"><span epub:type="pagebreak" id="page_233"/><span class="big">14</span><br/>LIMITS AND QUOTAS</h2>&#13;
<div class="image1"><img alt="image" src="../images/common01.jpg"/></div>&#13;
<p class="noindent">For our cluster to provide a predictable environment for applications, we need some control over what resources each individual application component uses. If an application component can use all of the CPU or memory on a given node, the Kubernetes scheduler will not be able to allocate a new Pod to a node confidently, as it won’t know how much available space each node has.</p>&#13;
<p class="indent">In this chapter, we’ll explore how to specify requested resources and limits to ensure that containers get the resources they need without impacting other containers. We’ll inspect individual containers at the runtime level so that we can see how Kubernetes configures the container technology we saw in <a href="part01.xhtml#part01">Part I</a> to adequately meet the resource requirements of a container without allowing the container to exceed its limits.</p>&#13;
<p class="indent">Finally, we’ll look at how role-based access control is used to manage quotas, limiting the amount of resources a given user or application can demand, which will help us understand how to administer a cluster in a manner that allows it to reliably support multiple separate applications or development teams.</p>&#13;
<h3 class="h3" id="ch00lev1sec60"><span epub:type="pagebreak" id="page_234"/>Requests and Limits</h3>&#13;
<p class="noindent">Kubernetes supports many different types of resources, including processing, memory, storage, network bandwidth, and use of special devices such as graphics processing units (GPUs). We’ll look at network limits later in this chapter, but let’s start with the most commonly specified resource types: processing and memory.</p>&#13;
<h4 class="h4" id="ch00lev2sec90">Processing and Memory Limits</h4>&#13;
<p class="noindent">The specifications for processing and memory resources serve two purposes: scheduling and preventing conflicts. Kubernetes provides a different kind of resource specification for each purpose. The Pod’s containers consume processing and memory resources in Kubernetes, so that’s where resource specifications are applied.</p>&#13;
<p class="indent">When scheduling Pods, Kubernetes uses the <span class="literal">requests</span> field in the container specification, summing this field across all containers in the Pod and finding a node with sufficient margin in both processing and memory. Generally, the <span class="literal">requests</span> field is set to the expected average resource requirements for each container in the Pod.</p>&#13;
<p class="indent">The second purpose of resource specification is preventing denial-of-service issues in which one container takes all of a node’s resources, negatively affecting other containers. This requires runtime enforcement of container resources. Kubernetes uses the <span class="literal">limits</span> field of the container specification for this purpose, thus we need to be sure to set the <span class="literal">limits</span> field high enough that a container is able to run correctly without reaching the limit.</p>&#13;
<div class="box5">&#13;
<p class="boxtitle-d"><strong>TUNING FOR PERFORMANCE</strong></p>&#13;
<p class="noindents">The idea that requests should match the expected average resource requirements is based on an assumption that any load spikes in the various containers in the cluster are unpredictable and uncorrelated, and load spikes can therefore be assumed to happen at different times. Even with that assumption, there is a risk that simultaneous load spikes in multiple containers on a node will result in that node being overloaded. And if the load spikes between different Pods are correlated, this risk of overload increases. At the same time, if we configure <span class="literal">requests</span> for the worst case scenario, we can end up with a very large cluster that is idle most of the time. In <a href="ch19.xhtml#ch19">Chapter 19</a>, we explore the different Quality of Service (QoS) classes that Kubernetes offers for Pods and discuss how to find a balance between performance guarantees and cluster efficiency.</p>&#13;
</div>&#13;
<p class="indent"><a href="ch14.xhtml#ch14list1">Listing 14-1</a> kicks off our examination with an example of using requests and limits with a Deployment.</p>&#13;
<p class="noindent6"><em>nginx-limit.yaml</em></p>&#13;
<pre>---&#13;
kind: Deployment&#13;
apiVersion: apps/v1&#13;
metadata:&#13;
  name: nginx&#13;
<span epub:type="pagebreak" id="page_235"/>spec:&#13;
  replicas: 1&#13;
  selector:&#13;
    matchLabels:&#13;
      app: nginx&#13;
  template:&#13;
    metadata:&#13;
      labels:&#13;
        app: nginx&#13;
    spec:&#13;
      containers:&#13;
      - name: nginx&#13;
        image: nginx&#13;
        resources:&#13;
          requests:&#13;
            memory: "64Mi"&#13;
            cpu: "250m"&#13;
          limits:&#13;
            memory: "128Mi"&#13;
            cpu: "500m"&#13;
      nodeName: host01</pre>&#13;
<p class="caption" id="ch14list1"><em>Listing 14-1: Deployment with limits</em></p>&#13;
<p class="indent">We’ll use this Deployment to explore how limits are configured at the level of the container runtime, so we use the <span class="literal">nodeName</span> field to make sure the container ends up on <em>host01</em>. This constrains where the scheduler can place the Pod, but the scheduler still uses the <span class="literal">requests</span> field to ensure that there are sufficient resources. If <em>host01</em> becomes too busy, the scheduler will just refuse to schedule the Pod, similar to what we saw in <a href="ch10.xhtml#ch10">Chapter 10</a>.</p>&#13;
<p class="indent">The <span class="literal">resources</span> field is defined at the level of the individual container, allowing us to specify separate resource requirements for each container in a Pod. For this container, we specify a memory request of <span class="literal">64Mi</span> and a memory limit of <span class="literal">128Mi</span>. The suffix <span class="literal">Mi</span> means that we are using the power-of-2 unit <em>mebibytes</em>, which is 2 to the 20th power, rather than the power-of-10 unit <em>megabytes</em>, which would be the slightly smaller value of 10 to the 6th power.</p>&#13;
<p class="indent">Meanwhile, the processing request and limit specified using the <span class="literal">cpu</span> fields is not based on any absolute unit of processing. Rather, it is based on a synthetic <em>cpu unit</em> for our cluster. Each cpu unit roughly corresponds to one virtual CPU or core. The <span class="literal">m</span> suffix specifies a <em>millicpu</em> so that our <span class="literal">requests</span> value of <span class="literal">250m</span> equates to one quarter of a core, whereas the <span class="literal">limit</span> of <span class="literal">500m</span> equates to half of a core.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>The example repository for this book is at</em> <a href="https://github.com/book-of-kubernetes/examples">https://github.com/book-of-kubernetes/examples</a>. <em>See “Running Examples” on <a href="ch00.xhtml#ch00lev1sec2">page xx</a> for details on getting set up.</em></p>&#13;
</div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_236"/>Let’s create this Deployment:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl apply -f /opt/nginx-limit.yaml</span> &#13;
deployment.apps/nginx created</pre>&#13;
<p class="indent">The Pod will be allocated to <span class="literal">host01</span> and started:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl get pods</span>&#13;
NAME                     READY   STATUS    RESTARTS   AGE&#13;
nginx-56dbd744d9-vg5rj   1/1     Running   0          22m</pre>&#13;
<p class="indent">And <span class="literal">host01</span> will show that resources have been allocated for the Pod:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl describe node host01</span>&#13;
Name:               host01&#13;
...&#13;
Non-terminated Pods:          (15 in total)&#13;
  Namespace Name                   CPU Requests CPU Limits Memory Requests Memory Limits Age&#13;
  --------- ----                   ------------ ---------- --------------- ------------- ---&#13;
...&#13;
  default   nginx-56dbd744d9-vg5rj 250m (12%)   500m (25%) 64M (3%)        128M (6%)     61s&#13;
...</pre>&#13;
<p class="indent">This is true even though our NGINX web server is idle and is not using a lot of processing or memory resources:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl top pods</span>&#13;
...&#13;
NAME                     CPU(cores)   MEMORY(bytes)   &#13;
nginx-56dbd744d9-vg5rj   0m           5Mi</pre>&#13;
<p class="indent">Similar to what we saw in <a href="ch12.xhtml#ch12">Chapter 12</a>, this command queries the metrics add-on that is collecting data from <span class="literal">kubelet</span> running on each cluster node.</p>&#13;
<h4 class="h4" id="ch00lev2sec91">Cgroup Enforcement</h4>&#13;
<p class="noindent">The processing and memory limits we specified are enforced using the Linux control group (cgroup) functionality we described in <a href="ch03.xhtml#ch03">Chapter 3</a>. Kubernetes manages its own space within each hierarchy inside the <em>/sys/fs/cgroup</em> filesystem. For example, memory limits are configured in the memory cgroup:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">ls -1F /sys/fs/cgroup/memory</span>&#13;
...&#13;
kubepods.slice/&#13;
...</pre>&#13;
<p class="indent">Each Pod on a given host has a directory within the <em>kubepods.slice</em> tree. However, finding the specific directory for a given Pod takes some work because Kubernetes divides Pods into different classes of service, and because the name of the cgroup directory does not match the ID of the Pod or its containers.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_237"/>To save us from searching around inside <em>/sys/fs/cgroup</em>, we’ll use a script installed by this chapter’s automated scripts: <em>/opt/cgroup-info</em>. This script uses <span class="literal">crictl</span> to query the container runtime for the cgroup path and then collects CPU and memory limit data from that path. The most important part of the script is this section that collects the path:</p>&#13;
<p class="noindent6"><em>cgroup-info</em></p>&#13;
<pre>#!/bin/bash&#13;
...&#13;
POD_ID=$(crictl pods --name ${POD} -q)&#13;
...&#13;
cgp_field='.info.config.linux.cgroup_parent'&#13;
CGP=$(crictl inspectp $POD_ID | jq -r "$cgp_field")&#13;
&#13;
CPU=/sys/fs/cgroup/cpu/$CGP&#13;
MEM=/sys/fs/cgroup/memory/$CGP&#13;
...</pre>&#13;
<p class="indent">The <span class="literal">crictl pods</span> command collects the Pod’s ID, which is then used with <span class="literal">crictl inspectp</span> and <span class="literal">jq</span> to collect one specific field, called <span class="literal">cgroup_parent</span>. This field is the cgroup subdirectory created for that pod within each resource type.</p>&#13;
<p class="indent">Let’s run this script with our NGINX web server to see how the CPU and memory limits have been configured:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl get pods</span>&#13;
NAME                     READY   STATUS    RESTARTS   AGE&#13;
nginx-56dbd744d9-vg5rj   1/1     Running   0          59m&#13;
root@host01:~# <span class="codestrong1">/opt/cgroup-info</span> <span class="codestrong1"><span class="codeitalic1">nginx-56dbd744d9-vg5rj</span></span>&#13;
&#13;
Container Runtime&#13;
-----------------&#13;
Pod ID: 54602befbd141a74316323b010fb38dae0c2b433cdbe12b5c4d626e6465c7315&#13;
Cgroup path: /kubepods.slice/...9f8f3dcf_6cca_49b8_a3df_d696ece01f59.slice&#13;
&#13;
CPU Settings&#13;
------------&#13;
CPU Shares: 256&#13;
CPU Quota (us): 50000 per 100000&#13;
&#13;
Memory Settings&#13;
---------------&#13;
Limit (bytes): 134217728</pre>&#13;
<p class="indent">We first collect the name of the Pod and then use it to collect cgroup information. Note that this works only because the Pod is running on <span class="literal">host01</span>; the script will work for any Pod, but it must be run from the host on which that Pod is running.</p>&#13;
<p class="indent">There are two key pieces of data for the CPU configuration. The quota is the hard limit; it means that in any given 100,000 microsecond period, <span epub:type="pagebreak" id="page_238"/>this Pod can use only 50,000 microseconds of processor time. This value corresponds to the <span class="literal">500m</span> CPU limit specified in <a href="ch14.xhtml#ch14list1">Listing 14-1</a> (recall that the <span class="literal">500m</span> limit equates to half a core).</p>&#13;
<p class="indent">In addition to this hard limit, the CPU request field we specified in <a href="ch14.xhtml#ch14list1">Listing 14-1</a> has been used to configure the CPU shares. As we saw in <a href="ch03.xhtml#ch03">Chapter 3</a>, this field configures the CPU usage on a relative basis. Because it is relative to the values in neighboring directories, it is unitless, so Kubernetes computes the CPU share on the basis of one core equaling 1,024. We specified a CPU request of <span class="literal">250m</span>, so this equates to 256.</p>&#13;
<p class="indent">The CPU share does not set any kind of limit on CPU usage, so if the system is idle, a Pod can use processing up to its hard limit. However, as the system becomes busy, the CPU share determines how much processing each Pod is allotted relative to others in the same class of service. This helps to ensure that if the system becomes overloaded, all Pods will be degraded fairly based on their CPU request.</p>&#13;
<p class="indent">Finally, for memory, there is a single relevant value. We specified a memory limit of <span class="literal">128Mi</span>, which equates to 128MiB. As we saw in <a href="ch03.xhtml#ch03">Chapter 3</a>, if our container tries to exceed this limit, it will be terminated. For this reason, it is critical to either configure the application such that it does not exceed this value, or to understand how the application acts under load to choose the optimum limit.</p>&#13;
<p class="indent">The amount of memory actually used by a process is ultimately up to that process, meaning that the memory request value has no purpose beyond its initial use in ensuring sufficient memory to schedule the Pod. For this reason, we don’t see the memory request value of <span class="literal">64Mi</span> being used anywhere in the cgroup configuration.</p>&#13;
<p class="indent">The way that resource allocations are reflected in cgroups shows us something important about cluster performance. Because <span class="literal">requests</span> is used for scheduling and <span class="literal">limits</span> is used for runtime enforcement, it is possible for a node to overcommit processing and memory. For the case in which containers have higher <span class="literal">limit</span> than <span class="literal">requests</span>, and containers consistently operate above their <span class="literal">requests</span>, this can cause performance issues with the containers on a node. We’ll discuss this in more detail in <a href="ch19.xhtml#ch19">Chapter 19</a>.</p>&#13;
<p class="indent">We’re finished with our NGINX Deployment, so let’s delete it:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl delete -f /opt/nginx-limit.yaml</span> &#13;
deployment.apps "nginx" deleted</pre>&#13;
<p class="indent">So far, the container runtime can enforce the limits we’ve seen. However, the cluster must enforce other types of limits, such as networking.</p>&#13;
<h4 class="h4" id="ch00lev2sec92">Network Limits</h4>&#13;
<p class="noindent">Ideally, our application will be architected so that required bandwidth for intercommunication is moderate, and our cluster will have sufficient bandwidth to meet the demand of all the containers. However, if we do have a container that tries to take more than its share of the network bandwidth, we need a way to limit it.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_239"/>Because the network devices are configured by plug-ins, we need a plug-in to manage bandwidth. Fortunately, the <span class="literal">bandwidth</span> plug-in is part of the standard set of CNI plug-ins installed with our Kubernetes cluster. Additionally, as we saw in <a href="ch08.xhtml#ch08">Chapter 8</a>, the default CNI configuration enables the <span class="literal">bandwidth</span> plug-in:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">cat /etc/cni/net.d/10-calico.conflist</span> &#13;
{&#13;
  "name": "k8s-pod-network",&#13;
  "cniVersion": "0.3.1",&#13;
  "plugins": [&#13;
...&#13;
    {&#13;
      "type": "bandwidth",&#13;
      "capabilities": {"bandwidth": true}&#13;
    },&#13;
...&#13;
  ]</pre>&#13;
<p class="indent">As a result, <span class="literal">kubelet</span> is already calling the <span class="literal">bandwidth</span> plug-in every time a new Pod is created. If a Pod is configured with bandwidth limits, the plug-in uses the Linux kernel’s traffic control capabilities that we saw in <a href="ch03.xhtml#ch03">Chapter 3</a> to ensure the Pod’s virtual network devices don’t exceed the specified limit.</p>&#13;
<p class="indent">Let’s look at an example. First, let’s deploy an <span class="literal">iperf3</span> server that will listen for client connections:</p>&#13;
<p class="noindent6"><em>iperf-server.yaml</em></p>&#13;
<pre>---&#13;
kind: Deployment&#13;
apiVersion: apps/v1&#13;
metadata:&#13;
  name: iperf-server&#13;
spec:&#13;
  replicas: 1&#13;
  selector:&#13;
    matchLabels:&#13;
      app: iperf-server&#13;
  template:&#13;
    metadata:&#13;
      labels:&#13;
        app: iperf-server&#13;
    spec:&#13;
      containers:&#13;
      - name: iperf&#13;
        image: bookofkubernetes/iperf3:stable&#13;
        env:&#13;
        - name: IPERF_SERVER&#13;
          value: "1"&#13;
        resources: ...&#13;
<span epub:type="pagebreak" id="page_240"/>---&#13;
kind: Service&#13;
apiVersion: v1&#13;
metadata:&#13;
  name: iperf-server&#13;
spec:&#13;
  selector:&#13;
    app: iperf-server&#13;
  ports:&#13;
  - protocol: TCP&#13;
    port: 5201&#13;
    targetPort: 5201</pre>&#13;
<p class="indent">In addition to a Deployment, we also create a Service. This way, our <span class="literal">iperf3</span> clients can find the server under its well-known name of <span class="literal">iperf-server</span>. We specify port 5201, which is the default port for <span class="literal">iperf3</span>.</p>&#13;
<p class="indent">Let’s deploy this server:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl apply -f /opt/iperf-server.yaml</span> &#13;
deployment.apps/iperf-server created&#13;
service/iperf-server created</pre>&#13;
<p class="indent">Let’s run an <span class="literal">iperf3</span> client without applying any bandwidth limits. This will give us a picture of how fast our cluster’s network is without any traffic control. Here’s the client definition:</p>&#13;
<p class="noindent6"><em>iperf.yaml</em></p>&#13;
<pre>---&#13;
kind: Pod&#13;
apiVersion: v1&#13;
metadata:&#13;
  name: iperf&#13;
spec:&#13;
  containers:&#13;
  - name: iperf&#13;
    image: bookofkubernetes/iperf3:stable&#13;
    resources: ...</pre>&#13;
<p class="indent">Normally, <span class="literal">iperf3</span> in client mode would run once and then terminate. This image has a script that runs <span class="literal">iperf3</span> repeatedly, sleeping for one minute between each run. Let’s start a client Pod:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl apply -f /opt/iperf.yaml</span> &#13;
pod/iperf created</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_241"/>It will take a few seconds for the Pod to start running, after which it will take 10 seconds for the initial run. After 30 seconds or so, the Pod log will show the results:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl logs iperf</span>&#13;
Connecting to host iperf-server, port 5201&#13;
[  5] local 172.31.89.200 port 54346 connected to 10.96.0.192 port 5201&#13;
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd&#13;
[  5]   0.00-1.00   sec   152 MBytes  1.28 Gbits/sec  225    281 KBytes       &#13;
[  5]   1.00-2.00   sec   154 MBytes  1.29 Gbits/sec  153    268 KBytes       &#13;
[  5]   2.00-3.00   sec   163 MBytes  1.37 Gbits/sec  230    325 KBytes       &#13;
[  5]   3.00-4.00   sec   171 MBytes  1.44 Gbits/sec  254    243 KBytes       &#13;
[  5]   4.00-5.00   sec   171 MBytes  1.44 Gbits/sec  191    319 KBytes       &#13;
[  5]   5.00-6.00   sec   174 MBytes  1.46 Gbits/sec  230    302 KBytes       &#13;
[  5]   6.00-7.00   sec   180 MBytes  1.51 Gbits/sec  199    221 KBytes       &#13;
[  5]   7.00-8.01   sec   151 MBytes  1.26 Gbits/sec  159    270 KBytes       &#13;
[  5]   8.01-9.00   sec   160 MBytes  1.36 Gbits/sec  145    298 KBytes       &#13;
[  5]   9.00-10.00  sec   147 MBytes  1.23 Gbits/sec  230    276 KBytes       &#13;
- - - - - - - - - - - - - - - - - - - - - - - - -&#13;
[ ID] Interval           Transfer     Bitrate         Retr&#13;
[  5]   0.00-10.00  sec  1.59 GBytes  1.36 Gbits/sec  2016             sender&#13;
[  5]   0.00-10.00  sec  1.59 GBytes  1.36 Gbits/sec                  receiver&#13;
&#13;
iperf Done.</pre>&#13;
<p class="indent">In this case, we see a transfer rate of <span class="literal">1.36 GBits/sec</span> between our client and server. Your results will be different depending on how your cluster is deployed and whether the client and server end up on the same host.</p>&#13;
<p class="indent">Before moving on, we’ll shut down the existing client to prevent it from interfering with our next test:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl delete pod iperf</span>&#13;
pod "iperf" deleted</pre>&#13;
<p class="indent">Obviously, while it’s running, <span class="literal">iperf3</span> is trying to use as much network bandwidth as possible. That’s fine for a test application, but it isn’t polite behavior for an application component in a Kubernetes cluster. To limit its bandwidth, we’ll add an annotation to the Pod definition:</p>&#13;
<p class="noindent6"><em>iperf-limit.yaml</em></p>&#13;
<pre> ---&#13;
 kind: Pod&#13;
 apiVersion: v1&#13;
 metadata:&#13;
   name: iperf-limit&#13;
<span class="ent">➊</span> annotations:&#13;
     kubernetes.io/ingress-bandwidth: 1M&#13;
     kubernetes.io/egress-bandwidth: 1M&#13;
 spec:&#13;
   containers:&#13;
<span epub:type="pagebreak" id="page_242"/>   - name: iperf&#13;
     image: bookofkubernetes/iperf3:stable&#13;
     resources: ...&#13;
   nodeName: host01</pre>&#13;
<p class="indent">We’ll want to inspect how the limits are being applied to the network devices, which will be easier if this Pod ends up on <span class="literal">host01</span>, so we set <span class="literal">nodeName</span> accordingly. Otherwise, the only change in this Pod definition is the <span class="literal">annotations</span> section in the Pod metadata <span class="ent">➊</span>. We set a value of <span class="literal">1M</span> for ingress and egress, corresponding to a 1Mb bandwidth limit on the Pod. When this Pod is scheduled, <span class="literal">kubelet</span> will pick up these annotations and send the specified bandwidth limits to the bandwidth plug-in so that it can configure Linux traffic shaping accordingly.</p>&#13;
<p class="indent">Let’s create this Pod and get a look at this in action:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl apply -f /opt/iperf-limit.yaml</span> &#13;
pod/iperf-limit created</pre>&#13;
<p class="indent">As before, we wait long enough for the client to complete one test with the server and then print the logs:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl logs iperf-limit</span>&#13;
Connecting to host iperf-server, port 5201&#13;
[  5] local 172.31.239.224 port 45680 connected to 10.96.0.192 port 5201&#13;
[ ID] Interval           Transfer     Bitrate         Retr  Cwnd&#13;
[  5]   0.00-1.01   sec  22.7 MBytes 190 Mbits/sec    0   1.37 KBytes       &#13;
[  5]   1.01-2.01   sec  0.00 Bytes  0.00 bits/sec    0    633 KBytes       &#13;
[  5]   2.01-3.00   sec  0.00 Bytes  0.00 bits/sec    0    639 KBytes       &#13;
[  5]   3.00-4.00   sec  0.00 Bytes  0.00 bits/sec    0    646 KBytes       &#13;
[  5]   4.00-5.00   sec  0.00 Bytes  0.00 bits/sec    0    653 KBytes       &#13;
[  5]   5.00-6.00   sec  1.25 MBytes 10.5 Mbits/sec   0    658 KBytes       &#13;
[  5]   6.00-7.00   sec  0.00 Bytes  0.00 bits/sec    0    658 KBytes       &#13;
[  5]   7.00-8.00   sec  0.00 Bytes  0.00 bits/sec    0    658 KBytes       &#13;
[  5]   8.00-9.00   sec  0.00 Bytes  0.00 bits/sec    0    658 KBytes       &#13;
[  5]   9.00-10.00  sec  0.00 Bytes  0.00 bits/sec    0    658 KBytes       &#13;
- - - - - - - - - - - - - - - - - - - - - - - - -&#13;
[ ID] Interval           Transfer     Bitrate         Retr&#13;
[  5]   0.00-10.00  sec  24.0 MBytes  20.1 Mbits/sec    0             sender&#13;
[  5]   0.00-10.10  sec  20.7 MBytes  17.2 Mbits/sec                  receiver&#13;
&#13;
iperf Done.</pre>&#13;
<p class="indent">The change is significant, as the Pod is limited to a fraction of the speed we saw with an unlimited client. However, because the traffic shaping is based on a token bucket filter, the traffic control is inexact over shorter intervals, so we see a bitrate of around 20Mb rather than 1Mb. To see why, let’s look at the actual traffic shaping configuration.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_243"/>The <span class="literal">bandwidth</span> plug-in is applying this token bucket filter to the host side of the virtual Ethernet (veth) pair that was created for the Pod, so we can see it by showing traffic control configuration for the host interfaces:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">tc qdisc show</span>&#13;
...&#13;
qdisc tbf 1: dev calid43b03f2e06 ... rate 1Mbit burst 21474835b lat 4123.2s &#13;
...</pre>&#13;
<p class="indent">The combination of <span class="literal">rate</span> and <span class="literal">burst</span> shows why our Pod was able to achieve 20Mb over the 10-second test run. Because of the <span class="literal">burst</span> value, the Pod was able to send a large quantity of data immediately, at the cost of spending several seconds without any ability to send or receive. Over a much longer interval, we would see an average of 1Mbps, but we would still see this bursting behavior.</p>&#13;
<p class="indent">Before moving on, let’s clean up our client and server:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl delete -f /opt/iperf-server.yaml</span> &#13;
deployment.apps "iperf-server" deleted&#13;
service "iperf-server" deleted&#13;
root@host01:~# <span class="codestrong1">kubectl delete -f /opt/iperf-limit.yaml</span>&#13;
pod "iperf-limit" deleted</pre>&#13;
<p class="indent">Managing the bandwidth of a Pod can be useful, but as we’ve seen, the bandwidth limit can behave like an intermittent connection from the Pod’s perspective. For that reason, this kind of traffic shaping should be considered a last resort for containers that cannot be configured to moderate their own bandwidth usage.</p>&#13;
<h3 class="h3" id="ch00lev1sec61">Quotas</h3>&#13;
<p class="noindent">Limits allow our Kubernetes cluster to ensure that each node has sufficient resources for its assigned Pods. However, if we want our cluster to host multiple applications reliably, we need a way to control the amount of resources that any one application can request.</p>&#13;
<p class="indent">To do this, we’ll use quotas. Quotas are allocated based on Namespaces; they specify the maximum amount of resources that can be allocated within that Namespace. This includes not only the primary resources of CPU and memory but also specialized cluster resources such as GPUs. We can even use quotas to specify the maximum number of a specific object type, such as a Deployment, Service, or CronJob, that can be created within a given Namespace.</p>&#13;
<p class="indent">Because quotas are allocated based on Namespaces, they need to be used in conjunction with the access controls we described in <a href="ch11.xhtml#ch11">Chapter 11</a> to ensure that a given user is bound by the quotas we create. This means that creating Namespaces and applying quotas is typically handled by the cluster administrator.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_244"/>Let’s create a sample Namespace for our Deployment:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl create namespace sample</span>&#13;
namespace/sample created</pre>&#13;
<p class="indent">Now, let’s create a <em>ResourceQuota</em> resource type to apply a quota to the Namespace:</p>&#13;
<p class="noindent6"><em>quota.yaml</em></p>&#13;
<pre>---&#13;
apiVersion: v1&#13;
kind: ResourceQuota&#13;
metadata:&#13;
  name: sample-quota&#13;
  namespace: sample&#13;
spec:&#13;
  hard:&#13;
    requests.cpu: "1"&#13;
    requests.memory: 256Mi&#13;
    limits.cpu: "2"&#13;
    limits.memory: 512Mi</pre>&#13;
<p class="indent">This resource defines a quota for CPU and memory for both requests and limits. The units are the same as those used for limits in the Deployment specification in <a href="ch14.xhtml#ch14list1">Listing 14-1</a>.</p>&#13;
<p class="indent">Let’s apply this quota to the <span class="literal">sample</span> Namespace:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl apply -f /opt/quota.yaml</span>&#13;
resourcequota/sample-quota created</pre>&#13;
<p class="indent">We can see that this quota has been applied successfully:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl describe namespace sample</span>&#13;
Name:         sample&#13;
Labels:       kubernetes.io/metadata.name=sample&#13;
Annotations:  &lt;none&gt;&#13;
Status:       Active&#13;
&#13;
Resource Quotas&#13;
  Name:            sample-quota&#13;
  Resource         Used  Hard&#13;
  --------         ---   ---&#13;
  limits.cpu       0     2&#13;
  limits.memory    0     512Mi&#13;
  requests.cpu     0     1&#13;
  requests.memory  0     256Mi&#13;
...</pre>&#13;
<p class="indent">Even though this quota will apply to all users that try to create Pods in the Namespace, even cluster administrators, it’s more realistic to use a <span epub:type="pagebreak" id="page_245"/>normal user, given that an administrator can always create new Namespaces to get around a quota. Thus, we’ll also create a user:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubeadm kubeconfig user --client-name=me \</span>&#13;
  <span class="codestrong1">--config /etc/kubernetes/kubeadm-init.yaml &gt; kubeconfig</span></pre>&#13;
<p class="indent">As we did in <a href="ch11.xhtml#ch11">Chapter 11</a>, we’ll bind the <span class="literal">edit</span> role to this user to provide the right to create and edit resources in the <span class="literal">sample</span> Namespace. We’ll use the same RoleBinding that we saw in <a href="ch11.xhtml#ch11list1">Listing 11-1</a>:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl apply -f /opt/edit-bind.yaml</span>&#13;
rolebinding.rbac.authorization.k8s.io/editor created</pre>&#13;
<p class="indent">Now that our user is set up, let’s set the <span class="literal">KUBECONFIG</span> environment variable so that future <span class="literal">kubectl</span> commands will operate as our normal user:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">export KUBECONFIG=kubeconfig</span></pre>&#13;
<p class="indent">First, we can verify that the <span class="literal">edit</span> role possessed by our normal user does not enable making changes to quotas in a Namespace, which makes sense—quotas are an administrator function:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl delete -n sample resourcequota sample-quota</span>&#13;
Error from server (Forbidden): resourcequotas "sample-quota" is forbidden: &#13;
User "me" cannot delete resource "resourcequotas" in API group "" in the &#13;
namespace "sample"</pre>&#13;
<p class="indent">We can now create some Pods in the <span class="literal">sample</span> Namespace to test the quota. First, let’s try to create a Pod with no limits:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl run -n sample nginx --image=nginx</span>&#13;
Error from server (Forbidden): pods "nginx" is forbidden: failed quota: &#13;
sample-quota: must specify limits.cpu,limits.memory...</pre>&#13;
<p class="indent">Because our Namespace has a quota, we are no longer allowed to create Pods without specifying limits.</p>&#13;
<p class="indent">In <a href="ch14.xhtml#ch14list2">Listing 14-2</a>, we try it again, this time using a Deployment that specifies resource limits for the Pods it creates.</p>&#13;
<p class="noindent6"><em>sleep.yaml</em></p>&#13;
<pre>---&#13;
kind: Deployment&#13;
apiVersion: apps/v1&#13;
metadata:&#13;
  name: sleep&#13;
  namespace: sample&#13;
spec:&#13;
  replicas: 1&#13;
  selector:&#13;
    matchLabels:&#13;
      app: sleep&#13;
  template:&#13;
<span epub:type="pagebreak" id="page_246"/>    metadata:&#13;
      labels:&#13;
        app: sleep&#13;
    spec:&#13;
      containers:&#13;
      - name: sleep&#13;
        image: busybox&#13;
        command:&#13;
          - "/bin/sleep"&#13;
          - "3600"&#13;
        resources:&#13;
          requests:&#13;
            memory: "64Mi"&#13;
            cpu: "250m"&#13;
          limits:&#13;
            memory: "128Mi"&#13;
            cpu: "512m"</pre>&#13;
<p class="caption" id="ch14list2"><em>Listing 14-2: Deployment with Limit</em></p>&#13;
<p class="indent">Now we can apply this to the cluster:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl apply -n sample -f /opt/sleep.yaml</span> &#13;
deployment.apps/sleep created</pre>&#13;
<p class="indent">This is successful because we specified the necessary request and limit fields and we didn’t exceed our quota. Additionally, a Pod is started with the limits we specified:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl get -n sample pods</span>&#13;
NAME                     READY   STATUS    RESTARTS   AGE&#13;
sleep-688dc46d95-wtppg   1/1     Running   0          72s</pre>&#13;
<p class="indent">However, we can see that we’re now using resources out of our quota:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl describe namespace sample</span>&#13;
Name:         sample&#13;
Labels:       kubernetes.io/metadata.name=sample&#13;
Annotations:  &lt;none&gt;&#13;
Status:       Active&#13;
&#13;
Resource Quotas&#13;
  Name:            sample-quota&#13;
  Resource         Used   Hard&#13;
  --------         ---    ---&#13;
  limits.cpu       512m   2&#13;
  limits.memory    128Mi  512Mi&#13;
  requests.cpu     250m   1&#13;
  requests.memory  64Mi   256Mi&#13;
...</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_247"/>This will limit our ability to scale this Deployment. Let’s illustrate:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl scale -n sample deployment sleep --replicas=12</span>&#13;
deployment.apps/sleep scaled&#13;
root@host01:~# <span class="codestrong1">kubectl get -n sample pods</span>&#13;
NAME                     READY   STATUS    RESTARTS   AGE&#13;
sleep-688dc46d95-trnbl   1/1     Running   0          6s&#13;
sleep-688dc46d95-vzfsx   1/1     Running   0          6s&#13;
sleep-688dc46d95-wtppg   1/1     Running   0          3m13s</pre>&#13;
<p class="indent">We’ve asked for 12 replicas, but we see only three running. If we describe the Deployment we can see an issue:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl describe -n sample deployment sleep</span>&#13;
Name:      sleep&#13;
Namespace: sample&#13;
...&#13;
Replicas:   12 desired | 3 updated | 3 total | 3 available | 9 unavailable&#13;
...&#13;
Conditions:&#13;
  Type             Status  Reason&#13;
  ----             ------  ------&#13;
  Progressing      True    NewReplicaSetAvailable&#13;
  Available        False   MinimumReplicasUnavailable&#13;
  ReplicaFailure   True    FailedCreate&#13;
OldReplicaSets:    &lt;none&gt;&#13;
NewReplicaSet:     sleep-688dc46d95 (3/12 replicas created)&#13;
...</pre>&#13;
<p class="indent">And the Namespace now reports that we have used up enough of our quota that there is no room to allocate the resources needed for another Pod:</p>&#13;
<pre>root@host01:~# <span class="codestrong1">kubectl describe namespace sample</span>&#13;
Name:         sample&#13;
...&#13;
Resource Quotas&#13;
  Name:            sample-quota&#13;
  Resource         Used   Hard&#13;
  --------         ---    ---&#13;
  limits.cpu       1536m  2&#13;
  limits.memory    384Mi  512Mi&#13;
  requests.cpu     750m   1&#13;
  requests.memory  192Mi  256Mi&#13;
...</pre>&#13;
<p class="indent">Our Pods are running <span class="literal">sleep</span>, so we know they’re barely using any CPU or memory. However, Kubernetes bases the quota utilization on what we specified, not what the Pod is actually using. This is critical because processes <span epub:type="pagebreak" id="page_248"/>may use more CPU or allocate more memory as they get busy, and Kubernetes needs to make sure it leaves enough resources for the rest of the cluster to operate correctly.</p>&#13;
<h3 class="h3" id="ch00lev1sec62">Final Thoughts</h3>&#13;
<p class="noindent">For our containerized applications to be reliable, we need to know that one application component can’t take too many resources and effectively starve the other containers running in a cluster. Kubernetes is able to use the resource limit functionality of the underlying container runtime and the Linux kernel to limit each container to only the resources it has been allocated. This practice ensures more reliable scheduling of containers onto nodes in the cluster and ensures that the available cluster resources are shared in a fair way even as the cluster becomes heavily loaded.</p>&#13;
<p class="indent">In this chapter, we’ve seen how to specify resource requirements for our Deployments and how to apply quotas to Namespaces, effectively enabling us to treat all of the nodes in our cluster as one large pool of available resources. In the next chapter, we’ll examine how that same principle extends to storage as we look at dynamically allocating storage to Pods, no matter where they are scheduled.</p>&#13;
</body></html>